{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Denis-R-V/TSR/blob/main/sign_detector_augmentated_v1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ8-zW_yJ279"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis-R-V/TSR/blob/main/sign_detector.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xtJ8o7tJ27-"
      },
      "source": [
        "# Система распознавания дорожных знаков на датасете RTSD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "colab = False\n",
        "\n",
        "if colab == True:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    !pip install kaggle\n",
        "    !mkdir ~/.kaggle\n",
        "    !cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "    \n",
        "    !kaggle datasets download watchman/rtsd-dataset\n",
        "    !unzip rtsd-dataset.zip\n",
        "    !rm rtsd-dataset.zip\n",
        "    !cp -r rtsd-frames/rtsd-frames/ .\n",
        "    !rm -r rtsd-frames/rtsd-frames/\n",
        "\n",
        "    !kaggle datasets download meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\n",
        "    !unzip gtsrb-german-traffic-sign.zip -d GTSRB/\n",
        "    !rm gtsrb-german-traffic-sign.zip\n",
        "\n",
        "    !kaggle datasets download mahadevkonar/belgiumts-dataset\n",
        "    !unzip belgiumts-dataset.zip -d BelgiumTSC/\n",
        "    !rm belgiumts-dataset.zip\n",
        "\n",
        "    !kaggle datasets download dmitryyemelyanov/chinese-traffic-signs\n",
        "    !unzip chinese-traffic-signs.zip -d ChineseTS/\n",
        "    !rm chinese-traffic-signs.zip\n",
        "\n",
        "    !cp /content/drive/MyDrive/TSR/train_anno_reduced_fp_detections.json .\n",
        "    !cp /content/drive/MyDrive/TSR/val_anno_fp_detections.json .\n",
        "    !cp /content/drive/MyDrive/TSR/train_anno_reduced_background.json .\n",
        "    !cp /content/drive/MyDrive/TSR/val_anno_background.json .\n",
        "    !cp /content/drive/MyDrive/TSR/RTSD_train_exp.pkl .\n",
        "\n",
        "    !pip install fiftyone\n",
        "\n",
        "if colab == True:\n",
        "    dataset_path = '.'\n",
        "    checkpoints_path = '../content/drive/MyDrive/TSR/checkpoints'\n",
        "else:\n",
        "    dataset_path = 'data'\n",
        "    checkpoints_path = 'checkpoints'\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "#import matplotlib.patches as patches\n",
        "#%matplotlib inline\n",
        "\n",
        "#from pycocotools.coco import COCO\n",
        "#import fiftyone as fo\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "#from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "#from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models import resnet152\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from sklearn import metrics\n",
        "from torchvision import models\n",
        "#import cv2\n",
        "#PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k69EoY9zJ28Y"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRRoJ7Q4J28Z"
      },
      "source": [
        "### Загрузчик данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''# Удаление категорий с количеством знаков меньше порога\n",
        "sign_threshold = 10\n",
        "filt = lambda x: x.sign.count() > sign_threshold\n",
        "RTSD_train_exp_lim = RTSD_train_exp.groupby('category_id').filter(filt)\n",
        "\n",
        "print(\"Количество уникальных категорий: {}\".format(len(RTSD_train_exp.category_id.unique())))\n",
        "RTSD_train_exp_lim'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>source</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>bbox</th>\n",
              "      <th>category_id</th>\n",
              "      <th>sign</th>\n",
              "      <th>sign_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rtsd-frames/autosave01_02_2012_09_16_49.jpg</td>\n",
              "      <td>RTSD_train</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>[763, 307, 800, 372]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rtsd-frames/autosave16_10_2012_07_15_14_0.jpg</td>\n",
              "      <td>RTSD_train</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>[968, 292, 992, 314]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rtsd-frames/autosave16_10_2012_07_15_14_0.jpg</td>\n",
              "      <td>RTSD_train</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>[781, 234, 875, 320]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rtsd-frames/autosave16_10_2012_07_15_14_1.jpg</td>\n",
              "      <td>RTSD_train</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>[763, 186, 790, 217]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rtsd-frames/autosave16_10_2012_07_15_14_1.jpg</td>\n",
              "      <td>RTSD_train</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>[758, 186, 800, 236]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133818</th>\n",
              "      <td>rtsd-frames/autosave24_10_2013_11_23_19_2.jpg</td>\n",
              "      <td>RTSD_train</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>[767, 306, 806, 366]</td>\n",
              "      <td>154</td>\n",
              "      <td>7_14</td>\n",
              "      <td>Пункт транспортного контроля</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133819</th>\n",
              "      <td>rtsd-frames/autosave24_10_2013_11_23_20_1.jpg</td>\n",
              "      <td>RTSD_train</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>[1143, 101, 1255, 252]</td>\n",
              "      <td>154</td>\n",
              "      <td>7_14</td>\n",
              "      <td>Пункт транспортного контроля</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133820</th>\n",
              "      <td>rtsd-frames/autosave24_10_2013_11_29_00_0.jpg</td>\n",
              "      <td>RTSD_train</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>[762, 367, 798, 384]</td>\n",
              "      <td>155</td>\n",
              "      <td>8_23</td>\n",
              "      <td>Фотовидеофиксация</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133821</th>\n",
              "      <td>rtsd-frames/autosave24_10_2013_11_29_00_1.jpg</td>\n",
              "      <td>RTSD_train</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>[878, 346, 934, 372]</td>\n",
              "      <td>155</td>\n",
              "      <td>8_23</td>\n",
              "      <td>Фотовидеофиксация</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133822</th>\n",
              "      <td>rtsd-frames/autosave24_10_2013_11_29_00_2.jpg</td>\n",
              "      <td>RTSD_train</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>[1203, 283, 1279, 331]</td>\n",
              "      <td>155</td>\n",
              "      <td>8_23</td>\n",
              "      <td>Фотовидеофиксация</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>133823 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            file_name      source width  \\\n",
              "0         rtsd-frames/autosave01_02_2012_09_16_49.jpg  RTSD_train  1280   \n",
              "1       rtsd-frames/autosave16_10_2012_07_15_14_0.jpg  RTSD_train  1280   \n",
              "2       rtsd-frames/autosave16_10_2012_07_15_14_0.jpg  RTSD_train  1280   \n",
              "3       rtsd-frames/autosave16_10_2012_07_15_14_1.jpg  RTSD_train  1280   \n",
              "4       rtsd-frames/autosave16_10_2012_07_15_14_1.jpg  RTSD_train  1280   \n",
              "...                                               ...         ...   ...   \n",
              "133818  rtsd-frames/autosave24_10_2013_11_23_19_2.jpg  RTSD_train  1280   \n",
              "133819  rtsd-frames/autosave24_10_2013_11_23_20_1.jpg  RTSD_train  1280   \n",
              "133820  rtsd-frames/autosave24_10_2013_11_29_00_0.jpg  RTSD_train  1280   \n",
              "133821  rtsd-frames/autosave24_10_2013_11_29_00_1.jpg  RTSD_train  1280   \n",
              "133822  rtsd-frames/autosave24_10_2013_11_29_00_2.jpg  RTSD_train  1280   \n",
              "\n",
              "       height                    bbox  category_id  sign  \\\n",
              "0         720    [763, 307, 800, 372]            0     0   \n",
              "1         720    [968, 292, 992, 314]            0     0   \n",
              "2         720    [781, 234, 875, 320]            0     0   \n",
              "3         720    [763, 186, 790, 217]            0     0   \n",
              "4         720    [758, 186, 800, 236]            0     0   \n",
              "...       ...                     ...          ...   ...   \n",
              "133818    720    [767, 306, 806, 366]          154  7_14   \n",
              "133819    720  [1143, 101, 1255, 252]          154  7_14   \n",
              "133820    720    [762, 367, 798, 384]          155  8_23   \n",
              "133821    720    [878, 346, 934, 372]          155  8_23   \n",
              "133822    720  [1203, 283, 1279, 331]          155  8_23   \n",
              "\n",
              "                           sign_name  \n",
              "0                         Background  \n",
              "1                         Background  \n",
              "2                         Background  \n",
              "3                         Background  \n",
              "4                         Background  \n",
              "...                              ...  \n",
              "133818  Пункт транспортного контроля  \n",
              "133819  Пункт транспортного контроля  \n",
              "133820             Фотовидеофиксация  \n",
              "133821             Фотовидеофиксация  \n",
              "133822             Фотовидеофиксация  \n",
              "\n",
              "[133823 rows x 8 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Загрузка аннотации обучающей выборки (расширенной)\n",
        "anno_train = pd.read_pickle(os.path.join(dataset_path, 'RTSD_train_exp.pkl'))  \n",
        "anno_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>source</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>bbox</th>\n",
              "      <th>category_id</th>\n",
              "      <th>sign</th>\n",
              "      <th>sign_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rtsd-frames/autosave10_10_2012_13_50_36_1.jpg</td>\n",
              "      <td>RTSD_test</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>[622, 375, 652, 402]</td>\n",
              "      <td>3</td>\n",
              "      <td>1_17</td>\n",
              "      <td>Искусственная неровность</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>rtsd-frames/autosave16_04_2013_15_11_26_1.jpg</td>\n",
              "      <td>RTSD_test</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>[1050, 436, 1079, 459]</td>\n",
              "      <td>3</td>\n",
              "      <td>1_17</td>\n",
              "      <td>Искусственная неровность</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>rtsd-frames/autosave16_04_2013_13_19_50_2.jpg</td>\n",
              "      <td>RTSD_test</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>[1033, 506, 1076, 546]</td>\n",
              "      <td>3</td>\n",
              "      <td>1_17</td>\n",
              "      <td>Искусственная неровность</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>rtsd-frames/autosave13_04_2013_11_07_29_0.jpg</td>\n",
              "      <td>RTSD_test</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>[1185, 380, 1221, 415]</td>\n",
              "      <td>3</td>\n",
              "      <td>1_17</td>\n",
              "      <td>Искусственная неровность</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>rtsd-frames/autosave16_04_2013_13_19_50_0.jpg</td>\n",
              "      <td>RTSD_test</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>[979, 530, 1014, 558]</td>\n",
              "      <td>3</td>\n",
              "      <td>1_17</td>\n",
              "      <td>Искусственная неровность</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7311</th>\n",
              "      <td>rtsd-frames/autosave16_04_2013_13_34_06_2.jpg</td>\n",
              "      <td>RTSD_test</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>[1192, 838, 1222, 866]</td>\n",
              "      <td>147</td>\n",
              "      <td>1_26</td>\n",
              "      <td>Перегон скота</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8035</th>\n",
              "      <td>rtsd-frames/autosave24_10_2013_11_21_12_0.jpg</td>\n",
              "      <td>RTSD_test</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>[869, 350, 894, 390]</td>\n",
              "      <td>153</td>\n",
              "      <td>7_18</td>\n",
              "      <td>Туалет</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8126</th>\n",
              "      <td>rtsd-frames/autosave10_10_2012_09_29_51_1.jpg</td>\n",
              "      <td>RTSD_test</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>[781, 333, 812, 362]</td>\n",
              "      <td>133</td>\n",
              "      <td>5_12</td>\n",
              "      <td>Конец дороги с полосой для маршрутных транспор...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8436</th>\n",
              "      <td>rtsd-frames/autosave16_10_2012_08_36_42_0.jpg</td>\n",
              "      <td>RTSD_test</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>[820, 316, 843, 358]</td>\n",
              "      <td>149</td>\n",
              "      <td>6_8_1</td>\n",
              "      <td>Тупик (прямо)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8668</th>\n",
              "      <td>rtsd-frames/autosave09_10_2012_11_07_59_3.jpg</td>\n",
              "      <td>RTSD_test</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>[799, 333, 851, 386]</td>\n",
              "      <td>114</td>\n",
              "      <td>2_7</td>\n",
              "      <td>Преимущество перед встречным движением</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8866 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          file_name     source  width  height  \\\n",
              "0     rtsd-frames/autosave10_10_2012_13_50_36_1.jpg  RTSD_test   1280     720   \n",
              "53    rtsd-frames/autosave16_04_2013_15_11_26_1.jpg  RTSD_test   1920    1080   \n",
              "61    rtsd-frames/autosave16_04_2013_13_19_50_2.jpg  RTSD_test   1920    1080   \n",
              "78    rtsd-frames/autosave13_04_2013_11_07_29_0.jpg  RTSD_test   1920    1080   \n",
              "90    rtsd-frames/autosave16_04_2013_13_19_50_0.jpg  RTSD_test   1920    1080   \n",
              "...                                             ...        ...    ...     ...   \n",
              "7311  rtsd-frames/autosave16_04_2013_13_34_06_2.jpg  RTSD_test   1920    1080   \n",
              "8035  rtsd-frames/autosave24_10_2013_11_21_12_0.jpg  RTSD_test   1280     720   \n",
              "8126  rtsd-frames/autosave10_10_2012_09_29_51_1.jpg  RTSD_test   1280     720   \n",
              "8436  rtsd-frames/autosave16_10_2012_08_36_42_0.jpg  RTSD_test   1280     720   \n",
              "8668  rtsd-frames/autosave09_10_2012_11_07_59_3.jpg  RTSD_test   1280     720   \n",
              "\n",
              "                        bbox  category_id   sign  \\\n",
              "0       [622, 375, 652, 402]            3   1_17   \n",
              "53    [1050, 436, 1079, 459]            3   1_17   \n",
              "61    [1033, 506, 1076, 546]            3   1_17   \n",
              "78    [1185, 380, 1221, 415]            3   1_17   \n",
              "90     [979, 530, 1014, 558]            3   1_17   \n",
              "...                      ...          ...    ...   \n",
              "7311  [1192, 838, 1222, 866]          147   1_26   \n",
              "8035    [869, 350, 894, 390]          153   7_18   \n",
              "8126    [781, 333, 812, 362]          133   5_12   \n",
              "8436    [820, 316, 843, 358]          149  6_8_1   \n",
              "8668    [799, 333, 851, 386]          114    2_7   \n",
              "\n",
              "                                              sign_name  \n",
              "0                              Искусственная неровность  \n",
              "53                             Искусственная неровность  \n",
              "61                             Искусственная неровность  \n",
              "78                             Искусственная неровность  \n",
              "90                             Искусственная неровность  \n",
              "...                                                 ...  \n",
              "7311                                      Перегон скота  \n",
              "8035                                             Туалет  \n",
              "8126  Конец дороги с полосой для маршрутных транспор...  \n",
              "8436                                      Тупик (прямо)  \n",
              "8668             Преимущество перед встречным движением  \n",
              "\n",
              "[8866 rows x 8 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Загрузка аннотации тестовой выборки\n",
        "with open(os.path.join(dataset_path, 'val_anno.json'), 'r') as read_file:\n",
        "    val_anno_json = json.load(read_file)\n",
        "read_file.close()\n",
        "\n",
        "anno_val = pd.DataFrame(val_anno_json.get('annotations'))\n",
        "anno_images_val = pd.DataFrame(val_anno_json.get('images'))\n",
        "anno_val = anno_val.merge(anno_images_val, left_on='image_id', right_on='id')[['file_name', 'width', 'height', 'bbox','category_id']]\n",
        "\n",
        "# Приведение bbox из формата COCO (x1, y1, w, h) к виду (x1, y1, x2, y2)\n",
        "anno_val['bbox'] = anno_val['bbox'].apply (lambda x: [x[0], x[1], x[0] + x[2], x[1] + x[3]])\n",
        "\n",
        "# Добавим вспомогательную колонку с источником изображения (датасет)\n",
        "anno_val.insert(1, 'source', 'RTSD_test')\n",
        "\n",
        "# Добавим для визуалиции labels\n",
        "with open(os.path.join(dataset_path, 'label_map.json'), 'r') as read_file:\n",
        "    label_map = json.load(read_file)\n",
        "read_file.close()\n",
        "\n",
        "anno_val = anno_val.merge(pd.DataFrame([label_map]).T.reset_index().set_index(0), left_on='category_id', right_index=True)\n",
        "anno_val.rename(columns={'index':'sign'}, inplace=True)\n",
        "\n",
        "# Добавим столбец с наименованием знака\n",
        "with open(os.path.join(dataset_path, 'labels_names_map.json'), 'r') as read_file:\n",
        "    labels_names_map = json.load(read_file)\n",
        "read_file.close()\n",
        "\n",
        "anno_val = anno_val.merge(pd.DataFrame([labels_names_map]).T, left_on='sign', right_index=True)\n",
        "anno_val.rename(columns={0:'sign_name'}, inplace=True)\n",
        "\n",
        "anno_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RTSD_extended_classifier(Dataset):\n",
        "    def __init__(self, dataset_path, annotation, transforms, sampling=False, samples_in_class=None):\n",
        "        \n",
        "        self.dataset_path = dataset_path\n",
        "        self.dataset = annotation\n",
        "        self.transforms = transforms\n",
        "        self.transforms_lib = None\n",
        "        try:\n",
        "            self.transforms.additional_targets == {}\n",
        "            self.transforms_lib = 'albumentations'\n",
        "        except:\n",
        "            self.transforms_lib = 'torchvision'\n",
        "\n",
        "        # Функция балансировки классов равным количество сэмплов\n",
        "        if sampling == True:\n",
        "            dataset_new = pd.DataFrame(columns = self.dataset.columns)\n",
        "            categories = list(self.dataset.category_id.unique())\n",
        "            if samples_in_class is None:\n",
        "                samples_in_class = self.dataset.category_id.value_counts().max()\n",
        "            for category in categories:\n",
        "                category_id = int(category)\n",
        "                df_cat_orig = self.dataset[self.dataset['category_id'] == category_id].copy()\n",
        "                df_cat_sampled = pd.DataFrame(columns = self.dataset.columns)\n",
        "                if samples_in_class//len(df_cat_orig) > 0:\n",
        "                    for i in range(samples_in_class//len(df_cat_orig)):\n",
        "                        df_cat_sampled = pd.concat((df_cat_sampled, df_cat_orig))\n",
        "                if len(df_cat_sampled) < samples_in_class:\n",
        "                    samples = df_cat_orig.sample(n=(samples_in_class - len(df_cat_sampled)), replace=True)\n",
        "                    df_cat_sampled = pd.concat((df_cat_sampled, samples))    \n",
        "                dataset_new = pd.concat((dataset_new, df_cat_sampled))\n",
        "            dataset_new.reset_index(inplace=True)\n",
        "            del dataset_new['index']\n",
        "            self.dataset = dataset_new\n",
        "\n",
        "        # вариант с codecamp\n",
        "        #dataset.groupby('category_id', group_keys= False).apply(lambda x: x.sample(2, replace=True))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.dataset.loc[index,'file_name']\n",
        "        bbox = self.dataset.loc[index,'bbox']\n",
        "        \n",
        "        if (self.dataset.loc[index,'source'] == 'RTSD_train') or (self.dataset.loc[index,'source'] == 'RTSD_test'):\n",
        "            #width = self.dataset.loc[index,'width']\n",
        "            #height = self.dataset.loc[index,'height']\n",
        "            sign_w = bbox[2] - bbox[0]\n",
        "            sign_h = bbox[3] - bbox[1]\n",
        "            x1 = max(bbox[0] - round(max((sign_w*0.05), 5)), 0)\n",
        "            y1 = max(bbox[1] - round(max((sign_h*0.05), 5)), 0)\n",
        "            x2 = min(bbox[2] + round(max((sign_w*0.05), 5)), self.dataset.loc[index,'width'])\n",
        "            y2 = min(bbox[3] + round(max((sign_h*0.05), 5)), self.dataset.loc[index,'height'])\n",
        "            bbox = [x1, y1, x2, y2]\n",
        "\n",
        "        img = Image.open(os.path.join(self.dataset_path, img_name))\n",
        "        img = img.crop(bbox)\n",
        "        \n",
        "        if self.transforms_lib == 'torchvision':\n",
        "            img = self.transforms(img)\n",
        "        elif self.transforms_lib == 'albumentations':\n",
        "            img = np.array(img).astype(np.float32)/255.\n",
        "            img = self.transforms(image=img)['image']\n",
        "            img = img.float()\n",
        "        else:\n",
        "            print('Ошибка выбора библиотеки аугментации')\n",
        "\n",
        "        label = torch.tensor(self.dataset.loc[index,'category_id'])\n",
        "    \n",
        "        \n",
        "        #from PIL import ImageOps\n",
        "        #old_img = Image.open(image_path)\n",
        "        # создание нового изображения с белым фоном\n",
        "        #new_image = ImageOps.expand(old_img, border=25, fill=(255,255,255))\n",
        "\n",
        "        return {'images':img, 'labels':label}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "    # Send train=True fro training transforms and False for val/test transforms\n",
        "def get_transform(augmentation_lib = 'torchvision', train=False):\n",
        "    if augmentation_lib =='torchvision':\n",
        "        if train == True:\n",
        "            return transforms.Compose([transforms.Resize((224,224)),\n",
        "                                       transforms.RandomPerspective(distortion_scale=0.4,p=0.7),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.ColorJitter(brightness=(0.5), contrast=(0.4), saturation=(0.4)),\n",
        "                                       transforms.GaussianBlur(11, sigma=(0.1, 2.0)),\n",
        "                                       transforms.RandomAdjustSharpness(5),\n",
        "                                       transforms.RandomRotation(10),\n",
        "                                       transforms.RandomResizedCrop((224,224), scale=(0.85, 1)), # Случайная обрезка изображения в диапахоне 85 - 100% и resize в исходный размер\n",
        "                                       #transforms.Normalize([0.485, 0.456, 0.406],      # 1 496\n",
        "                                       #                     [0.229, 0.224, 0.225]),\n",
        "                                       transforms.RandomErasing(p = 0.4, scale = (0.003, 0.1)),\n",
        "                                       transforms.RandomErasing(p = 0.6, scale = (0.003, 0.05)),\n",
        "                                       transforms.RandomErasing(p = 0.6, scale = (0.003, 0.05)),\n",
        "                                       transforms.RandomErasing(p = 0.6, scale = (0.003, 0.02)),\n",
        "                                       transforms.RandomErasing(p = 0.6, scale = (0.003, 0.02)),\n",
        "                                       transforms.RandomErasing(p = 0.6, scale = (0.001, 0.01)),\n",
        "                                       transforms.RandomErasing(p = 0.6, scale = (0.001, 0.01)),\n",
        "                                       transforms.RandomErasing(p = 0.6, scale = (0.001, 0.01)),\n",
        "                                       transforms.RandomErasing(p = 0.6, scale = (0.001, 0.01)),\n",
        "                                       transforms.RandomErasing(p = 0.6, scale = (0.001, 0.01)),\n",
        "                                       ])\n",
        "        else:\n",
        "            return transforms.Compose([transforms.Resize((224,224)),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       #transforms.Normalize([0.485, 0.456, 0.406],      # 1 496\n",
        "                                       #                     [0.229, 0.224, 0.225])\n",
        "                                       ])   \n",
        "    \n",
        "    elif augmentation_lib =='albumentations':\n",
        "        if train==True:\n",
        "            return A.Compose([A.augmentations.geometric.resize.Resize (224, 224, interpolation=1, always_apply=False, p=1),\n",
        "                              A.augmentations.transforms.GaussNoise (var_limit=(0.01, 0.05), mean=0, per_channel=False, always_apply=False, p=0.3),\n",
        "                              A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
        "                              A.RandomFog(fog_coef_lower=0.2, fog_coef_upper=0.3, alpha_coef=0.1, p=0.05), #Туман\n",
        "                              A.RandomRain(brightness_coefficient=0.9, drop_width=1, blur_value=5, p=0.05),\n",
        "                              A.Rotate(limit=10, p=0.5),\n",
        "                              ToTensorV2(p=1.0)\n",
        "                              ])\n",
        "            \n",
        "        else:\n",
        "            return A.Compose([A.augmentations.geometric.resize.Resize (224, 224, interpolation=1, always_apply=False, p=1),\n",
        "                              ToTensorV2(p=1.0)\n",
        "                              ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_tvs = RTSD_extended_classifier(dataset_path,\n",
        "                                  annotation = anno_train,\n",
        "                                  transforms = get_transform(augmentation_lib = 'torchvision', train=True),\n",
        "                                  sampling=True,\n",
        "                                  samples_in_class = 10\n",
        "                                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_sign(dataset, index):\n",
        "    item = dataset.__getitem__(index)\n",
        "    img = item['images']\n",
        "    target = item['labels']\n",
        "    #img, target = test.__getitem__(index)\n",
        "    img = img.permute(1, 2, 0).detach().numpy()\n",
        "    img = img*255\n",
        "    img = img.astype(np.uint8)\n",
        "    fig, a = plt.subplots(1,1)\n",
        "    #fig.set_size_inches(10,10)\n",
        "    display(int(target.cpu().detach().numpy()))\n",
        "    a.imshow(img)\n",
        "    return None\n",
        "plot_sign(test_1, 111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 373,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_alb = RTSD_extended_classifier(dataset_path,\n",
        "                                    annotation = anno_train,\n",
        "                                    transforms = get_transform(augmentation_lib = 'albumentations', train=True),\n",
        "                                    sampling=True,\n",
        "                                    samples_in_class = 10\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 383,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_sign(dataset, index):\n",
        "    item = dataset.__getitem__(index)\n",
        "    img = item['images']\n",
        "    target = item['labels']\n",
        "    #img, target = test.__getitem__(index)\n",
        "    img = img.permute(1, 2, 0).detach().numpy()\n",
        "    img = img*255\n",
        "    img = img.astype(np.uint8)\n",
        "    fig, a = plt.subplots(1,1)\n",
        "    #fig.set_size_inches(10,10)\n",
        "    display(int(target.cpu().detach().numpy()))\n",
        "    a.imshow(img)\n",
        "    return None\n",
        "plot_sign(test_alb, 904)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J90qxR2RJ28Z"
      },
      "source": [
        "### Гиперпараметры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "CI7vlkQPJ28Z"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device_id = 0\n",
        "if torch.cuda.is_available() == True:\n",
        "    device = f'cuda:{device_id}'\n",
        "elif torch.backends.mps.is_available() == True:\n",
        "    device = 'mps'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "\n",
        "model_name = 'resnet152_sampled_full_tvs_adam_001'\n",
        "last_epoch = None\n",
        "n_epochs = 20\n",
        "batch_size = 32\n",
        "num_classes = 156\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo40ASBXJ28Z"
      },
      "source": [
        "### Инициализация модели, задание оптимизатора и функции потерь"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TNQ4zYcHtHId"
      },
      "outputs": [],
      "source": [
        "def create_model(num_classes):\n",
        "    model = resnet152(weights='ResNet152_Weights.IMAGENET1K_V2')\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    #model.fc = nn.Sequential(nn.Linear(2048, 1024), nn.Linear(1024, num_classes))\n",
        "    #model.fc = nn.Sequential(nn.Linear(2048, num_classes))\n",
        "    for param in model.fc.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#checkpoint = torch.load(os.path.join(checkpoints_path, f'chkpt_classifier_{model_name}_{last_epoch}.pth'), map_location=device)\n",
        "#checkpoint.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "242586dd62d544a39c122c7b1ed6efc9",
            "78cb1778f71b45b88ffdb20bfe0cd66e",
            "6d83c78727204f529982e56c3bfe32c1",
            "55191ea6a8eb4574aff8a9bc21fdd55a",
            "ae7f4e349b634abd8b36184774421f7a",
            "e012c54a3a9f48b38c500c17227f67b8",
            "91eb94ac4f6347c6b7d860b73e3742da",
            "4146164713eb4c2db70cf52335398a3e",
            "e66226838c994913b2d58fd0db3f4282",
            "b17d80f4da05457781be26c19a1dca17",
            "8e403bce502349d28da4553899f80c33"
          ]
        },
        "id": "ZdWxX5-PJ28Z",
        "outputId": "d572c5f8-341f-46c4-adb3-14866216da69"
      },
      "outputs": [],
      "source": [
        "model = create_model(num_classes).to(device)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# parameters\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "#optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.0005)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)\n",
        "#optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "    # and a learning rate scheduler\n",
        "#lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "#lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "\n",
        "\n",
        "# Загрузка весов модели, состояния оптимизатора и шедулера\n",
        "if last_epoch is not None:\n",
        "    checkpoint = torch.load(os.path.join(checkpoints_path, f'chkpt_classifier_{model_name}_{last_epoch}.pth'), map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
        "\n",
        "train_dataset = RTSD_extended_classifier(dataset_path,\n",
        "                                         annotation = anno_train,\n",
        "                                         transforms = get_transform(augmentation_lib = 'torchvision', train=True),\n",
        "                                         sampling=True,\n",
        "                                         samples_in_class = 500\n",
        "                                         )\n",
        "\n",
        "val_dataset = RTSD_extended_classifier(dataset_path,\n",
        "                                       annotation = anno_val,\n",
        "                                       transforms = get_transform(augmentation_lib = 'torchvision', train=False)\n",
        "                                       )\n",
        "\n",
        "train_data_loader = DataLoader(\n",
        "                                train_dataset,\n",
        "                                #sampler=SubsetRandomSampler(),\n",
        "                                batch_size=batch_size,\n",
        "                                shuffle=True,\n",
        "                                #num_workers=4,\n",
        "                                #collate_fn=collate_fn\n",
        "                            )\n",
        "\n",
        "val_data_loader = DataLoader(\n",
        "                            val_dataset,\n",
        "                            #sampler=SubsetRandomSampler(),\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=False,\n",
        "                            #num_workers=4,\n",
        "                            #collate_fn=collate_fn\n",
        "                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YimGoL3J28Z"
      },
      "source": [
        "### Трейн луп"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(train_dataloader, epoch): \n",
        "    len_dataloader = len(train_dataloader)\n",
        "\n",
        "    training_loss=0\n",
        "    # для текущего accuracy\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    # для вывода метрик\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0        # training_loss\n",
        "    \n",
        "    for batch_idx, data in enumerate(train_dataloader):\n",
        "        \n",
        "        \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        #images, targets = data[0], data[1]\n",
        "        #images = images.to(device)\n",
        "        #targets = targets.to(device)\n",
        "        images = data['images'].to(device)\n",
        "        targets = data['labels'].to(device)\n",
        "        output = model(images)\n",
        "        loss = loss_function(output, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "       \n",
        "        running_loss = running_loss + ((1/(batch_idx+1))*(loss.data-running_loss))\n",
        "        if batch_idx%20 == 0:\n",
        "            print(f\"Batch Id {batch_idx}/{len_dataloader} is having training loss of {running_loss}\")\n",
        "            print(loss.item())\n",
        "\n",
        "        pred = output.data.max(1,keepdim=True)[1]\n",
        "\n",
        "        # для текущего accuracy\n",
        "        correct += np.sum(np.squeeze(pred.eq(targets.data.view_as(pred))).cpu().numpy())\n",
        "        total += images.size(0)\n",
        "        print(f\"Epoch #{epoch}. Accuracy on batch {batch_idx}/{len_dataloader}  on Training is {(100*correct/total)}\")\n",
        "        \n",
        "        # для вывода метрик\n",
        "        y_true.extend([int(item) for item in targets])\n",
        "        y_pred.extend([int(item) for item in pred])\n",
        "\n",
        "        #images = list(image.to(device) for image in images)\n",
        "        #targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        #loss_dict = model(images, targets)\n",
        "        #loss = sum(loss for loss in loss_dict.values())\n",
        "        #running_loss += loss.item()\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "        #if batch_idx % 50 == 0:\n",
        "        #    print(f\"\\tЭпоха {epoch}. Итерация {batch_idx}/{len_dataloader}. Loss: {loss}\")\n",
        "    train_loss = running_loss/len(train_dataloader.dataset)\n",
        "    train_accuracy = metrics.accuracy_score(y_true, y_pred)\n",
        "    train_f1_micro = metrics.f1_score(y_true, y_pred, average=\"micro\")\n",
        "    train_f1_macro =  metrics.f1_score(y_true, y_pred, average=\"macro\")\n",
        "    train_f1_weighted = metrics.f1_score(y_true, y_pred, average=\"weighted\")\n",
        "    return train_loss, train_accuracy, train_f1_micro, train_f1_macro, train_f1_weighted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def val (val_dataloader, epoch):\n",
        "    len_dataloader = len(val_dataloader)\n",
        "\n",
        "    validation_loss=0\n",
        "    # для текущего accuracy\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    # для вывода метрик\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for batch_idx, data in enumerate(val_dataloader):\n",
        "        \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        #images, targets = data[0], data[1]\n",
        "        #images = images.to(device)\n",
        "        #targets = targets.to(device)\n",
        "        images = data['images'].to(device)\n",
        "        targets = data['labels'].to(device)\n",
        "        #with torch.no_grad():\n",
        "            \n",
        "        output = model(images)\n",
        "        loss = loss_function(output, targets)\n",
        "        \n",
        "        validation_loss = validation_loss + ((1/(batch_idx+1))*(loss.data-validation_loss))\n",
        "        #if batch_idx%20 == 0:\n",
        "        print(f\"Epoch #{epoch}. Batch Id {batch_idx}/{len_dataloader}  is having validation loss of {validation_loss}\")\n",
        "        print(loss.item())\n",
        "        pred = output.data.max(1,keepdim=True)[1]\n",
        "\n",
        "        # для текущего accuracy\n",
        "        correct += np.sum(np.squeeze(pred.eq(targets.data.view_as(pred))).cpu().numpy())\n",
        "        total += images.size(0)\n",
        "        print(f\"Epoch #{epoch}. Batch Id {batch_idx}/{len_dataloader}  is having validation accuracy of {(100*correct/total)}\")\n",
        "\n",
        "        # для вывода метрик\n",
        "        y_true.extend([int(item) for item in targets])\n",
        "        y_pred.extend([int(item) for item in pred])\n",
        "        #images = list(image.to(device) for image in images)\n",
        "        #targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        #loss_dict = model(images, targets)\n",
        "        #loss = sum(loss for loss in loss_dict.values())\n",
        "        #running_loss += loss.item()\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "        #if batch_idx % 50 == 0:\n",
        "        #    print(f\"\\tЭпоха {epoch}. Итерация {batch_idx}/{len_dataloader}. Loss: {loss}\")\n",
        "    val_loss = validation_loss/len(val_dataloader.dataset)\n",
        "    val_accuracy = metrics.accuracy_score(y_true, y_pred)\n",
        "    val_f1_micro = metrics.f1_score(y_true, y_pred, average=\"micro\")\n",
        "    val_f1_macro =  metrics.f1_score(y_true, y_pred, average=\"macro\")\n",
        "    val_f1_weighted = metrics.f1_score(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "\n",
        "    return val_loss, val_accuracy, val_f1_micro, val_f1_macro, val_f1_weighted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Id 0/2438 is having training loss of 5.054804801940918\n",
            "5.054804801940918\n",
            "Epoch #0. Accuracy on batch 0/2438  on Training is 0.0\n",
            "Epoch #0. Accuracy on batch 1/2438  on Training is 0.0\n",
            "Epoch #0. Accuracy on batch 2/2438  on Training is 0.0\n",
            "Epoch #0. Accuracy on batch 3/2438  on Training is 0.0\n",
            "Epoch #0. Accuracy on batch 4/2438  on Training is 0.625\n",
            "Epoch #0. Accuracy on batch 5/2438  on Training is 0.5208333333333334\n",
            "Epoch #0. Accuracy on batch 6/2438  on Training is 0.44642857142857145\n",
            "Epoch #0. Accuracy on batch 7/2438  on Training is 0.390625\n",
            "Epoch #0. Accuracy on batch 8/2438  on Training is 0.3472222222222222\n",
            "Epoch #0. Accuracy on batch 9/2438  on Training is 0.3125\n",
            "Epoch #0. Accuracy on batch 10/2438  on Training is 0.5681818181818182\n",
            "Epoch #0. Accuracy on batch 11/2438  on Training is 1.3020833333333333\n",
            "Epoch #0. Accuracy on batch 12/2438  on Training is 1.2019230769230769\n",
            "Epoch #0. Accuracy on batch 13/2438  on Training is 1.1160714285714286\n",
            "Epoch #0. Accuracy on batch 14/2438  on Training is 1.25\n",
            "Epoch #0. Accuracy on batch 15/2438  on Training is 1.171875\n",
            "Epoch #0. Accuracy on batch 16/2438  on Training is 1.286764705882353\n",
            "Epoch #0. Accuracy on batch 17/2438  on Training is 1.3888888888888888\n",
            "Epoch #0. Accuracy on batch 18/2438  on Training is 1.644736842105263\n",
            "Epoch #0. Accuracy on batch 19/2438  on Training is 1.5625\n",
            "Batch Id 20/2438 is having training loss of 5.202823162078857\n",
            "5.2962212562561035\n",
            "Epoch #0. Accuracy on batch 20/2438  on Training is 1.7857142857142858\n",
            "Epoch #0. Accuracy on batch 21/2438  on Training is 1.8465909090909092\n",
            "Epoch #0. Accuracy on batch 22/2438  on Training is 1.9021739130434783\n",
            "Epoch #0. Accuracy on batch 23/2438  on Training is 1.8229166666666667\n",
            "Epoch #0. Accuracy on batch 24/2438  on Training is 2.0\n",
            "Epoch #0. Accuracy on batch 25/2438  on Training is 2.1634615384615383\n",
            "Epoch #0. Accuracy on batch 26/2438  on Training is 2.199074074074074\n",
            "Epoch #0. Accuracy on batch 27/2438  on Training is 2.232142857142857\n",
            "Epoch #0. Accuracy on batch 28/2438  on Training is 2.3706896551724137\n",
            "Epoch #0. Accuracy on batch 29/2438  on Training is 2.3958333333333335\n",
            "Epoch #0. Accuracy on batch 30/2438  on Training is 2.9233870967741935\n",
            "Epoch #0. Accuracy on batch 31/2438  on Training is 2.9296875\n",
            "Epoch #0. Accuracy on batch 32/2438  on Training is 3.0303030303030303\n",
            "Epoch #0. Accuracy on batch 33/2438  on Training is 3.2169117647058822\n",
            "Epoch #0. Accuracy on batch 34/2438  on Training is 3.2142857142857144\n",
            "Epoch #0. Accuracy on batch 35/2438  on Training is 3.3854166666666665\n",
            "Epoch #0. Accuracy on batch 36/2438  on Training is 3.6317567567567566\n",
            "Epoch #0. Accuracy on batch 37/2438  on Training is 3.700657894736842\n",
            "Epoch #0. Accuracy on batch 38/2438  on Training is 3.766025641025641\n",
            "Epoch #0. Accuracy on batch 39/2438  on Training is 3.75\n",
            "Batch Id 40/2438 is having training loss of 5.073734760284424\n",
            "4.6262946128845215\n",
            "Epoch #0. Accuracy on batch 40/2438  on Training is 3.9634146341463414\n",
            "Epoch #0. Accuracy on batch 41/2438  on Training is 4.166666666666667\n",
            "Epoch #0. Accuracy on batch 42/2438  on Training is 4.069767441860465\n",
            "Epoch #0. Accuracy on batch 43/2438  on Training is 3.977272727272727\n",
            "Epoch #0. Accuracy on batch 44/2438  on Training is 4.236111111111111\n",
            "Epoch #0. Accuracy on batch 45/2438  on Training is 4.211956521739131\n",
            "Epoch #0. Accuracy on batch 46/2438  on Training is 4.321808510638298\n",
            "Epoch #0. Accuracy on batch 47/2438  on Training is 4.557291666666667\n",
            "Epoch #0. Accuracy on batch 48/2438  on Training is 4.528061224489796\n",
            "Epoch #0. Accuracy on batch 49/2438  on Training is 4.6875\n",
            "Epoch #0. Accuracy on batch 50/2438  on Training is 4.7181372549019605\n",
            "Epoch #0. Accuracy on batch 51/2438  on Training is 4.8076923076923075\n",
            "Epoch #0. Accuracy on batch 52/2438  on Training is 4.893867924528302\n",
            "Epoch #0. Accuracy on batch 53/2438  on Training is 4.918981481481482\n",
            "Epoch #0. Accuracy on batch 54/2438  on Training is 5.0\n",
            "Epoch #0. Accuracy on batch 55/2438  on Training is 5.022321428571429\n",
            "Epoch #0. Accuracy on batch 56/2438  on Training is 4.989035087719298\n",
            "Epoch #0. Accuracy on batch 57/2438  on Training is 5.226293103448276\n",
            "Epoch #0. Accuracy on batch 58/2438  on Training is 5.4025423728813555\n",
            "Epoch #0. Accuracy on batch 59/2438  on Training is 5.572916666666667\n",
            "Batch Id 60/2438 is having training loss of 4.925441741943359\n",
            "4.472593307495117\n",
            "Epoch #0. Accuracy on batch 60/2438  on Training is 5.635245901639344\n",
            "Epoch #0. Accuracy on batch 61/2438  on Training is 5.846774193548387\n",
            "Epoch #0. Accuracy on batch 62/2438  on Training is 6.001984126984127\n",
            "Epoch #0. Accuracy on batch 63/2438  on Training is 5.95703125\n",
            "Epoch #0. Accuracy on batch 64/2438  on Training is 6.346153846153846\n",
            "Epoch #0. Accuracy on batch 65/2438  on Training is 6.4393939393939394\n",
            "Epoch #0. Accuracy on batch 66/2438  on Training is 6.669776119402985\n",
            "Epoch #0. Accuracy on batch 67/2438  on Training is 6.893382352941177\n",
            "Epoch #0. Accuracy on batch 68/2438  on Training is 7.065217391304348\n",
            "Epoch #0. Accuracy on batch 69/2438  on Training is 7.142857142857143\n",
            "Epoch #0. Accuracy on batch 70/2438  on Training is 7.350352112676056\n",
            "Epoch #0. Accuracy on batch 71/2438  on Training is 7.378472222222222\n",
            "Epoch #0. Accuracy on batch 72/2438  on Training is 7.491438356164384\n",
            "Epoch #0. Accuracy on batch 73/2438  on Training is 7.6858108108108105\n",
            "Epoch #0. Accuracy on batch 74/2438  on Training is 7.75\n",
            "Epoch #0. Accuracy on batch 75/2438  on Training is 7.8125\n",
            "Epoch #0. Accuracy on batch 76/2438  on Training is 7.832792207792208\n",
            "Epoch #0. Accuracy on batch 77/2438  on Training is 7.772435897435898\n",
            "Epoch #0. Accuracy on batch 78/2438  on Training is 7.871835443037975\n",
            "Epoch #0. Accuracy on batch 79/2438  on Training is 7.890625\n",
            "Batch Id 80/2438 is having training loss of 4.788638114929199\n",
            "4.358397483825684\n",
            "Epoch #0. Accuracy on batch 80/2438  on Training is 7.986111111111111\n",
            "Epoch #0. Accuracy on batch 81/2438  on Training is 8.117378048780488\n",
            "Epoch #0. Accuracy on batch 82/2438  on Training is 8.32078313253012\n",
            "Epoch #0. Accuracy on batch 83/2438  on Training is 8.370535714285714\n",
            "Epoch #0. Accuracy on batch 84/2438  on Training is 8.639705882352942\n",
            "Epoch #0. Accuracy on batch 85/2438  on Training is 8.684593023255815\n",
            "Epoch #0. Accuracy on batch 86/2438  on Training is 8.836206896551724\n",
            "Epoch #0. Accuracy on batch 87/2438  on Training is 8.948863636363637\n",
            "Epoch #0. Accuracy on batch 88/2438  on Training is 8.95365168539326\n",
            "Epoch #0. Accuracy on batch 89/2438  on Training is 9.131944444444445\n",
            "Epoch #0. Accuracy on batch 90/2438  on Training is 9.134615384615385\n",
            "Epoch #0. Accuracy on batch 91/2438  on Training is 9.273097826086957\n",
            "Epoch #0. Accuracy on batch 92/2438  on Training is 9.475806451612904\n",
            "Epoch #0. Accuracy on batch 93/2438  on Training is 9.54122340425532\n",
            "Epoch #0. Accuracy on batch 94/2438  on Training is 9.671052631578947\n",
            "Epoch #0. Accuracy on batch 95/2438  on Training is 9.700520833333334\n",
            "Epoch #0. Accuracy on batch 96/2438  on Training is 9.664948453608247\n",
            "Epoch #0. Accuracy on batch 97/2438  on Training is 9.78954081632653\n",
            "Epoch #0. Accuracy on batch 98/2438  on Training is 9.91161616161616\n",
            "Epoch #0. Accuracy on batch 99/2438  on Training is 10.0625\n",
            "Batch Id 100/2438 is having training loss of 4.682738780975342\n",
            "4.356311321258545\n",
            "Epoch #0. Accuracy on batch 100/2438  on Training is 10.055693069306932\n",
            "Epoch #0. Accuracy on batch 101/2438  on Training is 10.17156862745098\n",
            "Epoch #0. Accuracy on batch 102/2438  on Training is 10.16383495145631\n",
            "Epoch #0. Accuracy on batch 103/2438  on Training is 10.306490384615385\n",
            "Epoch #0. Accuracy on batch 104/2438  on Training is 10.297619047619047\n",
            "Epoch #0. Accuracy on batch 105/2438  on Training is 10.43632075471698\n",
            "Epoch #0. Accuracy on batch 106/2438  on Training is 10.514018691588785\n",
            "Epoch #0. Accuracy on batch 107/2438  on Training is 10.590277777777779\n",
            "Epoch #0. Accuracy on batch 108/2438  on Training is 10.693807339449542\n",
            "Epoch #0. Accuracy on batch 109/2438  on Training is 10.767045454545455\n",
            "Epoch #0. Accuracy on batch 110/2438  on Training is 10.951576576576576\n",
            "Epoch #0. Accuracy on batch 111/2438  on Training is 11.049107142857142\n",
            "Epoch #0. Accuracy on batch 112/2438  on Training is 11.255530973451327\n",
            "Epoch #0. Accuracy on batch 113/2438  on Training is 11.293859649122806\n",
            "Epoch #0. Accuracy on batch 114/2438  on Training is 11.41304347826087\n",
            "Epoch #0. Accuracy on batch 115/2438  on Training is 11.476293103448276\n",
            "Epoch #0. Accuracy on batch 116/2438  on Training is 11.458333333333334\n",
            "Epoch #0. Accuracy on batch 117/2438  on Training is 11.49364406779661\n",
            "Epoch #0. Accuracy on batch 118/2438  on Training is 11.554621848739496\n",
            "Epoch #0. Accuracy on batch 119/2438  on Training is 11.666666666666666\n",
            "Batch Id 120/2438 is having training loss of 4.589071750640869\n",
            "4.03920316696167\n",
            "Epoch #0. Accuracy on batch 120/2438  on Training is 11.647727272727273\n",
            "Epoch #0. Accuracy on batch 121/2438  on Training is 11.757172131147541\n",
            "Epoch #0. Accuracy on batch 122/2438  on Training is 11.788617886178862\n",
            "Epoch #0. Accuracy on batch 123/2438  on Training is 11.794354838709678\n",
            "Epoch #0. Accuracy on batch 124/2438  on Training is 11.85\n",
            "Epoch #0. Accuracy on batch 125/2438  on Training is 11.879960317460318\n",
            "Epoch #0. Accuracy on batch 126/2438  on Training is 11.934055118110237\n",
            "Epoch #0. Accuracy on batch 127/2438  on Training is 11.9384765625\n",
            "Epoch #0. Accuracy on batch 128/2438  on Training is 11.89437984496124\n",
            "Epoch #0. Accuracy on batch 129/2438  on Training is 11.923076923076923\n",
            "Epoch #0. Accuracy on batch 130/2438  on Training is 11.951335877862595\n",
            "Epoch #0. Accuracy on batch 131/2438  on Training is 12.026515151515152\n",
            "Epoch #0. Accuracy on batch 132/2438  on Training is 12.147556390977444\n",
            "Epoch #0. Accuracy on batch 133/2438  on Training is 12.220149253731343\n",
            "Epoch #0. Accuracy on batch 134/2438  on Training is 12.337962962962964\n",
            "Epoch #0. Accuracy on batch 135/2438  on Training is 12.454044117647058\n",
            "Epoch #0. Accuracy on batch 136/2438  on Training is 12.477189781021897\n",
            "Epoch #0. Accuracy on batch 137/2438  on Training is 12.5\n",
            "Epoch #0. Accuracy on batch 138/2438  on Training is 12.567446043165468\n",
            "Epoch #0. Accuracy on batch 139/2438  on Training is 12.65625\n",
            "Batch Id 140/2438 is having training loss of 4.509130001068115\n",
            "3.875375270843506\n",
            "Epoch #0. Accuracy on batch 140/2438  on Training is 12.699468085106384\n",
            "Epoch #0. Accuracy on batch 141/2438  on Training is 12.852112676056338\n",
            "Epoch #0. Accuracy on batch 142/2438  on Training is 12.91520979020979\n",
            "Epoch #0. Accuracy on batch 143/2438  on Training is 12.91232638888889\n",
            "Epoch #0. Accuracy on batch 144/2438  on Training is 12.952586206896552\n",
            "Epoch #0. Accuracy on batch 145/2438  on Training is 12.970890410958905\n",
            "Epoch #0. Accuracy on batch 146/2438  on Training is 13.031462585034014\n",
            "Epoch #0. Accuracy on batch 147/2438  on Training is 13.07010135135135\n",
            "Epoch #0. Accuracy on batch 148/2438  on Training is 13.024328859060402\n",
            "Epoch #0. Accuracy on batch 149/2438  on Training is 13.041666666666666\n",
            "Epoch #0. Accuracy on batch 150/2438  on Training is 13.100165562913908\n",
            "Epoch #0. Accuracy on batch 151/2438  on Training is 13.178453947368421\n",
            "Epoch #0. Accuracy on batch 152/2438  on Training is 13.235294117647058\n",
            "Epoch #0. Accuracy on batch 153/2438  on Training is 13.311688311688311\n",
            "Epoch #0. Accuracy on batch 154/2438  on Training is 13.42741935483871\n",
            "Epoch #0. Accuracy on batch 155/2438  on Training is 13.521634615384615\n",
            "Epoch #0. Accuracy on batch 156/2438  on Training is 13.57484076433121\n",
            "Epoch #0. Accuracy on batch 157/2438  on Training is 13.60759493670886\n",
            "Epoch #0. Accuracy on batch 158/2438  on Training is 13.698899371069182\n",
            "Epoch #0. Accuracy on batch 159/2438  on Training is 13.7109375\n",
            "Batch Id 160/2438 is having training loss of 4.429170608520508\n",
            "3.756107807159424\n",
            "Epoch #0. Accuracy on batch 160/2438  on Training is 13.74223602484472\n",
            "Epoch #0. Accuracy on batch 161/2438  on Training is 13.811728395061728\n",
            "Epoch #0. Accuracy on batch 162/2438  on Training is 13.88036809815951\n",
            "Epoch #0. Accuracy on batch 163/2438  on Training is 14.024390243902438\n",
            "Epoch #0. Accuracy on batch 164/2438  on Training is 14.053030303030303\n",
            "Epoch #0. Accuracy on batch 165/2438  on Training is 14.0625\n",
            "Epoch #0. Accuracy on batch 166/2438  on Training is 14.127994011976048\n",
            "Epoch #0. Accuracy on batch 167/2438  on Training is 14.136904761904763\n",
            "Epoch #0. Accuracy on batch 168/2438  on Training is 14.201183431952662\n",
            "Epoch #0. Accuracy on batch 169/2438  on Training is 14.283088235294118\n",
            "Epoch #0. Accuracy on batch 170/2438  on Training is 14.345760233918128\n",
            "Epoch #0. Accuracy on batch 171/2438  on Training is 14.462209302325581\n",
            "Epoch #0. Accuracy on batch 172/2438  on Training is 14.505057803468208\n",
            "Epoch #0. Accuracy on batch 173/2438  on Training is 14.583333333333334\n",
            "Epoch #0. Accuracy on batch 174/2438  on Training is 14.625\n",
            "Epoch #0. Accuracy on batch 175/2438  on Training is 14.683948863636363\n",
            "Epoch #0. Accuracy on batch 176/2438  on Training is 14.74223163841808\n",
            "Epoch #0. Accuracy on batch 177/2438  on Training is 14.799859550561798\n",
            "Epoch #0. Accuracy on batch 178/2438  on Training is 14.839385474860336\n",
            "Epoch #0. Accuracy on batch 179/2438  on Training is 14.98263888888889\n",
            "Batch Id 180/2438 is having training loss of 4.36061429977417\n",
            "3.960805892944336\n",
            "Epoch #0. Accuracy on batch 180/2438  on Training is 15.003453038674033\n",
            "Epoch #0. Accuracy on batch 181/2438  on Training is 15.07554945054945\n",
            "Epoch #0. Accuracy on batch 182/2438  on Training is 15.163934426229508\n",
            "Epoch #0. Accuracy on batch 183/2438  on Training is 15.251358695652174\n",
            "Epoch #0. Accuracy on batch 184/2438  on Training is 15.219594594594595\n",
            "Epoch #0. Accuracy on batch 185/2438  on Training is 15.305779569892474\n",
            "Epoch #0. Accuracy on batch 186/2438  on Training is 15.340909090909092\n",
            "Epoch #0. Accuracy on batch 187/2438  on Training is 15.408909574468085\n",
            "Epoch #0. Accuracy on batch 188/2438  on Training is 15.443121693121693\n",
            "Epoch #0. Accuracy on batch 189/2438  on Training is 15.526315789473685\n",
            "Epoch #0. Accuracy on batch 190/2438  on Training is 15.543193717277488\n",
            "Epoch #0. Accuracy on batch 191/2438  on Training is 15.608723958333334\n",
            "Epoch #0. Accuracy on batch 192/2438  on Training is 15.60880829015544\n",
            "Epoch #0. Accuracy on batch 193/2438  on Training is 15.625\n",
            "Epoch #0. Accuracy on batch 194/2438  on Training is 15.721153846153847\n",
            "Epoch #0. Accuracy on batch 195/2438  on Training is 15.720663265306122\n",
            "Epoch #0. Accuracy on batch 196/2438  on Training is 15.815355329949238\n",
            "Epoch #0. Accuracy on batch 197/2438  on Training is 15.893308080808081\n",
            "Epoch #0. Accuracy on batch 198/2438  on Training is 15.986180904522612\n",
            "Epoch #0. Accuracy on batch 199/2438  on Training is 16.0625\n",
            "Batch Id 200/2438 is having training loss of 4.291268348693848\n",
            "3.5786240100860596\n",
            "Epoch #0. Accuracy on batch 200/2438  on Training is 16.106965174129353\n",
            "Epoch #0. Accuracy on batch 201/2438  on Training is 16.135519801980198\n",
            "Epoch #0. Accuracy on batch 202/2438  on Training is 16.148399014778324\n",
            "Epoch #0. Accuracy on batch 203/2438  on Training is 16.222426470588236\n",
            "Epoch #0. Accuracy on batch 204/2438  on Training is 16.3109756097561\n",
            "Epoch #0. Accuracy on batch 205/2438  on Training is 16.32281553398058\n",
            "Epoch #0. Accuracy on batch 206/2438  on Training is 16.34963768115942\n",
            "Epoch #0. Accuracy on batch 207/2438  on Training is 16.436298076923077\n",
            "Epoch #0. Accuracy on batch 208/2438  on Training is 16.477272727272727\n",
            "Epoch #0. Accuracy on batch 209/2438  on Training is 16.50297619047619\n",
            "Epoch #0. Accuracy on batch 210/2438  on Training is 16.528436018957347\n",
            "Epoch #0. Accuracy on batch 211/2438  on Training is 16.568396226415093\n",
            "Epoch #0. Accuracy on batch 212/2438  on Training is 16.69600938967136\n",
            "Epoch #0. Accuracy on batch 213/2438  on Training is 16.764018691588785\n",
            "Epoch #0. Accuracy on batch 214/2438  on Training is 16.86046511627907\n",
            "Epoch #0. Accuracy on batch 215/2438  on Training is 16.927083333333332\n",
            "Epoch #0. Accuracy on batch 216/2438  on Training is 16.9786866359447\n",
            "Epoch #0. Accuracy on batch 217/2438  on Training is 17.029816513761467\n",
            "Epoch #0. Accuracy on batch 218/2438  on Training is 16.980593607305938\n",
            "Epoch #0. Accuracy on batch 219/2438  on Training is 17.03125\n",
            "Batch Id 220/2438 is having training loss of 4.227950096130371\n",
            "3.692741870880127\n",
            "Epoch #0. Accuracy on batch 220/2438  on Training is 17.05316742081448\n",
            "Epoch #0. Accuracy on batch 221/2438  on Training is 17.06081081081081\n",
            "Epoch #0. Accuracy on batch 222/2438  on Training is 17.054372197309416\n",
            "Epoch #0. Accuracy on batch 223/2438  on Training is 17.061941964285715\n",
            "Epoch #0. Accuracy on batch 224/2438  on Training is 17.11111111111111\n",
            "Epoch #0. Accuracy on batch 225/2438  on Training is 17.228982300884955\n",
            "Epoch #0. Accuracy on batch 226/2438  on Training is 17.22191629955947\n",
            "Epoch #0. Accuracy on batch 227/2438  on Training is 17.256030701754387\n",
            "Epoch #0. Accuracy on batch 228/2438  on Training is 17.34443231441048\n",
            "Epoch #0. Accuracy on batch 229/2438  on Training is 17.36413043478261\n",
            "Epoch #0. Accuracy on batch 230/2438  on Training is 17.397186147186147\n",
            "Epoch #0. Accuracy on batch 231/2438  on Training is 17.510775862068964\n",
            "Epoch #0. Accuracy on batch 232/2438  on Training is 17.556330472103003\n",
            "Epoch #0. Accuracy on batch 233/2438  on Training is 17.588141025641026\n",
            "Epoch #0. Accuracy on batch 234/2438  on Training is 17.726063829787233\n",
            "Epoch #0. Accuracy on batch 235/2438  on Training is 17.796610169491526\n",
            "Epoch #0. Accuracy on batch 236/2438  on Training is 17.89293248945148\n",
            "Epoch #0. Accuracy on batch 237/2438  on Training is 17.949054621848738\n",
            "Epoch #0. Accuracy on batch 238/2438  on Training is 17.97855648535565\n",
            "Epoch #0. Accuracy on batch 239/2438  on Training is 18.020833333333332\n",
            "Batch Id 240/2438 is having training loss of 4.1668925285339355\n",
            "3.6984221935272217\n",
            "Epoch #0. Accuracy on batch 240/2438  on Training is 18.04979253112033\n",
            "Epoch #0. Accuracy on batch 241/2438  on Training is 18.078512396694215\n",
            "Epoch #0. Accuracy on batch 242/2438  on Training is 18.132716049382715\n",
            "Epoch #0. Accuracy on batch 243/2438  on Training is 18.212090163934427\n",
            "Epoch #0. Accuracy on batch 244/2438  on Training is 18.239795918367346\n",
            "Epoch #0. Accuracy on batch 245/2438  on Training is 18.33079268292683\n",
            "Epoch #0. Accuracy on batch 246/2438  on Training is 18.31983805668016\n",
            "Epoch #0. Accuracy on batch 247/2438  on Training is 18.384576612903224\n",
            "Epoch #0. Accuracy on batch 248/2438  on Training is 18.48644578313253\n",
            "Epoch #0. Accuracy on batch 249/2438  on Training is 18.475\n",
            "Epoch #0. Accuracy on batch 250/2438  on Training is 18.563247011952193\n",
            "Epoch #0. Accuracy on batch 251/2438  on Training is 18.625992063492063\n",
            "Epoch #0. Accuracy on batch 252/2438  on Training is 18.675889328063242\n",
            "Epoch #0. Accuracy on batch 253/2438  on Training is 18.7376968503937\n",
            "Epoch #0. Accuracy on batch 254/2438  on Training is 18.762254901960784\n",
            "Epoch #0. Accuracy on batch 255/2438  on Training is 18.798828125\n",
            "Epoch #0. Accuracy on batch 256/2438  on Training is 18.82295719844358\n",
            "Epoch #0. Accuracy on batch 257/2438  on Training is 18.859011627906977\n",
            "Epoch #0. Accuracy on batch 258/2438  on Training is 18.88272200772201\n",
            "Epoch #0. Accuracy on batch 259/2438  on Training is 18.990384615384617\n",
            "Batch Id 260/2438 is having training loss of 4.106672286987305\n",
            "3.465812921524048\n",
            "Epoch #0. Accuracy on batch 260/2438  on Training is 19.02538314176245\n",
            "Epoch #0. Accuracy on batch 261/2438  on Training is 19.0243320610687\n",
            "Epoch #0. Accuracy on batch 262/2438  on Training is 19.047053231939163\n",
            "Epoch #0. Accuracy on batch 263/2438  on Training is 19.105113636363637\n",
            "Epoch #0. Accuracy on batch 264/2438  on Training is 19.18632075471698\n",
            "Epoch #0. Accuracy on batch 265/2438  on Training is 19.208176691729324\n",
            "Epoch #0. Accuracy on batch 266/2438  on Training is 19.22986891385768\n",
            "Epoch #0. Accuracy on batch 267/2438  on Training is 19.263059701492537\n",
            "Epoch #0. Accuracy on batch 268/2438  on Training is 19.296003717472118\n",
            "Epoch #0. Accuracy on batch 269/2438  on Training is 19.328703703703702\n",
            "Epoch #0. Accuracy on batch 270/2438  on Training is 19.349630996309962\n",
            "Epoch #0. Accuracy on batch 271/2438  on Training is 19.41636029411765\n",
            "Epoch #0. Accuracy on batch 272/2438  on Training is 19.45970695970696\n",
            "Epoch #0. Accuracy on batch 273/2438  on Training is 19.47992700729927\n",
            "Epoch #0. Accuracy on batch 274/2438  on Training is 19.511363636363637\n",
            "Epoch #0. Accuracy on batch 275/2438  on Training is 19.576539855072465\n",
            "Epoch #0. Accuracy on batch 276/2438  on Training is 19.64124548736462\n",
            "Epoch #0. Accuracy on batch 277/2438  on Training is 19.694244604316548\n",
            "Epoch #0. Accuracy on batch 278/2438  on Training is 19.746863799283155\n",
            "Epoch #0. Accuracy on batch 279/2438  on Training is 19.821428571428573\n",
            "Batch Id 280/2438 is having training loss of 4.049237251281738\n",
            "3.280975341796875\n",
            "Epoch #0. Accuracy on batch 280/2438  on Training is 19.873220640569397\n",
            "Epoch #0. Accuracy on batch 281/2438  on Training is 19.89140070921986\n",
            "Epoch #0. Accuracy on batch 282/2438  on Training is 19.9315371024735\n",
            "Epoch #0. Accuracy on batch 283/2438  on Training is 19.96038732394366\n",
            "Epoch #0. Accuracy on batch 284/2438  on Training is 20.0\n",
            "Epoch #0. Accuracy on batch 285/2438  on Training is 19.99562937062937\n",
            "Epoch #0. Accuracy on batch 286/2438  on Training is 20.056620209059233\n",
            "Epoch #0. Accuracy on batch 287/2438  on Training is 20.106336805555557\n",
            "Epoch #0. Accuracy on batch 288/2438  on Training is 20.155709342560552\n",
            "Epoch #0. Accuracy on batch 289/2438  on Training is 20.161637931034484\n",
            "Epoch #0. Accuracy on batch 290/2438  on Training is 20.189003436426116\n",
            "Epoch #0. Accuracy on batch 291/2438  on Training is 20.194777397260275\n",
            "Epoch #0. Accuracy on batch 292/2438  on Training is 20.189846416382252\n",
            "Epoch #0. Accuracy on batch 293/2438  on Training is 20.22746598639456\n",
            "Epoch #0. Accuracy on batch 294/2438  on Training is 20.296610169491526\n",
            "Epoch #0. Accuracy on batch 295/2438  on Training is 20.30194256756757\n",
            "Epoch #0. Accuracy on batch 296/2438  on Training is 20.328282828282827\n",
            "Epoch #0. Accuracy on batch 297/2438  on Training is 20.396392617449663\n",
            "Epoch #0. Accuracy on batch 298/2438  on Training is 20.44314381270903\n",
            "Epoch #0. Accuracy on batch 299/2438  on Training is 20.520833333333332\n",
            "Batch Id 300/2438 is having training loss of 3.9973342418670654\n",
            "3.1262094974517822\n",
            "Epoch #0. Accuracy on batch 300/2438  on Training is 20.556478405315616\n",
            "Epoch #0. Accuracy on batch 301/2438  on Training is 20.571192052980134\n",
            "Epoch #0. Accuracy on batch 302/2438  on Training is 20.647689768976896\n",
            "Epoch #0. Accuracy on batch 303/2438  on Training is 20.682565789473685\n",
            "Epoch #0. Accuracy on batch 304/2438  on Training is 20.686475409836067\n",
            "Epoch #0. Accuracy on batch 305/2438  on Training is 20.720996732026144\n",
            "Epoch #0. Accuracy on batch 306/2438  on Training is 20.745114006514658\n",
            "Epoch #0. Accuracy on batch 307/2438  on Training is 20.79951298701299\n",
            "Epoch #0. Accuracy on batch 308/2438  on Training is 20.843446601941746\n",
            "Epoch #0. Accuracy on batch 309/2438  on Training is 20.89717741935484\n",
            "Epoch #0. Accuracy on batch 310/2438  on Training is 20.890273311897108\n",
            "Epoch #0. Accuracy on batch 311/2438  on Training is 20.943509615384617\n",
            "Epoch #0. Accuracy on batch 312/2438  on Training is 20.986421725239616\n",
            "Epoch #0. Accuracy on batch 313/2438  on Training is 21.048964968152866\n",
            "Epoch #0. Accuracy on batch 314/2438  on Training is 21.071428571428573\n",
            "Epoch #0. Accuracy on batch 315/2438  on Training is 21.143196202531644\n",
            "Epoch #0. Accuracy on batch 316/2438  on Training is 21.194794952681388\n",
            "Epoch #0. Accuracy on batch 317/2438  on Training is 21.20676100628931\n",
            "Epoch #0. Accuracy on batch 318/2438  on Training is 21.218652037617556\n",
            "Epoch #0. Accuracy on batch 319/2438  on Training is 21.23046875\n",
            "Batch Id 320/2438 is having training loss of 3.9539685249328613\n",
            "3.4210727214813232\n",
            "Epoch #0. Accuracy on batch 320/2438  on Training is 21.24221183800623\n",
            "Epoch #0. Accuracy on batch 321/2438  on Training is 21.292701863354036\n",
            "Epoch #0. Accuracy on batch 322/2438  on Training is 21.362229102167184\n",
            "Epoch #0. Accuracy on batch 323/2438  on Training is 21.402391975308642\n",
            "Epoch #0. Accuracy on batch 324/2438  on Training is 21.41346153846154\n",
            "Epoch #0. Accuracy on batch 325/2438  on Training is 21.443634969325153\n",
            "Epoch #0. Accuracy on batch 326/2438  on Training is 21.454510703363916\n",
            "Epoch #0. Accuracy on batch 327/2438  on Training is 21.50342987804878\n",
            "Epoch #0. Accuracy on batch 328/2438  on Training is 21.523556231003038\n",
            "Epoch #0. Accuracy on batch 329/2438  on Training is 21.619318181818183\n",
            "Epoch #0. Accuracy on batch 330/2438  on Training is 21.65785498489426\n",
            "Epoch #0. Accuracy on batch 331/2438  on Training is 21.696159638554217\n",
            "Epoch #0. Accuracy on batch 332/2438  on Training is 21.696696696696698\n",
            "Epoch #0. Accuracy on batch 333/2438  on Training is 21.734655688622755\n",
            "Epoch #0. Accuracy on batch 334/2438  on Training is 21.77238805970149\n",
            "Epoch #0. Accuracy on batch 335/2438  on Training is 21.791294642857142\n",
            "Epoch #0. Accuracy on batch 336/2438  on Training is 21.847181008902076\n",
            "Epoch #0. Accuracy on batch 337/2438  on Training is 21.856508875739646\n",
            "Epoch #0. Accuracy on batch 338/2438  on Training is 21.911873156342182\n",
            "Epoch #0. Accuracy on batch 339/2438  on Training is 21.97610294117647\n",
            "Batch Id 340/2438 is having training loss of 3.906972885131836\n",
            "3.308999538421631\n",
            "Epoch #0. Accuracy on batch 340/2438  on Training is 21.994134897360702\n",
            "Epoch #0. Accuracy on batch 341/2438  on Training is 22.039473684210527\n",
            "Epoch #0. Accuracy on batch 342/2438  on Training is 22.075437317784257\n",
            "Epoch #0. Accuracy on batch 343/2438  on Training is 22.08393895348837\n",
            "Epoch #0. Accuracy on batch 344/2438  on Training is 22.10144927536232\n",
            "Epoch #0. Accuracy on batch 345/2438  on Training is 22.109826589595375\n",
            "Epoch #0. Accuracy on batch 346/2438  on Training is 22.082132564841498\n",
            "Epoch #0. Accuracy on batch 347/2438  on Training is 22.126436781609197\n",
            "Epoch #0. Accuracy on batch 348/2438  on Training is 22.11676217765043\n",
            "Epoch #0. Accuracy on batch 349/2438  on Training is 22.107142857142858\n",
            "Epoch #0. Accuracy on batch 350/2438  on Training is 22.10648148148148\n",
            "Epoch #0. Accuracy on batch 351/2438  on Training is 22.150213068181817\n",
            "Epoch #0. Accuracy on batch 352/2438  on Training is 22.211402266288953\n",
            "Epoch #0. Accuracy on batch 353/2438  on Training is 22.281073446327685\n",
            "Epoch #0. Accuracy on batch 354/2438  on Training is 22.315140845070424\n",
            "Epoch #0. Accuracy on batch 355/2438  on Training is 22.349016853932586\n",
            "Epoch #0. Accuracy on batch 356/2438  on Training is 22.373949579831933\n",
            "Epoch #0. Accuracy on batch 357/2438  on Training is 22.416201117318437\n",
            "Epoch #0. Accuracy on batch 358/2438  on Training is 22.466922005571032\n",
            "Epoch #0. Accuracy on batch 359/2438  on Training is 22.48263888888889\n",
            "Batch Id 360/2438 is having training loss of 3.871826171875\n",
            "2.8950788974761963\n",
            "Epoch #0. Accuracy on batch 360/2438  on Training is 22.532894736842106\n",
            "Epoch #0. Accuracy on batch 361/2438  on Training is 22.56560773480663\n",
            "Epoch #0. Accuracy on batch 362/2438  on Training is 22.623966942148762\n",
            "Epoch #0. Accuracy on batch 363/2438  on Training is 22.682005494505493\n",
            "Epoch #0. Accuracy on batch 364/2438  on Training is 22.722602739726028\n",
            "Epoch #0. Accuracy on batch 365/2438  on Training is 22.771516393442624\n",
            "Epoch #0. Accuracy on batch 366/2438  on Training is 22.777588555858312\n",
            "Epoch #0. Accuracy on batch 367/2438  on Training is 22.82608695652174\n",
            "Epoch #0. Accuracy on batch 368/2438  on Training is 22.87432249322493\n",
            "Epoch #0. Accuracy on batch 369/2438  on Training is 22.905405405405407\n",
            "Epoch #0. Accuracy on batch 370/2438  on Training is 22.970013477088948\n",
            "Epoch #0. Accuracy on batch 371/2438  on Training is 22.983870967741936\n",
            "Epoch #0. Accuracy on batch 372/2438  on Training is 23.031166219839143\n",
            "Epoch #0. Accuracy on batch 373/2438  on Training is 23.044786096256683\n",
            "Epoch #0. Accuracy on batch 374/2438  on Training is 23.041666666666668\n",
            "Epoch #0. Accuracy on batch 375/2438  on Training is 23.10505319148936\n",
            "Epoch #0. Accuracy on batch 376/2438  on Training is 23.16810344827586\n",
            "Epoch #0. Accuracy on batch 377/2438  on Training is 23.189484126984127\n",
            "Epoch #0. Accuracy on batch 378/2438  on Training is 23.194261213720317\n",
            "Epoch #0. Accuracy on batch 379/2438  on Training is 23.21546052631579\n",
            "Batch Id 380/2438 is having training loss of 3.829639434814453\n",
            "3.364764928817749\n",
            "Epoch #0. Accuracy on batch 380/2438  on Training is 23.22014435695538\n",
            "Epoch #0. Accuracy on batch 381/2438  on Training is 23.265706806282722\n",
            "Epoch #0. Accuracy on batch 382/2438  on Training is 23.302872062663184\n",
            "Epoch #0. Accuracy on batch 383/2438  on Training is 23.323567708333332\n",
            "Epoch #0. Accuracy on batch 384/2438  on Training is 23.36038961038961\n",
            "Epoch #0. Accuracy on batch 385/2438  on Training is 23.38082901554404\n",
            "Epoch #0. Accuracy on batch 386/2438  on Training is 23.401162790697676\n",
            "Epoch #0. Accuracy on batch 387/2438  on Training is 23.42944587628866\n",
            "Epoch #0. Accuracy on batch 388/2438  on Training is 23.425449871465297\n",
            "Epoch #0. Accuracy on batch 389/2438  on Training is 23.46955128205128\n",
            "Epoch #0. Accuracy on batch 390/2438  on Training is 23.505434782608695\n",
            "Epoch #0. Accuracy on batch 391/2438  on Training is 23.525191326530614\n",
            "Epoch #0. Accuracy on batch 392/2438  on Training is 23.584605597964376\n",
            "Epoch #0. Accuracy on batch 393/2438  on Training is 23.604060913705585\n",
            "Epoch #0. Accuracy on batch 394/2438  on Training is 23.63132911392405\n",
            "Epoch #0. Accuracy on batch 395/2438  on Training is 23.619002525252526\n",
            "Epoch #0. Accuracy on batch 396/2438  on Training is 23.6382241813602\n",
            "Epoch #0. Accuracy on batch 397/2438  on Training is 23.688756281407034\n",
            "Epoch #0. Accuracy on batch 398/2438  on Training is 23.739035087719298\n",
            "Epoch #0. Accuracy on batch 399/2438  on Training is 23.7578125\n",
            "Batch Id 400/2438 is having training loss of 3.7915048599243164\n",
            "2.919534683227539\n",
            "Epoch #0. Accuracy on batch 400/2438  on Training is 23.79208229426434\n",
            "Epoch #0. Accuracy on batch 401/2438  on Training is 23.818407960199004\n",
            "Epoch #0. Accuracy on batch 402/2438  on Training is 23.836848635235732\n",
            "Epoch #0. Accuracy on batch 403/2438  on Training is 23.870668316831683\n",
            "Epoch #0. Accuracy on batch 404/2438  on Training is 23.935185185185187\n",
            "Epoch #0. Accuracy on batch 405/2438  on Training is 23.945504926108374\n",
            "Epoch #0. Accuracy on batch 406/2438  on Training is 24.00184275184275\n",
            "Epoch #0. Accuracy on batch 407/2438  on Training is 24.042585784313726\n",
            "Epoch #0. Accuracy on batch 408/2438  on Training is 24.075488997555013\n",
            "Epoch #0. Accuracy on batch 409/2438  on Training is 24.085365853658537\n",
            "Epoch #0. Accuracy on batch 410/2438  on Training is 24.087591240875913\n",
            "Epoch #0. Accuracy on batch 411/2438  on Training is 24.11256067961165\n",
            "Epoch #0. Accuracy on batch 412/2438  on Training is 24.137409200968523\n",
            "Epoch #0. Accuracy on batch 413/2438  on Training is 24.184782608695652\n",
            "Epoch #0. Accuracy on batch 414/2438  on Training is 24.194277108433734\n",
            "Epoch #0. Accuracy on batch 415/2438  on Training is 24.21123798076923\n",
            "Epoch #0. Accuracy on batch 416/2438  on Training is 24.27308153477218\n",
            "Epoch #0. Accuracy on batch 417/2438  on Training is 24.297248803827753\n",
            "Epoch #0. Accuracy on batch 418/2438  on Training is 24.321300715990454\n",
            "Epoch #0. Accuracy on batch 419/2438  on Training is 24.33779761904762\n",
            "Batch Id 420/2438 is having training loss of 3.754307746887207\n",
            "3.3361122608184814\n",
            "Epoch #0. Accuracy on batch 420/2438  on Training is 24.346793349168646\n",
            "Epoch #0. Accuracy on batch 421/2438  on Training is 24.400177725118482\n",
            "Epoch #0. Accuracy on batch 422/2438  on Training is 24.43853427895981\n",
            "Epoch #0. Accuracy on batch 423/2438  on Training is 24.454599056603772\n",
            "Epoch #0. Accuracy on batch 424/2438  on Training is 24.470588235294116\n",
            "Epoch #0. Accuracy on batch 425/2438  on Training is 24.479166666666668\n",
            "Epoch #0. Accuracy on batch 426/2438  on Training is 24.51697892271663\n",
            "Epoch #0. Accuracy on batch 427/2438  on Training is 24.53271028037383\n",
            "Epoch #0. Accuracy on batch 428/2438  on Training is 24.562937062937063\n",
            "Epoch #0. Accuracy on batch 429/2438  on Training is 24.614825581395348\n",
            "Epoch #0. Accuracy on batch 430/2438  on Training is 24.659222737819025\n",
            "Epoch #0. Accuracy on batch 431/2438  on Training is 24.68894675925926\n",
            "Epoch #0. Accuracy on batch 432/2438  on Training is 24.725750577367204\n",
            "Epoch #0. Accuracy on batch 433/2438  on Training is 24.733582949308754\n",
            "Epoch #0. Accuracy on batch 434/2438  on Training is 24.777298850574713\n",
            "Epoch #0. Accuracy on batch 435/2438  on Training is 24.799311926605505\n",
            "Epoch #0. Accuracy on batch 436/2438  on Training is 24.878432494279178\n",
            "Epoch #0. Accuracy on batch 437/2438  on Training is 24.8787100456621\n",
            "Epoch #0. Accuracy on batch 438/2438  on Training is 24.871867881548976\n",
            "Epoch #0. Accuracy on batch 439/2438  on Training is 24.886363636363637\n",
            "Batch Id 440/2438 is having training loss of 3.7180166244506836\n",
            "3.0904152393341064\n",
            "Epoch #0. Accuracy on batch 440/2438  on Training is 24.91496598639456\n",
            "Epoch #0. Accuracy on batch 441/2438  on Training is 24.943438914027148\n",
            "Epoch #0. Accuracy on batch 442/2438  on Training is 24.978837471783297\n",
            "Epoch #0. Accuracy on batch 443/2438  on Training is 25.028153153153152\n",
            "Epoch #0. Accuracy on batch 444/2438  on Training is 25.084269662921347\n",
            "Epoch #0. Accuracy on batch 445/2438  on Training is 25.105100896860986\n",
            "Epoch #0. Accuracy on batch 446/2438  on Training is 25.16079418344519\n",
            "Epoch #0. Accuracy on batch 447/2438  on Training is 25.174386160714285\n",
            "Epoch #0. Accuracy on batch 448/2438  on Training is 25.18095768374165\n",
            "Epoch #0. Accuracy on batch 449/2438  on Training is 25.180555555555557\n",
            "Epoch #0. Accuracy on batch 450/2438  on Training is 25.152439024390244\n",
            "Epoch #0. Accuracy on batch 451/2438  on Training is 25.1866703539823\n",
            "Epoch #0. Accuracy on batch 452/2438  on Training is 25.186258278145694\n",
            "Epoch #0. Accuracy on batch 453/2438  on Training is 25.234030837004404\n",
            "Epoch #0. Accuracy on batch 454/2438  on Training is 25.274725274725274\n",
            "Epoch #0. Accuracy on batch 455/2438  on Training is 25.274122807017545\n",
            "Epoch #0. Accuracy on batch 456/2438  on Training is 25.294037199124727\n",
            "Epoch #0. Accuracy on batch 457/2438  on Training is 25.300218340611355\n",
            "Epoch #0. Accuracy on batch 458/2438  on Training is 25.326797385620914\n",
            "Epoch #0. Accuracy on batch 459/2438  on Training is 25.33288043478261\n",
            "Batch Id 460/2438 is having training loss of 3.684913396835327\n",
            "2.8032779693603516\n",
            "Epoch #0. Accuracy on batch 460/2438  on Training is 25.372830802603037\n",
            "Epoch #0. Accuracy on batch 461/2438  on Training is 25.37878787878788\n",
            "Epoch #0. Accuracy on batch 462/2438  on Training is 25.411717062634988\n",
            "Epoch #0. Accuracy on batch 463/2438  on Training is 25.46470905172414\n",
            "Epoch #0. Accuracy on batch 464/2438  on Training is 25.483870967741936\n",
            "Epoch #0. Accuracy on batch 465/2438  on Training is 25.502950643776824\n",
            "Epoch #0. Accuracy on batch 466/2438  on Training is 25.508565310492504\n",
            "Epoch #0. Accuracy on batch 467/2438  on Training is 25.514155982905983\n",
            "Epoch #0. Accuracy on batch 468/2438  on Training is 25.493070362473347\n",
            "Epoch #0. Accuracy on batch 469/2438  on Training is 25.511968085106382\n",
            "Epoch #0. Accuracy on batch 470/2438  on Training is 25.51751592356688\n",
            "Epoch #0. Accuracy on batch 471/2438  on Training is 25.516419491525422\n",
            "Epoch #0. Accuracy on batch 472/2438  on Training is 25.574788583509513\n",
            "Epoch #0. Accuracy on batch 473/2438  on Training is 25.606540084388186\n",
            "Epoch #0. Accuracy on batch 474/2438  on Training is 25.644736842105264\n",
            "Epoch #0. Accuracy on batch 475/2438  on Training is 25.682773109243698\n",
            "Epoch #0. Accuracy on batch 476/2438  on Training is 25.71409853249476\n",
            "Epoch #0. Accuracy on batch 477/2438  on Training is 25.72567991631799\n",
            "Epoch #0. Accuracy on batch 478/2438  on Training is 25.75026096033403\n",
            "Epoch #0. Accuracy on batch 479/2438  on Training is 25.774739583333332\n",
            "Batch Id 480/2438 is having training loss of 3.652024507522583\n",
            "2.9150876998901367\n",
            "Epoch #0. Accuracy on batch 480/2438  on Training is 25.82510395010395\n",
            "Epoch #0. Accuracy on batch 481/2438  on Training is 25.8298755186722\n",
            "Epoch #0. Accuracy on batch 482/2438  on Training is 25.860507246376812\n",
            "Epoch #0. Accuracy on batch 483/2438  on Training is 25.878099173553718\n",
            "Epoch #0. Accuracy on batch 484/2438  on Training is 25.92139175257732\n",
            "Epoch #0. Accuracy on batch 485/2438  on Training is 25.964506172839506\n",
            "Epoch #0. Accuracy on batch 486/2438  on Training is 25.96894250513347\n",
            "Epoch #0. Accuracy on batch 487/2438  on Training is 25.986168032786885\n",
            "Epoch #0. Accuracy on batch 488/2438  on Training is 26.003323108384457\n",
            "Epoch #0. Accuracy on batch 489/2438  on Training is 26.039540816326532\n",
            "Epoch #0. Accuracy on batch 490/2438  on Training is 26.04378818737271\n",
            "Epoch #0. Accuracy on batch 491/2438  on Training is 26.054369918699187\n",
            "Epoch #0. Accuracy on batch 492/2438  on Training is 26.08392494929006\n",
            "Epoch #0. Accuracy on batch 493/2438  on Training is 26.11336032388664\n",
            "Epoch #0. Accuracy on batch 494/2438  on Training is 26.15530303030303\n",
            "Epoch #0. Accuracy on batch 495/2438  on Training is 26.146673387096776\n",
            "Epoch #0. Accuracy on batch 496/2438  on Training is 26.175804828973842\n",
            "Epoch #0. Accuracy on batch 497/2438  on Training is 26.179718875502008\n",
            "Epoch #0. Accuracy on batch 498/2438  on Training is 26.20240480961924\n",
            "Epoch #0. Accuracy on batch 499/2438  on Training is 26.25625\n",
            "Batch Id 500/2438 is having training loss of 3.6208481788635254\n",
            "2.813565254211426\n",
            "Epoch #0. Accuracy on batch 500/2438  on Training is 26.29116766467066\n",
            "Epoch #0. Accuracy on batch 501/2438  on Training is 26.30104581673307\n",
            "Epoch #0. Accuracy on batch 502/2438  on Training is 26.32952286282306\n",
            "Epoch #0. Accuracy on batch 503/2438  on Training is 26.339285714285715\n",
            "Epoch #0. Accuracy on batch 504/2438  on Training is 26.342821782178216\n",
            "Epoch #0. Accuracy on batch 505/2438  on Training is 26.364871541501977\n",
            "Epoch #0. Accuracy on batch 506/2438  on Training is 26.41765285996055\n",
            "Epoch #0. Accuracy on batch 507/2438  on Training is 26.464074803149607\n",
            "Epoch #0. Accuracy on batch 508/2438  on Training is 26.49803536345776\n",
            "Epoch #0. Accuracy on batch 509/2438  on Training is 26.550245098039216\n",
            "Epoch #0. Accuracy on batch 510/2438  on Training is 26.571673189823876\n",
            "Epoch #0. Accuracy on batch 511/2438  on Training is 26.611328125\n",
            "Epoch #0. Accuracy on batch 512/2438  on Training is 26.65692007797271\n",
            "Epoch #0. Accuracy on batch 513/2438  on Training is 26.665856031128406\n",
            "Epoch #0. Accuracy on batch 514/2438  on Training is 26.692961165048544\n",
            "Epoch #0. Accuracy on batch 515/2438  on Training is 26.73812984496124\n",
            "Epoch #0. Accuracy on batch 516/2438  on Training is 26.74685686653772\n",
            "Epoch #0. Accuracy on batch 517/2438  on Training is 26.76761583011583\n",
            "Epoch #0. Accuracy on batch 518/2438  on Training is 26.782273603082853\n",
            "Epoch #0. Accuracy on batch 519/2438  on Training is 26.82091346153846\n",
            "Batch Id 520/2438 is having training loss of 3.589811086654663\n",
            "3.3235790729522705\n",
            "Epoch #0. Accuracy on batch 520/2438  on Training is 26.817418426103647\n",
            "Epoch #0. Accuracy on batch 521/2438  on Training is 26.81992337164751\n",
            "Epoch #0. Accuracy on batch 522/2438  on Training is 26.858269598470365\n",
            "Epoch #0. Accuracy on batch 523/2438  on Training is 26.872614503816795\n",
            "Epoch #0. Accuracy on batch 524/2438  on Training is 26.88095238095238\n",
            "Epoch #0. Accuracy on batch 525/2438  on Training is 26.918963878326995\n",
            "Epoch #0. Accuracy on batch 526/2438  on Training is 26.968690702087287\n",
            "Epoch #0. Accuracy on batch 527/2438  on Training is 26.988636363636363\n",
            "Epoch #0. Accuracy on batch 528/2438  on Training is 26.996691871455578\n",
            "Epoch #0. Accuracy on batch 529/2438  on Training is 26.9811320754717\n",
            "Epoch #0. Accuracy on batch 530/2438  on Training is 27.006826741996232\n",
            "Epoch #0. Accuracy on batch 531/2438  on Training is 27.032424812030076\n",
            "Epoch #0. Accuracy on batch 532/2438  on Training is 27.046200750469044\n",
            "Epoch #0. Accuracy on batch 533/2438  on Training is 27.095037453183522\n",
            "Epoch #0. Accuracy on batch 534/2438  on Training is 27.102803738317757\n",
            "Epoch #0. Accuracy on batch 535/2438  on Training is 27.11054104477612\n",
            "Epoch #0. Accuracy on batch 536/2438  on Training is 27.15316573556797\n",
            "Epoch #0. Accuracy on batch 537/2438  on Training is 27.16078066914498\n",
            "Epoch #0. Accuracy on batch 538/2438  on Training is 27.203153988868273\n",
            "Epoch #0. Accuracy on batch 539/2438  on Training is 27.22222222222222\n",
            "Batch Id 540/2438 is having training loss of 3.5616281032562256\n",
            "3.292459011077881\n",
            "Epoch #0. Accuracy on batch 540/2438  on Training is 27.223890942698706\n",
            "Epoch #0. Accuracy on batch 541/2438  on Training is 27.242850553505534\n",
            "Epoch #0. Accuracy on batch 542/2438  on Training is 27.273250460405155\n",
            "Epoch #0. Accuracy on batch 543/2438  on Training is 27.286305147058822\n",
            "Epoch #0. Accuracy on batch 544/2438  on Training is 27.28211009174312\n",
            "Epoch #0. Accuracy on batch 545/2438  on Training is 27.335164835164836\n",
            "Epoch #0. Accuracy on batch 546/2438  on Training is 27.370886654478976\n",
            "Epoch #0. Accuracy on batch 547/2438  on Training is 27.39507299270073\n",
            "Epoch #0. Accuracy on batch 548/2438  on Training is 27.40209471766849\n",
            "Epoch #0. Accuracy on batch 549/2438  on Training is 27.420454545454547\n",
            "Epoch #0. Accuracy on batch 550/2438  on Training is 27.4217332123412\n",
            "Epoch #0. Accuracy on batch 551/2438  on Training is 27.445652173913043\n",
            "Epoch #0. Accuracy on batch 552/2438  on Training is 27.480786618444846\n",
            "Epoch #0. Accuracy on batch 553/2438  on Training is 27.50451263537906\n",
            "Epoch #0. Accuracy on batch 554/2438  on Training is 27.52252252252252\n",
            "Epoch #0. Accuracy on batch 555/2438  on Training is 27.540467625899282\n",
            "Epoch #0. Accuracy on batch 556/2438  on Training is 27.56395870736086\n",
            "Epoch #0. Accuracy on batch 557/2438  on Training is 27.604166666666668\n",
            "Epoch #0. Accuracy on batch 558/2438  on Training is 27.649821109123433\n",
            "Epoch #0. Accuracy on batch 559/2438  on Training is 27.661830357142858\n",
            "Batch Id 560/2438 is having training loss of 3.5290026664733887\n",
            "2.520156145095825\n",
            "Epoch #0. Accuracy on batch 560/2438  on Training is 27.690508021390375\n",
            "Epoch #0. Accuracy on batch 561/2438  on Training is 27.702402135231317\n",
            "Epoch #0. Accuracy on batch 562/2438  on Training is 27.730905861456485\n",
            "Epoch #0. Accuracy on batch 563/2438  on Training is 27.74822695035461\n",
            "Epoch #0. Accuracy on batch 564/2438  on Training is 27.748893805309734\n",
            "Epoch #0. Accuracy on batch 565/2438  on Training is 27.78268551236749\n",
            "Epoch #0. Accuracy on batch 566/2438  on Training is 27.79431216931217\n",
            "Epoch #0. Accuracy on batch 567/2438  on Training is 27.833406690140844\n",
            "Epoch #0. Accuracy on batch 568/2438  on Training is 27.855887521968366\n",
            "Epoch #0. Accuracy on batch 569/2438  on Training is 27.87280701754386\n",
            "Epoch #0. Accuracy on batch 570/2438  on Training is 27.89514010507881\n",
            "Epoch #0. Accuracy on batch 571/2438  on Training is 27.92285839160839\n",
            "Epoch #0. Accuracy on batch 572/2438  on Training is 27.945026178010473\n",
            "Epoch #0. Accuracy on batch 573/2438  on Training is 27.978005226480835\n",
            "Epoch #0. Accuracy on batch 574/2438  on Training is 27.983695652173914\n",
            "Epoch #0. Accuracy on batch 575/2438  on Training is 28.02191840277778\n",
            "Epoch #0. Accuracy on batch 576/2438  on Training is 28.06542461005199\n",
            "Epoch #0. Accuracy on batch 577/2438  on Training is 28.076340830449826\n",
            "Epoch #0. Accuracy on batch 578/2438  on Training is 28.081822107081173\n",
            "Epoch #0. Accuracy on batch 579/2438  on Training is 28.10883620689655\n",
            "Batch Id 580/2438 is having training loss of 3.501278877258301\n",
            "2.9450223445892334\n",
            "Epoch #0. Accuracy on batch 580/2438  on Training is 28.119621342512907\n",
            "Epoch #0. Accuracy on batch 581/2438  on Training is 28.14647766323024\n",
            "Epoch #0. Accuracy on batch 582/2438  on Training is 28.17860205831904\n",
            "Epoch #0. Accuracy on batch 583/2438  on Training is 28.215967465753426\n",
            "Epoch #0. Accuracy on batch 584/2438  on Training is 28.253205128205128\n",
            "Epoch #0. Accuracy on batch 585/2438  on Training is 28.268984641638227\n",
            "Epoch #0. Accuracy on batch 586/2438  on Training is 28.274063032367973\n",
            "Epoch #0. Accuracy on batch 587/2438  on Training is 28.279124149659864\n",
            "Epoch #0. Accuracy on batch 588/2438  on Training is 28.326612903225808\n",
            "Epoch #0. Accuracy on batch 589/2438  on Training is 28.33686440677966\n",
            "Epoch #0. Accuracy on batch 590/2438  on Training is 28.368231810490695\n",
            "Epoch #0. Accuracy on batch 591/2438  on Training is 28.399493243243242\n",
            "Epoch #0. Accuracy on batch 592/2438  on Training is 28.43591905564924\n",
            "Epoch #0. Accuracy on batch 593/2438  on Training is 28.456439393939394\n",
            "Epoch #0. Accuracy on batch 594/2438  on Training is 28.47689075630252\n",
            "Epoch #0. Accuracy on batch 595/2438  on Training is 28.48678691275168\n",
            "Epoch #0. Accuracy on batch 596/2438  on Training is 28.517587939698494\n",
            "Epoch #0. Accuracy on batch 597/2438  on Training is 28.55351170568562\n",
            "Epoch #0. Accuracy on batch 598/2438  on Training is 28.568447412353922\n",
            "Epoch #0. Accuracy on batch 599/2438  on Training is 28.59375\n",
            "Batch Id 600/2438 is having training loss of 3.4735400676727295\n",
            "2.608778953552246\n",
            "Epoch #0. Accuracy on batch 600/2438  on Training is 28.62936772046589\n",
            "Epoch #0. Accuracy on batch 601/2438  on Training is 28.63372093023256\n",
            "Epoch #0. Accuracy on batch 602/2438  on Training is 28.65360696517413\n",
            "Epoch #0. Accuracy on batch 603/2438  on Training is 28.69412251655629\n",
            "Epoch #0. Accuracy on batch 604/2438  on Training is 28.72417355371901\n",
            "Epoch #0. Accuracy on batch 605/2438  on Training is 28.728341584158414\n",
            "Epoch #0. Accuracy on batch 606/2438  on Training is 28.722199341021415\n",
            "Epoch #0. Accuracy on batch 607/2438  on Training is 28.71607730263158\n",
            "Epoch #0. Accuracy on batch 608/2438  on Training is 28.745894909688012\n",
            "Epoch #0. Accuracy on batch 609/2438  on Training is 28.765368852459016\n",
            "Epoch #0. Accuracy on batch 610/2438  on Training is 28.769435351882162\n",
            "Epoch #0. Accuracy on batch 611/2438  on Training is 28.788807189542485\n",
            "Epoch #0. Accuracy on batch 612/2438  on Training is 28.808115823817293\n",
            "Epoch #0. Accuracy on batch 613/2438  on Training is 28.827361563517915\n",
            "Epoch #0. Accuracy on batch 614/2438  on Training is 28.86178861788618\n",
            "Epoch #0. Accuracy on batch 615/2438  on Training is 28.870738636363637\n",
            "Epoch #0. Accuracy on batch 616/2438  on Training is 28.884724473257698\n",
            "Epoch #0. Accuracy on batch 617/2438  on Training is 28.908778317152105\n",
            "Epoch #0. Accuracy on batch 618/2438  on Training is 28.91760904684976\n",
            "Epoch #0. Accuracy on batch 619/2438  on Training is 28.94657258064516\n",
            "Batch Id 620/2438 is having training loss of 3.4488377571105957\n",
            "2.3643693923950195\n",
            "Epoch #0. Accuracy on batch 620/2438  on Training is 28.985507246376812\n",
            "Epoch #0. Accuracy on batch 621/2438  on Training is 29.019292604501608\n",
            "Epoch #0. Accuracy on batch 622/2438  on Training is 29.03290529695024\n",
            "Epoch #0. Accuracy on batch 623/2438  on Training is 29.076522435897434\n",
            "Epoch #0. Accuracy on batch 624/2438  on Training is 29.1\n",
            "Epoch #0. Accuracy on batch 625/2438  on Training is 29.123402555910545\n",
            "Epoch #0. Accuracy on batch 626/2438  on Training is 29.161682615629985\n",
            "Epoch #0. Accuracy on batch 627/2438  on Training is 29.16998407643312\n",
            "Epoch #0. Accuracy on batch 628/2438  on Training is 29.198131955484897\n",
            "Epoch #0. Accuracy on batch 629/2438  on Training is 29.226190476190474\n",
            "Epoch #0. Accuracy on batch 630/2438  on Training is 29.229397781299525\n",
            "Epoch #0. Accuracy on batch 631/2438  on Training is 29.23259493670886\n",
            "Epoch #0. Accuracy on batch 632/2438  on Training is 29.24565560821485\n",
            "Epoch #0. Accuracy on batch 633/2438  on Training is 29.248817034700316\n",
            "Epoch #0. Accuracy on batch 634/2438  on Training is 29.251968503937007\n",
            "Epoch #0. Accuracy on batch 635/2438  on Training is 29.274764150943398\n",
            "Epoch #0. Accuracy on batch 636/2438  on Training is 29.28767660910518\n",
            "Epoch #0. Accuracy on batch 637/2438  on Training is 29.285854231974923\n",
            "Epoch #0. Accuracy on batch 638/2438  on Training is 29.30359937402191\n",
            "Epoch #0. Accuracy on batch 639/2438  on Training is 29.3017578125\n",
            "Batch Id 640/2438 is having training loss of 3.4233477115631104\n",
            "2.146336317062378\n",
            "Epoch #0. Accuracy on batch 640/2438  on Training is 29.34379875195008\n",
            "Epoch #0. Accuracy on batch 641/2438  on Training is 29.380841121495326\n",
            "Epoch #0. Accuracy on batch 642/2438  on Training is 29.398328149300156\n",
            "Epoch #0. Accuracy on batch 643/2438  on Training is 29.41576086956522\n",
            "Epoch #0. Accuracy on batch 644/2438  on Training is 29.462209302325583\n",
            "Epoch #0. Accuracy on batch 645/2438  on Training is 29.484326625387\n",
            "Epoch #0. Accuracy on batch 646/2438  on Training is 29.511205564142195\n",
            "Epoch #0. Accuracy on batch 647/2438  on Training is 29.50906635802469\n",
            "Epoch #0. Accuracy on batch 648/2438  on Training is 29.53582434514638\n",
            "Epoch #0. Accuracy on batch 649/2438  on Training is 29.5625\n",
            "Epoch #0. Accuracy on batch 650/2438  on Training is 29.57469278033794\n",
            "Epoch #0. Accuracy on batch 651/2438  on Training is 29.61081288343558\n",
            "Epoch #0. Accuracy on batch 652/2438  on Training is 29.6228943338438\n",
            "Epoch #0. Accuracy on batch 653/2438  on Training is 29.644495412844037\n",
            "Epoch #0. Accuracy on batch 654/2438  on Training is 29.68034351145038\n",
            "Epoch #0. Accuracy on batch 655/2438  on Training is 29.69702743902439\n",
            "Epoch #0. Accuracy on batch 656/2438  on Training is 29.7279299847793\n",
            "Epoch #0. Accuracy on batch 657/2438  on Training is 29.739741641337385\n",
            "Epoch #0. Accuracy on batch 658/2438  on Training is 29.756259484066767\n",
            "Epoch #0. Accuracy on batch 659/2438  on Training is 29.78219696969697\n",
            "Batch Id 660/2438 is having training loss of 3.397129535675049\n",
            "2.4007151126861572\n",
            "Epoch #0. Accuracy on batch 660/2438  on Training is 29.80805597579425\n",
            "Epoch #0. Accuracy on batch 661/2438  on Training is 29.805513595166165\n",
            "Epoch #0. Accuracy on batch 662/2438  on Training is 29.845399698340874\n",
            "Epoch #0. Accuracy on batch 663/2438  on Training is 29.889871987951807\n",
            "Epoch #0. Accuracy on batch 664/2438  on Training is 29.896616541353385\n",
            "Epoch #0. Accuracy on batch 665/2438  on Training is 29.91741741741742\n",
            "Epoch #0. Accuracy on batch 666/2438  on Training is 29.928785607196403\n",
            "Epoch #0. Accuracy on batch 667/2438  on Training is 29.926085329341316\n",
            "Epoch #0. Accuracy on batch 668/2438  on Training is 29.956091180866967\n",
            "Epoch #0. Accuracy on batch 669/2438  on Training is 29.96268656716418\n",
            "Epoch #0. Accuracy on batch 670/2438  on Training is 29.96926229508197\n",
            "Epoch #0. Accuracy on batch 671/2438  on Training is 30.003720238095237\n",
            "Epoch #0. Accuracy on batch 672/2438  on Training is 30.028789004457654\n",
            "Epoch #0. Accuracy on batch 673/2438  on Training is 30.044510385756677\n",
            "Epoch #0. Accuracy on batch 674/2438  on Training is 30.078703703703702\n",
            "Epoch #0. Accuracy on batch 675/2438  on Training is 30.075813609467456\n",
            "Epoch #0. Accuracy on batch 676/2438  on Training is 30.119091580502214\n",
            "Epoch #0. Accuracy on batch 677/2438  on Training is 30.129977876106196\n",
            "Epoch #0. Accuracy on batch 678/2438  on Training is 30.136229749631813\n",
            "Epoch #0. Accuracy on batch 679/2438  on Training is 30.13327205882353\n",
            "Batch Id 680/2438 is having training loss of 3.3728294372558594\n",
            "2.550067186355591\n",
            "Epoch #0. Accuracy on batch 680/2438  on Training is 30.157856093979444\n",
            "Epoch #0. Accuracy on batch 681/2438  on Training is 30.159457478005866\n",
            "Epoch #0. Accuracy on batch 682/2438  on Training is 30.193081991215227\n",
            "Epoch #0. Accuracy on batch 683/2438  on Training is 30.208333333333332\n",
            "Epoch #0. Accuracy on batch 684/2438  on Training is 30.232664233576642\n",
            "Epoch #0. Accuracy on batch 685/2438  on Training is 30.284256559766764\n",
            "Epoch #0. Accuracy on batch 686/2438  on Training is 30.31750363901019\n",
            "Epoch #0. Accuracy on batch 687/2438  on Training is 30.346111918604652\n",
            "Epoch #0. Accuracy on batch 688/2438  on Training is 30.379172714078376\n",
            "Epoch #0. Accuracy on batch 689/2438  on Training is 30.403079710144926\n",
            "Epoch #0. Accuracy on batch 690/2438  on Training is 30.43143994211288\n",
            "Epoch #0. Accuracy on batch 691/2438  on Training is 30.450686416184972\n",
            "Epoch #0. Accuracy on batch 692/2438  on Training is 30.474386724386726\n",
            "Epoch #0. Accuracy on batch 693/2438  on Training is 30.48901296829971\n",
            "Epoch #0. Accuracy on batch 694/2438  on Training is 30.494604316546763\n",
            "Epoch #0. Accuracy on batch 695/2438  on Training is 30.527119252873565\n",
            "Epoch #0. Accuracy on batch 696/2438  on Training is 30.52815638450502\n",
            "Epoch #0. Accuracy on batch 697/2438  on Training is 30.533667621776505\n",
            "Epoch #0. Accuracy on batch 698/2438  on Training is 30.54810443490701\n",
            "Epoch #0. Accuracy on batch 699/2438  on Training is 30.584821428571427\n",
            "Batch Id 700/2438 is having training loss of 3.3464996814727783\n",
            "2.087750196456909\n",
            "Epoch #0. Accuracy on batch 700/2438  on Training is 30.621433666191155\n",
            "Epoch #0. Accuracy on batch 701/2438  on Training is 30.644586894586894\n",
            "Epoch #0. Accuracy on batch 702/2438  on Training is 30.681009957325745\n",
            "Epoch #0. Accuracy on batch 703/2438  on Training is 30.695134943181817\n",
            "Epoch #0. Accuracy on batch 704/2438  on Training is 30.713652482269502\n",
            "Epoch #0. Accuracy on batch 705/2438  on Training is 30.709985835694052\n",
            "Epoch #0. Accuracy on batch 706/2438  on Training is 30.741690240452616\n",
            "Epoch #0. Accuracy on batch 707/2438  on Training is 30.746822033898304\n",
            "Epoch #0. Accuracy on batch 708/2438  on Training is 30.79601551480959\n",
            "Epoch #0. Accuracy on batch 709/2438  on Training is 30.801056338028168\n",
            "Epoch #0. Accuracy on batch 710/2438  on Training is 30.823663853727144\n",
            "Epoch #0. Accuracy on batch 711/2438  on Training is 30.84620786516854\n",
            "Epoch #0. Accuracy on batch 712/2438  on Training is 30.855539971949508\n",
            "Epoch #0. Accuracy on batch 713/2438  on Training is 30.85171568627451\n",
            "Epoch #0. Accuracy on batch 714/2438  on Training is 30.84353146853147\n",
            "Epoch #0. Accuracy on batch 715/2438  on Training is 30.852828212290504\n",
            "Epoch #0. Accuracy on batch 716/2438  on Training is 30.85774058577406\n",
            "Epoch #0. Accuracy on batch 717/2438  on Training is 30.880048746518106\n",
            "Epoch #0. Accuracy on batch 718/2438  on Training is 30.919680111265645\n",
            "Epoch #0. Accuracy on batch 719/2438  on Training is 30.950520833333332\n",
            "Batch Id 720/2438 is having training loss of 3.324414014816284\n",
            "2.5077054500579834\n",
            "Epoch #0. Accuracy on batch 720/2438  on Training is 30.976941747572816\n",
            "Epoch #0. Accuracy on batch 721/2438  on Training is 30.985976454293628\n",
            "Epoch #0. Accuracy on batch 722/2438  on Training is 30.990663900414937\n",
            "Epoch #0. Accuracy on batch 723/2438  on Training is 30.9996546961326\n",
            "Epoch #0. Accuracy on batch 724/2438  on Training is 31.017241379310345\n",
            "Epoch #0. Accuracy on batch 725/2438  on Training is 31.02617079889807\n",
            "Epoch #0. Accuracy on batch 726/2438  on Training is 31.035075653370015\n",
            "Epoch #0. Accuracy on batch 727/2438  on Training is 31.03537087912088\n",
            "Epoch #0. Accuracy on batch 728/2438  on Training is 31.061385459533607\n",
            "Epoch #0. Accuracy on batch 729/2438  on Training is 31.091609589041095\n",
            "Epoch #0. Accuracy on batch 730/2438  on Training is 31.117476060191517\n",
            "Epoch #0. Accuracy on batch 731/2438  on Training is 31.113387978142075\n",
            "Epoch #0. Accuracy on batch 732/2438  on Training is 31.1306275579809\n",
            "Epoch #0. Accuracy on batch 733/2438  on Training is 31.143562670299726\n",
            "Epoch #0. Accuracy on batch 734/2438  on Training is 31.1734693877551\n",
            "Epoch #0. Accuracy on batch 735/2438  on Training is 31.194802989130434\n",
            "Epoch #0. Accuracy on batch 736/2438  on Training is 31.21607869742198\n",
            "Epoch #0. Accuracy on batch 737/2438  on Training is 31.254234417344172\n",
            "Epoch #0. Accuracy on batch 738/2438  on Training is 31.275372124492556\n",
            "Epoch #0. Accuracy on batch 739/2438  on Training is 31.300675675675677\n",
            "Batch Id 740/2438 is having training loss of 3.3026106357574463\n",
            "2.3127622604370117\n",
            "Epoch #0. Accuracy on batch 740/2438  on Training is 31.321693657219974\n",
            "Epoch #0. Accuracy on batch 741/2438  on Training is 31.338443396226417\n",
            "Epoch #0. Accuracy on batch 742/2438  on Training is 31.35935397039031\n",
            "Epoch #0. Accuracy on batch 743/2438  on Training is 31.384408602150536\n",
            "Epoch #0. Accuracy on batch 744/2438  on Training is 31.39681208053691\n",
            "Epoch #0. Accuracy on batch 745/2438  on Training is 31.41756032171582\n",
            "Epoch #0. Accuracy on batch 746/2438  on Training is 31.429886211512716\n",
            "Epoch #0. Accuracy on batch 747/2438  on Training is 31.450534759358288\n",
            "Epoch #0. Accuracy on batch 748/2438  on Training is 31.471128170894527\n",
            "Epoch #0. Accuracy on batch 749/2438  on Training is 31.4875\n",
            "Epoch #0. Accuracy on batch 750/2438  on Training is 31.499667110519308\n",
            "Epoch #0. Accuracy on batch 751/2438  on Training is 31.495179521276597\n",
            "Epoch #0. Accuracy on batch 752/2438  on Training is 31.50730411686587\n",
            "Epoch #0. Accuracy on batch 753/2438  on Training is 31.527685676392572\n",
            "Epoch #0. Accuracy on batch 754/2438  on Training is 31.54387417218543\n",
            "Epoch #0. Accuracy on batch 755/2438  on Training is 31.555886243386244\n",
            "Epoch #0. Accuracy on batch 756/2438  on Training is 31.563738441215325\n",
            "Epoch #0. Accuracy on batch 757/2438  on Training is 31.592183377308707\n",
            "Epoch #0. Accuracy on batch 758/2438  on Training is 31.604084321475625\n",
            "Epoch #0. Accuracy on batch 759/2438  on Training is 31.620065789473685\n",
            "Batch Id 760/2438 is having training loss of 3.2807483673095703\n",
            "2.556896686553955\n",
            "Epoch #0. Accuracy on batch 760/2438  on Training is 31.644218134034166\n",
            "Epoch #0. Accuracy on batch 761/2438  on Training is 31.64780183727034\n",
            "Epoch #0. Accuracy on batch 762/2438  on Training is 31.688237221494102\n",
            "Epoch #0. Accuracy on batch 763/2438  on Training is 31.7122054973822\n",
            "Epoch #0. Accuracy on batch 764/2438  on Training is 31.752450980392158\n",
            "Epoch #0. Accuracy on batch 765/2438  on Training is 31.77219321148825\n",
            "Epoch #0. Accuracy on batch 766/2438  on Training is 31.779661016949152\n",
            "Epoch #0. Accuracy on batch 767/2438  on Training is 31.795247395833332\n",
            "Epoch #0. Accuracy on batch 768/2438  on Training is 31.806729518855658\n",
            "Epoch #0. Accuracy on batch 769/2438  on Training is 31.818181818181817\n",
            "Epoch #0. Accuracy on batch 770/2438  on Training is 31.813391699092087\n",
            "Epoch #0. Accuracy on batch 771/2438  on Training is 31.816709844559586\n",
            "Epoch #0. Accuracy on batch 772/2438  on Training is 31.840232858990944\n",
            "Epoch #0. Accuracy on batch 773/2438  on Training is 31.839470284237727\n",
            "Epoch #0. Accuracy on batch 774/2438  on Training is 31.850806451612904\n",
            "Epoch #0. Accuracy on batch 775/2438  on Training is 31.858086340206185\n",
            "Epoch #0. Accuracy on batch 776/2438  on Training is 31.86534749034749\n",
            "Epoch #0. Accuracy on batch 777/2438  on Training is 31.884640102827763\n",
            "Epoch #0. Accuracy on batch 778/2438  on Training is 31.895860077021823\n",
            "Epoch #0. Accuracy on batch 779/2438  on Training is 31.911057692307693\n",
            "Batch Id 780/2438 is having training loss of 3.261218786239624\n",
            "2.510801076889038\n",
            "Epoch #0. Accuracy on batch 780/2438  on Training is 31.92621638924456\n",
            "Epoch #0. Accuracy on batch 781/2438  on Training is 31.965313299232736\n",
            "Epoch #0. Accuracy on batch 782/2438  on Training is 31.988346104725416\n",
            "Epoch #0. Accuracy on batch 783/2438  on Training is 32.00733418367347\n",
            "Epoch #0. Accuracy on batch 784/2438  on Training is 32.03423566878981\n",
            "Epoch #0. Accuracy on batch 785/2438  on Training is 32.037213740458014\n",
            "Epoch #0. Accuracy on batch 786/2438  on Training is 32.06003811944092\n",
            "Epoch #0. Accuracy on batch 787/2438  on Training is 32.098667512690355\n",
            "Epoch #0. Accuracy on batch 788/2438  on Training is 32.129277566539926\n",
            "Epoch #0. Accuracy on batch 789/2438  on Training is 32.14398734177215\n",
            "Epoch #0. Accuracy on batch 790/2438  on Training is 32.14680783817952\n",
            "Epoch #0. Accuracy on batch 791/2438  on Training is 32.16934974747475\n",
            "Epoch #0. Accuracy on batch 792/2438  on Training is 32.180012610340476\n",
            "Epoch #0. Accuracy on batch 793/2438  on Training is 32.18277707808564\n",
            "Epoch #0. Accuracy on batch 794/2438  on Training is 32.193396226415096\n",
            "Epoch #0. Accuracy on batch 795/2438  on Training is 32.22361809045226\n",
            "Epoch #0. Accuracy on batch 796/2438  on Training is 32.23415934755332\n",
            "Epoch #0. Accuracy on batch 797/2438  on Training is 32.26425438596491\n",
            "Epoch #0. Accuracy on batch 798/2438  on Training is 32.27080725907384\n",
            "Epoch #0. Accuracy on batch 799/2438  on Training is 32.3125\n",
            "Batch Id 800/2438 is having training loss of 3.241065263748169\n",
            "2.5713648796081543\n",
            "Epoch #0. Accuracy on batch 800/2438  on Training is 32.32677902621723\n",
            "Epoch #0. Accuracy on batch 801/2438  on Training is 32.352711970074814\n",
            "Epoch #0. Accuracy on batch 802/2438  on Training is 32.363013698630134\n",
            "Epoch #0. Accuracy on batch 803/2438  on Training is 32.388837064676615\n",
            "Epoch #0. Accuracy on batch 804/2438  on Training is 32.399068322981364\n",
            "Epoch #0. Accuracy on batch 805/2438  on Training is 32.42090570719603\n",
            "Epoch #0. Accuracy on batch 806/2438  on Training is 32.44656133828996\n",
            "Epoch #0. Accuracy on batch 807/2438  on Training is 32.46828589108911\n",
            "Epoch #0. Accuracy on batch 808/2438  on Training is 32.4938195302843\n",
            "Epoch #0. Accuracy on batch 809/2438  on Training is 32.507716049382715\n",
            "Epoch #0. Accuracy on batch 810/2438  on Training is 32.52928483353884\n",
            "Epoch #0. Accuracy on batch 811/2438  on Training is 32.52386083743843\n",
            "Epoch #0. Accuracy on batch 812/2438  on Training is 32.53382533825338\n",
            "Epoch #0. Accuracy on batch 813/2438  on Training is 32.55528255528255\n",
            "Epoch #0. Accuracy on batch 814/2438  on Training is 32.565184049079754\n",
            "Epoch #0. Accuracy on batch 815/2438  on Training is 32.59420955882353\n",
            "Epoch #0. Accuracy on batch 816/2438  on Training is 32.60403916768666\n",
            "Epoch #0. Accuracy on batch 817/2438  on Training is 32.63676650366748\n",
            "Epoch #0. Accuracy on batch 818/2438  on Training is 32.650335775335776\n",
            "Epoch #0. Accuracy on batch 819/2438  on Training is 32.67530487804878\n",
            "Batch Id 820/2438 is having training loss of 3.2196033000946045\n",
            "2.0808980464935303\n",
            "Epoch #0. Accuracy on batch 820/2438  on Training is 32.70401948842875\n",
            "Epoch #0. Accuracy on batch 821/2438  on Training is 32.72886253041362\n",
            "Epoch #0. Accuracy on batch 822/2438  on Training is 32.746051032806804\n",
            "Epoch #0. Accuracy on batch 823/2438  on Training is 32.76319781553398\n",
            "Epoch #0. Accuracy on batch 824/2438  on Training is 32.78409090909091\n",
            "Epoch #0. Accuracy on batch 825/2438  on Training is 32.801150121065376\n",
            "Epoch #0. Accuracy on batch 826/2438  on Training is 32.82950423216445\n",
            "Epoch #0. Accuracy on batch 827/2438  on Training is 32.84269323671498\n",
            "Epoch #0. Accuracy on batch 828/2438  on Training is 32.859620024125455\n",
            "Epoch #0. Accuracy on batch 829/2438  on Training is 32.876506024096386\n",
            "Epoch #0. Accuracy on batch 830/2438  on Training is 32.8820697954272\n",
            "Epoch #0. Accuracy on batch 831/2438  on Training is 32.88386418269231\n",
            "Epoch #0. Accuracy on batch 832/2438  on Training is 32.89315726290516\n",
            "Epoch #0. Accuracy on batch 833/2438  on Training is 32.90617505995204\n",
            "Epoch #0. Accuracy on batch 834/2438  on Training is 32.93787425149701\n",
            "Epoch #0. Accuracy on batch 835/2438  on Training is 32.94706937799043\n",
            "Epoch #0. Accuracy on batch 836/2438  on Training is 32.956242532855434\n",
            "Epoch #0. Accuracy on batch 837/2438  on Training is 32.980310262529834\n",
            "Epoch #0. Accuracy on batch 838/2438  on Training is 33.00432061978546\n",
            "Epoch #0. Accuracy on batch 839/2438  on Training is 33.02827380952381\n",
            "Batch Id 840/2438 is having training loss of 3.1981804370880127\n",
            "2.5543363094329834\n",
            "Epoch #0. Accuracy on batch 840/2438  on Training is 33.03730677764566\n",
            "Epoch #0. Accuracy on batch 841/2438  on Training is 33.04631828978622\n",
            "Epoch #0. Accuracy on batch 842/2438  on Training is 33.062722419928825\n",
            "Epoch #0. Accuracy on batch 843/2438  on Training is 33.07538507109005\n",
            "Epoch #0. Accuracy on batch 844/2438  on Training is 33.09171597633136\n",
            "Epoch #0. Accuracy on batch 845/2438  on Training is 33.10431442080378\n",
            "Epoch #0. Accuracy on batch 846/2438  on Training is 33.105814639905546\n",
            "Epoch #0. Accuracy on batch 847/2438  on Training is 33.110996462264154\n",
            "Epoch #0. Accuracy on batch 848/2438  on Training is 33.12352767962309\n",
            "Epoch #0. Accuracy on batch 849/2438  on Training is 33.125\n",
            "Epoch #0. Accuracy on batch 850/2438  on Training is 33.13014101057579\n",
            "Epoch #0. Accuracy on batch 851/2438  on Training is 33.12793427230047\n",
            "Epoch #0. Accuracy on batch 852/2438  on Training is 33.12939624853458\n",
            "Epoch #0. Accuracy on batch 853/2438  on Training is 33.16378805620609\n",
            "Epoch #0. Accuracy on batch 854/2438  on Training is 33.183479532163744\n",
            "Epoch #0. Accuracy on batch 855/2438  on Training is 33.19947429906542\n",
            "Epoch #0. Accuracy on batch 856/2438  on Training is 33.20449241540257\n",
            "Epoch #0. Accuracy on batch 857/2438  on Training is 33.2240675990676\n",
            "Epoch #0. Accuracy on batch 858/2438  on Training is 33.23268335273574\n",
            "Epoch #0. Accuracy on batch 859/2438  on Training is 33.263081395348834\n",
            "Batch Id 860/2438 is having training loss of 3.1817467212677\n",
            "2.8452868461608887\n",
            "Epoch #0. Accuracy on batch 860/2438  on Training is 33.260743321718934\n",
            "Epoch #0. Accuracy on batch 861/2438  on Training is 33.287412993039446\n",
            "Epoch #0. Accuracy on batch 862/2438  on Training is 33.31764194669757\n",
            "Epoch #0. Accuracy on batch 863/2438  on Training is 33.322482638888886\n",
            "Epoch #0. Accuracy on batch 864/2438  on Training is 33.34537572254335\n",
            "Epoch #0. Accuracy on batch 865/2438  on Training is 33.3537817551963\n",
            "Epoch #0. Accuracy on batch 866/2438  on Training is 33.36937716262976\n",
            "Epoch #0. Accuracy on batch 867/2438  on Training is 33.37413594470046\n",
            "Epoch #0. Accuracy on batch 868/2438  on Training is 33.39326812428078\n",
            "Epoch #0. Accuracy on batch 869/2438  on Training is 33.394396551724135\n",
            "Epoch #0. Accuracy on batch 870/2438  on Training is 33.41346153846154\n",
            "Epoch #0. Accuracy on batch 871/2438  on Training is 33.428899082568805\n",
            "Epoch #0. Accuracy on batch 872/2438  on Training is 33.45504009163803\n",
            "Epoch #0. Accuracy on batch 873/2438  on Training is 33.463243707093824\n",
            "Epoch #0. Accuracy on batch 874/2438  on Training is 33.46071428571429\n",
            "Epoch #0. Accuracy on batch 875/2438  on Training is 33.476027397260275\n",
            "Epoch #0. Accuracy on batch 876/2438  on Training is 33.49130558722919\n",
            "Epoch #0. Accuracy on batch 877/2438  on Training is 33.499430523917994\n",
            "Epoch #0. Accuracy on batch 878/2438  on Training is 33.514647326507394\n",
            "Epoch #0. Accuracy on batch 879/2438  on Training is 33.53338068181818\n",
            "Batch Id 880/2438 is having training loss of 3.162930488586426\n",
            "2.4391496181488037\n",
            "Epoch #0. Accuracy on batch 880/2438  on Training is 33.541430192962544\n",
            "Epoch #0. Accuracy on batch 881/2438  on Training is 33.54946145124717\n",
            "Epoch #0. Accuracy on batch 882/2438  on Training is 33.57516987542469\n",
            "Epoch #0. Accuracy on batch 883/2438  on Training is 33.58667986425339\n",
            "Epoch #0. Accuracy on batch 884/2438  on Training is 33.61581920903955\n",
            "Epoch #0. Accuracy on batch 885/2438  on Training is 33.62020316027088\n",
            "Epoch #0. Accuracy on batch 886/2438  on Training is 33.63866967305524\n",
            "Epoch #0. Accuracy on batch 887/2438  on Training is 33.653575450450454\n",
            "Epoch #0. Accuracy on batch 888/2438  on Training is 33.67196287964005\n",
            "Epoch #0. Accuracy on batch 889/2438  on Training is 33.690308988764045\n",
            "Epoch #0. Accuracy on batch 890/2438  on Training is 33.68757014590348\n",
            "Epoch #0. Accuracy on batch 891/2438  on Training is 33.69534753363229\n",
            "Epoch #0. Accuracy on batch 892/2438  on Training is 33.692609182530795\n",
            "Epoch #0. Accuracy on batch 893/2438  on Training is 33.703859060402685\n",
            "Epoch #0. Accuracy on batch 894/2438  on Training is 33.71508379888268\n",
            "Epoch #0. Accuracy on batch 895/2438  on Training is 33.726283482142854\n",
            "Epoch #0. Accuracy on batch 896/2438  on Training is 33.73745819397993\n",
            "Epoch #0. Accuracy on batch 897/2438  on Training is 33.7451280623608\n",
            "Epoch #0. Accuracy on batch 898/2438  on Training is 33.756256952169075\n",
            "Epoch #0. Accuracy on batch 899/2438  on Training is 33.763888888888886\n",
            "Batch Id 900/2438 is having training loss of 3.144611120223999\n",
            "2.24629807472229\n",
            "Epoch #0. Accuracy on batch 900/2438  on Training is 33.78884572697003\n",
            "Epoch #0. Accuracy on batch 901/2438  on Training is 33.81028270509978\n",
            "Epoch #0. Accuracy on batch 902/2438  on Training is 33.82821151716501\n",
            "Epoch #0. Accuracy on batch 903/2438  on Training is 33.84610066371681\n",
            "Epoch #0. Accuracy on batch 904/2438  on Training is 33.860497237569064\n",
            "Epoch #0. Accuracy on batch 905/2438  on Training is 33.854166666666664\n",
            "Epoch #0. Accuracy on batch 906/2438  on Training is 33.87541345093715\n",
            "Epoch #0. Accuracy on batch 907/2438  on Training is 33.88973017621145\n",
            "Epoch #0. Accuracy on batch 908/2438  on Training is 33.92120462046205\n",
            "Epoch #0. Accuracy on batch 909/2438  on Training is 33.95260989010989\n",
            "Epoch #0. Accuracy on batch 910/2438  on Training is 33.94964324917673\n",
            "Epoch #0. Accuracy on batch 911/2438  on Training is 33.963815789473685\n",
            "Epoch #0. Accuracy on batch 912/2438  on Training is 33.967688937568454\n",
            "Epoch #0. Accuracy on batch 913/2438  on Training is 33.97497264770241\n",
            "Epoch #0. Accuracy on batch 914/2438  on Training is 33.97882513661202\n",
            "Epoch #0. Accuracy on batch 915/2438  on Training is 33.9826692139738\n",
            "Epoch #0. Accuracy on batch 916/2438  on Training is 33.98991275899673\n",
            "Epoch #0. Accuracy on batch 917/2438  on Training is 34.00735294117647\n",
            "Epoch #0. Accuracy on batch 918/2438  on Training is 34.007752992383026\n",
            "Epoch #0. Accuracy on batch 919/2438  on Training is 34.02853260869565\n",
            "Batch Id 920/2438 is having training loss of 3.127303123474121\n",
            "2.316483974456787\n",
            "Epoch #0. Accuracy on batch 920/2438  on Training is 34.04587404994571\n",
            "Epoch #0. Accuracy on batch 921/2438  on Training is 34.04962039045553\n",
            "Epoch #0. Accuracy on batch 922/2438  on Training is 34.04997291440954\n",
            "Epoch #0. Accuracy on batch 923/2438  on Training is 34.06047077922078\n",
            "Epoch #0. Accuracy on batch 924/2438  on Training is 34.070945945945944\n",
            "Epoch #0. Accuracy on batch 925/2438  on Training is 34.08477321814255\n",
            "Epoch #0. Accuracy on batch 926/2438  on Training is 34.0918284789644\n",
            "Epoch #0. Accuracy on batch 927/2438  on Training is 34.09886853448276\n",
            "Epoch #0. Accuracy on batch 928/2438  on Training is 34.09916576964478\n",
            "Epoch #0. Accuracy on batch 929/2438  on Training is 34.11290322580645\n",
            "Epoch #0. Accuracy on batch 930/2438  on Training is 34.119897959183675\n",
            "Epoch #0. Accuracy on batch 931/2438  on Training is 34.146995708154506\n",
            "Epoch #0. Accuracy on batch 932/2438  on Training is 34.16063772775991\n",
            "Epoch #0. Accuracy on batch 933/2438  on Training is 34.15752141327623\n",
            "Epoch #0. Accuracy on batch 934/2438  on Training is 34.18783422459893\n",
            "Epoch #0. Accuracy on batch 935/2438  on Training is 34.20472756410256\n",
            "Epoch #0. Accuracy on batch 936/2438  on Training is 34.20824439701174\n",
            "Epoch #0. Accuracy on batch 937/2438  on Training is 34.22841151385928\n",
            "Epoch #0. Accuracy on batch 938/2438  on Training is 34.23855165069222\n",
            "Epoch #0. Accuracy on batch 939/2438  on Training is 34.265292553191486\n",
            "Batch Id 940/2438 is having training loss of 3.1114425659179688\n",
            "1.9998492002487183\n",
            "Epoch #0. Accuracy on batch 940/2438  on Training is 34.29529755579171\n",
            "Epoch #0. Accuracy on batch 941/2438  on Training is 34.305334394904456\n",
            "Epoch #0. Accuracy on batch 942/2438  on Training is 34.31534994697773\n",
            "Epoch #0. Accuracy on batch 943/2438  on Training is 34.33196504237288\n",
            "Epoch #0. Accuracy on batch 944/2438  on Training is 34.345238095238095\n",
            "Epoch #0. Accuracy on batch 945/2438  on Training is 34.375\n",
            "Epoch #0. Accuracy on batch 946/2438  on Training is 34.378299894403376\n",
            "Epoch #0. Accuracy on batch 947/2438  on Training is 34.39148206751055\n",
            "Epoch #0. Accuracy on batch 948/2438  on Training is 34.40463645943098\n",
            "Epoch #0. Accuracy on batch 949/2438  on Training is 34.421052631578945\n",
            "Epoch #0. Accuracy on batch 950/2438  on Training is 34.43414826498423\n",
            "Epoch #0. Accuracy on batch 951/2438  on Training is 34.440651260504204\n",
            "Epoch #0. Accuracy on batch 952/2438  on Training is 34.46353620146905\n",
            "Epoch #0. Accuracy on batch 953/2438  on Training is 34.476546121593294\n",
            "Epoch #0. Accuracy on batch 954/2438  on Training is 34.49934554973822\n",
            "Epoch #0. Accuracy on batch 955/2438  on Training is 34.51882845188285\n",
            "Epoch #0. Accuracy on batch 956/2438  on Training is 34.544801462904914\n",
            "Epoch #0. Accuracy on batch 957/2438  on Training is 34.56093423799582\n",
            "Epoch #0. Accuracy on batch 958/2438  on Training is 34.56725755995829\n",
            "Epoch #0. Accuracy on batch 959/2438  on Training is 34.593098958333336\n",
            "Batch Id 960/2438 is having training loss of 3.0950610637664795\n",
            "2.4944064617156982\n",
            "Epoch #0. Accuracy on batch 960/2438  on Training is 34.602627471383975\n",
            "Epoch #0. Accuracy on batch 961/2438  on Training is 34.602390852390855\n",
            "Epoch #0. Accuracy on batch 962/2438  on Training is 34.60864485981308\n",
            "Epoch #0. Accuracy on batch 963/2438  on Training is 34.627852697095435\n",
            "Epoch #0. Accuracy on batch 964/2438  on Training is 34.65349740932643\n",
            "Epoch #0. Accuracy on batch 965/2438  on Training is 34.67261904761905\n",
            "Epoch #0. Accuracy on batch 966/2438  on Training is 34.69493278179938\n",
            "Epoch #0. Accuracy on batch 967/2438  on Training is 34.704287190082646\n",
            "Epoch #0. Accuracy on batch 968/2438  on Training is 34.72007223942209\n",
            "Epoch #0. Accuracy on batch 969/2438  on Training is 34.72938144329897\n",
            "Epoch #0. Accuracy on batch 970/2438  on Training is 34.74188980432544\n",
            "Epoch #0. Accuracy on batch 971/2438  on Training is 34.760802469135804\n",
            "Epoch #0. Accuracy on batch 972/2438  on Training is 34.76682939362796\n",
            "Epoch #0. Accuracy on batch 973/2438  on Training is 34.78567761806981\n",
            "Epoch #0. Accuracy on batch 974/2438  on Training is 34.79807692307692\n",
            "Epoch #0. Accuracy on batch 975/2438  on Training is 34.81365266393443\n",
            "Epoch #0. Accuracy on batch 976/2438  on Training is 34.82599795291709\n",
            "Epoch #0. Accuracy on batch 977/2438  on Training is 34.83831799591002\n",
            "Epoch #0. Accuracy on batch 978/2438  on Training is 34.86018896833504\n",
            "Epoch #0. Accuracy on batch 979/2438  on Training is 34.87563775510204\n",
            "Batch Id 980/2438 is having training loss of 3.0769875049591064\n",
            "2.465728998184204\n",
            "Epoch #0. Accuracy on batch 980/2438  on Training is 34.88468399592253\n",
            "Epoch #0. Accuracy on batch 981/2438  on Training is 34.90007637474542\n",
            "Epoch #0. Accuracy on batch 982/2438  on Training is 34.9059003051882\n",
            "Epoch #0. Accuracy on batch 983/2438  on Training is 34.927591463414636\n",
            "Epoch #0. Accuracy on batch 984/2438  on Training is 34.94606598984772\n",
            "Epoch #0. Accuracy on batch 985/2438  on Training is 34.95182555780933\n",
            "Epoch #0. Accuracy on batch 986/2438  on Training is 34.970238095238095\n",
            "Epoch #0. Accuracy on batch 987/2438  on Training is 34.979124493927124\n",
            "Epoch #0. Accuracy on batch 988/2438  on Training is 34.987992922143576\n",
            "Epoch #0. Accuracy on batch 989/2438  on Training is 35.00315656565657\n",
            "Epoch #0. Accuracy on batch 990/2438  on Training is 35.02144298688194\n",
            "Epoch #0. Accuracy on batch 991/2438  on Training is 35.03654233870968\n",
            "Epoch #0. Accuracy on batch 992/2438  on Training is 35.05161127895267\n",
            "Epoch #0. Accuracy on batch 993/2438  on Training is 35.063506036217305\n",
            "Epoch #0. Accuracy on batch 994/2438  on Training is 35.06595477386934\n",
            "Epoch #0. Accuracy on batch 995/2438  on Training is 35.0589859437751\n",
            "Epoch #0. Accuracy on batch 996/2438  on Training is 35.070837512537615\n",
            "Epoch #0. Accuracy on batch 997/2438  on Training is 35.079534068136276\n",
            "Epoch #0. Accuracy on batch 998/2438  on Training is 35.094469469469466\n",
            "Epoch #0. Accuracy on batch 999/2438  on Training is 35.10625\n",
            "Batch Id 1000/2438 is having training loss of 3.062248468399048\n",
            "2.5439703464508057\n",
            "Epoch #0. Accuracy on batch 1000/2438  on Training is 35.11488511488511\n",
            "Epoch #0. Accuracy on batch 1001/2438  on Training is 35.13285928143713\n",
            "Epoch #0. Accuracy on batch 1002/2438  on Training is 35.13833499501496\n",
            "Epoch #0. Accuracy on batch 1003/2438  on Training is 35.14691235059761\n",
            "Epoch #0. Accuracy on batch 1004/2438  on Training is 35.167910447761194\n",
            "Epoch #0. Accuracy on batch 1005/2438  on Training is 35.18576043737575\n",
            "Epoch #0. Accuracy on batch 1006/2438  on Training is 35.18495531281033\n",
            "Epoch #0. Accuracy on batch 1007/2438  on Training is 35.19965277777778\n",
            "Epoch #0. Accuracy on batch 1008/2438  on Training is 35.20502973240833\n",
            "Epoch #0. Accuracy on batch 1009/2438  on Training is 35.228960396039604\n",
            "Epoch #0. Accuracy on batch 1010/2438  on Training is 35.23738872403561\n",
            "Epoch #0. Accuracy on batch 1011/2438  on Training is 35.25197628458498\n",
            "Epoch #0. Accuracy on batch 1012/2438  on Training is 35.26345014807502\n",
            "Epoch #0. Accuracy on batch 1013/2438  on Training is 35.281065088757394\n",
            "Epoch #0. Accuracy on batch 1014/2438  on Training is 35.283251231527096\n",
            "Epoch #0. Accuracy on batch 1015/2438  on Training is 35.29158464566929\n",
            "Epoch #0. Accuracy on batch 1016/2438  on Training is 35.30604719764012\n",
            "Epoch #0. Accuracy on batch 1017/2438  on Training is 35.3235510805501\n",
            "Epoch #0. Accuracy on batch 1018/2438  on Training is 35.33488714425908\n",
            "Epoch #0. Accuracy on batch 1019/2438  on Training is 35.35232843137255\n",
            "Batch Id 1020/2438 is having training loss of 3.045570135116577\n",
            "1.751059889793396\n",
            "Epoch #0. Accuracy on batch 1020/2438  on Training is 35.38809990205681\n",
            "Epoch #0. Accuracy on batch 1021/2438  on Training is 35.39933953033268\n",
            "Epoch #0. Accuracy on batch 1022/2438  on Training is 35.3952834799609\n",
            "Epoch #0. Accuracy on batch 1023/2438  on Training is 35.4156494140625\n",
            "Epoch #0. Accuracy on batch 1024/2438  on Training is 35.423780487804876\n",
            "Epoch #0. Accuracy on batch 1025/2438  on Training is 35.44103313840156\n",
            "Epoch #0. Accuracy on batch 1026/2438  on Training is 35.461295034079846\n",
            "Epoch #0. Accuracy on batch 1027/2438  on Training is 35.46631809338521\n",
            "Epoch #0. Accuracy on batch 1028/2438  on Training is 35.47740524781341\n",
            "Epoch #0. Accuracy on batch 1029/2438  on Training is 35.48543689320388\n",
            "Epoch #0. Accuracy on batch 1030/2438  on Training is 35.50254607177497\n",
            "Epoch #0. Accuracy on batch 1031/2438  on Training is 35.510537790697676\n",
            "Epoch #0. Accuracy on batch 1032/2438  on Training is 35.515488867376575\n",
            "Epoch #0. Accuracy on batch 1033/2438  on Training is 35.52043036750484\n",
            "Epoch #0. Accuracy on batch 1034/2438  on Training is 35.53442028985507\n",
            "Epoch #0. Accuracy on batch 1035/2438  on Training is 35.557432432432435\n",
            "Epoch #0. Accuracy on batch 1036/2438  on Training is 35.56533269045323\n",
            "Epoch #0. Accuracy on batch 1037/2438  on Training is 35.576228323699425\n",
            "Epoch #0. Accuracy on batch 1038/2438  on Training is 35.58710298363811\n",
            "Epoch #0. Accuracy on batch 1039/2438  on Training is 35.60096153846154\n",
            "Batch Id 1040/2438 is having training loss of 3.031224489212036\n",
            "2.710547685623169\n",
            "Epoch #0. Accuracy on batch 1040/2438  on Training is 35.60578770413064\n",
            "Epoch #0. Accuracy on batch 1041/2438  on Training is 35.61360364683301\n",
            "Epoch #0. Accuracy on batch 1042/2438  on Training is 35.6214046021093\n",
            "Epoch #0. Accuracy on batch 1043/2438  on Training is 35.644157088122604\n",
            "Epoch #0. Accuracy on batch 1044/2438  on Training is 35.660885167464116\n",
            "Epoch #0. Accuracy on batch 1045/2438  on Training is 35.6656309751434\n",
            "Epoch #0. Accuracy on batch 1046/2438  on Training is 35.688276026743075\n",
            "Epoch #0. Accuracy on batch 1047/2438  on Training is 35.68404103053435\n",
            "Epoch #0. Accuracy on batch 1048/2438  on Training is 35.68577216396568\n",
            "Epoch #0. Accuracy on batch 1049/2438  on Training is 35.68452380952381\n",
            "Epoch #0. Accuracy on batch 1050/2438  on Training is 35.701117982873456\n",
            "Epoch #0. Accuracy on batch 1051/2438  on Training is 35.723621673003805\n",
            "Epoch #0. Accuracy on batch 1052/2438  on Training is 35.74608262108262\n",
            "Epoch #0. Accuracy on batch 1053/2438  on Training is 35.75367647058823\n",
            "Epoch #0. Accuracy on batch 1054/2438  on Training is 35.77014218009479\n",
            "Epoch #0. Accuracy on batch 1055/2438  on Training is 35.792495265151516\n",
            "Epoch #0. Accuracy on batch 1056/2438  on Training is 35.81480605487228\n",
            "Epoch #0. Accuracy on batch 1057/2438  on Training is 35.807537807183365\n",
            "Epoch #0. Accuracy on batch 1058/2438  on Training is 35.82389046270066\n",
            "Epoch #0. Accuracy on batch 1059/2438  on Training is 35.85495283018868\n",
            "Batch Id 1060/2438 is having training loss of 3.0168538093566895\n",
            "2.702333450317383\n",
            "Epoch #0. Accuracy on batch 1060/2438  on Training is 35.85650329877474\n",
            "Epoch #0. Accuracy on batch 1061/2438  on Training is 35.87570621468927\n",
            "Epoch #0. Accuracy on batch 1062/2438  on Training is 35.894873000940734\n",
            "Epoch #0. Accuracy on batch 1063/2438  on Training is 35.91106672932331\n",
            "Epoch #0. Accuracy on batch 1064/2438  on Training is 35.921361502347416\n",
            "Epoch #0. Accuracy on batch 1065/2438  on Training is 35.928705440900565\n",
            "Epoch #0. Accuracy on batch 1066/2438  on Training is 35.936035613870665\n",
            "Epoch #0. Accuracy on batch 1067/2438  on Training is 35.9433520599251\n",
            "Epoch #0. Accuracy on batch 1068/2438  on Training is 35.956501403180546\n",
            "Epoch #0. Accuracy on batch 1069/2438  on Training is 35.966705607476634\n",
            "Epoch #0. Accuracy on batch 1070/2438  on Training is 35.98856209150327\n",
            "Epoch #0. Accuracy on batch 1071/2438  on Training is 35.99871735074627\n",
            "Epoch #0. Accuracy on batch 1072/2438  on Training is 36.0059412861137\n",
            "Epoch #0. Accuracy on batch 1073/2438  on Training is 36.00733240223464\n",
            "Epoch #0. Accuracy on batch 1074/2438  on Training is 36.01162790697674\n",
            "Epoch #0. Accuracy on batch 1075/2438  on Training is 36.02753252788104\n",
            "Epoch #0. Accuracy on batch 1076/2438  on Training is 36.0230965645311\n",
            "Epoch #0. Accuracy on batch 1077/2438  on Training is 36.0418599257885\n",
            "Epoch #0. Accuracy on batch 1078/2438  on Training is 36.06058850787767\n",
            "Epoch #0. Accuracy on batch 1079/2438  on Training is 36.08796296296296\n",
            "Batch Id 1080/2438 is having training loss of 3.0006749629974365\n",
            "1.7917578220367432\n",
            "Epoch #0. Accuracy on batch 1080/2438  on Training is 36.097941720629045\n",
            "Epoch #0. Accuracy on batch 1081/2438  on Training is 36.11079020332717\n",
            "Epoch #0. Accuracy on batch 1082/2438  on Training is 36.123614958448755\n",
            "Epoch #0. Accuracy on batch 1083/2438  on Training is 36.13641605166052\n",
            "Epoch #0. Accuracy on batch 1084/2438  on Training is 36.1434331797235\n",
            "Epoch #0. Accuracy on batch 1085/2438  on Training is 36.15906998158379\n",
            "Epoch #0. Accuracy on batch 1086/2438  on Training is 36.177552897884084\n",
            "Epoch #0. Accuracy on batch 1087/2438  on Training is 36.19312959558823\n",
            "Epoch #0. Accuracy on batch 1088/2438  on Training is 36.20867768595041\n",
            "Epoch #0. Accuracy on batch 1089/2438  on Training is 36.21559633027523\n",
            "Epoch #0. Accuracy on batch 1090/2438  on Training is 36.22250229147571\n",
            "Epoch #0. Accuracy on batch 1091/2438  on Training is 36.22653388278388\n",
            "Epoch #0. Accuracy on batch 1092/2438  on Training is 36.216262580054895\n",
            "Epoch #0. Accuracy on batch 1093/2438  on Training is 36.22600548446069\n",
            "Epoch #0. Accuracy on batch 1094/2438  on Training is 36.23002283105023\n",
            "Epoch #0. Accuracy on batch 1095/2438  on Training is 36.231181569343065\n",
            "Epoch #0. Accuracy on batch 1096/2438  on Training is 36.25227894257065\n",
            "Epoch #0. Accuracy on batch 1097/2438  on Training is 36.25910746812386\n",
            "Epoch #0. Accuracy on batch 1098/2438  on Training is 36.27729754322111\n",
            "Epoch #0. Accuracy on batch 1099/2438  on Training is 36.29829545454545\n",
            "Batch Id 1100/2438 is having training loss of 2.9866373538970947\n",
            "2.0023598670959473\n",
            "Epoch #0. Accuracy on batch 1100/2438  on Training is 36.31641689373297\n",
            "Epoch #0. Accuracy on batch 1101/2438  on Training is 36.323162431941924\n",
            "Epoch #0. Accuracy on batch 1102/2438  on Training is 36.33556210335449\n",
            "Epoch #0. Accuracy on batch 1103/2438  on Training is 36.35926177536232\n",
            "Epoch #0. Accuracy on batch 1104/2438  on Training is 36.37443438914027\n",
            "Epoch #0. Accuracy on batch 1105/2438  on Training is 36.386754068716094\n",
            "Epoch #0. Accuracy on batch 1106/2438  on Training is 36.401874435411024\n",
            "Epoch #0. Accuracy on batch 1107/2438  on Training is 36.41132671480145\n",
            "Epoch #0. Accuracy on batch 1108/2438  on Training is 36.43203336339044\n",
            "Epoch #0. Accuracy on batch 1109/2438  on Training is 36.44425675675676\n",
            "Epoch #0. Accuracy on batch 1110/2438  on Training is 36.43958145814582\n",
            "Epoch #0. Accuracy on batch 1111/2438  on Training is 36.463017086330936\n",
            "Epoch #0. Accuracy on batch 1112/2438  on Training is 36.463948787061994\n",
            "Epoch #0. Accuracy on batch 1113/2438  on Training is 36.48732046678636\n",
            "Epoch #0. Accuracy on batch 1114/2438  on Training is 36.48822869955157\n",
            "Epoch #0. Accuracy on batch 1115/2438  on Training is 36.505936379928315\n",
            "Epoch #0. Accuracy on batch 1116/2438  on Training is 36.51801700984781\n",
            "Epoch #0. Accuracy on batch 1117/2438  on Training is 36.52728085867621\n",
            "Epoch #0. Accuracy on batch 1118/2438  on Training is 36.52815013404826\n",
            "Epoch #0. Accuracy on batch 1119/2438  on Training is 36.534598214285715\n",
            "Batch Id 1120/2438 is having training loss of 2.9724371433258057\n",
            "2.126549005508423\n",
            "Epoch #0. Accuracy on batch 1120/2438  on Training is 36.55218554861731\n",
            "Epoch #0. Accuracy on batch 1121/2438  on Training is 36.553030303030305\n",
            "Epoch #0. Accuracy on batch 1122/2438  on Training is 36.55109082813891\n",
            "Epoch #0. Accuracy on batch 1123/2438  on Training is 36.56583629893238\n",
            "Epoch #0. Accuracy on batch 1124/2438  on Training is 36.56944444444444\n",
            "Epoch #0. Accuracy on batch 1125/2438  on Training is 36.586922735346356\n",
            "Epoch #0. Accuracy on batch 1126/2438  on Training is 36.59327861579414\n",
            "Epoch #0. Accuracy on batch 1127/2438  on Training is 36.61070478723404\n",
            "Epoch #0. Accuracy on batch 1128/2438  on Training is 36.62533215234721\n",
            "Epoch #0. Accuracy on batch 1129/2438  on Training is 36.65099557522124\n",
            "Epoch #0. Accuracy on batch 1130/2438  on Training is 36.66556145004421\n",
            "Epoch #0. Accuracy on batch 1131/2438  on Training is 36.67181978798587\n",
            "Epoch #0. Accuracy on batch 1132/2438  on Training is 36.675308914386584\n",
            "Epoch #0. Accuracy on batch 1133/2438  on Training is 36.68705908289242\n",
            "Epoch #0. Accuracy on batch 1134/2438  on Training is 36.70429515418502\n",
            "Epoch #0. Accuracy on batch 1135/2438  on Training is 36.71049735915493\n",
            "Epoch #0. Accuracy on batch 1136/2438  on Training is 36.72493403693932\n",
            "Epoch #0. Accuracy on batch 1137/2438  on Training is 36.7338532513181\n",
            "Epoch #0. Accuracy on batch 1138/2438  on Training is 36.745500438981566\n",
            "Epoch #0. Accuracy on batch 1139/2438  on Training is 36.74616228070175\n",
            "Batch Id 1140/2438 is having training loss of 2.9593522548675537\n",
            "2.2883801460266113\n",
            "Epoch #0. Accuracy on batch 1140/2438  on Training is 36.763255915863276\n",
            "Epoch #0. Accuracy on batch 1141/2438  on Training is 36.77758318739054\n",
            "Epoch #0. Accuracy on batch 1142/2438  on Training is 36.786417322834644\n",
            "Epoch #0. Accuracy on batch 1143/2438  on Training is 36.78704108391609\n",
            "Epoch #0. Accuracy on batch 1144/2438  on Training is 36.79585152838428\n",
            "Epoch #0. Accuracy on batch 1145/2438  on Training is 36.81282722513089\n",
            "Epoch #0. Accuracy on batch 1146/2438  on Training is 36.818875326939846\n",
            "Epoch #0. Accuracy on batch 1147/2438  on Training is 36.82491289198606\n",
            "Epoch #0. Accuracy on batch 1148/2438  on Training is 36.83909921671018\n",
            "Epoch #0. Accuracy on batch 1149/2438  on Training is 36.869565217391305\n",
            "Epoch #0. Accuracy on batch 1150/2438  on Training is 36.87554300608167\n",
            "Epoch #0. Accuracy on batch 1151/2438  on Training is 36.8896484375\n",
            "Epoch #0. Accuracy on batch 1152/2438  on Training is 36.903729401561144\n",
            "Epoch #0. Accuracy on batch 1153/2438  on Training is 36.92861785095321\n",
            "Epoch #0. Accuracy on batch 1154/2438  on Training is 36.942640692640694\n",
            "Epoch #0. Accuracy on batch 1155/2438  on Training is 36.97285899653979\n",
            "Epoch #0. Accuracy on batch 1156/2438  on Training is 36.97601555747623\n",
            "Epoch #0. Accuracy on batch 1157/2438  on Training is 36.998056994818654\n",
            "Epoch #0. Accuracy on batch 1158/2438  on Training is 37.01466781708369\n",
            "Epoch #0. Accuracy on batch 1159/2438  on Training is 37.02316810344828\n",
            "Batch Id 1160/2438 is having training loss of 2.944385290145874\n",
            "2.016472101211548\n",
            "Epoch #0. Accuracy on batch 1160/2438  on Training is 37.03434539190353\n",
            "Epoch #0. Accuracy on batch 1161/2438  on Training is 37.0401247848537\n",
            "Epoch #0. Accuracy on batch 1162/2438  on Training is 37.05932932072227\n",
            "Epoch #0. Accuracy on batch 1163/2438  on Training is 37.06239261168385\n",
            "Epoch #0. Accuracy on batch 1164/2438  on Training is 37.06545064377682\n",
            "Epoch #0. Accuracy on batch 1165/2438  on Training is 37.076543739279586\n",
            "Epoch #0. Accuracy on batch 1166/2438  on Training is 37.092973436161095\n",
            "Epoch #0. Accuracy on batch 1167/2438  on Training is 37.11205051369863\n",
            "Epoch #0. Accuracy on batch 1168/2438  on Training is 37.12842172797263\n",
            "Epoch #0. Accuracy on batch 1169/2438  on Training is 37.131410256410255\n",
            "Epoch #0. Accuracy on batch 1170/2438  on Training is 37.13973099914603\n",
            "Epoch #0. Accuracy on batch 1171/2438  on Training is 37.14003839590443\n",
            "Epoch #0. Accuracy on batch 1172/2438  on Training is 37.14300937766411\n",
            "Epoch #0. Accuracy on batch 1173/2438  on Training is 37.16194633730835\n",
            "Epoch #0. Accuracy on batch 1174/2438  on Training is 37.18617021276596\n",
            "Epoch #0. Accuracy on batch 1175/2438  on Training is 37.19706632653061\n",
            "Epoch #0. Accuracy on batch 1176/2438  on Training is 37.213254035683946\n",
            "Epoch #0. Accuracy on batch 1177/2438  on Training is 37.2294142614601\n",
            "Epoch #0. Accuracy on batch 1178/2438  on Training is 37.25349872773537\n",
            "Epoch #0. Accuracy on batch 1179/2438  on Training is 37.27489406779661\n",
            "Batch Id 1180/2438 is having training loss of 2.929964303970337\n",
            "1.9636656045913696\n",
            "Epoch #0. Accuracy on batch 1180/2438  on Training is 37.2883149872989\n",
            "Epoch #0. Accuracy on batch 1181/2438  on Training is 37.32021996615905\n",
            "Epoch #0. Accuracy on batch 1182/2438  on Training is 37.32565511411665\n",
            "Epoch #0. Accuracy on batch 1183/2438  on Training is 37.31788429054054\n",
            "Epoch #0. Accuracy on batch 1184/2438  on Training is 37.33386075949367\n",
            "Epoch #0. Accuracy on batch 1185/2438  on Training is 37.347175379426645\n",
            "Epoch #0. Accuracy on batch 1186/2438  on Training is 37.36310025273799\n",
            "Epoch #0. Accuracy on batch 1187/2438  on Training is 37.37636784511785\n",
            "Epoch #0. Accuracy on batch 1188/2438  on Training is 37.37910008410429\n",
            "Epoch #0. Accuracy on batch 1189/2438  on Training is 37.38970588235294\n",
            "Epoch #0. Accuracy on batch 1190/2438  on Training is 37.40291771620487\n",
            "Epoch #0. Accuracy on batch 1191/2438  on Training is 37.413485738255034\n",
            "Epoch #0. Accuracy on batch 1192/2438  on Training is 37.42141659681475\n",
            "Epoch #0. Accuracy on batch 1193/2438  on Training is 37.41363065326633\n",
            "Epoch #0. Accuracy on batch 1194/2438  on Training is 37.42416317991632\n",
            "Epoch #0. Accuracy on batch 1195/2438  on Training is 37.43467809364549\n",
            "Epoch #0. Accuracy on batch 1196/2438  on Training is 37.45039682539682\n",
            "Epoch #0. Accuracy on batch 1197/2438  on Training is 37.45826377295492\n",
            "Epoch #0. Accuracy on batch 1198/2438  on Training is 37.466117597998334\n",
            "Epoch #0. Accuracy on batch 1199/2438  on Training is 37.484375\n",
            "Batch Id 1200/2438 is having training loss of 2.9175498485565186\n",
            "2.453650712966919\n",
            "Epoch #0. Accuracy on batch 1200/2438  on Training is 37.486990008326394\n",
            "Epoch #0. Accuracy on batch 1201/2438  on Training is 37.4948003327787\n",
            "Epoch #0. Accuracy on batch 1202/2438  on Training is 37.5\n",
            "Epoch #0. Accuracy on batch 1203/2438  on Training is 37.51038205980066\n",
            "Epoch #0. Accuracy on batch 1204/2438  on Training is 37.518153526970956\n",
            "Epoch #0. Accuracy on batch 1205/2438  on Training is 37.52072968490879\n",
            "Epoch #0. Accuracy on batch 1206/2438  on Training is 37.52847970173985\n",
            "Epoch #0. Accuracy on batch 1207/2438  on Training is 37.53362996688742\n",
            "Epoch #0. Accuracy on batch 1208/2438  on Training is 37.54911083540116\n",
            "Epoch #0. Accuracy on batch 1209/2438  on Training is 37.564566115702476\n",
            "Epoch #0. Accuracy on batch 1210/2438  on Training is 37.57999587118084\n",
            "Epoch #0. Accuracy on batch 1211/2438  on Training is 37.59282178217822\n",
            "Epoch #0. Accuracy on batch 1212/2438  on Training is 37.61077906018137\n",
            "Epoch #0. Accuracy on batch 1213/2438  on Training is 37.62098434925865\n",
            "Epoch #0. Accuracy on batch 1214/2438  on Training is 37.63117283950617\n",
            "Epoch #0. Accuracy on batch 1215/2438  on Training is 37.64905427631579\n",
            "Epoch #0. Accuracy on batch 1216/2438  on Training is 37.67974527526705\n",
            "Epoch #0. Accuracy on batch 1217/2438  on Training is 37.68472906403941\n",
            "Epoch #0. Accuracy on batch 1218/2438  on Training is 37.69483182936833\n",
            "Epoch #0. Accuracy on batch 1219/2438  on Training is 37.70747950819672\n",
            "Batch Id 1220/2438 is having training loss of 2.9034290313720703\n",
            "1.8913750648498535\n",
            "Epoch #0. Accuracy on batch 1220/2438  on Training is 37.722665847665844\n",
            "Epoch #0. Accuracy on batch 1221/2438  on Training is 37.72248363338789\n",
            "Epoch #0. Accuracy on batch 1222/2438  on Training is 37.729967293540476\n",
            "Epoch #0. Accuracy on batch 1223/2438  on Training is 37.732332516339866\n",
            "Epoch #0. Accuracy on batch 1224/2438  on Training is 37.73724489795919\n",
            "Epoch #0. Accuracy on batch 1225/2438  on Training is 37.74979608482871\n",
            "Epoch #0. Accuracy on batch 1226/2438  on Training is 37.752139364303176\n",
            "Epoch #0. Accuracy on batch 1227/2438  on Training is 37.759568403908794\n",
            "Epoch #0. Accuracy on batch 1228/2438  on Training is 37.77207078925956\n",
            "Epoch #0. Accuracy on batch 1229/2438  on Training is 37.79471544715447\n",
            "Epoch #0. Accuracy on batch 1230/2438  on Training is 37.80209179528838\n",
            "Epoch #0. Accuracy on batch 1231/2438  on Training is 37.8322849025974\n",
            "Epoch #0. Accuracy on batch 1232/2438  on Training is 37.84468775344688\n",
            "Epoch #0. Accuracy on batch 1233/2438  on Training is 37.84947325769854\n",
            "Epoch #0. Accuracy on batch 1234/2438  on Training is 37.85172064777328\n",
            "Epoch #0. Accuracy on batch 1235/2438  on Training is 37.86407766990291\n",
            "Epoch #0. Accuracy on batch 1236/2438  on Training is 37.873888439773644\n",
            "Epoch #0. Accuracy on batch 1237/2438  on Training is 37.8937802907916\n",
            "Epoch #0. Accuracy on batch 1238/2438  on Training is 37.911117836965296\n",
            "Epoch #0. Accuracy on batch 1239/2438  on Training is 37.92590725806452\n",
            "Batch Id 1240/2438 is having training loss of 2.8914053440093994\n",
            "2.3917338848114014\n",
            "Epoch #0. Accuracy on batch 1240/2438  on Training is 37.925564061240934\n",
            "Epoch #0. Accuracy on batch 1241/2438  on Training is 37.92773752012882\n",
            "Epoch #0. Accuracy on batch 1242/2438  on Training is 37.93744971842317\n",
            "Epoch #0. Accuracy on batch 1243/2438  on Training is 37.94463424437299\n",
            "Epoch #0. Accuracy on batch 1244/2438  on Training is 37.95180722891566\n",
            "Epoch #0. Accuracy on batch 1245/2438  on Training is 37.9715088282504\n",
            "Epoch #0. Accuracy on batch 1246/2438  on Training is 37.97113071371291\n",
            "Epoch #0. Accuracy on batch 1247/2438  on Training is 37.990785256410255\n",
            "Epoch #0. Accuracy on batch 1248/2438  on Training is 38.01291032826261\n",
            "Epoch #0. Accuracy on batch 1249/2438  on Training is 38.035\n",
            "Epoch #0. Accuracy on batch 1250/2438  on Training is 38.039568345323744\n",
            "Epoch #0. Accuracy on batch 1251/2438  on Training is 38.0591054313099\n",
            "Epoch #0. Accuracy on batch 1252/2438  on Training is 38.06364724660814\n",
            "Epoch #0. Accuracy on batch 1253/2438  on Training is 38.07565789473684\n",
            "Epoch #0. Accuracy on batch 1254/2438  on Training is 38.1050796812749\n",
            "Epoch #0. Accuracy on batch 1255/2438  on Training is 38.099621815286625\n",
            "Epoch #0. Accuracy on batch 1256/2438  on Training is 38.10908910103421\n",
            "Epoch #0. Accuracy on batch 1257/2438  on Training is 38.123509538950714\n",
            "Epoch #0. Accuracy on batch 1258/2438  on Training is 38.12797855440826\n",
            "Epoch #0. Accuracy on batch 1259/2438  on Training is 38.13988095238095\n",
            "Batch Id 1260/2438 is having training loss of 2.8780102729797363\n",
            "1.941686987876892\n",
            "Epoch #0. Accuracy on batch 1260/2438  on Training is 38.14928628072958\n",
            "Epoch #0. Accuracy on batch 1261/2438  on Training is 38.15867670364501\n",
            "Epoch #0. Accuracy on batch 1262/2438  on Training is 38.17300079176564\n",
            "Epoch #0. Accuracy on batch 1263/2438  on Training is 38.18482990506329\n",
            "Epoch #0. Accuracy on batch 1264/2438  on Training is 38.18675889328063\n",
            "Epoch #0. Accuracy on batch 1265/2438  on Training is 38.18127962085308\n",
            "Epoch #0. Accuracy on batch 1266/2438  on Training is 38.19554064719811\n",
            "Epoch #0. Accuracy on batch 1267/2438  on Training is 38.20731466876972\n",
            "Epoch #0. Accuracy on batch 1268/2438  on Training is 38.2067572892041\n",
            "Epoch #0. Accuracy on batch 1269/2438  on Training is 38.213582677165356\n",
            "Epoch #0. Accuracy on batch 1270/2438  on Training is 38.2302321007081\n",
            "Epoch #0. Accuracy on batch 1271/2438  on Training is 38.246855345911946\n",
            "Epoch #0. Accuracy on batch 1272/2438  on Training is 38.26345247446976\n",
            "Epoch #0. Accuracy on batch 1273/2438  on Training is 38.28492935635793\n",
            "Epoch #0. Accuracy on batch 1274/2438  on Training is 38.291666666666664\n",
            "Epoch #0. Accuracy on batch 1275/2438  on Training is 38.30574059561128\n",
            "Epoch #0. Accuracy on batch 1276/2438  on Training is 38.32713390759593\n",
            "Epoch #0. Accuracy on batch 1277/2438  on Training is 38.3362676056338\n",
            "Epoch #0. Accuracy on batch 1278/2438  on Training is 38.34294370602033\n",
            "Epoch #0. Accuracy on batch 1279/2438  on Training is 38.3544921875\n",
            "Batch Id 1280/2438 is having training loss of 2.865013360977173\n",
            "2.46494722366333\n",
            "Epoch #0. Accuracy on batch 1280/2438  on Training is 38.35626463700234\n",
            "Epoch #0. Accuracy on batch 1281/2438  on Training is 38.362909516380654\n",
            "Epoch #0. Accuracy on batch 1282/2438  on Training is 38.3719797349961\n",
            "Epoch #0. Accuracy on batch 1283/2438  on Training is 38.376168224299064\n",
            "Epoch #0. Accuracy on batch 1284/2438  on Training is 38.39737354085603\n",
            "Epoch #0. Accuracy on batch 1285/2438  on Training is 38.41854587869362\n",
            "Epoch #0. Accuracy on batch 1286/2438  on Training is 38.42511655011655\n",
            "Epoch #0. Accuracy on batch 1287/2438  on Training is 38.43652950310559\n",
            "Epoch #0. Accuracy on batch 1288/2438  on Training is 38.440651667959656\n",
            "Epoch #0. Accuracy on batch 1289/2438  on Training is 38.43265503875969\n",
            "Epoch #0. Accuracy on batch 1290/2438  on Training is 38.44403563129357\n",
            "Epoch #0. Accuracy on batch 1291/2438  on Training is 38.460236068111456\n",
            "Epoch #0. Accuracy on batch 1292/2438  on Training is 38.4715777262181\n",
            "Epoch #0. Accuracy on batch 1293/2438  on Training is 38.47565687789799\n",
            "Epoch #0. Accuracy on batch 1294/2438  on Training is 38.477316602316606\n",
            "Epoch #0. Accuracy on batch 1295/2438  on Training is 38.48620756172839\n",
            "Epoch #0. Accuracy on batch 1296/2438  on Training is 38.50954124903624\n",
            "Epoch #0. Accuracy on batch 1297/2438  on Training is 38.50635593220339\n",
            "Epoch #0. Accuracy on batch 1298/2438  on Training is 38.52242109314857\n",
            "Epoch #0. Accuracy on batch 1299/2438  on Training is 38.53365384615385\n",
            "Batch Id 1300/2438 is having training loss of 2.852456569671631\n",
            "2.0592408180236816\n",
            "Epoch #0. Accuracy on batch 1300/2438  on Training is 38.54486933128363\n",
            "Epoch #0. Accuracy on batch 1301/2438  on Training is 38.55846774193548\n",
            "Epoch #0. Accuracy on batch 1302/2438  on Training is 38.56724865694551\n",
            "Epoch #0. Accuracy on batch 1303/2438  on Training is 38.580809049079754\n",
            "Epoch #0. Accuracy on batch 1304/2438  on Training is 38.587164750957854\n",
            "Epoch #0. Accuracy on batch 1305/2438  on Training is 38.593510719754974\n",
            "Epoch #0. Accuracy on batch 1306/2438  on Training is 38.59506503442999\n",
            "Epoch #0. Accuracy on batch 1307/2438  on Training is 38.608562691131496\n",
            "Epoch #0. Accuracy on batch 1308/2438  on Training is 38.62920168067227\n",
            "Epoch #0. Accuracy on batch 1309/2438  on Training is 38.63549618320611\n",
            "Epoch #0. Accuracy on batch 1310/2438  on Training is 38.63939740655988\n",
            "Epoch #0. Accuracy on batch 1311/2438  on Training is 38.645674542682926\n",
            "Epoch #0. Accuracy on batch 1312/2438  on Training is 38.649562071591774\n",
            "Epoch #0. Accuracy on batch 1313/2438  on Training is 38.65582191780822\n",
            "Epoch #0. Accuracy on batch 1314/2438  on Training is 38.67157794676806\n",
            "Epoch #0. Accuracy on batch 1315/2438  on Training is 38.682560790273556\n",
            "Epoch #0. Accuracy on batch 1316/2438  on Training is 38.70301822323462\n",
            "Epoch #0. Accuracy on batch 1317/2438  on Training is 38.70447647951442\n",
            "Epoch #0. Accuracy on batch 1318/2438  on Training is 38.71067096285064\n",
            "Epoch #0. Accuracy on batch 1319/2438  on Training is 38.723958333333336\n",
            "Batch Id 1320/2438 is having training loss of 2.8410091400146484\n",
            "1.5804779529571533\n",
            "Epoch #0. Accuracy on batch 1320/2438  on Training is 38.74195685087055\n",
            "Epoch #0. Accuracy on batch 1321/2438  on Training is 38.750472768532525\n",
            "Epoch #0. Accuracy on batch 1322/2438  on Training is 38.76842403628118\n",
            "Epoch #0. Accuracy on batch 1323/2438  on Training is 38.76746601208459\n",
            "Epoch #0. Accuracy on batch 1324/2438  on Training is 38.7688679245283\n",
            "Epoch #0. Accuracy on batch 1325/2438  on Training is 38.779694570135746\n",
            "Epoch #0. Accuracy on batch 1326/2438  on Training is 38.79285983421251\n",
            "Epoch #0. Accuracy on batch 1327/2438  on Training is 38.813064759036145\n",
            "Epoch #0. Accuracy on batch 1328/2438  on Training is 38.82148231753198\n",
            "Epoch #0. Accuracy on batch 1329/2438  on Training is 38.818139097744364\n",
            "Epoch #0. Accuracy on batch 1330/2438  on Training is 38.81714876033058\n",
            "Epoch #0. Accuracy on batch 1331/2438  on Training is 38.830236486486484\n",
            "Epoch #0. Accuracy on batch 1332/2438  on Training is 38.8503375843961\n",
            "Epoch #0. Accuracy on batch 1333/2438  on Training is 38.858695652173914\n",
            "Epoch #0. Accuracy on batch 1334/2438  on Training is 38.864700374531836\n",
            "Epoch #0. Accuracy on batch 1335/2438  on Training is 38.87069610778443\n",
            "Epoch #0. Accuracy on batch 1336/2438  on Training is 38.88603216155572\n",
            "Epoch #0. Accuracy on batch 1337/2438  on Training is 38.89200298953662\n",
            "Epoch #0. Accuracy on batch 1338/2438  on Training is 38.902632561613146\n",
            "Epoch #0. Accuracy on batch 1339/2438  on Training is 38.90391791044776\n",
            "Batch Id 1340/2438 is having training loss of 2.8305399417877197\n",
            "1.9939725399017334\n",
            "Epoch #0. Accuracy on batch 1340/2438  on Training is 38.92151379567487\n",
            "Epoch #0. Accuracy on batch 1341/2438  on Training is 38.929769001490314\n",
            "Epoch #0. Accuracy on batch 1342/2438  on Training is 38.933358153387935\n",
            "Epoch #0. Accuracy on batch 1343/2438  on Training is 38.93461681547619\n",
            "Epoch #0. Accuracy on batch 1344/2438  on Training is 38.942843866171\n",
            "Epoch #0. Accuracy on batch 1345/2438  on Training is 38.95338038632987\n",
            "Epoch #0. Accuracy on batch 1346/2438  on Training is 38.949981440237565\n",
            "Epoch #0. Accuracy on batch 1347/2438  on Training is 38.951224035608305\n",
            "Epoch #0. Accuracy on batch 1348/2438  on Training is 38.95709785025945\n",
            "Epoch #0. Accuracy on batch 1349/2438  on Training is 38.97222222222222\n",
            "Epoch #0. Accuracy on batch 1350/2438  on Training is 38.98269800148039\n",
            "Epoch #0. Accuracy on batch 1351/2438  on Training is 38.98853550295858\n",
            "Epoch #0. Accuracy on batch 1352/2438  on Training is 39.00360310421286\n",
            "Epoch #0. Accuracy on batch 1353/2438  on Training is 39.01634047267356\n",
            "Epoch #0. Accuracy on batch 1354/2438  on Training is 39.01983394833948\n",
            "Epoch #0. Accuracy on batch 1355/2438  on Training is 39.034845132743364\n",
            "Epoch #0. Accuracy on batch 1356/2438  on Training is 39.04062269712601\n",
            "Epoch #0. Accuracy on batch 1357/2438  on Training is 39.05559646539028\n",
            "Epoch #0. Accuracy on batch 1358/2438  on Training is 39.07054819720383\n",
            "Epoch #0. Accuracy on batch 1359/2438  on Training is 39.076286764705884\n",
            "Batch Id 1360/2438 is having training loss of 2.821256637573242\n",
            "2.3292946815490723\n",
            "Epoch #0. Accuracy on batch 1360/2438  on Training is 39.079720793534165\n",
            "Epoch #0. Accuracy on batch 1361/2438  on Training is 39.10150513950074\n",
            "Epoch #0. Accuracy on batch 1362/2438  on Training is 39.107208363903155\n",
            "Epoch #0. Accuracy on batch 1363/2438  on Training is 39.11290322580645\n",
            "Epoch #0. Accuracy on batch 1364/2438  on Training is 39.13461538461539\n",
            "Epoch #0. Accuracy on batch 1365/2438  on Training is 39.14485724743778\n",
            "Epoch #0. Accuracy on batch 1366/2438  on Training is 39.152798098024874\n",
            "Epoch #0. Accuracy on batch 1367/2438  on Training is 39.15844298245614\n",
            "Epoch #0. Accuracy on batch 1368/2438  on Training is 39.1663623082542\n",
            "Epoch #0. Accuracy on batch 1369/2438  on Training is 39.17198905109489\n",
            "Epoch #0. Accuracy on batch 1370/2438  on Training is 39.19356309263311\n",
            "Epoch #0. Accuracy on batch 1371/2438  on Training is 39.20143950437318\n",
            "Epoch #0. Accuracy on batch 1372/2438  on Training is 39.22296067006555\n",
            "Epoch #0. Accuracy on batch 1373/2438  on Training is 39.23990174672489\n",
            "Epoch #0. Accuracy on batch 1374/2438  on Training is 39.25\n",
            "Epoch #0. Accuracy on batch 1375/2438  on Training is 39.2600835755814\n",
            "Epoch #0. Accuracy on batch 1376/2438  on Training is 39.270152505446625\n",
            "Epoch #0. Accuracy on batch 1377/2438  on Training is 39.28247460087083\n",
            "Epoch #0. Accuracy on batch 1378/2438  on Training is 39.29251269035533\n",
            "Epoch #0. Accuracy on batch 1379/2438  on Training is 39.302536231884055\n",
            "Batch Id 1380/2438 is having training loss of 2.809373378753662\n",
            "1.5094932317733765\n",
            "Epoch #0. Accuracy on batch 1380/2438  on Training is 39.32612237509051\n",
            "Epoch #0. Accuracy on batch 1381/2438  on Training is 39.33384587554269\n",
            "Epoch #0. Accuracy on batch 1382/2438  on Training is 39.34381778741866\n",
            "Epoch #0. Accuracy on batch 1383/2438  on Training is 39.34925939306358\n",
            "Epoch #0. Accuracy on batch 1384/2438  on Training is 39.356949458483754\n",
            "Epoch #0. Accuracy on batch 1385/2438  on Training is 39.36011904761905\n",
            "Epoch #0. Accuracy on batch 1386/2438  on Training is 39.36553713049748\n",
            "Epoch #0. Accuracy on batch 1387/2438  on Training is 39.37094740634006\n",
            "Epoch #0. Accuracy on batch 1388/2438  on Training is 39.383099352051836\n",
            "Epoch #0. Accuracy on batch 1389/2438  on Training is 39.39073741007194\n",
            "Epoch #0. Accuracy on batch 1390/2438  on Training is 39.393871315600286\n",
            "Epoch #0. Accuracy on batch 1391/2438  on Training is 39.408225574712645\n",
            "Epoch #0. Accuracy on batch 1392/2438  on Training is 39.4225592246949\n",
            "Epoch #0. Accuracy on batch 1393/2438  on Training is 39.42790530846485\n",
            "Epoch #0. Accuracy on batch 1394/2438  on Training is 39.431003584229394\n",
            "Epoch #0. Accuracy on batch 1395/2438  on Training is 39.43185888252149\n",
            "Epoch #0. Accuracy on batch 1396/2438  on Training is 39.44613457408733\n",
            "Epoch #0. Accuracy on batch 1397/2438  on Training is 39.45368383404864\n",
            "Epoch #0. Accuracy on batch 1398/2438  on Training is 39.458988563259474\n",
            "Epoch #0. Accuracy on batch 1399/2438  on Training is 39.470982142857146\n",
            "Batch Id 1400/2438 is having training loss of 2.798849582672119\n",
            "1.8491567373275757\n",
            "Epoch #0. Accuracy on batch 1400/2438  on Training is 39.48965024982156\n",
            "Epoch #0. Accuracy on batch 1401/2438  on Training is 39.50160485021398\n",
            "Epoch #0. Accuracy on batch 1402/2438  on Training is 39.5179971489665\n",
            "Epoch #0. Accuracy on batch 1403/2438  on Training is 39.521011396011396\n",
            "Epoch #0. Accuracy on batch 1404/2438  on Training is 39.53291814946619\n",
            "Epoch #0. Accuracy on batch 1405/2438  on Training is 39.5425853485064\n",
            "Epoch #0. Accuracy on batch 1406/2438  on Training is 39.563343994314145\n",
            "Epoch #0. Accuracy on batch 1407/2438  on Training is 39.56631747159091\n",
            "Epoch #0. Accuracy on batch 1408/2438  on Training is 39.580376153300215\n",
            "Epoch #0. Accuracy on batch 1409/2438  on Training is 39.583333333333336\n",
            "Epoch #0. Accuracy on batch 1410/2438  on Training is 39.6150779588944\n",
            "Epoch #0. Accuracy on batch 1411/2438  on Training is 39.62021954674221\n",
            "Epoch #0. Accuracy on batch 1412/2438  on Training is 39.64525831564048\n",
            "Epoch #0. Accuracy on batch 1413/2438  on Training is 39.65700141442716\n",
            "Epoch #0. Accuracy on batch 1414/2438  on Training is 39.6643109540636\n",
            "Epoch #0. Accuracy on batch 1415/2438  on Training is 39.67823093220339\n",
            "Epoch #0. Accuracy on batch 1416/2438  on Training is 39.683309809456595\n",
            "Epoch #0. Accuracy on batch 1417/2438  on Training is 39.69499294781382\n",
            "Epoch #0. Accuracy on batch 1418/2438  on Training is 39.71767089499647\n",
            "Epoch #0. Accuracy on batch 1419/2438  on Training is 39.727112676056336\n",
            "Batch Id 1420/2438 is having training loss of 2.786977767944336\n",
            "2.2147176265716553\n",
            "Epoch #0. Accuracy on batch 1420/2438  on Training is 39.736541168191415\n",
            "Epoch #0. Accuracy on batch 1421/2438  on Training is 39.74815400843882\n",
            "Epoch #0. Accuracy on batch 1422/2438  on Training is 39.75535839775123\n",
            "Epoch #0. Accuracy on batch 1423/2438  on Training is 39.76474719101124\n",
            "Epoch #0. Accuracy on batch 1424/2438  on Training is 39.776315789473685\n",
            "Epoch #0. Accuracy on batch 1425/2438  on Training is 39.781293828892004\n",
            "Epoch #0. Accuracy on batch 1426/2438  on Training is 39.788454800280306\n",
            "Epoch #0. Accuracy on batch 1427/2438  on Training is 39.804359243697476\n",
            "Epoch #0. Accuracy on batch 1428/2438  on Training is 39.80712036389083\n",
            "Epoch #0. Accuracy on batch 1429/2438  on Training is 39.80332167832168\n",
            "Epoch #0. Accuracy on batch 1430/2438  on Training is 39.812631027253666\n",
            "Epoch #0. Accuracy on batch 1431/2438  on Training is 39.81538058659218\n",
            "Epoch #0. Accuracy on batch 1432/2438  on Training is 39.837752965806004\n",
            "Epoch #0. Accuracy on batch 1433/2438  on Training is 39.84266039051604\n",
            "Epoch #0. Accuracy on batch 1434/2438  on Training is 39.849738675958186\n",
            "Epoch #0. Accuracy on batch 1435/2438  on Training is 39.8633356545961\n",
            "Epoch #0. Accuracy on batch 1436/2438  on Training is 39.870389700765486\n",
            "Epoch #0. Accuracy on batch 1437/2438  on Training is 39.87526077885953\n",
            "Epoch #0. Accuracy on batch 1438/2438  on Training is 39.89315496872828\n",
            "Epoch #0. Accuracy on batch 1439/2438  on Training is 39.904513888888886\n",
            "Batch Id 1440/2438 is having training loss of 2.776674747467041\n",
            "2.033963441848755\n",
            "Epoch #0. Accuracy on batch 1440/2438  on Training is 39.91368841082581\n",
            "Epoch #0. Accuracy on batch 1441/2438  on Training is 39.9250173370319\n",
            "Epoch #0. Accuracy on batch 1442/2438  on Training is 39.92983367983368\n",
            "Epoch #0. Accuracy on batch 1443/2438  on Training is 39.9389716066482\n",
            "Epoch #0. Accuracy on batch 1444/2438  on Training is 39.95242214532872\n",
            "Epoch #0. Accuracy on batch 1445/2438  on Training is 39.95504840940526\n",
            "Epoch #0. Accuracy on batch 1446/2438  on Training is 39.966309606081545\n",
            "Epoch #0. Accuracy on batch 1447/2438  on Training is 39.98187154696133\n",
            "Epoch #0. Accuracy on batch 1448/2438  on Training is 39.99094202898551\n",
            "Epoch #0. Accuracy on batch 1449/2438  on Training is 39.997844827586206\n",
            "Epoch #0. Accuracy on batch 1450/2438  on Training is 40.009045485871816\n",
            "Epoch #0. Accuracy on batch 1451/2438  on Training is 40.01807851239669\n",
            "Epoch #0. Accuracy on batch 1452/2438  on Training is 40.024948382656575\n",
            "Epoch #0. Accuracy on batch 1453/2438  on Training is 40.03180880330124\n",
            "Epoch #0. Accuracy on batch 1454/2438  on Training is 40.034364261168385\n",
            "Epoch #0. Accuracy on batch 1455/2438  on Training is 40.04550137362637\n",
            "Epoch #0. Accuracy on batch 1456/2438  on Training is 40.05662319835278\n",
            "Epoch #0. Accuracy on batch 1457/2438  on Training is 40.0698731138546\n",
            "Epoch #0. Accuracy on batch 1458/2438  on Training is 40.08738862234407\n",
            "Epoch #0. Accuracy on batch 1459/2438  on Training is 40.09631849315068\n",
            "Batch Id 1460/2438 is having training loss of 2.76615047454834\n",
            "1.9577637910842896\n",
            "Epoch #0. Accuracy on batch 1460/2438  on Training is 40.10951403148528\n",
            "Epoch #0. Accuracy on batch 1461/2438  on Training is 40.112004103967166\n",
            "Epoch #0. Accuracy on batch 1462/2438  on Training is 40.12303485987697\n",
            "Epoch #0. Accuracy on batch 1463/2438  on Training is 40.12978142076503\n",
            "Epoch #0. Accuracy on batch 1464/2438  on Training is 40.14505119453925\n",
            "Epoch #0. Accuracy on batch 1465/2438  on Training is 40.158168485675304\n",
            "Epoch #0. Accuracy on batch 1466/2438  on Training is 40.171267893660534\n",
            "Epoch #0. Accuracy on batch 1467/2438  on Training is 40.17370572207084\n",
            "Epoch #0. Accuracy on batch 1468/2438  on Training is 40.178267528931244\n",
            "Epoch #0. Accuracy on batch 1469/2438  on Training is 40.191326530612244\n",
            "Epoch #0. Accuracy on batch 1470/2438  on Training is 40.197994561522776\n",
            "Epoch #0. Accuracy on batch 1471/2438  on Training is 40.21102241847826\n",
            "Epoch #0. Accuracy on batch 1472/2438  on Training is 40.211303462321794\n",
            "Epoch #0. Accuracy on batch 1473/2438  on Training is 40.21794436906377\n",
            "Epoch #0. Accuracy on batch 1474/2438  on Training is 40.230932203389834\n",
            "Epoch #0. Accuracy on batch 1475/2438  on Training is 40.23755081300813\n",
            "Epoch #0. Accuracy on batch 1476/2438  on Training is 40.244160460392685\n",
            "Epoch #0. Accuracy on batch 1477/2438  on Training is 40.25498985115021\n",
            "Epoch #0. Accuracy on batch 1478/2438  on Training is 40.2552400270453\n",
            "Epoch #0. Accuracy on batch 1479/2438  on Training is 40.270270270270274\n",
            "Batch Id 1480/2438 is having training loss of 2.755462408065796\n",
            "2.054461717605591\n",
            "Epoch #0. Accuracy on batch 1480/2438  on Training is 40.27895003376097\n",
            "Epoch #0. Accuracy on batch 1481/2438  on Training is 40.29394399460189\n",
            "Epoch #0. Accuracy on batch 1482/2438  on Training is 40.30470330411328\n",
            "Epoch #0. Accuracy on batch 1483/2438  on Training is 40.30491913746631\n",
            "Epoch #0. Accuracy on batch 1484/2438  on Training is 40.31144781144781\n",
            "Epoch #0. Accuracy on batch 1485/2438  on Training is 40.31586473755047\n",
            "Epoch #0. Accuracy on batch 1486/2438  on Training is 40.32027572293208\n",
            "Epoch #0. Accuracy on batch 1487/2438  on Training is 40.324680779569896\n",
            "Epoch #0. Accuracy on batch 1488/2438  on Training is 40.32068502350571\n",
            "Epoch #0. Accuracy on batch 1489/2438  on Training is 40.31879194630873\n",
            "Epoch #0. Accuracy on batch 1490/2438  on Training is 40.32738095238095\n",
            "Epoch #0. Accuracy on batch 1491/2438  on Training is 40.33595844504021\n",
            "Epoch #0. Accuracy on batch 1492/2438  on Training is 40.34243134628265\n",
            "Epoch #0. Accuracy on batch 1493/2438  on Training is 40.353078982597054\n",
            "Epoch #0. Accuracy on batch 1494/2438  on Training is 40.35535117056856\n",
            "Epoch #0. Accuracy on batch 1495/2438  on Training is 40.35970922459893\n",
            "Epoch #0. Accuracy on batch 1496/2438  on Training is 40.36406145624583\n",
            "Epoch #0. Accuracy on batch 1497/2438  on Training is 40.374666221628836\n",
            "Epoch #0. Accuracy on batch 1498/2438  on Training is 40.37900266844563\n",
            "Epoch #0. Accuracy on batch 1499/2438  on Training is 40.38333333333333\n",
            "Batch Id 1500/2438 is having training loss of 2.747056722640991\n",
            "2.1767184734344482\n",
            "Epoch #0. Accuracy on batch 1500/2438  on Training is 40.38557628247835\n",
            "Epoch #0. Accuracy on batch 1501/2438  on Training is 40.39405792276964\n",
            "Epoch #0. Accuracy on batch 1502/2438  on Training is 40.41084497671324\n",
            "Epoch #0. Accuracy on batch 1503/2438  on Training is 40.421376329787236\n",
            "Epoch #0. Accuracy on batch 1504/2438  on Training is 40.43812292358804\n",
            "Epoch #0. Accuracy on batch 1505/2438  on Training is 40.448622177954846\n",
            "Epoch #0. Accuracy on batch 1506/2438  on Training is 40.44873921698739\n",
            "Epoch #0. Accuracy on batch 1507/2438  on Training is 40.46128978779841\n",
            "Epoch #0. Accuracy on batch 1508/2438  on Training is 40.46139827700464\n",
            "Epoch #0. Accuracy on batch 1509/2438  on Training is 40.46978476821192\n",
            "Epoch #0. Accuracy on batch 1510/2438  on Training is 40.48436465916612\n",
            "Epoch #0. Accuracy on batch 1511/2438  on Training is 40.48859126984127\n",
            "Epoch #0. Accuracy on batch 1512/2438  on Training is 40.505204890945144\n",
            "Epoch #0. Accuracy on batch 1513/2438  on Training is 40.513540290620874\n",
            "Epoch #0. Accuracy on batch 1514/2438  on Training is 40.523927392739274\n",
            "Epoch #0. Accuracy on batch 1515/2438  on Training is 40.53223944591029\n",
            "Epoch #0. Accuracy on batch 1516/2438  on Training is 40.538480553724455\n",
            "Epoch #0. Accuracy on batch 1517/2438  on Training is 40.54471343873518\n",
            "Epoch #0. Accuracy on batch 1518/2438  on Training is 40.559167215273206\n",
            "Epoch #0. Accuracy on batch 1519/2438  on Training is 40.55921052631579\n",
            "Batch Id 1520/2438 is having training loss of 2.736989736557007\n",
            "1.8562896251678467\n",
            "Epoch #0. Accuracy on batch 1520/2438  on Training is 40.569526627218934\n",
            "Epoch #0. Accuracy on batch 1521/2438  on Training is 40.57777595269383\n",
            "Epoch #0. Accuracy on batch 1522/2438  on Training is 40.58396257386737\n",
            "Epoch #0. Accuracy on batch 1523/2438  on Training is 40.588090551181104\n",
            "Epoch #0. Accuracy on batch 1524/2438  on Training is 40.60245901639344\n",
            "Epoch #0. Accuracy on batch 1525/2438  on Training is 40.60452162516383\n",
            "Epoch #0. Accuracy on batch 1526/2438  on Training is 40.610674525212836\n",
            "Epoch #0. Accuracy on batch 1527/2438  on Training is 40.62090968586387\n",
            "Epoch #0. Accuracy on batch 1528/2438  on Training is 40.635219097449315\n",
            "Epoch #0. Accuracy on batch 1529/2438  on Training is 40.63725490196079\n",
            "Epoch #0. Accuracy on batch 1530/2438  on Training is 40.64337034617897\n",
            "Epoch #0. Accuracy on batch 1531/2438  on Training is 40.65151762402089\n",
            "Epoch #0. Accuracy on batch 1532/2438  on Training is 40.657615786040445\n",
            "Epoch #0. Accuracy on batch 1533/2438  on Training is 40.66778031290743\n",
            "Epoch #0. Accuracy on batch 1534/2438  on Training is 40.67589576547231\n",
            "Epoch #0. Accuracy on batch 1535/2438  on Training is 40.68603515625\n",
            "Epoch #0. Accuracy on batch 1536/2438  on Training is 40.692094990240726\n",
            "Epoch #0. Accuracy on batch 1537/2438  on Training is 40.69408322496749\n",
            "Epoch #0. Accuracy on batch 1538/2438  on Training is 40.708252111760885\n",
            "Epoch #0. Accuracy on batch 1539/2438  on Training is 40.71834415584416\n",
            "Batch Id 1540/2438 is having training loss of 2.727135419845581\n",
            "1.677791953086853\n",
            "Epoch #0. Accuracy on batch 1540/2438  on Training is 40.73856262167424\n",
            "Epoch #0. Accuracy on batch 1541/2438  on Training is 40.73848897535668\n",
            "Epoch #0. Accuracy on batch 1542/2438  on Training is 40.75056707712249\n",
            "Epoch #0. Accuracy on batch 1543/2438  on Training is 40.756557642487046\n",
            "Epoch #0. Accuracy on batch 1544/2438  on Training is 40.756472491909385\n",
            "Epoch #0. Accuracy on batch 1545/2438  on Training is 40.77457956015524\n",
            "Epoch #0. Accuracy on batch 1546/2438  on Training is 40.78660310277957\n",
            "Epoch #0. Accuracy on batch 1547/2438  on Training is 40.80062984496124\n",
            "Epoch #0. Accuracy on batch 1548/2438  on Training is 40.818673337637186\n",
            "Epoch #0. Accuracy on batch 1549/2438  on Training is 40.832661290322584\n",
            "Epoch #0. Accuracy on batch 1550/2438  on Training is 40.85066086395874\n",
            "Epoch #0. Accuracy on batch 1551/2438  on Training is 40.86259664948454\n",
            "Epoch #0. Accuracy on batch 1552/2438  on Training is 40.872504829362526\n",
            "Epoch #0. Accuracy on batch 1553/2438  on Training is 40.87636743886744\n",
            "Epoch #0. Accuracy on batch 1554/2438  on Training is 40.890273311897104\n",
            "Epoch #0. Accuracy on batch 1555/2438  on Training is 40.898136246786635\n",
            "Epoch #0. Accuracy on batch 1556/2438  on Training is 40.89996788696211\n",
            "Epoch #0. Accuracy on batch 1557/2438  on Training is 40.91383183568678\n",
            "Epoch #0. Accuracy on batch 1558/2438  on Training is 40.91565105837075\n",
            "Epoch #0. Accuracy on batch 1559/2438  on Training is 40.92748397435897\n",
            "Batch Id 1560/2438 is having training loss of 2.7172160148620605\n",
            "1.7921185493469238\n",
            "Epoch #0. Accuracy on batch 1560/2438  on Training is 40.935297885970535\n",
            "Epoch #0. Accuracy on batch 1561/2438  on Training is 40.93910051216389\n",
            "Epoch #0. Accuracy on batch 1562/2438  on Training is 40.94289827255278\n",
            "Epoch #0. Accuracy on batch 1563/2438  on Training is 40.94669117647059\n",
            "Epoch #0. Accuracy on batch 1564/2438  on Training is 40.9564696485623\n",
            "Epoch #0. Accuracy on batch 1565/2438  on Training is 40.96024904214559\n",
            "Epoch #0. Accuracy on batch 1566/2438  on Training is 40.96801212507977\n",
            "Epoch #0. Accuracy on batch 1567/2438  on Training is 40.98373724489796\n",
            "Epoch #0. Accuracy on batch 1568/2438  on Training is 40.99147546207776\n",
            "Epoch #0. Accuracy on batch 1569/2438  on Training is 41.003184713375795\n",
            "Epoch #0. Accuracy on batch 1570/2438  on Training is 41.00692234245703\n",
            "Epoch #0. Accuracy on batch 1571/2438  on Training is 41.01860687022901\n",
            "Epoch #0. Accuracy on batch 1572/2438  on Training is 41.02034329307057\n",
            "Epoch #0. Accuracy on batch 1573/2438  on Training is 41.033989834815756\n",
            "Epoch #0. Accuracy on batch 1574/2438  on Training is 41.04761904761905\n",
            "Epoch #0. Accuracy on batch 1575/2438  on Training is 41.05329949238579\n",
            "Epoch #0. Accuracy on batch 1576/2438  on Training is 41.060954343690554\n",
            "Epoch #0. Accuracy on batch 1577/2438  on Training is 41.06265842839037\n",
            "Epoch #0. Accuracy on batch 1578/2438  on Training is 41.07425585813806\n",
            "Epoch #0. Accuracy on batch 1579/2438  on Training is 41.081882911392405\n",
            "Batch Id 1580/2438 is having training loss of 2.707714319229126\n",
            "1.7801380157470703\n",
            "Epoch #0. Accuracy on batch 1580/2438  on Training is 41.08950031625553\n",
            "Epoch #0. Accuracy on batch 1581/2438  on Training is 41.099083438685206\n",
            "Epoch #0. Accuracy on batch 1582/2438  on Training is 41.1047062539482\n",
            "Epoch #0. Accuracy on batch 1583/2438  on Training is 41.114267676767675\n",
            "Epoch #0. Accuracy on batch 1584/2438  on Training is 41.121845425867505\n",
            "Epoch #0. Accuracy on batch 1585/2438  on Training is 41.129413619167714\n",
            "Epoch #0. Accuracy on batch 1586/2438  on Training is 41.135003150598614\n",
            "Epoch #0. Accuracy on batch 1587/2438  on Training is 41.136649874055415\n",
            "Epoch #0. Accuracy on batch 1588/2438  on Training is 41.14222781623663\n",
            "Epoch #0. Accuracy on batch 1589/2438  on Training is 41.14779874213836\n",
            "Epoch #0. Accuracy on batch 1590/2438  on Training is 41.15729101194218\n",
            "Epoch #0. Accuracy on batch 1591/2438  on Training is 41.16284547738694\n",
            "Epoch #0. Accuracy on batch 1592/2438  on Training is 41.16446955430006\n",
            "Epoch #0. Accuracy on batch 1593/2438  on Training is 41.1719730238394\n",
            "Epoch #0. Accuracy on batch 1594/2438  on Training is 41.1814263322884\n",
            "Epoch #0. Accuracy on batch 1595/2438  on Training is 41.186951754385966\n",
            "Epoch #0. Accuracy on batch 1596/2438  on Training is 41.19051346274264\n",
            "Epoch #0. Accuracy on batch 1597/2438  on Training is 41.196026282853566\n",
            "Epoch #0. Accuracy on batch 1598/2438  on Training is 41.20348655409631\n",
            "Epoch #0. Accuracy on batch 1599/2438  on Training is 41.205078125\n",
            "Batch Id 1600/2438 is having training loss of 2.698647975921631\n",
            "2.1575253009796143\n",
            "Epoch #0. Accuracy on batch 1600/2438  on Training is 41.21252342286071\n",
            "Epoch #0. Accuracy on batch 1601/2438  on Training is 41.214107365792756\n",
            "Epoch #0. Accuracy on batch 1602/2438  on Training is 41.22348721147848\n",
            "Epoch #0. Accuracy on batch 1603/2438  on Training is 41.22506234413965\n",
            "Epoch #0. Accuracy on batch 1604/2438  on Training is 41.24026479750779\n",
            "Epoch #0. Accuracy on batch 1605/2438  on Training is 41.24961083437111\n",
            "Epoch #0. Accuracy on batch 1606/2438  on Training is 41.253111387678906\n",
            "Epoch #0. Accuracy on batch 1607/2438  on Training is 41.252720771144276\n",
            "Epoch #0. Accuracy on batch 1608/2438  on Training is 41.26981044126787\n",
            "Epoch #0. Accuracy on batch 1609/2438  on Training is 41.28105590062112\n",
            "Epoch #0. Accuracy on batch 1610/2438  on Training is 41.28840782122905\n",
            "Epoch #0. Accuracy on batch 1611/2438  on Training is 41.28993486352357\n",
            "Epoch #0. Accuracy on batch 1612/2438  on Training is 41.28952262864228\n",
            "Epoch #0. Accuracy on batch 1613/2438  on Training is 41.294919454770756\n",
            "Epoch #0. Accuracy on batch 1614/2438  on Training is 41.30611455108359\n",
            "Epoch #0. Accuracy on batch 1615/2438  on Training is 41.31342821782178\n",
            "Epoch #0. Accuracy on batch 1616/2438  on Training is 41.31686765615337\n",
            "Epoch #0. Accuracy on batch 1617/2438  on Training is 41.32802843016069\n",
            "Epoch #0. Accuracy on batch 1618/2438  on Training is 41.33338480543545\n",
            "Epoch #0. Accuracy on batch 1619/2438  on Training is 41.338734567901234\n",
            "Batch Id 1620/2438 is having training loss of 2.690577983856201\n",
            "2.2164063453674316\n",
            "Epoch #0. Accuracy on batch 1620/2438  on Training is 41.33829426280074\n",
            "Epoch #0. Accuracy on batch 1621/2438  on Training is 41.35134093711467\n",
            "Epoch #0. Accuracy on batch 1622/2438  on Training is 41.35281885397412\n",
            "Epoch #0. Accuracy on batch 1623/2438  on Training is 41.36006773399015\n",
            "Epoch #0. Accuracy on batch 1624/2438  on Training is 41.363461538461536\n",
            "Epoch #0. Accuracy on batch 1625/2438  on Training is 41.37261685116851\n",
            "Epoch #0. Accuracy on batch 1626/2438  on Training is 41.38368162261832\n",
            "Epoch #0. Accuracy on batch 1627/2438  on Training is 41.3947328009828\n",
            "Epoch #0. Accuracy on batch 1628/2438  on Training is 41.40385205647637\n",
            "Epoch #0. Accuracy on batch 1629/2438  on Training is 41.405291411042946\n",
            "Epoch #0. Accuracy on batch 1630/2438  on Training is 41.4201410177805\n",
            "Epoch #0. Accuracy on batch 1631/2438  on Training is 41.42922794117647\n",
            "Epoch #0. Accuracy on batch 1632/2438  on Training is 41.43256276791182\n",
            "Epoch #0. Accuracy on batch 1633/2438  on Training is 41.43971848225214\n",
            "Epoch #0. Accuracy on batch 1634/2438  on Training is 41.452599388379205\n",
            "Epoch #0. Accuracy on batch 1635/2438  on Training is 41.459734107579465\n",
            "Epoch #0. Accuracy on batch 1636/2438  on Training is 41.463042150274894\n",
            "Epoch #0. Accuracy on batch 1637/2438  on Training is 41.46253052503052\n",
            "Epoch #0. Accuracy on batch 1638/2438  on Training is 41.465832824893226\n",
            "Epoch #0. Accuracy on batch 1639/2438  on Training is 41.47484756097561\n",
            "Batch Id 1640/2438 is having training loss of 2.681377410888672\n",
            "1.709276556968689\n",
            "Epoch #0. Accuracy on batch 1640/2438  on Training is 41.48575563680682\n",
            "Epoch #0. Accuracy on batch 1641/2438  on Training is 41.49855359317905\n",
            "Epoch #0. Accuracy on batch 1642/2438  on Training is 41.51323797930615\n",
            "Epoch #0. Accuracy on batch 1643/2438  on Training is 41.52980535279806\n",
            "Epoch #0. Accuracy on batch 1644/2438  on Training is 41.54065349544073\n",
            "Epoch #0. Accuracy on batch 1645/2438  on Training is 41.55148845686513\n",
            "Epoch #0. Accuracy on batch 1646/2438  on Training is 41.56231026108075\n",
            "Epoch #0. Accuracy on batch 1647/2438  on Training is 41.5674302184466\n",
            "Epoch #0. Accuracy on batch 1648/2438  on Training is 41.5649636143117\n",
            "Epoch #0. Accuracy on batch 1649/2438  on Training is 41.56818181818182\n",
            "Epoch #0. Accuracy on batch 1650/2438  on Training is 41.57707450030285\n",
            "Epoch #0. Accuracy on batch 1651/2438  on Training is 41.58406476997579\n",
            "Epoch #0. Accuracy on batch 1652/2438  on Training is 41.58726557773745\n",
            "Epoch #0. Accuracy on batch 1653/2438  on Training is 41.59990931076179\n",
            "Epoch #0. Accuracy on batch 1654/2438  on Training is 41.59932024169184\n",
            "Epoch #0. Accuracy on batch 1655/2438  on Training is 41.596844806763286\n",
            "Epoch #0. Accuracy on batch 1656/2438  on Training is 41.59625829812915\n",
            "Epoch #0. Accuracy on batch 1657/2438  on Training is 41.601326899879375\n",
            "Epoch #0. Accuracy on batch 1658/2438  on Training is 41.604505726341166\n",
            "Epoch #0. Accuracy on batch 1659/2438  on Training is 41.61144578313253\n",
            "Batch Id 1660/2438 is having training loss of 2.673293113708496\n",
            "1.8187544345855713\n",
            "Epoch #0. Accuracy on batch 1660/2438  on Training is 41.62402167369055\n",
            "Epoch #0. Accuracy on batch 1661/2438  on Training is 41.63094163658243\n",
            "Epoch #0. Accuracy on batch 1662/2438  on Training is 41.637853277209864\n",
            "Epoch #0. Accuracy on batch 1663/2438  on Training is 41.63724459134615\n",
            "Epoch #0. Accuracy on batch 1664/2438  on Training is 41.64602102102102\n",
            "Epoch #0. Accuracy on batch 1665/2438  on Training is 41.652911164465785\n",
            "Epoch #0. Accuracy on batch 1666/2438  on Training is 41.66354229154169\n",
            "Epoch #0. Accuracy on batch 1667/2438  on Training is 41.67978117505995\n",
            "Epoch #0. Accuracy on batch 1668/2438  on Training is 41.69038346315159\n",
            "Epoch #0. Accuracy on batch 1669/2438  on Training is 41.699101796407184\n",
            "Epoch #0. Accuracy on batch 1670/2438  on Training is 41.69845900658289\n",
            "Epoch #0. Accuracy on batch 1671/2438  on Training is 41.71463815789474\n",
            "Epoch #0. Accuracy on batch 1672/2438  on Training is 41.72332635983263\n",
            "Epoch #0. Accuracy on batch 1673/2438  on Training is 41.72453703703704\n",
            "Epoch #0. Accuracy on batch 1674/2438  on Training is 41.72761194029851\n",
            "Epoch #0. Accuracy on batch 1675/2438  on Training is 41.72695405727924\n",
            "Epoch #0. Accuracy on batch 1676/2438  on Training is 41.73934108527132\n",
            "Epoch #0. Accuracy on batch 1677/2438  on Training is 41.75357568533969\n",
            "Epoch #0. Accuracy on batch 1678/2438  on Training is 41.75476474091721\n",
            "Epoch #0. Accuracy on batch 1679/2438  on Training is 41.767113095238095\n",
            "Batch Id 1680/2438 is having training loss of 2.664306640625\n",
            "2.014725923538208\n",
            "Epoch #0. Accuracy on batch 1680/2438  on Training is 41.77386972040452\n",
            "Epoch #0. Accuracy on batch 1681/2438  on Training is 41.78433412604043\n",
            "Epoch #0. Accuracy on batch 1682/2438  on Training is 41.785502079619725\n",
            "Epoch #0. Accuracy on batch 1683/2438  on Training is 41.79409144893112\n",
            "Epoch #0. Accuracy on batch 1684/2438  on Training is 41.800816023738875\n",
            "Epoch #0. Accuracy on batch 1685/2438  on Training is 41.80938612099644\n",
            "Epoch #0. Accuracy on batch 1686/2438  on Training is 41.81238885595732\n",
            "Epoch #0. Accuracy on batch 1687/2438  on Training is 41.811685426540286\n",
            "Epoch #0. Accuracy on batch 1688/2438  on Training is 41.81468324452339\n",
            "Epoch #0. Accuracy on batch 1689/2438  on Training is 41.82877218934911\n",
            "Epoch #0. Accuracy on batch 1690/2438  on Training is 41.837300413956235\n",
            "Epoch #0. Accuracy on batch 1691/2438  on Training is 41.856900118203306\n",
            "Epoch #0. Accuracy on batch 1692/2438  on Training is 41.85617247489663\n",
            "Epoch #0. Accuracy on batch 1693/2438  on Training is 41.862824675324674\n",
            "Epoch #0. Accuracy on batch 1694/2438  on Training is 41.86946902654867\n",
            "Epoch #0. Accuracy on batch 1695/2438  on Training is 41.87979068396226\n",
            "Epoch #0. Accuracy on batch 1696/2438  on Training is 41.88457572186211\n",
            "Epoch #0. Accuracy on batch 1697/2438  on Training is 41.89671672555948\n",
            "Epoch #0. Accuracy on batch 1698/2438  on Training is 41.90332548557975\n",
            "Epoch #0. Accuracy on batch 1699/2438  on Training is 41.91544117647059\n",
            "Batch Id 1700/2438 is having training loss of 2.656203269958496\n",
            "1.9613672494888306\n",
            "Epoch #0. Accuracy on batch 1700/2438  on Training is 41.9183568489124\n",
            "Epoch #0. Accuracy on batch 1701/2438  on Training is 41.92677732079906\n",
            "Epoch #0. Accuracy on batch 1702/2438  on Training is 41.93518790369935\n",
            "Epoch #0. Accuracy on batch 1703/2438  on Training is 41.938086854460096\n",
            "Epoch #0. Accuracy on batch 1704/2438  on Training is 41.950146627565985\n",
            "Epoch #0. Accuracy on batch 1705/2438  on Training is 41.94753810082063\n",
            "Epoch #0. Accuracy on batch 1706/2438  on Training is 41.96140890451084\n",
            "Epoch #0. Accuracy on batch 1707/2438  on Training is 41.96977459016394\n",
            "Epoch #0. Accuracy on batch 1708/2438  on Training is 41.97264482153306\n",
            "Epoch #0. Accuracy on batch 1709/2438  on Training is 41.9828216374269\n",
            "Epoch #0. Accuracy on batch 1710/2438  on Training is 41.991160140268846\n",
            "Epoch #0. Accuracy on batch 1711/2438  on Training is 41.9921875\n",
            "Epoch #0. Accuracy on batch 1712/2438  on Training is 41.99503794512551\n",
            "Epoch #0. Accuracy on batch 1713/2438  on Training is 41.99970828471412\n",
            "Epoch #0. Accuracy on batch 1714/2438  on Training is 42.00255102040816\n",
            "Epoch #0. Accuracy on batch 1715/2438  on Training is 42.01813811188811\n",
            "Epoch #0. Accuracy on batch 1716/2438  on Training is 42.031887012230634\n",
            "Epoch #0. Accuracy on batch 1717/2438  on Training is 42.04380093131548\n",
            "Epoch #0. Accuracy on batch 1718/2438  on Training is 42.05388307155323\n",
            "Epoch #0. Accuracy on batch 1719/2438  on Training is 42.069404069767444\n",
            "Batch Id 1720/2438 is having training loss of 2.6468474864959717\n",
            "1.9971909523010254\n",
            "Epoch #0. Accuracy on batch 1720/2438  on Training is 42.07764381173736\n",
            "Epoch #0. Accuracy on batch 1721/2438  on Training is 42.08950348432056\n",
            "Epoch #0. Accuracy on batch 1722/2438  on Training is 42.09953569355775\n",
            "Epoch #0. Accuracy on batch 1723/2438  on Training is 42.11680684454756\n",
            "Epoch #0. Accuracy on batch 1724/2438  on Training is 42.1213768115942\n",
            "Epoch #0. Accuracy on batch 1725/2438  on Training is 42.12956257242178\n",
            "Epoch #0. Accuracy on batch 1726/2438  on Training is 42.139548349739435\n",
            "Epoch #0. Accuracy on batch 1727/2438  on Training is 42.136863425925924\n",
            "Epoch #0. Accuracy on batch 1728/2438  on Training is 42.14321862348178\n",
            "Epoch #0. Accuracy on batch 1729/2438  on Training is 42.154985549132945\n",
            "Epoch #0. Accuracy on batch 1730/2438  on Training is 42.15049104563836\n",
            "Epoch #0. Accuracy on batch 1731/2438  on Training is 42.15863163972286\n",
            "Epoch #0. Accuracy on batch 1732/2438  on Training is 42.16495960761685\n",
            "Epoch #0. Accuracy on batch 1733/2438  on Training is 42.167675893886965\n",
            "Epoch #0. Accuracy on batch 1734/2438  on Training is 42.18299711815562\n",
            "Epoch #0. Accuracy on batch 1735/2438  on Training is 42.19830069124424\n",
            "Epoch #0. Accuracy on batch 1736/2438  on Training is 42.21178756476684\n",
            "Epoch #0. Accuracy on batch 1737/2438  on Training is 42.21267261219793\n",
            "Epoch #0. Accuracy on batch 1738/2438  on Training is 42.2171506612996\n",
            "Epoch #0. Accuracy on batch 1739/2438  on Training is 42.21623563218391\n",
            "Batch Id 1740/2438 is having training loss of 2.6385648250579834\n",
            "2.1203811168670654\n",
            "Epoch #0. Accuracy on batch 1740/2438  on Training is 42.21891154508903\n",
            "Epoch #0. Accuracy on batch 1741/2438  on Training is 42.223378300803674\n",
            "Epoch #0. Accuracy on batch 1742/2438  on Training is 42.22604704532415\n",
            "Epoch #0. Accuracy on batch 1743/2438  on Training is 42.23229644495413\n",
            "Epoch #0. Accuracy on batch 1744/2438  on Training is 42.23674785100287\n",
            "Epoch #0. Accuracy on batch 1745/2438  on Training is 42.23940435280642\n",
            "Epoch #0. Accuracy on batch 1746/2438  on Training is 42.24205781339439\n",
            "Epoch #0. Accuracy on batch 1747/2438  on Training is 42.25007151029748\n",
            "Epoch #0. Accuracy on batch 1748/2438  on Training is 42.25986277873071\n",
            "Epoch #0. Accuracy on batch 1749/2438  on Training is 42.27142857142857\n",
            "Epoch #0. Accuracy on batch 1750/2438  on Training is 42.274057681324955\n",
            "Epoch #0. Accuracy on batch 1751/2438  on Training is 42.27668378995434\n",
            "Epoch #0. Accuracy on batch 1752/2438  on Training is 42.286437535653164\n",
            "Epoch #0. Accuracy on batch 1753/2438  on Training is 42.29083523375142\n",
            "Epoch #0. Accuracy on batch 1754/2438  on Training is 42.300569800569804\n",
            "Epoch #0. Accuracy on batch 1755/2438  on Training is 42.30495444191344\n",
            "Epoch #0. Accuracy on batch 1756/2438  on Training is 42.31466989186113\n",
            "Epoch #0. Accuracy on batch 1757/2438  on Training is 42.32259670079636\n",
            "Epoch #0. Accuracy on batch 1758/2438  on Training is 42.33051449687322\n",
            "Epoch #0. Accuracy on batch 1759/2438  on Training is 42.33664772727273\n",
            "Batch Id 1760/2438 is having training loss of 2.6314096450805664\n",
            "1.9012281894683838\n",
            "Epoch #0. Accuracy on batch 1760/2438  on Training is 42.34277399204997\n",
            "Epoch #0. Accuracy on batch 1761/2438  on Training is 42.35598751418842\n",
            "Epoch #0. Accuracy on batch 1762/2438  on Training is 42.365640952921154\n",
            "Epoch #0. Accuracy on batch 1763/2438  on Training is 42.373511904761905\n",
            "Epoch #0. Accuracy on batch 1764/2438  on Training is 42.37960339943343\n",
            "Epoch #0. Accuracy on batch 1765/2438  on Training is 42.37860985277463\n",
            "Epoch #0. Accuracy on batch 1766/2438  on Training is 42.39530277306169\n",
            "Epoch #0. Accuracy on batch 1767/2438  on Training is 42.39606900452489\n",
            "Epoch #0. Accuracy on batch 1768/2438  on Training is 42.41096664782363\n",
            "Epoch #0. Accuracy on batch 1769/2438  on Training is 42.418785310734464\n",
            "Epoch #0. Accuracy on batch 1770/2438  on Training is 42.43365330321852\n",
            "Epoch #0. Accuracy on batch 1771/2438  on Training is 42.434396162528216\n",
            "Epoch #0. Accuracy on batch 1772/2438  on Training is 42.44571347997744\n",
            "Epoch #0. Accuracy on batch 1773/2438  on Training is 42.448210259301014\n",
            "Epoch #0. Accuracy on batch 1774/2438  on Training is 42.45246478873239\n",
            "Epoch #0. Accuracy on batch 1775/2438  on Training is 42.460233671171174\n",
            "Epoch #0. Accuracy on batch 1776/2438  on Training is 42.462718064153066\n",
            "Epoch #0. Accuracy on batch 1777/2438  on Training is 42.46519966254218\n",
            "Epoch #0. Accuracy on batch 1778/2438  on Training is 42.47119168071951\n",
            "Epoch #0. Accuracy on batch 1779/2438  on Training is 42.475421348314605\n",
            "Batch Id 1780/2438 is having training loss of 2.6236531734466553\n",
            "2.101654291152954\n",
            "Epoch #0. Accuracy on batch 1780/2438  on Training is 42.479646266142616\n",
            "Epoch #0. Accuracy on batch 1781/2438  on Training is 42.48737373737374\n",
            "Epoch #0. Accuracy on batch 1782/2438  on Training is 42.49333987661245\n",
            "Epoch #0. Accuracy on batch 1783/2438  on Training is 42.50105100896861\n",
            "Epoch #0. Accuracy on batch 1784/2438  on Training is 42.51225490196079\n",
            "Epoch #0. Accuracy on batch 1785/2438  on Training is 42.516447368421055\n",
            "Epoch #0. Accuracy on batch 1786/2438  on Training is 42.52413262451035\n",
            "Epoch #0. Accuracy on batch 1787/2438  on Training is 42.52307046979866\n",
            "Epoch #0. Accuracy on batch 1788/2438  on Training is 42.525503074343206\n",
            "Epoch #0. Accuracy on batch 1789/2438  on Training is 42.52967877094972\n",
            "Epoch #0. Accuracy on batch 1790/2438  on Training is 42.540829145728644\n",
            "Epoch #0. Accuracy on batch 1791/2438  on Training is 42.543247767857146\n",
            "Epoch #0. Accuracy on batch 1792/2438  on Training is 42.54914947016174\n",
            "Epoch #0. Accuracy on batch 1793/2438  on Training is 42.55678651059086\n",
            "Epoch #0. Accuracy on batch 1794/2438  on Training is 42.57137883008357\n",
            "Epoch #0. Accuracy on batch 1795/2438  on Training is 42.573775055679285\n",
            "Epoch #0. Accuracy on batch 1796/2438  on Training is 42.56921257651641\n",
            "Epoch #0. Accuracy on batch 1797/2438  on Training is 42.56813125695217\n",
            "Epoch #0. Accuracy on batch 1798/2438  on Training is 42.57573652028905\n",
            "Epoch #0. Accuracy on batch 1799/2438  on Training is 42.58159722222222\n",
            "Batch Id 1800/2438 is having training loss of 2.61661434173584\n",
            "2.295891046524048\n",
            "Epoch #0. Accuracy on batch 1800/2438  on Training is 42.58398112159911\n",
            "Epoch #0. Accuracy on batch 1801/2438  on Training is 42.596767480577135\n",
            "Epoch #0. Accuracy on batch 1802/2438  on Training is 42.606073211314474\n",
            "Epoch #0. Accuracy on batch 1803/2438  on Training is 42.61536862527716\n",
            "Epoch #0. Accuracy on batch 1804/2438  on Training is 42.6159972299169\n",
            "Epoch #0. Accuracy on batch 1805/2438  on Training is 42.62354651162791\n",
            "Epoch #0. Accuracy on batch 1806/2438  on Training is 42.62762866629773\n",
            "Epoch #0. Accuracy on batch 1807/2438  on Training is 42.631706305309734\n",
            "Epoch #0. Accuracy on batch 1808/2438  on Training is 42.639234383637366\n",
            "Epoch #0. Accuracy on batch 1809/2438  on Training is 42.64675414364641\n",
            "Epoch #0. Accuracy on batch 1810/2438  on Training is 42.65426559911651\n",
            "Epoch #0. Accuracy on batch 1811/2438  on Training is 42.67039183222958\n",
            "Epoch #0. Accuracy on batch 1812/2438  on Training is 42.6727109762824\n",
            "Epoch #0. Accuracy on batch 1813/2438  on Training is 42.6819184123484\n",
            "Epoch #0. Accuracy on batch 1814/2438  on Training is 42.69111570247934\n",
            "Epoch #0. Accuracy on batch 1815/2438  on Training is 42.70202367841409\n",
            "Epoch #0. Accuracy on batch 1816/2438  on Training is 42.71291964777105\n",
            "Epoch #0. Accuracy on batch 1817/2438  on Training is 42.708333333333336\n",
            "Epoch #0. Accuracy on batch 1818/2438  on Training is 42.71921385376581\n",
            "Epoch #0. Accuracy on batch 1819/2438  on Training is 42.72493131868132\n",
            "Batch Id 1820/2438 is having training loss of 2.607994556427002\n",
            "1.8339475393295288\n",
            "Epoch #0. Accuracy on batch 1820/2438  on Training is 42.732358594179026\n",
            "Epoch #0. Accuracy on batch 1821/2438  on Training is 42.739777716794734\n",
            "Epoch #0. Accuracy on batch 1822/2438  on Training is 42.75061711464619\n",
            "Epoch #0. Accuracy on batch 1823/2438  on Training is 42.76144462719298\n",
            "Epoch #0. Accuracy on batch 1824/2438  on Training is 42.772260273972606\n",
            "Epoch #0. Accuracy on batch 1825/2438  on Training is 42.77621851040526\n",
            "Epoch #0. Accuracy on batch 1826/2438  on Training is 42.7801724137931\n",
            "Epoch #0. Accuracy on batch 1827/2438  on Training is 42.7824124726477\n",
            "Epoch #0. Accuracy on batch 1828/2438  on Training is 42.7914844177146\n",
            "Epoch #0. Accuracy on batch 1829/2438  on Training is 42.798838797814206\n",
            "Epoch #0. Accuracy on batch 1830/2438  on Training is 42.801064991807756\n",
            "Epoch #0. Accuracy on batch 1831/2438  on Training is 42.79646561135371\n",
            "Epoch #0. Accuracy on batch 1832/2438  on Training is 42.80891980360065\n",
            "Epoch #0. Accuracy on batch 1833/2438  on Training is 42.81795256270447\n",
            "Epoch #0. Accuracy on batch 1834/2438  on Training is 42.825272479564035\n",
            "Epoch #0. Accuracy on batch 1835/2438  on Training is 42.830882352941174\n",
            "Epoch #0. Accuracy on batch 1836/2438  on Training is 42.83478497550354\n",
            "Epoch #0. Accuracy on batch 1837/2438  on Training is 42.84548422198041\n",
            "Epoch #0. Accuracy on batch 1838/2438  on Training is 42.8544725394236\n",
            "Epoch #0. Accuracy on batch 1839/2438  on Training is 42.861752717391305\n",
            "Batch Id 1840/2438 is having training loss of 2.600538969039917\n",
            "1.6139321327209473\n",
            "Epoch #0. Accuracy on batch 1840/2438  on Training is 42.86393264530147\n",
            "Epoch #0. Accuracy on batch 1841/2438  on Training is 42.869503257328994\n",
            "Epoch #0. Accuracy on batch 1842/2438  on Training is 42.88015463917526\n",
            "Epoch #0. Accuracy on batch 1843/2438  on Training is 42.87893167028199\n",
            "Epoch #0. Accuracy on batch 1844/2438  on Training is 42.889566395663955\n",
            "Epoch #0. Accuracy on batch 1845/2438  on Training is 42.90188244853738\n",
            "Epoch #0. Accuracy on batch 1846/2438  on Training is 42.905725500812125\n",
            "Epoch #0. Accuracy on batch 1847/2438  on Training is 42.90956439393939\n",
            "Epoch #0. Accuracy on batch 1848/2438  on Training is 42.92015954570038\n",
            "Epoch #0. Accuracy on batch 1849/2438  on Training is 42.923986486486484\n",
            "Epoch #0. Accuracy on batch 1850/2438  on Training is 42.929497568881686\n",
            "Epoch #0. Accuracy on batch 1851/2438  on Training is 42.93669006479482\n",
            "Epoch #0. Accuracy on batch 1852/2438  on Training is 42.945561252023744\n",
            "Epoch #0. Accuracy on batch 1853/2438  on Training is 42.94768069039914\n",
            "Epoch #0. Accuracy on batch 1854/2438  on Training is 42.956536388140165\n",
            "Epoch #0. Accuracy on batch 1855/2438  on Training is 42.965382543103445\n",
            "Epoch #0. Accuracy on batch 1856/2438  on Training is 42.9708535271944\n",
            "Epoch #0. Accuracy on batch 1857/2438  on Training is 42.97295479009688\n",
            "Epoch #0. Accuracy on batch 1858/2438  on Training is 42.975053792361486\n",
            "Epoch #0. Accuracy on batch 1859/2438  on Training is 42.97379032258065\n",
            "Batch Id 1860/2438 is having training loss of 2.5927133560180664\n",
            "2.078522205352783\n",
            "Epoch #0. Accuracy on batch 1860/2438  on Training is 42.97588662009672\n",
            "Epoch #0. Accuracy on batch 1861/2438  on Training is 42.984693877551024\n",
            "Epoch #0. Accuracy on batch 1862/2438  on Training is 42.99013687600644\n",
            "Epoch #0. Accuracy on batch 1863/2438  on Training is 42.995574034334766\n",
            "Epoch #0. Accuracy on batch 1864/2438  on Training is 42.99932975871314\n",
            "Epoch #0. Accuracy on batch 1865/2438  on Training is 43.00308145766345\n",
            "Epoch #0. Accuracy on batch 1866/2438  on Training is 43.0135243706481\n",
            "Epoch #0. Accuracy on batch 1867/2438  on Training is 43.02395610278373\n",
            "Epoch #0. Accuracy on batch 1868/2438  on Training is 43.0276886035313\n",
            "Epoch #0. Accuracy on batch 1869/2438  on Training is 43.038101604278076\n",
            "Epoch #0. Accuracy on batch 1870/2438  on Training is 43.05184393372528\n",
            "Epoch #0. Accuracy on batch 1871/2438  on Training is 43.0622329059829\n",
            "Epoch #0. Accuracy on batch 1872/2438  on Training is 43.067605445808866\n",
            "Epoch #0. Accuracy on batch 1873/2438  on Training is 43.07463980789755\n",
            "Epoch #0. Accuracy on batch 1874/2438  on Training is 43.08166666666666\n",
            "Epoch #0. Accuracy on batch 1875/2438  on Training is 43.09035181236674\n",
            "Epoch #0. Accuracy on batch 1876/2438  on Training is 43.0956979222163\n",
            "Epoch #0. Accuracy on batch 1877/2438  on Training is 43.09105431309904\n",
            "Epoch #0. Accuracy on batch 1878/2438  on Training is 43.09639435870144\n",
            "Epoch #0. Accuracy on batch 1879/2438  on Training is 43.10172872340426\n",
            "Batch Id 1880/2438 is having training loss of 2.5853450298309326\n",
            "2.3287739753723145\n",
            "Epoch #0. Accuracy on batch 1880/2438  on Training is 43.09875066454014\n",
            "Epoch #0. Accuracy on batch 1881/2438  on Training is 43.10241764080765\n",
            "Epoch #0. Accuracy on batch 1882/2438  on Training is 43.10774030801912\n",
            "Epoch #0. Accuracy on batch 1883/2438  on Training is 43.11471602972399\n",
            "Epoch #0. Accuracy on batch 1884/2438  on Training is 43.115053050397876\n",
            "Epoch #0. Accuracy on batch 1885/2438  on Training is 43.11538971367975\n",
            "Epoch #0. Accuracy on batch 1886/2438  on Training is 43.13394276629571\n",
            "Epoch #0. Accuracy on batch 1887/2438  on Training is 43.14088983050848\n",
            "Epoch #0. Accuracy on batch 1888/2438  on Training is 43.14617522498676\n",
            "Epoch #0. Accuracy on batch 1889/2438  on Training is 43.15641534391534\n",
            "Epoch #0. Accuracy on batch 1890/2438  on Training is 43.160034373347436\n",
            "Epoch #0. Accuracy on batch 1891/2438  on Training is 43.16530126849894\n",
            "Epoch #0. Accuracy on batch 1892/2438  on Training is 43.17716587427364\n",
            "Epoch #0. Accuracy on batch 1893/2438  on Training is 43.17416842661035\n",
            "Epoch #0. Accuracy on batch 1894/2438  on Training is 43.18271767810026\n",
            "Epoch #0. Accuracy on batch 1895/2438  on Training is 43.20114715189873\n",
            "Epoch #0. Accuracy on batch 1896/2438  on Training is 43.20308381655245\n",
            "Epoch #0. Accuracy on batch 1897/2438  on Training is 43.208311380400424\n",
            "Epoch #0. Accuracy on batch 1898/2438  on Training is 43.21682464454976\n",
            "Epoch #0. Accuracy on batch 1899/2438  on Training is 43.21875\n",
            "Batch Id 1900/2438 is having training loss of 2.5778305530548096\n",
            "1.92766273021698\n",
            "Epoch #0. Accuracy on batch 1900/2438  on Training is 43.22560494476591\n",
            "Epoch #0. Accuracy on batch 1901/2438  on Training is 43.229166666666664\n",
            "Epoch #0. Accuracy on batch 1902/2438  on Training is 43.22944035733053\n",
            "Epoch #0. Accuracy on batch 1903/2438  on Training is 43.24284401260504\n",
            "Epoch #0. Accuracy on batch 1904/2438  on Training is 43.251312335958005\n",
            "Epoch #0. Accuracy on batch 1905/2438  on Training is 43.26633001049318\n",
            "Epoch #0. Accuracy on batch 1906/2438  on Training is 43.26658363922391\n",
            "Epoch #0. Accuracy on batch 1907/2438  on Training is 43.26683700209644\n",
            "Epoch #0. Accuracy on batch 1908/2438  on Training is 43.2736380303824\n",
            "Epoch #0. Accuracy on batch 1909/2438  on Training is 43.28370418848168\n",
            "Epoch #0. Accuracy on batch 1910/2438  on Training is 43.29212454212454\n",
            "Epoch #0. Accuracy on batch 1911/2438  on Training is 43.30217050209205\n",
            "Epoch #0. Accuracy on batch 1912/2438  on Training is 43.317106638787244\n",
            "Epoch #0. Accuracy on batch 1913/2438  on Training is 43.32059822361546\n",
            "Epoch #0. Accuracy on batch 1914/2438  on Training is 43.3306135770235\n",
            "Epoch #0. Accuracy on batch 1915/2438  on Training is 43.34061847599165\n",
            "Epoch #0. Accuracy on batch 1916/2438  on Training is 43.34246218049035\n",
            "Epoch #0. Accuracy on batch 1917/2438  on Training is 43.34919186652763\n",
            "Epoch #0. Accuracy on batch 1918/2438  on Training is 43.354286086503386\n",
            "Epoch #0. Accuracy on batch 1919/2438  on Training is 43.362630208333336\n",
            "Batch Id 1920/2438 is having training loss of 2.571047306060791\n",
            "2.2886040210723877\n",
            "Epoch #0. Accuracy on batch 1920/2438  on Training is 43.36445861530453\n",
            "Epoch #0. Accuracy on batch 1921/2438  on Training is 43.37441467221644\n",
            "Epoch #0. Accuracy on batch 1922/2438  on Training is 43.382735309412375\n",
            "Epoch #0. Accuracy on batch 1923/2438  on Training is 43.3910472972973\n",
            "Epoch #0. Accuracy on batch 1924/2438  on Training is 43.40097402597402\n",
            "Epoch #0. Accuracy on batch 1925/2438  on Training is 43.40440031152648\n",
            "Epoch #0. Accuracy on batch 1926/2438  on Training is 43.4045796574987\n",
            "Epoch #0. Accuracy on batch 1927/2438  on Training is 43.411242219917014\n",
            "Epoch #0. Accuracy on batch 1928/2438  on Training is 43.41141783307413\n",
            "Epoch #0. Accuracy on batch 1929/2438  on Training is 43.43102331606217\n",
            "Epoch #0. Accuracy on batch 1930/2438  on Training is 43.440898498187465\n",
            "Epoch #0. Accuracy on batch 1931/2438  on Training is 43.44914596273292\n",
            "Epoch #0. Accuracy on batch 1932/2438  on Training is 43.455768235902745\n",
            "Epoch #0. Accuracy on batch 1933/2438  on Training is 43.45592037228542\n",
            "Epoch #0. Accuracy on batch 1934/2438  on Training is 43.45284237726098\n",
            "Epoch #0. Accuracy on batch 1935/2438  on Training is 43.46106663223141\n",
            "Epoch #0. Accuracy on batch 1936/2438  on Training is 43.467669075890555\n",
            "Epoch #0. Accuracy on batch 1937/2438  on Training is 43.474264705882355\n",
            "Epoch #0. Accuracy on batch 1938/2438  on Training is 43.48246518824136\n",
            "Epoch #0. Accuracy on batch 1939/2438  on Training is 43.49387886597938\n",
            "Batch Id 1940/2438 is having training loss of 2.5636255741119385\n",
            "1.7011780738830566\n",
            "Epoch #0. Accuracy on batch 1940/2438  on Training is 43.50367078825348\n",
            "Epoch #0. Accuracy on batch 1941/2438  on Training is 43.508625128733264\n",
            "Epoch #0. Accuracy on batch 1942/2438  on Training is 43.51679104477612\n",
            "Epoch #0. Accuracy on batch 1943/2438  on Training is 43.51851851851852\n",
            "Epoch #0. Accuracy on batch 1944/2438  on Training is 43.52345758354756\n",
            "Epoch #0. Accuracy on batch 1945/2438  on Training is 43.531603288797534\n",
            "Epoch #0. Accuracy on batch 1946/2438  on Training is 43.53653055983565\n",
            "Epoch #0. Accuracy on batch 1947/2438  on Training is 43.546265400410675\n",
            "Epoch #0. Accuracy on batch 1948/2438  on Training is 43.541559774243204\n",
            "Epoch #0. Accuracy on batch 1949/2438  on Training is 43.55288461538461\n",
            "Epoch #0. Accuracy on batch 1950/2438  on Training is 43.56099436186571\n",
            "Epoch #0. Accuracy on batch 1951/2438  on Training is 43.56749487704918\n",
            "Epoch #0. Accuracy on batch 1952/2438  on Training is 43.577188940092164\n",
            "Epoch #0. Accuracy on batch 1953/2438  on Training is 43.58047594677584\n",
            "Epoch #0. Accuracy on batch 1954/2438  on Training is 43.58375959079284\n",
            "Epoch #0. Accuracy on batch 1955/2438  on Training is 43.58863752556237\n",
            "Epoch #0. Accuracy on batch 1956/2438  on Training is 43.6030914665304\n",
            "Epoch #0. Accuracy on batch 1957/2438  on Training is 43.609550561797754\n",
            "Epoch #0. Accuracy on batch 1958/2438  on Training is 43.60962225625319\n",
            "Epoch #0. Accuracy on batch 1959/2438  on Training is 43.60809948979592\n",
            "Batch Id 1960/2438 is having training loss of 2.5562899112701416\n",
            "2.009290933609009\n",
            "Epoch #0. Accuracy on batch 1960/2438  on Training is 43.61135900050994\n",
            "Epoch #0. Accuracy on batch 1961/2438  on Training is 43.616207951070336\n",
            "Epoch #0. Accuracy on batch 1962/2438  on Training is 43.62105196128375\n",
            "Epoch #0. Accuracy on batch 1963/2438  on Training is 43.622708757637476\n",
            "Epoch #0. Accuracy on batch 1964/2438  on Training is 43.62913486005089\n",
            "Epoch #0. Accuracy on batch 1965/2438  on Training is 43.629196337741604\n",
            "Epoch #0. Accuracy on batch 1966/2438  on Training is 43.63720132180986\n",
            "Epoch #0. Accuracy on batch 1967/2438  on Training is 43.64837398373984\n",
            "Epoch #0. Accuracy on batch 1968/2438  on Training is 43.65318689690198\n",
            "Epoch #0. Accuracy on batch 1969/2438  on Training is 43.661167512690355\n",
            "Epoch #0. Accuracy on batch 1970/2438  on Training is 43.66438356164384\n",
            "Epoch #0. Accuracy on batch 1971/2438  on Training is 43.66284229208925\n",
            "Epoch #0. Accuracy on batch 1972/2438  on Training is 43.66605423213381\n",
            "Epoch #0. Accuracy on batch 1973/2438  on Training is 43.67242907801418\n",
            "Epoch #0. Accuracy on batch 1974/2438  on Training is 43.677215189873415\n",
            "Epoch #0. Accuracy on batch 1975/2438  on Training is 43.68357793522267\n",
            "Epoch #0. Accuracy on batch 1976/2438  on Training is 43.68361153262519\n",
            "Epoch #0. Accuracy on batch 1977/2438  on Training is 43.69312436804854\n",
            "Epoch #0. Accuracy on batch 1978/2438  on Training is 43.699469429004544\n",
            "Epoch #0. Accuracy on batch 1979/2438  on Training is 43.702651515151516\n",
            "Batch Id 1980/2438 is having training loss of 2.549745798110962\n",
            "2.034240961074829\n",
            "Epoch #0. Accuracy on batch 1980/2438  on Training is 43.70583038869258\n",
            "Epoch #0. Accuracy on batch 1981/2438  on Training is 43.7058526740666\n",
            "Epoch #0. Accuracy on batch 1982/2438  on Training is 43.71217851739788\n",
            "Epoch #0. Accuracy on batch 1983/2438  on Training is 43.709047379032256\n",
            "Epoch #0. Accuracy on batch 1984/2438  on Training is 43.710642317380355\n",
            "Epoch #0. Accuracy on batch 1985/2438  on Training is 43.726397280966765\n",
            "Epoch #0. Accuracy on batch 1986/2438  on Training is 43.73112732762959\n",
            "Epoch #0. Accuracy on batch 1987/2438  on Training is 43.74056841046278\n",
            "Epoch #0. Accuracy on batch 1988/2438  on Training is 43.75\n",
            "Epoch #0. Accuracy on batch 1989/2438  on Training is 43.75314070351759\n",
            "Epoch #0. Accuracy on batch 1990/2438  on Training is 43.7531391260673\n",
            "Epoch #0. Accuracy on batch 1991/2438  on Training is 43.76098142570281\n",
            "Epoch #0. Accuracy on batch 1992/2438  on Training is 43.76254390366282\n",
            "Epoch #0. Accuracy on batch 1993/2438  on Training is 43.770373620862586\n",
            "Epoch #0. Accuracy on batch 1994/2438  on Training is 43.778195488721806\n",
            "Epoch #0. Accuracy on batch 1995/2438  on Training is 43.795403306613224\n",
            "Epoch #0. Accuracy on batch 1996/2438  on Training is 43.79538057085628\n",
            "Epoch #0. Accuracy on batch 1997/2438  on Training is 43.800050050050054\n",
            "Epoch #0. Accuracy on batch 1998/2438  on Training is 43.80315157578789\n",
            "Epoch #0. Accuracy on batch 1999/2438  on Training is 43.80625\n",
            "Batch Id 2000/2438 is having training loss of 2.5439281463623047\n",
            "2.0964481830596924\n",
            "Epoch #0. Accuracy on batch 2000/2438  on Training is 43.804660169915046\n",
            "Epoch #0. Accuracy on batch 2001/2438  on Training is 43.809315684315685\n",
            "Epoch #0. Accuracy on batch 2002/2438  on Training is 43.81240639041438\n",
            "Epoch #0. Accuracy on batch 2003/2438  on Training is 43.8186127744511\n",
            "Epoch #0. Accuracy on batch 2004/2438  on Training is 43.8216957605985\n",
            "Epoch #0. Accuracy on batch 2005/2438  on Training is 43.834122632103686\n",
            "Epoch #0. Accuracy on batch 2006/2438  on Training is 43.84030891878425\n",
            "Epoch #0. Accuracy on batch 2007/2438  on Training is 43.8480453187251\n",
            "Epoch #0. Accuracy on batch 2008/2438  on Training is 43.846441015430564\n",
            "Epoch #0. Accuracy on batch 2009/2438  on Training is 43.85261194029851\n",
            "Epoch #0. Accuracy on batch 2010/2438  on Training is 43.85566882148185\n",
            "Epoch #0. Accuracy on batch 2011/2438  on Training is 43.86648856858847\n",
            "Epoch #0. Accuracy on batch 2012/2438  on Training is 43.869535519125684\n",
            "Epoch #0. Accuracy on batch 2013/2438  on Training is 43.88033763654419\n",
            "Epoch #0. Accuracy on batch 2014/2438  on Training is 43.88492555831265\n",
            "Epoch #0. Accuracy on batch 2015/2438  on Training is 43.87865823412698\n",
            "Epoch #0. Accuracy on batch 2016/2438  on Training is 43.887890431333666\n",
            "Epoch #0. Accuracy on batch 2017/2438  on Training is 43.89091922695739\n",
            "Epoch #0. Accuracy on batch 2018/2438  on Training is 43.89858841010401\n",
            "Epoch #0. Accuracy on batch 2019/2438  on Training is 43.89696782178218\n",
            "Batch Id 2020/2438 is having training loss of 2.5375380516052246\n",
            "1.5795135498046875\n",
            "Epoch #0. Accuracy on batch 2020/2438  on Training is 43.90771895101435\n",
            "Epoch #0. Accuracy on batch 2021/2438  on Training is 43.915368447082095\n",
            "Epoch #0. Accuracy on batch 2022/2438  on Training is 43.924555116164115\n",
            "Epoch #0. Accuracy on batch 2023/2438  on Training is 43.92292490118577\n",
            "Epoch #0. Accuracy on batch 2024/2438  on Training is 43.92746913580247\n",
            "Epoch #0. Accuracy on batch 2025/2438  on Training is 43.935093780848966\n",
            "Epoch #0. Accuracy on batch 2026/2438  on Training is 43.93808584114455\n",
            "Epoch #0. Accuracy on batch 2027/2438  on Training is 43.93799309664694\n",
            "Epoch #0. Accuracy on batch 2028/2438  on Training is 43.94406111384919\n",
            "Epoch #0. Accuracy on batch 2029/2438  on Training is 43.94858374384236\n",
            "Epoch #0. Accuracy on batch 2030/2438  on Training is 43.9561792220581\n",
            "Epoch #0. Accuracy on batch 2031/2438  on Training is 43.95300196850393\n",
            "Epoch #0. Accuracy on batch 2032/2438  on Training is 43.95905066404329\n",
            "Epoch #0. Accuracy on batch 2033/2438  on Training is 43.957411504424776\n",
            "Epoch #0. Accuracy on batch 2034/2438  on Training is 43.96038083538083\n",
            "Epoch #0. Accuracy on batch 2035/2438  on Training is 43.96641699410609\n",
            "Epoch #0. Accuracy on batch 2036/2438  on Training is 43.970913107511045\n",
            "Epoch #0. Accuracy on batch 2037/2438  on Training is 43.981538272816486\n",
            "Epoch #0. Accuracy on batch 2038/2438  on Training is 43.9829573320255\n",
            "Epoch #0. Accuracy on batch 2039/2438  on Training is 43.995098039215684\n",
            "Batch Id 2040/2438 is having training loss of 2.5315804481506348\n",
            "1.7592519521713257\n",
            "Epoch #0. Accuracy on batch 2040/2438  on Training is 44.00569573738363\n",
            "Epoch #0. Accuracy on batch 2041/2438  on Training is 44.00404015670911\n",
            "Epoch #0. Accuracy on batch 2042/2438  on Training is 44.01615271659325\n",
            "Epoch #0. Accuracy on batch 2043/2438  on Training is 44.01296477495108\n",
            "Epoch #0. Accuracy on batch 2044/2438  on Training is 44.020476772616135\n",
            "Epoch #0. Accuracy on batch 2045/2438  on Training is 44.02645405669599\n",
            "Epoch #0. Accuracy on batch 2046/2438  on Training is 44.03547874938935\n",
            "Epoch #0. Accuracy on batch 2047/2438  on Training is 44.0338134765625\n",
            "Epoch #0. Accuracy on batch 2048/2438  on Training is 44.04282576866764\n",
            "Epoch #0. Accuracy on batch 2049/2438  on Training is 44.05030487804878\n",
            "Epoch #0. Accuracy on batch 2050/2438  on Training is 44.05472940029254\n",
            "Epoch #0. Accuracy on batch 2051/2438  on Training is 44.05610380116959\n",
            "Epoch #0. Accuracy on batch 2052/2438  on Training is 44.05747686312713\n",
            "Epoch #0. Accuracy on batch 2053/2438  on Training is 44.06341285296981\n",
            "Epoch #0. Accuracy on batch 2054/2438  on Training is 44.06934306569343\n",
            "Epoch #0. Accuracy on batch 2055/2438  on Training is 44.07830739299611\n",
            "Epoch #0. Accuracy on batch 2056/2438  on Training is 44.0872630043753\n",
            "Epoch #0. Accuracy on batch 2057/2438  on Training is 44.09317298347911\n",
            "Epoch #0. Accuracy on batch 2058/2438  on Training is 44.09755949490044\n",
            "Epoch #0. Accuracy on batch 2059/2438  on Training is 44.1064927184466\n",
            "Batch Id 2060/2438 is having training loss of 2.5246737003326416\n",
            "1.286423921585083\n",
            "Epoch #0. Accuracy on batch 2060/2438  on Training is 44.118449781659386\n",
            "Epoch #0. Accuracy on batch 2061/2438  on Training is 44.12584869059166\n",
            "Epoch #0. Accuracy on batch 2062/2438  on Training is 44.13021085797382\n",
            "Epoch #0. Accuracy on batch 2063/2438  on Training is 44.140625\n",
            "Epoch #0. Accuracy on batch 2064/2438  on Training is 44.14497578692494\n",
            "Epoch #0. Accuracy on batch 2065/2438  on Training is 44.150834946757016\n",
            "Epoch #0. Accuracy on batch 2066/2438  on Training is 44.149129172714076\n",
            "Epoch #0. Accuracy on batch 2067/2438  on Training is 44.1519584139265\n",
            "Epoch #0. Accuracy on batch 2068/2438  on Training is 44.15780570323828\n",
            "Epoch #0. Accuracy on batch 2069/2438  on Training is 44.160628019323674\n",
            "Epoch #0. Accuracy on batch 2070/2438  on Training is 44.169483341380975\n",
            "Epoch #0. Accuracy on batch 2071/2438  on Training is 44.16928088803089\n",
            "Epoch #0. Accuracy on batch 2072/2438  on Training is 44.17360106126387\n",
            "Epoch #0. Accuracy on batch 2073/2438  on Training is 44.18093056894889\n",
            "Epoch #0. Accuracy on batch 2074/2438  on Training is 44.191265060240966\n",
            "Epoch #0. Accuracy on batch 2075/2438  on Training is 44.189547206165706\n",
            "Epoch #0. Accuracy on batch 2076/2438  on Training is 44.19685844968705\n",
            "Epoch #0. Accuracy on batch 2077/2438  on Training is 44.204162656400385\n",
            "Epoch #0. Accuracy on batch 2078/2438  on Training is 44.21596921596922\n",
            "Epoch #0. Accuracy on batch 2079/2438  on Training is 44.21724759615385\n",
            "Batch Id 2080/2438 is having training loss of 2.5184707641601562\n",
            "1.7626450061798096\n",
            "Epoch #0. Accuracy on batch 2080/2438  on Training is 44.223029793368575\n",
            "Epoch #0. Accuracy on batch 2081/2438  on Training is 44.22730547550432\n",
            "Epoch #0. Accuracy on batch 2082/2438  on Training is 44.231577052328376\n",
            "Epoch #0. Accuracy on batch 2083/2438  on Training is 44.23434500959693\n",
            "Epoch #0. Accuracy on batch 2084/2438  on Training is 44.2416067146283\n",
            "Epoch #0. Accuracy on batch 2085/2438  on Training is 44.24736337488015\n",
            "Epoch #0. Accuracy on batch 2086/2438  on Training is 44.24862242453282\n",
            "Epoch #0. Accuracy on batch 2087/2438  on Training is 44.25437021072797\n",
            "Epoch #0. Accuracy on batch 2088/2438  on Training is 44.25562470081378\n",
            "Epoch #0. Accuracy on batch 2089/2438  on Training is 44.256877990430624\n",
            "Epoch #0. Accuracy on batch 2090/2438  on Training is 44.25962458153993\n",
            "Epoch #0. Accuracy on batch 2091/2438  on Training is 44.269837476099426\n",
            "Epoch #0. Accuracy on batch 2092/2438  on Training is 44.27705446727186\n",
            "Epoch #0. Accuracy on batch 2093/2438  on Training is 44.282772206303726\n",
            "Epoch #0. Accuracy on batch 2094/2438  on Training is 44.28848448687351\n",
            "Epoch #0. Accuracy on batch 2095/2438  on Training is 44.28822757633588\n",
            "Epoch #0. Accuracy on batch 2096/2438  on Training is 44.2909513590844\n",
            "Epoch #0. Accuracy on batch 2097/2438  on Training is 44.29814108674928\n",
            "Epoch #0. Accuracy on batch 2098/2438  on Training is 44.30234635540734\n",
            "Epoch #0. Accuracy on batch 2099/2438  on Training is 44.308035714285715\n",
            "Batch Id 2100/2438 is having training loss of 2.512310743331909\n",
            "2.0424699783325195\n",
            "Epoch #0. Accuracy on batch 2100/2438  on Training is 44.30628272251309\n",
            "Epoch #0. Accuracy on batch 2101/2438  on Training is 44.31047811607992\n",
            "Epoch #0. Accuracy on batch 2102/2438  on Training is 44.317641464574415\n",
            "Epoch #0. Accuracy on batch 2103/2438  on Training is 44.32034220532319\n",
            "Epoch #0. Accuracy on batch 2104/2438  on Training is 44.32749406175772\n",
            "Epoch #0. Accuracy on batch 2105/2438  on Training is 44.337606837606835\n",
            "Epoch #0. Accuracy on batch 2106/2438  on Training is 44.34474371143806\n",
            "Epoch #0. Accuracy on batch 2107/2438  on Training is 44.351873814041745\n",
            "Epoch #0. Accuracy on batch 2108/2438  on Training is 44.36344238975818\n",
            "Epoch #0. Accuracy on batch 2109/2438  on Training is 44.37351895734597\n",
            "Epoch #0. Accuracy on batch 2110/2438  on Training is 44.379144954997635\n",
            "Epoch #0. Accuracy on batch 2111/2438  on Training is 44.38772490530303\n",
            "Epoch #0. Accuracy on batch 2112/2438  on Training is 44.39629673450071\n",
            "Epoch #0. Accuracy on batch 2113/2438  on Training is 44.39599101229896\n",
            "Epoch #0. Accuracy on batch 2114/2438  on Training is 44.400118203309695\n",
            "Epoch #0. Accuracy on batch 2115/2438  on Training is 44.40867202268431\n",
            "Epoch #0. Accuracy on batch 2116/2438  on Training is 44.41574161549362\n",
            "Epoch #0. Accuracy on batch 2117/2438  on Training is 44.42723087818697\n",
            "Epoch #0. Accuracy on batch 2118/2438  on Training is 44.43133553563001\n",
            "Epoch #0. Accuracy on batch 2119/2438  on Training is 44.43985849056604\n",
            "Batch Id 2120/2438 is having training loss of 2.505021095275879\n",
            "1.5222365856170654\n",
            "Epoch #0. Accuracy on batch 2120/2438  on Training is 44.44837340876945\n",
            "Epoch #0. Accuracy on batch 2121/2438  on Training is 44.464243638077285\n",
            "Epoch #0. Accuracy on batch 2122/2438  on Training is 44.46390720678286\n",
            "Epoch #0. Accuracy on batch 2123/2438  on Training is 44.4709274952919\n",
            "Epoch #0. Accuracy on batch 2124/2438  on Training is 44.47205882352941\n",
            "Epoch #0. Accuracy on batch 2125/2438  on Training is 44.47612888052681\n",
            "Epoch #0. Accuracy on batch 2126/2438  on Training is 44.47872590503056\n",
            "Epoch #0. Accuracy on batch 2127/2438  on Training is 44.48572603383459\n",
            "Epoch #0. Accuracy on batch 2128/2438  on Training is 44.488316110850164\n",
            "Epoch #0. Accuracy on batch 2129/2438  on Training is 44.492370892018776\n",
            "Epoch #0. Accuracy on batch 2130/2438  on Training is 44.499354763022055\n",
            "Epoch #0. Accuracy on batch 2131/2438  on Training is 44.494606003752345\n",
            "Epoch #0. Accuracy on batch 2132/2438  on Training is 44.4971870604782\n",
            "Epoch #0. Accuracy on batch 2133/2438  on Training is 44.51148078725398\n",
            "Epoch #0. Accuracy on batch 2134/2438  on Training is 44.516978922716625\n",
            "Epoch #0. Accuracy on batch 2135/2438  on Training is 44.51808286516854\n",
            "Epoch #0. Accuracy on batch 2136/2438  on Training is 44.523572765559194\n",
            "Epoch #0. Accuracy on batch 2137/2438  on Training is 44.53782740879326\n",
            "Epoch #0. Accuracy on batch 2138/2438  on Training is 44.54330294530154\n",
            "Epoch #0. Accuracy on batch 2139/2438  on Training is 44.544392523364486\n",
            "Batch Id 2140/2438 is having training loss of 2.4990155696868896\n",
            "1.4362192153930664\n",
            "Epoch #0. Accuracy on batch 2140/2438  on Training is 44.55423867351705\n",
            "Epoch #0. Accuracy on batch 2141/2438  on Training is 44.561157796451916\n",
            "Epoch #0. Accuracy on batch 2142/2438  on Training is 44.5680704619692\n",
            "Epoch #0. Accuracy on batch 2143/2438  on Training is 44.57497667910448\n",
            "Epoch #0. Accuracy on batch 2144/2438  on Training is 44.586247086247084\n",
            "Epoch #0. Accuracy on batch 2145/2438  on Training is 44.59313839701771\n",
            "Epoch #0. Accuracy on batch 2146/2438  on Training is 44.60293432696786\n",
            "Epoch #0. Accuracy on batch 2147/2438  on Training is 44.60690176908752\n",
            "Epoch #0. Accuracy on batch 2148/2438  on Training is 44.613773848301534\n",
            "Epoch #0. Accuracy on batch 2149/2438  on Training is 44.62063953488372\n",
            "Epoch #0. Accuracy on batch 2150/2438  on Training is 44.63331008833101\n",
            "Epoch #0. Accuracy on batch 2151/2438  on Training is 44.63870817843866\n",
            "Epoch #0. Accuracy on batch 2152/2438  on Training is 44.63394101254064\n",
            "Epoch #0. Accuracy on batch 2153/2438  on Training is 44.639333797585884\n",
            "Epoch #0. Accuracy on batch 2154/2438  on Training is 44.64907192575406\n",
            "Epoch #0. Accuracy on batch 2155/2438  on Training is 44.66169990723562\n",
            "Epoch #0. Accuracy on batch 2156/2438  on Training is 44.66417477978674\n",
            "Epoch #0. Accuracy on batch 2157/2438  on Training is 44.665199258572756\n",
            "Epoch #0. Accuracy on batch 2158/2438  on Training is 44.669117647058826\n",
            "Epoch #0. Accuracy on batch 2159/2438  on Training is 44.675925925925924\n",
            "Batch Id 2160/2438 is having training loss of 2.4925248622894287\n",
            "1.773180365562439\n",
            "Epoch #0. Accuracy on batch 2160/2438  on Training is 44.678389634428505\n",
            "Epoch #0. Accuracy on batch 2161/2438  on Training is 44.680851063829785\n",
            "Epoch #0. Accuracy on batch 2162/2438  on Training is 44.69342348589922\n",
            "Epoch #0. Accuracy on batch 2163/2438  on Training is 44.69154343807764\n",
            "Epoch #0. Accuracy on batch 2164/2438  on Training is 44.68966512702079\n",
            "Epoch #0. Accuracy on batch 2165/2438  on Training is 44.695002308402586\n",
            "Epoch #0. Accuracy on batch 2166/2438  on Training is 44.69745039224735\n",
            "Epoch #0. Accuracy on batch 2167/2438  on Training is 44.69845479704797\n",
            "Epoch #0. Accuracy on batch 2168/2438  on Training is 44.708102812355925\n",
            "Epoch #0. Accuracy on batch 2169/2438  on Training is 44.71198156682028\n",
            "Epoch #0. Accuracy on batch 2170/2438  on Training is 44.71009903270382\n",
            "Epoch #0. Accuracy on batch 2171/2438  on Training is 44.7154120626151\n",
            "Epoch #0. Accuracy on batch 2172/2438  on Training is 44.71496778647032\n",
            "Epoch #0. Accuracy on batch 2173/2438  on Training is 44.72171113155474\n",
            "Epoch #0. Accuracy on batch 2174/2438  on Training is 44.72844827586207\n",
            "Epoch #0. Accuracy on batch 2175/2438  on Training is 44.72943474264706\n",
            "Epoch #0. Accuracy on batch 2176/2438  on Training is 44.73759761139183\n",
            "Epoch #0. Accuracy on batch 2177/2438  on Training is 44.73714416896235\n",
            "Epoch #0. Accuracy on batch 2178/2438  on Training is 44.74673015144562\n",
            "Epoch #0. Accuracy on batch 2179/2438  on Training is 44.75057339449541\n",
            "Batch Id 2180/2438 is having training loss of 2.4867730140686035\n",
            "1.5048630237579346\n",
            "Epoch #0. Accuracy on batch 2180/2438  on Training is 44.7587116001834\n",
            "Epoch #0. Accuracy on batch 2181/2438  on Training is 44.76684234647113\n",
            "Epoch #0. Accuracy on batch 2182/2438  on Training is 44.76637654603756\n",
            "Epoch #0. Accuracy on batch 2183/2438  on Training is 44.76877289377289\n",
            "Epoch #0. Accuracy on batch 2184/2438  on Training is 44.77974828375286\n",
            "Epoch #0. Accuracy on batch 2185/2438  on Training is 44.787854528819764\n",
            "Epoch #0. Accuracy on batch 2186/2438  on Training is 44.78880887059899\n",
            "Epoch #0. Accuracy on batch 2187/2438  on Training is 44.79119058500914\n",
            "Epoch #0. Accuracy on batch 2188/2438  on Training is 44.78928734582001\n",
            "Epoch #0. Accuracy on batch 2189/2438  on Training is 44.798801369863014\n",
            "Epoch #0. Accuracy on batch 2190/2438  on Training is 44.805454130534\n",
            "Epoch #0. Accuracy on batch 2191/2438  on Training is 44.80782390510949\n",
            "Epoch #0. Accuracy on batch 2192/2438  on Training is 44.80876652986776\n",
            "Epoch #0. Accuracy on batch 2193/2438  on Training is 44.8082839562443\n",
            "Epoch #0. Accuracy on batch 2194/2438  on Training is 44.80780182232346\n",
            "Epoch #0. Accuracy on batch 2195/2438  on Training is 44.81301229508197\n",
            "Epoch #0. Accuracy on batch 2196/2438  on Training is 44.82390760127446\n",
            "Epoch #0. Accuracy on batch 2197/2438  on Training is 44.82910600545951\n",
            "Epoch #0. Accuracy on batch 2198/2438  on Training is 44.841405184174626\n",
            "Epoch #0. Accuracy on batch 2199/2438  on Training is 44.84659090909091\n",
            "Batch Id 2200/2438 is having training loss of 2.4806978702545166\n",
            "1.833469033241272\n",
            "Epoch #0. Accuracy on batch 2200/2438  on Training is 44.84751249432076\n",
            "Epoch #0. Accuracy on batch 2201/2438  on Training is 44.84701407811081\n",
            "Epoch #0. Accuracy on batch 2202/2438  on Training is 44.85077167498865\n",
            "Epoch #0. Accuracy on batch 2203/2438  on Training is 44.853107985480946\n",
            "Epoch #0. Accuracy on batch 2204/2438  on Training is 44.865362811791385\n",
            "Epoch #0. Accuracy on batch 2205/2438  on Training is 44.8719401631913\n",
            "Epoch #0. Accuracy on batch 2206/2438  on Training is 44.87567965564114\n",
            "Epoch #0. Accuracy on batch 2207/2438  on Training is 44.87941576086956\n",
            "Epoch #0. Accuracy on batch 2208/2438  on Training is 44.87890448166591\n",
            "Epoch #0. Accuracy on batch 2209/2438  on Training is 44.88829185520362\n",
            "Epoch #0. Accuracy on batch 2210/2438  on Training is 44.893430574400725\n",
            "Epoch #0. Accuracy on batch 2211/2438  on Training is 44.89856464737794\n",
            "Epoch #0. Accuracy on batch 2212/2438  on Training is 44.9036940804338\n",
            "Epoch #0. Accuracy on batch 2213/2438  on Training is 44.907407407407405\n",
            "Epoch #0. Accuracy on batch 2214/2438  on Training is 44.9068848758465\n",
            "Epoch #0. Accuracy on batch 2215/2438  on Training is 44.91341380866426\n",
            "Epoch #0. Accuracy on batch 2216/2438  on Training is 44.917117726657644\n",
            "Epoch #0. Accuracy on batch 2217/2438  on Training is 44.91377366997295\n",
            "Epoch #0. Accuracy on batch 2218/2438  on Training is 44.916065795403334\n",
            "Epoch #0. Accuracy on batch 2219/2438  on Training is 44.9169481981982\n",
            "Batch Id 2220/2438 is having training loss of 2.475390911102295\n",
            "1.8620307445526123\n",
            "Epoch #0. Accuracy on batch 2220/2438  on Training is 44.91782980639351\n",
            "Epoch #0. Accuracy on batch 2221/2438  on Training is 44.91730423042304\n",
            "Epoch #0. Accuracy on batch 2222/2438  on Training is 44.9322424651372\n",
            "Epoch #0. Accuracy on batch 2223/2438  on Training is 44.934521133093526\n",
            "Epoch #0. Accuracy on batch 2224/2438  on Training is 44.938202247191015\n",
            "Epoch #0. Accuracy on batch 2225/2438  on Training is 44.94047619047619\n",
            "Epoch #0. Accuracy on batch 2226/2438  on Training is 44.94976425684778\n",
            "Epoch #0. Accuracy on batch 2227/2438  on Training is 44.954836175942546\n",
            "Epoch #0. Accuracy on batch 2228/2438  on Training is 44.95990354419022\n",
            "Epoch #0. Accuracy on batch 2229/2438  on Training is 44.964966367713004\n",
            "Epoch #0. Accuracy on batch 2230/2438  on Training is 44.958818915284624\n",
            "Epoch #0. Accuracy on batch 2231/2438  on Training is 44.95967741935484\n",
            "Epoch #0. Accuracy on batch 2232/2438  on Training is 44.971730855351545\n",
            "Epoch #0. Accuracy on batch 2233/2438  on Training is 44.98237466427932\n",
            "Epoch #0. Accuracy on batch 2234/2438  on Training is 44.98601789709172\n",
            "Epoch #0. Accuracy on batch 2235/2438  on Training is 44.9966457960644\n",
            "Epoch #0. Accuracy on batch 2236/2438  on Training is 44.99888243182834\n",
            "Epoch #0. Accuracy on batch 2237/2438  on Training is 45.002513404825734\n",
            "Epoch #0. Accuracy on batch 2238/2438  on Training is 45.00474542206342\n",
            "Epoch #0. Accuracy on batch 2239/2438  on Training is 45.00697544642857\n",
            "Batch Id 2240/2438 is having training loss of 2.4694342613220215\n",
            "1.92140793800354\n",
            "Epoch #0. Accuracy on batch 2240/2438  on Training is 45.010597947344934\n",
            "Epoch #0. Accuracy on batch 2241/2438  on Training is 45.01421721677074\n",
            "Epoch #0. Accuracy on batch 2242/2438  on Training is 45.019226482389655\n",
            "Epoch #0. Accuracy on batch 2243/2438  on Training is 45.02423128342246\n",
            "Epoch #0. Accuracy on batch 2244/2438  on Training is 45.02644766146993\n",
            "Epoch #0. Accuracy on batch 2245/2438  on Training is 45.03283615316118\n",
            "Epoch #0. Accuracy on batch 2246/2438  on Training is 45.03782821539831\n",
            "Epoch #0. Accuracy on batch 2247/2438  on Training is 45.04003558718861\n",
            "Epoch #0. Accuracy on batch 2248/2438  on Training is 45.04918852823477\n",
            "Epoch #0. Accuracy on batch 2249/2438  on Training is 45.05416666666667\n",
            "Epoch #0. Accuracy on batch 2250/2438  on Training is 45.054975566414925\n",
            "Epoch #0. Accuracy on batch 2251/2438  on Training is 45.05994671403197\n",
            "Epoch #0. Accuracy on batch 2252/2438  on Training is 45.06630048823791\n",
            "Epoch #0. Accuracy on batch 2253/2438  on Training is 45.07264862466726\n",
            "Epoch #0. Accuracy on batch 2254/2438  on Training is 45.076219512195124\n",
            "Epoch #0. Accuracy on batch 2255/2438  on Training is 45.079787234042556\n",
            "Epoch #0. Accuracy on batch 2256/2438  on Training is 45.086120957022594\n",
            "Epoch #0. Accuracy on batch 2257/2438  on Training is 45.0993689105403\n",
            "Epoch #0. Accuracy on batch 2258/2438  on Training is 45.101538291279326\n",
            "Epoch #0. Accuracy on batch 2259/2438  on Training is 45.10923672566372\n",
            "Batch Id 2260/2438 is having training loss of 2.4630167484283447\n",
            "1.715672492980957\n",
            "Epoch #0. Accuracy on batch 2260/2438  on Training is 45.115546218487395\n",
            "Epoch #0. Accuracy on batch 2261/2438  on Training is 45.11908709106985\n",
            "Epoch #0. Accuracy on batch 2262/2438  on Training is 45.1295293857711\n",
            "Epoch #0. Accuracy on batch 2263/2438  on Training is 45.139962455830386\n",
            "Epoch #0. Accuracy on batch 2264/2438  on Training is 45.144867549668874\n",
            "Epoch #0. Accuracy on batch 2265/2438  on Training is 45.15252647837599\n",
            "Epoch #0. Accuracy on batch 2266/2438  on Training is 45.15052933392148\n",
            "Epoch #0. Accuracy on batch 2267/2438  on Training is 45.15680114638448\n",
            "Epoch #0. Accuracy on batch 2268/2438  on Training is 45.16031291317761\n",
            "Epoch #0. Accuracy on batch 2269/2438  on Training is 45.16382158590309\n",
            "Epoch #0. Accuracy on batch 2270/2438  on Training is 45.16595112285337\n",
            "Epoch #0. Accuracy on batch 2271/2438  on Training is 45.16945422535211\n",
            "Epoch #0. Accuracy on batch 2272/2438  on Training is 45.167454905411354\n",
            "Epoch #0. Accuracy on batch 2273/2438  on Training is 45.16683157431838\n",
            "Epoch #0. Accuracy on batch 2274/2438  on Training is 45.18131868131868\n",
            "Epoch #0. Accuracy on batch 2275/2438  on Training is 45.190300966608085\n",
            "Epoch #0. Accuracy on batch 2276/2438  on Training is 45.1951581027668\n",
            "Epoch #0. Accuracy on batch 2277/2438  on Training is 45.20275460930641\n",
            "Epoch #0. Accuracy on batch 2278/2438  on Training is 45.21034444931988\n",
            "Epoch #0. Accuracy on batch 2279/2438  on Training is 45.213815789473685\n",
            "Batch Id 2280/2438 is having training loss of 2.4565367698669434\n",
            "1.3671578168869019\n",
            "Epoch #0. Accuracy on batch 2280/2438  on Training is 45.22687417799211\n",
            "Epoch #0. Accuracy on batch 2281/2438  on Training is 45.23855170902717\n",
            "Epoch #0. Accuracy on batch 2282/2438  on Training is 45.24474375821288\n",
            "Epoch #0. Accuracy on batch 2283/2438  on Training is 45.2550350262697\n",
            "Epoch #0. Accuracy on batch 2284/2438  on Training is 45.25711159737418\n",
            "Epoch #0. Accuracy on batch 2285/2438  on Training is 45.26192038495188\n",
            "Epoch #0. Accuracy on batch 2286/2438  on Training is 45.263992129427194\n",
            "Epoch #0. Accuracy on batch 2287/2438  on Training is 45.27289117132867\n",
            "Epoch #0. Accuracy on batch 2288/2438  on Training is 45.27768676277851\n",
            "Epoch #0. Accuracy on batch 2289/2438  on Training is 45.27565502183406\n",
            "Epoch #0. Accuracy on batch 2290/2438  on Training is 45.27362505456133\n",
            "Epoch #0. Accuracy on batch 2291/2438  on Training is 45.27841404886562\n",
            "Epoch #0. Accuracy on batch 2292/2438  on Training is 45.279110335804624\n",
            "Epoch #0. Accuracy on batch 2293/2438  on Training is 45.285255013077595\n",
            "Epoch #0. Accuracy on batch 2294/2438  on Training is 45.29139433551198\n",
            "Epoch #0. Accuracy on batch 2295/2438  on Training is 45.29616724738676\n",
            "Epoch #0. Accuracy on batch 2296/2438  on Training is 45.29549412276883\n",
            "Epoch #0. Accuracy on batch 2297/2438  on Training is 45.29890121845083\n",
            "Epoch #0. Accuracy on batch 2298/2438  on Training is 45.30774249673771\n",
            "Epoch #0. Accuracy on batch 2299/2438  on Training is 45.31521739130435\n",
            "Batch Id 2300/2438 is having training loss of 2.450432300567627\n",
            "1.6315263509750366\n",
            "Epoch #0. Accuracy on batch 2300/2438  on Training is 45.31996957844415\n",
            "Epoch #0. Accuracy on batch 2301/2438  on Training is 45.322002606429194\n",
            "Epoch #0. Accuracy on batch 2302/2438  on Training is 45.328104646113765\n",
            "Epoch #0. Accuracy on batch 2303/2438  on Training is 45.334201388888886\n",
            "Epoch #0. Accuracy on batch 2304/2438  on Training is 45.34300433839479\n",
            "Epoch #0. Accuracy on batch 2305/2438  on Training is 45.342313529921945\n",
            "Epoch #0. Accuracy on batch 2306/2438  on Training is 45.34568703944517\n",
            "Epoch #0. Accuracy on batch 2307/2438  on Training is 45.34905762564991\n",
            "Epoch #0. Accuracy on batch 2308/2438  on Training is 45.356485491554785\n",
            "Epoch #0. Accuracy on batch 2309/2438  on Training is 45.35849567099567\n",
            "Epoch #0. Accuracy on batch 2310/2438  on Training is 45.36591302466465\n",
            "Epoch #0. Accuracy on batch 2311/2438  on Training is 45.370620674740486\n",
            "Epoch #0. Accuracy on batch 2312/2438  on Training is 45.37262213575443\n",
            "Epoch #0. Accuracy on batch 2313/2438  on Training is 45.38002376836646\n",
            "Epoch #0. Accuracy on batch 2314/2438  on Training is 45.388768898488124\n",
            "Epoch #0. Accuracy on batch 2315/2438  on Training is 45.39750647668394\n",
            "Epoch #0. Accuracy on batch 2316/2438  on Training is 45.40488778593008\n",
            "Epoch #0. Accuracy on batch 2317/2438  on Training is 45.40956643658326\n",
            "Epoch #0. Accuracy on batch 2318/2438  on Training is 45.412893488572664\n",
            "Epoch #0. Accuracy on batch 2319/2438  on Training is 45.41891163793103\n",
            "Batch Id 2320/2438 is having training loss of 2.444678783416748\n",
            "1.5097863674163818\n",
            "Epoch #0. Accuracy on batch 2320/2438  on Training is 45.42357819905213\n",
            "Epoch #0. Accuracy on batch 2321/2438  on Training is 45.41612833763997\n",
            "Epoch #0. Accuracy on batch 2322/2438  on Training is 45.42213732242789\n",
            "Epoch #0. Accuracy on batch 2323/2438  on Training is 45.42948580034423\n",
            "Epoch #0. Accuracy on batch 2324/2438  on Training is 45.435483870967744\n",
            "Epoch #0. Accuracy on batch 2325/2438  on Training is 45.44416380051591\n",
            "Epoch #0. Accuracy on batch 2326/2438  on Training is 45.44343575418994\n",
            "Epoch #0. Accuracy on batch 2327/2438  on Training is 45.44807774914089\n",
            "Epoch #0. Accuracy on batch 2328/2438  on Training is 45.454057535422926\n",
            "Epoch #0. Accuracy on batch 2329/2438  on Training is 45.45734978540773\n",
            "Epoch #0. Accuracy on batch 2330/2438  on Training is 45.461979836979836\n",
            "Epoch #0. Accuracy on batch 2331/2438  on Training is 45.463925814751285\n",
            "Epoch #0. Accuracy on batch 2332/2438  on Training is 45.46988855550793\n",
            "Epoch #0. Accuracy on batch 2333/2438  on Training is 45.47718508997429\n",
            "Epoch #0. Accuracy on batch 2334/2438  on Training is 45.48313704496788\n",
            "Epoch #0. Accuracy on batch 2335/2438  on Training is 45.49175941780822\n",
            "Epoch #0. Accuracy on batch 2336/2438  on Training is 45.50171159606333\n",
            "Epoch #0. Accuracy on batch 2337/2438  on Training is 45.51299187339607\n",
            "Epoch #0. Accuracy on batch 2338/2438  on Training is 45.5149102180419\n",
            "Epoch #0. Accuracy on batch 2339/2438  on Training is 45.51682692307692\n",
            "Batch Id 2340/2438 is having training loss of 2.438357353210449\n",
            "1.4428741931915283\n",
            "Epoch #0. Accuracy on batch 2340/2438  on Training is 45.52808628791115\n",
            "Epoch #0. Accuracy on batch 2341/2438  on Training is 45.53266438941076\n",
            "Epoch #0. Accuracy on batch 2342/2438  on Training is 45.539906103286384\n",
            "Epoch #0. Accuracy on batch 2343/2438  on Training is 45.5444752559727\n",
            "Epoch #0. Accuracy on batch 2344/2438  on Training is 45.54504264392324\n",
            "Epoch #0. Accuracy on batch 2345/2438  on Training is 45.55093776641091\n",
            "Epoch #0. Accuracy on batch 2346/2438  on Training is 45.5501704303366\n",
            "Epoch #0. Accuracy on batch 2347/2438  on Training is 45.54940374787053\n",
            "Epoch #0. Accuracy on batch 2348/2438  on Training is 45.54863771817795\n",
            "Epoch #0. Accuracy on batch 2349/2438  on Training is 45.55452127659574\n",
            "Epoch #0. Accuracy on batch 2350/2438  on Training is 45.56172905146746\n",
            "Epoch #0. Accuracy on batch 2351/2438  on Training is 45.55963010204081\n",
            "Epoch #0. Accuracy on batch 2352/2438  on Training is 45.56417339566511\n",
            "Epoch #0. Accuracy on batch 2353/2438  on Training is 45.57269541206457\n",
            "Epoch #0. Accuracy on batch 2354/2438  on Training is 45.57988322717622\n",
            "Epoch #0. Accuracy on batch 2355/2438  on Training is 45.58043293718166\n",
            "Epoch #0. Accuracy on batch 2356/2438  on Training is 45.579656342808654\n",
            "Epoch #0. Accuracy on batch 2357/2438  on Training is 45.582856234096695\n",
            "Epoch #0. Accuracy on batch 2358/2438  on Training is 45.584728698601104\n",
            "Epoch #0. Accuracy on batch 2359/2438  on Training is 45.58924788135593\n",
            "Batch Id 2360/2438 is having training loss of 2.4336931705474854\n",
            "1.5396194458007812\n",
            "Epoch #0. Accuracy on batch 2360/2438  on Training is 45.59508682761542\n",
            "Epoch #0. Accuracy on batch 2361/2438  on Training is 45.60224386113463\n",
            "Epoch #0. Accuracy on batch 2362/2438  on Training is 45.6001375370292\n",
            "Epoch #0. Accuracy on batch 2363/2438  on Training is 45.60596446700507\n",
            "Epoch #0. Accuracy on batch 2364/2438  on Training is 45.61575052854123\n",
            "Epoch #0. Accuracy on batch 2365/2438  on Training is 45.62552831783601\n",
            "Epoch #0. Accuracy on batch 2366/2438  on Training is 45.630016899028305\n",
            "Epoch #0. Accuracy on batch 2367/2438  on Training is 45.63186233108108\n",
            "Epoch #0. Accuracy on batch 2368/2438  on Training is 45.63766357112706\n",
            "Epoch #0. Accuracy on batch 2369/2438  on Training is 45.640822784810126\n",
            "Epoch #0. Accuracy on batch 2370/2438  on Training is 45.64397933361451\n",
            "Epoch #0. Accuracy on batch 2371/2438  on Training is 45.64845067453626\n",
            "Epoch #0. Accuracy on batch 2372/2438  on Training is 45.65028445006321\n",
            "Epoch #0. Accuracy on batch 2373/2438  on Training is 45.65080033698399\n",
            "Epoch #0. Accuracy on batch 2374/2438  on Training is 45.65921052631579\n",
            "Epoch #0. Accuracy on batch 2375/2438  on Training is 45.658406986531986\n",
            "Epoch #0. Accuracy on batch 2376/2438  on Training is 45.6602334875894\n",
            "Epoch #0. Accuracy on batch 2377/2438  on Training is 45.663372582001685\n",
            "Epoch #0. Accuracy on batch 2378/2438  on Training is 45.66650903741068\n",
            "Epoch #0. Accuracy on batch 2379/2438  on Training is 45.67358193277311\n",
            "Batch Id 2380/2438 is having training loss of 2.4280409812927246\n",
            "1.4925237894058228\n",
            "Epoch #0. Accuracy on batch 2380/2438  on Training is 45.68327383452331\n",
            "Epoch #0. Accuracy on batch 2381/2438  on Training is 45.686397984886646\n",
            "Epoch #0. Accuracy on batch 2382/2438  on Training is 45.693453629878306\n",
            "Epoch #0. Accuracy on batch 2383/2438  on Training is 45.703125\n",
            "Epoch #0. Accuracy on batch 2384/2438  on Training is 45.706236897274636\n",
            "Epoch #0. Accuracy on batch 2385/2438  on Training is 45.715894803017605\n",
            "Epoch #0. Accuracy on batch 2386/2438  on Training is 45.7229262672811\n",
            "Epoch #0. Accuracy on batch 2387/2438  on Training is 45.723408710217754\n",
            "Epoch #0. Accuracy on batch 2388/2438  on Training is 45.729123064043534\n",
            "Epoch #0. Accuracy on batch 2389/2438  on Training is 45.73614016736402\n",
            "Epoch #0. Accuracy on batch 2390/2438  on Training is 45.736616478460896\n",
            "Epoch #0. Accuracy on batch 2391/2438  on Training is 45.731866638795985\n",
            "Epoch #0. Accuracy on batch 2392/2438  on Training is 45.73495612202257\n",
            "Epoch #0. Accuracy on batch 2393/2438  on Training is 45.73934837092732\n",
            "Epoch #0. Accuracy on batch 2394/2438  on Training is 45.74634655532359\n",
            "Epoch #0. Accuracy on batch 2395/2438  on Training is 45.74812186978297\n",
            "Epoch #0. Accuracy on batch 2396/2438  on Training is 45.75641426783479\n",
            "Epoch #0. Accuracy on batch 2397/2438  on Training is 45.76600291909925\n",
            "Epoch #0. Accuracy on batch 2398/2438  on Training is 45.77297832430179\n",
            "Epoch #0. Accuracy on batch 2399/2438  on Training is 45.779947916666664\n",
            "Batch Id 2400/2438 is having training loss of 2.4218876361846924\n",
            "1.2373188734054565\n",
            "Epoch #0. Accuracy on batch 2400/2438  on Training is 45.78821324448147\n",
            "Epoch #0. Accuracy on batch 2401/2438  on Training is 45.79126769358868\n",
            "Epoch #0. Accuracy on batch 2402/2438  on Training is 45.793019142738245\n",
            "Epoch #0. Accuracy on batch 2403/2438  on Training is 45.80256863560732\n",
            "Epoch #0. Accuracy on batch 2404/2438  on Training is 45.805613305613306\n",
            "Epoch #0. Accuracy on batch 2405/2438  on Training is 45.807356608478806\n",
            "Epoch #0. Accuracy on batch 2406/2438  on Training is 45.81429164935604\n",
            "Epoch #0. Accuracy on batch 2407/2438  on Training is 45.821220930232556\n",
            "Epoch #0. Accuracy on batch 2408/2438  on Training is 45.8255500207555\n",
            "Epoch #0. Accuracy on batch 2409/2438  on Training is 45.829875518672196\n",
            "Epoch #0. Accuracy on batch 2410/2438  on Training is 45.83549357113231\n",
            "Epoch #0. Accuracy on batch 2411/2438  on Training is 45.83851575456053\n",
            "Epoch #0. Accuracy on batch 2412/2438  on Training is 45.845420638209696\n",
            "Epoch #0. Accuracy on batch 2413/2438  on Training is 45.8523198011599\n",
            "Epoch #0. Accuracy on batch 2414/2438  on Training is 45.852743271221534\n",
            "Epoch #0. Accuracy on batch 2415/2438  on Training is 45.85704677152318\n",
            "Epoch #0. Accuracy on batch 2416/2438  on Training is 45.85100330988829\n",
            "Epoch #0. Accuracy on batch 2417/2438  on Training is 45.85788875103391\n",
            "Epoch #0. Accuracy on batch 2418/2438  on Training is 45.86089293096321\n",
            "Epoch #0. Accuracy on batch 2419/2438  on Training is 45.863894628099175\n",
            "Batch Id 2420/2438 is having training loss of 2.4166924953460693\n",
            "1.8056375980377197\n",
            "Epoch #0. Accuracy on batch 2420/2438  on Training is 45.86689384551838\n",
            "Epoch #0. Accuracy on batch 2421/2438  on Training is 45.8724710982659\n",
            "Epoch #0. Accuracy on batch 2422/2438  on Training is 45.878043747420556\n",
            "Epoch #0. Accuracy on batch 2423/2438  on Training is 45.87458745874587\n",
            "Epoch #0. Accuracy on batch 2424/2438  on Training is 45.884020618556704\n",
            "Epoch #0. Accuracy on batch 2425/2438  on Training is 45.888293487221766\n",
            "Epoch #0. Accuracy on batch 2426/2438  on Training is 45.88998763906057\n",
            "Epoch #0. Accuracy on batch 2427/2438  on Training is 45.892967462932454\n",
            "Epoch #0. Accuracy on batch 2428/2438  on Training is 45.89208522025525\n",
            "Epoch #0. Accuracy on batch 2429/2438  on Training is 45.896347736625515\n",
            "Epoch #0. Accuracy on batch 2430/2438  on Training is 45.90317770464829\n",
            "Epoch #0. Accuracy on batch 2431/2438  on Training is 45.90871710526316\n",
            "Epoch #0. Accuracy on batch 2432/2438  on Training is 45.9168207973695\n",
            "Epoch #0. Accuracy on batch 2433/2438  on Training is 45.9249178307313\n",
            "Epoch #0. Accuracy on batch 2434/2438  on Training is 45.92915811088296\n",
            "Epoch #0. Accuracy on batch 2435/2438  on Training is 45.93467775041051\n",
            "Epoch #0. Accuracy on batch 2436/2438  on Training is 45.946604431678296\n",
            "Epoch #0. Accuracy on batch 2437/2438  on Training is 45.94871794871795\n",
            "Epoch #0. Batch Id 0/278  is having validation loss of 2.0122532844543457\n",
            "2.0122532844543457\n",
            "Epoch #0. Batch Id 0/278  is having validation accuracy of 46.875\n",
            "Epoch #0. Batch Id 1/278  is having validation loss of 2.0203449726104736\n",
            "2.0284366607666016\n",
            "Epoch #0. Batch Id 1/278  is having validation accuracy of 42.1875\n",
            "Epoch #0. Batch Id 2/278  is having validation loss of 1.9140375852584839\n",
            "1.701422929763794\n",
            "Epoch #0. Batch Id 2/278  is having validation accuracy of 45.833333333333336\n",
            "Epoch #0. Batch Id 3/278  is having validation loss of 1.7918701171875\n",
            "1.4253674745559692\n",
            "Epoch #0. Batch Id 3/278  is having validation accuracy of 50.78125\n",
            "Epoch #0. Batch Id 4/278  is having validation loss of 2.0089662075042725\n",
            "2.877350330352783\n",
            "Epoch #0. Batch Id 4/278  is having validation accuracy of 46.25\n",
            "Epoch #0. Batch Id 5/278  is having validation loss of 2.0163426399230957\n",
            "2.0532240867614746\n",
            "Epoch #0. Batch Id 5/278  is having validation accuracy of 48.958333333333336\n",
            "Epoch #0. Batch Id 6/278  is having validation loss of 2.0202038288116455\n",
            "2.0433716773986816\n",
            "Epoch #0. Batch Id 6/278  is having validation accuracy of 49.55357142857143\n",
            "Epoch #0. Batch Id 7/278  is having validation loss of 2.036571741104126\n",
            "2.1511478424072266\n",
            "Epoch #0. Batch Id 7/278  is having validation accuracy of 50.0\n",
            "Epoch #0. Batch Id 8/278  is having validation loss of 2.0148377418518066\n",
            "1.8409652709960938\n",
            "Epoch #0. Batch Id 8/278  is having validation accuracy of 48.958333333333336\n",
            "Epoch #0. Batch Id 9/278  is having validation loss of 1.968002200126648\n",
            "1.5464822053909302\n",
            "Epoch #0. Batch Id 9/278  is having validation accuracy of 50.0\n",
            "Epoch #0. Batch Id 10/278  is having validation loss of 1.9574880599975586\n",
            "1.8523463010787964\n",
            "Epoch #0. Batch Id 10/278  is having validation accuracy of 49.14772727272727\n",
            "Epoch #0. Batch Id 11/278  is having validation loss of 1.9451467990875244\n",
            "1.8093931674957275\n",
            "Epoch #0. Batch Id 11/278  is having validation accuracy of 49.479166666666664\n",
            "Epoch #0. Batch Id 12/278  is having validation loss of 1.9510986804962158\n",
            "2.0225212574005127\n",
            "Epoch #0. Batch Id 12/278  is having validation accuracy of 49.75961538461539\n",
            "Epoch #0. Batch Id 13/278  is having validation loss of 1.9625563621520996\n",
            "2.111506462097168\n",
            "Epoch #0. Batch Id 13/278  is having validation accuracy of 49.330357142857146\n",
            "Epoch #0. Batch Id 14/278  is having validation loss of 1.9488636255264282\n",
            "1.7571654319763184\n",
            "Epoch #0. Batch Id 14/278  is having validation accuracy of 50.416666666666664\n",
            "Epoch #0. Batch Id 15/278  is having validation loss of 1.965601921081543\n",
            "2.2166759967803955\n",
            "Epoch #0. Batch Id 15/278  is having validation accuracy of 50.1953125\n",
            "Epoch #0. Batch Id 16/278  is having validation loss of 1.9780449867248535\n",
            "2.177133560180664\n",
            "Epoch #0. Batch Id 16/278  is having validation accuracy of 50.36764705882353\n",
            "Epoch #0. Batch Id 17/278  is having validation loss of 1.984315276145935\n",
            "2.090909957885742\n",
            "Epoch #0. Batch Id 17/278  is having validation accuracy of 50.173611111111114\n",
            "Epoch #0. Batch Id 18/278  is having validation loss of 1.98457932472229\n",
            "1.9893312454223633\n",
            "Epoch #0. Batch Id 18/278  is having validation accuracy of 50.328947368421055\n",
            "Epoch #0. Batch Id 19/278  is having validation loss of 1.9889427423477173\n",
            "2.071847438812256\n",
            "Epoch #0. Batch Id 19/278  is having validation accuracy of 50.0\n",
            "Epoch #0. Batch Id 20/278  is having validation loss of 1.9841614961624146\n",
            "1.8885362148284912\n",
            "Epoch #0. Batch Id 20/278  is having validation accuracy of 49.851190476190474\n",
            "Epoch #0. Batch Id 21/278  is having validation loss of 1.9844157695770264\n",
            "1.989754319190979\n",
            "Epoch #0. Batch Id 21/278  is having validation accuracy of 49.85795454545455\n",
            "Epoch #0. Batch Id 22/278  is having validation loss of 1.95182466506958\n",
            "1.2348194122314453\n",
            "Epoch #0. Batch Id 22/278  is having validation accuracy of 50.95108695652174\n",
            "Epoch #0. Batch Id 23/278  is having validation loss of 1.9592684507369995\n",
            "2.130476474761963\n",
            "Epoch #0. Batch Id 23/278  is having validation accuracy of 50.78125\n",
            "Epoch #0. Batch Id 24/278  is having validation loss of 1.9417617321014404\n",
            "1.5215991735458374\n",
            "Epoch #0. Batch Id 24/278  is having validation accuracy of 51.375\n",
            "Epoch #0. Batch Id 25/278  is having validation loss of 1.95562744140625\n",
            "2.3022687435150146\n",
            "Epoch #0. Batch Id 25/278  is having validation accuracy of 51.08173076923077\n",
            "Epoch #0. Batch Id 26/278  is having validation loss of 1.964034080505371\n",
            "2.1826064586639404\n",
            "Epoch #0. Batch Id 26/278  is having validation accuracy of 50.5787037037037\n",
            "Epoch #0. Batch Id 27/278  is having validation loss of 1.9658535718917847\n",
            "2.0149807929992676\n",
            "Epoch #0. Batch Id 27/278  is having validation accuracy of 50.78125\n",
            "Epoch #0. Batch Id 28/278  is having validation loss of 1.9833076000213623\n",
            "2.4720211029052734\n",
            "Epoch #0. Batch Id 28/278  is having validation accuracy of 50.43103448275862\n",
            "Epoch #0. Batch Id 29/278  is having validation loss of 1.9894510507583618\n",
            "2.1676108837127686\n",
            "Epoch #0. Batch Id 29/278  is having validation accuracy of 50.0\n",
            "Epoch #0. Batch Id 30/278  is having validation loss of 1.988226056098938\n",
            "1.9514747858047485\n",
            "Epoch #0. Batch Id 30/278  is having validation accuracy of 50.0\n",
            "Epoch #0. Batch Id 31/278  is having validation loss of 1.9925856590270996\n",
            "2.1277315616607666\n",
            "Epoch #0. Batch Id 31/278  is having validation accuracy of 50.09765625\n",
            "Epoch #0. Batch Id 32/278  is having validation loss of 1.9984663724899292\n",
            "2.186650037765503\n",
            "Epoch #0. Batch Id 32/278  is having validation accuracy of 50.0\n",
            "Epoch #0. Batch Id 33/278  is having validation loss of 1.9974150657653809\n",
            "1.9627209901809692\n",
            "Epoch #0. Batch Id 33/278  is having validation accuracy of 49.81617647058823\n",
            "Epoch #0. Batch Id 34/278  is having validation loss of 2.0126378536224365\n",
            "2.530212163925171\n",
            "Epoch #0. Batch Id 34/278  is having validation accuracy of 49.19642857142857\n",
            "Epoch #0. Batch Id 35/278  is having validation loss of 2.006950616836548\n",
            "1.807900309562683\n",
            "Epoch #0. Batch Id 35/278  is having validation accuracy of 49.739583333333336\n",
            "Epoch #0. Batch Id 36/278  is having validation loss of 2.0013844966888428\n",
            "1.8010084629058838\n",
            "Epoch #0. Batch Id 36/278  is having validation accuracy of 49.74662162162162\n",
            "Epoch #0. Batch Id 37/278  is having validation loss of 1.9984183311462402\n",
            "1.8886717557907104\n",
            "Epoch #0. Batch Id 37/278  is having validation accuracy of 49.588815789473685\n",
            "Epoch #0. Batch Id 38/278  is having validation loss of 1.9974327087402344\n",
            "1.9599804878234863\n",
            "Epoch #0. Batch Id 38/278  is having validation accuracy of 49.919871794871796\n",
            "Epoch #0. Batch Id 39/278  is having validation loss of 1.9955030679702759\n",
            "1.9202457666397095\n",
            "Epoch #0. Batch Id 39/278  is having validation accuracy of 49.921875\n",
            "Epoch #0. Batch Id 40/278  is having validation loss of 1.997483491897583\n",
            "2.076700448989868\n",
            "Epoch #0. Batch Id 40/278  is having validation accuracy of 50.076219512195124\n",
            "Epoch #0. Batch Id 41/278  is having validation loss of 2.0053789615631104\n",
            "2.3290939331054688\n",
            "Epoch #0. Batch Id 41/278  is having validation accuracy of 49.851190476190474\n",
            "Epoch #0. Batch Id 42/278  is having validation loss of 1.9999052286148071\n",
            "1.7700084447860718\n",
            "Epoch #0. Batch Id 42/278  is having validation accuracy of 49.92732558139535\n",
            "Epoch #0. Batch Id 43/278  is having validation loss of 1.9925615787506104\n",
            "1.676783561706543\n",
            "Epoch #0. Batch Id 43/278  is having validation accuracy of 50.14204545454545\n",
            "Epoch #0. Batch Id 44/278  is having validation loss of 1.9934841394424438\n",
            "2.034078359603882\n",
            "Epoch #0. Batch Id 44/278  is having validation accuracy of 50.138888888888886\n",
            "Epoch #0. Batch Id 45/278  is having validation loss of 1.9980134963989258\n",
            "2.201836585998535\n",
            "Epoch #0. Batch Id 45/278  is having validation accuracy of 50.0\n",
            "Epoch #0. Batch Id 46/278  is having validation loss of 1.9930223226547241\n",
            "1.7634304761886597\n",
            "Epoch #0. Batch Id 46/278  is having validation accuracy of 50.13297872340426\n",
            "Epoch #0. Batch Id 47/278  is having validation loss of 1.990761637687683\n",
            "1.884511947631836\n",
            "Epoch #0. Batch Id 47/278  is having validation accuracy of 50.1953125\n",
            "Epoch #0. Batch Id 48/278  is having validation loss of 1.9856235980987549\n",
            "1.738994836807251\n",
            "Epoch #0. Batch Id 48/278  is having validation accuracy of 50.38265306122449\n",
            "Epoch #0. Batch Id 49/278  is having validation loss of 1.9879212379455566\n",
            "2.1005055904388428\n",
            "Epoch #0. Batch Id 49/278  is having validation accuracy of 50.375\n",
            "Epoch #0. Batch Id 50/278  is having validation loss of 1.980252981185913\n",
            "1.5968416929244995\n",
            "Epoch #0. Batch Id 50/278  is having validation accuracy of 50.42892156862745\n",
            "Epoch #0. Batch Id 51/278  is having validation loss of 1.976550579071045\n",
            "1.7877267599105835\n",
            "Epoch #0. Batch Id 51/278  is having validation accuracy of 50.54086538461539\n",
            "Epoch #0. Batch Id 52/278  is having validation loss of 1.9749454259872437\n",
            "1.8914774656295776\n",
            "Epoch #0. Batch Id 52/278  is having validation accuracy of 50.64858490566038\n",
            "Epoch #0. Batch Id 53/278  is having validation loss of 1.977541208267212\n",
            "2.1151185035705566\n",
            "Epoch #0. Batch Id 53/278  is having validation accuracy of 50.5787037037037\n",
            "Epoch #0. Batch Id 54/278  is having validation loss of 1.980666160583496\n",
            "2.149416208267212\n",
            "Epoch #0. Batch Id 54/278  is having validation accuracy of 50.28409090909091\n",
            "Epoch #0. Batch Id 55/278  is having validation loss of 1.983266830444336\n",
            "2.1263067722320557\n",
            "Epoch #0. Batch Id 55/278  is having validation accuracy of 50.223214285714285\n",
            "Epoch #0. Batch Id 56/278  is having validation loss of 1.9877876043319702\n",
            "2.240950584411621\n",
            "Epoch #0. Batch Id 56/278  is having validation accuracy of 49.94517543859649\n",
            "Epoch #0. Batch Id 57/278  is having validation loss of 1.978572964668274\n",
            "1.4533417224884033\n",
            "Epoch #0. Batch Id 57/278  is having validation accuracy of 50.269396551724135\n",
            "Epoch #0. Batch Id 58/278  is having validation loss of 1.9841580390930176\n",
            "2.308091878890991\n",
            "Epoch #0. Batch Id 58/278  is having validation accuracy of 50.0\n",
            "Epoch #0. Batch Id 59/278  is having validation loss of 1.9833869934082031\n",
            "1.9378948211669922\n",
            "Epoch #0. Batch Id 59/278  is having validation accuracy of 50.0\n",
            "Epoch #0. Batch Id 60/278  is having validation loss of 1.9796617031097412\n",
            "1.7561465501785278\n",
            "Epoch #0. Batch Id 60/278  is having validation accuracy of 50.10245901639344\n",
            "Epoch #0. Batch Id 61/278  is having validation loss of 1.9803169965744019\n",
            "2.0202863216400146\n",
            "Epoch #0. Batch Id 61/278  is having validation accuracy of 50.252016129032256\n",
            "Epoch #0. Batch Id 62/278  is having validation loss of 1.9754332304000854\n",
            "1.6726380586624146\n",
            "Epoch #0. Batch Id 62/278  is having validation accuracy of 50.49603174603175\n",
            "Epoch #0. Batch Id 63/278  is having validation loss of 1.9793400764465332\n",
            "2.2254748344421387\n",
            "Epoch #0. Batch Id 63/278  is having validation accuracy of 50.390625\n",
            "Epoch #0. Batch Id 64/278  is having validation loss of 1.98345947265625\n",
            "2.2471022605895996\n",
            "Epoch #0. Batch Id 64/278  is having validation accuracy of 50.28846153846154\n",
            "Epoch #0. Batch Id 65/278  is having validation loss of 1.9793224334716797\n",
            "1.7104146480560303\n",
            "Epoch #0. Batch Id 65/278  is having validation accuracy of 50.47348484848485\n",
            "Epoch #0. Batch Id 66/278  is having validation loss of 1.9772473573684692\n",
            "1.8402884006500244\n",
            "Epoch #0. Batch Id 66/278  is having validation accuracy of 50.37313432835821\n",
            "Epoch #0. Batch Id 67/278  is having validation loss of 1.9779397249221802\n",
            "2.024331569671631\n",
            "Epoch #0. Batch Id 67/278  is having validation accuracy of 50.137867647058826\n",
            "Epoch #0. Batch Id 68/278  is having validation loss of 1.9699296951293945\n",
            "1.425247073173523\n",
            "Epoch #0. Batch Id 68/278  is having validation accuracy of 50.45289855072464\n",
            "Epoch #0. Batch Id 69/278  is having validation loss of 1.9698073863983154\n",
            "1.9613679647445679\n",
            "Epoch #0. Batch Id 69/278  is having validation accuracy of 50.3125\n",
            "Epoch #0. Batch Id 70/278  is having validation loss of 1.9748318195343018\n",
            "2.3265395164489746\n",
            "Epoch #0. Batch Id 70/278  is having validation accuracy of 50.04401408450704\n",
            "Epoch #0. Batch Id 71/278  is having validation loss of 1.965181589126587\n",
            "1.2800164222717285\n",
            "Epoch #0. Batch Id 71/278  is having validation accuracy of 50.260416666666664\n",
            "Epoch #0. Batch Id 72/278  is having validation loss of 1.970782995223999\n",
            "2.374080181121826\n",
            "Epoch #0. Batch Id 72/278  is having validation accuracy of 50.08561643835616\n",
            "Epoch #0. Batch Id 73/278  is having validation loss of 1.9711560010910034\n",
            "1.998386025428772\n",
            "Epoch #0. Batch Id 73/278  is having validation accuracy of 50.126689189189186\n",
            "Epoch #0. Batch Id 74/278  is having validation loss of 1.971775770187378\n",
            "2.0176427364349365\n",
            "Epoch #0. Batch Id 74/278  is having validation accuracy of 50.166666666666664\n",
            "Epoch #0. Batch Id 75/278  is having validation loss of 1.9704349040985107\n",
            "1.8698694705963135\n",
            "Epoch #0. Batch Id 75/278  is having validation accuracy of 50.28782894736842\n",
            "Epoch #0. Batch Id 76/278  is having validation loss of 1.9751808643341064\n",
            "2.335871696472168\n",
            "Epoch #0. Batch Id 76/278  is having validation accuracy of 50.121753246753244\n",
            "Epoch #0. Batch Id 77/278  is having validation loss of 1.9730634689331055\n",
            "1.8100237846374512\n",
            "Epoch #0. Batch Id 77/278  is having validation accuracy of 50.24038461538461\n",
            "Epoch #0. Batch Id 78/278  is having validation loss of 1.9721579551696777\n",
            "1.901524543762207\n",
            "Epoch #0. Batch Id 78/278  is having validation accuracy of 50.15822784810127\n",
            "Epoch #0. Batch Id 79/278  is having validation loss of 1.972471833229065\n",
            "1.9972642660140991\n",
            "Epoch #0. Batch Id 79/278  is having validation accuracy of 50.0390625\n",
            "Epoch #0. Batch Id 80/278  is having validation loss of 1.9805067777633667\n",
            "2.6233036518096924\n",
            "Epoch #0. Batch Id 80/278  is having validation accuracy of 49.92283950617284\n",
            "Epoch #0. Batch Id 81/278  is having validation loss of 1.9825820922851562\n",
            "2.1506848335266113\n",
            "Epoch #0. Batch Id 81/278  is having validation accuracy of 49.84756097560975\n",
            "Epoch #0. Batch Id 82/278  is having validation loss of 1.98677659034729\n",
            "2.3307251930236816\n",
            "Epoch #0. Batch Id 82/278  is having validation accuracy of 49.69879518072289\n",
            "Epoch #0. Batch Id 83/278  is having validation loss of 1.9859564304351807\n",
            "1.9178828001022339\n",
            "Epoch #0. Batch Id 83/278  is having validation accuracy of 49.739583333333336\n",
            "Epoch #0. Batch Id 84/278  is having validation loss of 1.9857813119888306\n",
            "1.971070408821106\n",
            "Epoch #0. Batch Id 84/278  is having validation accuracy of 49.81617647058823\n",
            "Epoch #0. Batch Id 85/278  is having validation loss of 1.9851628541946411\n",
            "1.9325898885726929\n",
            "Epoch #0. Batch Id 85/278  is having validation accuracy of 49.89098837209303\n",
            "Epoch #0. Batch Id 86/278  is having validation loss of 1.9894570112228394\n",
            "2.358750104904175\n",
            "Epoch #0. Batch Id 86/278  is having validation accuracy of 49.820402298850574\n",
            "Epoch #0. Batch Id 87/278  is having validation loss of 1.9877631664276123\n",
            "1.840394377708435\n",
            "Epoch #0. Batch Id 87/278  is having validation accuracy of 49.92897727272727\n",
            "Epoch #0. Batch Id 88/278  is having validation loss of 1.9940779209136963\n",
            "2.5497798919677734\n",
            "Epoch #0. Batch Id 88/278  is having validation accuracy of 49.64887640449438\n",
            "Epoch #0. Batch Id 89/278  is having validation loss of 1.9914220571517944\n",
            "1.7550508975982666\n",
            "Epoch #0. Batch Id 89/278  is having validation accuracy of 49.72222222222222\n",
            "Epoch #0. Batch Id 90/278  is having validation loss of 1.988200306892395\n",
            "1.6982446908950806\n",
            "Epoch #0. Batch Id 90/278  is having validation accuracy of 49.793956043956044\n",
            "Epoch #0. Batch Id 91/278  is having validation loss of 1.987341046333313\n",
            "1.9091514348983765\n",
            "Epoch #0. Batch Id 91/278  is having validation accuracy of 49.89809782608695\n",
            "Epoch #0. Batch Id 92/278  is having validation loss of 1.9867881536483765\n",
            "1.9359174966812134\n",
            "Epoch #0. Batch Id 92/278  is having validation accuracy of 49.79838709677419\n",
            "Epoch #0. Batch Id 93/278  is having validation loss of 1.9831702709197998\n",
            "1.646710991859436\n",
            "Epoch #0. Batch Id 93/278  is having validation accuracy of 49.83377659574468\n",
            "Epoch #0. Batch Id 94/278  is having validation loss of 1.980112910270691\n",
            "1.6927204132080078\n",
            "Epoch #0. Batch Id 94/278  is having validation accuracy of 49.86842105263158\n",
            "Epoch #0. Batch Id 95/278  is having validation loss of 1.9794962406158447\n",
            "1.9209076166152954\n",
            "Epoch #0. Batch Id 95/278  is having validation accuracy of 49.90234375\n",
            "Epoch #0. Batch Id 96/278  is having validation loss of 1.9817936420440674\n",
            "2.2023420333862305\n",
            "Epoch #0. Batch Id 96/278  is having validation accuracy of 49.80670103092783\n",
            "Epoch #0. Batch Id 97/278  is having validation loss of 1.9828590154647827\n",
            "2.0861997604370117\n",
            "Epoch #0. Batch Id 97/278  is having validation accuracy of 49.744897959183675\n",
            "Epoch #0. Batch Id 98/278  is having validation loss of 1.9836397171020508\n",
            "2.0601465702056885\n",
            "Epoch #0. Batch Id 98/278  is having validation accuracy of 49.68434343434343\n",
            "Epoch #0. Batch Id 99/278  is having validation loss of 1.9812902212142944\n",
            "1.748694896697998\n",
            "Epoch #0. Batch Id 99/278  is having validation accuracy of 49.78125\n",
            "Epoch #0. Batch Id 100/278  is having validation loss of 1.9828078746795654\n",
            "2.1345672607421875\n",
            "Epoch #0. Batch Id 100/278  is having validation accuracy of 49.65965346534654\n",
            "Epoch #0. Batch Id 101/278  is having validation loss of 1.9849411249160767\n",
            "2.2003960609436035\n",
            "Epoch #0. Batch Id 101/278  is having validation accuracy of 49.60171568627451\n",
            "Epoch #0. Batch Id 102/278  is having validation loss of 1.9807225465774536\n",
            "1.550423264503479\n",
            "Epoch #0. Batch Id 102/278  is having validation accuracy of 49.726941747572816\n",
            "Epoch #0. Batch Id 103/278  is having validation loss of 1.9823517799377441\n",
            "2.1501684188842773\n",
            "Epoch #0. Batch Id 103/278  is having validation accuracy of 49.72956730769231\n",
            "Epoch #0. Batch Id 104/278  is having validation loss of 1.9816581010818481\n",
            "1.9095157384872437\n",
            "Epoch #0. Batch Id 104/278  is having validation accuracy of 49.55357142857143\n",
            "Epoch #0. Batch Id 105/278  is having validation loss of 1.9773842096328735\n",
            "1.5286202430725098\n",
            "Epoch #0. Batch Id 105/278  is having validation accuracy of 49.5872641509434\n",
            "Epoch #0. Batch Id 106/278  is having validation loss of 1.9747041463851929\n",
            "1.6906195878982544\n",
            "Epoch #0. Batch Id 106/278  is having validation accuracy of 49.70794392523364\n",
            "Epoch #0. Batch Id 107/278  is having validation loss of 1.9711799621582031\n",
            "1.5940979719161987\n",
            "Epoch #0. Batch Id 107/278  is having validation accuracy of 49.855324074074076\n",
            "Epoch #0. Batch Id 108/278  is having validation loss of 1.9721705913543701\n",
            "2.0791637897491455\n",
            "Epoch #0. Batch Id 108/278  is having validation accuracy of 49.799311926605505\n",
            "Epoch #0. Batch Id 109/278  is having validation loss of 1.9727038145065308\n",
            "2.030824661254883\n",
            "Epoch #0. Batch Id 109/278  is having validation accuracy of 49.71590909090909\n",
            "Epoch #0. Batch Id 110/278  is having validation loss of 1.9675202369689941\n",
            "1.397328495979309\n",
            "Epoch #0. Batch Id 110/278  is having validation accuracy of 49.77477477477478\n",
            "Epoch #0. Batch Id 111/278  is having validation loss of 1.9642537832260132\n",
            "1.6016772985458374\n",
            "Epoch #0. Batch Id 111/278  is having validation accuracy of 49.888392857142854\n",
            "Epoch #0. Batch Id 112/278  is having validation loss of 1.965323805809021\n",
            "2.0851662158966064\n",
            "Epoch #0. Batch Id 112/278  is having validation accuracy of 49.86172566371681\n",
            "Epoch #0. Batch Id 113/278  is having validation loss of 1.964035987854004\n",
            "1.8185076713562012\n",
            "Epoch #0. Batch Id 113/278  is having validation accuracy of 49.862938596491226\n",
            "Epoch #0. Batch Id 114/278  is having validation loss of 1.9673895835876465\n",
            "2.349703788757324\n",
            "Epoch #0. Batch Id 114/278  is having validation accuracy of 49.78260869565217\n",
            "Epoch #0. Batch Id 115/278  is having validation loss of 1.9694775342941284\n",
            "2.209592819213867\n",
            "Epoch #0. Batch Id 115/278  is having validation accuracy of 49.730603448275865\n",
            "Epoch #0. Batch Id 116/278  is having validation loss of 1.9734082221984863\n",
            "2.4293675422668457\n",
            "Epoch #0. Batch Id 116/278  is having validation accuracy of 49.626068376068375\n",
            "Epoch #0. Batch Id 117/278  is having validation loss of 1.9737846851348877\n",
            "2.0178298950195312\n",
            "Epoch #0. Batch Id 117/278  is having validation accuracy of 49.682203389830505\n",
            "Epoch #0. Batch Id 118/278  is having validation loss of 1.974287748336792\n",
            "2.0336527824401855\n",
            "Epoch #0. Batch Id 118/278  is having validation accuracy of 49.65861344537815\n",
            "Epoch #0. Batch Id 119/278  is having validation loss of 1.9738901853561401\n",
            "1.9265795946121216\n",
            "Epoch #0. Batch Id 119/278  is having validation accuracy of 49.6875\n",
            "Epoch #0. Batch Id 120/278  is having validation loss of 1.9721709489822388\n",
            "1.7658694982528687\n",
            "Epoch #0. Batch Id 120/278  is having validation accuracy of 49.6900826446281\n",
            "Epoch #0. Batch Id 121/278  is having validation loss of 1.9728864431381226\n",
            "2.059464693069458\n",
            "Epoch #0. Batch Id 121/278  is having validation accuracy of 49.64139344262295\n",
            "Epoch #0. Batch Id 122/278  is having validation loss of 1.9747450351715088\n",
            "2.2014920711517334\n",
            "Epoch #0. Batch Id 122/278  is having validation accuracy of 49.61890243902439\n",
            "Epoch #0. Batch Id 123/278  is having validation loss of 1.978318452835083\n",
            "2.4178547859191895\n",
            "Epoch #0. Batch Id 123/278  is having validation accuracy of 49.546370967741936\n",
            "Epoch #0. Batch Id 124/278  is having validation loss of 1.9777092933654785\n",
            "1.9021718502044678\n",
            "Epoch #0. Batch Id 124/278  is having validation accuracy of 49.6\n",
            "Epoch #0. Batch Id 125/278  is having validation loss of 1.9754756689071655\n",
            "1.6962765455245972\n",
            "Epoch #0. Batch Id 125/278  is having validation accuracy of 49.67757936507937\n",
            "Epoch #0. Batch Id 126/278  is having validation loss of 1.972625970840454\n",
            "1.6135703325271606\n",
            "Epoch #0. Batch Id 126/278  is having validation accuracy of 49.70472440944882\n",
            "Epoch #0. Batch Id 127/278  is having validation loss of 1.972330927848816\n",
            "1.9348539113998413\n",
            "Epoch #0. Batch Id 127/278  is having validation accuracy of 49.658203125\n",
            "Epoch #0. Batch Id 128/278  is having validation loss of 1.9707823991775513\n",
            "1.7725648880004883\n",
            "Epoch #0. Batch Id 128/278  is having validation accuracy of 49.7093023255814\n",
            "Epoch #0. Batch Id 129/278  is having validation loss of 1.9684842824935913\n",
            "1.6720257997512817\n",
            "Epoch #0. Batch Id 129/278  is having validation accuracy of 49.73557692307692\n",
            "Epoch #0. Batch Id 130/278  is having validation loss of 1.9637925624847412\n",
            "1.3538621664047241\n",
            "Epoch #0. Batch Id 130/278  is having validation accuracy of 49.8807251908397\n",
            "Epoch #0. Batch Id 131/278  is having validation loss of 1.9652384519577026\n",
            "2.1546528339385986\n",
            "Epoch #0. Batch Id 131/278  is having validation accuracy of 49.90530303030303\n",
            "Epoch #0. Batch Id 132/278  is having validation loss of 1.9652751684188843\n",
            "1.9701251983642578\n",
            "Epoch #0. Batch Id 132/278  is having validation accuracy of 49.88251879699248\n",
            "Epoch #0. Batch Id 133/278  is having validation loss of 1.9675912857055664\n",
            "2.275636672973633\n",
            "Epoch #0. Batch Id 133/278  is having validation accuracy of 49.8134328358209\n",
            "Epoch #0. Batch Id 134/278  is having validation loss of 1.9707425832748413\n",
            "2.3930182456970215\n",
            "Epoch #0. Batch Id 134/278  is having validation accuracy of 49.745370370370374\n",
            "Epoch #0. Batch Id 135/278  is having validation loss of 1.9733455181121826\n",
            "2.324737787246704\n",
            "Epoch #0. Batch Id 135/278  is having validation accuracy of 49.56341911764706\n",
            "Epoch #0. Batch Id 136/278  is having validation loss of 1.9729729890823364\n",
            "1.9223051071166992\n",
            "Epoch #0. Batch Id 136/278  is having validation accuracy of 49.63503649635037\n",
            "Epoch #0. Batch Id 137/278  is having validation loss of 1.9736793041229248\n",
            "2.070444107055664\n",
            "Epoch #0. Batch Id 137/278  is having validation accuracy of 49.569746376811594\n",
            "Epoch #0. Batch Id 138/278  is having validation loss of 1.9720418453216553\n",
            "1.7460792064666748\n",
            "Epoch #0. Batch Id 138/278  is having validation accuracy of 49.617805755395686\n",
            "Epoch #0. Batch Id 139/278  is having validation loss of 1.9715403318405151\n",
            "1.901825189590454\n",
            "Epoch #0. Batch Id 139/278  is having validation accuracy of 49.642857142857146\n",
            "Epoch #0. Batch Id 140/278  is having validation loss of 1.9712244272232056\n",
            "1.9269994497299194\n",
            "Epoch #0. Batch Id 140/278  is having validation accuracy of 49.55673758865248\n",
            "Epoch #0. Batch Id 141/278  is having validation loss of 1.9706244468688965\n",
            "1.886031985282898\n",
            "Epoch #0. Batch Id 141/278  is having validation accuracy of 49.581866197183096\n",
            "Epoch #0. Batch Id 142/278  is having validation loss of 1.968400001525879\n",
            "1.6525304317474365\n",
            "Epoch #0. Batch Id 142/278  is having validation accuracy of 49.60664335664335\n",
            "Epoch #0. Batch Id 143/278  is having validation loss of 1.9687702655792236\n",
            "2.021721601486206\n",
            "Epoch #0. Batch Id 143/278  is having validation accuracy of 49.52256944444444\n",
            "Epoch #0. Batch Id 144/278  is having validation loss of 1.969955563545227\n",
            "2.1406402587890625\n",
            "Epoch #0. Batch Id 144/278  is having validation accuracy of 49.525862068965516\n",
            "Epoch #0. Batch Id 145/278  is having validation loss of 1.9698705673217773\n",
            "1.9575488567352295\n",
            "Epoch #0. Batch Id 145/278  is having validation accuracy of 49.486301369863014\n",
            "Epoch #0. Batch Id 146/278  is having validation loss of 1.9682503938674927\n",
            "1.7317034006118774\n",
            "Epoch #0. Batch Id 146/278  is having validation accuracy of 49.53231292517007\n",
            "Epoch #0. Batch Id 147/278  is having validation loss of 1.9688011407852173\n",
            "2.04976749420166\n",
            "Epoch #0. Batch Id 147/278  is having validation accuracy of 49.55658783783784\n",
            "Epoch #0. Batch Id 148/278  is having validation loss of 1.969520092010498\n",
            "2.0759241580963135\n",
            "Epoch #0. Batch Id 148/278  is having validation accuracy of 49.475671140939596\n",
            "Epoch #0. Batch Id 149/278  is having validation loss of 1.9721360206604004\n",
            "2.3619139194488525\n",
            "Epoch #0. Batch Id 149/278  is having validation accuracy of 49.395833333333336\n",
            "Epoch #0. Batch Id 150/278  is having validation loss of 1.972220540046692\n",
            "1.984904408454895\n",
            "Epoch #0. Batch Id 150/278  is having validation accuracy of 49.35844370860927\n",
            "Epoch #0. Batch Id 151/278  is having validation loss of 1.9740525484085083\n",
            "2.250681161880493\n",
            "Epoch #0. Batch Id 151/278  is having validation accuracy of 49.30098684210526\n",
            "Epoch #0. Batch Id 152/278  is having validation loss of 1.9753546714782715\n",
            "2.173283338546753\n",
            "Epoch #0. Batch Id 152/278  is having validation accuracy of 49.28513071895425\n",
            "Epoch #0. Batch Id 153/278  is having validation loss of 1.97510826587677\n",
            "1.9374061822891235\n",
            "Epoch #0. Batch Id 153/278  is having validation accuracy of 49.249188311688314\n",
            "Epoch #0. Batch Id 154/278  is having validation loss of 1.9794659614562988\n",
            "2.6505563259124756\n",
            "Epoch #0. Batch Id 154/278  is having validation accuracy of 49.17338709677419\n",
            "Epoch #0. Batch Id 155/278  is having validation loss of 1.978407621383667\n",
            "1.8143736124038696\n",
            "Epoch #0. Batch Id 155/278  is having validation accuracy of 49.1786858974359\n",
            "Epoch #0. Batch Id 156/278  is having validation loss of 1.9794179201126099\n",
            "2.1370224952697754\n",
            "Epoch #0. Batch Id 156/278  is having validation accuracy of 49.12420382165605\n",
            "Epoch #0. Batch Id 157/278  is having validation loss of 1.979931116104126\n",
            "2.0604982376098633\n",
            "Epoch #0. Batch Id 157/278  is having validation accuracy of 49.09018987341772\n",
            "Epoch #0. Batch Id 158/278  is having validation loss of 1.9808156490325928\n",
            "2.120567798614502\n",
            "Epoch #0. Batch Id 158/278  is having validation accuracy of 49.174528301886795\n",
            "Epoch #0. Batch Id 159/278  is having validation loss of 1.9812041521072388\n",
            "2.042980194091797\n",
            "Epoch #0. Batch Id 159/278  is having validation accuracy of 49.23828125\n",
            "Epoch #0. Batch Id 160/278  is having validation loss of 1.9821521043777466\n",
            "2.1338207721710205\n",
            "Epoch #0. Batch Id 160/278  is having validation accuracy of 49.24301242236025\n",
            "Epoch #0. Batch Id 161/278  is having validation loss of 1.983404278755188\n",
            "2.1850080490112305\n",
            "Epoch #0. Batch Id 161/278  is having validation accuracy of 49.18981481481482\n",
            "Epoch #0. Batch Id 162/278  is having validation loss of 1.9824883937835693\n",
            "1.8341115713119507\n",
            "Epoch #0. Batch Id 162/278  is having validation accuracy of 49.27147239263804\n",
            "Epoch #0. Batch Id 163/278  is having validation loss of 1.9815622568130493\n",
            "1.830601692199707\n",
            "Epoch #0. Batch Id 163/278  is having validation accuracy of 49.3140243902439\n",
            "Epoch #0. Batch Id 164/278  is having validation loss of 1.9835788011550903\n",
            "2.3142919540405273\n",
            "Epoch #0. Batch Id 164/278  is having validation accuracy of 49.28030303030303\n",
            "Epoch #0. Batch Id 165/278  is having validation loss of 1.982923150062561\n",
            "1.8747429847717285\n",
            "Epoch #0. Batch Id 165/278  is having validation accuracy of 49.3222891566265\n",
            "Epoch #0. Batch Id 166/278  is having validation loss of 1.981227993965149\n",
            "1.6998224258422852\n",
            "Epoch #0. Batch Id 166/278  is having validation accuracy of 49.36377245508982\n",
            "Epoch #0. Batch Id 167/278  is having validation loss of 1.9812061786651611\n",
            "1.9775655269622803\n",
            "Epoch #0. Batch Id 167/278  is having validation accuracy of 49.29315476190476\n",
            "Epoch #0. Batch Id 168/278  is having validation loss of 1.9790050983428955\n",
            "1.6092150211334229\n",
            "Epoch #0. Batch Id 168/278  is having validation accuracy of 49.389792899408285\n",
            "Epoch #0. Batch Id 169/278  is having validation loss of 1.9793733358383179\n",
            "2.0416102409362793\n",
            "Epoch #0. Batch Id 169/278  is having validation accuracy of 49.43014705882353\n",
            "Epoch #0. Batch Id 170/278  is having validation loss of 1.981305718421936\n",
            "2.3098180294036865\n",
            "Epoch #0. Batch Id 170/278  is having validation accuracy of 49.37865497076023\n",
            "Epoch #0. Batch Id 171/278  is having validation loss of 1.9833600521087646\n",
            "2.334645986557007\n",
            "Epoch #0. Batch Id 171/278  is having validation accuracy of 49.309593023255815\n",
            "Epoch #0. Batch Id 172/278  is having validation loss of 1.9810763597488403\n",
            "1.5882915258407593\n",
            "Epoch #0. Batch Id 172/278  is having validation accuracy of 49.38583815028902\n",
            "Epoch #0. Batch Id 173/278  is having validation loss of 1.9803235530853271\n",
            "1.8500806093215942\n",
            "Epoch #0. Batch Id 173/278  is having validation accuracy of 49.44324712643678\n",
            "Epoch #0. Batch Id 174/278  is having validation loss of 1.9821085929870605\n",
            "2.2927072048187256\n",
            "Epoch #0. Batch Id 174/278  is having validation accuracy of 49.44642857142857\n",
            "Epoch #0. Batch Id 175/278  is having validation loss of 1.9820650815963745\n",
            "1.9744553565979004\n",
            "Epoch #0. Batch Id 175/278  is having validation accuracy of 49.44957386363637\n",
            "Epoch #0. Batch Id 176/278  is having validation loss of 1.9807229042053223\n",
            "1.7445039749145508\n",
            "Epoch #0. Batch Id 176/278  is having validation accuracy of 49.487994350282484\n",
            "Epoch #0. Batch Id 177/278  is having validation loss of 1.981050729751587\n",
            "2.039078950881958\n",
            "Epoch #0. Batch Id 177/278  is having validation accuracy of 49.57865168539326\n",
            "Epoch #0. Batch Id 178/278  is having validation loss of 1.9850826263427734\n",
            "2.702753782272339\n",
            "Epoch #0. Batch Id 178/278  is having validation accuracy of 49.49371508379888\n",
            "Epoch #0. Batch Id 179/278  is having validation loss of 1.9874399900436401\n",
            "2.4094059467315674\n",
            "Epoch #0. Batch Id 179/278  is having validation accuracy of 49.46180555555556\n",
            "Epoch #0. Batch Id 180/278  is having validation loss of 1.9870554208755493\n",
            "1.9178268909454346\n",
            "Epoch #0. Batch Id 180/278  is having validation accuracy of 49.4993093922652\n",
            "Epoch #0. Batch Id 181/278  is having validation loss of 1.9870158433914185\n",
            "1.9798568487167358\n",
            "Epoch #0. Batch Id 181/278  is having validation accuracy of 49.45054945054945\n",
            "Epoch #0. Batch Id 182/278  is having validation loss of 1.98673415184021\n",
            "1.9354579448699951\n",
            "Epoch #0. Batch Id 182/278  is having validation accuracy of 49.419398907103826\n",
            "Epoch #0. Batch Id 183/278  is having validation loss of 1.9882434606552124\n",
            "2.264451742172241\n",
            "Epoch #0. Batch Id 183/278  is having validation accuracy of 49.405570652173914\n",
            "Epoch #0. Batch Id 184/278  is having validation loss of 1.988526701927185\n",
            "2.0406458377838135\n",
            "Epoch #0. Batch Id 184/278  is having validation accuracy of 49.42567567567568\n",
            "Epoch #0. Batch Id 185/278  is having validation loss of 1.9861056804656982\n",
            "1.5382072925567627\n",
            "Epoch #0. Batch Id 185/278  is having validation accuracy of 49.52956989247312\n",
            "Epoch #0. Batch Id 186/278  is having validation loss of 1.9851990938186646\n",
            "1.816573977470398\n",
            "Epoch #0. Batch Id 186/278  is having validation accuracy of 49.5153743315508\n",
            "Epoch #0. Batch Id 187/278  is having validation loss of 1.9846006631851196\n",
            "1.8726881742477417\n",
            "Epoch #0. Batch Id 187/278  is having validation accuracy of 49.567819148936174\n",
            "Epoch #0. Batch Id 188/278  is having validation loss of 1.9852442741394043\n",
            "2.1062498092651367\n",
            "Epoch #0. Batch Id 188/278  is having validation accuracy of 49.6031746031746\n",
            "Epoch #0. Batch Id 189/278  is having validation loss of 1.983618140220642\n",
            "1.6762794256210327\n",
            "Epoch #0. Batch Id 189/278  is having validation accuracy of 49.671052631578945\n",
            "Epoch #0. Batch Id 190/278  is having validation loss of 1.9832133054733276\n",
            "1.9062981605529785\n",
            "Epoch #0. Batch Id 190/278  is having validation accuracy of 49.656413612565444\n",
            "Epoch #0. Batch Id 191/278  is having validation loss of 1.9848202466964722\n",
            "2.2917518615722656\n",
            "Epoch #0. Batch Id 191/278  is having validation accuracy of 49.593098958333336\n",
            "Epoch #0. Batch Id 192/278  is having validation loss of 1.9866162538528442\n",
            "2.331456422805786\n",
            "Epoch #0. Batch Id 192/278  is having validation accuracy of 49.54663212435233\n",
            "Epoch #0. Batch Id 193/278  is having validation loss of 1.9871141910552979\n",
            "2.0832080841064453\n",
            "Epoch #0. Batch Id 193/278  is having validation accuracy of 49.54896907216495\n",
            "Epoch #0. Batch Id 194/278  is having validation loss of 1.987898588180542\n",
            "2.1400697231292725\n",
            "Epoch #0. Batch Id 194/278  is having validation accuracy of 49.48717948717949\n",
            "Epoch #0. Batch Id 195/278  is having validation loss of 1.9867979288101196\n",
            "1.7721668481826782\n",
            "Epoch #0. Batch Id 195/278  is having validation accuracy of 49.52168367346939\n",
            "Epoch #0. Batch Id 196/278  is having validation loss of 1.986557126045227\n",
            "1.9393696784973145\n",
            "Epoch #0. Batch Id 196/278  is having validation accuracy of 49.49238578680203\n",
            "Epoch #0. Batch Id 197/278  is having validation loss of 1.9863015413284302\n",
            "1.9359493255615234\n",
            "Epoch #0. Batch Id 197/278  is having validation accuracy of 49.494949494949495\n",
            "Epoch #0. Batch Id 198/278  is having validation loss of 1.987654209136963\n",
            "2.2554826736450195\n",
            "Epoch #0. Batch Id 198/278  is having validation accuracy of 49.48178391959799\n",
            "Epoch #0. Batch Id 199/278  is having validation loss of 1.986196517944336\n",
            "1.6961214542388916\n",
            "Epoch #0. Batch Id 199/278  is having validation accuracy of 49.53125\n",
            "Epoch #0. Batch Id 200/278  is having validation loss of 1.9880627393722534\n",
            "2.3613078594207764\n",
            "Epoch #0. Batch Id 200/278  is having validation accuracy of 49.48694029850746\n",
            "Epoch #0. Batch Id 201/278  is having validation loss of 1.9872723817825317\n",
            "1.8284153938293457\n",
            "Epoch #0. Batch Id 201/278  is having validation accuracy of 49.551361386138616\n",
            "Epoch #0. Batch Id 202/278  is having validation loss of 1.9849904775619507\n",
            "1.5240453481674194\n",
            "Epoch #0. Batch Id 202/278  is having validation accuracy of 49.63054187192118\n",
            "Epoch #0. Batch Id 203/278  is having validation loss of 1.9855217933654785\n",
            "2.0933785438537598\n",
            "Epoch #0. Batch Id 203/278  is having validation accuracy of 49.58639705882353\n",
            "Epoch #0. Batch Id 204/278  is having validation loss of 1.986859917640686\n",
            "2.2598390579223633\n",
            "Epoch #0. Batch Id 204/278  is having validation accuracy of 49.542682926829265\n",
            "Epoch #0. Batch Id 205/278  is having validation loss of 1.9860507249832153\n",
            "1.820157766342163\n",
            "Epoch #0. Batch Id 205/278  is having validation accuracy of 49.59041262135922\n",
            "Epoch #0. Batch Id 206/278  is having validation loss of 1.984306812286377\n",
            "1.625058889389038\n",
            "Epoch #0. Batch Id 206/278  is having validation accuracy of 49.6225845410628\n",
            "Epoch #0. Batch Id 207/278  is having validation loss of 1.983561635017395\n",
            "1.8293157815933228\n",
            "Epoch #0. Batch Id 207/278  is having validation accuracy of 49.62439903846154\n",
            "Epoch #0. Batch Id 208/278  is having validation loss of 1.9843450784683228\n",
            "2.147310733795166\n",
            "Epoch #0. Batch Id 208/278  is having validation accuracy of 49.61124401913876\n",
            "Epoch #0. Batch Id 209/278  is having validation loss of 1.9834328889846802\n",
            "1.7927947044372559\n",
            "Epoch #0. Batch Id 209/278  is having validation accuracy of 49.61309523809524\n",
            "Epoch #0. Batch Id 210/278  is having validation loss of 1.984674334526062\n",
            "2.2453675270080566\n",
            "Epoch #0. Batch Id 210/278  is having validation accuracy of 49.600118483412324\n",
            "Epoch #0. Batch Id 211/278  is having validation loss of 1.9838528633117676\n",
            "1.81051504611969\n",
            "Epoch #0. Batch Id 211/278  is having validation accuracy of 49.602004716981135\n",
            "Epoch #0. Batch Id 212/278  is having validation loss of 1.9829699993133545\n",
            "1.7957983016967773\n",
            "Epoch #0. Batch Id 212/278  is having validation accuracy of 49.63321596244131\n",
            "Epoch #0. Batch Id 213/278  is having validation loss of 1.9831891059875488\n",
            "2.02984619140625\n",
            "Epoch #0. Batch Id 213/278  is having validation accuracy of 49.620327102803735\n",
            "Epoch #0. Batch Id 214/278  is having validation loss of 1.9830995798110962\n",
            "1.963951587677002\n",
            "Epoch #0. Batch Id 214/278  is having validation accuracy of 49.56395348837209\n",
            "Epoch #0. Batch Id 215/278  is having validation loss of 1.9840404987335205\n",
            "2.18634295463562\n",
            "Epoch #0. Batch Id 215/278  is having validation accuracy of 49.479166666666664\n",
            "Epoch #0. Batch Id 216/278  is having validation loss of 1.9841266870498657\n",
            "2.0027501583099365\n",
            "Epoch #0. Batch Id 216/278  is having validation accuracy of 49.45276497695853\n",
            "Epoch #0. Batch Id 217/278  is having validation loss of 1.9835762977600098\n",
            "1.864134430885315\n",
            "Epoch #0. Batch Id 217/278  is having validation accuracy of 49.46961009174312\n",
            "Epoch #0. Batch Id 218/278  is having validation loss of 1.9840784072875977\n",
            "2.093547821044922\n",
            "Epoch #0. Batch Id 218/278  is having validation accuracy of 49.47203196347032\n",
            "Epoch #0. Batch Id 219/278  is having validation loss of 1.9835747480392456\n",
            "1.8732678890228271\n",
            "Epoch #0. Batch Id 219/278  is having validation accuracy of 49.50284090909091\n",
            "Epoch #0. Batch Id 220/278  is having validation loss of 1.9843155145645142\n",
            "2.147273540496826\n",
            "Epoch #0. Batch Id 220/278  is having validation accuracy of 49.4485294117647\n",
            "Epoch #0. Batch Id 221/278  is having validation loss of 1.9848928451538086\n",
            "2.1124823093414307\n",
            "Epoch #0. Batch Id 221/278  is having validation accuracy of 49.43693693693694\n",
            "Epoch #0. Batch Id 222/278  is having validation loss of 1.9855194091796875\n",
            "2.1246073246002197\n",
            "Epoch #0. Batch Id 222/278  is having validation accuracy of 49.43946188340807\n",
            "Epoch #0. Batch Id 223/278  is having validation loss of 1.9860546588897705\n",
            "2.105417490005493\n",
            "Epoch #0. Batch Id 223/278  is having validation accuracy of 49.400111607142854\n",
            "Epoch #0. Batch Id 224/278  is having validation loss of 1.9864641427993774\n",
            "2.0781919956207275\n",
            "Epoch #0. Batch Id 224/278  is having validation accuracy of 49.388888888888886\n",
            "Epoch #0. Batch Id 225/278  is having validation loss of 1.9869111776351929\n",
            "2.0874853134155273\n",
            "Epoch #0. Batch Id 225/278  is having validation accuracy of 49.35011061946903\n",
            "Epoch #0. Batch Id 226/278  is having validation loss of 1.9868277311325073\n",
            "1.9679723978042603\n",
            "Epoch #0. Batch Id 226/278  is having validation accuracy of 49.32544052863436\n",
            "Epoch #0. Batch Id 227/278  is having validation loss of 1.9875777959823608\n",
            "2.1578361988067627\n",
            "Epoch #0. Batch Id 227/278  is having validation accuracy of 49.3421052631579\n",
            "Epoch #0. Batch Id 228/278  is having validation loss of 1.9896472692489624\n",
            "2.4614949226379395\n",
            "Epoch #0. Batch Id 228/278  is having validation accuracy of 49.31768558951965\n",
            "Epoch #0. Batch Id 229/278  is having validation loss of 1.9889202117919922\n",
            "1.8224241733551025\n",
            "Epoch #0. Batch Id 229/278  is having validation accuracy of 49.33423913043478\n",
            "Epoch #0. Batch Id 230/278  is having validation loss of 1.9889470338821411\n",
            "1.9951132535934448\n",
            "Epoch #0. Batch Id 230/278  is having validation accuracy of 49.35064935064935\n",
            "Epoch #0. Batch Id 231/278  is having validation loss of 1.9896842241287231\n",
            "2.159963369369507\n",
            "Epoch #0. Batch Id 231/278  is having validation accuracy of 49.32650862068966\n",
            "Epoch #0. Batch Id 232/278  is having validation loss of 1.9917619228363037\n",
            "2.4737915992736816\n",
            "Epoch #0. Batch Id 232/278  is having validation accuracy of 49.31598712446352\n",
            "Epoch #0. Batch Id 233/278  is having validation loss of 1.9907264709472656\n",
            "1.7494759559631348\n",
            "Epoch #0. Batch Id 233/278  is having validation accuracy of 49.318910256410255\n",
            "Epoch #0. Batch Id 234/278  is having validation loss of 1.9887375831604004\n",
            "1.5233395099639893\n",
            "Epoch #0. Batch Id 234/278  is having validation accuracy of 49.388297872340424\n",
            "Epoch #0. Batch Id 235/278  is having validation loss of 1.9907690286636353\n",
            "2.4681503772735596\n",
            "Epoch #0. Batch Id 235/278  is having validation accuracy of 49.35116525423729\n",
            "Epoch #0. Batch Id 236/278  is having validation loss of 1.990663766860962\n",
            "1.9658207893371582\n",
            "Epoch #0. Batch Id 236/278  is having validation accuracy of 49.34071729957806\n",
            "Epoch #0. Batch Id 237/278  is having validation loss of 1.990005612373352\n",
            "1.8340295553207397\n",
            "Epoch #0. Batch Id 237/278  is having validation accuracy of 49.34348739495798\n",
            "Epoch #0. Batch Id 238/278  is having validation loss of 1.9895858764648438\n",
            "1.8896950483322144\n",
            "Epoch #0. Batch Id 238/278  is having validation accuracy of 49.30700836820084\n",
            "Epoch #0. Batch Id 239/278  is having validation loss of 1.9922726154327393\n",
            "2.634411096572876\n",
            "Epoch #0. Batch Id 239/278  is having validation accuracy of 49.21875\n",
            "Epoch #0. Batch Id 240/278  is having validation loss of 1.9922274351119995\n",
            "1.9813905954360962\n",
            "Epoch #0. Batch Id 240/278  is having validation accuracy of 49.22199170124481\n",
            "Epoch #0. Batch Id 241/278  is having validation loss of 1.9924311637878418\n",
            "2.0415165424346924\n",
            "Epoch #0. Batch Id 241/278  is having validation accuracy of 49.22520661157025\n",
            "Epoch #0. Batch Id 242/278  is having validation loss of 1.991232991218567\n",
            "1.7012755870819092\n",
            "Epoch #0. Batch Id 242/278  is having validation accuracy of 49.29269547325103\n",
            "Epoch #0. Batch Id 243/278  is having validation loss of 1.9892243146896362\n",
            "1.5011242628097534\n",
            "Epoch #0. Batch Id 243/278  is having validation accuracy of 49.35963114754098\n",
            "Epoch #0. Batch Id 244/278  is having validation loss of 1.9896202087402344\n",
            "2.086228370666504\n",
            "Epoch #0. Batch Id 244/278  is having validation accuracy of 49.33673469387755\n",
            "Epoch #0. Batch Id 245/278  is having validation loss of 1.991361141204834\n",
            "2.4178950786590576\n",
            "Epoch #0. Batch Id 245/278  is having validation accuracy of 49.26321138211382\n",
            "Epoch #0. Batch Id 246/278  is having validation loss of 1.9930254220962524\n",
            "2.4024293422698975\n",
            "Epoch #0. Batch Id 246/278  is having validation accuracy of 49.20293522267207\n",
            "Epoch #0. Batch Id 247/278  is having validation loss of 1.994567632675171\n",
            "2.3754825592041016\n",
            "Epoch #0. Batch Id 247/278  is having validation accuracy of 49.10534274193548\n",
            "Epoch #0. Batch Id 248/278  is having validation loss of 1.994847059249878\n",
            "2.064138174057007\n",
            "Epoch #0. Batch Id 248/278  is having validation accuracy of 49.071285140562246\n",
            "Epoch #0. Batch Id 249/278  is having validation loss of 1.9946011304855347\n",
            "1.933351755142212\n",
            "Epoch #0. Batch Id 249/278  is having validation accuracy of 49.075\n",
            "Epoch #0. Batch Id 250/278  is having validation loss of 1.9956024885177612\n",
            "2.2459568977355957\n",
            "Epoch #0. Batch Id 250/278  is having validation accuracy of 49.05378486055777\n",
            "Epoch #0. Batch Id 251/278  is having validation loss of 1.9974603652954102\n",
            "2.4637856483459473\n",
            "Epoch #0. Batch Id 251/278  is having validation accuracy of 49.069940476190474\n",
            "Epoch #0. Batch Id 252/278  is having validation loss of 1.9981229305267334\n",
            "2.1650876998901367\n",
            "Epoch #0. Batch Id 252/278  is having validation accuracy of 49.06126482213439\n",
            "Epoch #0. Batch Id 253/278  is having validation loss of 1.9983354806900024\n",
            "2.0521183013916016\n",
            "Epoch #0. Batch Id 253/278  is having validation accuracy of 49.05265748031496\n",
            "Epoch #0. Batch Id 254/278  is having validation loss of 1.9971970319747925\n",
            "1.708045244216919\n",
            "Epoch #0. Batch Id 254/278  is having validation accuracy of 49.080882352941174\n",
            "Epoch #0. Batch Id 255/278  is having validation loss of 1.9971637725830078\n",
            "1.9886938333511353\n",
            "Epoch #0. Batch Id 255/278  is having validation accuracy of 49.03564453125\n",
            "Epoch #0. Batch Id 256/278  is having validation loss of 1.9981788396835327\n",
            "2.258028984069824\n",
            "Epoch #0. Batch Id 256/278  is having validation accuracy of 48.978599221789885\n",
            "Epoch #0. Batch Id 257/278  is having validation loss of 1.9975327253341675\n",
            "1.8314838409423828\n",
            "Epoch #0. Batch Id 257/278  is having validation accuracy of 48.98255813953488\n",
            "Epoch #0. Batch Id 258/278  is having validation loss of 1.9978243112564087\n",
            "2.0730648040771484\n",
            "Epoch #0. Batch Id 258/278  is having validation accuracy of 48.96235521235521\n",
            "Epoch #0. Batch Id 259/278  is having validation loss of 1.9964320659637451\n",
            "1.6358507871627808\n",
            "Epoch #0. Batch Id 259/278  is having validation accuracy of 49.03846153846154\n",
            "Epoch #0. Batch Id 260/278  is having validation loss of 1.9937081336975098\n",
            "1.2854714393615723\n",
            "Epoch #0. Batch Id 260/278  is having validation accuracy of 49.10201149425287\n",
            "Epoch #0. Batch Id 261/278  is having validation loss of 1.9921324253082275\n",
            "1.5808613300323486\n",
            "Epoch #0. Batch Id 261/278  is having validation accuracy of 49.16507633587786\n",
            "Epoch #0. Batch Id 262/278  is having validation loss of 1.9938533306121826\n",
            "2.4447402954101562\n",
            "Epoch #0. Batch Id 262/278  is having validation accuracy of 49.10884030418251\n",
            "Epoch #0. Batch Id 263/278  is having validation loss of 1.9940913915634155\n",
            "2.05670166015625\n",
            "Epoch #0. Batch Id 263/278  is having validation accuracy of 49.13589015151515\n",
            "Epoch #0. Batch Id 264/278  is having validation loss of 1.9928208589553833\n",
            "1.657414436340332\n",
            "Epoch #0. Batch Id 264/278  is having validation accuracy of 49.174528301886795\n",
            "Epoch #0. Batch Id 265/278  is having validation loss of 1.9928722381591797\n",
            "2.006479263305664\n",
            "Epoch #0. Batch Id 265/278  is having validation accuracy of 49.17763157894737\n",
            "Epoch #0. Batch Id 266/278  is having validation loss of 1.9919675588607788\n",
            "1.7513152360916138\n",
            "Epoch #0. Batch Id 266/278  is having validation accuracy of 49.215823970037455\n",
            "Epoch #0. Batch Id 267/278  is having validation loss of 1.990725040435791\n",
            "1.6589730978012085\n",
            "Epoch #0. Batch Id 267/278  is having validation accuracy of 49.24207089552239\n",
            "Epoch #0. Batch Id 268/278  is having validation loss of 1.9892414808273315\n",
            "1.5916578769683838\n",
            "Epoch #0. Batch Id 268/278  is having validation accuracy of 49.27973977695167\n",
            "Epoch #0. Batch Id 269/278  is having validation loss of 1.9879212379455566\n",
            "1.632760763168335\n",
            "Epoch #0. Batch Id 269/278  is having validation accuracy of 49.3287037037037\n",
            "Epoch #0. Batch Id 270/278  is having validation loss of 1.9881864786148071\n",
            "2.0598042011260986\n",
            "Epoch #0. Batch Id 270/278  is having validation accuracy of 49.308118081180815\n",
            "Epoch #0. Batch Id 271/278  is having validation loss of 1.9888567924499512\n",
            "2.170499324798584\n",
            "Epoch #0. Batch Id 271/278  is having validation accuracy of 49.276194852941174\n",
            "Epoch #0. Batch Id 272/278  is having validation loss of 1.9893476963043213\n",
            "2.122871160507202\n",
            "Epoch #0. Batch Id 272/278  is having validation accuracy of 49.26739926739927\n",
            "Epoch #0. Batch Id 273/278  is having validation loss of 1.9905246496200562\n",
            "2.3118340969085693\n",
            "Epoch #0. Batch Id 273/278  is having validation accuracy of 49.21304744525548\n",
            "Epoch #0. Batch Id 274/278  is having validation loss of 1.99012291431427\n",
            "1.8800381422042847\n",
            "Epoch #0. Batch Id 274/278  is having validation accuracy of 49.19318181818182\n",
            "Epoch #0. Batch Id 275/278  is having validation loss of 1.9903351068496704\n",
            "2.0487000942230225\n",
            "Epoch #0. Batch Id 275/278  is having validation accuracy of 49.18478260869565\n",
            "Epoch #0. Batch Id 276/278  is having validation loss of 1.9896916151046753\n",
            "1.812081217765808\n",
            "Epoch #0. Batch Id 276/278  is having validation accuracy of 49.1764440433213\n",
            "Epoch #0. Batch Id 277/278  is having validation loss of 1.985194206237793\n",
            "0.7394266128540039\n",
            "Epoch #0. Batch Id 277/278  is having validation accuracy of 49.18790886532822\n",
            "Эпоха #0 train_loss: 3.0916158721083775e-05, val_loss: 0.0002239109162474051\n",
            "Потрачено 26.5 минут на 0 эпоху\n",
            "Batch Id 0/2438 is having training loss of 1.9709632396697998\n",
            "1.9709632396697998\n",
            "Epoch #1. Accuracy on batch 0/2438  on Training is 43.75\n",
            "Epoch #1. Accuracy on batch 1/2438  on Training is 48.4375\n",
            "Epoch #1. Accuracy on batch 2/2438  on Training is 53.125\n",
            "Epoch #1. Accuracy on batch 3/2438  on Training is 56.25\n",
            "Epoch #1. Accuracy on batch 4/2438  on Training is 54.375\n",
            "Epoch #1. Accuracy on batch 5/2438  on Training is 57.291666666666664\n",
            "Epoch #1. Accuracy on batch 6/2438  on Training is 57.142857142857146\n",
            "Epoch #1. Accuracy on batch 7/2438  on Training is 59.375\n",
            "Epoch #1. Accuracy on batch 8/2438  on Training is 60.06944444444444\n",
            "Epoch #1. Accuracy on batch 9/2438  on Training is 59.6875\n",
            "Epoch #1. Accuracy on batch 10/2438  on Training is 59.94318181818182\n",
            "Epoch #1. Accuracy on batch 11/2438  on Training is 60.416666666666664\n",
            "Epoch #1. Accuracy on batch 12/2438  on Training is 60.33653846153846\n",
            "Epoch #1. Accuracy on batch 13/2438  on Training is 60.267857142857146\n",
            "Epoch #1. Accuracy on batch 14/2438  on Training is 59.375\n",
            "Epoch #1. Accuracy on batch 15/2438  on Training is 57.6171875\n",
            "Epoch #1. Accuracy on batch 16/2438  on Training is 56.61764705882353\n",
            "Epoch #1. Accuracy on batch 17/2438  on Training is 56.59722222222222\n",
            "Epoch #1. Accuracy on batch 18/2438  on Training is 56.578947368421055\n",
            "Epoch #1. Accuracy on batch 19/2438  on Training is 56.5625\n",
            "Batch Id 20/2438 is having training loss of 1.6800707578659058\n",
            "1.5149999856948853\n",
            "Epoch #1. Accuracy on batch 20/2438  on Training is 56.99404761904762\n",
            "Epoch #1. Accuracy on batch 21/2438  on Training is 56.96022727272727\n",
            "Epoch #1. Accuracy on batch 22/2438  on Training is 57.06521739130435\n",
            "Epoch #1. Accuracy on batch 23/2438  on Training is 57.161458333333336\n",
            "Epoch #1. Accuracy on batch 24/2438  on Training is 56.625\n",
            "Epoch #1. Accuracy on batch 25/2438  on Training is 56.49038461538461\n",
            "Epoch #1. Accuracy on batch 26/2438  on Training is 56.25\n",
            "Epoch #1. Accuracy on batch 27/2438  on Training is 56.25\n",
            "Epoch #1. Accuracy on batch 28/2438  on Training is 56.25\n",
            "Epoch #1. Accuracy on batch 29/2438  on Training is 56.979166666666664\n",
            "Epoch #1. Accuracy on batch 30/2438  on Training is 57.358870967741936\n",
            "Epoch #1. Accuracy on batch 31/2438  on Training is 57.51953125\n",
            "Epoch #1. Accuracy on batch 32/2438  on Training is 57.291666666666664\n",
            "Epoch #1. Accuracy on batch 33/2438  on Training is 57.44485294117647\n",
            "Epoch #1. Accuracy on batch 34/2438  on Training is 57.857142857142854\n",
            "Epoch #1. Accuracy on batch 35/2438  on Training is 58.24652777777778\n",
            "Epoch #1. Accuracy on batch 36/2438  on Training is 58.108108108108105\n",
            "Epoch #1. Accuracy on batch 37/2438  on Training is 58.223684210526315\n",
            "Epoch #1. Accuracy on batch 38/2438  on Training is 58.17307692307692\n",
            "Epoch #1. Accuracy on batch 39/2438  on Training is 58.125\n",
            "Batch Id 40/2438 is having training loss of 1.7215607166290283\n",
            "1.200850009918213\n",
            "Epoch #1. Accuracy on batch 40/2438  on Training is 58.6890243902439\n",
            "Epoch #1. Accuracy on batch 41/2438  on Training is 58.779761904761905\n",
            "Epoch #1. Accuracy on batch 42/2438  on Training is 58.64825581395349\n",
            "Epoch #1. Accuracy on batch 43/2438  on Training is 58.73579545454545\n",
            "Epoch #1. Accuracy on batch 44/2438  on Training is 58.611111111111114\n",
            "Epoch #1. Accuracy on batch 45/2438  on Training is 58.83152173913044\n",
            "Epoch #1. Accuracy on batch 46/2438  on Training is 59.04255319148936\n",
            "Epoch #1. Accuracy on batch 47/2438  on Training is 59.1796875\n",
            "Epoch #1. Accuracy on batch 48/2438  on Training is 59.24744897959184\n",
            "Epoch #1. Accuracy on batch 49/2438  on Training is 59.0625\n",
            "Epoch #1. Accuracy on batch 50/2438  on Training is 59.068627450980394\n",
            "Epoch #1. Accuracy on batch 51/2438  on Training is 59.375\n",
            "Epoch #1. Accuracy on batch 52/2438  on Training is 59.375\n",
            "Epoch #1. Accuracy on batch 53/2438  on Training is 59.25925925925926\n",
            "Epoch #1. Accuracy on batch 54/2438  on Training is 59.43181818181818\n",
            "Epoch #1. Accuracy on batch 55/2438  on Training is 59.31919642857143\n",
            "Epoch #1. Accuracy on batch 56/2438  on Training is 59.32017543859649\n",
            "Epoch #1. Accuracy on batch 57/2438  on Training is 59.375\n",
            "Epoch #1. Accuracy on batch 58/2438  on Training is 59.32203389830509\n",
            "Epoch #1. Accuracy on batch 59/2438  on Training is 59.21875\n",
            "Batch Id 60/2438 is having training loss of 1.6766693592071533\n",
            "1.1849550008773804\n",
            "Epoch #1. Accuracy on batch 60/2438  on Training is 59.42622950819672\n",
            "Epoch #1. Accuracy on batch 61/2438  on Training is 59.67741935483871\n",
            "Epoch #1. Accuracy on batch 62/2438  on Training is 59.47420634920635\n",
            "Epoch #1. Accuracy on batch 63/2438  on Training is 59.521484375\n",
            "Epoch #1. Accuracy on batch 64/2438  on Training is 59.42307692307692\n",
            "Epoch #1. Accuracy on batch 65/2438  on Training is 59.23295454545455\n",
            "Epoch #1. Accuracy on batch 66/2438  on Training is 59.281716417910445\n",
            "Epoch #1. Accuracy on batch 67/2438  on Training is 59.05330882352941\n",
            "Epoch #1. Accuracy on batch 68/2438  on Training is 59.05797101449275\n",
            "Epoch #1. Accuracy on batch 69/2438  on Training is 59.0625\n",
            "Epoch #1. Accuracy on batch 70/2438  on Training is 58.934859154929576\n",
            "Epoch #1. Accuracy on batch 71/2438  on Training is 58.723958333333336\n",
            "Epoch #1. Accuracy on batch 72/2438  on Training is 58.77568493150685\n",
            "Epoch #1. Accuracy on batch 73/2438  on Training is 58.78378378378378\n",
            "Epoch #1. Accuracy on batch 74/2438  on Training is 58.666666666666664\n",
            "Epoch #1. Accuracy on batch 75/2438  on Training is 58.63486842105263\n",
            "Epoch #1. Accuracy on batch 76/2438  on Training is 58.482142857142854\n",
            "Epoch #1. Accuracy on batch 77/2438  on Training is 58.37339743589744\n",
            "Epoch #1. Accuracy on batch 78/2438  on Training is 58.30696202531646\n",
            "Epoch #1. Accuracy on batch 79/2438  on Training is 58.4375\n",
            "Batch Id 80/2438 is having training loss of 1.705845832824707\n",
            "1.3334392309188843\n",
            "Epoch #1. Accuracy on batch 80/2438  on Training is 58.56481481481482\n",
            "Epoch #1. Accuracy on batch 81/2438  on Training is 58.6890243902439\n",
            "Epoch #1. Accuracy on batch 82/2438  on Training is 58.6972891566265\n",
            "Epoch #1. Accuracy on batch 83/2438  on Training is 58.66815476190476\n",
            "Epoch #1. Accuracy on batch 84/2438  on Training is 58.56617647058823\n",
            "Epoch #1. Accuracy on batch 85/2438  on Training is 58.502906976744185\n",
            "Epoch #1. Accuracy on batch 86/2438  on Training is 58.58477011494253\n",
            "Epoch #1. Accuracy on batch 87/2438  on Training is 58.66477272727273\n",
            "Epoch #1. Accuracy on batch 88/2438  on Training is 58.56741573033708\n",
            "Epoch #1. Accuracy on batch 89/2438  on Training is 58.645833333333336\n",
            "Epoch #1. Accuracy on batch 90/2438  on Training is 58.58516483516483\n",
            "Epoch #1. Accuracy on batch 91/2438  on Training is 58.62771739130435\n",
            "Epoch #1. Accuracy on batch 92/2438  on Training is 58.534946236559136\n",
            "Epoch #1. Accuracy on batch 93/2438  on Training is 58.67686170212766\n",
            "Epoch #1. Accuracy on batch 94/2438  on Training is 58.7171052631579\n",
            "Epoch #1. Accuracy on batch 95/2438  on Training is 58.756510416666664\n",
            "Epoch #1. Accuracy on batch 96/2438  on Training is 58.69845360824742\n",
            "Epoch #1. Accuracy on batch 97/2438  on Training is 58.76913265306123\n",
            "Epoch #1. Accuracy on batch 98/2438  on Training is 58.93308080808081\n",
            "Epoch #1. Accuracy on batch 99/2438  on Training is 58.875\n",
            "Batch Id 100/2438 is having training loss of 1.6992040872573853\n",
            "1.8810913562774658\n",
            "Epoch #1. Accuracy on batch 100/2438  on Training is 58.8490099009901\n",
            "Epoch #1. Accuracy on batch 101/2438  on Training is 58.76225490196079\n",
            "Epoch #1. Accuracy on batch 102/2438  on Training is 58.70752427184466\n",
            "Epoch #1. Accuracy on batch 103/2438  on Training is 58.77403846153846\n",
            "Epoch #1. Accuracy on batch 104/2438  on Training is 58.660714285714285\n",
            "Epoch #1. Accuracy on batch 105/2438  on Training is 58.755896226415096\n",
            "Epoch #1. Accuracy on batch 106/2438  on Training is 58.674065420560744\n",
            "Epoch #1. Accuracy on batch 107/2438  on Training is 58.82523148148148\n",
            "Epoch #1. Accuracy on batch 108/2438  on Training is 58.74426605504587\n",
            "Epoch #1. Accuracy on batch 109/2438  on Training is 58.80681818181818\n",
            "Epoch #1. Accuracy on batch 110/2438  on Training is 58.840090090090094\n",
            "Epoch #1. Accuracy on batch 111/2438  on Training is 58.7890625\n",
            "Epoch #1. Accuracy on batch 112/2438  on Training is 58.849557522123895\n",
            "Epoch #1. Accuracy on batch 113/2438  on Training is 58.82675438596491\n",
            "Epoch #1. Accuracy on batch 114/2438  on Training is 58.77717391304348\n",
            "Epoch #1. Accuracy on batch 115/2438  on Training is 58.83620689655172\n",
            "Epoch #1. Accuracy on batch 116/2438  on Training is 58.92094017094017\n",
            "Epoch #1. Accuracy on batch 117/2438  on Training is 59.057203389830505\n",
            "Epoch #1. Accuracy on batch 118/2438  on Training is 59.00735294117647\n",
            "Epoch #1. Accuracy on batch 119/2438  on Training is 58.958333333333336\n",
            "Batch Id 120/2438 is having training loss of 1.6959576606750488\n",
            "1.443464994430542\n",
            "Epoch #1. Accuracy on batch 120/2438  on Training is 59.0650826446281\n",
            "Epoch #1. Accuracy on batch 121/2438  on Training is 59.067622950819676\n",
            "Epoch #1. Accuracy on batch 122/2438  on Training is 58.99390243902439\n",
            "Epoch #1. Accuracy on batch 123/2438  on Training is 58.971774193548384\n",
            "Epoch #1. Accuracy on batch 124/2438  on Training is 58.925\n",
            "Epoch #1. Accuracy on batch 125/2438  on Training is 59.00297619047619\n",
            "Epoch #1. Accuracy on batch 126/2438  on Training is 58.95669291338583\n",
            "Epoch #1. Accuracy on batch 127/2438  on Training is 58.935546875\n",
            "Epoch #1. Accuracy on batch 128/2438  on Training is 58.84205426356589\n",
            "Epoch #1. Accuracy on batch 129/2438  on Training is 58.79807692307692\n",
            "Epoch #1. Accuracy on batch 130/2438  on Training is 58.73091603053435\n",
            "Epoch #1. Accuracy on batch 131/2438  on Training is 58.71212121212121\n",
            "Epoch #1. Accuracy on batch 132/2438  on Training is 58.64661654135338\n",
            "Epoch #1. Accuracy on batch 133/2438  on Training is 58.65205223880597\n",
            "Epoch #1. Accuracy on batch 134/2438  on Training is 58.726851851851855\n",
            "Epoch #1. Accuracy on batch 135/2438  on Training is 58.7545955882353\n",
            "Epoch #1. Accuracy on batch 136/2438  on Training is 58.85036496350365\n",
            "Epoch #1. Accuracy on batch 137/2438  on Training is 58.78623188405797\n",
            "Epoch #1. Accuracy on batch 138/2438  on Training is 58.85791366906475\n",
            "Epoch #1. Accuracy on batch 139/2438  on Training is 58.72767857142857\n",
            "Batch Id 140/2438 is having training loss of 1.6974554061889648\n",
            "1.3316433429718018\n",
            "Epoch #1. Accuracy on batch 140/2438  on Training is 58.8209219858156\n",
            "Epoch #1. Accuracy on batch 141/2438  on Training is 58.912852112676056\n",
            "Epoch #1. Accuracy on batch 142/2438  on Training is 58.89423076923077\n",
            "Epoch #1. Accuracy on batch 143/2438  on Training is 58.83246527777778\n",
            "Epoch #1. Accuracy on batch 144/2438  on Training is 58.85775862068966\n",
            "Epoch #1. Accuracy on batch 145/2438  on Training is 58.83989726027397\n",
            "Epoch #1. Accuracy on batch 146/2438  on Training is 58.886054421768705\n",
            "Epoch #1. Accuracy on batch 147/2438  on Training is 58.84712837837838\n",
            "Epoch #1. Accuracy on batch 148/2438  on Training is 58.850671140939596\n",
            "Epoch #1. Accuracy on batch 149/2438  on Training is 58.729166666666664\n",
            "Epoch #1. Accuracy on batch 150/2438  on Training is 58.85761589403973\n",
            "Epoch #1. Accuracy on batch 151/2438  on Training is 58.81990131578947\n",
            "Epoch #1. Accuracy on batch 152/2438  on Training is 58.8235294117647\n",
            "Epoch #1. Accuracy on batch 153/2438  on Training is 58.78652597402598\n",
            "Epoch #1. Accuracy on batch 154/2438  on Training is 58.810483870967744\n",
            "Epoch #1. Accuracy on batch 155/2438  on Training is 58.854166666666664\n",
            "Epoch #1. Accuracy on batch 156/2438  on Training is 58.89729299363057\n",
            "Epoch #1. Accuracy on batch 157/2438  on Training is 58.95965189873418\n",
            "Epoch #1. Accuracy on batch 158/2438  on Training is 58.9622641509434\n",
            "Epoch #1. Accuracy on batch 159/2438  on Training is 58.96484375\n",
            "Batch Id 160/2438 is having training loss of 1.6932356357574463\n",
            "1.8205043077468872\n",
            "Epoch #1. Accuracy on batch 160/2438  on Training is 58.94798136645963\n",
            "Epoch #1. Accuracy on batch 161/2438  on Training is 58.93132716049383\n",
            "Epoch #1. Accuracy on batch 162/2438  on Training is 58.9340490797546\n",
            "Epoch #1. Accuracy on batch 163/2438  on Training is 58.80335365853659\n",
            "Epoch #1. Accuracy on batch 164/2438  on Training is 58.84469696969697\n",
            "Epoch #1. Accuracy on batch 165/2438  on Training is 58.86671686746988\n",
            "Epoch #1. Accuracy on batch 166/2438  on Training is 58.869760479041915\n",
            "Epoch #1. Accuracy on batch 167/2438  on Training is 58.798363095238095\n",
            "Epoch #1. Accuracy on batch 168/2438  on Training is 58.8387573964497\n",
            "Epoch #1. Accuracy on batch 169/2438  on Training is 58.8235294117647\n",
            "Epoch #1. Accuracy on batch 170/2438  on Training is 58.845029239766085\n",
            "Epoch #1. Accuracy on batch 171/2438  on Training is 58.82994186046512\n",
            "Epoch #1. Accuracy on batch 172/2438  on Training is 58.83309248554913\n",
            "Epoch #1. Accuracy on batch 173/2438  on Training is 58.81824712643678\n",
            "Epoch #1. Accuracy on batch 174/2438  on Training is 58.785714285714285\n",
            "Epoch #1. Accuracy on batch 175/2438  on Training is 58.71803977272727\n",
            "Epoch #1. Accuracy on batch 176/2438  on Training is 58.79237288135593\n",
            "Epoch #1. Accuracy on batch 177/2438  on Training is 58.813202247191015\n",
            "Epoch #1. Accuracy on batch 178/2438  on Training is 58.83379888268156\n",
            "Epoch #1. Accuracy on batch 179/2438  on Training is 58.81944444444444\n",
            "Batch Id 180/2438 is having training loss of 1.6898936033248901\n",
            "1.4277292490005493\n",
            "Epoch #1. Accuracy on batch 180/2438  on Training is 58.857044198895025\n",
            "Epoch #1. Accuracy on batch 181/2438  on Training is 58.87706043956044\n",
            "Epoch #1. Accuracy on batch 182/2438  on Training is 58.87978142076503\n",
            "Epoch #1. Accuracy on batch 183/2438  on Training is 58.84850543478261\n",
            "Epoch #1. Accuracy on batch 184/2438  on Training is 58.91891891891892\n",
            "Epoch #1. Accuracy on batch 185/2438  on Training is 58.971774193548384\n",
            "Epoch #1. Accuracy on batch 186/2438  on Training is 59.024064171122994\n",
            "Epoch #1. Accuracy on batch 187/2438  on Training is 58.976063829787236\n",
            "Epoch #1. Accuracy on batch 188/2438  on Training is 58.9781746031746\n",
            "Epoch #1. Accuracy on batch 189/2438  on Training is 58.98026315789474\n",
            "Epoch #1. Accuracy on batch 190/2438  on Training is 58.98232984293194\n",
            "Epoch #1. Accuracy on batch 191/2438  on Training is 59.016927083333336\n",
            "Epoch #1. Accuracy on batch 192/2438  on Training is 58.97020725388601\n",
            "Epoch #1. Accuracy on batch 193/2438  on Training is 58.97229381443299\n",
            "Epoch #1. Accuracy on batch 194/2438  on Training is 58.958333333333336\n",
            "Epoch #1. Accuracy on batch 195/2438  on Training is 58.92857142857143\n",
            "Epoch #1. Accuracy on batch 196/2438  on Training is 58.930837563451774\n",
            "Epoch #1. Accuracy on batch 197/2438  on Training is 58.996212121212125\n",
            "Epoch #1. Accuracy on batch 198/2438  on Training is 58.95100502512563\n",
            "Epoch #1. Accuracy on batch 199/2438  on Training is 59.015625\n",
            "Batch Id 200/2438 is having training loss of 1.6871815919876099\n",
            "1.830918550491333\n",
            "Epoch #1. Accuracy on batch 200/2438  on Training is 59.017412935323385\n",
            "Epoch #1. Accuracy on batch 201/2438  on Training is 58.972772277227726\n",
            "Epoch #1. Accuracy on batch 202/2438  on Training is 59.00554187192118\n",
            "Epoch #1. Accuracy on batch 203/2438  on Training is 59.02267156862745\n",
            "Epoch #1. Accuracy on batch 204/2438  on Training is 59.00914634146341\n",
            "Epoch #1. Accuracy on batch 205/2438  on Training is 58.980582524271846\n",
            "Epoch #1. Accuracy on batch 206/2438  on Training is 58.89190821256039\n",
            "Epoch #1. Accuracy on batch 207/2438  on Training is 58.87920673076923\n",
            "Epoch #1. Accuracy on batch 208/2438  on Training is 58.89653110047847\n",
            "Epoch #1. Accuracy on batch 209/2438  on Training is 58.92857142857143\n",
            "Epoch #1. Accuracy on batch 210/2438  on Training is 58.88625592417062\n",
            "Epoch #1. Accuracy on batch 211/2438  on Training is 58.903301886792455\n",
            "Epoch #1. Accuracy on batch 212/2438  on Training is 58.90551643192488\n",
            "Epoch #1. Accuracy on batch 213/2438  on Training is 58.9661214953271\n",
            "Epoch #1. Accuracy on batch 214/2438  on Training is 58.93895348837209\n",
            "Epoch #1. Accuracy on batch 215/2438  on Training is 58.998842592592595\n",
            "Epoch #1. Accuracy on batch 216/2438  on Training is 59.00057603686636\n",
            "Epoch #1. Accuracy on batch 217/2438  on Training is 59.07396788990825\n",
            "Epoch #1. Accuracy on batch 218/2438  on Training is 59.08961187214612\n",
            "Epoch #1. Accuracy on batch 219/2438  on Training is 59.0625\n",
            "Batch Id 220/2438 is having training loss of 1.681097388267517\n",
            "1.6421294212341309\n",
            "Epoch #1. Accuracy on batch 220/2438  on Training is 59.092194570135746\n",
            "Epoch #1. Accuracy on batch 221/2438  on Training is 59.12162162162162\n",
            "Epoch #1. Accuracy on batch 222/2438  on Training is 59.06670403587444\n",
            "Epoch #1. Accuracy on batch 223/2438  on Training is 59.12388392857143\n",
            "Epoch #1. Accuracy on batch 224/2438  on Training is 59.09722222222222\n",
            "Epoch #1. Accuracy on batch 225/2438  on Training is 59.01548672566372\n",
            "Epoch #1. Accuracy on batch 226/2438  on Training is 59.085903083700444\n",
            "Epoch #1. Accuracy on batch 227/2438  on Training is 59.046052631578945\n",
            "Epoch #1. Accuracy on batch 228/2438  on Training is 59.047489082969435\n",
            "Epoch #1. Accuracy on batch 229/2438  on Training is 59.04891304347826\n",
            "Epoch #1. Accuracy on batch 230/2438  on Training is 59.00974025974026\n",
            "Epoch #1. Accuracy on batch 231/2438  on Training is 59.038254310344826\n",
            "Epoch #1. Accuracy on batch 232/2438  on Training is 59.066523605150216\n",
            "Epoch #1. Accuracy on batch 233/2438  on Training is 59.04113247863248\n",
            "Epoch #1. Accuracy on batch 234/2438  on Training is 59.02925531914894\n",
            "Epoch #1. Accuracy on batch 235/2438  on Training is 59.04396186440678\n",
            "Epoch #1. Accuracy on batch 236/2438  on Training is 59.01898734177215\n",
            "Epoch #1. Accuracy on batch 237/2438  on Training is 59.05987394957983\n",
            "Epoch #1. Accuracy on batch 238/2438  on Training is 59.04811715481171\n",
            "Epoch #1. Accuracy on batch 239/2438  on Training is 59.0625\n",
            "Batch Id 240/2438 is having training loss of 1.6763044595718384\n",
            "1.2148491144180298\n",
            "Epoch #1. Accuracy on batch 240/2438  on Training is 59.11566390041494\n",
            "Epoch #1. Accuracy on batch 241/2438  on Training is 59.0650826446281\n",
            "Epoch #1. Accuracy on batch 242/2438  on Training is 59.09207818930041\n",
            "Epoch #1. Accuracy on batch 243/2438  on Training is 59.09323770491803\n",
            "Epoch #1. Accuracy on batch 244/2438  on Training is 59.06887755102041\n",
            "Epoch #1. Accuracy on batch 245/2438  on Training is 59.09552845528455\n",
            "Epoch #1. Accuracy on batch 246/2438  on Training is 59.08400809716599\n",
            "Epoch #1. Accuracy on batch 247/2438  on Training is 59.122983870967744\n",
            "Epoch #1. Accuracy on batch 248/2438  on Training is 59.18674698795181\n",
            "Epoch #1. Accuracy on batch 249/2438  on Training is 59.1875\n",
            "Epoch #1. Accuracy on batch 250/2438  on Training is 59.20069721115538\n",
            "Epoch #1. Accuracy on batch 251/2438  on Training is 59.23859126984127\n",
            "Epoch #1. Accuracy on batch 252/2438  on Training is 59.20207509881423\n",
            "Epoch #1. Accuracy on batch 253/2438  on Training is 59.22736220472441\n",
            "Epoch #1. Accuracy on batch 254/2438  on Training is 59.22794117647059\n",
            "Epoch #1. Accuracy on batch 255/2438  on Training is 59.19189453125\n",
            "Epoch #1. Accuracy on batch 256/2438  on Training is 59.143968871595334\n",
            "Epoch #1. Accuracy on batch 257/2438  on Training is 59.16908914728682\n",
            "Epoch #1. Accuracy on batch 258/2438  on Training is 59.21814671814672\n",
            "Epoch #1. Accuracy on batch 259/2438  on Training is 59.23076923076923\n",
            "Batch Id 260/2438 is having training loss of 1.6765084266662598\n",
            "1.8948019742965698\n",
            "Epoch #1. Accuracy on batch 260/2438  on Training is 59.183429118773944\n",
            "Epoch #1. Accuracy on batch 261/2438  on Training is 59.18416030534351\n",
            "Epoch #1. Accuracy on batch 262/2438  on Training is 59.196768060836504\n",
            "Epoch #1. Accuracy on batch 263/2438  on Training is 59.17376893939394\n",
            "Epoch #1. Accuracy on batch 264/2438  on Training is 59.1627358490566\n",
            "Epoch #1. Accuracy on batch 265/2438  on Training is 59.17528195488722\n",
            "Epoch #1. Accuracy on batch 266/2438  on Training is 59.24625468164794\n",
            "Epoch #1. Accuracy on batch 267/2438  on Training is 59.1884328358209\n",
            "Epoch #1. Accuracy on batch 268/2438  on Training is 59.189126394052046\n",
            "Epoch #1. Accuracy on batch 269/2438  on Training is 59.17824074074074\n",
            "Epoch #1. Accuracy on batch 270/2438  on Training is 59.15590405904059\n",
            "Epoch #1. Accuracy on batch 271/2438  on Training is 59.076286764705884\n",
            "Epoch #1. Accuracy on batch 272/2438  on Training is 59.123168498168496\n",
            "Epoch #1. Accuracy on batch 273/2438  on Training is 59.13549270072993\n",
            "Epoch #1. Accuracy on batch 274/2438  on Training is 59.14772727272727\n",
            "Epoch #1. Accuracy on batch 275/2438  on Training is 59.18251811594203\n",
            "Epoch #1. Accuracy on batch 276/2438  on Training is 59.126805054151625\n",
            "Epoch #1. Accuracy on batch 277/2438  on Training is 59.138938848920866\n",
            "Epoch #1. Accuracy on batch 278/2438  on Training is 59.15098566308244\n",
            "Epoch #1. Accuracy on batch 279/2438  on Training is 59.16294642857143\n",
            "Batch Id 280/2438 is having training loss of 1.6726542711257935\n",
            "1.946769118309021\n",
            "Epoch #1. Accuracy on batch 280/2438  on Training is 59.119217081850536\n",
            "Epoch #1. Accuracy on batch 281/2438  on Training is 59.13120567375886\n",
            "Epoch #1. Accuracy on batch 282/2438  on Training is 59.1541519434629\n",
            "Epoch #1. Accuracy on batch 283/2438  on Training is 59.16593309859155\n",
            "Epoch #1. Accuracy on batch 284/2438  on Training is 59.10087719298246\n",
            "Epoch #1. Accuracy on batch 285/2438  on Training is 59.07998251748252\n",
            "Epoch #1. Accuracy on batch 286/2438  on Training is 59.04834494773519\n",
            "Epoch #1. Accuracy on batch 287/2438  on Training is 59.103732638888886\n",
            "Epoch #1. Accuracy on batch 288/2438  on Training is 59.115484429065745\n",
            "Epoch #1. Accuracy on batch 289/2438  on Training is 59.0948275862069\n",
            "Epoch #1. Accuracy on batch 290/2438  on Training is 59.11726804123711\n",
            "Epoch #1. Accuracy on batch 291/2438  on Training is 59.12885273972603\n",
            "Epoch #1. Accuracy on batch 292/2438  on Training is 59.129692832764505\n",
            "Epoch #1. Accuracy on batch 293/2438  on Training is 59.09863945578231\n",
            "Epoch #1. Accuracy on batch 294/2438  on Training is 59.13135593220339\n",
            "Epoch #1. Accuracy on batch 295/2438  on Training is 59.142736486486484\n",
            "Epoch #1. Accuracy on batch 296/2438  on Training is 59.13299663299663\n",
            "Epoch #1. Accuracy on batch 297/2438  on Training is 59.144295302013425\n",
            "Epoch #1. Accuracy on batch 298/2438  on Training is 59.165969899665555\n",
            "Epoch #1. Accuracy on batch 299/2438  on Training is 59.208333333333336\n",
            "Batch Id 300/2438 is having training loss of 1.6683011054992676\n",
            "1.8405873775482178\n",
            "Epoch #1. Accuracy on batch 300/2438  on Training is 59.17774086378738\n",
            "Epoch #1. Accuracy on batch 301/2438  on Training is 59.16804635761589\n",
            "Epoch #1. Accuracy on batch 302/2438  on Training is 59.18935643564357\n",
            "Epoch #1. Accuracy on batch 303/2438  on Training is 59.16940789473684\n",
            "Epoch #1. Accuracy on batch 304/2438  on Training is 59.21106557377049\n",
            "Epoch #1. Accuracy on batch 305/2438  on Training is 59.19117647058823\n",
            "Epoch #1. Accuracy on batch 306/2438  on Training is 59.20195439739414\n",
            "Epoch #1. Accuracy on batch 307/2438  on Training is 59.21266233766234\n",
            "Epoch #1. Accuracy on batch 308/2438  on Training is 59.20307443365696\n",
            "Epoch #1. Accuracy on batch 309/2438  on Training is 59.203629032258064\n",
            "Epoch #1. Accuracy on batch 310/2438  on Training is 59.26446945337621\n",
            "Epoch #1. Accuracy on batch 311/2438  on Training is 59.23477564102564\n",
            "Epoch #1. Accuracy on batch 312/2438  on Training is 59.24520766773163\n",
            "Epoch #1. Accuracy on batch 313/2438  on Training is 59.225716560509554\n",
            "Epoch #1. Accuracy on batch 314/2438  on Training is 59.236111111111114\n",
            "Epoch #1. Accuracy on batch 315/2438  on Training is 59.26621835443038\n",
            "Epoch #1. Accuracy on batch 316/2438  on Training is 59.256703470031546\n",
            "Epoch #1. Accuracy on batch 317/2438  on Training is 59.198113207547166\n",
            "Epoch #1. Accuracy on batch 318/2438  on Training is 59.198667711598745\n",
            "Epoch #1. Accuracy on batch 319/2438  on Training is 59.16015625\n",
            "Batch Id 320/2438 is having training loss of 1.6630381345748901\n",
            "1.5914801359176636\n",
            "Epoch #1. Accuracy on batch 320/2438  on Training is 59.17056074766355\n",
            "Epoch #1. Accuracy on batch 321/2438  on Training is 59.171195652173914\n",
            "Epoch #1. Accuracy on batch 322/2438  on Training is 59.13312693498452\n",
            "Epoch #1. Accuracy on batch 323/2438  on Training is 59.15316358024691\n",
            "Epoch #1. Accuracy on batch 324/2438  on Training is 59.15384615384615\n",
            "Epoch #1. Accuracy on batch 325/2438  on Training is 59.14493865030675\n",
            "Epoch #1. Accuracy on batch 326/2438  on Training is 59.15519877675841\n",
            "Epoch #1. Accuracy on batch 327/2438  on Training is 59.213033536585364\n",
            "Epoch #1. Accuracy on batch 328/2438  on Training is 59.24202127659574\n",
            "Epoch #1. Accuracy on batch 329/2438  on Training is 59.20454545454545\n",
            "Epoch #1. Accuracy on batch 330/2438  on Training is 59.223942598187314\n",
            "Epoch #1. Accuracy on batch 331/2438  on Training is 59.233810240963855\n",
            "Epoch #1. Accuracy on batch 332/2438  on Training is 59.262387387387385\n",
            "Epoch #1. Accuracy on batch 333/2438  on Training is 59.262724550898206\n",
            "Epoch #1. Accuracy on batch 334/2438  on Training is 59.27238805970149\n",
            "Epoch #1. Accuracy on batch 335/2438  on Training is 59.27269345238095\n",
            "Epoch #1. Accuracy on batch 336/2438  on Training is 59.24517804154303\n",
            "Epoch #1. Accuracy on batch 337/2438  on Training is 59.19933431952663\n",
            "Epoch #1. Accuracy on batch 338/2438  on Training is 59.209070796460175\n",
            "Epoch #1. Accuracy on batch 339/2438  on Training is 59.22794117647059\n",
            "Batch Id 340/2438 is having training loss of 1.6579967737197876\n",
            "1.948707103729248\n",
            "Epoch #1. Accuracy on batch 340/2438  on Training is 59.2008797653959\n",
            "Epoch #1. Accuracy on batch 341/2438  on Training is 59.192251461988306\n",
            "Epoch #1. Accuracy on batch 342/2438  on Training is 59.183673469387756\n",
            "Epoch #1. Accuracy on batch 343/2438  on Training is 59.18422965116279\n",
            "Epoch #1. Accuracy on batch 344/2438  on Training is 59.17572463768116\n",
            "Epoch #1. Accuracy on batch 345/2438  on Training is 59.14920520231214\n",
            "Epoch #1. Accuracy on batch 346/2438  on Training is 59.122838616714695\n",
            "Epoch #1. Accuracy on batch 347/2438  on Training is 59.114583333333336\n",
            "Epoch #1. Accuracy on batch 348/2438  on Training is 59.04369627507163\n",
            "Epoch #1. Accuracy on batch 349/2438  on Training is 59.044642857142854\n",
            "Epoch #1. Accuracy on batch 350/2438  on Training is 59.001068376068375\n",
            "Epoch #1. Accuracy on batch 351/2438  on Training is 59.00213068181818\n",
            "Epoch #1. Accuracy on batch 352/2438  on Training is 58.994334277620396\n",
            "Epoch #1. Accuracy on batch 353/2438  on Training is 59.066031073446325\n",
            "Epoch #1. Accuracy on batch 354/2438  on Training is 59.09330985915493\n",
            "Epoch #1. Accuracy on batch 355/2438  on Training is 59.120435393258425\n",
            "Epoch #1. Accuracy on batch 356/2438  on Training is 59.08613445378151\n",
            "Epoch #1. Accuracy on batch 357/2438  on Training is 59.11312849162011\n",
            "Epoch #1. Accuracy on batch 358/2438  on Training is 59.139972144846794\n",
            "Epoch #1. Accuracy on batch 359/2438  on Training is 59.140625\n",
            "Batch Id 360/2438 is having training loss of 1.6605114936828613\n",
            "1.5481693744659424\n",
            "Epoch #1. Accuracy on batch 360/2438  on Training is 59.106648199445985\n",
            "Epoch #1. Accuracy on batch 361/2438  on Training is 59.090124309392266\n",
            "Epoch #1. Accuracy on batch 362/2438  on Training is 59.108126721763085\n",
            "Epoch #1. Accuracy on batch 363/2438  on Training is 59.083104395604394\n",
            "Epoch #1. Accuracy on batch 364/2438  on Training is 59.05821917808219\n",
            "Epoch #1. Accuracy on batch 365/2438  on Training is 59.03346994535519\n",
            "Epoch #1. Accuracy on batch 366/2438  on Training is 59.017370572207085\n",
            "Epoch #1. Accuracy on batch 367/2438  on Training is 59.03532608695652\n",
            "Epoch #1. Accuracy on batch 368/2438  on Training is 59.03624661246612\n",
            "Epoch #1. Accuracy on batch 369/2438  on Training is 59.020270270270274\n",
            "Epoch #1. Accuracy on batch 370/2438  on Training is 59.02122641509434\n",
            "Epoch #1. Accuracy on batch 371/2438  on Training is 59.01377688172043\n",
            "Epoch #1. Accuracy on batch 372/2438  on Training is 59.03150134048257\n",
            "Epoch #1. Accuracy on batch 373/2438  on Training is 59.032419786096256\n",
            "Epoch #1. Accuracy on batch 374/2438  on Training is 59.0\n",
            "Epoch #1. Accuracy on batch 375/2438  on Training is 59.0093085106383\n",
            "Epoch #1. Accuracy on batch 376/2438  on Training is 59.001989389920425\n",
            "Epoch #1. Accuracy on batch 377/2438  on Training is 59.00297619047619\n",
            "Epoch #1. Accuracy on batch 378/2438  on Training is 58.95448548812665\n",
            "Epoch #1. Accuracy on batch 379/2438  on Training is 58.94736842105263\n",
            "Batch Id 380/2438 is having training loss of 1.6628875732421875\n",
            "1.3647388219833374\n",
            "Epoch #1. Accuracy on batch 380/2438  on Training is 58.94849081364829\n",
            "Epoch #1. Accuracy on batch 381/2438  on Training is 58.96596858638743\n",
            "Epoch #1. Accuracy on batch 382/2438  on Training is 58.9588772845953\n",
            "Epoch #1. Accuracy on batch 383/2438  on Training is 58.976236979166664\n",
            "Epoch #1. Accuracy on batch 384/2438  on Training is 58.97727272727273\n",
            "Epoch #1. Accuracy on batch 385/2438  on Training is 58.97830310880829\n",
            "Epoch #1. Accuracy on batch 386/2438  on Training is 58.97125322997416\n",
            "Epoch #1. Accuracy on batch 387/2438  on Training is 58.98840206185567\n",
            "Epoch #1. Accuracy on batch 388/2438  on Training is 58.98939588688946\n",
            "Epoch #1. Accuracy on batch 389/2438  on Training is 59.01442307692308\n",
            "Epoch #1. Accuracy on batch 390/2438  on Training is 59.00735294117647\n",
            "Epoch #1. Accuracy on batch 391/2438  on Training is 59.00829081632653\n",
            "Epoch #1. Accuracy on batch 392/2438  on Training is 59.017175572519086\n",
            "Epoch #1. Accuracy on batch 393/2438  on Training is 59.026015228426395\n",
            "Epoch #1. Accuracy on batch 394/2438  on Training is 59.01898734177215\n",
            "Epoch #1. Accuracy on batch 395/2438  on Training is 58.988320707070706\n",
            "Epoch #1. Accuracy on batch 396/2438  on Training is 58.997166246851386\n",
            "Epoch #1. Accuracy on batch 397/2438  on Training is 58.99811557788945\n",
            "Epoch #1. Accuracy on batch 398/2438  on Training is 59.00689223057644\n",
            "Epoch #1. Accuracy on batch 399/2438  on Training is 58.9921875\n",
            "Batch Id 400/2438 is having training loss of 1.6636402606964111\n",
            "1.5497404336929321\n",
            "Epoch #1. Accuracy on batch 400/2438  on Training is 59.00093516209476\n",
            "Epoch #1. Accuracy on batch 401/2438  on Training is 59.00186567164179\n",
            "Epoch #1. Accuracy on batch 402/2438  on Training is 59.0105459057072\n",
            "Epoch #1. Accuracy on batch 403/2438  on Training is 59.01918316831683\n",
            "Epoch #1. Accuracy on batch 404/2438  on Training is 59.02006172839506\n",
            "Epoch #1. Accuracy on batch 405/2438  on Training is 59.01323891625616\n",
            "Epoch #1. Accuracy on batch 406/2438  on Training is 59.014127764127764\n",
            "Epoch #1. Accuracy on batch 407/2438  on Training is 59.01501225490196\n",
            "Epoch #1. Accuracy on batch 408/2438  on Training is 59.02353300733496\n",
            "Epoch #1. Accuracy on batch 409/2438  on Training is 59.03963414634146\n",
            "Epoch #1. Accuracy on batch 410/2438  on Training is 59.05565693430657\n",
            "Epoch #1. Accuracy on batch 411/2438  on Training is 59.05643203883495\n",
            "Epoch #1. Accuracy on batch 412/2438  on Training is 59.03450363196126\n",
            "Epoch #1. Accuracy on batch 413/2438  on Training is 59.03532608695652\n",
            "Epoch #1. Accuracy on batch 414/2438  on Training is 59.04367469879518\n",
            "Epoch #1. Accuracy on batch 415/2438  on Training is 59.05949519230769\n",
            "Epoch #1. Accuracy on batch 416/2438  on Training is 59.030275779376495\n",
            "Epoch #1. Accuracy on batch 417/2438  on Training is 59.06848086124402\n",
            "Epoch #1. Accuracy on batch 418/2438  on Training is 59.10650357995227\n",
            "Epoch #1. Accuracy on batch 419/2438  on Training is 59.129464285714285\n",
            "Batch Id 420/2438 is having training loss of 1.6624177694320679\n",
            "1.3874070644378662\n",
            "Epoch #1. Accuracy on batch 420/2438  on Training is 59.1374703087886\n",
            "Epoch #1. Accuracy on batch 421/2438  on Training is 59.130627962085306\n",
            "Epoch #1. Accuracy on batch 422/2438  on Training is 59.13120567375886\n",
            "Epoch #1. Accuracy on batch 423/2438  on Training is 59.139150943396224\n",
            "Epoch #1. Accuracy on batch 424/2438  on Training is 59.13235294117647\n",
            "Epoch #1. Accuracy on batch 425/2438  on Training is 59.132922535211264\n",
            "Epoch #1. Accuracy on batch 426/2438  on Training is 59.12617096018735\n",
            "Epoch #1. Accuracy on batch 427/2438  on Training is 59.09754672897196\n",
            "Epoch #1. Accuracy on batch 428/2438  on Training is 59.13461538461539\n",
            "Epoch #1. Accuracy on batch 429/2438  on Training is 59.14970930232558\n",
            "Epoch #1. Accuracy on batch 430/2438  on Training is 59.15023201856148\n",
            "Epoch #1. Accuracy on batch 431/2438  on Training is 59.13628472222222\n",
            "Epoch #1. Accuracy on batch 432/2438  on Training is 59.165704387990765\n",
            "Epoch #1. Accuracy on batch 433/2438  on Training is 59.151785714285715\n",
            "Epoch #1. Accuracy on batch 434/2438  on Training is 59.173850574712645\n",
            "Epoch #1. Accuracy on batch 435/2438  on Training is 59.14564220183486\n",
            "Epoch #1. Accuracy on batch 436/2438  on Training is 59.11756292906178\n",
            "Epoch #1. Accuracy on batch 437/2438  on Training is 59.12528538812786\n",
            "Epoch #1. Accuracy on batch 438/2438  on Training is 59.147209567198175\n",
            "Epoch #1. Accuracy on batch 439/2438  on Training is 59.16193181818182\n",
            "Batch Id 440/2438 is having training loss of 1.6624215841293335\n",
            "1.3981077671051025\n",
            "Epoch #1. Accuracy on batch 440/2438  on Training is 59.169501133786845\n",
            "Epoch #1. Accuracy on batch 441/2438  on Training is 59.18410633484163\n",
            "Epoch #1. Accuracy on batch 442/2438  on Training is 59.184537246049665\n",
            "Epoch #1. Accuracy on batch 443/2438  on Training is 59.1920045045045\n",
            "Epoch #1. Accuracy on batch 444/2438  on Training is 59.17837078651685\n",
            "Epoch #1. Accuracy on batch 445/2438  on Training is 59.16479820627803\n",
            "Epoch #1. Accuracy on batch 446/2438  on Training is 59.18624161073826\n",
            "Epoch #1. Accuracy on batch 447/2438  on Training is 59.1796875\n",
            "Epoch #1. Accuracy on batch 448/2438  on Training is 59.194042316258354\n",
            "Epoch #1. Accuracy on batch 449/2438  on Training is 59.18055555555556\n",
            "Epoch #1. Accuracy on batch 450/2438  on Training is 59.18791574279379\n",
            "Epoch #1. Accuracy on batch 451/2438  on Training is 59.215984513274336\n",
            "Epoch #1. Accuracy on batch 452/2438  on Training is 59.216335540838855\n",
            "Epoch #1. Accuracy on batch 453/2438  on Training is 59.24421806167401\n",
            "Epoch #1. Accuracy on batch 454/2438  on Training is 59.26510989010989\n",
            "Epoch #1. Accuracy on batch 455/2438  on Training is 59.27905701754386\n",
            "Epoch #1. Accuracy on batch 456/2438  on Training is 59.29978118161926\n",
            "Epoch #1. Accuracy on batch 457/2438  on Training is 59.306768558951966\n",
            "Epoch #1. Accuracy on batch 458/2438  on Training is 59.28649237472767\n",
            "Epoch #1. Accuracy on batch 459/2438  on Training is 59.29347826086956\n",
            "Batch Id 460/2438 is having training loss of 1.6581107378005981\n",
            "1.4146777391433716\n",
            "Epoch #1. Accuracy on batch 460/2438  on Training is 59.31399132321041\n",
            "Epoch #1. Accuracy on batch 461/2438  on Training is 59.29383116883117\n",
            "Epoch #1. Accuracy on batch 462/2438  on Training is 59.253509719222464\n",
            "Epoch #1. Accuracy on batch 463/2438  on Training is 59.24703663793103\n",
            "Epoch #1. Accuracy on batch 464/2438  on Training is 59.200268817204304\n",
            "Epoch #1. Accuracy on batch 465/2438  on Training is 59.20734978540773\n",
            "Epoch #1. Accuracy on batch 466/2438  on Training is 59.20770877944325\n",
            "Epoch #1. Accuracy on batch 467/2438  on Training is 59.22809829059829\n",
            "Epoch #1. Accuracy on batch 468/2438  on Training is 59.24840085287846\n",
            "Epoch #1. Accuracy on batch 469/2438  on Training is 59.255319148936174\n",
            "Epoch #1. Accuracy on batch 470/2438  on Training is 59.22903397027601\n",
            "Epoch #1. Accuracy on batch 471/2438  on Training is 59.235963983050844\n",
            "Epoch #1. Accuracy on batch 472/2438  on Training is 59.2164376321353\n",
            "Epoch #1. Accuracy on batch 473/2438  on Training is 59.22336497890296\n",
            "Epoch #1. Accuracy on batch 474/2438  on Training is 59.21052631578947\n",
            "Epoch #1. Accuracy on batch 475/2438  on Training is 59.19774159663866\n",
            "Epoch #1. Accuracy on batch 476/2438  on Training is 59.198113207547166\n",
            "Epoch #1. Accuracy on batch 477/2438  on Training is 59.19194560669456\n",
            "Epoch #1. Accuracy on batch 478/2438  on Training is 59.17927974947808\n",
            "Epoch #1. Accuracy on batch 479/2438  on Training is 59.147135416666664\n",
            "Batch Id 480/2438 is having training loss of 1.6594464778900146\n",
            "1.9730991125106812\n",
            "Epoch #1. Accuracy on batch 480/2438  on Training is 59.11512474012474\n",
            "Epoch #1. Accuracy on batch 481/2438  on Training is 59.14808091286307\n",
            "Epoch #1. Accuracy on batch 482/2438  on Training is 59.12914078674948\n",
            "Epoch #1. Accuracy on batch 483/2438  on Training is 59.142561983471076\n",
            "Epoch #1. Accuracy on batch 484/2438  on Training is 59.16237113402062\n",
            "Epoch #1. Accuracy on batch 485/2438  on Training is 59.14994855967078\n",
            "Epoch #1. Accuracy on batch 486/2438  on Training is 59.15041067761807\n",
            "Epoch #1. Accuracy on batch 487/2438  on Training is 59.150870901639344\n",
            "Epoch #1. Accuracy on batch 488/2438  on Training is 59.17689161554192\n",
            "Epoch #1. Accuracy on batch 489/2438  on Training is 59.170918367346935\n",
            "Epoch #1. Accuracy on batch 490/2438  on Training is 59.18406313645621\n",
            "Epoch #1. Accuracy on batch 491/2438  on Training is 59.19080284552845\n",
            "Epoch #1. Accuracy on batch 492/2438  on Training is 59.21653144016227\n",
            "Epoch #1. Accuracy on batch 493/2438  on Training is 59.2042004048583\n",
            "Epoch #1. Accuracy on batch 494/2438  on Training is 59.19191919191919\n",
            "Epoch #1. Accuracy on batch 495/2438  on Training is 59.160786290322584\n",
            "Epoch #1. Accuracy on batch 496/2438  on Training is 59.173792756539235\n",
            "Epoch #1. Accuracy on batch 497/2438  on Training is 59.174196787148595\n",
            "Epoch #1. Accuracy on batch 498/2438  on Training is 59.16207414829659\n",
            "Epoch #1. Accuracy on batch 499/2438  on Training is 59.18125\n",
            "Batch Id 500/2438 is having training loss of 1.6573894023895264\n",
            "1.404123067855835\n",
            "Epoch #1. Accuracy on batch 500/2438  on Training is 59.2003493013972\n",
            "Epoch #1. Accuracy on batch 501/2438  on Training is 59.175796812749006\n",
            "Epoch #1. Accuracy on batch 502/2438  on Training is 59.1948310139165\n",
            "Epoch #1. Accuracy on batch 503/2438  on Training is 59.201388888888886\n",
            "Epoch #1. Accuracy on batch 504/2438  on Training is 59.17079207920792\n",
            "Epoch #1. Accuracy on batch 505/2438  on Training is 59.17737154150198\n",
            "Epoch #1. Accuracy on batch 506/2438  on Training is 59.17776134122288\n",
            "Epoch #1. Accuracy on batch 507/2438  on Training is 59.17199803149607\n",
            "Epoch #1. Accuracy on batch 508/2438  on Training is 59.196954813359525\n",
            "Epoch #1. Accuracy on batch 509/2438  on Training is 59.22181372549019\n",
            "Epoch #1. Accuracy on batch 510/2438  on Training is 59.24045988258317\n",
            "Epoch #1. Accuracy on batch 511/2438  on Training is 59.246826171875\n",
            "Epoch #1. Accuracy on batch 512/2438  on Training is 59.22270955165692\n",
            "Epoch #1. Accuracy on batch 513/2438  on Training is 59.20476653696498\n",
            "Epoch #1. Accuracy on batch 514/2438  on Training is 59.199029126213595\n",
            "Epoch #1. Accuracy on batch 515/2438  on Training is 59.21753875968992\n",
            "Epoch #1. Accuracy on batch 516/2438  on Training is 59.199709864603484\n",
            "Epoch #1. Accuracy on batch 517/2438  on Training is 59.200048262548265\n",
            "Epoch #1. Accuracy on batch 518/2438  on Training is 59.22447013487476\n",
            "Epoch #1. Accuracy on batch 519/2438  on Training is 59.24278846153846\n",
            "Batch Id 520/2438 is having training loss of 1.6556639671325684\n",
            "1.8197306394577026\n",
            "Epoch #1. Accuracy on batch 520/2438  on Training is 59.23704414587332\n",
            "Epoch #1. Accuracy on batch 521/2438  on Training is 59.24329501915709\n",
            "Epoch #1. Accuracy on batch 522/2438  on Training is 59.27342256214149\n",
            "Epoch #1. Accuracy on batch 523/2438  on Training is 59.27361641221374\n",
            "Epoch #1. Accuracy on batch 524/2438  on Training is 59.279761904761905\n",
            "Epoch #1. Accuracy on batch 525/2438  on Training is 59.274001901140686\n",
            "Epoch #1. Accuracy on batch 526/2438  on Training is 59.291982922201136\n",
            "Epoch #1. Accuracy on batch 527/2438  on Training is 59.31581439393939\n",
            "Epoch #1. Accuracy on batch 528/2438  on Training is 59.29820415879017\n",
            "Epoch #1. Accuracy on batch 529/2438  on Training is 59.28655660377358\n",
            "Epoch #1. Accuracy on batch 530/2438  on Training is 59.263182674199626\n",
            "Epoch #1. Accuracy on batch 531/2438  on Training is 59.26926691729323\n",
            "Epoch #1. Accuracy on batch 532/2438  on Training is 59.25773921200751\n",
            "Epoch #1. Accuracy on batch 533/2438  on Training is 59.22284644194757\n",
            "Epoch #1. Accuracy on batch 534/2438  on Training is 59.228971962616825\n",
            "Epoch #1. Accuracy on batch 535/2438  on Training is 59.25839552238806\n",
            "Epoch #1. Accuracy on batch 536/2438  on Training is 59.252793296089386\n",
            "Epoch #1. Accuracy on batch 537/2438  on Training is 59.25882899628253\n",
            "Epoch #1. Accuracy on batch 538/2438  on Training is 59.253246753246756\n",
            "Epoch #1. Accuracy on batch 539/2438  on Training is 59.270833333333336\n",
            "Batch Id 540/2438 is having training loss of 1.6542649269104004\n",
            "1.6844682693481445\n",
            "Epoch #1. Accuracy on batch 540/2438  on Training is 59.2710258780037\n",
            "Epoch #1. Accuracy on batch 541/2438  on Training is 59.27698339483395\n",
            "Epoch #1. Accuracy on batch 542/2438  on Training is 59.28867403314917\n",
            "Epoch #1. Accuracy on batch 543/2438  on Training is 59.30606617647059\n",
            "Epoch #1. Accuracy on batch 544/2438  on Training is 59.32912844036697\n",
            "Epoch #1. Accuracy on batch 545/2438  on Training is 59.32921245421245\n",
            "Epoch #1. Accuracy on batch 546/2438  on Training is 59.32929616087751\n",
            "Epoch #1. Accuracy on batch 547/2438  on Training is 59.31797445255474\n",
            "Epoch #1. Accuracy on batch 548/2438  on Training is 59.318078324225866\n",
            "Epoch #1. Accuracy on batch 549/2438  on Training is 59.35227272727273\n",
            "Epoch #1. Accuracy on batch 550/2438  on Training is 59.35798548094374\n",
            "Epoch #1. Accuracy on batch 551/2438  on Training is 59.352355072463766\n",
            "Epoch #1. Accuracy on batch 552/2438  on Training is 59.346745027124776\n",
            "Epoch #1. Accuracy on batch 553/2438  on Training is 59.34679602888087\n",
            "Epoch #1. Accuracy on batch 554/2438  on Training is 59.34121621621622\n",
            "Epoch #1. Accuracy on batch 555/2438  on Training is 59.35251798561151\n",
            "Epoch #1. Accuracy on batch 556/2438  on Training is 59.369389587073606\n",
            "Epoch #1. Accuracy on batch 557/2438  on Training is 59.352598566308245\n",
            "Epoch #1. Accuracy on batch 558/2438  on Training is 59.34704830053667\n",
            "Epoch #1. Accuracy on batch 559/2438  on Training is 59.347098214285715\n",
            "Batch Id 560/2438 is having training loss of 1.6540179252624512\n",
            "1.9290841817855835\n",
            "Epoch #1. Accuracy on batch 560/2438  on Training is 59.3304367201426\n",
            "Epoch #1. Accuracy on batch 561/2438  on Training is 59.3471975088968\n",
            "Epoch #1. Accuracy on batch 562/2438  on Training is 59.33614564831261\n",
            "Epoch #1. Accuracy on batch 563/2438  on Training is 59.31959219858156\n",
            "Epoch #1. Accuracy on batch 564/2438  on Training is 59.325221238938056\n",
            "Epoch #1. Accuracy on batch 565/2438  on Training is 59.32530918727915\n",
            "Epoch #1. Accuracy on batch 566/2438  on Training is 59.363977072310405\n",
            "Epoch #1. Accuracy on batch 567/2438  on Training is 59.36399647887324\n",
            "Epoch #1. Accuracy on batch 568/2438  on Training is 59.353031634446396\n",
            "Epoch #1. Accuracy on batch 569/2438  on Training is 59.33114035087719\n",
            "Epoch #1. Accuracy on batch 570/2438  on Training is 59.30932574430823\n",
            "Epoch #1. Accuracy on batch 571/2438  on Training is 59.30944055944056\n",
            "Epoch #1. Accuracy on batch 572/2438  on Training is 59.282286212914485\n",
            "Epoch #1. Accuracy on batch 573/2438  on Training is 59.27700348432056\n",
            "Epoch #1. Accuracy on batch 574/2438  on Training is 59.27717391304348\n",
            "Epoch #1. Accuracy on batch 575/2438  on Training is 59.299045138888886\n",
            "Epoch #1. Accuracy on batch 576/2438  on Training is 59.2775129982669\n",
            "Epoch #1. Accuracy on batch 577/2438  on Training is 59.30471453287197\n",
            "Epoch #1. Accuracy on batch 578/2438  on Training is 59.31023316062176\n",
            "Epoch #1. Accuracy on batch 579/2438  on Training is 59.29956896551724\n",
            "Batch Id 580/2438 is having training loss of 1.653265118598938\n",
            "1.5874232053756714\n",
            "Epoch #1. Accuracy on batch 580/2438  on Training is 59.299698795180724\n",
            "Epoch #1. Accuracy on batch 581/2438  on Training is 59.299828178694156\n",
            "Epoch #1. Accuracy on batch 582/2438  on Training is 59.29995711835335\n",
            "Epoch #1. Accuracy on batch 583/2438  on Training is 59.321489726027394\n",
            "Epoch #1. Accuracy on batch 584/2438  on Training is 59.332264957264954\n",
            "Epoch #1. Accuracy on batch 585/2438  on Training is 59.3216723549488\n",
            "Epoch #1. Accuracy on batch 586/2438  on Training is 59.32708688245315\n",
            "Epoch #1. Accuracy on batch 587/2438  on Training is 59.33248299319728\n",
            "Epoch #1. Accuracy on batch 588/2438  on Training is 59.36438879456706\n",
            "Epoch #1. Accuracy on batch 589/2438  on Training is 59.369703389830505\n",
            "Epoch #1. Accuracy on batch 590/2438  on Training is 59.38557529610829\n",
            "Epoch #1. Accuracy on batch 591/2438  on Training is 59.411951013513516\n",
            "Epoch #1. Accuracy on batch 592/2438  on Training is 59.41715851602024\n",
            "Epoch #1. Accuracy on batch 593/2438  on Training is 59.406565656565654\n",
            "Epoch #1. Accuracy on batch 594/2438  on Training is 59.40651260504202\n",
            "Epoch #1. Accuracy on batch 595/2438  on Training is 59.395973154362416\n",
            "Epoch #1. Accuracy on batch 596/2438  on Training is 59.40640703517588\n",
            "Epoch #1. Accuracy on batch 597/2438  on Training is 59.40635451505017\n",
            "Epoch #1. Accuracy on batch 598/2438  on Training is 59.40630217028381\n",
            "Epoch #1. Accuracy on batch 599/2438  on Training is 59.40625\n",
            "Batch Id 600/2438 is having training loss of 1.6486235857009888\n",
            "1.2692337036132812\n",
            "Epoch #1. Accuracy on batch 600/2438  on Training is 59.43219633943428\n",
            "Epoch #1. Accuracy on batch 601/2438  on Training is 59.426910299003325\n",
            "Epoch #1. Accuracy on batch 602/2438  on Training is 59.43718905472637\n",
            "Epoch #1. Accuracy on batch 603/2438  on Training is 59.42673841059602\n",
            "Epoch #1. Accuracy on batch 604/2438  on Training is 59.43181818181818\n",
            "Epoch #1. Accuracy on batch 605/2438  on Training is 59.431724422442244\n",
            "Epoch #1. Accuracy on batch 606/2438  on Training is 59.41618616144975\n",
            "Epoch #1. Accuracy on batch 607/2438  on Training is 59.410978618421055\n",
            "Epoch #1. Accuracy on batch 608/2438  on Training is 59.4057881773399\n",
            "Epoch #1. Accuracy on batch 609/2438  on Training is 59.385245901639344\n",
            "Epoch #1. Accuracy on batch 610/2438  on Training is 59.375\n",
            "Epoch #1. Accuracy on batch 611/2438  on Training is 59.39031862745098\n",
            "Epoch #1. Accuracy on batch 612/2438  on Training is 59.385195758564436\n",
            "Epoch #1. Accuracy on batch 613/2438  on Training is 59.375\n",
            "Epoch #1. Accuracy on batch 614/2438  on Training is 59.395325203252035\n",
            "Epoch #1. Accuracy on batch 615/2438  on Training is 59.39021915584416\n",
            "Epoch #1. Accuracy on batch 616/2438  on Training is 59.36487034035656\n",
            "Epoch #1. Accuracy on batch 617/2438  on Training is 59.36994336569579\n",
            "Epoch #1. Accuracy on batch 618/2438  on Training is 59.35985460420032\n",
            "Epoch #1. Accuracy on batch 619/2438  on Training is 59.36995967741935\n",
            "Batch Id 620/2438 is having training loss of 1.6501214504241943\n",
            "2.057466506958008\n",
            "Epoch #1. Accuracy on batch 620/2438  on Training is 59.34983896940419\n",
            "Epoch #1. Accuracy on batch 621/2438  on Training is 59.34485530546624\n",
            "Epoch #1. Accuracy on batch 622/2438  on Training is 59.34991974317817\n",
            "Epoch #1. Accuracy on batch 623/2438  on Training is 59.309895833333336\n",
            "Epoch #1. Accuracy on batch 624/2438  on Training is 59.3\n",
            "Epoch #1. Accuracy on batch 625/2438  on Training is 59.29512779552716\n",
            "Epoch #1. Accuracy on batch 626/2438  on Training is 59.2902711323764\n",
            "Epoch #1. Accuracy on batch 627/2438  on Training is 59.28045382165605\n",
            "Epoch #1. Accuracy on batch 628/2438  on Training is 59.28060413354531\n",
            "Epoch #1. Accuracy on batch 629/2438  on Training is 59.28075396825397\n",
            "Epoch #1. Accuracy on batch 630/2438  on Training is 59.27595087163233\n",
            "Epoch #1. Accuracy on batch 631/2438  on Training is 59.27610759493671\n",
            "Epoch #1. Accuracy on batch 632/2438  on Training is 59.30588467614534\n",
            "Epoch #1. Accuracy on batch 633/2438  on Training is 59.28134858044164\n",
            "Epoch #1. Accuracy on batch 634/2438  on Training is 59.27165354330709\n",
            "Epoch #1. Accuracy on batch 635/2438  on Training is 59.257075471698116\n",
            "Epoch #1. Accuracy on batch 636/2438  on Training is 59.232731554160125\n",
            "Epoch #1. Accuracy on batch 637/2438  on Training is 59.22805642633229\n",
            "Epoch #1. Accuracy on batch 638/2438  on Training is 59.21850547730829\n",
            "Epoch #1. Accuracy on batch 639/2438  on Training is 59.2138671875\n",
            "Batch Id 640/2438 is having training loss of 1.6543909311294556\n",
            "1.3904051780700684\n",
            "Epoch #1. Accuracy on batch 640/2438  on Training is 59.21411856474259\n",
            "Epoch #1. Accuracy on batch 641/2438  on Training is 59.199766355140184\n",
            "Epoch #1. Accuracy on batch 642/2438  on Training is 59.21461897356143\n",
            "Epoch #1. Accuracy on batch 643/2438  on Training is 59.21001552795031\n",
            "Epoch #1. Accuracy on batch 644/2438  on Training is 59.23449612403101\n",
            "Epoch #1. Accuracy on batch 645/2438  on Training is 59.234713622291025\n",
            "Epoch #1. Accuracy on batch 646/2438  on Training is 59.22044049459042\n",
            "Epoch #1. Accuracy on batch 647/2438  on Training is 59.23996913580247\n",
            "Epoch #1. Accuracy on batch 648/2438  on Training is 59.26425269645608\n",
            "Epoch #1. Accuracy on batch 649/2438  on Training is 59.24519230769231\n",
            "Epoch #1. Accuracy on batch 650/2438  on Training is 59.264592933947775\n",
            "Epoch #1. Accuracy on batch 651/2438  on Training is 59.25996932515337\n",
            "Epoch #1. Accuracy on batch 652/2438  on Training is 59.27928790199081\n",
            "Epoch #1. Accuracy on batch 653/2438  on Training is 59.2842125382263\n",
            "Epoch #1. Accuracy on batch 654/2438  on Training is 59.284351145038165\n",
            "Epoch #1. Accuracy on batch 655/2438  on Training is 59.28448932926829\n",
            "Epoch #1. Accuracy on batch 656/2438  on Training is 59.27511415525114\n",
            "Epoch #1. Accuracy on batch 657/2438  on Training is 59.28001519756839\n",
            "Epoch #1. Accuracy on batch 658/2438  on Training is 59.284901365705615\n",
            "Epoch #1. Accuracy on batch 659/2438  on Training is 59.28977272727273\n",
            "Batch Id 660/2438 is having training loss of 1.6511924266815186\n",
            "1.6537851095199585\n",
            "Epoch #1. Accuracy on batch 660/2438  on Training is 59.27099092284418\n",
            "Epoch #1. Accuracy on batch 661/2438  on Training is 59.27114803625378\n",
            "Epoch #1. Accuracy on batch 662/2438  on Training is 59.257164404223225\n",
            "Epoch #1. Accuracy on batch 663/2438  on Training is 59.2714608433735\n",
            "Epoch #1. Accuracy on batch 664/2438  on Training is 59.27161654135338\n",
            "Epoch #1. Accuracy on batch 665/2438  on Training is 59.28115615615616\n",
            "Epoch #1. Accuracy on batch 666/2438  on Training is 59.30003748125937\n",
            "Epoch #1. Accuracy on batch 667/2438  on Training is 59.28611526946108\n",
            "Epoch #1. Accuracy on batch 668/2438  on Training is 59.276905829596416\n",
            "Epoch #1. Accuracy on batch 669/2438  on Training is 59.25839552238806\n",
            "Epoch #1. Accuracy on batch 670/2438  on Training is 59.24459761549925\n",
            "Epoch #1. Accuracy on batch 671/2438  on Training is 59.25874255952381\n",
            "Epoch #1. Accuracy on batch 672/2438  on Training is 59.27284546805349\n",
            "Epoch #1. Accuracy on batch 673/2438  on Training is 59.28227002967359\n",
            "Epoch #1. Accuracy on batch 674/2438  on Training is 59.291666666666664\n",
            "Epoch #1. Accuracy on batch 675/2438  on Training is 59.29641272189349\n",
            "Epoch #1. Accuracy on batch 676/2438  on Training is 59.29652880354505\n",
            "Epoch #1. Accuracy on batch 677/2438  on Training is 59.31047197640118\n",
            "Epoch #1. Accuracy on batch 678/2438  on Training is 59.31977172312224\n",
            "Epoch #1. Accuracy on batch 679/2438  on Training is 59.310661764705884\n",
            "Batch Id 680/2438 is having training loss of 1.6501744985580444\n",
            "1.6264015436172485\n",
            "Epoch #1. Accuracy on batch 680/2438  on Training is 59.315345080763585\n",
            "Epoch #1. Accuracy on batch 681/2438  on Training is 59.315432551319645\n",
            "Epoch #1. Accuracy on batch 682/2438  on Training is 59.297218155197655\n",
            "Epoch #1. Accuracy on batch 683/2438  on Training is 59.29276315789474\n",
            "Epoch #1. Accuracy on batch 684/2438  on Training is 59.292883211678834\n",
            "Epoch #1. Accuracy on batch 685/2438  on Training is 59.28389212827988\n",
            "Epoch #1. Accuracy on batch 686/2438  on Training is 59.29312227074236\n",
            "Epoch #1. Accuracy on batch 687/2438  on Training is 59.28869912790697\n",
            "Epoch #1. Accuracy on batch 688/2438  on Training is 59.29335994194485\n",
            "Epoch #1. Accuracy on batch 689/2438  on Training is 59.29347826086956\n",
            "Epoch #1. Accuracy on batch 690/2438  on Training is 59.275506512301014\n",
            "Epoch #1. Accuracy on batch 691/2438  on Training is 59.27565028901734\n",
            "Epoch #1. Accuracy on batch 692/2438  on Training is 59.28030303030303\n",
            "Epoch #1. Accuracy on batch 693/2438  on Training is 59.26693083573487\n",
            "Epoch #1. Accuracy on batch 694/2438  on Training is 59.25359712230216\n",
            "Epoch #1. Accuracy on batch 695/2438  on Training is 59.262751436781606\n",
            "Epoch #1. Accuracy on batch 696/2438  on Training is 59.2853299856528\n",
            "Epoch #1. Accuracy on batch 697/2438  on Training is 59.28098137535817\n",
            "Epoch #1. Accuracy on batch 698/2438  on Training is 59.29005722460658\n",
            "Epoch #1. Accuracy on batch 699/2438  on Training is 59.285714285714285\n",
            "Batch Id 700/2438 is having training loss of 1.6508064270019531\n",
            "1.669824481010437\n",
            "Epoch #1. Accuracy on batch 700/2438  on Training is 59.281383737517835\n",
            "Epoch #1. Accuracy on batch 701/2438  on Training is 59.26816239316239\n",
            "Epoch #1. Accuracy on batch 702/2438  on Training is 59.277204836415365\n",
            "Epoch #1. Accuracy on batch 703/2438  on Training is 59.28178267045455\n",
            "Epoch #1. Accuracy on batch 704/2438  on Training is 59.2863475177305\n",
            "Epoch #1. Accuracy on batch 705/2438  on Training is 59.29975212464589\n",
            "Epoch #1. Accuracy on batch 706/2438  on Training is 59.28217821782178\n",
            "Epoch #1. Accuracy on batch 707/2438  on Training is 59.291137005649716\n",
            "Epoch #1. Accuracy on batch 708/2438  on Training is 59.291255289139634\n",
            "Epoch #1. Accuracy on batch 709/2438  on Training is 59.29577464788732\n",
            "Epoch #1. Accuracy on batch 710/2438  on Training is 59.28709563994374\n",
            "Epoch #1. Accuracy on batch 711/2438  on Training is 59.278441011235955\n",
            "Epoch #1. Accuracy on batch 712/2438  on Training is 59.26981065918653\n",
            "Epoch #1. Accuracy on batch 713/2438  on Training is 59.283088235294116\n",
            "Epoch #1. Accuracy on batch 714/2438  on Training is 59.27447552447553\n",
            "Epoch #1. Accuracy on batch 715/2438  on Training is 59.26588687150838\n",
            "Epoch #1. Accuracy on batch 716/2438  on Training is 59.266039051603904\n",
            "Epoch #1. Accuracy on batch 717/2438  on Training is 59.27054317548747\n",
            "Epoch #1. Accuracy on batch 718/2438  on Training is 59.27068845618915\n",
            "Epoch #1. Accuracy on batch 719/2438  on Training is 59.296875\n",
            "Batch Id 720/2438 is having training loss of 1.6514437198638916\n",
            "1.8350340127944946\n",
            "Epoch #1. Accuracy on batch 720/2438  on Training is 59.28398058252427\n",
            "Epoch #1. Accuracy on batch 721/2438  on Training is 59.28843490304709\n",
            "Epoch #1. Accuracy on batch 722/2438  on Training is 59.25829875518672\n",
            "Epoch #1. Accuracy on batch 723/2438  on Training is 59.24551104972376\n",
            "Epoch #1. Accuracy on batch 724/2438  on Training is 59.258620689655174\n",
            "Epoch #1. Accuracy on batch 725/2438  on Training is 59.237258953168045\n",
            "Epoch #1. Accuracy on batch 726/2438  on Training is 59.22455295735901\n",
            "Epoch #1. Accuracy on batch 727/2438  on Training is 59.21617445054945\n",
            "Epoch #1. Accuracy on batch 728/2438  on Training is 59.20353223593964\n",
            "Epoch #1. Accuracy on batch 729/2438  on Training is 59.2208904109589\n",
            "Epoch #1. Accuracy on batch 730/2438  on Training is 59.22110123119015\n",
            "Epoch #1. Accuracy on batch 731/2438  on Training is 59.212773224043715\n",
            "Epoch #1. Accuracy on batch 732/2438  on Training is 59.22578444747612\n",
            "Epoch #1. Accuracy on batch 733/2438  on Training is 59.24301771117166\n",
            "Epoch #1. Accuracy on batch 734/2438  on Training is 59.230442176870746\n",
            "Epoch #1. Accuracy on batch 735/2438  on Training is 59.23913043478261\n",
            "Epoch #1. Accuracy on batch 736/2438  on Training is 59.22659430122117\n",
            "Epoch #1. Accuracy on batch 737/2438  on Training is 59.21409214092141\n",
            "Epoch #1. Accuracy on batch 738/2438  on Training is 59.214309878213804\n",
            "Epoch #1. Accuracy on batch 739/2438  on Training is 59.214527027027025\n",
            "Batch Id 740/2438 is having training loss of 1.6556804180145264\n",
            "1.7794504165649414\n",
            "Epoch #1. Accuracy on batch 740/2438  on Training is 59.21052631578947\n",
            "Epoch #1. Accuracy on batch 741/2438  on Training is 59.23601752021563\n",
            "Epoch #1. Accuracy on batch 742/2438  on Training is 59.24461641991925\n",
            "Epoch #1. Accuracy on batch 743/2438  on Training is 59.240591397849464\n",
            "Epoch #1. Accuracy on batch 744/2438  on Training is 59.23238255033557\n",
            "Epoch #1. Accuracy on batch 745/2438  on Training is 59.22419571045577\n",
            "Epoch #1. Accuracy on batch 746/2438  on Training is 59.23694779116466\n",
            "Epoch #1. Accuracy on batch 747/2438  on Training is 59.245487967914436\n",
            "Epoch #1. Accuracy on batch 748/2438  on Training is 59.254005340453936\n",
            "Epoch #1. Accuracy on batch 749/2438  on Training is 59.270833333333336\n",
            "Epoch #1. Accuracy on batch 750/2438  on Training is 59.266810918774965\n",
            "Epoch #1. Accuracy on batch 751/2438  on Training is 59.254488031914896\n",
            "Epoch #1. Accuracy on batch 752/2438  on Training is 59.22974767596281\n",
            "Epoch #1. Accuracy on batch 753/2438  on Training is 59.250663129973475\n",
            "Epoch #1. Accuracy on batch 754/2438  on Training is 59.259105960264904\n",
            "Epoch #1. Accuracy on batch 755/2438  on Training is 59.263392857142854\n",
            "Epoch #1. Accuracy on batch 756/2438  on Training is 59.28005284015852\n",
            "Epoch #1. Accuracy on batch 757/2438  on Training is 59.28017810026385\n",
            "Epoch #1. Accuracy on batch 758/2438  on Training is 59.267951251646906\n",
            "Epoch #1. Accuracy on batch 759/2438  on Training is 59.239309210526315\n",
            "Batch Id 760/2438 is having training loss of 1.6539239883422852\n",
            "1.5818077325820923\n",
            "Epoch #1. Accuracy on batch 760/2438  on Training is 59.239487516425754\n",
            "Epoch #1. Accuracy on batch 761/2438  on Training is 59.24786745406824\n",
            "Epoch #1. Accuracy on batch 762/2438  on Training is 59.23984272608126\n",
            "Epoch #1. Accuracy on batch 763/2438  on Training is 59.21956806282723\n",
            "Epoch #1. Accuracy on batch 764/2438  on Training is 59.22385620915033\n",
            "Epoch #1. Accuracy on batch 765/2438  on Training is 59.23221279373368\n",
            "Epoch #1. Accuracy on batch 766/2438  on Training is 59.21202737940026\n",
            "Epoch #1. Accuracy on batch 767/2438  on Training is 59.195963541666664\n",
            "Epoch #1. Accuracy on batch 768/2438  on Training is 59.208387516254874\n",
            "Epoch #1. Accuracy on batch 769/2438  on Training is 59.208603896103895\n",
            "Epoch #1. Accuracy on batch 770/2438  on Training is 59.22908560311284\n",
            "Epoch #1. Accuracy on batch 771/2438  on Training is 59.237370466321245\n",
            "Epoch #1. Accuracy on batch 772/2438  on Training is 59.24159120310479\n",
            "Epoch #1. Accuracy on batch 773/2438  on Training is 59.25387596899225\n",
            "Epoch #1. Accuracy on batch 774/2438  on Training is 59.266129032258064\n",
            "Epoch #1. Accuracy on batch 775/2438  on Training is 59.27029639175258\n",
            "Epoch #1. Accuracy on batch 776/2438  on Training is 59.274453024453024\n",
            "Epoch #1. Accuracy on batch 777/2438  on Training is 59.27859897172237\n",
            "Epoch #1. Accuracy on batch 778/2438  on Training is 59.27872272143774\n",
            "Epoch #1. Accuracy on batch 779/2438  on Training is 59.28285256410256\n",
            "Batch Id 780/2438 is having training loss of 1.6533652544021606\n",
            "1.691435694694519\n",
            "Epoch #1. Accuracy on batch 780/2438  on Training is 59.278969270166456\n",
            "Epoch #1. Accuracy on batch 781/2438  on Training is 59.29108056265984\n",
            "Epoch #1. Accuracy on batch 782/2438  on Training is 59.299169859514684\n",
            "Epoch #1. Accuracy on batch 783/2438  on Training is 59.295280612244895\n",
            "Epoch #1. Accuracy on batch 784/2438  on Training is 59.29140127388535\n",
            "Epoch #1. Accuracy on batch 785/2438  on Training is 59.30343511450382\n",
            "Epoch #1. Accuracy on batch 786/2438  on Training is 59.29161372299873\n",
            "Epoch #1. Accuracy on batch 787/2438  on Training is 59.29171954314721\n",
            "Epoch #1. Accuracy on batch 788/2438  on Training is 59.291825095057035\n",
            "Epoch #1. Accuracy on batch 789/2438  on Training is 59.284018987341774\n",
            "Epoch #1. Accuracy on batch 790/2438  on Training is 59.30783817951959\n",
            "Epoch #1. Accuracy on batch 791/2438  on Training is 59.311868686868685\n",
            "Epoch #1. Accuracy on batch 792/2438  on Training is 59.30800756620429\n",
            "Epoch #1. Accuracy on batch 793/2438  on Training is 59.31202770780856\n",
            "Epoch #1. Accuracy on batch 794/2438  on Training is 59.312106918238996\n",
            "Epoch #1. Accuracy on batch 795/2438  on Training is 59.2964824120603\n",
            "Epoch #1. Accuracy on batch 796/2438  on Training is 59.30834378920954\n",
            "Epoch #1. Accuracy on batch 797/2438  on Training is 59.30059523809524\n",
            "Epoch #1. Accuracy on batch 798/2438  on Training is 59.308510638297875\n",
            "Epoch #1. Accuracy on batch 799/2438  on Training is 59.3203125\n",
            "Batch Id 800/2438 is having training loss of 1.6519938707351685\n",
            "1.7116550207138062\n",
            "Epoch #1. Accuracy on batch 800/2438  on Training is 59.31257802746567\n",
            "Epoch #1. Accuracy on batch 801/2438  on Training is 59.324345386533665\n",
            "Epoch #1. Accuracy on batch 802/2438  on Training is 59.320516811955166\n",
            "Epoch #1. Accuracy on batch 803/2438  on Training is 59.33224502487562\n",
            "Epoch #1. Accuracy on batch 804/2438  on Training is 59.34782608695652\n",
            "Epoch #1. Accuracy on batch 805/2438  on Training is 59.359491315136474\n",
            "Epoch #1. Accuracy on batch 806/2438  on Training is 59.351765799256505\n",
            "Epoch #1. Accuracy on batch 807/2438  on Training is 59.363397277227726\n",
            "Epoch #1. Accuracy on batch 808/2438  on Training is 59.36727441285538\n",
            "Epoch #1. Accuracy on batch 809/2438  on Training is 59.37114197530864\n",
            "Epoch #1. Accuracy on batch 810/2438  on Training is 59.3865598027127\n",
            "Epoch #1. Accuracy on batch 811/2438  on Training is 59.39039408866995\n",
            "Epoch #1. Accuracy on batch 812/2438  on Training is 59.38268757687577\n",
            "Epoch #1. Accuracy on batch 813/2438  on Training is 59.37883906633907\n",
            "Epoch #1. Accuracy on batch 814/2438  on Training is 59.37116564417178\n",
            "Epoch #1. Accuracy on batch 815/2438  on Training is 59.38265931372549\n",
            "Epoch #1. Accuracy on batch 816/2438  on Training is 59.37117503059976\n",
            "Epoch #1. Accuracy on batch 817/2438  on Training is 59.375\n",
            "Epoch #1. Accuracy on batch 818/2438  on Training is 59.36355311355312\n",
            "Epoch #1. Accuracy on batch 819/2438  on Training is 59.35594512195122\n",
            "Batch Id 820/2438 is having training loss of 1.6490854024887085\n",
            "1.1681413650512695\n",
            "Epoch #1. Accuracy on batch 820/2438  on Training is 59.36738733252132\n",
            "Epoch #1. Accuracy on batch 821/2438  on Training is 59.35979318734793\n",
            "Epoch #1. Accuracy on batch 822/2438  on Training is 59.36740583232078\n",
            "Epoch #1. Accuracy on batch 823/2438  on Training is 59.36362257281554\n",
            "Epoch #1. Accuracy on batch 824/2438  on Training is 59.371212121212125\n",
            "Epoch #1. Accuracy on batch 825/2438  on Training is 59.375\n",
            "Epoch #1. Accuracy on batch 826/2438  on Training is 59.39011487303507\n",
            "Epoch #1. Accuracy on batch 827/2438  on Training is 59.39387077294686\n",
            "Epoch #1. Accuracy on batch 828/2438  on Training is 59.397617611580216\n",
            "Epoch #1. Accuracy on batch 829/2438  on Training is 59.408885542168676\n",
            "Epoch #1. Accuracy on batch 830/2438  on Training is 59.416365824308066\n",
            "Epoch #1. Accuracy on batch 831/2438  on Training is 59.42007211538461\n",
            "Epoch #1. Accuracy on batch 832/2438  on Training is 59.44252701080432\n",
            "Epoch #1. Accuracy on batch 833/2438  on Training is 59.43869904076739\n",
            "Epoch #1. Accuracy on batch 834/2438  on Training is 59.4311377245509\n",
            "Epoch #1. Accuracy on batch 835/2438  on Training is 59.43107057416268\n",
            "Epoch #1. Accuracy on batch 836/2438  on Training is 59.44967144563919\n",
            "Epoch #1. Accuracy on batch 837/2438  on Training is 59.44585322195704\n",
            "Epoch #1. Accuracy on batch 838/2438  on Training is 59.41969606674613\n",
            "Epoch #1. Accuracy on batch 839/2438  on Training is 59.408482142857146\n",
            "Batch Id 840/2438 is having training loss of 1.6473643779754639\n",
            "1.5064839124679565\n",
            "Epoch #1. Accuracy on batch 840/2438  on Training is 59.408442330558856\n",
            "Epoch #1. Accuracy on batch 841/2438  on Training is 59.412114014251785\n",
            "Epoch #1. Accuracy on batch 842/2438  on Training is 59.404655990510086\n",
            "Epoch #1. Accuracy on batch 843/2438  on Training is 59.38240521327014\n",
            "Epoch #1. Accuracy on batch 844/2438  on Training is 59.375\n",
            "Epoch #1. Accuracy on batch 845/2438  on Training is 59.375\n",
            "Epoch #1. Accuracy on batch 846/2438  on Training is 59.36393152302243\n",
            "Epoch #1. Accuracy on batch 847/2438  on Training is 59.378685141509436\n",
            "Epoch #1. Accuracy on batch 848/2438  on Training is 59.38236160188457\n",
            "Epoch #1. Accuracy on batch 849/2438  on Training is 59.38970588235294\n",
            "Epoch #1. Accuracy on batch 850/2438  on Training is 59.37867215041128\n",
            "Epoch #1. Accuracy on batch 851/2438  on Training is 59.382335680751176\n",
            "Epoch #1. Accuracy on batch 852/2438  on Training is 59.37866354044549\n",
            "Epoch #1. Accuracy on batch 853/2438  on Training is 59.37134074941452\n",
            "Epoch #1. Accuracy on batch 854/2438  on Training is 59.375\n",
            "Epoch #1. Accuracy on batch 855/2438  on Training is 59.37865070093458\n",
            "Epoch #1. Accuracy on batch 856/2438  on Training is 59.37864644107351\n",
            "Epoch #1. Accuracy on batch 857/2438  on Training is 59.38592657342657\n",
            "Epoch #1. Accuracy on batch 858/2438  on Training is 59.37863795110594\n",
            "Epoch #1. Accuracy on batch 859/2438  on Training is 59.364098837209305\n",
            "Batch Id 860/2438 is having training loss of 1.6487840414047241\n",
            "1.8833205699920654\n",
            "Epoch #1. Accuracy on batch 860/2438  on Training is 59.3568524970964\n",
            "Epoch #1. Accuracy on batch 861/2438  on Training is 59.35687354988399\n",
            "Epoch #1. Accuracy on batch 862/2438  on Training is 59.35689455388181\n",
            "Epoch #1. Accuracy on batch 863/2438  on Training is 59.353298611111114\n",
            "Epoch #1. Accuracy on batch 864/2438  on Training is 59.36777456647399\n",
            "Epoch #1. Accuracy on batch 865/2438  on Training is 59.378608545034645\n",
            "Epoch #1. Accuracy on batch 866/2438  on Training is 59.38220876585928\n",
            "Epoch #1. Accuracy on batch 867/2438  on Training is 59.367799539170505\n",
            "Epoch #1. Accuracy on batch 868/2438  on Training is 59.35342347525892\n",
            "Epoch #1. Accuracy on batch 869/2438  on Training is 59.35344827586207\n",
            "Epoch #1. Accuracy on batch 870/2438  on Training is 59.342709529276696\n",
            "Epoch #1. Accuracy on batch 871/2438  on Training is 59.34991399082569\n",
            "Epoch #1. Accuracy on batch 872/2438  on Training is 59.34636311569301\n",
            "Epoch #1. Accuracy on batch 873/2438  on Training is 59.35712242562929\n",
            "Epoch #1. Accuracy on batch 874/2438  on Training is 59.34642857142857\n",
            "Epoch #1. Accuracy on batch 875/2438  on Training is 59.34289383561644\n",
            "Epoch #1. Accuracy on batch 876/2438  on Training is 59.35362029646522\n",
            "Epoch #1. Accuracy on batch 877/2438  on Training is 59.35364464692483\n",
            "Epoch #1. Accuracy on batch 878/2438  on Training is 59.339448236632535\n",
            "Epoch #1. Accuracy on batch 879/2438  on Training is 59.3359375\n",
            "Batch Id 880/2438 is having training loss of 1.6500203609466553\n",
            "2.2162251472473145\n",
            "Epoch #1. Accuracy on batch 880/2438  on Training is 59.314699205448356\n",
            "Epoch #1. Accuracy on batch 881/2438  on Training is 59.31831065759637\n",
            "Epoch #1. Accuracy on batch 882/2438  on Training is 59.33253114382786\n",
            "Epoch #1. Accuracy on batch 883/2438  on Training is 59.33257918552036\n",
            "Epoch #1. Accuracy on batch 884/2438  on Training is 59.318502824858754\n",
            "Epoch #1. Accuracy on batch 885/2438  on Training is 59.32209367945824\n",
            "Epoch #1. Accuracy on batch 886/2438  on Training is 59.31510710259301\n",
            "Epoch #1. Accuracy on batch 887/2438  on Training is 59.315174549549546\n",
            "Epoch #1. Accuracy on batch 888/2438  on Training is 59.322272215973\n",
            "Epoch #1. Accuracy on batch 889/2438  on Training is 59.325842696629216\n",
            "Epoch #1. Accuracy on batch 890/2438  on Training is 59.315375982042646\n",
            "Epoch #1. Accuracy on batch 891/2438  on Training is 59.3294562780269\n",
            "Epoch #1. Accuracy on batch 892/2438  on Training is 59.33300671892497\n",
            "Epoch #1. Accuracy on batch 893/2438  on Training is 59.33305369127517\n",
            "Epoch #1. Accuracy on batch 894/2438  on Training is 59.322625698324025\n",
            "Epoch #1. Accuracy on batch 895/2438  on Training is 59.305245535714285\n",
            "Epoch #1. Accuracy on batch 896/2438  on Training is 59.319258639910814\n",
            "Epoch #1. Accuracy on batch 897/2438  on Training is 59.32628062360802\n",
            "Epoch #1. Accuracy on batch 898/2438  on Training is 59.32633481646273\n",
            "Epoch #1. Accuracy on batch 899/2438  on Training is 59.326388888888886\n",
            "Batch Id 900/2438 is having training loss of 1.6478173732757568\n",
            "1.3349831104278564\n",
            "Epoch #1. Accuracy on batch 900/2438  on Training is 59.33684794672586\n",
            "Epoch #1. Accuracy on batch 901/2438  on Training is 59.32649667405765\n",
            "Epoch #1. Accuracy on batch 902/2438  on Training is 59.340393133997786\n",
            "Epoch #1. Accuracy on batch 903/2438  on Training is 59.32660398230089\n",
            "Epoch #1. Accuracy on batch 904/2438  on Training is 59.3232044198895\n",
            "Epoch #1. Accuracy on batch 905/2438  on Training is 59.326710816777044\n",
            "Epoch #1. Accuracy on batch 906/2438  on Training is 59.33020948180816\n",
            "Epoch #1. Accuracy on batch 907/2438  on Training is 59.33025881057269\n",
            "Epoch #1. Accuracy on batch 908/2438  on Training is 59.33374587458746\n",
            "Epoch #1. Accuracy on batch 909/2438  on Training is 59.354395604395606\n",
            "Epoch #1. Accuracy on batch 910/2438  on Training is 59.37156970362239\n",
            "Epoch #1. Accuracy on batch 911/2438  on Training is 59.38870614035088\n",
            "Epoch #1. Accuracy on batch 912/2438  on Training is 59.3921139101862\n",
            "Epoch #1. Accuracy on batch 913/2438  on Training is 59.4160284463895\n",
            "Epoch #1. Accuracy on batch 914/2438  on Training is 59.40915300546448\n",
            "Epoch #1. Accuracy on batch 915/2438  on Training is 59.42276200873363\n",
            "Epoch #1. Accuracy on batch 916/2438  on Training is 59.412486368593235\n",
            "Epoch #1. Accuracy on batch 917/2438  on Training is 59.412445533769066\n",
            "Epoch #1. Accuracy on batch 918/2438  on Training is 59.42260609357998\n",
            "Epoch #1. Accuracy on batch 919/2438  on Training is 59.41236413043478\n",
            "Batch Id 920/2438 is having training loss of 1.6444135904312134\n",
            "1.3284181356430054\n",
            "Epoch #1. Accuracy on batch 920/2438  on Training is 59.41910966340934\n",
            "Epoch #1. Accuracy on batch 921/2438  on Training is 59.43261930585683\n",
            "Epoch #1. Accuracy on batch 922/2438  on Training is 59.42578548212351\n",
            "Epoch #1. Accuracy on batch 923/2438  on Training is 59.43249458874459\n",
            "Epoch #1. Accuracy on batch 924/2438  on Training is 59.435810810810814\n",
            "Epoch #1. Accuracy on batch 925/2438  on Training is 59.43237041036717\n",
            "Epoch #1. Accuracy on batch 926/2438  on Training is 59.435679611650485\n",
            "Epoch #1. Accuracy on batch 927/2438  on Training is 59.44571659482759\n",
            "Epoch #1. Accuracy on batch 928/2438  on Training is 59.452368137782564\n",
            "Epoch #1. Accuracy on batch 929/2438  on Training is 59.45228494623656\n",
            "Epoch #1. Accuracy on batch 930/2438  on Training is 59.45555853920516\n",
            "Epoch #1. Accuracy on batch 931/2438  on Training is 59.44541309012875\n",
            "Epoch #1. Accuracy on batch 932/2438  on Training is 59.44868703108253\n",
            "Epoch #1. Accuracy on batch 933/2438  on Training is 59.435224839400426\n",
            "Epoch #1. Accuracy on batch 934/2438  on Training is 59.4418449197861\n",
            "Epoch #1. Accuracy on batch 935/2438  on Training is 59.44511217948718\n",
            "Epoch #1. Accuracy on batch 936/2438  on Training is 59.438367129135536\n",
            "Epoch #1. Accuracy on batch 937/2438  on Training is 59.444962686567166\n",
            "Epoch #1. Accuracy on batch 938/2438  on Training is 59.44821618743344\n",
            "Epoch #1. Accuracy on batch 939/2438  on Training is 59.444813829787236\n",
            "Batch Id 940/2438 is having training loss of 1.6426721811294556\n",
            "1.4462066888809204\n",
            "Epoch #1. Accuracy on batch 940/2438  on Training is 59.448060573857596\n",
            "Epoch #1. Accuracy on batch 941/2438  on Training is 59.461252653927815\n",
            "Epoch #1. Accuracy on batch 942/2438  on Training is 59.45453340402969\n",
            "Epoch #1. Accuracy on batch 943/2438  on Training is 59.457759533898304\n",
            "Epoch #1. Accuracy on batch 944/2438  on Training is 59.4510582010582\n",
            "Epoch #1. Accuracy on batch 945/2438  on Training is 59.457584566596196\n",
            "Epoch #1. Accuracy on batch 946/2438  on Training is 59.46739704329462\n",
            "Epoch #1. Accuracy on batch 947/2438  on Training is 59.46070675105485\n",
            "Epoch #1. Accuracy on batch 948/2438  on Training is 59.437565858798735\n",
            "Epoch #1. Accuracy on batch 949/2438  on Training is 59.42763157894737\n",
            "Epoch #1. Accuracy on batch 950/2438  on Training is 59.417718191377496\n",
            "Epoch #1. Accuracy on batch 951/2438  on Training is 59.42423844537815\n",
            "Epoch #1. Accuracy on batch 952/2438  on Training is 59.43730325288563\n",
            "Epoch #1. Accuracy on batch 953/2438  on Training is 59.4437893081761\n",
            "Epoch #1. Accuracy on batch 954/2438  on Training is 59.45353403141361\n",
            "Epoch #1. Accuracy on batch 955/2438  on Training is 59.4697960251046\n",
            "Epoch #1. Accuracy on batch 956/2438  on Training is 59.47622779519331\n",
            "Epoch #1. Accuracy on batch 957/2438  on Training is 59.48590814196242\n",
            "Epoch #1. Accuracy on batch 958/2438  on Training is 59.472758081334725\n",
            "Epoch #1. Accuracy on batch 959/2438  on Training is 59.47265625\n",
            "Batch Id 960/2438 is having training loss of 1.6408005952835083\n",
            "1.621549367904663\n",
            "Epoch #1. Accuracy on batch 960/2438  on Training is 59.47255463059313\n",
            "Epoch #1. Accuracy on batch 961/2438  on Training is 59.478950103950105\n",
            "Epoch #1. Accuracy on batch 962/2438  on Training is 59.469106957424714\n",
            "Epoch #1. Accuracy on batch 963/2438  on Training is 59.47549273858921\n",
            "Epoch #1. Accuracy on batch 964/2438  on Training is 59.47538860103627\n",
            "Epoch #1. Accuracy on batch 965/2438  on Training is 59.47528467908903\n",
            "Epoch #1. Accuracy on batch 966/2438  on Training is 59.471949327817995\n",
            "Epoch #1. Accuracy on batch 967/2438  on Training is 59.47184917355372\n",
            "Epoch #1. Accuracy on batch 968/2438  on Training is 59.48142414860681\n",
            "Epoch #1. Accuracy on batch 969/2438  on Training is 59.49742268041237\n",
            "Epoch #1. Accuracy on batch 970/2438  on Training is 59.5005149330587\n",
            "Epoch #1. Accuracy on batch 971/2438  on Training is 59.51324588477366\n",
            "Epoch #1. Accuracy on batch 972/2438  on Training is 59.50346865364851\n",
            "Epoch #1. Accuracy on batch 973/2438  on Training is 59.51937885010267\n",
            "Epoch #1. Accuracy on batch 974/2438  on Training is 59.51923076923077\n",
            "Epoch #1. Accuracy on batch 975/2438  on Training is 59.52228483606557\n",
            "Epoch #1. Accuracy on batch 976/2438  on Training is 59.538126919140225\n",
            "Epoch #1. Accuracy on batch 977/2438  on Training is 59.5411554192229\n",
            "Epoch #1. Accuracy on batch 978/2438  on Training is 59.53460163432074\n",
            "Epoch #1. Accuracy on batch 979/2438  on Training is 59.54081632653061\n",
            "Batch Id 980/2438 is having training loss of 1.6386973857879639\n",
            "1.876042127609253\n",
            "Epoch #1. Accuracy on batch 980/2438  on Training is 59.53109072375128\n",
            "Epoch #1. Accuracy on batch 981/2438  on Training is 59.521384928716905\n",
            "Epoch #1. Accuracy on batch 982/2438  on Training is 59.52123601220753\n",
            "Epoch #1. Accuracy on batch 983/2438  on Training is 59.52743902439025\n",
            "Epoch #1. Accuracy on batch 984/2438  on Training is 59.51776649746193\n",
            "Epoch #1. Accuracy on batch 985/2438  on Training is 59.530299188640974\n",
            "Epoch #1. Accuracy on batch 986/2438  on Training is 59.533308004052685\n",
            "Epoch #1. Accuracy on batch 987/2438  on Training is 59.53631072874494\n",
            "Epoch #1. Accuracy on batch 988/2438  on Training is 59.539307381193126\n",
            "Epoch #1. Accuracy on batch 989/2438  on Training is 59.54545454545455\n",
            "Epoch #1. Accuracy on batch 990/2438  on Training is 59.56420282542886\n",
            "Epoch #1. Accuracy on batch 991/2438  on Training is 59.551411290322584\n",
            "Epoch #1. Accuracy on batch 992/2438  on Training is 59.56382175226586\n",
            "Epoch #1. Accuracy on batch 993/2438  on Training is 59.55105633802817\n",
            "Epoch #1. Accuracy on batch 994/2438  on Training is 59.56658291457286\n",
            "Epoch #1. Accuracy on batch 995/2438  on Training is 59.556977911646584\n",
            "Epoch #1. Accuracy on batch 996/2438  on Training is 59.55052657973922\n",
            "Epoch #1. Accuracy on batch 997/2438  on Training is 59.550350701402806\n",
            "Epoch #1. Accuracy on batch 998/2438  on Training is 59.5533033033033\n",
            "Epoch #1. Accuracy on batch 999/2438  on Training is 59.55\n",
            "Batch Id 1000/2438 is having training loss of 1.6373894214630127\n",
            "1.7045207023620605\n",
            "Epoch #1. Accuracy on batch 1000/2438  on Training is 59.5467032967033\n",
            "Epoch #1. Accuracy on batch 1001/2438  on Training is 59.559006986027946\n",
            "Epoch #1. Accuracy on batch 1002/2438  on Training is 59.58063310069791\n",
            "Epoch #1. Accuracy on batch 1003/2438  on Training is 59.574203187250994\n",
            "Epoch #1. Accuracy on batch 1004/2438  on Training is 59.58955223880597\n",
            "Epoch #1. Accuracy on batch 1005/2438  on Training is 59.59244532803181\n",
            "Epoch #1. Accuracy on batch 1006/2438  on Training is 59.61395233366435\n",
            "Epoch #1. Accuracy on batch 1007/2438  on Training is 59.62301587301587\n",
            "Epoch #1. Accuracy on batch 1008/2438  on Training is 59.62586719524281\n",
            "Epoch #1. Accuracy on batch 1009/2438  on Training is 59.62561881188119\n",
            "Epoch #1. Accuracy on batch 1010/2438  on Training is 59.631552917903065\n",
            "Epoch #1. Accuracy on batch 1011/2438  on Training is 59.63747529644269\n",
            "Epoch #1. Accuracy on batch 1012/2438  on Training is 59.649555774925965\n",
            "Epoch #1. Accuracy on batch 1013/2438  on Training is 59.63387573964497\n",
            "Epoch #1. Accuracy on batch 1014/2438  on Training is 59.633620689655174\n",
            "Epoch #1. Accuracy on batch 1015/2438  on Training is 59.62721456692913\n",
            "Epoch #1. Accuracy on batch 1016/2438  on Training is 59.61467551622419\n",
            "Epoch #1. Accuracy on batch 1017/2438  on Training is 59.608300589390964\n",
            "Epoch #1. Accuracy on batch 1018/2438  on Training is 59.60500490677134\n",
            "Epoch #1. Accuracy on batch 1019/2438  on Training is 59.623161764705884\n",
            "Batch Id 1020/2438 is having training loss of 1.6346639394760132\n",
            "1.3167622089385986\n",
            "Epoch #1. Accuracy on batch 1020/2438  on Training is 59.62291870714985\n",
            "Epoch #1. Accuracy on batch 1021/2438  on Training is 59.63184931506849\n",
            "Epoch #1. Accuracy on batch 1022/2438  on Training is 59.637707722385144\n",
            "Epoch #1. Accuracy on batch 1023/2438  on Training is 59.6466064453125\n",
            "Epoch #1. Accuracy on batch 1024/2438  on Training is 59.64939024390244\n",
            "Epoch #1. Accuracy on batch 1025/2438  on Training is 59.64607699805068\n",
            "Epoch #1. Accuracy on batch 1026/2438  on Training is 59.648855890944496\n",
            "Epoch #1. Accuracy on batch 1027/2438  on Training is 59.64554961089494\n",
            "Epoch #1. Accuracy on batch 1028/2438  on Training is 59.642249757045676\n",
            "Epoch #1. Accuracy on batch 1029/2438  on Training is 59.651092233009706\n",
            "Epoch #1. Accuracy on batch 1030/2438  on Training is 59.65082444228904\n",
            "Epoch #1. Accuracy on batch 1031/2438  on Training is 59.65661337209303\n",
            "Epoch #1. Accuracy on batch 1032/2438  on Training is 59.6533155856728\n",
            "Epoch #1. Accuracy on batch 1033/2438  on Training is 59.65606866537718\n",
            "Epoch #1. Accuracy on batch 1034/2438  on Training is 59.664855072463766\n",
            "Epoch #1. Accuracy on batch 1035/2438  on Training is 59.670608108108105\n",
            "Epoch #1. Accuracy on batch 1036/2438  on Training is 59.66429604628737\n",
            "Epoch #1. Accuracy on batch 1037/2438  on Training is 59.66401734104046\n",
            "Epoch #1. Accuracy on batch 1038/2438  on Training is 59.65772377285852\n",
            "Epoch #1. Accuracy on batch 1039/2438  on Training is 59.67247596153846\n",
            "Batch Id 1040/2438 is having training loss of 1.633043885231018\n",
            "1.8989306688308716\n",
            "Epoch #1. Accuracy on batch 1040/2438  on Training is 59.66918828049952\n",
            "Epoch #1. Accuracy on batch 1041/2438  on Training is 59.68090211132438\n",
            "Epoch #1. Accuracy on batch 1042/2438  on Training is 59.680608820709494\n",
            "Epoch #1. Accuracy on batch 1043/2438  on Training is 59.68630268199234\n",
            "Epoch #1. Accuracy on batch 1044/2438  on Training is 59.671052631578945\n",
            "Epoch #1. Accuracy on batch 1045/2438  on Training is 59.682719885277244\n",
            "Epoch #1. Accuracy on batch 1046/2438  on Training is 59.69436485195798\n",
            "Epoch #1. Accuracy on batch 1047/2438  on Training is 59.700023854961835\n",
            "Epoch #1. Accuracy on batch 1048/2438  on Training is 59.69375595805529\n",
            "Epoch #1. Accuracy on batch 1049/2438  on Training is 59.6875\n",
            "Epoch #1. Accuracy on batch 1050/2438  on Training is 59.681255946717414\n",
            "Epoch #1. Accuracy on batch 1051/2438  on Training is 59.66908269961977\n",
            "Epoch #1. Accuracy on batch 1052/2438  on Training is 59.6806742640076\n",
            "Epoch #1. Accuracy on batch 1053/2438  on Training is 59.68631404174573\n",
            "Epoch #1. Accuracy on batch 1054/2438  on Training is 59.677132701421804\n",
            "Epoch #1. Accuracy on batch 1055/2438  on Training is 59.68276515151515\n",
            "Epoch #1. Accuracy on batch 1056/2438  on Training is 59.67360454115421\n",
            "Epoch #1. Accuracy on batch 1057/2438  on Training is 59.65264650283554\n",
            "Epoch #1. Accuracy on batch 1058/2438  on Training is 59.65238432483475\n",
            "Epoch #1. Accuracy on batch 1059/2438  on Training is 59.658018867924525\n",
            "Batch Id 1060/2438 is having training loss of 1.6322507858276367\n",
            "1.8085110187530518\n",
            "Epoch #1. Accuracy on batch 1060/2438  on Training is 59.65775212064091\n",
            "Epoch #1. Accuracy on batch 1061/2438  on Training is 59.657485875706215\n",
            "Epoch #1. Accuracy on batch 1062/2438  on Training is 59.666039510818436\n",
            "Epoch #1. Accuracy on batch 1063/2438  on Training is 59.65989191729323\n",
            "Epoch #1. Accuracy on batch 1064/2438  on Training is 59.6537558685446\n",
            "Epoch #1. Accuracy on batch 1065/2438  on Training is 59.6593574108818\n",
            "Epoch #1. Accuracy on batch 1066/2438  on Training is 59.65616213683224\n",
            "Epoch #1. Accuracy on batch 1067/2438  on Training is 59.66175093632959\n",
            "Epoch #1. Accuracy on batch 1068/2438  on Training is 59.66148269410664\n",
            "Epoch #1. Accuracy on batch 1069/2438  on Training is 59.658294392523366\n",
            "Epoch #1. Accuracy on batch 1070/2438  on Training is 59.66678338001867\n",
            "Epoch #1. Accuracy on batch 1071/2438  on Training is 59.66942630597015\n",
            "Epoch #1. Accuracy on batch 1072/2438  on Training is 59.672064305685\n",
            "Epoch #1. Accuracy on batch 1073/2438  on Training is 59.66014897579144\n",
            "Epoch #1. Accuracy on batch 1074/2438  on Training is 59.64825581395349\n",
            "Epoch #1. Accuracy on batch 1075/2438  on Training is 59.65671468401487\n",
            "Epoch #1. Accuracy on batch 1076/2438  on Training is 59.653551532033426\n",
            "Epoch #1. Accuracy on batch 1077/2438  on Training is 59.647495361781075\n",
            "Epoch #1. Accuracy on batch 1078/2438  on Training is 59.6501390176089\n",
            "Epoch #1. Accuracy on batch 1079/2438  on Training is 59.6556712962963\n",
            "Batch Id 1080/2438 is having training loss of 1.6325064897537231\n",
            "1.6989569664001465\n",
            "Epoch #1. Accuracy on batch 1080/2438  on Training is 59.652520814061056\n",
            "Epoch #1. Accuracy on batch 1081/2438  on Training is 59.66381700554528\n",
            "Epoch #1. Accuracy on batch 1082/2438  on Training is 59.67797783933518\n",
            "Epoch #1. Accuracy on batch 1083/2438  on Training is 59.67769833948339\n",
            "Epoch #1. Accuracy on batch 1084/2438  on Training is 59.67165898617512\n",
            "Epoch #1. Accuracy on batch 1085/2438  on Training is 59.67426335174954\n",
            "Epoch #1. Accuracy on batch 1086/2438  on Training is 59.67686292548298\n",
            "Epoch #1. Accuracy on batch 1087/2438  on Training is 59.67945772058823\n",
            "Epoch #1. Accuracy on batch 1088/2438  on Training is 59.69065656565657\n",
            "Epoch #1. Accuracy on batch 1089/2438  on Training is 59.68176605504587\n",
            "Epoch #1. Accuracy on batch 1090/2438  on Training is 59.69007791017415\n",
            "Epoch #1. Accuracy on batch 1091/2438  on Training is 59.704097985347985\n",
            "Epoch #1. Accuracy on batch 1092/2438  on Training is 59.70093778591034\n",
            "Epoch #1. Accuracy on batch 1093/2438  on Training is 59.70635283363803\n",
            "Epoch #1. Accuracy on batch 1094/2438  on Training is 59.717465753424655\n",
            "Epoch #1. Accuracy on batch 1095/2438  on Training is 59.70859945255474\n",
            "Epoch #1. Accuracy on batch 1096/2438  on Training is 59.6912032816773\n",
            "Epoch #1. Accuracy on batch 1097/2438  on Training is 59.693761384335154\n",
            "Epoch #1. Accuracy on batch 1098/2438  on Training is 59.704845313921744\n",
            "Epoch #1. Accuracy on batch 1099/2438  on Training is 59.71590909090909\n",
            "Batch Id 1100/2438 is having training loss of 1.62985098361969\n",
            "1.342743158340454\n",
            "Epoch #1. Accuracy on batch 1100/2438  on Training is 59.726952770208904\n",
            "Epoch #1. Accuracy on batch 1101/2438  on Training is 59.71812613430127\n",
            "Epoch #1. Accuracy on batch 1102/2438  on Training is 59.709315503173165\n",
            "Epoch #1. Accuracy on batch 1103/2438  on Training is 59.71184329710145\n",
            "Epoch #1. Accuracy on batch 1104/2438  on Training is 59.70871040723982\n",
            "Epoch #1. Accuracy on batch 1105/2438  on Training is 59.70275768535262\n",
            "Epoch #1. Accuracy on batch 1106/2438  on Training is 59.70246160794941\n",
            "Epoch #1. Accuracy on batch 1107/2438  on Training is 59.71062725631769\n",
            "Epoch #1. Accuracy on batch 1108/2438  on Training is 59.710324616771864\n",
            "Epoch #1. Accuracy on batch 1109/2438  on Training is 59.71002252252252\n",
            "Epoch #1. Accuracy on batch 1110/2438  on Training is 59.70972097209721\n",
            "Epoch #1. Accuracy on batch 1111/2438  on Training is 59.703799460431654\n",
            "Epoch #1. Accuracy on batch 1112/2438  on Training is 59.697888589398026\n",
            "Epoch #1. Accuracy on batch 1113/2438  on Training is 59.7004039497307\n",
            "Epoch #1. Accuracy on batch 1114/2438  on Training is 59.7085201793722\n",
            "Epoch #1. Accuracy on batch 1115/2438  on Training is 59.71382168458781\n",
            "Epoch #1. Accuracy on batch 1116/2438  on Training is 59.71351835273053\n",
            "Epoch #1. Accuracy on batch 1117/2438  on Training is 59.71321556350626\n",
            "Epoch #1. Accuracy on batch 1118/2438  on Training is 59.70732797140304\n",
            "Epoch #1. Accuracy on batch 1119/2438  on Training is 59.70703125\n",
            "Batch Id 1120/2438 is having training loss of 1.629921317100525\n",
            "1.5048812627792358\n",
            "Epoch #1. Accuracy on batch 1120/2438  on Training is 59.715098126672615\n",
            "Epoch #1. Accuracy on batch 1121/2438  on Training is 59.72036541889483\n",
            "Epoch #1. Accuracy on batch 1122/2438  on Training is 59.720057880676755\n",
            "Epoch #1. Accuracy on batch 1123/2438  on Training is 59.73643238434164\n",
            "Epoch #1. Accuracy on batch 1124/2438  on Training is 59.75277777777778\n",
            "Epoch #1. Accuracy on batch 1125/2438  on Training is 59.75521758436945\n",
            "Epoch #1. Accuracy on batch 1126/2438  on Training is 59.74101597160603\n",
            "Epoch #1. Accuracy on batch 1127/2438  on Training is 59.746232269503544\n",
            "Epoch #1. Accuracy on batch 1128/2438  on Training is 59.74867139061116\n",
            "Epoch #1. Accuracy on batch 1129/2438  on Training is 59.73451327433628\n",
            "Epoch #1. Accuracy on batch 1130/2438  on Training is 59.72866931918656\n",
            "Epoch #1. Accuracy on batch 1131/2438  on Training is 59.74492049469965\n",
            "Epoch #1. Accuracy on batch 1132/2438  on Training is 59.741835834068844\n",
            "Epoch #1. Accuracy on batch 1133/2438  on Training is 59.74702380952381\n",
            "Epoch #1. Accuracy on batch 1134/2438  on Training is 59.752202643171806\n",
            "Epoch #1. Accuracy on batch 1135/2438  on Training is 59.749119718309856\n",
            "Epoch #1. Accuracy on batch 1136/2438  on Training is 59.748790677220754\n",
            "Epoch #1. Accuracy on batch 1137/2438  on Training is 59.75120826010545\n",
            "Epoch #1. Accuracy on batch 1138/2438  on Training is 59.75636523266023\n",
            "Epoch #1. Accuracy on batch 1139/2438  on Training is 59.76973684210526\n",
            "Batch Id 1140/2438 is having training loss of 1.626326560974121\n",
            "1.5424503087997437\n",
            "Epoch #1. Accuracy on batch 1140/2438  on Training is 59.76939088518843\n",
            "Epoch #1. Accuracy on batch 1141/2438  on Training is 59.76357267950963\n",
            "Epoch #1. Accuracy on batch 1142/2438  on Training is 59.77143482064742\n",
            "Epoch #1. Accuracy on batch 1143/2438  on Training is 59.765625\n",
            "Epoch #1. Accuracy on batch 1144/2438  on Training is 59.76255458515284\n",
            "Epoch #1. Accuracy on batch 1145/2438  on Training is 59.75676265270506\n",
            "Epoch #1. Accuracy on batch 1146/2438  on Training is 59.75370531822145\n",
            "Epoch #1. Accuracy on batch 1147/2438  on Training is 59.75609756097561\n",
            "Epoch #1. Accuracy on batch 1148/2438  on Training is 59.766644908616186\n",
            "Epoch #1. Accuracy on batch 1149/2438  on Training is 59.76902173913044\n",
            "Epoch #1. Accuracy on batch 1150/2438  on Training is 59.77410947002606\n",
            "Epoch #1. Accuracy on batch 1151/2438  on Training is 59.768337673611114\n",
            "Epoch #1. Accuracy on batch 1152/2438  on Training is 59.76528620988725\n",
            "Epoch #1. Accuracy on batch 1153/2438  on Training is 59.76224003466204\n",
            "Epoch #1. Accuracy on batch 1154/2438  on Training is 59.77272727272727\n",
            "Epoch #1. Accuracy on batch 1155/2438  on Training is 59.75886678200692\n",
            "Epoch #1. Accuracy on batch 1156/2438  on Training is 59.763936905790835\n",
            "Epoch #1. Accuracy on batch 1157/2438  on Training is 59.76899827288428\n",
            "Epoch #1. Accuracy on batch 1158/2438  on Training is 59.7767471958585\n",
            "Epoch #1. Accuracy on batch 1159/2438  on Training is 59.77640086206897\n",
            "Batch Id 1160/2438 is having training loss of 1.6251720190048218\n",
            "1.0034489631652832\n",
            "Epoch #1. Accuracy on batch 1160/2438  on Training is 59.79220499569337\n",
            "Epoch #1. Accuracy on batch 1161/2438  on Training is 59.8052925989673\n",
            "Epoch #1. Accuracy on batch 1162/2438  on Training is 59.823731728288905\n",
            "Epoch #1. Accuracy on batch 1163/2438  on Training is 59.815292096219935\n",
            "Epoch #1. Accuracy on batch 1164/2438  on Training is 59.82832618025751\n",
            "Epoch #1. Accuracy on batch 1165/2438  on Training is 59.82525728987993\n",
            "Epoch #1. Accuracy on batch 1166/2438  on Training is 59.82754927163668\n",
            "Epoch #1. Accuracy on batch 1167/2438  on Training is 59.83251284246575\n",
            "Epoch #1. Accuracy on batch 1168/2438  on Training is 59.829448246364414\n",
            "Epoch #1. Accuracy on batch 1169/2438  on Training is 59.826388888888886\n",
            "Epoch #1. Accuracy on batch 1170/2438  on Training is 59.80732280102477\n",
            "Epoch #1. Accuracy on batch 1171/2438  on Training is 59.80695392491467\n",
            "Epoch #1. Accuracy on batch 1172/2438  on Training is 59.817242114237\n",
            "Epoch #1. Accuracy on batch 1173/2438  on Training is 59.8195272572402\n",
            "Epoch #1. Accuracy on batch 1174/2438  on Training is 59.827127659574465\n",
            "Epoch #1. Accuracy on batch 1175/2438  on Training is 59.8187712585034\n",
            "Epoch #1. Accuracy on batch 1176/2438  on Training is 59.81308411214953\n",
            "Epoch #1. Accuracy on batch 1177/2438  on Training is 59.815365025466896\n",
            "Epoch #1. Accuracy on batch 1178/2438  on Training is 59.82294317217981\n",
            "Epoch #1. Accuracy on batch 1179/2438  on Training is 59.838453389830505\n",
            "Batch Id 1180/2438 is having training loss of 1.6233974695205688\n",
            "1.5655890703201294\n",
            "Epoch #1. Accuracy on batch 1180/2438  on Training is 59.8354149026249\n",
            "Epoch #1. Accuracy on batch 1181/2438  on Training is 59.83502538071066\n",
            "Epoch #1. Accuracy on batch 1182/2438  on Training is 59.831994928148774\n",
            "Epoch #1. Accuracy on batch 1183/2438  on Training is 59.8316089527027\n",
            "Epoch #1. Accuracy on batch 1184/2438  on Training is 59.836497890295355\n",
            "Epoch #1. Accuracy on batch 1185/2438  on Training is 59.85191821247892\n",
            "Epoch #1. Accuracy on batch 1186/2438  on Training is 59.85678180286436\n",
            "Epoch #1. Accuracy on batch 1187/2438  on Training is 59.864267676767675\n",
            "Epoch #1. Accuracy on batch 1188/2438  on Training is 59.86911269974769\n",
            "Epoch #1. Accuracy on batch 1189/2438  on Training is 59.884453781512605\n",
            "Epoch #1. Accuracy on batch 1190/2438  on Training is 59.894521410579344\n",
            "Epoch #1. Accuracy on batch 1191/2438  on Training is 59.8967072147651\n",
            "Epoch #1. Accuracy on batch 1192/2438  on Training is 59.90150880134116\n",
            "Epoch #1. Accuracy on batch 1193/2438  on Training is 59.90891959798995\n",
            "Epoch #1. Accuracy on batch 1194/2438  on Training is 59.91108786610879\n",
            "Epoch #1. Accuracy on batch 1195/2438  on Training is 59.91847826086956\n",
            "Epoch #1. Accuracy on batch 1196/2438  on Training is 59.925856307435254\n",
            "Epoch #1. Accuracy on batch 1197/2438  on Training is 59.93061352253756\n",
            "Epoch #1. Accuracy on batch 1198/2438  on Training is 59.940575479566306\n",
            "Epoch #1. Accuracy on batch 1199/2438  on Training is 59.947916666666664\n",
            "Batch Id 1200/2438 is having training loss of 1.620289921760559\n",
            "1.286535620689392\n",
            "Epoch #1. Accuracy on batch 1200/2438  on Training is 59.94483763530391\n",
            "Epoch #1. Accuracy on batch 1201/2438  on Training is 59.944363560732114\n",
            "Epoch #1. Accuracy on batch 1202/2438  on Training is 59.94908561928512\n",
            "Epoch #1. Accuracy on batch 1203/2438  on Training is 59.94860880398671\n",
            "Epoch #1. Accuracy on batch 1204/2438  on Training is 59.94294605809129\n",
            "Epoch #1. Accuracy on batch 1205/2438  on Training is 59.942475124378106\n",
            "Epoch #1. Accuracy on batch 1206/2438  on Training is 59.93941590720795\n",
            "Epoch #1. Accuracy on batch 1207/2438  on Training is 59.94670943708609\n",
            "Epoch #1. Accuracy on batch 1208/2438  on Training is 59.959160463192724\n",
            "Epoch #1. Accuracy on batch 1209/2438  on Training is 59.96126033057851\n",
            "Epoch #1. Accuracy on batch 1210/2438  on Training is 59.960776218001655\n",
            "Epoch #1. Accuracy on batch 1211/2438  on Training is 59.95255775577558\n",
            "Epoch #1. Accuracy on batch 1212/2438  on Training is 59.949505358615006\n",
            "Epoch #1. Accuracy on batch 1213/2438  on Training is 59.96447693574959\n",
            "Epoch #1. Accuracy on batch 1214/2438  on Training is 59.98456790123457\n",
            "Epoch #1. Accuracy on batch 1215/2438  on Training is 59.97635690789474\n",
            "Epoch #1. Accuracy on batch 1216/2438  on Training is 59.98099835661463\n",
            "Epoch #1. Accuracy on batch 1217/2438  on Training is 59.970238095238095\n",
            "Epoch #1. Accuracy on batch 1218/2438  on Training is 59.9748769483183\n",
            "Epoch #1. Accuracy on batch 1219/2438  on Training is 59.96926229508197\n",
            "Batch Id 1220/2438 is having training loss of 1.6186673641204834\n",
            "1.4115411043167114\n",
            "Epoch #1. Accuracy on batch 1220/2438  on Training is 59.97645372645373\n",
            "Epoch #1. Accuracy on batch 1221/2438  on Training is 59.973404255319146\n",
            "Epoch #1. Accuracy on batch 1222/2438  on Training is 59.97035977105478\n",
            "Epoch #1. Accuracy on batch 1223/2438  on Training is 59.96476715686274\n",
            "Epoch #1. Accuracy on batch 1224/2438  on Training is 59.96683673469388\n",
            "Epoch #1. Accuracy on batch 1225/2438  on Training is 59.979098694942905\n",
            "Epoch #1. Accuracy on batch 1226/2438  on Training is 59.976059494702525\n",
            "Epoch #1. Accuracy on batch 1227/2438  on Training is 59.97557003257329\n",
            "Epoch #1. Accuracy on batch 1228/2438  on Training is 59.980166802278276\n",
            "Epoch #1. Accuracy on batch 1229/2438  on Training is 59.97713414634146\n",
            "Epoch #1. Accuracy on batch 1230/2438  on Training is 59.9817221770918\n",
            "Epoch #1. Accuracy on batch 1231/2438  on Training is 59.98630275974026\n",
            "Epoch #1. Accuracy on batch 1232/2438  on Training is 59.988341443633416\n",
            "Epoch #1. Accuracy on batch 1233/2438  on Training is 59.985311993517016\n",
            "Epoch #1. Accuracy on batch 1234/2438  on Training is 59.98987854251012\n",
            "Epoch #1. Accuracy on batch 1235/2438  on Training is 59.98938106796116\n",
            "Epoch #1. Accuracy on batch 1236/2438  on Training is 59.99393694421989\n",
            "Epoch #1. Accuracy on batch 1237/2438  on Training is 59.99596122778675\n",
            "Epoch #1. Accuracy on batch 1238/2438  on Training is 60.003026634382564\n",
            "Epoch #1. Accuracy on batch 1239/2438  on Training is 59.99747983870968\n",
            "Batch Id 1240/2438 is having training loss of 1.6179072856903076\n",
            "1.2451096773147583\n",
            "Epoch #1. Accuracy on batch 1240/2438  on Training is 60.00201450443191\n",
            "Epoch #1. Accuracy on batch 1241/2438  on Training is 60.00905797101449\n",
            "Epoch #1. Accuracy on batch 1242/2438  on Training is 60.01860418342719\n",
            "Epoch #1. Accuracy on batch 1243/2438  on Training is 60.01306270096463\n",
            "Epoch #1. Accuracy on batch 1244/2438  on Training is 60.02008032128514\n",
            "Epoch #1. Accuracy on batch 1245/2438  on Training is 60.02207062600321\n",
            "Epoch #1. Accuracy on batch 1246/2438  on Training is 60.01152766639936\n",
            "Epoch #1. Accuracy on batch 1247/2438  on Training is 60.01101762820513\n",
            "Epoch #1. Accuracy on batch 1248/2438  on Training is 59.99799839871898\n",
            "Epoch #1. Accuracy on batch 1249/2438  on Training is 59.9975\n",
            "Epoch #1. Accuracy on batch 1250/2438  on Training is 59.99200639488409\n",
            "Epoch #1. Accuracy on batch 1251/2438  on Training is 59.98402555910543\n",
            "Epoch #1. Accuracy on batch 1252/2438  on Training is 59.98852753391859\n",
            "Epoch #1. Accuracy on batch 1253/2438  on Training is 59.98803827751196\n",
            "Epoch #1. Accuracy on batch 1254/2438  on Training is 59.99003984063745\n",
            "Epoch #1. Accuracy on batch 1255/2438  on Training is 59.99203821656051\n",
            "Epoch #1. Accuracy on batch 1256/2438  on Training is 60.00149164677804\n",
            "Epoch #1. Accuracy on batch 1257/2438  on Training is 60.00347774244833\n",
            "Epoch #1. Accuracy on batch 1258/2438  on Training is 60.01290706910246\n",
            "Epoch #1. Accuracy on batch 1259/2438  on Training is 60.01240079365079\n",
            "Batch Id 1260/2438 is having training loss of 1.6161545515060425\n",
            "1.1955366134643555\n",
            "Epoch #1. Accuracy on batch 1260/2438  on Training is 60.021808088818396\n",
            "Epoch #1. Accuracy on batch 1261/2438  on Training is 60.01881933438986\n",
            "Epoch #1. Accuracy on batch 1262/2438  on Training is 60.023258115597784\n",
            "Epoch #1. Accuracy on batch 1263/2438  on Training is 60.03510680379747\n",
            "Epoch #1. Accuracy on batch 1264/2438  on Training is 60.0296442687747\n",
            "Epoch #1. Accuracy on batch 1265/2438  on Training is 60.01678515007899\n",
            "Epoch #1. Accuracy on batch 1266/2438  on Training is 60.016278610891874\n",
            "Epoch #1. Accuracy on batch 1267/2438  on Training is 60.01330835962145\n",
            "Epoch #1. Accuracy on batch 1268/2438  on Training is 60.0177304964539\n",
            "Epoch #1. Accuracy on batch 1269/2438  on Training is 60.02706692913386\n",
            "Epoch #1. Accuracy on batch 1270/2438  on Training is 60.03147128245476\n",
            "Epoch #1. Accuracy on batch 1271/2438  on Training is 60.03586871069182\n",
            "Epoch #1. Accuracy on batch 1272/2438  on Training is 60.02798507462686\n",
            "Epoch #1. Accuracy on batch 1273/2438  on Training is 60.02992543171115\n",
            "Epoch #1. Accuracy on batch 1274/2438  on Training is 60.02696078431372\n",
            "Epoch #1. Accuracy on batch 1275/2438  on Training is 60.03379702194357\n",
            "Epoch #1. Accuracy on batch 1276/2438  on Training is 60.030833985904465\n",
            "Epoch #1. Accuracy on batch 1277/2438  on Training is 60.03765649452269\n",
            "Epoch #1. Accuracy on batch 1278/2438  on Training is 60.04691164972635\n",
            "Epoch #1. Accuracy on batch 1279/2438  on Training is 60.06103515625\n",
            "Batch Id 1280/2438 is having training loss of 1.6145156621932983\n",
            "1.5176507234573364\n",
            "Epoch #1. Accuracy on batch 1280/2438  on Training is 60.06049960967994\n",
            "Epoch #1. Accuracy on batch 1281/2438  on Training is 60.06484009360374\n",
            "Epoch #1. Accuracy on batch 1282/2438  on Training is 60.05699532346064\n",
            "Epoch #1. Accuracy on batch 1283/2438  on Training is 60.061331775700936\n",
            "Epoch #1. Accuracy on batch 1284/2438  on Training is 60.070525291828794\n",
            "Epoch #1. Accuracy on batch 1285/2438  on Training is 60.065124416796266\n",
            "Epoch #1. Accuracy on batch 1286/2438  on Training is 60.08401320901321\n",
            "Epoch #1. Accuracy on batch 1287/2438  on Training is 60.09074145962733\n",
            "Epoch #1. Accuracy on batch 1288/2438  on Training is 60.08776183087665\n",
            "Epoch #1. Accuracy on batch 1289/2438  on Training is 60.07994186046512\n",
            "Epoch #1. Accuracy on batch 1290/2438  on Training is 60.07697521301317\n",
            "Epoch #1. Accuracy on batch 1291/2438  on Training is 60.071594427244584\n",
            "Epoch #1. Accuracy on batch 1292/2438  on Training is 60.071055684454755\n",
            "Epoch #1. Accuracy on batch 1293/2438  on Training is 60.070517774343124\n",
            "Epoch #1. Accuracy on batch 1294/2438  on Training is 60.077220077220076\n",
            "Epoch #1. Accuracy on batch 1295/2438  on Training is 60.07667824074074\n",
            "Epoch #1. Accuracy on batch 1296/2438  on Training is 60.078546646106396\n",
            "Epoch #1. Accuracy on batch 1297/2438  on Training is 60.08281972265023\n",
            "Epoch #1. Accuracy on batch 1298/2438  on Training is 60.089491916859124\n",
            "Epoch #1. Accuracy on batch 1299/2438  on Training is 60.09615384615385\n",
            "Batch Id 1300/2438 is having training loss of 1.6132441759109497\n",
            "1.4702706336975098\n",
            "Epoch #1. Accuracy on batch 1300/2438  on Training is 60.095599538816295\n",
            "Epoch #1. Accuracy on batch 1301/2438  on Training is 60.097446236559136\n",
            "Epoch #1. Accuracy on batch 1302/2438  on Training is 60.087298541826556\n",
            "Epoch #1. Accuracy on batch 1303/2438  on Training is 60.09154524539877\n",
            "Epoch #1. Accuracy on batch 1304/2438  on Training is 60.09578544061303\n",
            "Epoch #1. Accuracy on batch 1305/2438  on Training is 60.09284073506891\n",
            "Epoch #1. Accuracy on batch 1306/2438  on Training is 60.082727620504976\n",
            "Epoch #1. Accuracy on batch 1307/2438  on Training is 60.082186544342505\n",
            "Epoch #1. Accuracy on batch 1308/2438  on Training is 60.08880825057296\n",
            "Epoch #1. Accuracy on batch 1309/2438  on Training is 60.095419847328245\n",
            "Epoch #1. Accuracy on batch 1310/2438  on Training is 60.090102974828376\n",
            "Epoch #1. Accuracy on batch 1311/2438  on Training is 60.09908536585366\n",
            "Epoch #1. Accuracy on batch 1312/2438  on Training is 60.11281416603199\n",
            "Epoch #1. Accuracy on batch 1313/2438  on Training is 60.12652207001522\n",
            "Epoch #1. Accuracy on batch 1314/2438  on Training is 60.13070342205323\n",
            "Epoch #1. Accuracy on batch 1315/2438  on Training is 60.13487841945289\n",
            "Epoch #1. Accuracy on batch 1316/2438  on Training is 60.139047076689444\n",
            "Epoch #1. Accuracy on batch 1317/2438  on Training is 60.150322458270104\n",
            "Epoch #1. Accuracy on batch 1318/2438  on Training is 60.1497346474602\n",
            "Epoch #1. Accuracy on batch 1319/2438  on Training is 60.14914772727273\n",
            "Batch Id 1320/2438 is having training loss of 1.6104992628097534\n",
            "1.263245701789856\n",
            "Epoch #1. Accuracy on batch 1320/2438  on Training is 60.150927327781986\n",
            "Epoch #1. Accuracy on batch 1321/2438  on Training is 60.15034039334342\n",
            "Epoch #1. Accuracy on batch 1322/2438  on Training is 60.145030234315946\n",
            "Epoch #1. Accuracy on batch 1323/2438  on Training is 60.15388972809668\n",
            "Epoch #1. Accuracy on batch 1324/2438  on Training is 60.160377358490564\n",
            "Epoch #1. Accuracy on batch 1325/2438  on Training is 60.16921191553544\n",
            "Epoch #1. Accuracy on batch 1326/2438  on Training is 60.17803315749811\n",
            "Epoch #1. Accuracy on batch 1327/2438  on Training is 60.17742846385542\n",
            "Epoch #1. Accuracy on batch 1328/2438  on Training is 60.18387885628292\n",
            "Epoch #1. Accuracy on batch 1329/2438  on Training is 60.20206766917293\n",
            "Epoch #1. Accuracy on batch 1330/2438  on Training is 60.208489857250186\n",
            "Epoch #1. Accuracy on batch 1331/2438  on Training is 60.212556306306304\n",
            "Epoch #1. Accuracy on batch 1332/2438  on Training is 60.20723930982746\n",
            "Epoch #1. Accuracy on batch 1333/2438  on Training is 60.21364317841079\n",
            "Epoch #1. Accuracy on batch 1334/2438  on Training is 60.21535580524345\n",
            "Epoch #1. Accuracy on batch 1335/2438  on Training is 60.22876122754491\n",
            "Epoch #1. Accuracy on batch 1336/2438  on Training is 60.23279730740464\n",
            "Epoch #1. Accuracy on batch 1337/2438  on Training is 60.22982062780269\n",
            "Epoch #1. Accuracy on batch 1338/2438  on Training is 60.23151605675878\n",
            "Epoch #1. Accuracy on batch 1339/2438  on Training is 60.228544776119406\n",
            "Batch Id 1340/2438 is having training loss of 1.607251524925232\n",
            "1.6640828847885132\n",
            "Epoch #1. Accuracy on batch 1340/2438  on Training is 60.22790827740492\n",
            "Epoch #1. Accuracy on batch 1341/2438  on Training is 60.22960134128167\n",
            "Epoch #1. Accuracy on batch 1342/2438  on Training is 60.23361876396128\n",
            "Epoch #1. Accuracy on batch 1343/2438  on Training is 60.232979910714285\n",
            "Epoch #1. Accuracy on batch 1344/2438  on Training is 60.24395910780669\n",
            "Epoch #1. Accuracy on batch 1345/2438  on Training is 60.24331352154532\n",
            "Epoch #1. Accuracy on batch 1346/2438  on Training is 60.24034892353378\n",
            "Epoch #1. Accuracy on batch 1347/2438  on Training is 60.24434347181009\n",
            "Epoch #1. Accuracy on batch 1348/2438  on Training is 60.23211638250556\n",
            "Epoch #1. Accuracy on batch 1349/2438  on Training is 60.236111111111114\n",
            "Epoch #1. Accuracy on batch 1350/2438  on Training is 60.23778682457439\n",
            "Epoch #1. Accuracy on batch 1351/2438  on Training is 60.23252588757396\n",
            "Epoch #1. Accuracy on batch 1352/2438  on Training is 60.23651145602365\n",
            "Epoch #1. Accuracy on batch 1353/2438  on Training is 60.23818316100443\n",
            "Epoch #1. Accuracy on batch 1354/2438  on Training is 60.239852398523986\n",
            "Epoch #1. Accuracy on batch 1355/2438  on Training is 60.248432890855455\n",
            "Epoch #1. Accuracy on batch 1356/2438  on Training is 60.23397199705232\n",
            "Epoch #1. Accuracy on batch 1357/2438  on Training is 60.2195324005891\n",
            "Epoch #1. Accuracy on batch 1358/2438  on Training is 60.223509933774835\n",
            "Epoch #1. Accuracy on batch 1359/2438  on Training is 60.22288602941177\n",
            "Batch Id 1360/2438 is having training loss of 1.6080490350723267\n",
            "1.4175509214401245\n",
            "Epoch #1. Accuracy on batch 1360/2438  on Training is 60.22226304188097\n",
            "Epoch #1. Accuracy on batch 1361/2438  on Training is 60.22393538913363\n",
            "Epoch #1. Accuracy on batch 1362/2438  on Training is 60.22101980924431\n",
            "Epoch #1. Accuracy on batch 1363/2438  on Training is 60.224981671554254\n",
            "Epoch #1. Accuracy on batch 1364/2438  on Training is 60.23351648351648\n",
            "Epoch #1. Accuracy on batch 1365/2438  on Training is 60.22373718887262\n",
            "Epoch #1. Accuracy on batch 1366/2438  on Training is 60.225402340892465\n",
            "Epoch #1. Accuracy on batch 1367/2438  on Training is 60.215643274853804\n",
            "Epoch #1. Accuracy on batch 1368/2438  on Training is 60.2104638422206\n",
            "Epoch #1. Accuracy on batch 1369/2438  on Training is 60.20985401459854\n",
            "Epoch #1. Accuracy on batch 1370/2438  on Training is 60.209245076586434\n",
            "Epoch #1. Accuracy on batch 1371/2438  on Training is 60.206359329446066\n",
            "Epoch #1. Accuracy on batch 1372/2438  on Training is 60.203477785870355\n",
            "Epoch #1. Accuracy on batch 1373/2438  on Training is 60.20742358078603\n",
            "Epoch #1. Accuracy on batch 1374/2438  on Training is 60.20681818181818\n",
            "Epoch #1. Accuracy on batch 1375/2438  on Training is 60.19940043604651\n",
            "Epoch #1. Accuracy on batch 1376/2438  on Training is 60.19880174291939\n",
            "Epoch #1. Accuracy on batch 1377/2438  on Training is 60.20500725689405\n",
            "Epoch #1. Accuracy on batch 1378/2438  on Training is 60.213469905728786\n",
            "Epoch #1. Accuracy on batch 1379/2438  on Training is 60.21059782608695\n",
            "Batch Id 1380/2438 is having training loss of 1.6062724590301514\n",
            "1.4848053455352783\n",
            "Epoch #1. Accuracy on batch 1380/2438  on Training is 60.212255611875456\n",
            "Epoch #1. Accuracy on batch 1381/2438  on Training is 60.21617221418234\n",
            "Epoch #1. Accuracy on batch 1382/2438  on Training is 60.220083152566886\n",
            "Epoch #1. Accuracy on batch 1383/2438  on Training is 60.23076228323699\n",
            "Epoch #1. Accuracy on batch 1384/2438  on Training is 60.23014440433213\n",
            "Epoch #1. Accuracy on batch 1385/2438  on Training is 60.22727272727273\n",
            "Epoch #1. Accuracy on batch 1386/2438  on Training is 60.22891131939438\n",
            "Epoch #1. Accuracy on batch 1387/2438  on Training is 60.23054755043228\n",
            "Epoch #1. Accuracy on batch 1388/2438  on Training is 60.21868250539957\n",
            "Epoch #1. Accuracy on batch 1389/2438  on Training is 60.21357913669065\n",
            "Epoch #1. Accuracy on batch 1390/2438  on Training is 60.2152228612509\n",
            "Epoch #1. Accuracy on batch 1391/2438  on Training is 60.2191091954023\n",
            "Epoch #1. Accuracy on batch 1392/2438  on Training is 60.2185032304379\n",
            "Epoch #1. Accuracy on batch 1393/2438  on Training is 60.22013988522238\n",
            "Epoch #1. Accuracy on batch 1394/2438  on Training is 60.212813620071685\n",
            "Epoch #1. Accuracy on batch 1395/2438  on Training is 60.22340616045845\n",
            "Epoch #1. Accuracy on batch 1396/2438  on Training is 60.21832498210451\n",
            "Epoch #1. Accuracy on batch 1397/2438  on Training is 60.215486409155936\n",
            "Epoch #1. Accuracy on batch 1398/2438  on Training is 60.22382058613295\n",
            "Epoch #1. Accuracy on batch 1399/2438  on Training is 60.223214285714285\n",
            "Batch Id 1400/2438 is having training loss of 1.6054482460021973\n",
            "1.69894540309906\n",
            "Epoch #1. Accuracy on batch 1400/2438  on Training is 60.224839400428266\n",
            "Epoch #1. Accuracy on batch 1401/2438  on Training is 60.2242332382311\n",
            "Epoch #1. Accuracy on batch 1402/2438  on Training is 60.230310049893085\n",
            "Epoch #1. Accuracy on batch 1403/2438  on Training is 60.225249287749286\n",
            "Epoch #1. Accuracy on batch 1404/2438  on Training is 60.21574733096085\n",
            "Epoch #1. Accuracy on batch 1405/2438  on Training is 60.20848150782361\n",
            "Epoch #1. Accuracy on batch 1406/2438  on Training is 60.21233120113717\n",
            "Epoch #1. Accuracy on batch 1407/2438  on Training is 60.21839488636363\n",
            "Epoch #1. Accuracy on batch 1408/2438  on Training is 60.2333215046132\n",
            "Epoch #1. Accuracy on batch 1409/2438  on Training is 60.230496453900706\n",
            "Epoch #1. Accuracy on batch 1410/2438  on Training is 60.23210489014883\n",
            "Epoch #1. Accuracy on batch 1411/2438  on Training is 60.22928470254958\n",
            "Epoch #1. Accuracy on batch 1412/2438  on Training is 60.23089171974522\n",
            "Epoch #1. Accuracy on batch 1413/2438  on Training is 60.23249646393211\n",
            "Epoch #1. Accuracy on batch 1414/2438  on Training is 60.22968197879859\n",
            "Epoch #1. Accuracy on batch 1415/2438  on Training is 60.233492231638415\n",
            "Epoch #1. Accuracy on batch 1416/2438  on Training is 60.24170783345095\n",
            "Epoch #1. Accuracy on batch 1417/2438  on Training is 60.238892806770096\n",
            "Epoch #1. Accuracy on batch 1418/2438  on Training is 60.24048625792812\n",
            "Epoch #1. Accuracy on batch 1419/2438  on Training is 60.239876760563384\n",
            "Batch Id 1420/2438 is having training loss of 1.6054153442382812\n",
            "2.0702645778656006\n",
            "Epoch #1. Accuracy on batch 1420/2438  on Training is 60.22827234342013\n",
            "Epoch #1. Accuracy on batch 1421/2438  on Training is 60.22986990154712\n",
            "Epoch #1. Accuracy on batch 1422/2438  on Training is 60.23366127898805\n",
            "Epoch #1. Accuracy on batch 1423/2438  on Training is 60.23525280898876\n",
            "Epoch #1. Accuracy on batch 1424/2438  on Training is 60.24122807017544\n",
            "Epoch #1. Accuracy on batch 1425/2438  on Training is 60.236237727910236\n",
            "Epoch #1. Accuracy on batch 1426/2438  on Training is 60.23344428871759\n",
            "Epoch #1. Accuracy on batch 1427/2438  on Training is 60.237219887955185\n",
            "Epoch #1. Accuracy on batch 1428/2438  on Training is 60.240990202939116\n",
            "Epoch #1. Accuracy on batch 1429/2438  on Training is 60.25568181818182\n",
            "Epoch #1. Accuracy on batch 1430/2438  on Training is 60.24851502445842\n",
            "Epoch #1. Accuracy on batch 1431/2438  on Training is 60.245722765363126\n",
            "Epoch #1. Accuracy on batch 1432/2438  on Training is 60.242934403349615\n",
            "Epoch #1. Accuracy on batch 1433/2438  on Training is 60.24014993026499\n",
            "Epoch #1. Accuracy on batch 1434/2438  on Training is 60.24390243902439\n",
            "Epoch #1. Accuracy on batch 1435/2438  on Training is 60.258530640668525\n",
            "Epoch #1. Accuracy on batch 1436/2438  on Training is 60.264439805149614\n",
            "Epoch #1. Accuracy on batch 1437/2438  on Training is 60.25947496522949\n",
            "Epoch #1. Accuracy on batch 1438/2438  on Training is 60.25886031966643\n",
            "Epoch #1. Accuracy on batch 1439/2438  on Training is 60.256076388888886\n",
            "Batch Id 1440/2438 is having training loss of 1.6036731004714966\n",
            "1.1540193557739258\n",
            "Epoch #1. Accuracy on batch 1440/2438  on Training is 60.264139486467734\n",
            "Epoch #1. Accuracy on batch 1441/2438  on Training is 60.25485436893204\n",
            "Epoch #1. Accuracy on batch 1442/2438  on Training is 60.25424462924463\n",
            "Epoch #1. Accuracy on batch 1443/2438  on Training is 60.25796398891967\n",
            "Epoch #1. Accuracy on batch 1444/2438  on Training is 60.26167820069204\n",
            "Epoch #1. Accuracy on batch 1445/2438  on Training is 60.26322614107884\n",
            "Epoch #1. Accuracy on batch 1446/2438  on Training is 60.26045266067727\n",
            "Epoch #1. Accuracy on batch 1447/2438  on Training is 60.259841160220994\n",
            "Epoch #1. Accuracy on batch 1448/2438  on Training is 60.272170462387855\n",
            "Epoch #1. Accuracy on batch 1449/2438  on Training is 60.2801724137931\n",
            "Epoch #1. Accuracy on batch 1450/2438  on Training is 60.2881633356306\n",
            "Epoch #1. Accuracy on batch 1451/2438  on Training is 60.29183884297521\n",
            "Epoch #1. Accuracy on batch 1452/2438  on Training is 60.2912078458362\n",
            "Epoch #1. Accuracy on batch 1453/2438  on Training is 60.29917469050894\n",
            "Epoch #1. Accuracy on batch 1454/2438  on Training is 60.28994845360825\n",
            "Epoch #1. Accuracy on batch 1455/2438  on Training is 60.28717376373626\n",
            "Epoch #1. Accuracy on batch 1456/2438  on Training is 60.2886925188744\n",
            "Epoch #1. Accuracy on batch 1457/2438  on Training is 60.28163580246913\n",
            "Epoch #1. Accuracy on batch 1458/2438  on Training is 60.28315627141878\n",
            "Epoch #1. Accuracy on batch 1459/2438  on Training is 60.28039383561644\n",
            "Batch Id 1460/2438 is having training loss of 1.6013379096984863\n",
            "1.0982087850570679\n",
            "Epoch #1. Accuracy on batch 1460/2438  on Training is 60.28832991101985\n",
            "Epoch #1. Accuracy on batch 1461/2438  on Training is 60.28770519835842\n",
            "Epoch #1. Accuracy on batch 1462/2438  on Training is 60.28280929596719\n",
            "Epoch #1. Accuracy on batch 1463/2438  on Training is 60.290727459016395\n",
            "Epoch #1. Accuracy on batch 1464/2438  on Training is 60.29223549488054\n",
            "Epoch #1. Accuracy on batch 1465/2438  on Training is 60.29800477489768\n",
            "Epoch #1. Accuracy on batch 1466/2438  on Training is 60.28459441036128\n",
            "Epoch #1. Accuracy on batch 1467/2438  on Training is 60.28610354223433\n",
            "Epoch #1. Accuracy on batch 1468/2438  on Training is 60.28973791695031\n",
            "Epoch #1. Accuracy on batch 1469/2438  on Training is 60.29124149659864\n",
            "Epoch #1. Accuracy on batch 1470/2438  on Training is 60.29911624745071\n",
            "Epoch #1. Accuracy on batch 1471/2438  on Training is 60.29636548913044\n",
            "Epoch #1. Accuracy on batch 1472/2438  on Training is 60.2872539035981\n",
            "Epoch #1. Accuracy on batch 1473/2438  on Training is 60.292995251017636\n",
            "Epoch #1. Accuracy on batch 1474/2438  on Training is 60.28813559322034\n",
            "Epoch #1. Accuracy on batch 1475/2438  on Training is 60.295985772357724\n",
            "Epoch #1. Accuracy on batch 1476/2438  on Training is 60.30170954637779\n",
            "Epoch #1. Accuracy on batch 1477/2438  on Training is 60.31588294993234\n",
            "Epoch #1. Accuracy on batch 1478/2438  on Training is 60.3236984448952\n",
            "Epoch #1. Accuracy on batch 1479/2438  on Training is 60.33994932432432\n",
            "Batch Id 1480/2438 is having training loss of 1.5990862846374512\n",
            "1.7058229446411133\n",
            "Epoch #1. Accuracy on batch 1480/2438  on Training is 60.34140783254558\n",
            "Epoch #1. Accuracy on batch 1481/2438  on Training is 60.342864372469634\n",
            "Epoch #1. Accuracy on batch 1482/2438  on Training is 60.35485502360081\n",
            "Epoch #1. Accuracy on batch 1483/2438  on Training is 60.34998315363882\n",
            "Epoch #1. Accuracy on batch 1484/2438  on Training is 60.3493265993266\n",
            "Epoch #1. Accuracy on batch 1485/2438  on Training is 60.34446500672947\n",
            "Epoch #1. Accuracy on batch 1486/2438  on Training is 60.34171149966375\n",
            "Epoch #1. Accuracy on batch 1487/2438  on Training is 60.34106182795699\n",
            "Epoch #1. Accuracy on batch 1488/2438  on Training is 60.33201813297515\n",
            "Epoch #1. Accuracy on batch 1489/2438  on Training is 60.33137583892618\n",
            "Epoch #1. Accuracy on batch 1490/2438  on Training is 60.33492622401073\n",
            "Epoch #1. Accuracy on batch 1491/2438  on Training is 60.334282841823054\n",
            "Epoch #1. Accuracy on batch 1492/2438  on Training is 60.329454119223044\n",
            "Epoch #1. Accuracy on batch 1493/2438  on Training is 60.330906961178044\n",
            "Epoch #1. Accuracy on batch 1494/2438  on Training is 60.31981605351171\n",
            "Epoch #1. Accuracy on batch 1495/2438  on Training is 60.32754010695187\n",
            "Epoch #1. Accuracy on batch 1496/2438  on Training is 60.33316633266533\n",
            "Epoch #1. Accuracy on batch 1497/2438  on Training is 60.328354472630174\n",
            "Epoch #1. Accuracy on batch 1498/2438  on Training is 60.325633755837224\n",
            "Epoch #1. Accuracy on batch 1499/2438  on Training is 60.31875\n",
            "Batch Id 1500/2438 is having training loss of 1.5988386869430542\n",
            "1.0623213052749634\n",
            "Epoch #1. Accuracy on batch 1500/2438  on Training is 60.33061292471685\n",
            "Epoch #1. Accuracy on batch 1501/2438  on Training is 60.334137816245004\n",
            "Epoch #1. Accuracy on batch 1502/2438  on Training is 60.333499667332\n",
            "Epoch #1. Accuracy on batch 1503/2438  on Training is 60.33701795212766\n",
            "Epoch #1. Accuracy on batch 1504/2438  on Training is 60.3343023255814\n",
            "Epoch #1. Accuracy on batch 1505/2438  on Training is 60.34404050464808\n",
            "Epoch #1. Accuracy on batch 1506/2438  on Training is 60.35791307232913\n",
            "Epoch #1. Accuracy on batch 1507/2438  on Training is 60.35518899204244\n",
            "Epoch #1. Accuracy on batch 1508/2438  on Training is 60.3607521537442\n",
            "Epoch #1. Accuracy on batch 1509/2438  on Training is 60.36837748344371\n",
            "Epoch #1. Accuracy on batch 1510/2438  on Training is 60.37392455327598\n",
            "Epoch #1. Accuracy on batch 1511/2438  on Training is 60.37533068783069\n",
            "Epoch #1. Accuracy on batch 1512/2438  on Training is 60.3726040978189\n",
            "Epoch #1. Accuracy on batch 1513/2438  on Training is 60.36988110964333\n",
            "Epoch #1. Accuracy on batch 1514/2438  on Training is 60.369224422442244\n",
            "Epoch #1. Accuracy on batch 1515/2438  on Training is 60.37062994722955\n",
            "Epoch #1. Accuracy on batch 1516/2438  on Training is 60.37615359261701\n",
            "Epoch #1. Accuracy on batch 1517/2438  on Training is 60.38578722002635\n",
            "Epoch #1. Accuracy on batch 1518/2438  on Training is 60.39746543778802\n",
            "Epoch #1. Accuracy on batch 1519/2438  on Training is 60.39268092105263\n",
            "Batch Id 1520/2438 is having training loss of 1.5965871810913086\n",
            "1.702476143836975\n",
            "Epoch #1. Accuracy on batch 1520/2438  on Training is 60.38379355687048\n",
            "Epoch #1. Accuracy on batch 1521/2438  on Training is 60.37697109067017\n",
            "Epoch #1. Accuracy on batch 1522/2438  on Training is 60.38246881155614\n",
            "Epoch #1. Accuracy on batch 1523/2438  on Training is 60.37975721784777\n",
            "Epoch #1. Accuracy on batch 1524/2438  on Training is 60.381147540983605\n",
            "Epoch #1. Accuracy on batch 1525/2438  on Training is 60.38253604193971\n",
            "Epoch #1. Accuracy on batch 1526/2438  on Training is 60.39415520628684\n",
            "Epoch #1. Accuracy on batch 1527/2438  on Training is 60.40166884816754\n",
            "Epoch #1. Accuracy on batch 1528/2438  on Training is 60.41530412034009\n",
            "Epoch #1. Accuracy on batch 1529/2438  on Training is 60.41053921568628\n",
            "Epoch #1. Accuracy on batch 1530/2438  on Training is 60.40782168517309\n",
            "Epoch #1. Accuracy on batch 1531/2438  on Training is 60.405107702349866\n",
            "Epoch #1. Accuracy on batch 1532/2438  on Training is 60.406474233529025\n",
            "Epoch #1. Accuracy on batch 1533/2438  on Training is 60.40580182529335\n",
            "Epoch #1. Accuracy on batch 1534/2438  on Training is 60.41123778501629\n",
            "Epoch #1. Accuracy on batch 1535/2438  on Training is 60.414632161458336\n",
            "Epoch #1. Accuracy on batch 1536/2438  on Training is 60.42005530253741\n",
            "Epoch #1. Accuracy on batch 1537/2438  on Training is 60.41531209362809\n",
            "Epoch #1. Accuracy on batch 1538/2438  on Training is 60.416666666666664\n",
            "Epoch #1. Accuracy on batch 1539/2438  on Training is 60.420048701298704\n",
            "Batch Id 1540/2438 is having training loss of 1.5950385332107544\n",
            "1.406195878982544\n",
            "Epoch #1. Accuracy on batch 1540/2438  on Training is 60.41937053861129\n",
            "Epoch #1. Accuracy on batch 1541/2438  on Training is 60.42679961089494\n",
            "Epoch #1. Accuracy on batch 1542/2438  on Training is 60.41396629941672\n",
            "Epoch #1. Accuracy on batch 1543/2438  on Training is 60.41329339378238\n",
            "Epoch #1. Accuracy on batch 1544/2438  on Training is 60.42677993527508\n",
            "Epoch #1. Accuracy on batch 1545/2438  on Training is 60.42205692108668\n",
            "Epoch #1. Accuracy on batch 1546/2438  on Training is 60.42744020685197\n",
            "Epoch #1. Accuracy on batch 1547/2438  on Training is 60.426760335917315\n",
            "Epoch #1. Accuracy on batch 1548/2438  on Training is 60.42608134280181\n",
            "Epoch #1. Accuracy on batch 1549/2438  on Training is 60.431451612903224\n",
            "Epoch #1. Accuracy on batch 1550/2438  on Training is 60.43882978723404\n",
            "Epoch #1. Accuracy on batch 1551/2438  on Training is 60.434117268041234\n",
            "Epoch #1. Accuracy on batch 1552/2438  on Training is 60.43544752092724\n",
            "Epoch #1. Accuracy on batch 1553/2438  on Training is 60.4488416988417\n",
            "Epoch #1. Accuracy on batch 1554/2438  on Training is 60.444131832797424\n",
            "Epoch #1. Accuracy on batch 1555/2438  on Training is 60.447461439588686\n",
            "Epoch #1. Accuracy on batch 1556/2438  on Training is 60.45480089916506\n",
            "Epoch #1. Accuracy on batch 1557/2438  on Training is 60.44608472400513\n",
            "Epoch #1. Accuracy on batch 1558/2438  on Training is 60.43938422065427\n",
            "Epoch #1. Accuracy on batch 1559/2438  on Training is 60.43870192307692\n",
            "Batch Id 1560/2438 is having training loss of 1.5941860675811768\n",
            "1.3103079795837402\n",
            "Epoch #1. Accuracy on batch 1560/2438  on Training is 60.4440262652146\n",
            "Epoch #1. Accuracy on batch 1561/2438  on Training is 60.44134122919334\n",
            "Epoch #1. Accuracy on batch 1562/2438  on Training is 60.44865642994242\n",
            "Epoch #1. Accuracy on batch 1563/2438  on Training is 60.46195652173913\n",
            "Epoch #1. Accuracy on batch 1564/2438  on Training is 60.46725239616613\n",
            "Epoch #1. Accuracy on batch 1565/2438  on Training is 60.46655491698595\n",
            "Epoch #1. Accuracy on batch 1566/2438  on Training is 60.447910019144864\n",
            "Epoch #1. Accuracy on batch 1567/2438  on Training is 60.44921875\n",
            "Epoch #1. Accuracy on batch 1568/2438  on Training is 60.44455066921606\n",
            "Epoch #1. Accuracy on batch 1569/2438  on Training is 60.4359076433121\n",
            "Epoch #1. Accuracy on batch 1570/2438  on Training is 60.425286441756846\n",
            "Epoch #1. Accuracy on batch 1571/2438  on Training is 60.42461832061068\n",
            "Epoch #1. Accuracy on batch 1572/2438  on Training is 60.42395104895105\n",
            "Epoch #1. Accuracy on batch 1573/2438  on Training is 60.41732846251588\n",
            "Epoch #1. Accuracy on batch 1574/2438  on Training is 60.41468253968254\n",
            "Epoch #1. Accuracy on batch 1575/2438  on Training is 60.41203997461929\n",
            "Epoch #1. Accuracy on batch 1576/2438  on Training is 60.41732720355105\n",
            "Epoch #1. Accuracy on batch 1577/2438  on Training is 60.41864702154626\n",
            "Epoch #1. Accuracy on batch 1578/2438  on Training is 60.41600696643445\n",
            "Epoch #1. Accuracy on batch 1579/2438  on Training is 60.41337025316456\n",
            "Batch Id 1580/2438 is having training loss of 1.5945148468017578\n",
            "1.6487385034561157\n",
            "Epoch #1. Accuracy on batch 1580/2438  on Training is 60.41469006957622\n",
            "Epoch #1. Accuracy on batch 1581/2438  on Training is 60.40613147914033\n",
            "Epoch #1. Accuracy on batch 1582/2438  on Training is 60.39955780164245\n",
            "Epoch #1. Accuracy on batch 1583/2438  on Training is 60.40482954545455\n",
            "Epoch #1. Accuracy on batch 1584/2438  on Training is 60.40023659305994\n",
            "Epoch #1. Accuracy on batch 1585/2438  on Training is 60.39959016393443\n",
            "Epoch #1. Accuracy on batch 1586/2438  on Training is 60.40288279773157\n",
            "Epoch #1. Accuracy on batch 1587/2438  on Training is 60.40813916876574\n",
            "Epoch #1. Accuracy on batch 1588/2438  on Training is 60.40355569540591\n",
            "Epoch #1. Accuracy on batch 1589/2438  on Training is 60.402908805031444\n",
            "Epoch #1. Accuracy on batch 1590/2438  on Training is 60.40815524827153\n",
            "Epoch #1. Accuracy on batch 1591/2438  on Training is 60.409469221105525\n",
            "Epoch #1. Accuracy on batch 1592/2438  on Training is 60.40685812931576\n",
            "Epoch #1. Accuracy on batch 1593/2438  on Training is 60.40817126725219\n",
            "Epoch #1. Accuracy on batch 1594/2438  on Training is 60.42319749216301\n",
            "Epoch #1. Accuracy on batch 1595/2438  on Training is 60.428414786967416\n",
            "Epoch #1. Accuracy on batch 1596/2438  on Training is 60.427755165936134\n",
            "Epoch #1. Accuracy on batch 1597/2438  on Training is 60.43296307884856\n",
            "Epoch #1. Accuracy on batch 1598/2438  on Training is 60.43621013133208\n",
            "Epoch #1. Accuracy on batch 1599/2438  on Training is 60.43359375\n",
            "Batch Id 1600/2438 is having training loss of 1.5929255485534668\n",
            "1.211018681526184\n",
            "Epoch #1. Accuracy on batch 1600/2438  on Training is 60.436836352279826\n",
            "Epoch #1. Accuracy on batch 1601/2438  on Training is 60.440074906367045\n",
            "Epoch #1. Accuracy on batch 1602/2438  on Training is 60.4433094198378\n",
            "Epoch #1. Accuracy on batch 1603/2438  on Training is 60.44653990024938\n",
            "Epoch #1. Accuracy on batch 1604/2438  on Training is 60.440031152647975\n",
            "Epoch #1. Accuracy on batch 1605/2438  on Training is 60.43936799501868\n",
            "Epoch #1. Accuracy on batch 1606/2438  on Training is 60.45037336652147\n",
            "Epoch #1. Accuracy on batch 1607/2438  on Training is 60.45747823383085\n",
            "Epoch #1. Accuracy on batch 1608/2438  on Training is 60.45874766935985\n",
            "Epoch #1. Accuracy on batch 1609/2438  on Training is 60.45807453416149\n",
            "Epoch #1. Accuracy on batch 1610/2438  on Training is 60.45934202358784\n",
            "Epoch #1. Accuracy on batch 1611/2438  on Training is 60.46254652605459\n",
            "Epoch #1. Accuracy on batch 1612/2438  on Training is 60.46574705517669\n",
            "Epoch #1. Accuracy on batch 1613/2438  on Training is 60.46894361833953\n",
            "Epoch #1. Accuracy on batch 1614/2438  on Training is 60.46826625386997\n",
            "Epoch #1. Accuracy on batch 1615/2438  on Training is 60.47919245049505\n",
            "Epoch #1. Accuracy on batch 1616/2438  on Training is 60.48237476808905\n",
            "Epoch #1. Accuracy on batch 1617/2438  on Training is 60.48169035846724\n",
            "Epoch #1. Accuracy on batch 1618/2438  on Training is 60.479076590487956\n",
            "Epoch #1. Accuracy on batch 1619/2438  on Training is 60.48225308641975\n",
            "Batch Id 1620/2438 is having training loss of 1.591654658317566\n",
            "1.8216904401779175\n",
            "Epoch #1. Accuracy on batch 1620/2438  on Training is 60.47385872917952\n",
            "Epoch #1. Accuracy on batch 1621/2438  on Training is 60.47510789149199\n",
            "Epoch #1. Accuracy on batch 1622/2438  on Training is 60.48020640788663\n",
            "Epoch #1. Accuracy on batch 1623/2438  on Training is 60.47952586206897\n",
            "Epoch #1. Accuracy on batch 1624/2438  on Training is 60.48269230769231\n",
            "Epoch #1. Accuracy on batch 1625/2438  on Training is 60.47816728167282\n",
            "Epoch #1. Accuracy on batch 1626/2438  on Training is 60.47940995697603\n",
            "Epoch #1. Accuracy on batch 1627/2438  on Training is 60.48640970515971\n",
            "Epoch #1. Accuracy on batch 1628/2438  on Training is 60.49340085942296\n",
            "Epoch #1. Accuracy on batch 1629/2438  on Training is 60.49271472392638\n",
            "Epoch #1. Accuracy on batch 1630/2438  on Training is 60.49394543225015\n",
            "Epoch #1. Accuracy on batch 1631/2438  on Training is 60.49325980392157\n",
            "Epoch #1. Accuracy on batch 1632/2438  on Training is 60.49448867115738\n",
            "Epoch #1. Accuracy on batch 1633/2438  on Training is 60.49571603427172\n",
            "Epoch #1. Accuracy on batch 1634/2438  on Training is 60.49311926605505\n",
            "Epoch #1. Accuracy on batch 1635/2438  on Training is 60.49434596577017\n",
            "Epoch #1. Accuracy on batch 1636/2438  on Training is 60.497480146609654\n",
            "Epoch #1. Accuracy on batch 1637/2438  on Training is 60.502518315018314\n",
            "Epoch #1. Accuracy on batch 1638/2438  on Training is 60.5037370347773\n",
            "Epoch #1. Accuracy on batch 1639/2438  on Training is 60.504954268292686\n",
            "Batch Id 1640/2438 is having training loss of 1.5896466970443726\n",
            "1.2243292331695557\n",
            "Epoch #1. Accuracy on batch 1640/2438  on Training is 60.51188299817185\n",
            "Epoch #1. Accuracy on batch 1641/2438  on Training is 60.51690012180268\n",
            "Epoch #1. Accuracy on batch 1642/2438  on Training is 60.50859707851491\n",
            "Epoch #1. Accuracy on batch 1643/2438  on Training is 60.509808394160586\n",
            "Epoch #1. Accuracy on batch 1644/2438  on Training is 60.507218844984806\n",
            "Epoch #1. Accuracy on batch 1645/2438  on Training is 60.50842952612393\n",
            "Epoch #1. Accuracy on batch 1646/2438  on Training is 60.50774134790528\n",
            "Epoch #1. Accuracy on batch 1647/2438  on Training is 60.50136529126213\n",
            "Epoch #1. Accuracy on batch 1648/2438  on Training is 60.51015767131595\n",
            "Epoch #1. Accuracy on batch 1649/2438  on Training is 60.515151515151516\n",
            "Epoch #1. Accuracy on batch 1650/2438  on Training is 60.51635372501514\n",
            "Epoch #1. Accuracy on batch 1651/2438  on Training is 60.517554479418884\n",
            "Epoch #1. Accuracy on batch 1652/2438  on Training is 60.52442528735632\n",
            "Epoch #1. Accuracy on batch 1653/2438  on Training is 60.52561970979444\n",
            "Epoch #1. Accuracy on batch 1654/2438  on Training is 60.5154833836858\n",
            "Epoch #1. Accuracy on batch 1655/2438  on Training is 60.51856884057971\n",
            "Epoch #1. Accuracy on batch 1656/2438  on Training is 60.525422450211224\n",
            "Epoch #1. Accuracy on batch 1657/2438  on Training is 60.520958986731\n",
            "Epoch #1. Accuracy on batch 1658/2438  on Training is 60.52215189873418\n",
            "Epoch #1. Accuracy on batch 1659/2438  on Training is 60.519578313253014\n",
            "Batch Id 1660/2438 is having training loss of 1.589035153388977\n",
            "1.421957015991211\n",
            "Epoch #1. Accuracy on batch 1660/2438  on Training is 60.524533413606264\n",
            "Epoch #1. Accuracy on batch 1661/2438  on Training is 60.529482551143204\n",
            "Epoch #1. Accuracy on batch 1662/2438  on Training is 60.53442573662056\n",
            "Epoch #1. Accuracy on batch 1663/2438  on Training is 60.53748497596154\n",
            "Epoch #1. Accuracy on batch 1664/2438  on Training is 60.533033033033036\n",
            "Epoch #1. Accuracy on batch 1665/2438  on Training is 60.53421368547419\n",
            "Epoch #1. Accuracy on batch 1666/2438  on Training is 60.546640671865624\n",
            "Epoch #1. Accuracy on batch 1667/2438  on Training is 60.555305755395686\n",
            "Epoch #1. Accuracy on batch 1668/2438  on Training is 60.55647094068304\n",
            "Epoch #1. Accuracy on batch 1669/2438  on Training is 60.56137724550898\n",
            "Epoch #1. Accuracy on batch 1670/2438  on Training is 60.5662776780371\n",
            "Epoch #1. Accuracy on batch 1671/2438  on Training is 60.561827153110045\n",
            "Epoch #1. Accuracy on batch 1672/2438  on Training is 60.56298565451285\n",
            "Epoch #1. Accuracy on batch 1673/2438  on Training is 60.569743130227\n",
            "Epoch #1. Accuracy on batch 1674/2438  on Training is 60.57462686567164\n",
            "Epoch #1. Accuracy on batch 1675/2438  on Training is 60.57950477326969\n",
            "Epoch #1. Accuracy on batch 1676/2438  on Training is 60.569469290399525\n",
            "Epoch #1. Accuracy on batch 1677/2438  on Training is 60.578069129916564\n",
            "Epoch #1. Accuracy on batch 1678/2438  on Training is 60.582936271590235\n",
            "Epoch #1. Accuracy on batch 1679/2438  on Training is 60.576636904761905\n",
            "Batch Id 1680/2438 is having training loss of 1.5864531993865967\n",
            "1.7878986597061157\n",
            "Epoch #1. Accuracy on batch 1680/2438  on Training is 60.57220404521119\n",
            "Epoch #1. Accuracy on batch 1681/2438  on Training is 60.56406064209275\n",
            "Epoch #1. Accuracy on batch 1682/2438  on Training is 60.55964052287582\n",
            "Epoch #1. Accuracy on batch 1683/2438  on Training is 60.54780285035629\n",
            "Epoch #1. Accuracy on batch 1684/2438  on Training is 60.545252225519285\n",
            "Epoch #1. Accuracy on batch 1685/2438  on Training is 60.54085112692764\n",
            "Epoch #1. Accuracy on batch 1686/2438  on Training is 60.54016004742146\n",
            "Epoch #1. Accuracy on batch 1687/2438  on Training is 60.54502369668246\n",
            "Epoch #1. Accuracy on batch 1688/2438  on Training is 60.53693013617525\n",
            "Epoch #1. Accuracy on batch 1689/2438  on Training is 60.53809171597633\n",
            "Epoch #1. Accuracy on batch 1690/2438  on Training is 60.53925192193968\n",
            "Epoch #1. Accuracy on batch 1691/2438  on Training is 60.536716903073284\n",
            "Epoch #1. Accuracy on batch 1692/2438  on Training is 60.53787655050207\n",
            "Epoch #1. Accuracy on batch 1693/2438  on Training is 60.53350059031877\n",
            "Epoch #1. Accuracy on batch 1694/2438  on Training is 60.53466076696165\n",
            "Epoch #1. Accuracy on batch 1695/2438  on Training is 60.543189858490564\n",
            "Epoch #1. Accuracy on batch 1696/2438  on Training is 60.53329404832056\n",
            "Epoch #1. Accuracy on batch 1697/2438  on Training is 60.528931095406364\n",
            "Epoch #1. Accuracy on batch 1698/2438  on Training is 60.526412595644494\n",
            "Epoch #1. Accuracy on batch 1699/2438  on Training is 60.529411764705884\n",
            "Batch Id 1700/2438 is having training loss of 1.586957573890686\n",
            "1.6159220933914185\n",
            "Epoch #1. Accuracy on batch 1700/2438  on Training is 60.52873309817754\n",
            "Epoch #1. Accuracy on batch 1701/2438  on Training is 60.52989130434783\n",
            "Epoch #1. Accuracy on batch 1702/2438  on Training is 60.53838813857898\n",
            "Epoch #1. Accuracy on batch 1703/2438  on Training is 60.543207159624416\n",
            "Epoch #1. Accuracy on batch 1704/2438  on Training is 60.54802052785924\n",
            "Epoch #1. Accuracy on batch 1705/2438  on Training is 60.55099648300117\n",
            "Epoch #1. Accuracy on batch 1706/2438  on Training is 60.548476859988284\n",
            "Epoch #1. Accuracy on batch 1707/2438  on Training is 60.54778981264637\n",
            "Epoch #1. Accuracy on batch 1708/2438  on Training is 60.54527501462844\n",
            "Epoch #1. Accuracy on batch 1709/2438  on Training is 60.54641812865497\n",
            "Epoch #1. Accuracy on batch 1710/2438  on Training is 60.551212741087085\n",
            "Epoch #1. Accuracy on batch 1711/2438  on Training is 60.55052570093458\n",
            "Epoch #1. Accuracy on batch 1712/2438  on Training is 60.54801517805021\n",
            "Epoch #1. Accuracy on batch 1713/2438  on Training is 60.549154025670944\n",
            "Epoch #1. Accuracy on batch 1714/2438  on Training is 60.548469387755105\n",
            "Epoch #1. Accuracy on batch 1715/2438  on Training is 60.54960664335665\n",
            "Epoch #1. Accuracy on batch 1716/2438  on Training is 60.55438264414677\n",
            "Epoch #1. Accuracy on batch 1717/2438  on Training is 60.56279103608848\n",
            "Epoch #1. Accuracy on batch 1718/2438  on Training is 60.56391797556719\n",
            "Epoch #1. Accuracy on batch 1719/2438  on Training is 60.56140988372093\n",
            "Batch Id 1720/2438 is having training loss of 1.5853441953659058\n",
            "1.5675108432769775\n",
            "Epoch #1. Accuracy on batch 1720/2438  on Training is 60.55890470656595\n",
            "Epoch #1. Accuracy on batch 1721/2438  on Training is 60.56729094076655\n",
            "Epoch #1. Accuracy on batch 1722/2438  on Training is 60.56478525827046\n",
            "Epoch #1. Accuracy on batch 1723/2438  on Training is 60.56409512761021\n",
            "Epoch #1. Accuracy on batch 1724/2438  on Training is 60.55978260869565\n",
            "Epoch #1. Accuracy on batch 1725/2438  on Training is 60.564527809965234\n",
            "Epoch #1. Accuracy on batch 1726/2438  on Training is 60.56745801968732\n",
            "Epoch #1. Accuracy on batch 1727/2438  on Training is 60.57038483796296\n",
            "Epoch #1. Accuracy on batch 1728/2438  on Training is 60.57873048004627\n",
            "Epoch #1. Accuracy on batch 1729/2438  on Training is 60.583453757225435\n",
            "Epoch #1. Accuracy on batch 1730/2438  on Training is 60.57372905834777\n",
            "Epoch #1. Accuracy on batch 1731/2438  on Training is 60.578449769053115\n",
            "Epoch #1. Accuracy on batch 1732/2438  on Training is 60.577755337564916\n",
            "Epoch #1. Accuracy on batch 1733/2438  on Training is 60.57886389850058\n",
            "Epoch #1. Accuracy on batch 1734/2438  on Training is 60.585374639769455\n",
            "Epoch #1. Accuracy on batch 1735/2438  on Training is 60.59007776497696\n",
            "Epoch #1. Accuracy on batch 1736/2438  on Training is 60.59837363270006\n",
            "Epoch #1. Accuracy on batch 1737/2438  on Training is 60.59227560414269\n",
            "Epoch #1. Accuracy on batch 1738/2438  on Training is 60.589778608395626\n",
            "Epoch #1. Accuracy on batch 1739/2438  on Training is 60.59626436781609\n",
            "Batch Id 1740/2438 is having training loss of 1.5833265781402588\n",
            "1.858789324760437\n",
            "Epoch #1. Accuracy on batch 1740/2438  on Training is 60.59017805858702\n",
            "Epoch #1. Accuracy on batch 1741/2438  on Training is 60.589480482204365\n",
            "Epoch #1. Accuracy on batch 1742/2438  on Training is 60.58699082042455\n",
            "Epoch #1. Accuracy on batch 1743/2438  on Training is 60.59525516055046\n",
            "Epoch #1. Accuracy on batch 1744/2438  on Training is 60.5945558739255\n",
            "Epoch #1. Accuracy on batch 1745/2438  on Training is 60.595647193585336\n",
            "Epoch #1. Accuracy on batch 1746/2438  on Training is 60.59494848311391\n",
            "Epoch #1. Accuracy on batch 1747/2438  on Training is 60.599613844393595\n",
            "Epoch #1. Accuracy on batch 1748/2438  on Training is 60.6007004002287\n",
            "Epoch #1. Accuracy on batch 1749/2438  on Training is 60.60357142857143\n",
            "Epoch #1. Accuracy on batch 1750/2438  on Training is 60.59930039977156\n",
            "Epoch #1. Accuracy on batch 1751/2438  on Training is 60.61108732876713\n",
            "Epoch #1. Accuracy on batch 1752/2438  on Training is 60.601468910439245\n",
            "Epoch #1. Accuracy on batch 1753/2438  on Training is 60.60255131128849\n",
            "Epoch #1. Accuracy on batch 1754/2438  on Training is 60.60363247863248\n",
            "Epoch #1. Accuracy on batch 1755/2438  on Training is 60.61005125284738\n",
            "Epoch #1. Accuracy on batch 1756/2438  on Training is 60.61646272054639\n",
            "Epoch #1. Accuracy on batch 1757/2438  on Training is 60.622866894197955\n",
            "Epoch #1. Accuracy on batch 1758/2438  on Training is 60.632816941444005\n",
            "Epoch #1. Accuracy on batch 1759/2438  on Training is 60.62855113636363\n",
            "Batch Id 1760/2438 is having training loss of 1.5821173191070557\n",
            "1.7422592639923096\n",
            "Epoch #1. Accuracy on batch 1760/2438  on Training is 60.62783929585463\n",
            "Epoch #1. Accuracy on batch 1761/2438  on Training is 60.623581157775256\n",
            "Epoch #1. Accuracy on batch 1762/2438  on Training is 60.619327850255246\n",
            "Epoch #1. Accuracy on batch 1763/2438  on Training is 60.61862244897959\n",
            "Epoch #1. Accuracy on batch 1764/2438  on Training is 60.623229461756374\n",
            "Epoch #1. Accuracy on batch 1765/2438  on Training is 60.62429218573046\n",
            "Epoch #1. Accuracy on batch 1766/2438  on Training is 60.63242784380306\n",
            "Epoch #1. Accuracy on batch 1767/2438  on Training is 60.635251696832576\n",
            "Epoch #1. Accuracy on batch 1768/2438  on Training is 60.63277275296778\n",
            "Epoch #1. Accuracy on batch 1769/2438  on Training is 60.630296610169495\n",
            "Epoch #1. Accuracy on batch 1770/2438  on Training is 60.6348814229249\n",
            "Epoch #1. Accuracy on batch 1771/2438  on Training is 60.63064334085779\n",
            "Epoch #1. Accuracy on batch 1772/2438  on Training is 60.633460236886634\n",
            "Epoch #1. Accuracy on batch 1773/2438  on Training is 60.63275084554679\n",
            "Epoch #1. Accuracy on batch 1774/2438  on Training is 60.62852112676056\n",
            "Epoch #1. Accuracy on batch 1775/2438  on Training is 60.620777027027025\n",
            "Epoch #1. Accuracy on batch 1776/2438  on Training is 60.62359313449634\n",
            "Epoch #1. Accuracy on batch 1777/2438  on Training is 60.62464848143982\n",
            "Epoch #1. Accuracy on batch 1778/2438  on Training is 60.62043282743114\n",
            "Epoch #1. Accuracy on batch 1779/2438  on Training is 60.63026685393258\n",
            "Batch Id 1780/2438 is having training loss of 1.5831081867218018\n",
            "1.977574348449707\n",
            "Epoch #1. Accuracy on batch 1780/2438  on Training is 60.62429814710837\n",
            "Epoch #1. Accuracy on batch 1781/2438  on Training is 60.63236531986532\n",
            "Epoch #1. Accuracy on batch 1782/2438  on Training is 60.62464946719013\n",
            "Epoch #1. Accuracy on batch 1783/2438  on Training is 60.63095571748879\n",
            "Epoch #1. Accuracy on batch 1784/2438  on Training is 60.63375350140056\n",
            "Epoch #1. Accuracy on batch 1785/2438  on Training is 60.62779955207167\n",
            "Epoch #1. Accuracy on batch 1786/2438  on Training is 60.63584219362059\n",
            "Epoch #1. Accuracy on batch 1787/2438  on Training is 60.636884787472034\n",
            "Epoch #1. Accuracy on batch 1788/2438  on Training is 60.644913359418666\n",
            "Epoch #1. Accuracy on batch 1789/2438  on Training is 60.642458100558656\n",
            "Epoch #1. Accuracy on batch 1790/2438  on Training is 60.645240089335566\n",
            "Epoch #1. Accuracy on batch 1791/2438  on Training is 60.64453125\n",
            "Epoch #1. Accuracy on batch 1792/2438  on Training is 60.64382320133854\n",
            "Epoch #1. Accuracy on batch 1793/2438  on Training is 60.650083612040135\n",
            "Epoch #1. Accuracy on batch 1794/2438  on Training is 60.64937325905292\n",
            "Epoch #1. Accuracy on batch 1795/2438  on Training is 60.65214365256125\n",
            "Epoch #1. Accuracy on batch 1796/2438  on Training is 60.65317195325542\n",
            "Epoch #1. Accuracy on batch 1797/2438  on Training is 60.65072302558398\n",
            "Epoch #1. Accuracy on batch 1798/2438  on Training is 60.64480266814897\n",
            "Epoch #1. Accuracy on batch 1799/2438  on Training is 60.64409722222222\n",
            "Batch Id 1800/2438 is having training loss of 1.5820387601852417\n",
            "1.5794003009796143\n",
            "Epoch #1. Accuracy on batch 1800/2438  on Training is 60.64512770682954\n",
            "Epoch #1. Accuracy on batch 1801/2438  on Training is 60.647891231964486\n",
            "Epoch #1. Accuracy on batch 1802/2438  on Training is 60.64371880199667\n",
            "Epoch #1. Accuracy on batch 1803/2438  on Training is 60.65340909090909\n",
            "Epoch #1. Accuracy on batch 1804/2438  on Training is 60.65616343490305\n",
            "Epoch #1. Accuracy on batch 1805/2438  on Training is 60.65891472868217\n",
            "Epoch #1. Accuracy on batch 1806/2438  on Training is 60.65993359158827\n",
            "Epoch #1. Accuracy on batch 1807/2438  on Training is 60.66959347345133\n",
            "Epoch #1. Accuracy on batch 1808/2438  on Training is 60.66542288557214\n",
            "Epoch #1. Accuracy on batch 1809/2438  on Training is 60.6664364640884\n",
            "Epoch #1. Accuracy on batch 1810/2438  on Training is 60.66572335726118\n",
            "Epoch #1. Accuracy on batch 1811/2438  on Training is 60.67018487858719\n",
            "Epoch #1. Accuracy on batch 1812/2438  on Training is 60.67119415333701\n",
            "Epoch #1. Accuracy on batch 1813/2438  on Training is 60.668756890848954\n",
            "Epoch #1. Accuracy on batch 1814/2438  on Training is 60.673209366391184\n",
            "Epoch #1. Accuracy on batch 1815/2438  on Training is 60.66733204845815\n",
            "Epoch #1. Accuracy on batch 1816/2438  on Training is 60.67006053935058\n",
            "Epoch #1. Accuracy on batch 1817/2438  on Training is 60.66762926292629\n",
            "Epoch #1. Accuracy on batch 1818/2438  on Training is 60.666918636613524\n",
            "Epoch #1. Accuracy on batch 1819/2438  on Training is 60.65934065934066\n",
            "Batch Id 1820/2438 is having training loss of 1.5812801122665405\n",
            "1.3222113847732544\n",
            "Epoch #1. Accuracy on batch 1820/2438  on Training is 60.66549972542559\n",
            "Epoch #1. Accuracy on batch 1821/2438  on Training is 60.66650658616904\n",
            "Epoch #1. Accuracy on batch 1822/2438  on Training is 60.674369171695005\n",
            "Epoch #1. Accuracy on batch 1823/2438  on Training is 60.677083333333336\n",
            "Epoch #1. Accuracy on batch 1824/2438  on Training is 60.67465753424658\n",
            "Epoch #1. Accuracy on batch 1825/2438  on Training is 60.68079134720701\n",
            "Epoch #1. Accuracy on batch 1826/2438  on Training is 60.67836617405583\n",
            "Epoch #1. Accuracy on batch 1827/2438  on Training is 60.670815098468275\n",
            "Epoch #1. Accuracy on batch 1828/2438  on Training is 60.66498086386003\n",
            "Epoch #1. Accuracy on batch 1829/2438  on Training is 60.672814207650276\n",
            "Epoch #1. Accuracy on batch 1830/2438  on Training is 60.672105406881485\n",
            "Epoch #1. Accuracy on batch 1831/2438  on Training is 60.66628002183406\n",
            "Epoch #1. Accuracy on batch 1832/2438  on Training is 60.67239498090562\n",
            "Epoch #1. Accuracy on batch 1833/2438  on Training is 60.67850327153762\n",
            "Epoch #1. Accuracy on batch 1834/2438  on Training is 60.677792915531334\n",
            "Epoch #1. Accuracy on batch 1835/2438  on Training is 60.68218954248366\n",
            "Epoch #1. Accuracy on batch 1836/2438  on Training is 60.67637452367991\n",
            "Epoch #1. Accuracy on batch 1837/2438  on Training is 60.6841675734494\n",
            "Epoch #1. Accuracy on batch 1838/2438  on Training is 60.68515497553018\n",
            "Epoch #1. Accuracy on batch 1839/2438  on Training is 60.68783967391305\n",
            "Batch Id 1840/2438 is having training loss of 1.5800929069519043\n",
            "1.1254503726959229\n",
            "Epoch #1. Accuracy on batch 1840/2438  on Training is 60.69731124388919\n",
            "Epoch #1. Accuracy on batch 1841/2438  on Training is 60.69998642779587\n",
            "Epoch #1. Accuracy on batch 1842/2438  on Training is 60.69248507867607\n",
            "Epoch #1. Accuracy on batch 1843/2438  on Training is 60.69346529284165\n",
            "Epoch #1. Accuracy on batch 1844/2438  on Training is 60.69275067750677\n",
            "Epoch #1. Accuracy on batch 1845/2438  on Training is 60.69711538461539\n",
            "Epoch #1. Accuracy on batch 1846/2438  on Training is 60.69978343259339\n",
            "Epoch #1. Accuracy on batch 1847/2438  on Training is 60.695684523809526\n",
            "Epoch #1. Accuracy on batch 1848/2438  on Training is 60.69497025419145\n",
            "Epoch #1. Accuracy on batch 1849/2438  on Training is 60.69087837837838\n",
            "Epoch #1. Accuracy on batch 1850/2438  on Training is 60.6884792004322\n",
            "Epoch #1. Accuracy on batch 1851/2438  on Training is 60.68102051835853\n",
            "Epoch #1. Accuracy on batch 1852/2438  on Training is 60.67694279546681\n",
            "Epoch #1. Accuracy on batch 1853/2438  on Training is 60.68298274002157\n",
            "Epoch #1. Accuracy on batch 1854/2438  on Training is 60.68396226415094\n",
            "Epoch #1. Accuracy on batch 1855/2438  on Training is 60.689991918103445\n",
            "Epoch #1. Accuracy on batch 1856/2438  on Training is 60.68928379106085\n",
            "Epoch #1. Accuracy on batch 1857/2438  on Training is 60.6852125941873\n",
            "Epoch #1. Accuracy on batch 1858/2438  on Training is 60.684507799892415\n",
            "Epoch #1. Accuracy on batch 1859/2438  on Training is 60.685483870967744\n",
            "Batch Id 1860/2438 is having training loss of 1.5799283981323242\n",
            "1.357391357421875\n",
            "Epoch #1. Accuracy on batch 1860/2438  on Training is 60.689817302525526\n",
            "Epoch #1. Accuracy on batch 1861/2438  on Training is 60.69918098818475\n",
            "Epoch #1. Accuracy on batch 1862/2438  on Training is 60.696792807300056\n",
            "Epoch #1. Accuracy on batch 1863/2438  on Training is 60.701113197424895\n",
            "Epoch #1. Accuracy on batch 1864/2438  on Training is 60.70040214477212\n",
            "Epoch #1. Accuracy on batch 1865/2438  on Training is 60.70806538049303\n",
            "Epoch #1. Accuracy on batch 1866/2438  on Training is 60.704003749330475\n",
            "Epoch #1. Accuracy on batch 1867/2438  on Training is 60.70663811563169\n",
            "Epoch #1. Accuracy on batch 1868/2438  on Training is 60.70090957731407\n",
            "Epoch #1. Accuracy on batch 1869/2438  on Training is 60.70020053475936\n",
            "Epoch #1. Accuracy on batch 1870/2438  on Training is 60.711183858898984\n",
            "Epoch #1. Accuracy on batch 1871/2438  on Training is 60.70713141025641\n",
            "Epoch #1. Accuracy on batch 1872/2438  on Training is 60.6997463961559\n",
            "Epoch #1. Accuracy on batch 1873/2438  on Training is 60.699039487726786\n",
            "Epoch #1. Accuracy on batch 1874/2438  on Training is 60.69166666666667\n",
            "Epoch #1. Accuracy on batch 1875/2438  on Training is 60.692630597014926\n",
            "Epoch #1. Accuracy on batch 1876/2438  on Training is 60.69692328183271\n",
            "Epoch #1. Accuracy on batch 1877/2438  on Training is 60.697883386581466\n",
            "Epoch #1. Accuracy on batch 1878/2438  on Training is 60.693853113358166\n",
            "Epoch #1. Accuracy on batch 1879/2438  on Training is 60.691489361702125\n",
            "Batch Id 1880/2438 is having training loss of 1.578995704650879\n",
            "1.2816318273544312\n",
            "Epoch #1. Accuracy on batch 1880/2438  on Training is 60.69078947368421\n",
            "Epoch #1. Accuracy on batch 1881/2438  on Training is 60.686769394261425\n",
            "Epoch #1. Accuracy on batch 1882/2438  on Training is 60.696030270844396\n",
            "Epoch #1. Accuracy on batch 1883/2438  on Training is 60.69698779193206\n",
            "Epoch #1. Accuracy on batch 1884/2438  on Training is 60.69960212201592\n",
            "Epoch #1. Accuracy on batch 1885/2438  on Training is 60.697242841993635\n",
            "Epoch #1. Accuracy on batch 1886/2438  on Training is 60.6981981981982\n",
            "Epoch #1. Accuracy on batch 1887/2438  on Training is 60.70908368644068\n",
            "Epoch #1. Accuracy on batch 1888/2438  on Training is 60.705068819481205\n",
            "Epoch #1. Accuracy on batch 1889/2438  on Training is 60.70601851851852\n",
            "Epoch #1. Accuracy on batch 1890/2438  on Training is 60.70696721311475\n",
            "Epoch #1. Accuracy on batch 1891/2438  on Training is 60.71286997885835\n",
            "Epoch #1. Accuracy on batch 1892/2438  on Training is 60.71381405176968\n",
            "Epoch #1. Accuracy on batch 1893/2438  on Training is 60.72135691657867\n",
            "Epoch #1. Accuracy on batch 1894/2438  on Training is 60.72229551451187\n",
            "Epoch #1. Accuracy on batch 1895/2438  on Training is 60.721584915611814\n",
            "Epoch #1. Accuracy on batch 1896/2438  on Training is 60.722522403795466\n",
            "Epoch #1. Accuracy on batch 1897/2438  on Training is 60.72510537407798\n",
            "Epoch #1. Accuracy on batch 1898/2438  on Training is 60.72604002106372\n",
            "Epoch #1. Accuracy on batch 1899/2438  on Training is 60.73026315789474\n",
            "Batch Id 1900/2438 is having training loss of 1.5771445035934448\n",
            "1.1690200567245483\n",
            "Epoch #1. Accuracy on batch 1900/2438  on Training is 60.729550236717515\n",
            "Epoch #1. Accuracy on batch 1901/2438  on Training is 60.737053101997894\n",
            "Epoch #1. Accuracy on batch 1902/2438  on Training is 60.73962165002627\n",
            "Epoch #1. Accuracy on batch 1903/2438  on Training is 60.73890493697479\n",
            "Epoch #1. Accuracy on batch 1904/2438  on Training is 60.73654855643045\n",
            "Epoch #1. Accuracy on batch 1905/2438  on Training is 60.73747376705142\n",
            "Epoch #1. Accuracy on batch 1906/2438  on Training is 60.735120608285264\n",
            "Epoch #1. Accuracy on batch 1907/2438  on Training is 60.73604559748428\n",
            "Epoch #1. Accuracy on batch 1908/2438  on Training is 60.74024358302776\n",
            "Epoch #1. Accuracy on batch 1909/2438  on Training is 60.736256544502616\n",
            "Epoch #1. Accuracy on batch 1910/2438  on Training is 60.73717948717949\n",
            "Epoch #1. Accuracy on batch 1911/2438  on Training is 60.73810146443515\n",
            "Epoch #1. Accuracy on batch 1912/2438  on Training is 60.73575535807632\n",
            "Epoch #1. Accuracy on batch 1913/2438  on Training is 60.72524817136886\n",
            "Epoch #1. Accuracy on batch 1914/2438  on Training is 60.71638381201044\n",
            "Epoch #1. Accuracy on batch 1915/2438  on Training is 60.715683716075155\n",
            "Epoch #1. Accuracy on batch 1916/2438  on Training is 60.71824465310381\n",
            "Epoch #1. Accuracy on batch 1917/2438  on Training is 60.71917361835245\n",
            "Epoch #1. Accuracy on batch 1918/2438  on Training is 60.72661542470036\n",
            "Epoch #1. Accuracy on batch 1919/2438  on Training is 60.735677083333336\n",
            "Batch Id 1920/2438 is having training loss of 1.5766863822937012\n",
            "1.3806068897247314\n",
            "Epoch #1. Accuracy on batch 1920/2438  on Training is 60.73334200937012\n",
            "Epoch #1. Accuracy on batch 1921/2438  on Training is 60.739138917793966\n",
            "Epoch #1. Accuracy on batch 1922/2438  on Training is 60.74167966718669\n",
            "Epoch #1. Accuracy on batch 1923/2438  on Training is 60.749090436590436\n",
            "Epoch #1. Accuracy on batch 1924/2438  on Training is 60.75\n",
            "Epoch #1. Accuracy on batch 1925/2438  on Training is 60.75739875389408\n",
            "Epoch #1. Accuracy on batch 1926/2438  on Training is 60.75668137000519\n",
            "Epoch #1. Accuracy on batch 1927/2438  on Training is 60.75758558091286\n",
            "Epoch #1. Accuracy on batch 1928/2438  on Training is 60.75848885432867\n",
            "Epoch #1. Accuracy on batch 1929/2438  on Training is 60.76586787564767\n",
            "Epoch #1. Accuracy on batch 1930/2438  on Training is 60.76191092698084\n",
            "Epoch #1. Accuracy on batch 1931/2438  on Training is 60.770898033126294\n",
            "Epoch #1. Accuracy on batch 1932/2438  on Training is 60.773409208484225\n",
            "Epoch #1. Accuracy on batch 1933/2438  on Training is 60.77914943123061\n",
            "Epoch #1. Accuracy on batch 1934/2438  on Training is 60.77357881136951\n",
            "Epoch #1. Accuracy on batch 1935/2438  on Training is 60.7760847107438\n",
            "Epoch #1. Accuracy on batch 1936/2438  on Training is 60.77536138358286\n",
            "Epoch #1. Accuracy on batch 1937/2438  on Training is 60.77302631578947\n",
            "Epoch #1. Accuracy on batch 1938/2438  on Training is 60.773916967509024\n",
            "Epoch #1. Accuracy on batch 1939/2438  on Training is 60.77158505154639\n",
            "Batch Id 1940/2438 is having training loss of 1.5744829177856445\n",
            "0.6456250548362732\n",
            "Epoch #1. Accuracy on batch 1940/2438  on Training is 60.78857547655848\n",
            "Epoch #1. Accuracy on batch 1941/2438  on Training is 60.792675077239956\n",
            "Epoch #1. Accuracy on batch 1942/2438  on Training is 60.78872876994339\n",
            "Epoch #1. Accuracy on batch 1943/2438  on Training is 60.784786522633745\n",
            "Epoch #1. Accuracy on batch 1944/2438  on Training is 60.78888174807198\n",
            "Epoch #1. Accuracy on batch 1945/2438  on Training is 60.79457862281603\n",
            "Epoch #1. Accuracy on batch 1946/2438  on Training is 60.789034411915765\n",
            "Epoch #1. Accuracy on batch 1947/2438  on Training is 60.79472535934291\n",
            "Epoch #1. Accuracy on batch 1948/2438  on Training is 60.79079014879425\n",
            "Epoch #1. Accuracy on batch 1949/2438  on Training is 60.791666666666664\n",
            "Epoch #1. Accuracy on batch 1950/2438  on Training is 60.80055099948744\n",
            "Epoch #1. Accuracy on batch 1951/2438  on Training is 60.80462346311475\n",
            "Epoch #1. Accuracy on batch 1952/2438  on Training is 60.81029185867896\n",
            "Epoch #1. Accuracy on batch 1953/2438  on Training is 60.81595445240532\n",
            "Epoch #1. Accuracy on batch 1954/2438  on Training is 60.80562659846547\n",
            "Epoch #1. Accuracy on batch 1955/2438  on Training is 60.80010224948875\n",
            "Epoch #1. Accuracy on batch 1956/2438  on Training is 60.80256770567195\n",
            "Epoch #1. Accuracy on batch 1957/2438  on Training is 60.797050561797754\n",
            "Epoch #1. Accuracy on batch 1958/2438  on Training is 60.801110260336905\n",
            "Epoch #1. Accuracy on batch 1959/2438  on Training is 60.80994897959184\n",
            "Batch Id 1960/2438 is having training loss of 1.5728130340576172\n",
            "1.5684809684753418\n",
            "Epoch #1. Accuracy on batch 1960/2438  on Training is 60.80603008669046\n",
            "Epoch #1. Accuracy on batch 1961/2438  on Training is 60.81007900101937\n",
            "Epoch #1. Accuracy on batch 1962/2438  on Training is 60.801388181355065\n",
            "Epoch #1. Accuracy on batch 1963/2438  on Training is 60.81339103869654\n",
            "Epoch #1. Accuracy on batch 1964/2438  on Training is 60.81424936386768\n",
            "Epoch #1. Accuracy on batch 1965/2438  on Training is 60.816696337741604\n",
            "Epoch #1. Accuracy on batch 1966/2438  on Training is 60.82549567869852\n",
            "Epoch #1. Accuracy on batch 1967/2438  on Training is 60.82634654471545\n",
            "Epoch #1. Accuracy on batch 1968/2438  on Training is 60.82243524631793\n",
            "Epoch #1. Accuracy on batch 1969/2438  on Training is 60.82328680203046\n",
            "Epoch #1. Accuracy on batch 1970/2438  on Training is 60.81779553526129\n",
            "Epoch #1. Accuracy on batch 1971/2438  on Training is 60.8186485801217\n",
            "Epoch #1. Accuracy on batch 1972/2438  on Training is 60.82583628991384\n",
            "Epoch #1. Accuracy on batch 1973/2438  on Training is 60.82985055724417\n",
            "Epoch #1. Accuracy on batch 1974/2438  on Training is 60.824367088607595\n",
            "Epoch #1. Accuracy on batch 1975/2438  on Training is 60.822052125506076\n",
            "Epoch #1. Accuracy on batch 1976/2438  on Training is 60.821320182094084\n",
            "Epoch #1. Accuracy on batch 1977/2438  on Training is 60.81584934277048\n",
            "Epoch #1. Accuracy on batch 1978/2438  on Training is 60.81827943405761\n",
            "Epoch #1. Accuracy on batch 1979/2438  on Training is 60.81912878787879\n",
            "Batch Id 1980/2438 is having training loss of 1.571794867515564\n",
            "1.4407395124435425\n",
            "Epoch #1. Accuracy on batch 1980/2438  on Training is 60.82155477031802\n",
            "Epoch #1. Accuracy on batch 1981/2438  on Training is 60.81767154389505\n",
            "Epoch #1. Accuracy on batch 1982/2438  on Training is 60.820095814422594\n",
            "Epoch #1. Accuracy on batch 1983/2438  on Training is 60.816217237903224\n",
            "Epoch #1. Accuracy on batch 1984/2438  on Training is 60.81391687657431\n",
            "Epoch #1. Accuracy on batch 1985/2438  on Training is 60.81161883182276\n",
            "Epoch #1. Accuracy on batch 1986/2438  on Training is 60.81718671363865\n",
            "Epoch #1. Accuracy on batch 1987/2438  on Training is 60.825892857142854\n",
            "Epoch #1. Accuracy on batch 1988/2438  on Training is 60.81887883358472\n",
            "Epoch #1. Accuracy on batch 1989/2438  on Training is 60.81501256281407\n",
            "Epoch #1. Accuracy on batch 1990/2438  on Training is 60.81742842792566\n",
            "Epoch #1. Accuracy on batch 1991/2438  on Training is 60.815135542168676\n",
            "Epoch #1. Accuracy on batch 1992/2438  on Training is 60.81127696939288\n",
            "Epoch #1. Accuracy on batch 1993/2438  on Training is 60.812123871614844\n",
            "Epoch #1. Accuracy on batch 1994/2438  on Training is 60.81610275689223\n",
            "Epoch #1. Accuracy on batch 1995/2438  on Training is 60.81381513026052\n",
            "Epoch #1. Accuracy on batch 1996/2438  on Training is 60.81622433650476\n",
            "Epoch #1. Accuracy on batch 1997/2438  on Training is 60.8201951951952\n",
            "Epoch #1. Accuracy on batch 1998/2438  on Training is 60.8225987993997\n",
            "Epoch #1. Accuracy on batch 1999/2438  on Training is 60.8296875\n",
            "Batch Id 2000/2438 is having training loss of 1.5708541870117188\n",
            "1.3577507734298706\n",
            "Epoch #1. Accuracy on batch 2000/2438  on Training is 60.83208395802099\n",
            "Epoch #1. Accuracy on batch 2001/2438  on Training is 60.83603896103896\n",
            "Epoch #1. Accuracy on batch 2002/2438  on Training is 60.830629056415376\n",
            "Epoch #1. Accuracy on batch 2003/2438  on Training is 60.826783932135726\n",
            "Epoch #1. Accuracy on batch 2004/2438  on Training is 60.82917705735661\n",
            "Epoch #1. Accuracy on batch 2005/2438  on Training is 60.83000997008973\n",
            "Epoch #1. Accuracy on batch 2006/2438  on Training is 60.827727952167415\n",
            "Epoch #1. Accuracy on batch 2007/2438  on Training is 60.82389193227092\n",
            "Epoch #1. Accuracy on batch 2008/2438  on Training is 60.823170731707314\n",
            "Epoch #1. Accuracy on batch 2009/2438  on Training is 60.82089552238806\n",
            "Epoch #1. Accuracy on batch 2010/2438  on Training is 60.82173048234709\n",
            "Epoch #1. Accuracy on batch 2011/2438  on Training is 60.82101143141153\n",
            "Epoch #1. Accuracy on batch 2012/2438  on Training is 60.82029309488326\n",
            "Epoch #1. Accuracy on batch 2013/2438  on Training is 60.819575471698116\n",
            "Epoch #1. Accuracy on batch 2014/2438  on Training is 60.81885856079405\n",
            "Epoch #1. Accuracy on batch 2015/2438  on Training is 60.82744295634921\n",
            "Epoch #1. Accuracy on batch 2016/2438  on Training is 60.83601883986118\n",
            "Epoch #1. Accuracy on batch 2017/2438  on Training is 60.841489098116945\n",
            "Epoch #1. Accuracy on batch 2018/2438  on Training is 60.846953937592865\n",
            "Epoch #1. Accuracy on batch 2019/2438  on Training is 60.850866336633665\n",
            "Batch Id 2020/2438 is having training loss of 1.5696463584899902\n",
            "1.293540358543396\n",
            "Epoch #1. Accuracy on batch 2020/2438  on Training is 60.854774863928746\n",
            "Epoch #1. Accuracy on batch 2021/2438  on Training is 60.85713402571711\n",
            "Epoch #1. Accuracy on batch 2022/2438  on Training is 60.865669797330696\n",
            "Epoch #1. Accuracy on batch 2023/2438  on Training is 60.872653162055336\n",
            "Epoch #1. Accuracy on batch 2024/2438  on Training is 60.87808641975309\n",
            "Epoch #1. Accuracy on batch 2025/2438  on Training is 60.866547384007895\n",
            "Epoch #1. Accuracy on batch 2026/2438  on Training is 60.8766033547114\n",
            "Epoch #1. Accuracy on batch 2027/2438  on Training is 60.882026627218934\n",
            "Epoch #1. Accuracy on batch 2028/2438  on Training is 60.88436421882701\n",
            "Epoch #1. Accuracy on batch 2029/2438  on Training is 60.879002463054185\n",
            "Epoch #1. Accuracy on batch 2030/2438  on Training is 60.88133924175283\n",
            "Epoch #1. Accuracy on batch 2031/2438  on Training is 60.87752214566929\n",
            "Epoch #1. Accuracy on batch 2032/2438  on Training is 60.88600590260698\n",
            "Epoch #1. Accuracy on batch 2033/2438  on Training is 60.88526302851524\n",
            "Epoch #1. Accuracy on batch 2034/2438  on Training is 60.88298525798526\n",
            "Epoch #1. Accuracy on batch 2035/2438  on Training is 60.88070972495088\n",
            "Epoch #1. Accuracy on batch 2036/2438  on Training is 60.8722999509082\n",
            "Epoch #1. Accuracy on batch 2037/2438  on Training is 60.8684985279686\n",
            "Epoch #1. Accuracy on batch 2038/2438  on Training is 60.86163560568907\n",
            "Epoch #1. Accuracy on batch 2039/2438  on Training is 60.8609068627451\n",
            "Batch Id 2040/2438 is having training loss of 1.5684137344360352\n",
            "1.3362092971801758\n",
            "Epoch #1. Accuracy on batch 2040/2438  on Training is 60.86324105830475\n",
            "Epoch #1. Accuracy on batch 2041/2438  on Training is 60.865572967678744\n",
            "Epoch #1. Accuracy on batch 2042/2438  on Training is 60.86484336759667\n",
            "Epoch #1. Accuracy on batch 2043/2438  on Training is 60.85799902152642\n",
            "Epoch #1. Accuracy on batch 2044/2438  on Training is 60.86185819070904\n",
            "Epoch #1. Accuracy on batch 2045/2438  on Training is 60.86571358748778\n",
            "Epoch #1. Accuracy on batch 2046/2438  on Training is 60.86803859306302\n",
            "Epoch #1. Accuracy on batch 2047/2438  on Training is 60.8673095703125\n",
            "Epoch #1. Accuracy on batch 2048/2438  on Training is 60.87573206442167\n",
            "Epoch #1. Accuracy on batch 2049/2438  on Training is 60.8719512195122\n",
            "Epoch #1. Accuracy on batch 2050/2438  on Training is 60.87731594344223\n",
            "Epoch #1. Accuracy on batch 2051/2438  on Training is 60.88572124756335\n",
            "Epoch #1. Accuracy on batch 2052/2438  on Training is 60.881941061860694\n",
            "Epoch #1. Accuracy on batch 2053/2438  on Training is 60.87968597857839\n",
            "Epoch #1. Accuracy on batch 2054/2438  on Training is 60.88047445255474\n",
            "Epoch #1. Accuracy on batch 2055/2438  on Training is 60.88430204280156\n",
            "Epoch #1. Accuracy on batch 2056/2438  on Training is 60.877491492464756\n",
            "Epoch #1. Accuracy on batch 2057/2438  on Training is 60.875242954324584\n",
            "Epoch #1. Accuracy on batch 2058/2438  on Training is 60.87754978144731\n",
            "Epoch #1. Accuracy on batch 2059/2438  on Training is 60.87985436893204\n",
            "Batch Id 2060/2438 is having training loss of 1.566985845565796\n",
            "1.530853271484375\n",
            "Epoch #1. Accuracy on batch 2060/2438  on Training is 60.876091703056765\n",
            "Epoch #1. Accuracy on batch 2061/2438  on Training is 60.87839476236663\n",
            "Epoch #1. Accuracy on batch 2062/2438  on Training is 60.879180804653416\n",
            "Epoch #1. Accuracy on batch 2063/2438  on Training is 60.87996608527132\n",
            "Epoch #1. Accuracy on batch 2064/2438  on Training is 60.880750605326874\n",
            "Epoch #1. Accuracy on batch 2065/2438  on Training is 60.88455953533398\n",
            "Epoch #1. Accuracy on batch 2066/2438  on Training is 60.88685292694726\n",
            "Epoch #1. Accuracy on batch 2067/2438  on Training is 60.88914410058027\n",
            "Epoch #1. Accuracy on batch 2068/2438  on Training is 60.89143305944901\n",
            "Epoch #1. Accuracy on batch 2069/2438  on Training is 60.88768115942029\n",
            "Epoch #1. Accuracy on batch 2070/2438  on Training is 60.886950748430706\n",
            "Epoch #1. Accuracy on batch 2071/2438  on Training is 60.89225386100386\n",
            "Epoch #1. Accuracy on batch 2072/2438  on Training is 60.89152194886638\n",
            "Epoch #1. Accuracy on batch 2073/2438  on Training is 60.8922974927676\n",
            "Epoch #1. Accuracy on batch 2074/2438  on Training is 60.894578313253014\n",
            "Epoch #1. Accuracy on batch 2075/2438  on Training is 60.896856936416185\n",
            "Epoch #1. Accuracy on batch 2076/2438  on Training is 60.89010592200289\n",
            "Epoch #1. Accuracy on batch 2077/2438  on Training is 60.881857555341675\n",
            "Epoch #1. Accuracy on batch 2078/2438  on Training is 60.89315776815777\n",
            "Epoch #1. Accuracy on batch 2079/2438  on Training is 60.89693509615385\n",
            "Batch Id 2080/2438 is having training loss of 1.5664258003234863\n",
            "1.5000522136688232\n",
            "Epoch #1. Accuracy on batch 2080/2438  on Training is 60.89620374819798\n",
            "Epoch #1. Accuracy on batch 2081/2438  on Training is 60.892471181556196\n",
            "Epoch #1. Accuracy on batch 2082/2438  on Training is 60.891742678828614\n",
            "Epoch #1. Accuracy on batch 2083/2438  on Training is 60.891014875239925\n",
            "Epoch #1. Accuracy on batch 2084/2438  on Training is 60.885791366906474\n",
            "Epoch #1. Accuracy on batch 2085/2438  on Training is 60.88057286673058\n",
            "Epoch #1. Accuracy on batch 2086/2438  on Training is 60.87985146142789\n",
            "Epoch #1. Accuracy on batch 2087/2438  on Training is 60.883620689655174\n",
            "Epoch #1. Accuracy on batch 2088/2438  on Training is 60.88439444710388\n",
            "Epoch #1. Accuracy on batch 2089/2438  on Training is 60.88666267942584\n",
            "Epoch #1. Accuracy on batch 2090/2438  on Training is 60.88743424198948\n",
            "Epoch #1. Accuracy on batch 2091/2438  on Training is 60.88820506692161\n",
            "Epoch #1. Accuracy on batch 2092/2438  on Training is 60.893454371715244\n",
            "Epoch #1. Accuracy on batch 2093/2438  on Training is 60.89123686723973\n",
            "Epoch #1. Accuracy on batch 2094/2438  on Training is 60.89051312649165\n",
            "Epoch #1. Accuracy on batch 2095/2438  on Training is 60.892771946564885\n",
            "Epoch #1. Accuracy on batch 2096/2438  on Training is 60.89949928469242\n",
            "Epoch #1. Accuracy on batch 2097/2438  on Training is 60.90175166825548\n",
            "Epoch #1. Accuracy on batch 2098/2438  on Training is 60.90251310147689\n",
            "Epoch #1. Accuracy on batch 2099/2438  on Training is 60.907738095238095\n",
            "Batch Id 2100/2438 is having training loss of 1.5661520957946777\n",
            "1.5268583297729492\n",
            "Epoch #1. Accuracy on batch 2100/2438  on Training is 60.908495954307476\n",
            "Epoch #1. Accuracy on batch 2101/2438  on Training is 60.907766412940056\n",
            "Epoch #1. Accuracy on batch 2102/2438  on Training is 60.90555159296243\n",
            "Epoch #1. Accuracy on batch 2103/2438  on Training is 60.915221007604565\n",
            "Epoch #1. Accuracy on batch 2104/2438  on Training is 60.923396674584325\n",
            "Epoch #1. Accuracy on batch 2105/2438  on Training is 60.93008072174739\n",
            "Epoch #1. Accuracy on batch 2106/2438  on Training is 60.9234100616991\n",
            "Epoch #1. Accuracy on batch 2107/2438  on Training is 60.92267552182163\n",
            "Epoch #1. Accuracy on batch 2108/2438  on Training is 60.92490516832622\n",
            "Epoch #1. Accuracy on batch 2109/2438  on Training is 60.92565165876777\n",
            "Epoch #1. Accuracy on batch 2110/2438  on Training is 60.930838465182376\n",
            "Epoch #1. Accuracy on batch 2111/2438  on Training is 60.92418323863637\n",
            "Epoch #1. Accuracy on batch 2112/2438  on Training is 60.930844770468525\n",
            "Epoch #1. Accuracy on batch 2113/2438  on Training is 60.928630558183535\n",
            "Epoch #1. Accuracy on batch 2114/2438  on Training is 60.926418439716315\n",
            "Epoch #1. Accuracy on batch 2115/2438  on Training is 60.928638941398866\n",
            "Epoch #1. Accuracy on batch 2116/2438  on Training is 60.929381199811054\n",
            "Epoch #1. Accuracy on batch 2117/2438  on Training is 60.936024551463646\n",
            "Epoch #1. Accuracy on batch 2118/2438  on Training is 60.93971212836244\n",
            "Epoch #1. Accuracy on batch 2119/2438  on Training is 60.938974056603776\n",
            "Batch Id 2120/2438 is having training loss of 1.5647886991500854\n",
            "1.54855477809906\n",
            "Epoch #1. Accuracy on batch 2120/2438  on Training is 60.93676331918906\n",
            "Epoch #1. Accuracy on batch 2121/2438  on Training is 60.94044533459001\n",
            "Epoch #1. Accuracy on batch 2122/2438  on Training is 60.94559585492228\n",
            "Epoch #1. Accuracy on batch 2123/2438  on Training is 60.94632768361582\n",
            "Epoch #1. Accuracy on batch 2124/2438  on Training is 60.9485294117647\n",
            "Epoch #1. Accuracy on batch 2125/2438  on Training is 60.95072906867357\n",
            "Epoch #1. Accuracy on batch 2126/2438  on Training is 60.951457451810064\n",
            "Epoch #1. Accuracy on batch 2127/2438  on Training is 60.958059210526315\n",
            "Epoch #1. Accuracy on batch 2128/2438  on Training is 60.9631869422264\n",
            "Epoch #1. Accuracy on batch 2129/2438  on Training is 60.963908450704224\n",
            "Epoch #1. Accuracy on batch 2130/2438  on Training is 60.96462928202722\n",
            "Epoch #1. Accuracy on batch 2131/2438  on Training is 60.97121247654784\n",
            "Epoch #1. Accuracy on batch 2132/2438  on Training is 60.9719292076887\n",
            "Epoch #1. Accuracy on batch 2133/2438  on Training is 60.97410965323336\n",
            "Epoch #1. Accuracy on batch 2134/2438  on Training is 60.97336065573771\n",
            "Epoch #1. Accuracy on batch 2135/2438  on Training is 60.974075374531836\n",
            "Epoch #1. Accuracy on batch 2136/2438  on Training is 60.96894010294806\n",
            "Epoch #1. Accuracy on batch 2137/2438  on Training is 60.97257951356408\n",
            "Epoch #1. Accuracy on batch 2138/2438  on Training is 60.97329359513792\n",
            "Epoch #1. Accuracy on batch 2139/2438  on Training is 60.97984813084112\n",
            "Batch Id 2140/2438 is having training loss of 1.562875509262085\n",
            "1.196495771408081\n",
            "Epoch #1. Accuracy on batch 2140/2438  on Training is 60.983477347034096\n",
            "Epoch #1. Accuracy on batch 2141/2438  on Training is 60.9812675070028\n",
            "Epoch #1. Accuracy on batch 2142/2438  on Training is 60.98489267382175\n",
            "Epoch #1. Accuracy on batch 2143/2438  on Training is 60.98851445895522\n",
            "Epoch #1. Accuracy on batch 2144/2438  on Training is 60.984848484848484\n",
            "Epoch #1. Accuracy on batch 2145/2438  on Training is 60.97827353215284\n",
            "Epoch #1. Accuracy on batch 2146/2438  on Training is 60.98480437820214\n",
            "Epoch #1. Accuracy on batch 2147/2438  on Training is 60.98696461824954\n",
            "Epoch #1. Accuracy on batch 2148/2438  on Training is 60.9891228478362\n",
            "Epoch #1. Accuracy on batch 2149/2438  on Training is 60.98837209302326\n",
            "Epoch #1. Accuracy on batch 2150/2438  on Training is 60.99052766155277\n",
            "Epoch #1. Accuracy on batch 2151/2438  on Training is 60.999941914498145\n",
            "Epoch #1. Accuracy on batch 2152/2438  on Training is 60.99338132837901\n",
            "Epoch #1. Accuracy on batch 2153/2438  on Training is 60.992629990714946\n",
            "Epoch #1. Accuracy on batch 2154/2438  on Training is 60.99332946635731\n",
            "Epoch #1. Accuracy on batch 2155/2438  on Training is 60.99112940630798\n",
            "Epoch #1. Accuracy on batch 2156/2438  on Training is 60.994726471951786\n",
            "Epoch #1. Accuracy on batch 2157/2438  on Training is 60.99976830398517\n",
            "Epoch #1. Accuracy on batch 2158/2438  on Training is 61.003358036127835\n",
            "Epoch #1. Accuracy on batch 2159/2438  on Training is 61.002604166666664\n",
            "Batch Id 2160/2438 is having training loss of 1.5620708465576172\n",
            "1.1968744993209839\n",
            "Epoch #1. Accuracy on batch 2160/2438  on Training is 61.00474317445627\n",
            "Epoch #1. Accuracy on batch 2161/2438  on Training is 61.003989361702125\n",
            "Epoch #1. Accuracy on batch 2162/2438  on Training is 61.01190476190476\n",
            "Epoch #1. Accuracy on batch 2163/2438  on Training is 61.01836876155268\n",
            "Epoch #1. Accuracy on batch 2164/2438  on Training is 61.02049653579677\n",
            "Epoch #1. Accuracy on batch 2165/2438  on Training is 61.018294090489384\n",
            "Epoch #1. Accuracy on batch 2166/2438  on Training is 61.011767420396865\n",
            "Epoch #1. Accuracy on batch 2167/2438  on Training is 61.01389529520295\n",
            "Epoch #1. Accuracy on batch 2168/2438  on Training is 61.01746196403873\n",
            "Epoch #1. Accuracy on batch 2169/2438  on Training is 61.013824884792626\n",
            "Epoch #1. Accuracy on batch 2170/2438  on Training is 61.01450944265316\n",
            "Epoch #1. Accuracy on batch 2171/2438  on Training is 61.012315837937386\n",
            "Epoch #1. Accuracy on batch 2172/2438  on Training is 61.01300046019328\n",
            "Epoch #1. Accuracy on batch 2173/2438  on Training is 61.010809567617294\n",
            "Epoch #1. Accuracy on batch 2174/2438  on Training is 61.01005747126437\n",
            "Epoch #1. Accuracy on batch 2175/2438  on Training is 61.01361443014706\n",
            "Epoch #1. Accuracy on batch 2176/2438  on Training is 61.024345429490126\n",
            "Epoch #1. Accuracy on batch 2177/2438  on Training is 61.02502295684114\n",
            "Epoch #1. Accuracy on batch 2178/2438  on Training is 61.02856815052777\n",
            "Epoch #1. Accuracy on batch 2179/2438  on Training is 61.034977064220186\n",
            "Batch Id 2180/2438 is having training loss of 1.5606577396392822\n",
            "1.3700921535491943\n",
            "Epoch #1. Accuracy on batch 2180/2438  on Training is 61.03278312700596\n",
            "Epoch #1. Accuracy on batch 2181/2438  on Training is 61.0291590284143\n",
            "Epoch #1. Accuracy on batch 2182/2438  on Training is 61.03126431516262\n",
            "Epoch #1. Accuracy on batch 2183/2438  on Training is 61.03479853479853\n",
            "Epoch #1. Accuracy on batch 2184/2438  on Training is 61.036899313501145\n",
            "Epoch #1. Accuracy on batch 2185/2438  on Training is 61.030420860018296\n",
            "Epoch #1. Accuracy on batch 2186/2438  on Training is 61.02251943301326\n",
            "Epoch #1. Accuracy on batch 2187/2438  on Training is 61.02462294332724\n",
            "Epoch #1. Accuracy on batch 2188/2438  on Training is 61.02815212425765\n",
            "Epoch #1. Accuracy on batch 2189/2438  on Training is 61.02454337899543\n",
            "Epoch #1. Accuracy on batch 2190/2438  on Training is 61.02664308534916\n",
            "Epoch #1. Accuracy on batch 2191/2438  on Training is 61.034443430656935\n",
            "Epoch #1. Accuracy on batch 2192/2438  on Training is 61.03226174190606\n",
            "Epoch #1. Accuracy on batch 2193/2438  on Training is 61.03577939835916\n",
            "Epoch #1. Accuracy on batch 2194/2438  on Training is 61.04071753986332\n",
            "Epoch #1. Accuracy on batch 2195/2438  on Training is 61.044228142076506\n",
            "Epoch #1. Accuracy on batch 2196/2438  on Training is 61.044890760127444\n",
            "Epoch #1. Accuracy on batch 2197/2438  on Training is 61.04697452229299\n",
            "Epoch #1. Accuracy on batch 2198/2438  on Training is 61.0518985902683\n",
            "Epoch #1. Accuracy on batch 2199/2438  on Training is 61.05681818181818\n",
            "Batch Id 2200/2438 is having training loss of 1.5589505434036255\n",
            "1.3496631383895874\n",
            "Epoch #1. Accuracy on batch 2200/2438  on Training is 61.05747387551113\n",
            "Epoch #1. Accuracy on batch 2201/2438  on Training is 61.0552906448683\n",
            "Epoch #1. Accuracy on batch 2202/2438  on Training is 61.05594643667726\n",
            "Epoch #1. Accuracy on batch 2203/2438  on Training is 61.059437386569876\n",
            "Epoch #1. Accuracy on batch 2204/2438  on Training is 61.057256235827666\n",
            "Epoch #1. Accuracy on batch 2205/2438  on Training is 61.0564936536718\n",
            "Epoch #1. Accuracy on batch 2206/2438  on Training is 61.057147711826005\n",
            "Epoch #1. Accuracy on batch 2207/2438  on Training is 61.05638586956522\n",
            "Epoch #1. Accuracy on batch 2208/2438  on Training is 61.057039384336804\n",
            "Epoch #1. Accuracy on batch 2209/2438  on Training is 61.06334841628959\n",
            "Epoch #1. Accuracy on batch 2210/2438  on Training is 61.06258480325644\n",
            "Epoch #1. Accuracy on batch 2211/2438  on Training is 61.05758363471971\n",
            "Epoch #1. Accuracy on batch 2212/2438  on Training is 61.05964753727971\n",
            "Epoch #1. Accuracy on batch 2213/2438  on Training is 61.0645325203252\n",
            "Epoch #1. Accuracy on batch 2214/2438  on Training is 61.068002257336346\n",
            "Epoch #1. Accuracy on batch 2215/2438  on Training is 61.074289259927795\n",
            "Epoch #1. Accuracy on batch 2216/2438  on Training is 61.07493234100135\n",
            "Epoch #1. Accuracy on batch 2217/2438  on Training is 61.06853020739405\n",
            "Epoch #1. Accuracy on batch 2218/2438  on Training is 61.06917530419108\n",
            "Epoch #1. Accuracy on batch 2219/2438  on Training is 61.076858108108105\n",
            "Batch Id 2220/2438 is having training loss of 1.5576748847961426\n",
            "1.1693211793899536\n",
            "Epoch #1. Accuracy on batch 2220/2438  on Training is 61.07749887438091\n",
            "Epoch #1. Accuracy on batch 2221/2438  on Training is 61.07532628262826\n",
            "Epoch #1. Accuracy on batch 2222/2438  on Training is 61.07174988753936\n",
            "Epoch #1. Accuracy on batch 2223/2438  on Training is 61.070986960431654\n",
            "Epoch #1. Accuracy on batch 2224/2438  on Training is 61.06741573033708\n",
            "Epoch #1. Accuracy on batch 2225/2438  on Training is 61.073674752920034\n",
            "Epoch #1. Accuracy on batch 2226/2438  on Training is 61.07291198922317\n",
            "Epoch #1. Accuracy on batch 2227/2438  on Training is 61.07635771992819\n",
            "Epoch #1. Accuracy on batch 2228/2438  on Training is 61.0699865410498\n",
            "Epoch #1. Accuracy on batch 2229/2438  on Training is 61.072029147982065\n",
            "Epoch #1. Accuracy on batch 2230/2438  on Training is 61.07827207530256\n",
            "Epoch #1. Accuracy on batch 2231/2438  on Training is 61.074708781362006\n",
            "Epoch #1. Accuracy on batch 2232/2438  on Training is 61.07674652933274\n",
            "Epoch #1. Accuracy on batch 2233/2438  on Training is 61.073187108325875\n",
            "Epoch #1. Accuracy on batch 2234/2438  on Training is 61.07522371364653\n",
            "Epoch #1. Accuracy on batch 2235/2438  on Training is 61.07166815742397\n",
            "Epoch #1. Accuracy on batch 2236/2438  on Training is 61.073703620920874\n",
            "Epoch #1. Accuracy on batch 2237/2438  on Training is 61.06875558534406\n",
            "Epoch #1. Accuracy on batch 2238/2438  on Training is 61.065207682000896\n",
            "Epoch #1. Accuracy on batch 2239/2438  on Training is 61.064453125\n",
            "Batch Id 2240/2438 is having training loss of 1.5569034814834595\n",
            "1.1818400621414185\n",
            "Epoch #1. Accuracy on batch 2240/2438  on Training is 61.06648817492191\n",
            "Epoch #1. Accuracy on batch 2241/2438  on Training is 61.0671275646744\n",
            "Epoch #1. Accuracy on batch 2242/2438  on Training is 61.06637316094516\n",
            "Epoch #1. Accuracy on batch 2243/2438  on Training is 61.065619429590015\n",
            "Epoch #1. Accuracy on batch 2244/2438  on Training is 61.06208240534521\n",
            "Epoch #1. Accuracy on batch 2245/2438  on Training is 61.064113980409616\n",
            "Epoch #1. Accuracy on batch 2246/2438  on Training is 61.061971517578996\n",
            "Epoch #1. Accuracy on batch 2247/2438  on Training is 61.058440836298935\n",
            "Epoch #1. Accuracy on batch 2248/2438  on Training is 61.04935526900845\n",
            "Epoch #1. Accuracy on batch 2249/2438  on Training is 61.048611111111114\n",
            "Epoch #1. Accuracy on batch 2250/2438  on Training is 61.0478676143936\n",
            "Epoch #1. Accuracy on batch 2251/2438  on Training is 61.05822602131439\n",
            "Epoch #1. Accuracy on batch 2252/2438  on Training is 61.05470483799379\n",
            "Epoch #1. Accuracy on batch 2253/2438  on Training is 61.058118899733806\n",
            "Epoch #1. Accuracy on batch 2254/2438  on Training is 61.057372505543235\n",
            "Epoch #1. Accuracy on batch 2255/2438  on Training is 61.05247118794326\n",
            "Epoch #1. Accuracy on batch 2256/2438  on Training is 61.05449712007089\n",
            "Epoch #1. Accuracy on batch 2257/2438  on Training is 61.05375332152347\n",
            "Epoch #1. Accuracy on batch 2258/2438  on Training is 61.0571602478973\n",
            "Epoch #1. Accuracy on batch 2259/2438  on Training is 61.05779867256637\n",
            "Batch Id 2260/2438 is having training loss of 1.5559026002883911\n",
            "1.0782663822174072\n",
            "Epoch #1. Accuracy on batch 2260/2438  on Training is 61.063965059708096\n",
            "Epoch #1. Accuracy on batch 2261/2438  on Training is 61.06045534924845\n",
            "Epoch #1. Accuracy on batch 2262/2438  on Training is 61.058329650905875\n",
            "Epoch #1. Accuracy on batch 2263/2438  on Training is 61.05620583038869\n",
            "Epoch #1. Accuracy on batch 2264/2438  on Training is 61.05822295805739\n",
            "Epoch #1. Accuracy on batch 2265/2438  on Training is 61.054721977052075\n",
            "Epoch #1. Accuracy on batch 2266/2438  on Training is 61.06087340097044\n",
            "Epoch #1. Accuracy on batch 2267/2438  on Training is 61.05875220458554\n",
            "Epoch #1. Accuracy on batch 2268/2438  on Training is 61.059387395328336\n",
            "Epoch #1. Accuracy on batch 2269/2438  on Training is 61.05726872246696\n",
            "Epoch #1. Accuracy on batch 2270/2438  on Training is 61.062032144429764\n",
            "Epoch #1. Accuracy on batch 2271/2438  on Training is 61.064040492957744\n",
            "Epoch #1. Accuracy on batch 2272/2438  on Training is 61.06467223933128\n",
            "Epoch #1. Accuracy on batch 2273/2438  on Training is 61.0639291996482\n",
            "Epoch #1. Accuracy on batch 2274/2438  on Training is 61.06456043956044\n",
            "Epoch #1. Accuracy on batch 2275/2438  on Training is 61.06519112478032\n",
            "Epoch #1. Accuracy on batch 2276/2438  on Training is 61.07131093544137\n",
            "Epoch #1. Accuracy on batch 2277/2438  on Training is 61.07056628621598\n",
            "Epoch #1. Accuracy on batch 2278/2438  on Training is 61.07256472136902\n",
            "Epoch #1. Accuracy on batch 2279/2438  on Training is 61.07593201754386\n",
            "Batch Id 2280/2438 is having training loss of 1.5554033517837524\n",
            "1.644513487815857\n",
            "Epoch #1. Accuracy on batch 2280/2438  on Training is 61.073816308636566\n",
            "Epoch #1. Accuracy on batch 2281/2438  on Training is 61.07581069237511\n",
            "Epoch #1. Accuracy on batch 2282/2438  on Training is 61.07780332895313\n",
            "Epoch #1. Accuracy on batch 2283/2438  on Training is 61.070216725043785\n",
            "Epoch #1. Accuracy on batch 2284/2438  on Training is 61.066739606126916\n",
            "Epoch #1. Accuracy on batch 2285/2438  on Training is 61.0673665791776\n",
            "Epoch #1. Accuracy on batch 2286/2438  on Training is 61.06935942282466\n",
            "Epoch #1. Accuracy on batch 2287/2438  on Training is 61.07271634615385\n",
            "Epoch #1. Accuracy on batch 2288/2438  on Training is 61.07880078636959\n",
            "Epoch #1. Accuracy on batch 2289/2438  on Training is 61.07669213973799\n",
            "Epoch #1. Accuracy on batch 2290/2438  on Training is 61.075949367088604\n",
            "Epoch #1. Accuracy on batch 2291/2438  on Training is 61.07929755671902\n",
            "Epoch #1. Accuracy on batch 2292/2438  on Training is 61.0840056694287\n",
            "Epoch #1. Accuracy on batch 2293/2438  on Training is 61.08189843068875\n",
            "Epoch #1. Accuracy on batch 2294/2438  on Training is 61.08660130718954\n",
            "Epoch #1. Accuracy on batch 2295/2438  on Training is 61.08313371080139\n",
            "Epoch #1. Accuracy on batch 2296/2438  on Training is 61.08511101436657\n",
            "Epoch #1. Accuracy on batch 2297/2438  on Training is 61.08436684073107\n",
            "Epoch #1. Accuracy on batch 2298/2438  on Training is 61.083623314484555\n",
            "Epoch #1. Accuracy on batch 2299/2438  on Training is 61.088315217391305\n",
            "Batch Id 2300/2438 is having training loss of 1.5546901226043701\n",
            "1.1956202983856201\n",
            "Epoch #1. Accuracy on batch 2300/2438  on Training is 61.09300304215559\n",
            "Epoch #1. Accuracy on batch 2301/2438  on Training is 61.09497176368375\n",
            "Epoch #1. Accuracy on batch 2302/2438  on Training is 61.09286799826314\n",
            "Epoch #1. Accuracy on batch 2303/2438  on Training is 61.092122395833336\n",
            "Epoch #1. Accuracy on batch 2304/2438  on Training is 61.088665943600866\n",
            "Epoch #1. Accuracy on batch 2305/2438  on Training is 61.09063313096271\n",
            "Epoch #1. Accuracy on batch 2306/2438  on Training is 61.09259861291721\n",
            "Epoch #1. Accuracy on batch 2307/2438  on Training is 61.090500433275565\n",
            "Epoch #1. Accuracy on batch 2308/2438  on Training is 61.096524469467305\n",
            "Epoch #1. Accuracy on batch 2309/2438  on Training is 61.09036796536797\n",
            "Epoch #1. Accuracy on batch 2310/2438  on Training is 61.08962570315881\n",
            "Epoch #1. Accuracy on batch 2311/2438  on Training is 61.09564230103806\n",
            "Epoch #1. Accuracy on batch 2312/2438  on Training is 61.09354734111543\n",
            "Epoch #1. Accuracy on batch 2313/2438  on Training is 61.0941551426102\n",
            "Epoch #1. Accuracy on batch 2314/2438  on Training is 61.09341252699784\n",
            "Epoch #1. Accuracy on batch 2315/2438  on Training is 61.08862262521589\n",
            "Epoch #1. Accuracy on batch 2316/2438  on Training is 61.08923176521364\n",
            "Epoch #1. Accuracy on batch 2317/2438  on Training is 61.08984037963762\n",
            "Epoch #1. Accuracy on batch 2318/2438  on Training is 61.09044846916775\n",
            "Epoch #1. Accuracy on batch 2319/2438  on Training is 61.088362068965516\n",
            "Batch Id 2320/2438 is having training loss of 1.5543105602264404\n",
            "1.4140386581420898\n",
            "Epoch #1. Accuracy on batch 2320/2438  on Training is 61.088970271434725\n",
            "Epoch #1. Accuracy on batch 2321/2438  on Training is 61.09092377260982\n",
            "Epoch #1. Accuracy on batch 2322/2438  on Training is 61.091530348687044\n",
            "Epoch #1. Accuracy on batch 2323/2438  on Training is 61.094825731497416\n",
            "Epoch #1. Accuracy on batch 2324/2438  on Training is 61.096774193548384\n",
            "Epoch #1. Accuracy on batch 2325/2438  on Training is 61.09469045571797\n",
            "Epoch #1. Accuracy on batch 2326/2438  on Training is 61.10335195530726\n",
            "Epoch #1. Accuracy on batch 2327/2438  on Training is 61.09992482817869\n",
            "Epoch #1. Accuracy on batch 2328/2438  on Training is 61.09784242164019\n",
            "Epoch #1. Accuracy on batch 2329/2438  on Training is 61.09844420600859\n",
            "Epoch #1. Accuracy on batch 2330/2438  on Training is 61.09234234234234\n",
            "Epoch #1. Accuracy on batch 2331/2438  on Training is 61.09428602058319\n",
            "Epoch #1. Accuracy on batch 2332/2438  on Training is 61.09087012430347\n",
            "Epoch #1. Accuracy on batch 2333/2438  on Training is 61.094151670951156\n",
            "Epoch #1. Accuracy on batch 2334/2438  on Training is 61.09743040685225\n",
            "Epoch #1. Accuracy on batch 2335/2438  on Training is 61.10338184931507\n",
            "Epoch #1. Accuracy on batch 2336/2438  on Training is 61.09996790757381\n",
            "Epoch #1. Accuracy on batch 2337/2438  on Training is 61.101903336184776\n",
            "Epoch #1. Accuracy on batch 2338/2438  on Training is 61.10383710987602\n",
            "Epoch #1. Accuracy on batch 2339/2438  on Training is 61.10309829059829\n",
            "Batch Id 2340/2438 is having training loss of 1.5530849695205688\n",
            "1.7512133121490479\n",
            "Epoch #1. Accuracy on batch 2340/2438  on Training is 61.102360102520294\n",
            "Epoch #1. Accuracy on batch 2341/2438  on Training is 61.10429120409906\n",
            "Epoch #1. Accuracy on batch 2342/2438  on Training is 61.10355313700384\n",
            "Epoch #1. Accuracy on batch 2343/2438  on Training is 61.109481655290104\n",
            "Epoch #1. Accuracy on batch 2344/2438  on Training is 61.11273987206823\n",
            "Epoch #1. Accuracy on batch 2345/2438  on Training is 61.110667092924125\n",
            "Epoch #1. Accuracy on batch 2346/2438  on Training is 61.10992756710694\n",
            "Epoch #1. Accuracy on batch 2347/2438  on Training is 61.106526831345825\n",
            "Epoch #1. Accuracy on batch 2348/2438  on Training is 61.109780757769265\n",
            "Epoch #1. Accuracy on batch 2349/2438  on Training is 61.107712765957444\n",
            "Epoch #1. Accuracy on batch 2350/2438  on Training is 61.10963419821353\n",
            "Epoch #1. Accuracy on batch 2351/2438  on Training is 61.10889668367347\n",
            "Epoch #1. Accuracy on batch 2352/2438  on Training is 61.10417552061198\n",
            "Epoch #1. Accuracy on batch 2353/2438  on Training is 61.10742353440951\n",
            "Epoch #1. Accuracy on batch 2354/2438  on Training is 61.1119957537155\n",
            "Epoch #1. Accuracy on batch 2355/2438  on Training is 61.111258488964346\n",
            "Epoch #1. Accuracy on batch 2356/2438  on Training is 61.107870173949934\n",
            "Epoch #1. Accuracy on batch 2357/2438  on Training is 61.11243638676845\n",
            "Epoch #1. Accuracy on batch 2358/2438  on Training is 61.12362229758372\n",
            "Epoch #1. Accuracy on batch 2359/2438  on Training is 61.121557203389834\n",
            "Batch Id 2360/2438 is having training loss of 1.5523794889450073\n",
            "2.180154800415039\n",
            "Epoch #1. Accuracy on batch 2360/2438  on Training is 61.11552308343922\n",
            "Epoch #1. Accuracy on batch 2361/2438  on Training is 61.1200783234547\n",
            "Epoch #1. Accuracy on batch 2362/2438  on Training is 61.12198476512907\n",
            "Epoch #1. Accuracy on batch 2363/2438  on Training is 61.11728003384095\n",
            "Epoch #1. Accuracy on batch 2364/2438  on Training is 61.10597251585624\n",
            "Epoch #1. Accuracy on batch 2365/2438  on Training is 61.10524091293322\n",
            "Epoch #1. Accuracy on batch 2366/2438  on Training is 61.10318969159273\n",
            "Epoch #1. Accuracy on batch 2367/2438  on Training is 61.109058277027025\n",
            "Epoch #1. Accuracy on batch 2368/2438  on Training is 61.10832629801604\n",
            "Epoch #1. Accuracy on batch 2369/2438  on Training is 61.10363924050633\n",
            "Epoch #1. Accuracy on batch 2370/2438  on Training is 61.10159215520877\n",
            "Epoch #1. Accuracy on batch 2371/2438  on Training is 61.10481661045531\n",
            "Epoch #1. Accuracy on batch 2372/2438  on Training is 61.10145385587863\n",
            "Epoch #1. Accuracy on batch 2373/2438  on Training is 61.10204296545914\n",
            "Epoch #1. Accuracy on batch 2374/2438  on Training is 61.10263157894737\n",
            "Epoch #1. Accuracy on batch 2375/2438  on Training is 61.103219696969695\n",
            "Epoch #1. Accuracy on batch 2376/2438  on Training is 61.10117795540597\n",
            "Epoch #1. Accuracy on batch 2377/2438  on Training is 61.1030803195963\n",
            "Epoch #1. Accuracy on batch 2378/2438  on Training is 61.09578604455653\n",
            "Epoch #1. Accuracy on batch 2379/2438  on Training is 61.101628151260506\n",
            "Batch Id 2380/2438 is having training loss of 1.551941156387329\n",
            "1.3293428421020508\n",
            "Epoch #1. Accuracy on batch 2380/2438  on Training is 61.10221545569089\n",
            "Epoch #1. Accuracy on batch 2381/2438  on Training is 61.10804995801847\n",
            "Epoch #1. Accuracy on batch 2382/2438  on Training is 61.10601133025598\n",
            "Epoch #1. Accuracy on batch 2383/2438  on Training is 61.10659605704698\n",
            "Epoch #1. Accuracy on batch 2384/2438  on Training is 61.111111111111114\n",
            "Epoch #1. Accuracy on batch 2385/2438  on Training is 61.11693210393965\n",
            "Epoch #1. Accuracy on batch 2386/2438  on Training is 61.1279849183075\n",
            "Epoch #1. Accuracy on batch 2387/2438  on Training is 61.1285594639866\n",
            "Epoch #1. Accuracy on batch 2388/2438  on Training is 61.126517371285054\n",
            "Epoch #1. Accuracy on batch 2389/2438  on Training is 61.12709205020921\n",
            "Epoch #1. Accuracy on batch 2390/2438  on Training is 61.12897323295692\n",
            "Epoch #1. Accuracy on batch 2391/2438  on Training is 61.1269335284281\n",
            "Epoch #1. Accuracy on batch 2392/2438  on Training is 61.13142498955286\n",
            "Epoch #1. Accuracy on batch 2393/2438  on Training is 61.13069131161237\n",
            "Epoch #1. Accuracy on batch 2394/2438  on Training is 61.1312630480167\n",
            "Epoch #1. Accuracy on batch 2395/2438  on Training is 61.13444282136895\n",
            "Epoch #1. Accuracy on batch 2396/2438  on Training is 61.140227367542764\n",
            "Epoch #1. Accuracy on batch 2397/2438  on Training is 61.13949124270225\n",
            "Epoch #1. Accuracy on batch 2398/2438  on Training is 61.145268862025844\n",
            "Epoch #1. Accuracy on batch 2399/2438  on Training is 61.1484375\n",
            "Batch Id 2400/2438 is having training loss of 1.550086498260498\n",
            "1.5019428730010986\n",
            "Epoch #1. Accuracy on batch 2400/2438  on Training is 61.147698875468556\n",
            "Epoch #1. Accuracy on batch 2401/2438  on Training is 61.149562864279766\n",
            "Epoch #1. Accuracy on batch 2402/2438  on Training is 61.14882438618394\n",
            "Epoch #1. Accuracy on batch 2403/2438  on Training is 61.149386439267886\n",
            "Epoch #1. Accuracy on batch 2404/2438  on Training is 61.156444906444904\n",
            "Epoch #1. Accuracy on batch 2405/2438  on Training is 61.1531068162926\n",
            "Epoch #1. Accuracy on batch 2406/2438  on Training is 61.1523680930619\n",
            "Epoch #1. Accuracy on batch 2407/2438  on Training is 61.155523255813954\n",
            "Epoch #1. Accuracy on batch 2408/2438  on Training is 61.14959526774595\n",
            "Epoch #1. Accuracy on batch 2409/2438  on Training is 61.1527489626556\n",
            "Epoch #1. Accuracy on batch 2410/2438  on Training is 61.158492326835336\n",
            "Epoch #1. Accuracy on batch 2411/2438  on Training is 61.16293532338308\n",
            "Epoch #1. Accuracy on batch 2412/2438  on Training is 61.163489432242024\n",
            "Epoch #1. Accuracy on batch 2413/2438  on Training is 61.16274855012428\n",
            "Epoch #1. Accuracy on batch 2414/2438  on Training is 61.16459627329193\n",
            "Epoch #1. Accuracy on batch 2415/2438  on Training is 61.16902938741722\n",
            "Epoch #1. Accuracy on batch 2416/2438  on Training is 61.164408357467934\n",
            "Epoch #1. Accuracy on batch 2417/2438  on Training is 61.15979114971051\n",
            "Epoch #1. Accuracy on batch 2418/2438  on Training is 61.15905332782141\n",
            "Epoch #1. Accuracy on batch 2419/2438  on Training is 61.15702479338843\n",
            "Batch Id 2420/2438 is having training loss of 1.548959732055664\n",
            "0.8145351409912109\n",
            "Epoch #1. Accuracy on batch 2420/2438  on Training is 61.16532424617927\n",
            "Epoch #1. Accuracy on batch 2421/2438  on Training is 61.168455821635014\n",
            "Epoch #1. Accuracy on batch 2422/2438  on Training is 61.16642591828312\n",
            "Epoch #1. Accuracy on batch 2423/2438  on Training is 61.1682652640264\n",
            "Epoch #1. Accuracy on batch 2424/2438  on Training is 61.16881443298969\n",
            "Epoch #1. Accuracy on batch 2425/2438  on Training is 61.16807502061006\n",
            "Epoch #1. Accuracy on batch 2426/2438  on Training is 61.16991141326741\n",
            "Epoch #1. Accuracy on batch 2427/2438  on Training is 61.173033360790775\n",
            "Epoch #1. Accuracy on batch 2428/2438  on Training is 61.18001235076163\n",
            "Epoch #1. Accuracy on batch 2429/2438  on Training is 61.18698559670782\n",
            "Epoch #1. Accuracy on batch 2430/2438  on Training is 61.18495475113122\n",
            "Epoch #1. Accuracy on batch 2431/2438  on Training is 61.19063527960526\n",
            "Epoch #1. Accuracy on batch 2432/2438  on Training is 61.192457870941226\n",
            "Epoch #1. Accuracy on batch 2433/2438  on Training is 61.19556285949055\n",
            "Epoch #1. Accuracy on batch 2434/2438  on Training is 61.19481519507187\n",
            "Epoch #1. Accuracy on batch 2435/2438  on Training is 61.19278530377668\n",
            "Epoch #1. Accuracy on batch 2436/2438  on Training is 61.18819244973328\n",
            "Epoch #1. Accuracy on batch 2437/2438  on Training is 61.184615384615384\n",
            "Epoch #1. Batch Id 0/278  is having validation loss of 1.6249665021896362\n",
            "1.6249665021896362\n",
            "Epoch #1. Batch Id 0/278  is having validation accuracy of 53.125\n",
            "Epoch #1. Batch Id 1/278  is having validation loss of 1.5577685832977295\n",
            "1.4905707836151123\n",
            "Epoch #1. Batch Id 1/278  is having validation accuracy of 57.8125\n",
            "Epoch #1. Batch Id 2/278  is having validation loss of 1.525238037109375\n",
            "1.4601768255233765\n",
            "Epoch #1. Batch Id 2/278  is having validation accuracy of 59.375\n",
            "Epoch #1. Batch Id 3/278  is having validation loss of 1.409275770187378\n",
            "1.0613892078399658\n",
            "Epoch #1. Batch Id 3/278  is having validation accuracy of 62.5\n",
            "Epoch #1. Batch Id 4/278  is having validation loss of 1.6820989847183228\n",
            "2.7733917236328125\n",
            "Epoch #1. Batch Id 4/278  is having validation accuracy of 55.625\n",
            "Epoch #1. Batch Id 5/278  is having validation loss of 1.6967049837112427\n",
            "1.7697349786758423\n",
            "Epoch #1. Batch Id 5/278  is having validation accuracy of 56.770833333333336\n",
            "Epoch #1. Batch Id 6/278  is having validation loss of 1.7185251712799072\n",
            "1.8494462966918945\n",
            "Epoch #1. Batch Id 6/278  is having validation accuracy of 55.357142857142854\n",
            "Epoch #1. Batch Id 7/278  is having validation loss of 1.7240031957626343\n",
            "1.7623493671417236\n",
            "Epoch #1. Batch Id 7/278  is having validation accuracy of 54.6875\n",
            "Epoch #1. Batch Id 8/278  is having validation loss of 1.7048263549804688\n",
            "1.551411747932434\n",
            "Epoch #1. Batch Id 8/278  is having validation accuracy of 54.513888888888886\n",
            "Epoch #1. Batch Id 9/278  is having validation loss of 1.6559698581695557\n",
            "1.2162607908248901\n",
            "Epoch #1. Batch Id 9/278  is having validation accuracy of 56.25\n",
            "Epoch #1. Batch Id 10/278  is having validation loss of 1.640659213066101\n",
            "1.4875530004501343\n",
            "Epoch #1. Batch Id 10/278  is having validation accuracy of 55.96590909090909\n",
            "Epoch #1. Batch Id 11/278  is having validation loss of 1.618288278579712\n",
            "1.3722081184387207\n",
            "Epoch #1. Batch Id 11/278  is having validation accuracy of 56.510416666666664\n",
            "Epoch #1. Batch Id 12/278  is having validation loss of 1.6381511688232422\n",
            "1.8765065670013428\n",
            "Epoch #1. Batch Id 12/278  is having validation accuracy of 56.49038461538461\n",
            "Epoch #1. Batch Id 13/278  is having validation loss of 1.657700538635254\n",
            "1.9118422269821167\n",
            "Epoch #1. Batch Id 13/278  is having validation accuracy of 54.910714285714285\n",
            "Epoch #1. Batch Id 14/278  is having validation loss of 1.6435726881027222\n",
            "1.4457824230194092\n",
            "Epoch #1. Batch Id 14/278  is having validation accuracy of 55.833333333333336\n",
            "Epoch #1. Batch Id 15/278  is having validation loss of 1.6408950090408325\n",
            "1.600728988647461\n",
            "Epoch #1. Batch Id 15/278  is having validation accuracy of 56.4453125\n",
            "Epoch #1. Batch Id 16/278  is having validation loss of 1.6447625160217285\n",
            "1.706642985343933\n",
            "Epoch #1. Batch Id 16/278  is having validation accuracy of 56.8014705882353\n",
            "Epoch #1. Batch Id 17/278  is having validation loss of 1.6607590913772583\n",
            "1.932700514793396\n",
            "Epoch #1. Batch Id 17/278  is having validation accuracy of 55.90277777777778\n",
            "Epoch #1. Batch Id 18/278  is having validation loss of 1.6667191982269287\n",
            "1.774001955986023\n",
            "Epoch #1. Batch Id 18/278  is having validation accuracy of 55.5921052631579\n",
            "Epoch #1. Batch Id 19/278  is having validation loss of 1.6609442234039307\n",
            "1.5512194633483887\n",
            "Epoch #1. Batch Id 19/278  is having validation accuracy of 55.78125\n",
            "Epoch #1. Batch Id 20/278  is having validation loss of 1.6553676128387451\n",
            "1.5438358783721924\n",
            "Epoch #1. Batch Id 20/278  is having validation accuracy of 55.50595238095238\n",
            "Epoch #1. Batch Id 21/278  is having validation loss of 1.6619677543640137\n",
            "1.8005706071853638\n",
            "Epoch #1. Batch Id 21/278  is having validation accuracy of 55.25568181818182\n",
            "Epoch #1. Batch Id 22/278  is having validation loss of 1.6324447393417358\n",
            "0.9829390048980713\n",
            "Epoch #1. Batch Id 22/278  is having validation accuracy of 56.11413043478261\n",
            "Epoch #1. Batch Id 23/278  is having validation loss of 1.639402985572815\n",
            "1.7994427680969238\n",
            "Epoch #1. Batch Id 23/278  is having validation accuracy of 55.989583333333336\n",
            "Epoch #1. Batch Id 24/278  is having validation loss of 1.626489520072937\n",
            "1.3165669441223145\n",
            "Epoch #1. Batch Id 24/278  is having validation accuracy of 56.375\n",
            "Epoch #1. Batch Id 25/278  is having validation loss of 1.6380983591079712\n",
            "1.9283199310302734\n",
            "Epoch #1. Batch Id 25/278  is having validation accuracy of 56.37019230769231\n",
            "Epoch #1. Batch Id 26/278  is having validation loss of 1.6533548831939697\n",
            "2.0500240325927734\n",
            "Epoch #1. Batch Id 26/278  is having validation accuracy of 56.25\n",
            "Epoch #1. Batch Id 27/278  is having validation loss of 1.650925636291504\n",
            "1.5853359699249268\n",
            "Epoch #1. Batch Id 27/278  is having validation accuracy of 56.473214285714285\n",
            "Epoch #1. Batch Id 28/278  is having validation loss of 1.671496868133545\n",
            "2.2474923133850098\n",
            "Epoch #1. Batch Id 28/278  is having validation accuracy of 56.03448275862069\n",
            "Epoch #1. Batch Id 29/278  is having validation loss of 1.669479489326477\n",
            "1.6109743118286133\n",
            "Epoch #1. Batch Id 29/278  is having validation accuracy of 56.041666666666664\n",
            "Epoch #1. Batch Id 30/278  is having validation loss of 1.673994779586792\n",
            "1.8094542026519775\n",
            "Epoch #1. Batch Id 30/278  is having validation accuracy of 56.149193548387096\n",
            "Epoch #1. Batch Id 31/278  is having validation loss of 1.6758534908294678\n",
            "1.7334749698638916\n",
            "Epoch #1. Batch Id 31/278  is having validation accuracy of 56.15234375\n",
            "Epoch #1. Batch Id 32/278  is having validation loss of 1.6805546283721924\n",
            "1.8309911489486694\n",
            "Epoch #1. Batch Id 32/278  is having validation accuracy of 56.43939393939394\n",
            "Epoch #1. Batch Id 33/278  is having validation loss of 1.676487684249878\n",
            "1.5422775745391846\n",
            "Epoch #1. Batch Id 33/278  is having validation accuracy of 56.61764705882353\n",
            "Epoch #1. Batch Id 34/278  is having validation loss of 1.693289875984192\n",
            "2.2645630836486816\n",
            "Epoch #1. Batch Id 34/278  is having validation accuracy of 55.982142857142854\n",
            "Epoch #1. Batch Id 35/278  is having validation loss of 1.6855480670928955\n",
            "1.4145863056182861\n",
            "Epoch #1. Batch Id 35/278  is having validation accuracy of 56.33680555555556\n",
            "Epoch #1. Batch Id 36/278  is having validation loss of 1.6795899868011475\n",
            "1.4650977849960327\n",
            "Epoch #1. Batch Id 36/278  is having validation accuracy of 56.50337837837838\n",
            "Epoch #1. Batch Id 37/278  is having validation loss of 1.6768841743469238\n",
            "1.5767674446105957\n",
            "Epoch #1. Batch Id 37/278  is having validation accuracy of 56.41447368421053\n",
            "Epoch #1. Batch Id 38/278  is having validation loss of 1.6786701679229736\n",
            "1.746537685394287\n",
            "Epoch #1. Batch Id 38/278  is having validation accuracy of 56.330128205128204\n",
            "Epoch #1. Batch Id 39/278  is having validation loss of 1.6764403581619263\n",
            "1.5894789695739746\n",
            "Epoch #1. Batch Id 39/278  is having validation accuracy of 56.484375\n",
            "Epoch #1. Batch Id 40/278  is having validation loss of 1.680387020111084\n",
            "1.8382530212402344\n",
            "Epoch #1. Batch Id 40/278  is having validation accuracy of 56.55487804878049\n",
            "Epoch #1. Batch Id 41/278  is having validation loss of 1.6842191219329834\n",
            "1.8413336277008057\n",
            "Epoch #1. Batch Id 41/278  is having validation accuracy of 56.62202380952381\n",
            "Epoch #1. Batch Id 42/278  is having validation loss of 1.6770620346069336\n",
            "1.3764622211456299\n",
            "Epoch #1. Batch Id 42/278  is having validation accuracy of 56.83139534883721\n",
            "Epoch #1. Batch Id 43/278  is having validation loss of 1.6712756156921387\n",
            "1.4224581718444824\n",
            "Epoch #1. Batch Id 43/278  is having validation accuracy of 56.88920454545455\n",
            "Epoch #1. Batch Id 44/278  is having validation loss of 1.6714860200881958\n",
            "1.6807454824447632\n",
            "Epoch #1. Batch Id 44/278  is having validation accuracy of 56.80555555555556\n",
            "Epoch #1. Batch Id 45/278  is having validation loss of 1.6719636917114258\n",
            "1.69346022605896\n",
            "Epoch #1. Batch Id 45/278  is having validation accuracy of 56.65760869565217\n",
            "Epoch #1. Batch Id 46/278  is having validation loss of 1.6642283201217651\n",
            "1.308401346206665\n",
            "Epoch #1. Batch Id 46/278  is having validation accuracy of 56.715425531914896\n",
            "Epoch #1. Batch Id 47/278  is having validation loss of 1.6592422723770142\n",
            "1.4248977899551392\n",
            "Epoch #1. Batch Id 47/278  is having validation accuracy of 56.901041666666664\n",
            "Epoch #1. Batch Id 48/278  is having validation loss of 1.6534230709075928\n",
            "1.374099850654602\n",
            "Epoch #1. Batch Id 48/278  is having validation accuracy of 57.27040816326531\n",
            "Epoch #1. Batch Id 49/278  is having validation loss of 1.6548941135406494\n",
            "1.7269729375839233\n",
            "Epoch #1. Batch Id 49/278  is having validation accuracy of 57.1875\n",
            "Epoch #1. Batch Id 50/278  is having validation loss of 1.6471987962722778\n",
            "1.262435793876648\n",
            "Epoch #1. Batch Id 50/278  is having validation accuracy of 57.23039215686274\n",
            "Epoch #1. Batch Id 51/278  is having validation loss of 1.6411871910095215\n",
            "1.3345941305160522\n",
            "Epoch #1. Batch Id 51/278  is having validation accuracy of 57.39182692307692\n",
            "Epoch #1. Batch Id 52/278  is having validation loss of 1.6402266025543213\n",
            "1.590278148651123\n",
            "Epoch #1. Batch Id 52/278  is having validation accuracy of 57.54716981132076\n",
            "Epoch #1. Batch Id 53/278  is having validation loss of 1.645829677581787\n",
            "1.9427956342697144\n",
            "Epoch #1. Batch Id 53/278  is having validation accuracy of 57.523148148148145\n",
            "Epoch #1. Batch Id 54/278  is having validation loss of 1.645565152168274\n",
            "1.6312834024429321\n",
            "Epoch #1. Batch Id 54/278  is having validation accuracy of 57.44318181818182\n",
            "Epoch #1. Batch Id 55/278  is having validation loss of 1.6460767984390259\n",
            "1.674214482307434\n",
            "Epoch #1. Batch Id 55/278  is having validation accuracy of 57.310267857142854\n",
            "Epoch #1. Batch Id 56/278  is having validation loss of 1.650808334350586\n",
            "1.9157737493515015\n",
            "Epoch #1. Batch Id 56/278  is having validation accuracy of 57.23684210526316\n",
            "Epoch #1. Batch Id 57/278  is having validation loss of 1.6443884372711182\n",
            "1.2784560918807983\n",
            "Epoch #1. Batch Id 57/278  is having validation accuracy of 57.327586206896555\n",
            "Epoch #1. Batch Id 58/278  is having validation loss of 1.6496713161468506\n",
            "1.9560749530792236\n",
            "Epoch #1. Batch Id 58/278  is having validation accuracy of 57.097457627118644\n",
            "Epoch #1. Batch Id 59/278  is having validation loss of 1.6474440097808838\n",
            "1.5160332918167114\n",
            "Epoch #1. Batch Id 59/278  is having validation accuracy of 57.291666666666664\n",
            "Epoch #1. Batch Id 60/278  is having validation loss of 1.6445691585540771\n",
            "1.472078561782837\n",
            "Epoch #1. Batch Id 60/278  is having validation accuracy of 57.42827868852459\n",
            "Epoch #1. Batch Id 61/278  is having validation loss of 1.6452233791351318\n",
            "1.6851310729980469\n",
            "Epoch #1. Batch Id 61/278  is having validation accuracy of 57.51008064516129\n",
            "Epoch #1. Batch Id 62/278  is having validation loss of 1.6381089687347412\n",
            "1.1970129013061523\n",
            "Epoch #1. Batch Id 62/278  is having validation accuracy of 57.73809523809524\n",
            "Epoch #1. Batch Id 63/278  is having validation loss of 1.6426442861557007\n",
            "1.9283716678619385\n",
            "Epoch #1. Batch Id 63/278  is having validation accuracy of 57.71484375\n",
            "Epoch #1. Batch Id 64/278  is having validation loss of 1.6496262550354004\n",
            "2.0964696407318115\n",
            "Epoch #1. Batch Id 64/278  is having validation accuracy of 57.54807692307692\n",
            "Epoch #1. Batch Id 65/278  is having validation loss of 1.6448605060577393\n",
            "1.335089921951294\n",
            "Epoch #1. Batch Id 65/278  is having validation accuracy of 57.71780303030303\n",
            "Epoch #1. Batch Id 66/278  is having validation loss of 1.642435073852539\n",
            "1.4823544025421143\n",
            "Epoch #1. Batch Id 66/278  is having validation accuracy of 57.78917910447761\n",
            "Epoch #1. Batch Id 67/278  is having validation loss of 1.6440397500991821\n",
            "1.7515491247177124\n",
            "Epoch #1. Batch Id 67/278  is having validation accuracy of 57.674632352941174\n",
            "Epoch #1. Batch Id 68/278  is having validation loss of 1.63705313205719\n",
            "1.1619646549224854\n",
            "Epoch #1. Batch Id 68/278  is having validation accuracy of 57.835144927536234\n",
            "Epoch #1. Batch Id 69/278  is having validation loss of 1.6355705261230469\n",
            "1.5332746505737305\n",
            "Epoch #1. Batch Id 69/278  is having validation accuracy of 57.99107142857143\n",
            "Epoch #1. Batch Id 70/278  is having validation loss of 1.6400775909423828\n",
            "1.9555758237838745\n",
            "Epoch #1. Batch Id 70/278  is having validation accuracy of 57.83450704225352\n",
            "Epoch #1. Batch Id 71/278  is having validation loss of 1.632765769958496\n",
            "1.113628625869751\n",
            "Epoch #1. Batch Id 71/278  is having validation accuracy of 57.986111111111114\n",
            "Epoch #1. Batch Id 72/278  is having validation loss of 1.636809229850769\n",
            "1.9279344081878662\n",
            "Epoch #1. Batch Id 72/278  is having validation accuracy of 57.83390410958904\n",
            "Epoch #1. Batch Id 73/278  is having validation loss of 1.6370737552642822\n",
            "1.6563810110092163\n",
            "Epoch #1. Batch Id 73/278  is having validation accuracy of 57.89695945945946\n",
            "Epoch #1. Batch Id 74/278  is having validation loss of 1.6405352354049683\n",
            "1.896681308746338\n",
            "Epoch #1. Batch Id 74/278  is having validation accuracy of 57.833333333333336\n",
            "Epoch #1. Batch Id 75/278  is having validation loss of 1.63983952999115\n",
            "1.5876580476760864\n",
            "Epoch #1. Batch Id 75/278  is having validation accuracy of 57.89473684210526\n",
            "Epoch #1. Batch Id 76/278  is having validation loss of 1.644089698791504\n",
            "1.9670982360839844\n",
            "Epoch #1. Batch Id 76/278  is having validation accuracy of 57.75162337662338\n",
            "Epoch #1. Batch Id 77/278  is having validation loss of 1.640639066696167\n",
            "1.3749357461929321\n",
            "Epoch #1. Batch Id 77/278  is having validation accuracy of 57.8125\n",
            "Epoch #1. Batch Id 78/278  is having validation loss of 1.6406285762786865\n",
            "1.6398097276687622\n",
            "Epoch #1. Batch Id 78/278  is having validation accuracy of 57.75316455696203\n",
            "Epoch #1. Batch Id 79/278  is having validation loss of 1.6390373706817627\n",
            "1.513333797454834\n",
            "Epoch #1. Batch Id 79/278  is having validation accuracy of 57.578125\n",
            "Epoch #1. Batch Id 80/278  is having validation loss of 1.6455204486846924\n",
            "2.1641621589660645\n",
            "Epoch #1. Batch Id 80/278  is having validation accuracy of 57.44598765432099\n",
            "Epoch #1. Batch Id 81/278  is having validation loss of 1.6486737728118896\n",
            "1.9040946960449219\n",
            "Epoch #1. Batch Id 81/278  is having validation accuracy of 57.355182926829265\n",
            "Epoch #1. Batch Id 82/278  is having validation loss of 1.6533153057098389\n",
            "2.0339179039001465\n",
            "Epoch #1. Batch Id 82/278  is having validation accuracy of 57.30421686746988\n",
            "Epoch #1. Batch Id 83/278  is having validation loss of 1.651862621307373\n",
            "1.5312937498092651\n",
            "Epoch #1. Batch Id 83/278  is having validation accuracy of 57.40327380952381\n",
            "Epoch #1. Batch Id 84/278  is having validation loss of 1.649649977684021\n",
            "1.4637866020202637\n",
            "Epoch #1. Batch Id 84/278  is having validation accuracy of 57.536764705882355\n",
            "Epoch #1. Batch Id 85/278  is having validation loss of 1.647374153137207\n",
            "1.45392906665802\n",
            "Epoch #1. Batch Id 85/278  is having validation accuracy of 57.70348837209303\n",
            "Epoch #1. Batch Id 86/278  is having validation loss of 1.6514170169830322\n",
            "1.9991042613983154\n",
            "Epoch #1. Batch Id 86/278  is having validation accuracy of 57.57902298850575\n",
            "Epoch #1. Batch Id 87/278  is having validation loss of 1.6501544713974\n",
            "1.5403097867965698\n",
            "Epoch #1. Batch Id 87/278  is having validation accuracy of 57.52840909090909\n",
            "Epoch #1. Batch Id 88/278  is having validation loss of 1.6557788848876953\n",
            "2.150729179382324\n",
            "Epoch #1. Batch Id 88/278  is having validation accuracy of 57.23314606741573\n",
            "Epoch #1. Batch Id 89/278  is having validation loss of 1.6520618200302124\n",
            "1.3212387561798096\n",
            "Epoch #1. Batch Id 89/278  is having validation accuracy of 57.326388888888886\n",
            "Epoch #1. Batch Id 90/278  is having validation loss of 1.6482925415039062\n",
            "1.30905282497406\n",
            "Epoch #1. Batch Id 90/278  is having validation accuracy of 57.3489010989011\n",
            "Epoch #1. Batch Id 91/278  is having validation loss of 1.6477599143981934\n",
            "1.5992858409881592\n",
            "Epoch #1. Batch Id 91/278  is having validation accuracy of 57.50679347826087\n",
            "Epoch #1. Batch Id 92/278  is having validation loss of 1.6482996940612793\n",
            "1.6979628801345825\n",
            "Epoch #1. Batch Id 92/278  is having validation accuracy of 57.526881720430104\n",
            "Epoch #1. Batch Id 93/278  is having validation loss of 1.6454582214355469\n",
            "1.3811984062194824\n",
            "Epoch #1. Batch Id 93/278  is having validation accuracy of 57.64627659574468\n",
            "Epoch #1. Batch Id 94/278  is having validation loss of 1.6415666341781616\n",
            "1.2757577896118164\n",
            "Epoch #1. Batch Id 94/278  is having validation accuracy of 57.76315789473684\n",
            "Epoch #1. Batch Id 95/278  is having validation loss of 1.6404554843902588\n",
            "1.5348942279815674\n",
            "Epoch #1. Batch Id 95/278  is having validation accuracy of 57.779947916666664\n",
            "Epoch #1. Batch Id 96/278  is having validation loss of 1.642118215560913\n",
            "1.8017418384552002\n",
            "Epoch #1. Batch Id 96/278  is having validation accuracy of 57.699742268041234\n",
            "Epoch #1. Batch Id 97/278  is having validation loss of 1.641657829284668\n",
            "1.5969979763031006\n",
            "Epoch #1. Batch Id 97/278  is having validation accuracy of 57.71683673469388\n",
            "Epoch #1. Batch Id 98/278  is having validation loss of 1.6436221599578857\n",
            "1.8361234664916992\n",
            "Epoch #1. Batch Id 98/278  is having validation accuracy of 57.57575757575758\n",
            "Epoch #1. Batch Id 99/278  is having validation loss of 1.6420502662658691\n",
            "1.4864273071289062\n",
            "Epoch #1. Batch Id 99/278  is having validation accuracy of 57.625\n",
            "Epoch #1. Batch Id 100/278  is having validation loss of 1.6426140069961548\n",
            "1.6989920139312744\n",
            "Epoch #1. Batch Id 100/278  is having validation accuracy of 57.51856435643565\n",
            "Epoch #1. Batch Id 101/278  is having validation loss of 1.6435860395431519\n",
            "1.741766333580017\n",
            "Epoch #1. Batch Id 101/278  is having validation accuracy of 57.47549019607843\n",
            "Epoch #1. Batch Id 102/278  is having validation loss of 1.6395970582962036\n",
            "1.2327265739440918\n",
            "Epoch #1. Batch Id 102/278  is having validation accuracy of 57.64563106796116\n",
            "Epoch #1. Batch Id 103/278  is having validation loss of 1.6431512832641602\n",
            "2.0092320442199707\n",
            "Epoch #1. Batch Id 103/278  is having validation accuracy of 57.51201923076923\n",
            "Epoch #1. Batch Id 104/278  is having validation loss of 1.6411155462265015\n",
            "1.4294050931930542\n",
            "Epoch #1. Batch Id 104/278  is having validation accuracy of 57.44047619047619\n",
            "Epoch #1. Batch Id 105/278  is having validation loss of 1.6371500492095947\n",
            "1.2207775115966797\n",
            "Epoch #1. Batch Id 105/278  is having validation accuracy of 57.488207547169814\n",
            "Epoch #1. Batch Id 106/278  is having validation loss of 1.6347397565841675\n",
            "1.3792439699172974\n",
            "Epoch #1. Batch Id 106/278  is having validation accuracy of 57.447429906542055\n",
            "Epoch #1. Batch Id 107/278  is having validation loss of 1.6307015419006348\n",
            "1.1986075639724731\n",
            "Epoch #1. Batch Id 107/278  is having validation accuracy of 57.552083333333336\n",
            "Epoch #1. Batch Id 108/278  is having validation loss of 1.632896065711975\n",
            "1.8699028491973877\n",
            "Epoch #1. Batch Id 108/278  is having validation accuracy of 57.45412844036697\n",
            "Epoch #1. Batch Id 109/278  is having validation loss of 1.6336766481399536\n",
            "1.7187633514404297\n",
            "Epoch #1. Batch Id 109/278  is having validation accuracy of 57.44318181818182\n",
            "Epoch #1. Batch Id 110/278  is having validation loss of 1.629128336906433\n",
            "1.1288083791732788\n",
            "Epoch #1. Batch Id 110/278  is having validation accuracy of 57.460585585585584\n",
            "Epoch #1. Batch Id 111/278  is having validation loss of 1.6267919540405273\n",
            "1.3674590587615967\n",
            "Epoch #1. Batch Id 111/278  is having validation accuracy of 57.533482142857146\n",
            "Epoch #1. Batch Id 112/278  is having validation loss of 1.6295390129089355\n",
            "1.9372050762176514\n",
            "Epoch #1. Batch Id 112/278  is having validation accuracy of 57.466814159292035\n",
            "Epoch #1. Batch Id 113/278  is having validation loss of 1.630164623260498\n",
            "1.7008605003356934\n",
            "Epoch #1. Batch Id 113/278  is having validation accuracy of 57.42872807017544\n",
            "Epoch #1. Batch Id 114/278  is having validation loss of 1.634045958518982\n",
            "2.076523780822754\n",
            "Epoch #1. Batch Id 114/278  is having validation accuracy of 57.20108695652174\n",
            "Epoch #1. Batch Id 115/278  is having validation loss of 1.6373077630996704\n",
            "2.012420415878296\n",
            "Epoch #1. Batch Id 115/278  is having validation accuracy of 57.16594827586207\n",
            "Epoch #1. Batch Id 116/278  is having validation loss of 1.6433992385864258\n",
            "2.3500053882598877\n",
            "Epoch #1. Batch Id 116/278  is having validation accuracy of 57.10470085470085\n",
            "Epoch #1. Batch Id 117/278  is having validation loss of 1.6454895734786987\n",
            "1.8900545835494995\n",
            "Epoch #1. Batch Id 117/278  is having validation accuracy of 57.15042372881356\n",
            "Epoch #1. Batch Id 118/278  is having validation loss of 1.6443240642547607\n",
            "1.5067986249923706\n",
            "Epoch #1. Batch Id 118/278  is having validation accuracy of 57.169117647058826\n",
            "Epoch #1. Batch Id 119/278  is having validation loss of 1.64429771900177\n",
            "1.641159176826477\n",
            "Epoch #1. Batch Id 119/278  is having validation accuracy of 57.161458333333336\n",
            "Epoch #1. Batch Id 120/278  is having validation loss of 1.6416585445404053\n",
            "1.3249564170837402\n",
            "Epoch #1. Batch Id 120/278  is having validation accuracy of 57.12809917355372\n",
            "Epoch #1. Batch Id 121/278  is having validation loss of 1.6430424451828003\n",
            "1.8104877471923828\n",
            "Epoch #1. Batch Id 121/278  is having validation accuracy of 57.06967213114754\n",
            "Epoch #1. Batch Id 122/278  is having validation loss of 1.6467372179031372\n",
            "2.097505807876587\n",
            "Epoch #1. Batch Id 122/278  is having validation accuracy of 56.96138211382114\n",
            "Epoch #1. Batch Id 123/278  is having validation loss of 1.6506004333496094\n",
            "2.1257734298706055\n",
            "Epoch #1. Batch Id 123/278  is having validation accuracy of 56.88004032258065\n",
            "Epoch #1. Batch Id 124/278  is having validation loss of 1.650546669960022\n",
            "1.6438853740692139\n",
            "Epoch #1. Batch Id 124/278  is having validation accuracy of 56.875\n",
            "Epoch #1. Batch Id 125/278  is having validation loss of 1.6488174200057983\n",
            "1.4326674938201904\n",
            "Epoch #1. Batch Id 125/278  is having validation accuracy of 56.94444444444444\n",
            "Epoch #1. Batch Id 126/278  is having validation loss of 1.6467947959899902\n",
            "1.391942024230957\n",
            "Epoch #1. Batch Id 126/278  is having validation accuracy of 56.938976377952756\n",
            "Epoch #1. Batch Id 127/278  is having validation loss of 1.6464778184890747\n",
            "1.6062272787094116\n",
            "Epoch #1. Batch Id 127/278  is having validation accuracy of 56.93359375\n",
            "Epoch #1. Batch Id 128/278  is having validation loss of 1.6432900428771973\n",
            "1.2352484464645386\n",
            "Epoch #1. Batch Id 128/278  is having validation accuracy of 57.07364341085271\n",
            "Epoch #1. Batch Id 129/278  is having validation loss of 1.6425557136535645\n",
            "1.547829508781433\n",
            "Epoch #1. Batch Id 129/278  is having validation accuracy of 57.11538461538461\n",
            "Epoch #1. Batch Id 130/278  is having validation loss of 1.6372876167297363\n",
            "0.9524381160736084\n",
            "Epoch #1. Batch Id 130/278  is having validation accuracy of 57.25190839694657\n",
            "Epoch #1. Batch Id 131/278  is having validation loss of 1.6395373344421387\n",
            "1.9342544078826904\n",
            "Epoch #1. Batch Id 131/278  is having validation accuracy of 57.22064393939394\n",
            "Epoch #1. Batch Id 132/278  is having validation loss of 1.6401079893112183\n",
            "1.7154326438903809\n",
            "Epoch #1. Batch Id 132/278  is having validation accuracy of 57.18984962406015\n",
            "Epoch #1. Batch Id 133/278  is having validation loss of 1.6425398588180542\n",
            "1.9659779071807861\n",
            "Epoch #1. Batch Id 133/278  is having validation accuracy of 57.11287313432836\n",
            "Epoch #1. Batch Id 134/278  is having validation loss of 1.64487886428833\n",
            "1.9583104848861694\n",
            "Epoch #1. Batch Id 134/278  is having validation accuracy of 57.06018518518518\n",
            "Epoch #1. Batch Id 135/278  is having validation loss of 1.6470556259155273\n",
            "1.9409151077270508\n",
            "Epoch #1. Batch Id 135/278  is having validation accuracy of 56.916360294117645\n",
            "Epoch #1. Batch Id 136/278  is having validation loss of 1.6479370594024658\n",
            "1.7678149938583374\n",
            "Epoch #1. Batch Id 136/278  is having validation accuracy of 56.957116788321166\n",
            "Epoch #1. Batch Id 137/278  is having validation loss of 1.6489019393920898\n",
            "1.7810864448547363\n",
            "Epoch #1. Batch Id 137/278  is having validation accuracy of 56.88405797101449\n",
            "Epoch #1. Batch Id 138/278  is having validation loss of 1.6464574337005615\n",
            "1.3091154098510742\n",
            "Epoch #1. Batch Id 138/278  is having validation accuracy of 56.8794964028777\n",
            "Epoch #1. Batch Id 139/278  is having validation loss of 1.645780324935913\n",
            "1.5516581535339355\n",
            "Epoch #1. Batch Id 139/278  is having validation accuracy of 56.941964285714285\n",
            "Epoch #1. Batch Id 140/278  is having validation loss of 1.646572470664978\n",
            "1.7574717998504639\n",
            "Epoch #1. Batch Id 140/278  is having validation accuracy of 56.9813829787234\n",
            "Epoch #1. Batch Id 141/278  is having validation loss of 1.6443471908569336\n",
            "1.3305860757827759\n",
            "Epoch #1. Batch Id 141/278  is having validation accuracy of 57.04225352112676\n",
            "Epoch #1. Batch Id 142/278  is having validation loss of 1.6412944793701172\n",
            "1.2078118324279785\n",
            "Epoch #1. Batch Id 142/278  is having validation accuracy of 57.10227272727273\n",
            "Epoch #1. Batch Id 143/278  is having validation loss of 1.6431094408035278\n",
            "1.9026459455490112\n",
            "Epoch #1. Batch Id 143/278  is having validation accuracy of 57.03125\n",
            "Epoch #1. Batch Id 144/278  is having validation loss of 1.64613938331604\n",
            "2.082453966140747\n",
            "Epoch #1. Batch Id 144/278  is having validation accuracy of 56.98275862068966\n",
            "Epoch #1. Batch Id 145/278  is having validation loss of 1.6470493078231812\n",
            "1.7789889574050903\n",
            "Epoch #1. Batch Id 145/278  is having validation accuracy of 56.977739726027394\n",
            "Epoch #1. Batch Id 146/278  is having validation loss of 1.6461069583892822\n",
            "1.50852370262146\n",
            "Epoch #1. Batch Id 146/278  is having validation accuracy of 56.97278911564626\n",
            "Epoch #1. Batch Id 147/278  is having validation loss of 1.6461424827575684\n",
            "1.6513632535934448\n",
            "Epoch #1. Batch Id 147/278  is having validation accuracy of 57.03125\n",
            "Epoch #1. Batch Id 148/278  is having validation loss of 1.6484794616699219\n",
            "1.9943515062332153\n",
            "Epoch #1. Batch Id 148/278  is having validation accuracy of 56.94211409395973\n",
            "Epoch #1. Batch Id 149/278  is having validation loss of 1.6511143445968628\n",
            "2.0437092781066895\n",
            "Epoch #1. Batch Id 149/278  is having validation accuracy of 56.916666666666664\n",
            "Epoch #1. Batch Id 150/278  is having validation loss of 1.6523280143737793\n",
            "1.8343737125396729\n",
            "Epoch #1. Batch Id 150/278  is having validation accuracy of 56.89155629139073\n",
            "Epoch #1. Batch Id 151/278  is having validation loss of 1.6536054611206055\n",
            "1.8465036153793335\n",
            "Epoch #1. Batch Id 151/278  is having validation accuracy of 56.82565789473684\n",
            "Epoch #1. Batch Id 152/278  is having validation loss of 1.65463387966156\n",
            "1.8109540939331055\n",
            "Epoch #1. Batch Id 152/278  is having validation accuracy of 56.8014705882353\n",
            "Epoch #1. Batch Id 153/278  is having validation loss of 1.653456211090088\n",
            "1.4732706546783447\n",
            "Epoch #1. Batch Id 153/278  is having validation accuracy of 56.7573051948052\n",
            "Epoch #1. Batch Id 154/278  is having validation loss of 1.656378984451294\n",
            "2.1064891815185547\n",
            "Epoch #1. Batch Id 154/278  is having validation accuracy of 56.653225806451616\n",
            "Epoch #1. Batch Id 155/278  is having validation loss of 1.6545419692993164\n",
            "1.369810938835144\n",
            "Epoch #1. Batch Id 155/278  is having validation accuracy of 56.69070512820513\n",
            "Epoch #1. Batch Id 156/278  is having validation loss of 1.6561074256896973\n",
            "1.9003130197525024\n",
            "Epoch #1. Batch Id 156/278  is having validation accuracy of 56.64808917197452\n",
            "Epoch #1. Batch Id 157/278  is having validation loss of 1.6560930013656616\n",
            "1.6538233757019043\n",
            "Epoch #1. Batch Id 157/278  is having validation accuracy of 56.625791139240505\n",
            "Epoch #1. Batch Id 158/278  is having validation loss of 1.657227635383606\n",
            "1.8365075588226318\n",
            "Epoch #1. Batch Id 158/278  is having validation accuracy of 56.643081761006286\n",
            "Epoch #1. Batch Id 159/278  is having validation loss of 1.6576095819473267\n",
            "1.7183336019515991\n",
            "Epoch #1. Batch Id 159/278  is having validation accuracy of 56.640625\n",
            "Epoch #1. Batch Id 160/278  is having validation loss of 1.6593964099884033\n",
            "1.945286750793457\n",
            "Epoch #1. Batch Id 160/278  is having validation accuracy of 56.599378881987576\n",
            "Epoch #1. Batch Id 161/278  is having validation loss of 1.6604666709899902\n",
            "1.8327809572219849\n",
            "Epoch #1. Batch Id 161/278  is having validation accuracy of 56.59722222222222\n",
            "Epoch #1. Batch Id 162/278  is having validation loss of 1.6588594913482666\n",
            "1.3984977006912231\n",
            "Epoch #1. Batch Id 162/278  is having validation accuracy of 56.6909509202454\n",
            "Epoch #1. Batch Id 163/278  is having validation loss of 1.6578596830368042\n",
            "1.494892954826355\n",
            "Epoch #1. Batch Id 163/278  is having validation accuracy of 56.74542682926829\n",
            "Epoch #1. Batch Id 164/278  is having validation loss of 1.660799264907837\n",
            "2.142887830734253\n",
            "Epoch #1. Batch Id 164/278  is having validation accuracy of 56.68560606060606\n",
            "Epoch #1. Batch Id 165/278  is having validation loss of 1.6598680019378662\n",
            "1.5062105655670166\n",
            "Epoch #1. Batch Id 165/278  is having validation accuracy of 56.75828313253012\n",
            "Epoch #1. Batch Id 166/278  is having validation loss of 1.6579053401947021\n",
            "1.3321044445037842\n",
            "Epoch #1. Batch Id 166/278  is having validation accuracy of 56.830089820359284\n",
            "Epoch #1. Batch Id 167/278  is having validation loss of 1.6568506956100464\n",
            "1.4807348251342773\n",
            "Epoch #1. Batch Id 167/278  is having validation accuracy of 56.845238095238095\n",
            "Epoch #1. Batch Id 168/278  is having validation loss of 1.6548150777816772\n",
            "1.3128398656845093\n",
            "Epoch #1. Batch Id 168/278  is having validation accuracy of 56.87869822485207\n",
            "Epoch #1. Batch Id 169/278  is having validation loss of 1.6547330617904663\n",
            "1.640870213508606\n",
            "Epoch #1. Batch Id 169/278  is having validation accuracy of 56.9485294117647\n",
            "Epoch #1. Batch Id 170/278  is having validation loss of 1.6569687128067017\n",
            "2.037024974822998\n",
            "Epoch #1. Batch Id 170/278  is having validation accuracy of 56.9078947368421\n",
            "Epoch #1. Batch Id 171/278  is having validation loss of 1.659171223640442\n",
            "2.0358030796051025\n",
            "Epoch #1. Batch Id 171/278  is having validation accuracy of 56.84956395348837\n",
            "Epoch #1. Batch Id 172/278  is having validation loss of 1.6568019390106201\n",
            "1.2492855787277222\n",
            "Epoch #1. Batch Id 172/278  is having validation accuracy of 56.88222543352601\n",
            "Epoch #1. Batch Id 173/278  is having validation loss of 1.6556286811828613\n",
            "1.4526453018188477\n",
            "Epoch #1. Batch Id 173/278  is having validation accuracy of 56.91451149425287\n",
            "Epoch #1. Batch Id 174/278  is having validation loss of 1.657223105430603\n",
            "1.9346566200256348\n",
            "Epoch #1. Batch Id 174/278  is having validation accuracy of 56.910714285714285\n",
            "Epoch #1. Batch Id 175/278  is having validation loss of 1.65701162815094\n",
            "1.620010256767273\n",
            "Epoch #1. Batch Id 175/278  is having validation accuracy of 56.88920454545455\n",
            "Epoch #1. Batch Id 176/278  is having validation loss of 1.6562049388885498\n",
            "1.5142179727554321\n",
            "Epoch #1. Batch Id 176/278  is having validation accuracy of 56.938559322033896\n",
            "Epoch #1. Batch Id 177/278  is having validation loss of 1.656422734260559\n",
            "1.694973349571228\n",
            "Epoch #1. Batch Id 177/278  is having validation accuracy of 56.95224719101124\n",
            "Epoch #1. Batch Id 178/278  is having validation loss of 1.659826397895813\n",
            "2.265676498413086\n",
            "Epoch #1. Batch Id 178/278  is having validation accuracy of 56.80865921787709\n",
            "Epoch #1. Batch Id 179/278  is having validation loss of 1.6617013216018677\n",
            "1.9973232746124268\n",
            "Epoch #1. Batch Id 179/278  is having validation accuracy of 56.75347222222222\n",
            "Epoch #1. Batch Id 180/278  is having validation loss of 1.662161111831665\n",
            "1.7449270486831665\n",
            "Epoch #1. Batch Id 180/278  is having validation accuracy of 56.7506906077348\n",
            "Epoch #1. Batch Id 181/278  is having validation loss of 1.6614711284637451\n",
            "1.5365740060806274\n",
            "Epoch #1. Batch Id 181/278  is having validation accuracy of 56.74793956043956\n",
            "Epoch #1. Batch Id 182/278  is having validation loss of 1.6612701416015625\n",
            "1.6246848106384277\n",
            "Epoch #1. Batch Id 182/278  is having validation accuracy of 56.71106557377049\n",
            "Epoch #1. Batch Id 183/278  is having validation loss of 1.6631556749343872\n",
            "2.0082039833068848\n",
            "Epoch #1. Batch Id 183/278  is having validation accuracy of 56.65760869565217\n",
            "Epoch #1. Batch Id 184/278  is having validation loss of 1.6629024744033813\n",
            "1.616316556930542\n",
            "Epoch #1. Batch Id 184/278  is having validation accuracy of 56.6554054054054\n",
            "Epoch #1. Batch Id 185/278  is having validation loss of 1.6604928970336914\n",
            "1.2147274017333984\n",
            "Epoch #1. Batch Id 185/278  is having validation accuracy of 56.737231182795696\n",
            "Epoch #1. Batch Id 186/278  is having validation loss of 1.6601288318634033\n",
            "1.592405915260315\n",
            "Epoch #1. Batch Id 186/278  is having validation accuracy of 56.717914438502675\n",
            "Epoch #1. Batch Id 187/278  is having validation loss of 1.6588979959487915\n",
            "1.4287360906600952\n",
            "Epoch #1. Batch Id 187/278  is having validation accuracy of 56.74867021276596\n",
            "Epoch #1. Batch Id 188/278  is having validation loss of 1.6600086688995361\n",
            "1.8688056468963623\n",
            "Epoch #1. Batch Id 188/278  is having validation accuracy of 56.76256613756614\n",
            "Epoch #1. Batch Id 189/278  is having validation loss of 1.6579121351242065\n",
            "1.2616602182388306\n",
            "Epoch #1. Batch Id 189/278  is having validation accuracy of 56.8421052631579\n",
            "Epoch #1. Batch Id 190/278  is having validation loss of 1.6569114923477173\n",
            "1.4667835235595703\n",
            "Epoch #1. Batch Id 190/278  is having validation accuracy of 56.855366492146594\n",
            "Epoch #1. Batch Id 191/278  is having validation loss of 1.659278154373169\n",
            "2.111302137374878\n",
            "Epoch #1. Batch Id 191/278  is having validation accuracy of 56.787109375\n",
            "Epoch #1. Batch Id 192/278  is having validation loss of 1.6597837209701538\n",
            "1.7568503618240356\n",
            "Epoch #1. Batch Id 192/278  is having validation accuracy of 56.784326424870464\n",
            "Epoch #1. Batch Id 193/278  is having validation loss of 1.6610885858535767\n",
            "1.912933349609375\n",
            "Epoch #1. Batch Id 193/278  is having validation accuracy of 56.78157216494845\n",
            "Epoch #1. Batch Id 194/278  is having validation loss of 1.6611093282699585\n",
            "1.6651344299316406\n",
            "Epoch #1. Batch Id 194/278  is having validation accuracy of 56.77884615384615\n",
            "Epoch #1. Batch Id 195/278  is having validation loss of 1.6605321168899536\n",
            "1.5479663610458374\n",
            "Epoch #1. Batch Id 195/278  is having validation accuracy of 56.808035714285715\n",
            "Epoch #1. Batch Id 196/278  is having validation loss of 1.6610040664672852\n",
            "1.753510594367981\n",
            "Epoch #1. Batch Id 196/278  is having validation accuracy of 56.773477157360404\n",
            "Epoch #1. Batch Id 197/278  is having validation loss of 1.6608936786651611\n",
            "1.6391457319259644\n",
            "Epoch #1. Batch Id 197/278  is having validation accuracy of 56.770833333333336\n",
            "Epoch #1. Batch Id 198/278  is having validation loss of 1.6635081768035889\n",
            "2.18118953704834\n",
            "Epoch #1. Batch Id 198/278  is having validation accuracy of 56.73680904522613\n",
            "Epoch #1. Batch Id 199/278  is having validation loss of 1.6623984575271606\n",
            "1.441569447517395\n",
            "Epoch #1. Batch Id 199/278  is having validation accuracy of 56.75\n",
            "Epoch #1. Batch Id 200/278  is having validation loss of 1.664538860321045\n",
            "2.092630624771118\n",
            "Epoch #1. Batch Id 200/278  is having validation accuracy of 56.66977611940298\n",
            "Epoch #1. Batch Id 201/278  is having validation loss of 1.6635510921478271\n",
            "1.4650168418884277\n",
            "Epoch #1. Batch Id 201/278  is having validation accuracy of 56.72957920792079\n",
            "Epoch #1. Batch Id 202/278  is having validation loss of 1.6611781120300293\n",
            "1.1818262338638306\n",
            "Epoch #1. Batch Id 202/278  is having validation accuracy of 56.81958128078818\n",
            "Epoch #1. Batch Id 203/278  is having validation loss of 1.6612516641616821\n",
            "1.6761715412139893\n",
            "Epoch #1. Batch Id 203/278  is having validation accuracy of 56.8014705882353\n",
            "Epoch #1. Batch Id 204/278  is having validation loss of 1.6633168458938599\n",
            "2.0846235752105713\n",
            "Epoch #1. Batch Id 204/278  is having validation accuracy of 56.72256097560975\n",
            "Epoch #1. Batch Id 205/278  is having validation loss of 1.6632661819458008\n",
            "1.6528881788253784\n",
            "Epoch #1. Batch Id 205/278  is having validation accuracy of 56.6747572815534\n",
            "Epoch #1. Batch Id 206/278  is having validation loss of 1.6618419885635376\n",
            "1.368446707725525\n",
            "Epoch #1. Batch Id 206/278  is having validation accuracy of 56.71799516908212\n",
            "Epoch #1. Batch Id 207/278  is having validation loss of 1.661410927772522\n",
            "1.5721862316131592\n",
            "Epoch #1. Batch Id 207/278  is having validation accuracy of 56.71574519230769\n",
            "Epoch #1. Batch Id 208/278  is having validation loss of 1.662212610244751\n",
            "1.828956961631775\n",
            "Epoch #1. Batch Id 208/278  is having validation accuracy of 56.698564593301434\n",
            "Epoch #1. Batch Id 209/278  is having validation loss of 1.6624311208724976\n",
            "1.7081115245819092\n",
            "Epoch #1. Batch Id 209/278  is having validation accuracy of 56.63690476190476\n",
            "Epoch #1. Batch Id 210/278  is having validation loss of 1.66314697265625\n",
            "1.8134863376617432\n",
            "Epoch #1. Batch Id 210/278  is having validation accuracy of 56.63507109004739\n",
            "Epoch #1. Batch Id 211/278  is having validation loss of 1.6622178554534912\n",
            "1.4661729335784912\n",
            "Epoch #1. Batch Id 211/278  is having validation accuracy of 56.633254716981135\n",
            "Epoch #1. Batch Id 212/278  is having validation loss of 1.6629148721694946\n",
            "1.8106738328933716\n",
            "Epoch #1. Batch Id 212/278  is having validation accuracy of 56.63145539906103\n",
            "Epoch #1. Batch Id 213/278  is having validation loss of 1.6636005640029907\n",
            "1.8096543550491333\n",
            "Epoch #1. Batch Id 213/278  is having validation accuracy of 56.615070093457945\n",
            "Epoch #1. Batch Id 214/278  is having validation loss of 1.6642265319824219\n",
            "1.798190951347351\n",
            "Epoch #1. Batch Id 214/278  is having validation accuracy of 56.5843023255814\n",
            "Epoch #1. Batch Id 215/278  is having validation loss of 1.6654634475708008\n",
            "1.9314022064208984\n",
            "Epoch #1. Batch Id 215/278  is having validation accuracy of 56.495949074074076\n",
            "Epoch #1. Batch Id 216/278  is having validation loss of 1.666280746459961\n",
            "1.842829942703247\n",
            "Epoch #1. Batch Id 216/278  is having validation accuracy of 56.46601382488479\n",
            "Epoch #1. Batch Id 217/278  is having validation loss of 1.6658662557601929\n",
            "1.5759159326553345\n",
            "Epoch #1. Batch Id 217/278  is having validation accuracy of 56.50802752293578\n",
            "Epoch #1. Batch Id 218/278  is having validation loss of 1.6660817861557007\n",
            "1.7130781412124634\n",
            "Epoch #1. Batch Id 218/278  is having validation accuracy of 56.50684931506849\n",
            "Epoch #1. Batch Id 219/278  is having validation loss of 1.6658034324645996\n",
            "1.6048436164855957\n",
            "Epoch #1. Batch Id 219/278  is having validation accuracy of 56.53409090909091\n",
            "Epoch #1. Batch Id 220/278  is having validation loss of 1.6670058965682983\n",
            "1.9315459728240967\n",
            "Epoch #1. Batch Id 220/278  is having validation accuracy of 56.4762443438914\n",
            "Epoch #1. Batch Id 221/278  is having validation loss of 1.6669749021530151\n",
            "1.6601179838180542\n",
            "Epoch #1. Batch Id 221/278  is having validation accuracy of 56.47522522522522\n",
            "Epoch #1. Batch Id 222/278  is having validation loss of 1.6676961183547974\n",
            "1.827805519104004\n",
            "Epoch #1. Batch Id 222/278  is having validation accuracy of 56.446188340807176\n",
            "Epoch #1. Batch Id 223/278  is having validation loss of 1.6683404445648193\n",
            "1.8120371103286743\n",
            "Epoch #1. Batch Id 223/278  is having validation accuracy of 56.38950892857143\n",
            "Epoch #1. Batch Id 224/278  is having validation loss of 1.6692709922790527\n",
            "1.877705693244934\n",
            "Epoch #1. Batch Id 224/278  is having validation accuracy of 56.388888888888886\n",
            "Epoch #1. Batch Id 225/278  is having validation loss of 1.6691036224365234\n",
            "1.6314431428909302\n",
            "Epoch #1. Batch Id 225/278  is having validation accuracy of 56.37444690265487\n",
            "Epoch #1. Batch Id 226/278  is having validation loss of 1.6685353517532349\n",
            "1.5400996208190918\n",
            "Epoch #1. Batch Id 226/278  is having validation accuracy of 56.40143171806167\n",
            "Epoch #1. Batch Id 227/278  is having validation loss of 1.6700413227081299\n",
            "2.0119099617004395\n",
            "Epoch #1. Batch Id 227/278  is having validation accuracy of 56.40076754385965\n",
            "Epoch #1. Batch Id 228/278  is having validation loss of 1.6732364892959595\n",
            "2.4017319679260254\n",
            "Epoch #1. Batch Id 228/278  is having validation accuracy of 56.318231441048034\n",
            "Epoch #1. Batch Id 229/278  is having validation loss of 1.673000693321228\n",
            "1.6190115213394165\n",
            "Epoch #1. Batch Id 229/278  is having validation accuracy of 56.317934782608695\n",
            "Epoch #1. Batch Id 230/278  is having validation loss of 1.672600269317627\n",
            "1.5804952383041382\n",
            "Epoch #1. Batch Id 230/278  is having validation accuracy of 56.34469696969697\n",
            "Epoch #1. Batch Id 231/278  is having validation loss of 1.6747654676437378\n",
            "2.1749253273010254\n",
            "Epoch #1. Batch Id 231/278  is having validation accuracy of 56.31734913793103\n",
            "Epoch #1. Batch Id 232/278  is having validation loss of 1.676212191581726\n",
            "2.011840581893921\n",
            "Epoch #1. Batch Id 232/278  is having validation accuracy of 56.29023605150215\n",
            "Epoch #1. Batch Id 233/278  is having validation loss of 1.6751917600631714\n",
            "1.43741774559021\n",
            "Epoch #1. Batch Id 233/278  is having validation accuracy of 56.3034188034188\n",
            "Epoch #1. Batch Id 234/278  is having validation loss of 1.6737786531448364\n",
            "1.343116044998169\n",
            "Epoch #1. Batch Id 234/278  is having validation accuracy of 56.34308510638298\n",
            "Epoch #1. Batch Id 235/278  is having validation loss of 1.6761835813522339\n",
            "2.241351366043091\n",
            "Epoch #1. Batch Id 235/278  is having validation accuracy of 56.28972457627118\n",
            "Epoch #1. Batch Id 236/278  is having validation loss of 1.676439642906189\n",
            "1.7368669509887695\n",
            "Epoch #1. Batch Id 236/278  is having validation accuracy of 56.26318565400844\n",
            "Epoch #1. Batch Id 237/278  is having validation loss of 1.6764070987701416\n",
            "1.6686809062957764\n",
            "Epoch #1. Batch Id 237/278  is having validation accuracy of 56.289390756302524\n",
            "Epoch #1. Batch Id 238/278  is having validation loss of 1.675503134727478\n",
            "1.4603543281555176\n",
            "Epoch #1. Batch Id 238/278  is having validation accuracy of 56.26307531380753\n",
            "Epoch #1. Batch Id 239/278  is having validation loss of 1.6778779029846191\n",
            "2.245450973510742\n",
            "Epoch #1. Batch Id 239/278  is having validation accuracy of 56.158854166666664\n",
            "Epoch #1. Batch Id 240/278  is having validation loss of 1.676838755607605\n",
            "1.427451729774475\n",
            "Epoch #1. Batch Id 240/278  is having validation accuracy of 56.21109958506224\n",
            "Epoch #1. Batch Id 241/278  is having validation loss of 1.6775727272033691\n",
            "1.8544707298278809\n",
            "Epoch #1. Batch Id 241/278  is having validation accuracy of 56.19834710743802\n",
            "Epoch #1. Batch Id 242/278  is having validation loss of 1.6774564981460571\n",
            "1.6493356227874756\n",
            "Epoch #1. Batch Id 242/278  is having validation accuracy of 56.23713991769547\n",
            "Epoch #1. Batch Id 243/278  is having validation loss of 1.6758067607879639\n",
            "1.274906873703003\n",
            "Epoch #1. Batch Id 243/278  is having validation accuracy of 56.30122950819672\n",
            "Epoch #1. Batch Id 244/278  is having validation loss of 1.6763423681259155\n",
            "1.807039499282837\n",
            "Epoch #1. Batch Id 244/278  is having validation accuracy of 56.28826530612245\n",
            "Epoch #1. Batch Id 245/278  is having validation loss of 1.6787360906600952\n",
            "2.265193462371826\n",
            "Epoch #1. Batch Id 245/278  is having validation accuracy of 56.199186991869915\n",
            "Epoch #1. Batch Id 246/278  is having validation loss of 1.6801460981369019\n",
            "2.027020215988159\n",
            "Epoch #1. Batch Id 246/278  is having validation accuracy of 56.14878542510122\n",
            "Epoch #1. Batch Id 247/278  is having validation loss of 1.6813362836837769\n",
            "1.9753245115280151\n",
            "Epoch #1. Batch Id 247/278  is having validation accuracy of 56.08618951612903\n",
            "Epoch #1. Batch Id 248/278  is having validation loss of 1.6816520690917969\n",
            "1.7599666118621826\n",
            "Epoch #1. Batch Id 248/278  is having validation accuracy of 56.07429718875502\n",
            "Epoch #1. Batch Id 249/278  is having validation loss of 1.6817420721054077\n",
            "1.7041609287261963\n",
            "Epoch #1. Batch Id 249/278  is having validation accuracy of 56.1\n",
            "Epoch #1. Batch Id 250/278  is having validation loss of 1.6820703744888306\n",
            "1.7641481161117554\n",
            "Epoch #1. Batch Id 250/278  is having validation accuracy of 56.07569721115538\n",
            "Epoch #1. Batch Id 251/278  is having validation loss of 1.6841325759887695\n",
            "2.201754570007324\n",
            "Epoch #1. Batch Id 251/278  is having validation accuracy of 56.039186507936506\n",
            "Epoch #1. Batch Id 252/278  is having validation loss of 1.6843994855880737\n",
            "1.7516593933105469\n",
            "Epoch #1. Batch Id 252/278  is having validation accuracy of 56.05237154150198\n",
            "Epoch #1. Batch Id 253/278  is having validation loss of 1.6850913763046265\n",
            "1.860154390335083\n",
            "Epoch #1. Batch Id 253/278  is having validation accuracy of 56.028543307086615\n",
            "Epoch #1. Batch Id 254/278  is having validation loss of 1.6835986375808716\n",
            "1.3044352531433105\n",
            "Epoch #1. Batch Id 254/278  is having validation accuracy of 56.07843137254902\n",
            "Epoch #1. Batch Id 255/278  is having validation loss of 1.682542324066162\n",
            "1.4131689071655273\n",
            "Epoch #1. Batch Id 255/278  is having validation accuracy of 56.0791015625\n",
            "Epoch #1. Batch Id 256/278  is having validation loss of 1.6825511455535889\n",
            "1.684818983078003\n",
            "Epoch #1. Batch Id 256/278  is having validation accuracy of 56.07976653696498\n",
            "Epoch #1. Batch Id 257/278  is having validation loss of 1.6814219951629639\n",
            "1.391243577003479\n",
            "Epoch #1. Batch Id 257/278  is having validation accuracy of 56.116763565891475\n",
            "Epoch #1. Batch Id 258/278  is having validation loss of 1.682432770729065\n",
            "1.943205714225769\n",
            "Epoch #1. Batch Id 258/278  is having validation accuracy of 56.06901544401544\n",
            "Epoch #1. Batch Id 259/278  is having validation loss of 1.681361436843872\n",
            "1.4038784503936768\n",
            "Epoch #1. Batch Id 259/278  is having validation accuracy of 56.09375\n",
            "Epoch #1. Batch Id 260/278  is having validation loss of 1.6784844398498535\n",
            "0.9304643273353577\n",
            "Epoch #1. Batch Id 260/278  is having validation accuracy of 56.1661877394636\n",
            "Epoch #1. Batch Id 261/278  is having validation loss of 1.6777660846710205\n",
            "1.4902715682983398\n",
            "Epoch #1. Batch Id 261/278  is having validation accuracy of 56.19036259541985\n",
            "Epoch #1. Batch Id 262/278  is having validation loss of 1.6794897317886353\n",
            "2.1310925483703613\n",
            "Epoch #1. Batch Id 262/278  is having validation accuracy of 56.15494296577947\n",
            "Epoch #1. Batch Id 263/278  is having validation loss of 1.6794624328613281\n",
            "1.672278642654419\n",
            "Epoch #1. Batch Id 263/278  is having validation accuracy of 56.19081439393939\n",
            "Epoch #1. Batch Id 264/278  is having validation loss of 1.6782681941986084\n",
            "1.3629846572875977\n",
            "Epoch #1. Batch Id 264/278  is having validation accuracy of 56.214622641509436\n",
            "Epoch #1. Batch Id 265/278  is having validation loss of 1.6785329580307007\n",
            "1.7487026453018188\n",
            "Epoch #1. Batch Id 265/278  is having validation accuracy of 56.23825187969925\n",
            "Epoch #1. Batch Id 266/278  is having validation loss of 1.6776747703552246\n",
            "1.4493829011917114\n",
            "Epoch #1. Batch Id 266/278  is having validation accuracy of 56.27340823970037\n",
            "Epoch #1. Batch Id 267/278  is having validation loss of 1.6765373945236206\n",
            "1.3728504180908203\n",
            "Epoch #1. Batch Id 267/278  is having validation accuracy of 56.28498134328358\n",
            "Epoch #1. Batch Id 268/278  is having validation loss of 1.674889087677002\n",
            "1.2331383228302002\n",
            "Epoch #1. Batch Id 268/278  is having validation accuracy of 56.354553903345725\n",
            "Epoch #1. Batch Id 269/278  is having validation loss of 1.6736127138137817\n",
            "1.3302767276763916\n",
            "Epoch #1. Batch Id 269/278  is having validation accuracy of 56.40046296296296\n",
            "Epoch #1. Batch Id 270/278  is having validation loss of 1.6737899780273438\n",
            "1.721658706665039\n",
            "Epoch #1. Batch Id 270/278  is having validation accuracy of 56.388376383763834\n",
            "Epoch #1. Batch Id 271/278  is having validation loss of 1.674678921699524\n",
            "1.9155948162078857\n",
            "Epoch #1. Batch Id 271/278  is having validation accuracy of 56.37637867647059\n",
            "Epoch #1. Batch Id 272/278  is having validation loss of 1.675921082496643\n",
            "2.013787031173706\n",
            "Epoch #1. Batch Id 272/278  is having validation accuracy of 56.36446886446886\n",
            "Epoch #1. Batch Id 273/278  is having validation loss of 1.6775000095367432\n",
            "2.1085472106933594\n",
            "Epoch #1. Batch Id 273/278  is having validation accuracy of 56.30702554744526\n",
            "Epoch #1. Batch Id 274/278  is having validation loss of 1.676988124847412\n",
            "1.536725640296936\n",
            "Epoch #1. Batch Id 274/278  is having validation accuracy of 56.31818181818182\n",
            "Epoch #1. Batch Id 275/278  is having validation loss of 1.6775250434875488\n",
            "1.8251664638519287\n",
            "Epoch #1. Batch Id 275/278  is having validation accuracy of 56.28396739130435\n",
            "Epoch #1. Batch Id 276/278  is having validation loss of 1.6768499612808228\n",
            "1.4905263185501099\n",
            "Epoch #1. Batch Id 276/278  is having validation accuracy of 56.272563176895304\n",
            "Epoch #1. Batch Id 277/278  is having validation loss of 1.6713612079620361\n",
            "0.1509825885295868\n",
            "Epoch #1. Batch Id 277/278  is having validation accuracy of 56.282427250169185\n",
            "Эпоха #1 train_loss: 1.9849838281515986e-05, val_loss: 0.00018851355707738549\n",
            "Потрачено 27.1 минут на 1 эпоху\n",
            "Batch Id 0/2438 is having training loss of 1.386178731918335\n",
            "1.386178731918335\n",
            "Epoch #2. Accuracy on batch 0/2438  on Training is 68.75\n",
            "Epoch #2. Accuracy on batch 1/2438  on Training is 65.625\n",
            "Epoch #2. Accuracy on batch 2/2438  on Training is 65.625\n",
            "Epoch #2. Accuracy on batch 3/2438  on Training is 67.1875\n",
            "Epoch #2. Accuracy on batch 4/2438  on Training is 66.25\n",
            "Epoch #2. Accuracy on batch 5/2438  on Training is 64.0625\n",
            "Epoch #2. Accuracy on batch 6/2438  on Training is 65.17857142857143\n",
            "Epoch #2. Accuracy on batch 7/2438  on Training is 63.28125\n",
            "Epoch #2. Accuracy on batch 8/2438  on Training is 63.888888888888886\n",
            "Epoch #2. Accuracy on batch 9/2438  on Training is 62.8125\n",
            "Epoch #2. Accuracy on batch 10/2438  on Training is 64.20454545454545\n",
            "Epoch #2. Accuracy on batch 11/2438  on Training is 64.58333333333333\n",
            "Epoch #2. Accuracy on batch 12/2438  on Training is 64.66346153846153\n",
            "Epoch #2. Accuracy on batch 13/2438  on Training is 65.17857142857143\n",
            "Epoch #2. Accuracy on batch 14/2438  on Training is 64.58333333333333\n",
            "Epoch #2. Accuracy on batch 15/2438  on Training is 64.453125\n",
            "Epoch #2. Accuracy on batch 16/2438  on Training is 64.5220588235294\n",
            "Epoch #2. Accuracy on batch 17/2438  on Training is 65.10416666666667\n",
            "Epoch #2. Accuracy on batch 18/2438  on Training is 65.46052631578948\n",
            "Epoch #2. Accuracy on batch 19/2438  on Training is 65.3125\n",
            "Batch Id 20/2438 is having training loss of 1.4396741390228271\n",
            "1.8549007177352905\n",
            "Epoch #2. Accuracy on batch 20/2438  on Training is 65.0297619047619\n",
            "Epoch #2. Accuracy on batch 21/2438  on Training is 64.77272727272727\n",
            "Epoch #2. Accuracy on batch 22/2438  on Training is 64.80978260869566\n",
            "Epoch #2. Accuracy on batch 23/2438  on Training is 65.10416666666667\n",
            "Epoch #2. Accuracy on batch 24/2438  on Training is 64.875\n",
            "Epoch #2. Accuracy on batch 25/2438  on Training is 64.66346153846153\n",
            "Epoch #2. Accuracy on batch 26/2438  on Training is 64.35185185185185\n",
            "Epoch #2. Accuracy on batch 27/2438  on Training is 63.61607142857143\n",
            "Epoch #2. Accuracy on batch 28/2438  on Training is 63.03879310344828\n",
            "Epoch #2. Accuracy on batch 29/2438  on Training is 63.541666666666664\n",
            "Epoch #2. Accuracy on batch 30/2438  on Training is 63.104838709677416\n",
            "Epoch #2. Accuracy on batch 31/2438  on Training is 63.28125\n",
            "Epoch #2. Accuracy on batch 32/2438  on Training is 63.25757575757576\n",
            "Epoch #2. Accuracy on batch 33/2438  on Training is 63.419117647058826\n",
            "Epoch #2. Accuracy on batch 34/2438  on Training is 63.482142857142854\n",
            "Epoch #2. Accuracy on batch 35/2438  on Training is 63.454861111111114\n",
            "Epoch #2. Accuracy on batch 36/2438  on Training is 63.766891891891895\n",
            "Epoch #2. Accuracy on batch 37/2438  on Training is 63.32236842105263\n",
            "Epoch #2. Accuracy on batch 38/2438  on Training is 63.30128205128205\n",
            "Epoch #2. Accuracy on batch 39/2438  on Training is 63.4375\n",
            "Batch Id 40/2438 is having training loss of 1.4496855735778809\n",
            "1.2021639347076416\n",
            "Epoch #2. Accuracy on batch 40/2438  on Training is 63.71951219512195\n",
            "Epoch #2. Accuracy on batch 41/2438  on Training is 63.69047619047619\n",
            "Epoch #2. Accuracy on batch 42/2438  on Training is 63.80813953488372\n",
            "Epoch #2. Accuracy on batch 43/2438  on Training is 63.84943181818182\n",
            "Epoch #2. Accuracy on batch 44/2438  on Training is 63.611111111111114\n",
            "Epoch #2. Accuracy on batch 45/2438  on Training is 63.24728260869565\n",
            "Epoch #2. Accuracy on batch 46/2438  on Training is 63.16489361702128\n",
            "Epoch #2. Accuracy on batch 47/2438  on Training is 63.020833333333336\n",
            "Epoch #2. Accuracy on batch 48/2438  on Training is 62.691326530612244\n",
            "Epoch #2. Accuracy on batch 49/2438  on Training is 62.5\n",
            "Epoch #2. Accuracy on batch 50/2438  on Training is 62.745098039215684\n",
            "Epoch #2. Accuracy on batch 51/2438  on Training is 62.56009615384615\n",
            "Epoch #2. Accuracy on batch 52/2438  on Training is 62.617924528301884\n",
            "Epoch #2. Accuracy on batch 53/2438  on Training is 62.789351851851855\n",
            "Epoch #2. Accuracy on batch 54/2438  on Training is 62.5\n",
            "Epoch #2. Accuracy on batch 55/2438  on Training is 62.667410714285715\n",
            "Epoch #2. Accuracy on batch 56/2438  on Training is 62.5\n",
            "Epoch #2. Accuracy on batch 57/2438  on Training is 62.60775862068966\n",
            "Epoch #2. Accuracy on batch 58/2438  on Training is 62.817796610169495\n",
            "Epoch #2. Accuracy on batch 59/2438  on Training is 62.96875\n",
            "Batch Id 60/2438 is having training loss of 1.429580569267273\n",
            "1.1124831438064575\n",
            "Epoch #2. Accuracy on batch 60/2438  on Training is 63.06352459016394\n",
            "Epoch #2. Accuracy on batch 61/2438  on Training is 62.600806451612904\n",
            "Epoch #2. Accuracy on batch 62/2438  on Training is 62.351190476190474\n",
            "Epoch #2. Accuracy on batch 63/2438  on Training is 62.158203125\n",
            "Epoch #2. Accuracy on batch 64/2438  on Training is 62.5\n",
            "Epoch #2. Accuracy on batch 65/2438  on Training is 62.547348484848484\n",
            "Epoch #2. Accuracy on batch 66/2438  on Training is 62.6865671641791\n",
            "Epoch #2. Accuracy on batch 67/2438  on Training is 62.775735294117645\n",
            "Epoch #2. Accuracy on batch 68/2438  on Training is 62.81702898550725\n",
            "Epoch #2. Accuracy on batch 69/2438  on Training is 62.67857142857143\n",
            "Epoch #2. Accuracy on batch 70/2438  on Training is 62.67605633802817\n",
            "Epoch #2. Accuracy on batch 71/2438  on Training is 62.673611111111114\n",
            "Epoch #2. Accuracy on batch 72/2438  on Training is 62.58561643835616\n",
            "Epoch #2. Accuracy on batch 73/2438  on Training is 62.795608108108105\n",
            "Epoch #2. Accuracy on batch 74/2438  on Training is 62.75\n",
            "Epoch #2. Accuracy on batch 75/2438  on Training is 62.870065789473685\n",
            "Epoch #2. Accuracy on batch 76/2438  on Training is 62.90584415584416\n",
            "Epoch #2. Accuracy on batch 77/2438  on Training is 62.780448717948715\n",
            "Epoch #2. Accuracy on batch 78/2438  on Training is 62.776898734177216\n",
            "Epoch #2. Accuracy on batch 79/2438  on Training is 62.6953125\n",
            "Batch Id 80/2438 is having training loss of 1.436138391494751\n",
            "1.207322597503662\n",
            "Epoch #2. Accuracy on batch 80/2438  on Training is 62.80864197530864\n",
            "Epoch #2. Accuracy on batch 81/2438  on Training is 62.88109756097561\n",
            "Epoch #2. Accuracy on batch 82/2438  on Training is 62.80120481927711\n",
            "Epoch #2. Accuracy on batch 83/2438  on Training is 62.94642857142857\n",
            "Epoch #2. Accuracy on batch 84/2438  on Training is 63.1985294117647\n",
            "Epoch #2. Accuracy on batch 85/2438  on Training is 63.22674418604651\n",
            "Epoch #2. Accuracy on batch 86/2438  on Training is 63.2183908045977\n",
            "Epoch #2. Accuracy on batch 87/2438  on Training is 63.21022727272727\n",
            "Epoch #2. Accuracy on batch 88/2438  on Training is 63.16713483146067\n",
            "Epoch #2. Accuracy on batch 89/2438  on Training is 63.19444444444444\n",
            "Epoch #2. Accuracy on batch 90/2438  on Training is 63.22115384615385\n",
            "Epoch #2. Accuracy on batch 91/2438  on Training is 63.11141304347826\n",
            "Epoch #2. Accuracy on batch 92/2438  on Training is 62.93682795698925\n",
            "Epoch #2. Accuracy on batch 93/2438  on Training is 62.99867021276596\n",
            "Epoch #2. Accuracy on batch 94/2438  on Training is 63.026315789473685\n",
            "Epoch #2. Accuracy on batch 95/2438  on Training is 63.053385416666664\n",
            "Epoch #2. Accuracy on batch 96/2438  on Training is 63.11211340206186\n",
            "Epoch #2. Accuracy on batch 97/2438  on Training is 63.01020408163265\n",
            "Epoch #2. Accuracy on batch 98/2438  on Training is 62.94191919191919\n",
            "Epoch #2. Accuracy on batch 99/2438  on Training is 62.875\n",
            "Batch Id 100/2438 is having training loss of 1.430827021598816\n",
            "1.6400173902511597\n",
            "Epoch #2. Accuracy on batch 100/2438  on Training is 62.74752475247525\n",
            "Epoch #2. Accuracy on batch 101/2438  on Training is 62.68382352941177\n",
            "Epoch #2. Accuracy on batch 102/2438  on Training is 62.682038834951456\n",
            "Epoch #2. Accuracy on batch 103/2438  on Training is 62.40985576923077\n",
            "Epoch #2. Accuracy on batch 104/2438  on Training is 62.529761904761905\n",
            "Epoch #2. Accuracy on batch 105/2438  on Training is 62.529481132075475\n",
            "Epoch #2. Accuracy on batch 106/2438  on Training is 62.529205607476634\n",
            "Epoch #2. Accuracy on batch 107/2438  on Training is 62.52893518518518\n",
            "Epoch #2. Accuracy on batch 108/2438  on Training is 62.55733944954128\n",
            "Epoch #2. Accuracy on batch 109/2438  on Training is 62.64204545454545\n",
            "Epoch #2. Accuracy on batch 110/2438  on Training is 62.556306306306304\n",
            "Epoch #2. Accuracy on batch 111/2438  on Training is 62.6953125\n",
            "Epoch #2. Accuracy on batch 112/2438  on Training is 62.665929203539825\n",
            "Epoch #2. Accuracy on batch 113/2438  on Training is 62.637061403508774\n",
            "Epoch #2. Accuracy on batch 114/2438  on Training is 62.608695652173914\n",
            "Epoch #2. Accuracy on batch 115/2438  on Training is 62.6885775862069\n",
            "Epoch #2. Accuracy on batch 116/2438  on Training is 62.82051282051282\n",
            "Epoch #2. Accuracy on batch 117/2438  on Training is 62.817796610169495\n",
            "Epoch #2. Accuracy on batch 118/2438  on Training is 62.84138655462185\n",
            "Epoch #2. Accuracy on batch 119/2438  on Training is 62.8125\n",
            "Batch Id 120/2438 is having training loss of 1.4245598316192627\n",
            "1.452193021774292\n",
            "Epoch #2. Accuracy on batch 120/2438  on Training is 62.8099173553719\n",
            "Epoch #2. Accuracy on batch 121/2438  on Training is 62.85860655737705\n",
            "Epoch #2. Accuracy on batch 122/2438  on Training is 62.93191056910569\n",
            "Epoch #2. Accuracy on batch 123/2438  on Training is 62.80241935483871\n",
            "Epoch #2. Accuracy on batch 124/2438  on Training is 62.825\n",
            "Epoch #2. Accuracy on batch 125/2438  on Training is 62.82242063492063\n",
            "Epoch #2. Accuracy on batch 126/2438  on Training is 62.89370078740158\n",
            "Epoch #2. Accuracy on batch 127/2438  on Training is 62.890625\n",
            "Epoch #2. Accuracy on batch 128/2438  on Training is 63.008720930232556\n",
            "Epoch #2. Accuracy on batch 129/2438  on Training is 63.00480769230769\n",
            "Epoch #2. Accuracy on batch 130/2438  on Training is 63.0486641221374\n",
            "Epoch #2. Accuracy on batch 131/2438  on Training is 63.13920454545455\n",
            "Epoch #2. Accuracy on batch 132/2438  on Training is 63.1109022556391\n",
            "Epoch #2. Accuracy on batch 133/2438  on Training is 63.17630597014925\n",
            "Epoch #2. Accuracy on batch 134/2438  on Training is 63.333333333333336\n",
            "Epoch #2. Accuracy on batch 135/2438  on Training is 63.32720588235294\n",
            "Epoch #2. Accuracy on batch 136/2438  on Training is 63.32116788321168\n",
            "Epoch #2. Accuracy on batch 137/2438  on Training is 63.36050724637681\n",
            "Epoch #2. Accuracy on batch 138/2438  on Training is 63.3318345323741\n",
            "Epoch #2. Accuracy on batch 139/2438  on Training is 63.28125\n",
            "Batch Id 140/2438 is having training loss of 1.4270002841949463\n",
            "1.6212568283081055\n",
            "Epoch #2. Accuracy on batch 140/2438  on Training is 63.2313829787234\n",
            "Epoch #2. Accuracy on batch 141/2438  on Training is 63.27024647887324\n",
            "Epoch #2. Accuracy on batch 142/2438  on Training is 63.35227272727273\n",
            "Epoch #2. Accuracy on batch 143/2438  on Training is 63.259548611111114\n",
            "Epoch #2. Accuracy on batch 144/2438  on Training is 63.31896551724138\n",
            "Epoch #2. Accuracy on batch 145/2438  on Training is 63.35616438356164\n",
            "Epoch #2. Accuracy on batch 146/2438  on Training is 63.392857142857146\n",
            "Epoch #2. Accuracy on batch 147/2438  on Training is 63.36570945945946\n",
            "Epoch #2. Accuracy on batch 148/2438  on Training is 63.33892617449664\n",
            "Epoch #2. Accuracy on batch 149/2438  on Training is 63.354166666666664\n",
            "Epoch #2. Accuracy on batch 150/2438  on Training is 63.431291390728475\n",
            "Epoch #2. Accuracy on batch 151/2438  on Training is 63.50740131578947\n",
            "Epoch #2. Accuracy on batch 152/2438  on Training is 63.56209150326797\n",
            "Epoch #2. Accuracy on batch 153/2438  on Training is 63.59577922077922\n",
            "Epoch #2. Accuracy on batch 154/2438  on Training is 63.568548387096776\n",
            "Epoch #2. Accuracy on batch 155/2438  on Training is 63.64182692307692\n",
            "Epoch #2. Accuracy on batch 156/2438  on Training is 63.515127388535035\n",
            "Epoch #2. Accuracy on batch 157/2438  on Training is 63.50870253164557\n",
            "Epoch #2. Accuracy on batch 158/2438  on Training is 63.56132075471698\n",
            "Epoch #2. Accuracy on batch 159/2438  on Training is 63.4765625\n",
            "Batch Id 160/2438 is having training loss of 1.4219413995742798\n",
            "1.541778564453125\n",
            "Epoch #2. Accuracy on batch 160/2438  on Training is 63.412267080745345\n",
            "Epoch #2. Accuracy on batch 161/2438  on Training is 63.40663580246913\n",
            "Epoch #2. Accuracy on batch 162/2438  on Training is 63.43941717791411\n",
            "Epoch #2. Accuracy on batch 163/2438  on Training is 63.395579268292686\n",
            "Epoch #2. Accuracy on batch 164/2438  on Training is 63.27651515151515\n",
            "Epoch #2. Accuracy on batch 165/2438  on Training is 63.29066265060241\n",
            "Epoch #2. Accuracy on batch 166/2438  on Training is 63.37949101796407\n",
            "Epoch #2. Accuracy on batch 167/2438  on Training is 63.35565476190476\n",
            "Epoch #2. Accuracy on batch 168/2438  on Training is 63.35059171597633\n",
            "Epoch #2. Accuracy on batch 169/2438  on Training is 63.32720588235294\n",
            "Epoch #2. Accuracy on batch 170/2438  on Training is 63.32236842105263\n",
            "Epoch #2. Accuracy on batch 171/2438  on Training is 63.372093023255815\n",
            "Epoch #2. Accuracy on batch 172/2438  on Training is 63.38511560693642\n",
            "Epoch #2. Accuracy on batch 173/2438  on Training is 63.39798850574713\n",
            "Epoch #2. Accuracy on batch 174/2438  on Training is 63.410714285714285\n",
            "Epoch #2. Accuracy on batch 175/2438  on Training is 63.33451704545455\n",
            "Epoch #2. Accuracy on batch 176/2438  on Training is 63.29449152542373\n",
            "Epoch #2. Accuracy on batch 177/2438  on Training is 63.2373595505618\n",
            "Epoch #2. Accuracy on batch 178/2438  on Training is 63.30307262569833\n",
            "Epoch #2. Accuracy on batch 179/2438  on Training is 63.19444444444444\n",
            "Batch Id 180/2438 is having training loss of 1.4258090257644653\n",
            "1.1679273843765259\n",
            "Epoch #2. Accuracy on batch 180/2438  on Training is 63.25966850828729\n",
            "Epoch #2. Accuracy on batch 181/2438  on Training is 63.255494505494504\n",
            "Epoch #2. Accuracy on batch 182/2438  on Training is 63.25136612021858\n",
            "Epoch #2. Accuracy on batch 183/2438  on Training is 63.213315217391305\n",
            "Epoch #2. Accuracy on batch 184/2438  on Training is 63.226351351351354\n",
            "Epoch #2. Accuracy on batch 185/2438  on Training is 63.222446236559136\n",
            "Epoch #2. Accuracy on batch 186/2438  on Training is 63.218582887700535\n",
            "Epoch #2. Accuracy on batch 187/2438  on Training is 63.19813829787234\n",
            "Epoch #2. Accuracy on batch 188/2438  on Training is 63.210978835978835\n",
            "Epoch #2. Accuracy on batch 189/2438  on Training is 63.24013157894737\n",
            "Epoch #2. Accuracy on batch 190/2438  on Training is 63.20353403141361\n",
            "Epoch #2. Accuracy on batch 191/2438  on Training is 63.232421875\n",
            "Epoch #2. Accuracy on batch 192/2438  on Training is 63.29339378238342\n",
            "Epoch #2. Accuracy on batch 193/2438  on Training is 63.28930412371134\n",
            "Epoch #2. Accuracy on batch 194/2438  on Training is 63.31730769230769\n",
            "Epoch #2. Accuracy on batch 195/2438  on Training is 63.28125\n",
            "Epoch #2. Accuracy on batch 196/2438  on Training is 63.29314720812183\n",
            "Epoch #2. Accuracy on batch 197/2438  on Training is 63.27335858585859\n",
            "Epoch #2. Accuracy on batch 198/2438  on Training is 63.26947236180904\n",
            "Epoch #2. Accuracy on batch 199/2438  on Training is 63.328125\n",
            "Batch Id 200/2438 is having training loss of 1.421285629272461\n",
            "1.3908514976501465\n",
            "Epoch #2. Accuracy on batch 200/2438  on Training is 63.292910447761194\n",
            "Epoch #2. Accuracy on batch 201/2438  on Training is 63.273514851485146\n",
            "Epoch #2. Accuracy on batch 202/2438  on Training is 63.33128078817734\n",
            "Epoch #2. Accuracy on batch 203/2438  on Training is 63.34252450980392\n",
            "Epoch #2. Accuracy on batch 204/2438  on Training is 63.323170731707314\n",
            "Epoch #2. Accuracy on batch 205/2438  on Training is 63.304004854368934\n",
            "Epoch #2. Accuracy on batch 206/2438  on Training is 63.3756038647343\n",
            "Epoch #2. Accuracy on batch 207/2438  on Training is 63.41646634615385\n",
            "Epoch #2. Accuracy on batch 208/2438  on Training is 63.427033492822964\n",
            "Epoch #2. Accuracy on batch 209/2438  on Training is 63.42261904761905\n",
            "Epoch #2. Accuracy on batch 210/2438  on Training is 63.41824644549763\n",
            "Epoch #2. Accuracy on batch 211/2438  on Training is 63.443396226415096\n",
            "Epoch #2. Accuracy on batch 212/2438  on Training is 63.409624413145536\n",
            "Epoch #2. Accuracy on batch 213/2438  on Training is 63.46378504672897\n",
            "Epoch #2. Accuracy on batch 214/2438  on Training is 63.473837209302324\n",
            "Epoch #2. Accuracy on batch 215/2438  on Training is 63.527199074074076\n",
            "Epoch #2. Accuracy on batch 216/2438  on Training is 63.47926267281106\n",
            "Epoch #2. Accuracy on batch 217/2438  on Training is 63.50344036697248\n",
            "Epoch #2. Accuracy on batch 218/2438  on Training is 63.49885844748859\n",
            "Epoch #2. Accuracy on batch 219/2438  on Training is 63.49431818181818\n",
            "Batch Id 220/2438 is having training loss of 1.412743330001831\n",
            "0.9255169630050659\n",
            "Epoch #2. Accuracy on batch 220/2438  on Training is 63.588800904977376\n",
            "Epoch #2. Accuracy on batch 221/2438  on Training is 63.597972972972975\n",
            "Epoch #2. Accuracy on batch 222/2438  on Training is 63.63508968609865\n",
            "Epoch #2. Accuracy on batch 223/2438  on Training is 63.602120535714285\n",
            "Epoch #2. Accuracy on batch 224/2438  on Training is 63.55555555555556\n",
            "Epoch #2. Accuracy on batch 225/2438  on Training is 63.50940265486726\n",
            "Epoch #2. Accuracy on batch 226/2438  on Training is 63.422356828193834\n",
            "Epoch #2. Accuracy on batch 227/2438  on Training is 63.37719298245614\n",
            "Epoch #2. Accuracy on batch 228/2438  on Training is 63.40065502183406\n",
            "Epoch #2. Accuracy on batch 229/2438  on Training is 63.369565217391305\n",
            "Epoch #2. Accuracy on batch 230/2438  on Training is 63.32521645021645\n",
            "Epoch #2. Accuracy on batch 231/2438  on Training is 63.28125\n",
            "Epoch #2. Accuracy on batch 232/2438  on Training is 63.26448497854077\n",
            "Epoch #2. Accuracy on batch 233/2438  on Training is 63.28792735042735\n",
            "Epoch #2. Accuracy on batch 234/2438  on Training is 63.27127659574468\n",
            "Epoch #2. Accuracy on batch 235/2438  on Training is 63.26800847457627\n",
            "Epoch #2. Accuracy on batch 236/2438  on Training is 63.25158227848101\n",
            "Epoch #2. Accuracy on batch 237/2438  on Training is 63.2484243697479\n",
            "Epoch #2. Accuracy on batch 238/2438  on Training is 63.25836820083682\n",
            "Epoch #2. Accuracy on batch 239/2438  on Training is 63.294270833333336\n",
            "Batch Id 240/2438 is having training loss of 1.4165068864822388\n",
            "1.090330958366394\n",
            "Epoch #2. Accuracy on batch 240/2438  on Training is 63.329875518672196\n",
            "Epoch #2. Accuracy on batch 241/2438  on Training is 63.391012396694215\n",
            "Epoch #2. Accuracy on batch 242/2438  on Training is 63.32304526748971\n",
            "Epoch #2. Accuracy on batch 243/2438  on Training is 63.29405737704918\n",
            "Epoch #2. Accuracy on batch 244/2438  on Training is 63.316326530612244\n",
            "Epoch #2. Accuracy on batch 245/2438  on Training is 63.30030487804878\n",
            "Epoch #2. Accuracy on batch 246/2438  on Training is 63.25910931174089\n",
            "Epoch #2. Accuracy on batch 247/2438  on Training is 63.23084677419355\n",
            "Epoch #2. Accuracy on batch 248/2438  on Training is 63.25301204819277\n",
            "Epoch #2. Accuracy on batch 249/2438  on Training is 63.2375\n",
            "Epoch #2. Accuracy on batch 250/2438  on Training is 63.2843625498008\n",
            "Epoch #2. Accuracy on batch 251/2438  on Training is 63.30605158730159\n",
            "Epoch #2. Accuracy on batch 252/2438  on Training is 63.3399209486166\n",
            "Epoch #2. Accuracy on batch 253/2438  on Training is 63.348917322834644\n",
            "Epoch #2. Accuracy on batch 254/2438  on Training is 63.333333333333336\n",
            "Epoch #2. Accuracy on batch 255/2438  on Training is 63.34228515625\n",
            "Epoch #2. Accuracy on batch 256/2438  on Training is 63.3511673151751\n",
            "Epoch #2. Accuracy on batch 257/2438  on Training is 63.32364341085271\n",
            "Epoch #2. Accuracy on batch 258/2438  on Training is 63.32046332046332\n",
            "Epoch #2. Accuracy on batch 259/2438  on Training is 63.34134615384615\n",
            "Batch Id 260/2438 is having training loss of 1.4210667610168457\n",
            "2.1462786197662354\n",
            "Epoch #2. Accuracy on batch 260/2438  on Training is 63.24233716475096\n",
            "Epoch #2. Accuracy on batch 261/2438  on Training is 63.25143129770992\n",
            "Epoch #2. Accuracy on batch 262/2438  on Training is 63.29610266159696\n",
            "Epoch #2. Accuracy on batch 263/2438  on Training is 63.269412878787875\n",
            "Epoch #2. Accuracy on batch 264/2438  on Training is 63.278301886792455\n",
            "Epoch #2. Accuracy on batch 265/2438  on Training is 63.275375939849624\n",
            "Epoch #2. Accuracy on batch 266/2438  on Training is 63.30758426966292\n",
            "Epoch #2. Accuracy on batch 267/2438  on Training is 63.33955223880597\n",
            "Epoch #2. Accuracy on batch 268/2438  on Training is 63.38289962825279\n",
            "Epoch #2. Accuracy on batch 269/2438  on Training is 63.379629629629626\n",
            "Epoch #2. Accuracy on batch 270/2438  on Training is 63.353321033210335\n",
            "Epoch #2. Accuracy on batch 271/2438  on Training is 63.32720588235294\n",
            "Epoch #2. Accuracy on batch 272/2438  on Training is 63.392857142857146\n",
            "Epoch #2. Accuracy on batch 273/2438  on Training is 63.42381386861314\n",
            "Epoch #2. Accuracy on batch 274/2438  on Training is 63.44318181818182\n",
            "Epoch #2. Accuracy on batch 275/2438  on Training is 63.45108695652174\n",
            "Epoch #2. Accuracy on batch 276/2438  on Training is 63.45893501805054\n",
            "Epoch #2. Accuracy on batch 277/2438  on Training is 63.410521582733814\n",
            "Epoch #2. Accuracy on batch 278/2438  on Training is 63.373655913978496\n",
            "Epoch #2. Accuracy on batch 279/2438  on Training is 63.41517857142857\n",
            "Batch Id 280/2438 is having training loss of 1.4171704053878784\n",
            "2.320178747177124\n",
            "Epoch #2. Accuracy on batch 280/2438  on Training is 63.33407473309609\n",
            "Epoch #2. Accuracy on batch 281/2438  on Training is 63.34219858156028\n",
            "Epoch #2. Accuracy on batch 282/2438  on Training is 63.350265017667844\n",
            "Epoch #2. Accuracy on batch 283/2438  on Training is 63.36927816901409\n",
            "Epoch #2. Accuracy on batch 284/2438  on Training is 63.32236842105263\n",
            "Epoch #2. Accuracy on batch 285/2438  on Training is 63.35227272727273\n",
            "Epoch #2. Accuracy on batch 286/2438  on Training is 63.33841463414634\n",
            "Epoch #2. Accuracy on batch 287/2438  on Training is 63.37890625\n",
            "Epoch #2. Accuracy on batch 288/2438  on Training is 63.397491349480966\n",
            "Epoch #2. Accuracy on batch 289/2438  on Training is 63.394396551724135\n",
            "Epoch #2. Accuracy on batch 290/2438  on Training is 63.402061855670105\n",
            "Epoch #2. Accuracy on batch 291/2438  on Training is 63.43107876712329\n",
            "Epoch #2. Accuracy on batch 292/2438  on Training is 63.44923208191126\n",
            "Epoch #2. Accuracy on batch 293/2438  on Training is 63.44600340136054\n",
            "Epoch #2. Accuracy on batch 294/2438  on Training is 63.442796610169495\n",
            "Epoch #2. Accuracy on batch 295/2438  on Training is 63.439611486486484\n",
            "Epoch #2. Accuracy on batch 296/2438  on Training is 63.40488215488215\n",
            "Epoch #2. Accuracy on batch 297/2438  on Training is 63.43330536912752\n",
            "Epoch #2. Accuracy on batch 298/2438  on Training is 63.45108695652174\n",
            "Epoch #2. Accuracy on batch 299/2438  on Training is 63.427083333333336\n",
            "Batch Id 300/2438 is having training loss of 1.416203260421753\n",
            "1.2606730461120605\n",
            "Epoch #2. Accuracy on batch 300/2438  on Training is 63.42400332225914\n",
            "Epoch #2. Accuracy on batch 301/2438  on Training is 63.42094370860927\n",
            "Epoch #2. Accuracy on batch 302/2438  on Training is 63.40759075907591\n",
            "Epoch #2. Accuracy on batch 303/2438  on Training is 63.42516447368421\n",
            "Epoch #2. Accuracy on batch 304/2438  on Training is 63.46311475409836\n",
            "Epoch #2. Accuracy on batch 305/2438  on Training is 63.439542483660134\n",
            "Epoch #2. Accuracy on batch 306/2438  on Training is 63.45684039087948\n",
            "Epoch #2. Accuracy on batch 307/2438  on Training is 63.43344155844156\n",
            "Epoch #2. Accuracy on batch 308/2438  on Training is 63.41019417475728\n",
            "Epoch #2. Accuracy on batch 309/2438  on Training is 63.4375\n",
            "Epoch #2. Accuracy on batch 310/2438  on Training is 63.45458199356913\n",
            "Epoch #2. Accuracy on batch 311/2438  on Training is 63.48157051282051\n",
            "Epoch #2. Accuracy on batch 312/2438  on Training is 63.468450479233226\n",
            "Epoch #2. Accuracy on batch 313/2438  on Training is 63.47531847133758\n",
            "Epoch #2. Accuracy on batch 314/2438  on Training is 63.432539682539684\n",
            "Epoch #2. Accuracy on batch 315/2438  on Training is 63.45925632911393\n",
            "Epoch #2. Accuracy on batch 316/2438  on Training is 63.49566246056782\n",
            "Epoch #2. Accuracy on batch 317/2438  on Training is 63.5121855345912\n",
            "Epoch #2. Accuracy on batch 318/2438  on Training is 63.51880877742947\n",
            "Epoch #2. Accuracy on batch 319/2438  on Training is 63.505859375\n",
            "Batch Id 320/2438 is having training loss of 1.4195334911346436\n",
            "1.7253361940383911\n",
            "Epoch #2. Accuracy on batch 320/2438  on Training is 63.51246105919003\n",
            "Epoch #2. Accuracy on batch 321/2438  on Training is 63.50931677018634\n",
            "Epoch #2. Accuracy on batch 322/2438  on Training is 63.5061919504644\n",
            "Epoch #2. Accuracy on batch 323/2438  on Training is 63.4837962962963\n",
            "Epoch #2. Accuracy on batch 324/2438  on Training is 63.49038461538461\n",
            "Epoch #2. Accuracy on batch 325/2438  on Training is 63.468174846625764\n",
            "Epoch #2. Accuracy on batch 326/2438  on Training is 63.50344036697248\n",
            "Epoch #2. Accuracy on batch 327/2438  on Training is 63.53849085365854\n",
            "Epoch #2. Accuracy on batch 328/2438  on Training is 63.55433130699088\n",
            "Epoch #2. Accuracy on batch 329/2438  on Training is 63.52272727272727\n",
            "Epoch #2. Accuracy on batch 330/2438  on Training is 63.51963746223565\n",
            "Epoch #2. Accuracy on batch 331/2438  on Training is 63.53539156626506\n",
            "Epoch #2. Accuracy on batch 332/2438  on Training is 63.551051051051054\n",
            "Epoch #2. Accuracy on batch 333/2438  on Training is 63.50112275449102\n",
            "Epoch #2. Accuracy on batch 334/2438  on Training is 63.507462686567166\n",
            "Epoch #2. Accuracy on batch 335/2438  on Training is 63.55096726190476\n",
            "Epoch #2. Accuracy on batch 336/2438  on Training is 63.538575667655785\n",
            "Epoch #2. Accuracy on batch 337/2438  on Training is 63.48002958579882\n",
            "Epoch #2. Accuracy on batch 338/2438  on Training is 63.44948377581121\n",
            "Epoch #2. Accuracy on batch 339/2438  on Training is 63.48345588235294\n",
            "Batch Id 340/2438 is having training loss of 1.4231573343276978\n",
            "1.6763360500335693\n",
            "Epoch #2. Accuracy on batch 340/2438  on Training is 63.45307917888563\n",
            "Epoch #2. Accuracy on batch 341/2438  on Training is 63.44115497076023\n",
            "Epoch #2. Accuracy on batch 342/2438  on Training is 63.46574344023323\n",
            "Epoch #2. Accuracy on batch 343/2438  on Training is 63.48110465116279\n",
            "Epoch #2. Accuracy on batch 344/2438  on Training is 63.4963768115942\n",
            "Epoch #2. Accuracy on batch 345/2438  on Training is 63.51156069364162\n",
            "Epoch #2. Accuracy on batch 346/2438  on Training is 63.52665706051873\n",
            "Epoch #2. Accuracy on batch 347/2438  on Training is 63.52370689655172\n",
            "Epoch #2. Accuracy on batch 348/2438  on Training is 63.51181948424069\n",
            "Epoch #2. Accuracy on batch 349/2438  on Training is 63.544642857142854\n",
            "Epoch #2. Accuracy on batch 350/2438  on Training is 63.550569800569804\n",
            "Epoch #2. Accuracy on batch 351/2438  on Training is 63.56534090909091\n",
            "Epoch #2. Accuracy on batch 352/2438  on Training is 63.56232294617564\n",
            "Epoch #2. Accuracy on batch 353/2438  on Training is 63.585805084745765\n",
            "Epoch #2. Accuracy on batch 354/2438  on Training is 63.58274647887324\n",
            "Epoch #2. Accuracy on batch 355/2438  on Training is 63.58848314606742\n",
            "Epoch #2. Accuracy on batch 356/2438  on Training is 63.57668067226891\n",
            "Epoch #2. Accuracy on batch 357/2438  on Training is 63.59986033519553\n",
            "Epoch #2. Accuracy on batch 358/2438  on Training is 63.59679665738162\n",
            "Epoch #2. Accuracy on batch 359/2438  on Training is 63.619791666666664\n",
            "Batch Id 360/2438 is having training loss of 1.415611743927002\n",
            "0.9313530921936035\n",
            "Epoch #2. Accuracy on batch 360/2438  on Training is 63.66862880886426\n",
            "Epoch #2. Accuracy on batch 361/2438  on Training is 63.66540055248619\n",
            "Epoch #2. Accuracy on batch 362/2438  on Training is 63.69662534435262\n",
            "Epoch #2. Accuracy on batch 363/2438  on Training is 63.70192307692308\n",
            "Epoch #2. Accuracy on batch 364/2438  on Training is 63.715753424657535\n",
            "Epoch #2. Accuracy on batch 365/2438  on Training is 63.72096994535519\n",
            "Epoch #2. Accuracy on batch 366/2438  on Training is 63.76021798365122\n",
            "Epoch #2. Accuracy on batch 367/2438  on Training is 63.78226902173913\n",
            "Epoch #2. Accuracy on batch 368/2438  on Training is 63.795731707317074\n",
            "Epoch #2. Accuracy on batch 369/2438  on Training is 63.817567567567565\n",
            "Epoch #2. Accuracy on batch 370/2438  on Training is 63.82243935309973\n",
            "Epoch #2. Accuracy on batch 371/2438  on Training is 63.81888440860215\n",
            "Epoch #2. Accuracy on batch 372/2438  on Training is 63.81534852546917\n",
            "Epoch #2. Accuracy on batch 373/2438  on Training is 63.836898395721924\n",
            "Epoch #2. Accuracy on batch 374/2438  on Training is 63.825\n",
            "Epoch #2. Accuracy on batch 375/2438  on Training is 63.80485372340426\n",
            "Epoch #2. Accuracy on batch 376/2438  on Training is 63.759946949602124\n",
            "Epoch #2. Accuracy on batch 377/2438  on Training is 63.78141534391534\n",
            "Epoch #2. Accuracy on batch 378/2438  on Training is 63.79452506596306\n",
            "Epoch #2. Accuracy on batch 379/2438  on Training is 63.81578947368421\n",
            "Batch Id 380/2438 is having training loss of 1.4095255136489868\n",
            "1.53435218334198\n",
            "Epoch #2. Accuracy on batch 380/2438  on Training is 63.81233595800525\n",
            "Epoch #2. Accuracy on batch 381/2438  on Training is 63.81708115183246\n",
            "Epoch #2. Accuracy on batch 382/2438  on Training is 63.838120104438644\n",
            "Epoch #2. Accuracy on batch 383/2438  on Training is 63.850911458333336\n",
            "Epoch #2. Accuracy on batch 384/2438  on Training is 63.839285714285715\n",
            "Epoch #2. Accuracy on batch 385/2438  on Training is 63.835816062176164\n",
            "Epoch #2. Accuracy on batch 386/2438  on Training is 63.832364341085274\n",
            "Epoch #2. Accuracy on batch 387/2438  on Training is 63.845038659793815\n",
            "Epoch #2. Accuracy on batch 388/2438  on Training is 63.88174807197944\n",
            "Epoch #2. Accuracy on batch 389/2438  on Training is 63.91025641025641\n",
            "Epoch #2. Accuracy on batch 390/2438  on Training is 63.89865728900256\n",
            "Epoch #2. Accuracy on batch 391/2438  on Training is 63.895089285714285\n",
            "Epoch #2. Accuracy on batch 392/2438  on Training is 63.907442748091604\n",
            "Epoch #2. Accuracy on batch 393/2438  on Training is 63.911802030456855\n",
            "Epoch #2. Accuracy on batch 394/2438  on Training is 63.88449367088607\n",
            "Epoch #2. Accuracy on batch 395/2438  on Training is 63.888888888888886\n",
            "Epoch #2. Accuracy on batch 396/2438  on Training is 63.87751889168766\n",
            "Epoch #2. Accuracy on batch 397/2438  on Training is 63.86620603015076\n",
            "Epoch #2. Accuracy on batch 398/2438  on Training is 63.86278195488722\n",
            "Epoch #2. Accuracy on batch 399/2438  on Training is 63.8671875\n",
            "Batch Id 400/2438 is having training loss of 1.4072480201721191\n",
            "1.2957619428634644\n",
            "Epoch #2. Accuracy on batch 400/2438  on Training is 63.88715710723192\n",
            "Epoch #2. Accuracy on batch 401/2438  on Training is 63.922574626865675\n",
            "Epoch #2. Accuracy on batch 402/2438  on Training is 63.89578163771712\n",
            "Epoch #2. Accuracy on batch 403/2438  on Training is 63.87685643564357\n",
            "Epoch #2. Accuracy on batch 404/2438  on Training is 63.88117283950617\n",
            "Epoch #2. Accuracy on batch 405/2438  on Training is 63.885467980295566\n",
            "Epoch #2. Accuracy on batch 406/2438  on Training is 63.90509828009828\n",
            "Epoch #2. Accuracy on batch 407/2438  on Training is 63.9016544117647\n",
            "Epoch #2. Accuracy on batch 408/2438  on Training is 63.890586797066014\n",
            "Epoch #2. Accuracy on batch 409/2438  on Training is 63.917682926829265\n",
            "Epoch #2. Accuracy on batch 410/2438  on Training is 63.92183698296837\n",
            "Epoch #2. Accuracy on batch 411/2438  on Training is 63.96389563106796\n",
            "Epoch #2. Accuracy on batch 412/2438  on Training is 63.97548426150121\n",
            "Epoch #2. Accuracy on batch 413/2438  on Training is 63.9417270531401\n",
            "Epoch #2. Accuracy on batch 414/2438  on Training is 63.95331325301205\n",
            "Epoch #2. Accuracy on batch 415/2438  on Training is 63.96484375\n",
            "Epoch #2. Accuracy on batch 416/2438  on Training is 63.9613309352518\n",
            "Epoch #2. Accuracy on batch 417/2438  on Training is 63.98773923444976\n",
            "Epoch #2. Accuracy on batch 418/2438  on Training is 63.96927207637231\n",
            "Epoch #2. Accuracy on batch 419/2438  on Training is 63.973214285714285\n",
            "Batch Id 420/2438 is having training loss of 1.4027022123336792\n",
            "1.083617091178894\n",
            "Epoch #2. Accuracy on batch 420/2438  on Training is 63.99940617577197\n",
            "Epoch #2. Accuracy on batch 421/2438  on Training is 63.988447867298575\n",
            "Epoch #2. Accuracy on batch 422/2438  on Training is 63.999704491725765\n",
            "Epoch #2. Accuracy on batch 423/2438  on Training is 63.981426886792455\n",
            "Epoch #2. Accuracy on batch 424/2438  on Training is 63.9485294117647\n",
            "Epoch #2. Accuracy on batch 425/2438  on Training is 63.95246478873239\n",
            "Epoch #2. Accuracy on batch 426/2438  on Training is 64.00029274004685\n",
            "Epoch #2. Accuracy on batch 427/2438  on Training is 63.97488317757009\n",
            "Epoch #2. Accuracy on batch 428/2438  on Training is 63.93502331002331\n",
            "Epoch #2. Accuracy on batch 429/2438  on Training is 63.88081395348837\n",
            "Epoch #2. Accuracy on batch 430/2438  on Training is 63.855858468677496\n",
            "Epoch #2. Accuracy on batch 431/2438  on Training is 63.852719907407405\n",
            "Epoch #2. Accuracy on batch 432/2438  on Training is 63.871247113163975\n",
            "Epoch #2. Accuracy on batch 433/2438  on Training is 63.89688940092166\n",
            "Epoch #2. Accuracy on batch 434/2438  on Training is 63.91522988505747\n",
            "Epoch #2. Accuracy on batch 435/2438  on Training is 63.91198394495413\n",
            "Epoch #2. Accuracy on batch 436/2438  on Training is 63.93735697940503\n",
            "Epoch #2. Accuracy on batch 437/2438  on Training is 63.93407534246575\n",
            "Epoch #2. Accuracy on batch 438/2438  on Training is 63.91657175398633\n",
            "Epoch #2. Accuracy on batch 439/2438  on Training is 63.92755681818182\n",
            "Batch Id 440/2438 is having training loss of 1.403351068496704\n",
            "1.2443809509277344\n",
            "Epoch #2. Accuracy on batch 440/2438  on Training is 63.95266439909297\n",
            "Epoch #2. Accuracy on batch 441/2438  on Training is 63.949377828054295\n",
            "Epoch #2. Accuracy on batch 442/2438  on Training is 63.988431151241535\n",
            "Epoch #2. Accuracy on batch 443/2438  on Training is 63.9991554054054\n",
            "Epoch #2. Accuracy on batch 444/2438  on Training is 64.03089887640449\n",
            "Epoch #2. Accuracy on batch 445/2438  on Training is 64.03447309417041\n",
            "Epoch #2. Accuracy on batch 446/2438  on Training is 64.06599552572708\n",
            "Epoch #2. Accuracy on batch 447/2438  on Training is 64.08342633928571\n",
            "Epoch #2. Accuracy on batch 448/2438  on Training is 64.05902004454343\n",
            "Epoch #2. Accuracy on batch 449/2438  on Training is 64.04166666666667\n",
            "Epoch #2. Accuracy on batch 450/2438  on Training is 64.03824833702882\n",
            "Epoch #2. Accuracy on batch 451/2438  on Training is 64.04175884955752\n",
            "Epoch #2. Accuracy on batch 452/2438  on Training is 64.02455849889624\n",
            "Epoch #2. Accuracy on batch 453/2438  on Training is 64.03496696035242\n",
            "Epoch #2. Accuracy on batch 454/2438  on Training is 64.06593406593407\n",
            "Epoch #2. Accuracy on batch 455/2438  on Training is 64.07620614035088\n",
            "Epoch #2. Accuracy on batch 456/2438  on Training is 64.10694748358863\n",
            "Epoch #2. Accuracy on batch 457/2438  on Training is 64.11026200873363\n",
            "Epoch #2. Accuracy on batch 458/2438  on Training is 64.12717864923748\n",
            "Epoch #2. Accuracy on batch 459/2438  on Training is 64.11684782608695\n",
            "Batch Id 460/2438 is having training loss of 1.398527979850769\n",
            "1.36251962184906\n",
            "Epoch #2. Accuracy on batch 460/2438  on Training is 64.12689804772235\n",
            "Epoch #2. Accuracy on batch 461/2438  on Training is 64.1301406926407\n",
            "Epoch #2. Accuracy on batch 462/2438  on Training is 64.17386609071275\n",
            "Epoch #2. Accuracy on batch 463/2438  on Training is 64.16352370689656\n",
            "Epoch #2. Accuracy on batch 464/2438  on Training is 64.14650537634408\n",
            "Epoch #2. Accuracy on batch 465/2438  on Training is 64.17650214592274\n",
            "Epoch #2. Accuracy on batch 466/2438  on Training is 64.14614561027837\n",
            "Epoch #2. Accuracy on batch 467/2438  on Training is 64.12259615384616\n",
            "Epoch #2. Accuracy on batch 468/2438  on Training is 64.11247334754798\n",
            "Epoch #2. Accuracy on batch 469/2438  on Training is 64.15558510638297\n",
            "Epoch #2. Accuracy on batch 470/2438  on Training is 64.13880042462846\n",
            "Epoch #2. Accuracy on batch 471/2438  on Training is 64.17505296610169\n",
            "Epoch #2. Accuracy on batch 472/2438  on Training is 64.17151162790698\n",
            "Epoch #2. Accuracy on batch 473/2438  on Training is 64.16798523206751\n",
            "Epoch #2. Accuracy on batch 474/2438  on Training is 64.1907894736842\n",
            "Epoch #2. Accuracy on batch 475/2438  on Training is 64.2266281512605\n",
            "Epoch #2. Accuracy on batch 476/2438  on Training is 64.22955974842768\n",
            "Epoch #2. Accuracy on batch 477/2438  on Training is 64.21940376569037\n",
            "Epoch #2. Accuracy on batch 478/2438  on Training is 64.23538622129436\n",
            "Epoch #2. Accuracy on batch 479/2438  on Training is 64.25130208333333\n",
            "Batch Id 480/2438 is having training loss of 1.3923835754394531\n",
            "1.5010015964508057\n",
            "Epoch #2. Accuracy on batch 480/2438  on Training is 64.24116424116424\n",
            "Epoch #2. Accuracy on batch 481/2438  on Training is 64.27645228215768\n",
            "Epoch #2. Accuracy on batch 482/2438  on Training is 64.27277432712215\n",
            "Epoch #2. Accuracy on batch 483/2438  on Training is 64.29493801652893\n",
            "Epoch #2. Accuracy on batch 484/2438  on Training is 64.26546391752578\n",
            "Epoch #2. Accuracy on batch 485/2438  on Training is 64.24897119341564\n",
            "Epoch #2. Accuracy on batch 486/2438  on Training is 64.23896303901438\n",
            "Epoch #2. Accuracy on batch 487/2438  on Training is 64.28022540983606\n",
            "Epoch #2. Accuracy on batch 488/2438  on Training is 64.27658486707567\n",
            "Epoch #2. Accuracy on batch 489/2438  on Training is 64.2920918367347\n",
            "Epoch #2. Accuracy on batch 490/2438  on Training is 64.29480651731161\n",
            "Epoch #2. Accuracy on batch 491/2438  on Training is 64.29751016260163\n",
            "Epoch #2. Accuracy on batch 492/2438  on Training is 64.28118661257606\n",
            "Epoch #2. Accuracy on batch 493/2438  on Training is 64.29023279352226\n",
            "Epoch #2. Accuracy on batch 494/2438  on Training is 64.33080808080808\n",
            "Epoch #2. Accuracy on batch 495/2438  on Training is 64.29561491935483\n",
            "Epoch #2. Accuracy on batch 496/2438  on Training is 64.28571428571429\n",
            "Epoch #2. Accuracy on batch 497/2438  on Training is 64.28840361445783\n",
            "Epoch #2. Accuracy on batch 498/2438  on Training is 64.32239478957916\n",
            "Epoch #2. Accuracy on batch 499/2438  on Training is 64.34375\n",
            "Batch Id 500/2438 is having training loss of 1.3895708322525024\n",
            "1.5506138801574707\n",
            "Epoch #2. Accuracy on batch 500/2438  on Training is 64.33383233532935\n",
            "Epoch #2. Accuracy on batch 501/2438  on Training is 64.3550796812749\n",
            "Epoch #2. Accuracy on batch 502/2438  on Training is 64.34517892644135\n",
            "Epoch #2. Accuracy on batch 503/2438  on Training is 64.34771825396825\n",
            "Epoch #2. Accuracy on batch 504/2438  on Training is 64.3378712871287\n",
            "Epoch #2. Accuracy on batch 505/2438  on Training is 64.33423913043478\n",
            "Epoch #2. Accuracy on batch 506/2438  on Training is 64.33062130177515\n",
            "Epoch #2. Accuracy on batch 507/2438  on Training is 64.33316929133858\n",
            "Epoch #2. Accuracy on batch 508/2438  on Training is 64.3602652259332\n",
            "Epoch #2. Accuracy on batch 509/2438  on Training is 64.36887254901961\n",
            "Epoch #2. Accuracy on batch 510/2438  on Training is 64.35909980430529\n",
            "Epoch #2. Accuracy on batch 511/2438  on Training is 64.36767578125\n",
            "Epoch #2. Accuracy on batch 512/2438  on Training is 64.35794346978558\n",
            "Epoch #2. Accuracy on batch 513/2438  on Training is 64.33000972762646\n",
            "Epoch #2. Accuracy on batch 514/2438  on Training is 64.33252427184466\n",
            "Epoch #2. Accuracy on batch 515/2438  on Training is 64.35319767441861\n",
            "Epoch #2. Accuracy on batch 516/2438  on Training is 64.33147969052224\n",
            "Epoch #2. Accuracy on batch 517/2438  on Training is 64.35810810810811\n",
            "Epoch #2. Accuracy on batch 518/2438  on Training is 64.36657032755299\n",
            "Epoch #2. Accuracy on batch 519/2438  on Training is 64.375\n",
            "Batch Id 520/2438 is having training loss of 1.387151837348938\n",
            "1.2264293432235718\n",
            "Epoch #2. Accuracy on batch 520/2438  on Training is 64.37140115163147\n",
            "Epoch #2. Accuracy on batch 521/2438  on Training is 64.39176245210729\n",
            "Epoch #2. Accuracy on batch 522/2438  on Training is 64.39412045889101\n",
            "Epoch #2. Accuracy on batch 523/2438  on Training is 64.40243320610686\n",
            "Epoch #2. Accuracy on batch 524/2438  on Training is 64.41666666666667\n",
            "Epoch #2. Accuracy on batch 525/2438  on Training is 64.42490494296578\n",
            "Epoch #2. Accuracy on batch 526/2438  on Training is 64.43904174573055\n",
            "Epoch #2. Accuracy on batch 527/2438  on Training is 64.453125\n",
            "Epoch #2. Accuracy on batch 528/2438  on Training is 64.46124763705104\n",
            "Epoch #2. Accuracy on batch 529/2438  on Training is 64.49292452830188\n",
            "Epoch #2. Accuracy on batch 530/2438  on Training is 64.44797551789077\n",
            "Epoch #2. Accuracy on batch 531/2438  on Training is 64.45018796992481\n",
            "Epoch #2. Accuracy on batch 532/2438  on Training is 64.4406660412758\n",
            "Epoch #2. Accuracy on batch 533/2438  on Training is 64.41362359550561\n",
            "Epoch #2. Accuracy on batch 534/2438  on Training is 64.42757009345794\n",
            "Epoch #2. Accuracy on batch 535/2438  on Training is 64.40065298507463\n",
            "Epoch #2. Accuracy on batch 536/2438  on Training is 64.3854748603352\n",
            "Epoch #2. Accuracy on batch 537/2438  on Training is 64.39939591078067\n",
            "Epoch #2. Accuracy on batch 538/2438  on Training is 64.36688311688312\n",
            "Epoch #2. Accuracy on batch 539/2438  on Training is 64.36921296296296\n",
            "Batch Id 540/2438 is having training loss of 1.383904218673706\n",
            "1.3067530393600464\n",
            "Epoch #2. Accuracy on batch 540/2438  on Training is 64.38308687615528\n",
            "Epoch #2. Accuracy on batch 541/2438  on Training is 64.35654981549816\n",
            "Epoch #2. Accuracy on batch 542/2438  on Training is 64.34737569060773\n",
            "Epoch #2. Accuracy on batch 543/2438  on Training is 64.35546875\n",
            "Epoch #2. Accuracy on batch 544/2438  on Training is 64.36353211009174\n",
            "Epoch #2. Accuracy on batch 545/2438  on Training is 64.37156593406593\n",
            "Epoch #2. Accuracy on batch 546/2438  on Training is 64.3510054844607\n",
            "Epoch #2. Accuracy on batch 547/2438  on Training is 64.35903284671532\n",
            "Epoch #2. Accuracy on batch 548/2438  on Training is 64.38979963570128\n",
            "Epoch #2. Accuracy on batch 549/2438  on Training is 64.39204545454545\n",
            "Epoch #2. Accuracy on batch 550/2438  on Training is 64.39995462794919\n",
            "Epoch #2. Accuracy on batch 551/2438  on Training is 64.39651268115942\n",
            "Epoch #2. Accuracy on batch 552/2438  on Training is 64.37047920433996\n",
            "Epoch #2. Accuracy on batch 553/2438  on Training is 64.38966606498195\n",
            "Epoch #2. Accuracy on batch 554/2438  on Training is 64.40878378378379\n",
            "Epoch #2. Accuracy on batch 555/2438  on Training is 64.39973021582733\n",
            "Epoch #2. Accuracy on batch 556/2438  on Training is 64.37948833034112\n",
            "Epoch #2. Accuracy on batch 557/2438  on Training is 64.38172043010752\n",
            "Epoch #2. Accuracy on batch 558/2438  on Training is 64.39512522361359\n",
            "Epoch #2. Accuracy on batch 559/2438  on Training is 64.40848214285714\n",
            "Batch Id 560/2438 is having training loss of 1.3815404176712036\n",
            "1.0123704671859741\n",
            "Epoch #2. Accuracy on batch 560/2438  on Training is 64.43850267379679\n",
            "Epoch #2. Accuracy on batch 561/2438  on Training is 64.418371886121\n",
            "Epoch #2. Accuracy on batch 562/2438  on Training is 64.41496447602131\n",
            "Epoch #2. Accuracy on batch 563/2438  on Training is 64.42265070921985\n",
            "Epoch #2. Accuracy on batch 564/2438  on Training is 64.45243362831859\n",
            "Epoch #2. Accuracy on batch 565/2438  on Training is 64.42689929328623\n",
            "Epoch #2. Accuracy on batch 566/2438  on Training is 64.41247795414462\n",
            "Epoch #2. Accuracy on batch 567/2438  on Training is 64.40360915492958\n",
            "Epoch #2. Accuracy on batch 568/2438  on Training is 64.38927943760984\n",
            "Epoch #2. Accuracy on batch 569/2438  on Training is 64.3859649122807\n",
            "Epoch #2. Accuracy on batch 570/2438  on Training is 64.3717162872154\n",
            "Epoch #2. Accuracy on batch 571/2438  on Training is 64.35751748251748\n",
            "Epoch #2. Accuracy on batch 572/2438  on Training is 64.3706369982548\n",
            "Epoch #2. Accuracy on batch 573/2438  on Training is 64.37282229965157\n",
            "Epoch #2. Accuracy on batch 574/2438  on Training is 64.38586956521739\n",
            "Epoch #2. Accuracy on batch 575/2438  on Training is 64.36089409722223\n",
            "Epoch #2. Accuracy on batch 576/2438  on Training is 64.3630849220104\n",
            "Epoch #2. Accuracy on batch 577/2438  on Training is 64.35445501730104\n",
            "Epoch #2. Accuracy on batch 578/2438  on Training is 64.35664939550949\n",
            "Epoch #2. Accuracy on batch 579/2438  on Training is 64.35344827586206\n",
            "Batch Id 580/2438 is having training loss of 1.3830552101135254\n",
            "1.478855013847351\n",
            "Epoch #2. Accuracy on batch 580/2438  on Training is 64.32874354561102\n",
            "Epoch #2. Accuracy on batch 581/2438  on Training is 64.330970790378\n",
            "Epoch #2. Accuracy on batch 582/2438  on Training is 64.31710977701543\n",
            "Epoch #2. Accuracy on batch 583/2438  on Training is 64.31399828767124\n",
            "Epoch #2. Accuracy on batch 584/2438  on Training is 64.2948717948718\n",
            "Epoch #2. Accuracy on batch 585/2438  on Training is 64.32380546075085\n",
            "Epoch #2. Accuracy on batch 586/2438  on Training is 64.3313458262351\n",
            "Epoch #2. Accuracy on batch 587/2438  on Training is 64.328231292517\n",
            "Epoch #2. Accuracy on batch 588/2438  on Training is 64.356960950764\n",
            "Epoch #2. Accuracy on batch 589/2438  on Training is 64.34851694915254\n",
            "Epoch #2. Accuracy on batch 590/2438  on Training is 64.36125211505922\n",
            "Epoch #2. Accuracy on batch 591/2438  on Training is 64.36338682432432\n",
            "Epoch #2. Accuracy on batch 592/2438  on Training is 64.35497470489038\n",
            "Epoch #2. Accuracy on batch 593/2438  on Training is 64.36237373737374\n",
            "Epoch #2. Accuracy on batch 594/2438  on Training is 64.36974789915966\n",
            "Epoch #2. Accuracy on batch 595/2438  on Training is 64.37709731543625\n",
            "Epoch #2. Accuracy on batch 596/2438  on Training is 64.38442211055276\n",
            "Epoch #2. Accuracy on batch 597/2438  on Training is 64.39172240802675\n",
            "Epoch #2. Accuracy on batch 598/2438  on Training is 64.38334724540901\n",
            "Epoch #2. Accuracy on batch 599/2438  on Training is 64.40104166666667\n",
            "Batch Id 600/2438 is having training loss of 1.3813458681106567\n",
            "1.3675957918167114\n",
            "Epoch #2. Accuracy on batch 600/2438  on Training is 64.403078202995\n",
            "Epoch #2. Accuracy on batch 601/2438  on Training is 64.38953488372093\n",
            "Epoch #2. Accuracy on batch 602/2438  on Training is 64.36567164179104\n",
            "Epoch #2. Accuracy on batch 603/2438  on Training is 64.37810430463576\n",
            "Epoch #2. Accuracy on batch 604/2438  on Training is 64.3853305785124\n",
            "Epoch #2. Accuracy on batch 605/2438  on Training is 64.3822194719472\n",
            "Epoch #2. Accuracy on batch 606/2438  on Training is 64.39456342668863\n",
            "Epoch #2. Accuracy on batch 607/2438  on Training is 64.39658717105263\n",
            "Epoch #2. Accuracy on batch 608/2438  on Training is 64.38834154351396\n",
            "Epoch #2. Accuracy on batch 609/2438  on Training is 64.38524590163935\n",
            "Epoch #2. Accuracy on batch 610/2438  on Training is 64.39238952536824\n",
            "Epoch #2. Accuracy on batch 611/2438  on Training is 64.39950980392157\n",
            "Epoch #2. Accuracy on batch 612/2438  on Training is 64.38111745513866\n",
            "Epoch #2. Accuracy on batch 613/2438  on Training is 64.39841205211727\n",
            "Epoch #2. Accuracy on batch 614/2438  on Training is 64.380081300813\n",
            "Epoch #2. Accuracy on batch 615/2438  on Training is 64.38210227272727\n",
            "Epoch #2. Accuracy on batch 616/2438  on Training is 64.39424635332253\n",
            "Epoch #2. Accuracy on batch 617/2438  on Training is 64.4164644012945\n",
            "Epoch #2. Accuracy on batch 618/2438  on Training is 64.41336833602585\n",
            "Epoch #2. Accuracy on batch 619/2438  on Training is 64.40524193548387\n",
            "Batch Id 620/2438 is having training loss of 1.3819222450256348\n",
            "1.4372620582580566\n",
            "Epoch #2. Accuracy on batch 620/2438  on Training is 64.39210950080515\n",
            "Epoch #2. Accuracy on batch 621/2438  on Training is 64.37399517684888\n",
            "Epoch #2. Accuracy on batch 622/2438  on Training is 64.36597110754414\n",
            "Epoch #2. Accuracy on batch 623/2438  on Training is 64.3329326923077\n",
            "Epoch #2. Accuracy on batch 624/2438  on Training is 64.345\n",
            "Epoch #2. Accuracy on batch 625/2438  on Training is 64.3370607028754\n",
            "Epoch #2. Accuracy on batch 626/2438  on Training is 64.34409888357257\n",
            "Epoch #2. Accuracy on batch 627/2438  on Training is 64.34613853503184\n",
            "Epoch #2. Accuracy on batch 628/2438  on Training is 64.33326709062003\n",
            "Epoch #2. Accuracy on batch 629/2438  on Training is 64.33035714285714\n",
            "Epoch #2. Accuracy on batch 630/2438  on Training is 64.32745641838352\n",
            "Epoch #2. Accuracy on batch 631/2438  on Training is 64.32456487341773\n",
            "Epoch #2. Accuracy on batch 632/2438  on Training is 64.31180884676145\n",
            "Epoch #2. Accuracy on batch 633/2438  on Training is 64.33852523659306\n",
            "Epoch #2. Accuracy on batch 634/2438  on Training is 64.31102362204724\n",
            "Epoch #2. Accuracy on batch 635/2438  on Training is 64.32291666666667\n",
            "Epoch #2. Accuracy on batch 636/2438  on Training is 64.3151491365777\n",
            "Epoch #2. Accuracy on batch 637/2438  on Training is 64.29760971786834\n",
            "Epoch #2. Accuracy on batch 638/2438  on Training is 64.30457746478874\n",
            "Epoch #2. Accuracy on batch 639/2438  on Training is 64.3017578125\n",
            "Batch Id 640/2438 is having training loss of 1.3845938444137573\n",
            "1.424773931503296\n",
            "Epoch #2. Accuracy on batch 640/2438  on Training is 64.29894695787831\n",
            "Epoch #2. Accuracy on batch 641/2438  on Training is 64.27667445482867\n",
            "Epoch #2. Accuracy on batch 642/2438  on Training is 64.29821150855365\n",
            "Epoch #2. Accuracy on batch 643/2438  on Training is 64.31482919254658\n",
            "Epoch #2. Accuracy on batch 644/2438  on Training is 64.31686046511628\n",
            "Epoch #2. Accuracy on batch 645/2438  on Training is 64.3092105263158\n",
            "Epoch #2. Accuracy on batch 646/2438  on Training is 64.31124420401855\n",
            "Epoch #2. Accuracy on batch 647/2438  on Training is 64.33256172839506\n",
            "Epoch #2. Accuracy on batch 648/2438  on Training is 64.3345531587057\n",
            "Epoch #2. Accuracy on batch 649/2438  on Training is 64.32692307692308\n",
            "Epoch #2. Accuracy on batch 650/2438  on Training is 64.31931643625192\n",
            "Epoch #2. Accuracy on batch 651/2438  on Training is 64.3213190184049\n",
            "Epoch #2. Accuracy on batch 652/2438  on Training is 64.29938744257274\n",
            "Epoch #2. Accuracy on batch 653/2438  on Training is 64.29185779816514\n",
            "Epoch #2. Accuracy on batch 654/2438  on Training is 64.29866412213741\n",
            "Epoch #2. Accuracy on batch 655/2438  on Training is 64.30544969512195\n",
            "Epoch #2. Accuracy on batch 656/2438  on Training is 64.31221461187215\n",
            "Epoch #2. Accuracy on batch 657/2438  on Training is 64.3094604863222\n",
            "Epoch #2. Accuracy on batch 658/2438  on Training is 64.28774658573596\n",
            "Epoch #2. Accuracy on batch 659/2438  on Training is 64.28977272727273\n",
            "Batch Id 660/2438 is having training loss of 1.3852308988571167\n",
            "1.7282328605651855\n",
            "Epoch #2. Accuracy on batch 660/2438  on Training is 64.28706505295007\n",
            "Epoch #2. Accuracy on batch 661/2438  on Training is 64.28436555891238\n",
            "Epoch #2. Accuracy on batch 662/2438  on Training is 64.29581447963801\n",
            "Epoch #2. Accuracy on batch 663/2438  on Training is 64.29781626506023\n",
            "Epoch #2. Accuracy on batch 664/2438  on Training is 64.29511278195488\n",
            "Epoch #2. Accuracy on batch 665/2438  on Training is 64.28303303303304\n",
            "Epoch #2. Accuracy on batch 666/2438  on Training is 64.27567466266866\n",
            "Epoch #2. Accuracy on batch 667/2438  on Training is 64.27769461077844\n",
            "Epoch #2. Accuracy on batch 668/2438  on Training is 64.26569506726457\n",
            "Epoch #2. Accuracy on batch 669/2438  on Training is 64.25839552238806\n",
            "Epoch #2. Accuracy on batch 670/2438  on Training is 64.26508941877795\n",
            "Epoch #2. Accuracy on batch 671/2438  on Training is 64.27176339285714\n",
            "Epoch #2. Accuracy on batch 672/2438  on Training is 64.27377414561664\n",
            "Epoch #2. Accuracy on batch 673/2438  on Training is 64.28968842729971\n",
            "Epoch #2. Accuracy on batch 674/2438  on Training is 64.29166666666667\n",
            "Epoch #2. Accuracy on batch 675/2438  on Training is 64.28439349112426\n",
            "Epoch #2. Accuracy on batch 676/2438  on Training is 64.29098966026588\n",
            "Epoch #2. Accuracy on batch 677/2438  on Training is 64.30217551622418\n",
            "Epoch #2. Accuracy on batch 678/2438  on Training is 64.28571428571429\n",
            "Epoch #2. Accuracy on batch 679/2438  on Training is 64.29227941176471\n",
            "Batch Id 680/2438 is having training loss of 1.3851983547210693\n",
            "1.1646355390548706\n",
            "Epoch #2. Accuracy on batch 680/2438  on Training is 64.29882525697504\n",
            "Epoch #2. Accuracy on batch 681/2438  on Training is 64.28702346041055\n",
            "Epoch #2. Accuracy on batch 682/2438  on Training is 64.29813323572475\n",
            "Epoch #2. Accuracy on batch 683/2438  on Training is 64.27722953216374\n",
            "Epoch #2. Accuracy on batch 684/2438  on Training is 64.29744525547446\n",
            "Epoch #2. Accuracy on batch 685/2438  on Training is 64.3039358600583\n",
            "Epoch #2. Accuracy on batch 686/2438  on Training is 64.31040756914119\n",
            "Epoch #2. Accuracy on batch 687/2438  on Training is 64.3077761627907\n",
            "Epoch #2. Accuracy on batch 688/2438  on Training is 64.30968795355588\n",
            "Epoch #2. Accuracy on batch 689/2438  on Training is 64.3161231884058\n",
            "Epoch #2. Accuracy on batch 690/2438  on Training is 64.3044500723589\n",
            "Epoch #2. Accuracy on batch 691/2438  on Training is 64.3153901734104\n",
            "Epoch #2. Accuracy on batch 692/2438  on Training is 64.31277056277057\n",
            "Epoch #2. Accuracy on batch 693/2438  on Training is 64.30565561959654\n",
            "Epoch #2. Accuracy on batch 694/2438  on Training is 64.29856115107914\n",
            "Epoch #2. Accuracy on batch 695/2438  on Training is 64.28699712643679\n",
            "Epoch #2. Accuracy on batch 696/2438  on Training is 64.2978837876614\n",
            "Epoch #2. Accuracy on batch 697/2438  on Training is 64.30426217765043\n",
            "Epoch #2. Accuracy on batch 698/2438  on Training is 64.29721030042919\n",
            "Epoch #2. Accuracy on batch 699/2438  on Training is 64.28125\n",
            "Batch Id 700/2438 is having training loss of 1.3840479850769043\n",
            "1.6564656496047974\n",
            "Epoch #2. Accuracy on batch 700/2438  on Training is 64.28316690442226\n",
            "Epoch #2. Accuracy on batch 701/2438  on Training is 64.28507834757835\n",
            "Epoch #2. Accuracy on batch 702/2438  on Training is 64.29587482219061\n",
            "Epoch #2. Accuracy on batch 703/2438  on Training is 64.30220170454545\n",
            "Epoch #2. Accuracy on batch 704/2438  on Training is 64.3040780141844\n",
            "Epoch #2. Accuracy on batch 705/2438  on Training is 64.31922804532577\n",
            "Epoch #2. Accuracy on batch 706/2438  on Training is 64.30339462517681\n",
            "Epoch #2. Accuracy on batch 707/2438  on Training is 64.30526129943503\n",
            "Epoch #2. Accuracy on batch 708/2438  on Training is 64.31593794076164\n",
            "Epoch #2. Accuracy on batch 709/2438  on Training is 64.29137323943662\n",
            "Epoch #2. Accuracy on batch 710/2438  on Training is 64.28885372714487\n",
            "Epoch #2. Accuracy on batch 711/2438  on Training is 64.2775632022472\n",
            "Epoch #2. Accuracy on batch 712/2438  on Training is 64.2663043478261\n",
            "Epoch #2. Accuracy on batch 713/2438  on Training is 64.2594537815126\n",
            "Epoch #2. Accuracy on batch 714/2438  on Training is 64.26136363636364\n",
            "Epoch #2. Accuracy on batch 715/2438  on Training is 64.25890363128492\n",
            "Epoch #2. Accuracy on batch 716/2438  on Training is 64.25645048814505\n",
            "Epoch #2. Accuracy on batch 717/2438  on Training is 64.24965181058496\n",
            "Epoch #2. Accuracy on batch 718/2438  on Training is 64.25591098748261\n",
            "Epoch #2. Accuracy on batch 719/2438  on Training is 64.27517361111111\n",
            "Batch Id 720/2438 is having training loss of 1.3835545778274536\n",
            "1.0500268936157227\n",
            "Epoch #2. Accuracy on batch 720/2438  on Training is 64.28571428571429\n",
            "Epoch #2. Accuracy on batch 721/2438  on Training is 64.29622576177286\n",
            "Epoch #2. Accuracy on batch 722/2438  on Training is 64.29806362378976\n",
            "Epoch #2. Accuracy on batch 723/2438  on Training is 64.29989640883979\n",
            "Epoch #2. Accuracy on batch 724/2438  on Training is 64.30172413793103\n",
            "Epoch #2. Accuracy on batch 725/2438  on Training is 64.30354683195593\n",
            "Epoch #2. Accuracy on batch 726/2438  on Training is 64.29676753782668\n",
            "Epoch #2. Accuracy on batch 727/2438  on Training is 64.30288461538461\n",
            "Epoch #2. Accuracy on batch 728/2438  on Training is 64.30469821673525\n",
            "Epoch #2. Accuracy on batch 729/2438  on Training is 64.29366438356165\n",
            "Epoch #2. Accuracy on batch 730/2438  on Training is 64.2954856361149\n",
            "Epoch #2. Accuracy on batch 731/2438  on Training is 64.2973019125683\n",
            "Epoch #2. Accuracy on batch 732/2438  on Training is 64.31616643929058\n",
            "Epoch #2. Accuracy on batch 733/2438  on Training is 64.32646457765668\n",
            "Epoch #2. Accuracy on batch 734/2438  on Training is 64.31122448979592\n",
            "Epoch #2. Accuracy on batch 735/2438  on Training is 64.31725543478261\n",
            "Epoch #2. Accuracy on batch 736/2438  on Training is 64.32327001356852\n",
            "Epoch #2. Accuracy on batch 737/2438  on Training is 64.3165650406504\n",
            "Epoch #2. Accuracy on batch 738/2438  on Training is 64.32679296346414\n",
            "Epoch #2. Accuracy on batch 739/2438  on Training is 64.32854729729729\n",
            "Batch Id 740/2438 is having training loss of 1.380836844444275\n",
            "1.3332220315933228\n",
            "Epoch #2. Accuracy on batch 740/2438  on Training is 64.31764507422402\n",
            "Epoch #2. Accuracy on batch 741/2438  on Training is 64.32361859838275\n",
            "Epoch #2. Accuracy on batch 742/2438  on Training is 64.31275235531629\n",
            "Epoch #2. Accuracy on batch 743/2438  on Training is 64.31031586021506\n",
            "Epoch #2. Accuracy on batch 744/2438  on Training is 64.2994966442953\n",
            "Epoch #2. Accuracy on batch 745/2438  on Training is 64.29289544235925\n",
            "Epoch #2. Accuracy on batch 746/2438  on Training is 64.28631191432396\n",
            "Epoch #2. Accuracy on batch 747/2438  on Training is 64.27556818181819\n",
            "Epoch #2. Accuracy on batch 748/2438  on Training is 64.27319759679573\n",
            "Epoch #2. Accuracy on batch 749/2438  on Training is 64.25\n",
            "Epoch #2. Accuracy on batch 750/2438  on Training is 64.25599201065246\n",
            "Epoch #2. Accuracy on batch 751/2438  on Training is 64.26196808510639\n",
            "Epoch #2. Accuracy on batch 752/2438  on Training is 64.25962815405046\n",
            "Epoch #2. Accuracy on batch 753/2438  on Training is 64.24900530503979\n",
            "Epoch #2. Accuracy on batch 754/2438  on Training is 64.25082781456953\n",
            "Epoch #2. Accuracy on batch 755/2438  on Training is 64.2567791005291\n",
            "Epoch #2. Accuracy on batch 756/2438  on Training is 64.26684280052841\n",
            "Epoch #2. Accuracy on batch 757/2438  on Training is 64.26038918205805\n",
            "Epoch #2. Accuracy on batch 758/2438  on Training is 64.26218708827405\n",
            "Epoch #2. Accuracy on batch 759/2438  on Training is 64.26809210526316\n",
            "Batch Id 760/2438 is having training loss of 1.3819727897644043\n",
            "1.18881356716156\n",
            "Epoch #2. Accuracy on batch 760/2438  on Training is 64.27808804204993\n",
            "Epoch #2. Accuracy on batch 761/2438  on Training is 64.26345144356955\n",
            "Epoch #2. Accuracy on batch 762/2438  on Training is 64.26933158584535\n",
            "Epoch #2. Accuracy on batch 763/2438  on Training is 64.28746727748691\n",
            "Epoch #2. Accuracy on batch 764/2438  on Training is 64.28104575163398\n",
            "Epoch #2. Accuracy on batch 765/2438  on Training is 64.27872062663185\n",
            "Epoch #2. Accuracy on batch 766/2438  on Training is 64.30084745762711\n",
            "Epoch #2. Accuracy on batch 767/2438  on Training is 64.31477864583333\n",
            "Epoch #2. Accuracy on batch 768/2438  on Training is 64.30835500650196\n",
            "Epoch #2. Accuracy on batch 769/2438  on Training is 64.29383116883118\n",
            "Epoch #2. Accuracy on batch 770/2438  on Training is 64.27529182879377\n",
            "Epoch #2. Accuracy on batch 771/2438  on Training is 64.26084844559585\n",
            "Epoch #2. Accuracy on batch 772/2438  on Training is 64.26665588615782\n",
            "Epoch #2. Accuracy on batch 773/2438  on Training is 64.27244832041343\n",
            "Epoch #2. Accuracy on batch 774/2438  on Training is 64.29435483870968\n",
            "Epoch #2. Accuracy on batch 775/2438  on Training is 64.29606958762886\n",
            "Epoch #2. Accuracy on batch 776/2438  on Training is 64.3018018018018\n",
            "Epoch #2. Accuracy on batch 777/2438  on Training is 64.29546915167096\n",
            "Epoch #2. Accuracy on batch 778/2438  on Training is 64.29717586649551\n",
            "Epoch #2. Accuracy on batch 779/2438  on Training is 64.26682692307692\n",
            "Batch Id 780/2438 is having training loss of 1.3824609518051147\n",
            "1.4681963920593262\n",
            "Epoch #2. Accuracy on batch 780/2438  on Training is 64.25256081946223\n",
            "Epoch #2. Accuracy on batch 781/2438  on Training is 64.27030051150895\n",
            "Epoch #2. Accuracy on batch 782/2438  on Training is 64.26404853128992\n",
            "Epoch #2. Accuracy on batch 783/2438  on Training is 64.26179846938776\n",
            "Epoch #2. Accuracy on batch 784/2438  on Training is 64.27945859872611\n",
            "Epoch #2. Accuracy on batch 785/2438  on Training is 64.27719465648855\n",
            "Epoch #2. Accuracy on batch 786/2438  on Training is 64.27096569250318\n",
            "Epoch #2. Accuracy on batch 787/2438  on Training is 64.26475253807106\n",
            "Epoch #2. Accuracy on batch 788/2438  on Training is 64.25459442332065\n",
            "Epoch #2. Accuracy on batch 789/2438  on Training is 64.26028481012658\n",
            "Epoch #2. Accuracy on batch 790/2438  on Training is 64.25805941845765\n",
            "Epoch #2. Accuracy on batch 791/2438  on Training is 64.26373106060606\n",
            "Epoch #2. Accuracy on batch 792/2438  on Training is 64.26938839848675\n",
            "Epoch #2. Accuracy on batch 793/2438  on Training is 64.27503148614609\n",
            "Epoch #2. Accuracy on batch 794/2438  on Training is 64.26100628930817\n",
            "Epoch #2. Accuracy on batch 795/2438  on Training is 64.24309045226131\n",
            "Epoch #2. Accuracy on batch 796/2438  on Training is 64.25266624843162\n",
            "Epoch #2. Accuracy on batch 797/2438  on Training is 64.25046992481202\n",
            "Epoch #2. Accuracy on batch 798/2438  on Training is 64.26001251564456\n",
            "Epoch #2. Accuracy on batch 799/2438  on Training is 64.26953125\n",
            "Batch Id 800/2438 is having training loss of 1.3816156387329102\n",
            "1.2777973413467407\n",
            "Epoch #2. Accuracy on batch 800/2438  on Training is 64.27122347066167\n",
            "Epoch #2. Accuracy on batch 801/2438  on Training is 64.27680798004988\n",
            "Epoch #2. Accuracy on batch 802/2438  on Training is 64.25124533001245\n",
            "Epoch #2. Accuracy on batch 803/2438  on Training is 64.2451803482587\n",
            "Epoch #2. Accuracy on batch 804/2438  on Training is 64.2468944099379\n",
            "Epoch #2. Accuracy on batch 805/2438  on Training is 64.23309553349876\n",
            "Epoch #2. Accuracy on batch 806/2438  on Training is 64.23094795539033\n",
            "Epoch #2. Accuracy on batch 807/2438  on Training is 64.22493811881188\n",
            "Epoch #2. Accuracy on batch 808/2438  on Training is 64.2150803461063\n",
            "Epoch #2. Accuracy on batch 809/2438  on Training is 64.21296296296296\n",
            "Epoch #2. Accuracy on batch 810/2438  on Training is 64.21470406905055\n",
            "Epoch #2. Accuracy on batch 811/2438  on Training is 64.22798645320196\n",
            "Epoch #2. Accuracy on batch 812/2438  on Training is 64.24507995079951\n",
            "Epoch #2. Accuracy on batch 813/2438  on Training is 64.23525798525799\n",
            "Epoch #2. Accuracy on batch 814/2438  on Training is 64.23312883435582\n",
            "Epoch #2. Accuracy on batch 815/2438  on Training is 64.23483455882354\n",
            "Epoch #2. Accuracy on batch 816/2438  on Training is 64.2250611995104\n",
            "Epoch #2. Accuracy on batch 817/2438  on Training is 64.22677261613691\n",
            "Epoch #2. Accuracy on batch 818/2438  on Training is 64.23229548229548\n",
            "Epoch #2. Accuracy on batch 819/2438  on Training is 64.21875\n",
            "Batch Id 820/2438 is having training loss of 1.3832247257232666\n",
            "1.2647829055786133\n",
            "Epoch #2. Accuracy on batch 820/2438  on Training is 64.22426918392205\n",
            "Epoch #2. Accuracy on batch 821/2438  on Training is 64.23737834549878\n",
            "Epoch #2. Accuracy on batch 822/2438  on Training is 64.24665856622114\n",
            "Epoch #2. Accuracy on batch 823/2438  on Training is 64.23695388349515\n",
            "Epoch #2. Accuracy on batch 824/2438  on Training is 64.23863636363636\n",
            "Epoch #2. Accuracy on batch 825/2438  on Training is 64.2516646489104\n",
            "Epoch #2. Accuracy on batch 826/2438  on Training is 64.23821039903265\n",
            "Epoch #2. Accuracy on batch 827/2438  on Training is 64.23988526570048\n",
            "Epoch #2. Accuracy on batch 828/2438  on Training is 64.25286489746682\n",
            "Epoch #2. Accuracy on batch 829/2438  on Training is 64.26581325301204\n",
            "Epoch #2. Accuracy on batch 830/2438  on Training is 64.27496991576415\n",
            "Epoch #2. Accuracy on batch 831/2438  on Training is 64.26532451923077\n",
            "Epoch #2. Accuracy on batch 832/2438  on Training is 64.27445978391357\n",
            "Epoch #2. Accuracy on batch 833/2438  on Training is 64.2873201438849\n",
            "Epoch #2. Accuracy on batch 834/2438  on Training is 64.28517964071857\n",
            "Epoch #2. Accuracy on batch 835/2438  on Training is 64.28304425837321\n",
            "Epoch #2. Accuracy on batch 836/2438  on Training is 64.28091397849462\n",
            "Epoch #2. Accuracy on batch 837/2438  on Training is 64.26014319809069\n",
            "Epoch #2. Accuracy on batch 838/2438  on Training is 64.25432061978546\n",
            "Epoch #2. Accuracy on batch 839/2438  on Training is 64.2485119047619\n",
            "Batch Id 840/2438 is having training loss of 1.3835906982421875\n",
            "1.252226710319519\n",
            "Epoch #2. Accuracy on batch 840/2438  on Training is 64.2538644470868\n",
            "Epoch #2. Accuracy on batch 841/2438  on Training is 64.25178147268409\n",
            "Epoch #2. Accuracy on batch 842/2438  on Training is 64.24228944246738\n",
            "Epoch #2. Accuracy on batch 843/2438  on Training is 64.2550355450237\n",
            "Epoch #2. Accuracy on batch 844/2438  on Training is 64.24926035502959\n",
            "Epoch #2. Accuracy on batch 845/2438  on Training is 64.2471926713948\n",
            "Epoch #2. Accuracy on batch 846/2438  on Training is 64.24144037780401\n",
            "Epoch #2. Accuracy on batch 847/2438  on Training is 64.23201650943396\n",
            "Epoch #2. Accuracy on batch 848/2438  on Training is 64.22629564193169\n",
            "Epoch #2. Accuracy on batch 849/2438  on Training is 64.23529411764706\n",
            "Epoch #2. Accuracy on batch 850/2438  on Training is 64.23325499412456\n",
            "Epoch #2. Accuracy on batch 851/2438  on Training is 64.23855633802818\n",
            "Epoch #2. Accuracy on batch 852/2438  on Training is 64.25117233294256\n",
            "Epoch #2. Accuracy on batch 853/2438  on Training is 64.25278103044496\n",
            "Epoch #2. Accuracy on batch 854/2438  on Training is 64.25073099415205\n",
            "Epoch #2. Accuracy on batch 855/2438  on Training is 64.23773364485982\n",
            "Epoch #2. Accuracy on batch 856/2438  on Training is 64.22112018669779\n",
            "Epoch #2. Accuracy on batch 857/2438  on Training is 64.23004079254079\n",
            "Epoch #2. Accuracy on batch 858/2438  on Training is 64.23530267753202\n",
            "Epoch #2. Accuracy on batch 859/2438  on Training is 64.24055232558139\n",
            "Batch Id 860/2438 is having training loss of 1.3827364444732666\n",
            "1.3839588165283203\n",
            "Epoch #2. Accuracy on batch 860/2438  on Training is 64.24216027874564\n",
            "Epoch #2. Accuracy on batch 861/2438  on Training is 64.2510150812065\n",
            "Epoch #2. Accuracy on batch 862/2438  on Training is 64.24536500579374\n",
            "Epoch #2. Accuracy on batch 863/2438  on Training is 64.25419560185185\n",
            "Epoch #2. Accuracy on batch 864/2438  on Training is 64.26661849710983\n",
            "Epoch #2. Accuracy on batch 865/2438  on Training is 64.28262124711317\n",
            "Epoch #2. Accuracy on batch 866/2438  on Training is 64.28056516724337\n",
            "Epoch #2. Accuracy on batch 867/2438  on Training is 64.2713133640553\n",
            "Epoch #2. Accuracy on batch 868/2438  on Training is 64.27287111622555\n",
            "Epoch #2. Accuracy on batch 869/2438  on Training is 64.26364942528735\n",
            "Epoch #2. Accuracy on batch 870/2438  on Training is 64.27597588978186\n",
            "Epoch #2. Accuracy on batch 871/2438  on Training is 64.26677178899082\n",
            "Epoch #2. Accuracy on batch 872/2438  on Training is 64.26116838487972\n",
            "Epoch #2. Accuracy on batch 873/2438  on Training is 64.25915331807781\n",
            "Epoch #2. Accuracy on batch 874/2438  on Training is 64.275\n",
            "Epoch #2. Accuracy on batch 875/2438  on Training is 64.28724315068493\n",
            "Epoch #2. Accuracy on batch 876/2438  on Training is 64.29945838084379\n",
            "Epoch #2. Accuracy on batch 877/2438  on Training is 64.30452733485194\n",
            "Epoch #2. Accuracy on batch 878/2438  on Training is 64.29891922639364\n",
            "Epoch #2. Accuracy on batch 879/2438  on Training is 64.31818181818181\n",
            "Batch Id 880/2438 is having training loss of 1.3800075054168701\n",
            "1.0530914068222046\n",
            "Epoch #2. Accuracy on batch 880/2438  on Training is 64.33385357548241\n",
            "Epoch #2. Accuracy on batch 881/2438  on Training is 64.32468820861678\n",
            "Epoch #2. Accuracy on batch 882/2438  on Training is 64.31200453001132\n",
            "Epoch #2. Accuracy on batch 883/2438  on Training is 64.31348981900453\n",
            "Epoch #2. Accuracy on batch 884/2438  on Training is 64.3114406779661\n",
            "Epoch #2. Accuracy on batch 885/2438  on Training is 64.33408577878104\n",
            "Epoch #2. Accuracy on batch 886/2438  on Training is 64.34611048478016\n",
            "Epoch #2. Accuracy on batch 887/2438  on Training is 64.33699324324324\n",
            "Epoch #2. Accuracy on batch 888/2438  on Training is 64.34195725534308\n",
            "Epoch #2. Accuracy on batch 889/2438  on Training is 64.33286516853933\n",
            "Epoch #2. Accuracy on batch 890/2438  on Training is 64.34132996632997\n",
            "Epoch #2. Accuracy on batch 891/2438  on Training is 64.32525224215247\n",
            "Epoch #2. Accuracy on batch 892/2438  on Training is 64.33370660694288\n",
            "Epoch #2. Accuracy on batch 893/2438  on Training is 64.33165548098434\n",
            "Epoch #2. Accuracy on batch 894/2438  on Training is 64.32611731843575\n",
            "Epoch #2. Accuracy on batch 895/2438  on Training is 64.33454241071429\n",
            "Epoch #2. Accuracy on batch 896/2438  on Training is 64.32552954292085\n",
            "Epoch #2. Accuracy on batch 897/2438  on Training is 64.33393652561247\n",
            "Epoch #2. Accuracy on batch 898/2438  on Training is 64.33189655172414\n",
            "Epoch #2. Accuracy on batch 899/2438  on Training is 64.34027777777777\n",
            "Batch Id 900/2438 is having training loss of 1.3800102472305298\n",
            "1.3593860864639282\n",
            "Epoch #2. Accuracy on batch 900/2438  on Training is 64.33476692563818\n",
            "Epoch #2. Accuracy on batch 901/2438  on Training is 64.33966186252772\n",
            "Epoch #2. Accuracy on batch 902/2438  on Training is 64.33416389811738\n",
            "Epoch #2. Accuracy on batch 903/2438  on Training is 64.32867809734513\n",
            "Epoch #2. Accuracy on batch 904/2438  on Training is 64.33356353591161\n",
            "Epoch #2. Accuracy on batch 905/2438  on Training is 64.33498896247241\n",
            "Epoch #2. Accuracy on batch 906/2438  on Training is 64.35708379272326\n",
            "Epoch #2. Accuracy on batch 907/2438  on Training is 64.36536343612335\n",
            "Epoch #2. Accuracy on batch 908/2438  on Training is 64.37018701870187\n",
            "Epoch #2. Accuracy on batch 909/2438  on Training is 64.36126373626374\n",
            "Epoch #2. Accuracy on batch 910/2438  on Training is 64.34892974753019\n",
            "Epoch #2. Accuracy on batch 911/2438  on Training is 64.3469024122807\n",
            "Epoch #2. Accuracy on batch 912/2438  on Training is 64.35857064622125\n",
            "Epoch #2. Accuracy on batch 913/2438  on Training is 64.34286105032822\n",
            "Epoch #2. Accuracy on batch 914/2438  on Training is 64.32718579234972\n",
            "Epoch #2. Accuracy on batch 915/2438  on Training is 64.32519104803494\n",
            "Epoch #2. Accuracy on batch 916/2438  on Training is 64.30275354416575\n",
            "Epoch #2. Accuracy on batch 917/2438  on Training is 64.31781045751634\n",
            "Epoch #2. Accuracy on batch 918/2438  on Training is 64.32603373231774\n",
            "Epoch #2. Accuracy on batch 919/2438  on Training is 64.32065217391305\n",
            "Batch Id 920/2438 is having training loss of 1.3817622661590576\n",
            "2.143995761871338\n",
            "Epoch #2. Accuracy on batch 920/2438  on Training is 64.2915309446254\n",
            "Epoch #2. Accuracy on batch 921/2438  on Training is 64.29975596529285\n",
            "Epoch #2. Accuracy on batch 922/2438  on Training is 64.30457746478874\n",
            "Epoch #2. Accuracy on batch 923/2438  on Training is 64.30938852813853\n",
            "Epoch #2. Accuracy on batch 924/2438  on Training is 64.3108108108108\n",
            "Epoch #2. Accuracy on batch 925/2438  on Training is 64.30885529157668\n",
            "Epoch #2. Accuracy on batch 926/2438  on Training is 64.31364617044228\n",
            "Epoch #2. Accuracy on batch 927/2438  on Training is 64.30495689655173\n",
            "Epoch #2. Accuracy on batch 928/2438  on Training is 64.30637782561894\n",
            "Epoch #2. Accuracy on batch 929/2438  on Training is 64.3010752688172\n",
            "Epoch #2. Accuracy on batch 930/2438  on Training is 64.27564446831364\n",
            "Epoch #2. Accuracy on batch 931/2438  on Training is 64.26703326180258\n",
            "Epoch #2. Accuracy on batch 932/2438  on Training is 64.28188638799571\n",
            "Epoch #2. Accuracy on batch 933/2438  on Training is 64.2732869379015\n",
            "Epoch #2. Accuracy on batch 934/2438  on Training is 64.27139037433155\n",
            "Epoch #2. Accuracy on batch 935/2438  on Training is 64.2661591880342\n",
            "Epoch #2. Accuracy on batch 936/2438  on Training is 64.25093383137673\n",
            "Epoch #2. Accuracy on batch 937/2438  on Training is 64.24573560767591\n",
            "Epoch #2. Accuracy on batch 938/2438  on Training is 64.23389243876464\n",
            "Epoch #2. Accuracy on batch 939/2438  on Training is 64.23204787234043\n",
            "Batch Id 940/2438 is having training loss of 1.3828986883163452\n",
            "1.3495235443115234\n",
            "Epoch #2. Accuracy on batch 940/2438  on Training is 64.23684909670563\n",
            "Epoch #2. Accuracy on batch 941/2438  on Training is 64.24164012738854\n",
            "Epoch #2. Accuracy on batch 942/2438  on Training is 64.22653764581123\n",
            "Epoch #2. Accuracy on batch 943/2438  on Training is 64.23132944915254\n",
            "Epoch #2. Accuracy on batch 944/2438  on Training is 64.23941798941799\n",
            "Epoch #2. Accuracy on batch 945/2438  on Training is 64.25409619450318\n",
            "Epoch #2. Accuracy on batch 946/2438  on Training is 64.26874340021119\n",
            "Epoch #2. Accuracy on batch 947/2438  on Training is 64.26358122362869\n",
            "Epoch #2. Accuracy on batch 948/2438  on Training is 64.2781875658588\n",
            "Epoch #2. Accuracy on batch 949/2438  on Training is 64.26315789473684\n",
            "Epoch #2. Accuracy on batch 950/2438  on Training is 64.26458990536278\n",
            "Epoch #2. Accuracy on batch 951/2438  on Training is 64.2594537815126\n",
            "Epoch #2. Accuracy on batch 952/2438  on Training is 64.2576075550892\n",
            "Epoch #2. Accuracy on batch 953/2438  on Training is 64.23611111111111\n",
            "Epoch #2. Accuracy on batch 954/2438  on Training is 64.24083769633508\n",
            "Epoch #2. Accuracy on batch 955/2438  on Training is 64.22594142259415\n",
            "Epoch #2. Accuracy on batch 956/2438  on Training is 64.24046499477534\n",
            "Epoch #2. Accuracy on batch 957/2438  on Training is 64.23864822546973\n",
            "Epoch #2. Accuracy on batch 958/2438  on Training is 64.24335245046925\n",
            "Epoch #2. Accuracy on batch 959/2438  on Training is 64.25455729166667\n",
            "Batch Id 960/2438 is having training loss of 1.3826240301132202\n",
            "1.5434852838516235\n",
            "Epoch #2. Accuracy on batch 960/2438  on Training is 64.23972424557752\n",
            "Epoch #2. Accuracy on batch 961/2438  on Training is 64.24441268191268\n",
            "Epoch #2. Accuracy on batch 962/2438  on Training is 64.24909138110073\n",
            "Epoch #2. Accuracy on batch 963/2438  on Training is 64.25376037344398\n",
            "Epoch #2. Accuracy on batch 964/2438  on Training is 64.25194300518135\n",
            "Epoch #2. Accuracy on batch 965/2438  on Training is 64.25336438923395\n",
            "Epoch #2. Accuracy on batch 966/2438  on Training is 64.23862461220268\n",
            "Epoch #2. Accuracy on batch 967/2438  on Training is 64.23037190082644\n",
            "Epoch #2. Accuracy on batch 968/2438  on Training is 64.22858617131062\n",
            "Epoch #2. Accuracy on batch 969/2438  on Training is 64.24291237113403\n",
            "Epoch #2. Accuracy on batch 970/2438  on Training is 64.25399073120494\n",
            "Epoch #2. Accuracy on batch 971/2438  on Training is 64.24897119341564\n",
            "Epoch #2. Accuracy on batch 972/2438  on Training is 64.24717368961973\n",
            "Epoch #2. Accuracy on batch 973/2438  on Training is 64.25179671457906\n",
            "Epoch #2. Accuracy on batch 974/2438  on Training is 64.25641025641026\n",
            "Epoch #2. Accuracy on batch 975/2438  on Training is 64.2578125\n",
            "Epoch #2. Accuracy on batch 976/2438  on Training is 64.26560900716478\n",
            "Epoch #2. Accuracy on batch 977/2438  on Training is 64.25421779141104\n",
            "Epoch #2. Accuracy on batch 978/2438  on Training is 64.2588100102145\n",
            "Epoch #2. Accuracy on batch 979/2438  on Training is 64.26977040816327\n",
            "Batch Id 980/2438 is having training loss of 1.3813602924346924\n",
            "1.1534968614578247\n",
            "Epoch #2. Accuracy on batch 980/2438  on Training is 64.28389398572885\n",
            "Epoch #2. Accuracy on batch 981/2438  on Training is 64.30753564154786\n",
            "Epoch #2. Accuracy on batch 982/2438  on Training is 64.31841302136317\n",
            "Epoch #2. Accuracy on batch 983/2438  on Training is 64.3260924796748\n",
            "Epoch #2. Accuracy on batch 984/2438  on Training is 64.33692893401015\n",
            "Epoch #2. Accuracy on batch 985/2438  on Training is 64.33823529411765\n",
            "Epoch #2. Accuracy on batch 986/2438  on Training is 64.3458713272543\n",
            "Epoch #2. Accuracy on batch 987/2438  on Training is 64.35349190283401\n",
            "Epoch #2. Accuracy on batch 988/2438  on Training is 64.33897876643074\n",
            "Epoch #2. Accuracy on batch 989/2438  on Training is 64.32449494949495\n",
            "Epoch #2. Accuracy on batch 990/2438  on Training is 64.31634712411706\n",
            "Epoch #2. Accuracy on batch 991/2438  on Training is 64.31451612903226\n",
            "Epoch #2. Accuracy on batch 992/2438  on Training is 64.31268882175226\n",
            "Epoch #2. Accuracy on batch 993/2438  on Training is 64.31400905432595\n",
            "Epoch #2. Accuracy on batch 994/2438  on Training is 64.33417085427136\n",
            "Epoch #2. Accuracy on batch 995/2438  on Training is 64.34174196787149\n",
            "Epoch #2. Accuracy on batch 996/2438  on Training is 64.34302908726178\n",
            "Epoch #2. Accuracy on batch 997/2438  on Training is 64.3380511022044\n",
            "Epoch #2. Accuracy on batch 998/2438  on Training is 64.33308308308308\n",
            "Epoch #2. Accuracy on batch 999/2438  on Training is 64.340625\n",
            "Batch Id 1000/2438 is having training loss of 1.3786991834640503\n",
            "0.9220215082168579\n",
            "Epoch #2. Accuracy on batch 1000/2438  on Training is 64.35751748251748\n",
            "Epoch #2. Accuracy on batch 1001/2438  on Training is 64.34942614770459\n",
            "Epoch #2. Accuracy on batch 1002/2438  on Training is 64.34135094715853\n",
            "Epoch #2. Accuracy on batch 1003/2438  on Training is 64.33640438247012\n",
            "Epoch #2. Accuracy on batch 1004/2438  on Training is 64.34390547263682\n",
            "Epoch #2. Accuracy on batch 1005/2438  on Training is 64.35449801192843\n",
            "Epoch #2. Accuracy on batch 1006/2438  on Training is 64.36506951340616\n",
            "Epoch #2. Accuracy on batch 1007/2438  on Training is 64.36321924603175\n",
            "Epoch #2. Accuracy on batch 1008/2438  on Training is 64.35517839444995\n",
            "Epoch #2. Accuracy on batch 1009/2438  on Training is 64.36262376237623\n",
            "Epoch #2. Accuracy on batch 1010/2438  on Training is 64.36078140454995\n",
            "Epoch #2. Accuracy on batch 1011/2438  on Training is 64.36203063241106\n",
            "Epoch #2. Accuracy on batch 1012/2438  on Training is 64.3571076011846\n",
            "Epoch #2. Accuracy on batch 1013/2438  on Training is 64.34294871794872\n",
            "Epoch #2. Accuracy on batch 1014/2438  on Training is 64.35344827586206\n",
            "Epoch #2. Accuracy on batch 1015/2438  on Training is 64.35777559055119\n",
            "Epoch #2. Accuracy on batch 1016/2438  on Training is 64.35594886922321\n",
            "Epoch #2. Accuracy on batch 1017/2438  on Training is 64.3602652259332\n",
            "Epoch #2. Accuracy on batch 1018/2438  on Training is 64.3707065750736\n",
            "Epoch #2. Accuracy on batch 1019/2438  on Training is 64.35661764705883\n",
            "Batch Id 1020/2438 is having training loss of 1.3784226179122925\n",
            "1.47000253200531\n",
            "Epoch #2. Accuracy on batch 1020/2438  on Training is 64.34867776689521\n",
            "Epoch #2. Accuracy on batch 1021/2438  on Training is 64.34686888454011\n",
            "Epoch #2. Accuracy on batch 1022/2438  on Training is 64.35422776148583\n",
            "Epoch #2. Accuracy on batch 1023/2438  on Training is 64.34326171875\n",
            "Epoch #2. Accuracy on batch 1024/2438  on Training is 64.34146341463415\n",
            "Epoch #2. Accuracy on batch 1025/2438  on Training is 64.33357699805069\n",
            "Epoch #2. Accuracy on batch 1026/2438  on Training is 64.34092015579357\n",
            "Epoch #2. Accuracy on batch 1027/2438  on Training is 64.34216926070039\n",
            "Epoch #2. Accuracy on batch 1028/2438  on Training is 64.35556365403305\n",
            "Epoch #2. Accuracy on batch 1029/2438  on Training is 64.35679611650485\n",
            "Epoch #2. Accuracy on batch 1030/2438  on Training is 64.36105722599417\n",
            "Epoch #2. Accuracy on batch 1031/2438  on Training is 64.35925387596899\n",
            "Epoch #2. Accuracy on batch 1032/2438  on Training is 64.34837850919652\n",
            "Epoch #2. Accuracy on batch 1033/2438  on Training is 64.35867988394584\n",
            "Epoch #2. Accuracy on batch 1034/2438  on Training is 64.3659420289855\n",
            "Epoch #2. Accuracy on batch 1035/2438  on Training is 64.36414092664093\n",
            "Epoch #2. Accuracy on batch 1036/2438  on Training is 64.35932979749276\n",
            "Epoch #2. Accuracy on batch 1037/2438  on Training is 64.3695809248555\n",
            "Epoch #2. Accuracy on batch 1038/2438  on Training is 64.38282001924928\n",
            "Epoch #2. Accuracy on batch 1039/2438  on Training is 64.38401442307692\n",
            "Batch Id 1040/2438 is having training loss of 1.3783135414123535\n",
            "1.8088361024856567\n",
            "Epoch #2. Accuracy on batch 1040/2438  on Training is 64.37319884726224\n",
            "Epoch #2. Accuracy on batch 1041/2438  on Training is 64.37440019193858\n",
            "Epoch #2. Accuracy on batch 1042/2438  on Training is 64.39357622243529\n",
            "Epoch #2. Accuracy on batch 1043/2438  on Training is 64.40672892720306\n",
            "Epoch #2. Accuracy on batch 1044/2438  on Training is 64.41088516746412\n",
            "Epoch #2. Accuracy on batch 1045/2438  on Training is 64.41503346080306\n",
            "Epoch #2. Accuracy on batch 1046/2438  on Training is 64.40723495702005\n",
            "Epoch #2. Accuracy on batch 1047/2438  on Training is 64.40839694656489\n",
            "Epoch #2. Accuracy on batch 1048/2438  on Training is 64.42445185891324\n",
            "Epoch #2. Accuracy on batch 1049/2438  on Training is 64.41964285714286\n",
            "Epoch #2. Accuracy on batch 1050/2438  on Training is 64.4297098001903\n",
            "Epoch #2. Accuracy on batch 1051/2438  on Training is 64.43975760456274\n",
            "Epoch #2. Accuracy on batch 1052/2438  on Training is 64.43791547958214\n",
            "Epoch #2. Accuracy on batch 1053/2438  on Training is 64.43904174573055\n",
            "Epoch #2. Accuracy on batch 1054/2438  on Training is 64.43127962085308\n",
            "Epoch #2. Accuracy on batch 1055/2438  on Training is 64.4235321969697\n",
            "Epoch #2. Accuracy on batch 1056/2438  on Training is 64.4217123935667\n",
            "Epoch #2. Accuracy on batch 1057/2438  on Training is 64.42284971644612\n",
            "Epoch #2. Accuracy on batch 1058/2438  on Training is 64.4298866855524\n",
            "Epoch #2. Accuracy on batch 1059/2438  on Training is 64.44575471698113\n",
            "Batch Id 1060/2438 is having training loss of 1.3762550354003906\n",
            "1.0125395059585571\n",
            "Epoch #2. Accuracy on batch 1060/2438  on Training is 64.45275683317625\n",
            "Epoch #2. Accuracy on batch 1061/2438  on Training is 64.45386064030131\n",
            "Epoch #2. Accuracy on batch 1062/2438  on Training is 64.44026340545625\n",
            "Epoch #2. Accuracy on batch 1063/2438  on Training is 64.44137687969925\n",
            "Epoch #2. Accuracy on batch 1064/2438  on Training is 64.43955399061034\n",
            "Epoch #2. Accuracy on batch 1065/2438  on Training is 64.42893996247655\n",
            "Epoch #2. Accuracy on batch 1066/2438  on Training is 64.43884723523898\n",
            "Epoch #2. Accuracy on batch 1067/2438  on Training is 64.44288389513109\n",
            "Epoch #2. Accuracy on batch 1068/2438  on Training is 64.45275958840037\n",
            "Epoch #2. Accuracy on batch 1069/2438  on Training is 64.44509345794393\n",
            "Epoch #2. Accuracy on batch 1070/2438  on Training is 64.44327731092437\n",
            "Epoch #2. Accuracy on batch 1071/2438  on Training is 64.4472947761194\n",
            "Epoch #2. Accuracy on batch 1072/2438  on Training is 64.4513047530289\n",
            "Epoch #2. Accuracy on batch 1073/2438  on Training is 64.4465782122905\n",
            "Epoch #2. Accuracy on batch 1074/2438  on Training is 64.44767441860465\n",
            "Epoch #2. Accuracy on batch 1075/2438  on Training is 64.44005576208178\n",
            "Epoch #2. Accuracy on batch 1076/2438  on Training is 64.4469591457753\n",
            "Epoch #2. Accuracy on batch 1077/2438  on Training is 64.43355751391465\n",
            "Epoch #2. Accuracy on batch 1078/2438  on Training is 64.42597312326228\n",
            "Epoch #2. Accuracy on batch 1079/2438  on Training is 64.42418981481481\n",
            "Batch Id 1080/2438 is having training loss of 1.376682996749878\n",
            "1.7201266288757324\n",
            "Epoch #2. Accuracy on batch 1080/2438  on Training is 64.42240980573543\n",
            "Epoch #2. Accuracy on batch 1081/2438  on Training is 64.42929759704252\n",
            "Epoch #2. Accuracy on batch 1082/2438  on Training is 64.42463065558634\n",
            "Epoch #2. Accuracy on batch 1083/2438  on Training is 64.41997232472325\n",
            "Epoch #2. Accuracy on batch 1084/2438  on Training is 64.42396313364056\n",
            "Epoch #2. Accuracy on batch 1085/2438  on Training is 64.4308241252302\n",
            "Epoch #2. Accuracy on batch 1086/2438  on Training is 64.42617295308187\n",
            "Epoch #2. Accuracy on batch 1087/2438  on Training is 64.42153033088235\n",
            "Epoch #2. Accuracy on batch 1088/2438  on Training is 64.42837465564739\n",
            "Epoch #2. Accuracy on batch 1089/2438  on Training is 64.42660550458716\n",
            "Epoch #2. Accuracy on batch 1090/2438  on Training is 64.42483959670028\n",
            "Epoch #2. Accuracy on batch 1091/2438  on Training is 64.43166208791209\n",
            "Epoch #2. Accuracy on batch 1092/2438  on Training is 64.44419030192132\n",
            "Epoch #2. Accuracy on batch 1093/2438  on Training is 64.44526965265082\n",
            "Epoch #2. Accuracy on batch 1094/2438  on Training is 64.45490867579909\n",
            "Epoch #2. Accuracy on batch 1095/2438  on Training is 64.46453010948905\n",
            "Epoch #2. Accuracy on batch 1096/2438  on Training is 64.45419325433\n",
            "Epoch #2. Accuracy on batch 1097/2438  on Training is 64.46664389799636\n",
            "Epoch #2. Accuracy on batch 1098/2438  on Training is 64.46485441310283\n",
            "Epoch #2. Accuracy on batch 1099/2438  on Training is 64.4715909090909\n",
            "Batch Id 1100/2438 is having training loss of 1.3757342100143433\n",
            "1.488932728767395\n",
            "Epoch #2. Accuracy on batch 1100/2438  on Training is 64.46696185286103\n",
            "Epoch #2. Accuracy on batch 1101/2438  on Training is 64.46801270417423\n",
            "Epoch #2. Accuracy on batch 1102/2438  on Training is 64.45489573889392\n",
            "Epoch #2. Accuracy on batch 1103/2438  on Training is 64.45595561594203\n",
            "Epoch #2. Accuracy on batch 1104/2438  on Training is 64.44852941176471\n",
            "Epoch #2. Accuracy on batch 1105/2438  on Training is 64.45806962025317\n",
            "Epoch #2. Accuracy on batch 1106/2438  on Training is 64.44783197831978\n",
            "Epoch #2. Accuracy on batch 1107/2438  on Training is 64.44889440433214\n",
            "Epoch #2. Accuracy on batch 1108/2438  on Training is 64.44713706041479\n",
            "Epoch #2. Accuracy on batch 1109/2438  on Training is 64.45382882882883\n",
            "Epoch #2. Accuracy on batch 1110/2438  on Training is 64.4520702070207\n",
            "Epoch #2. Accuracy on batch 1111/2438  on Training is 64.45874550359713\n",
            "Epoch #2. Accuracy on batch 1112/2438  on Training is 64.46821653189578\n",
            "Epoch #2. Accuracy on batch 1113/2438  on Training is 64.47206014362656\n",
            "Epoch #2. Accuracy on batch 1114/2438  on Training is 64.4786995515695\n",
            "Epoch #2. Accuracy on batch 1115/2438  on Training is 64.47132616487455\n",
            "Epoch #2. Accuracy on batch 1116/2438  on Training is 64.48075201432408\n",
            "Epoch #2. Accuracy on batch 1117/2438  on Training is 64.46779964221825\n",
            "Epoch #2. Accuracy on batch 1118/2438  on Training is 64.47441912421804\n",
            "Epoch #2. Accuracy on batch 1119/2438  on Training is 64.47265625\n",
            "Batch Id 1120/2438 is having training loss of 1.375442385673523\n",
            "1.4086521863937378\n",
            "Epoch #2. Accuracy on batch 1120/2438  on Training is 64.47368421052632\n",
            "Epoch #2. Accuracy on batch 1121/2438  on Training is 64.46078431372548\n",
            "Epoch #2. Accuracy on batch 1122/2438  on Training is 64.45347284060553\n",
            "Epoch #2. Accuracy on batch 1123/2438  on Training is 64.46285587188612\n",
            "Epoch #2. Accuracy on batch 1124/2438  on Training is 64.45833333333333\n",
            "Epoch #2. Accuracy on batch 1125/2438  on Training is 64.46214476021315\n",
            "Epoch #2. Accuracy on batch 1126/2438  on Training is 64.46040372670808\n",
            "Epoch #2. Accuracy on batch 1127/2438  on Training is 64.46420656028369\n",
            "Epoch #2. Accuracy on batch 1128/2438  on Training is 64.46523472099203\n",
            "Epoch #2. Accuracy on batch 1129/2438  on Training is 64.46073008849558\n",
            "Epoch #2. Accuracy on batch 1130/2438  on Training is 64.45070733863837\n",
            "Epoch #2. Accuracy on batch 1131/2438  on Training is 64.4627871024735\n",
            "Epoch #2. Accuracy on batch 1132/2438  on Training is 64.45829655781112\n",
            "Epoch #2. Accuracy on batch 1133/2438  on Training is 64.4620811287478\n",
            "Epoch #2. Accuracy on batch 1134/2438  on Training is 64.47687224669603\n",
            "Epoch #2. Accuracy on batch 1135/2438  on Training is 64.47788292253522\n",
            "Epoch #2. Accuracy on batch 1136/2438  on Training is 64.4843887423043\n",
            "Epoch #2. Accuracy on batch 1137/2438  on Training is 64.48813708260106\n",
            "Epoch #2. Accuracy on batch 1138/2438  on Training is 64.49187884108868\n",
            "Epoch #2. Accuracy on batch 1139/2438  on Training is 64.49561403508773\n",
            "Batch Id 1140/2438 is having training loss of 1.3748654127120972\n",
            "1.5460240840911865\n",
            "Epoch #2. Accuracy on batch 1140/2438  on Training is 64.49386503067484\n",
            "Epoch #2. Accuracy on batch 1141/2438  on Training is 64.49211908931699\n",
            "Epoch #2. Accuracy on batch 1142/2438  on Training is 64.47944006999126\n",
            "Epoch #2. Accuracy on batch 1143/2438  on Training is 64.46951486013987\n",
            "Epoch #2. Accuracy on batch 1144/2438  on Training is 64.47598253275109\n",
            "Epoch #2. Accuracy on batch 1145/2438  on Training is 64.49334642233858\n",
            "Epoch #2. Accuracy on batch 1146/2438  on Training is 64.48071054925893\n",
            "Epoch #2. Accuracy on batch 1147/2438  on Training is 64.48715156794425\n",
            "Epoch #2. Accuracy on batch 1148/2438  on Training is 64.49902088772846\n",
            "Epoch #2. Accuracy on batch 1149/2438  on Training is 64.50815217391305\n",
            "Epoch #2. Accuracy on batch 1150/2438  on Training is 64.51455256298871\n",
            "Epoch #2. Accuracy on batch 1151/2438  on Training is 64.51280381944444\n",
            "Epoch #2. Accuracy on batch 1152/2438  on Training is 64.51918907198612\n",
            "Epoch #2. Accuracy on batch 1153/2438  on Training is 64.51473136915078\n",
            "Epoch #2. Accuracy on batch 1154/2438  on Training is 64.5211038961039\n",
            "Epoch #2. Accuracy on batch 1155/2438  on Training is 64.51124567474048\n",
            "Epoch #2. Accuracy on batch 1156/2438  on Training is 64.51761019878997\n",
            "Epoch #2. Accuracy on batch 1157/2438  on Training is 64.52396373056995\n",
            "Epoch #2. Accuracy on batch 1158/2438  on Training is 64.53030629853322\n",
            "Epoch #2. Accuracy on batch 1159/2438  on Training is 64.53933189655173\n",
            "Batch Id 1160/2438 is having training loss of 1.3732889890670776\n",
            "1.1982982158660889\n",
            "Epoch #2. Accuracy on batch 1160/2438  on Training is 64.54026701119724\n",
            "Epoch #2. Accuracy on batch 1161/2438  on Training is 64.54388984509467\n",
            "Epoch #2. Accuracy on batch 1162/2438  on Training is 64.54750644883921\n",
            "Epoch #2. Accuracy on batch 1163/2438  on Training is 64.55380154639175\n",
            "Epoch #2. Accuracy on batch 1164/2438  on Training is 64.55203862660944\n",
            "Epoch #2. Accuracy on batch 1165/2438  on Training is 64.5422384219554\n",
            "Epoch #2. Accuracy on batch 1166/2438  on Training is 64.54852185089975\n",
            "Epoch #2. Accuracy on batch 1167/2438  on Training is 64.54944349315069\n",
            "Epoch #2. Accuracy on batch 1168/2438  on Training is 64.5503635585971\n",
            "Epoch #2. Accuracy on batch 1169/2438  on Training is 64.54594017094017\n",
            "Epoch #2. Accuracy on batch 1170/2438  on Training is 64.55219897523484\n",
            "Epoch #2. Accuracy on batch 1171/2438  on Training is 64.54511518771331\n",
            "Epoch #2. Accuracy on batch 1172/2438  on Training is 64.53537936913897\n",
            "Epoch #2. Accuracy on batch 1173/2438  on Training is 64.5442930153322\n",
            "Epoch #2. Accuracy on batch 1174/2438  on Training is 64.54787234042553\n",
            "Epoch #2. Accuracy on batch 1175/2438  on Training is 64.5514455782313\n",
            "Epoch #2. Accuracy on batch 1176/2438  on Training is 64.54704757858964\n",
            "Epoch #2. Accuracy on batch 1177/2438  on Training is 64.54000424448218\n",
            "Epoch #2. Accuracy on batch 1178/2438  on Training is 64.53827396098389\n",
            "Epoch #2. Accuracy on batch 1179/2438  on Training is 64.5259533898305\n",
            "Batch Id 1180/2438 is having training loss of 1.373974323272705\n",
            "1.2324656248092651\n",
            "Epoch #2. Accuracy on batch 1180/2438  on Training is 64.52423793395428\n",
            "Epoch #2. Accuracy on batch 1181/2438  on Training is 64.5093062605753\n",
            "Epoch #2. Accuracy on batch 1182/2438  on Training is 64.50760777683854\n",
            "Epoch #2. Accuracy on batch 1183/2438  on Training is 64.50327280405405\n",
            "Epoch #2. Accuracy on batch 1184/2438  on Training is 64.50158227848101\n",
            "Epoch #2. Accuracy on batch 1185/2438  on Training is 64.4893549747049\n",
            "Epoch #2. Accuracy on batch 1186/2438  on Training is 64.49294439764111\n",
            "Epoch #2. Accuracy on batch 1187/2438  on Training is 64.47285353535354\n",
            "Epoch #2. Accuracy on batch 1188/2438  on Training is 64.47382253994954\n",
            "Epoch #2. Accuracy on batch 1189/2438  on Training is 64.46165966386555\n",
            "Epoch #2. Accuracy on batch 1190/2438  on Training is 64.46263643996642\n",
            "Epoch #2. Accuracy on batch 1191/2438  on Training is 64.4583682885906\n",
            "Epoch #2. Accuracy on batch 1192/2438  on Training is 64.47244341994971\n",
            "Epoch #2. Accuracy on batch 1193/2438  on Training is 64.47340871021775\n",
            "Epoch #2. Accuracy on batch 1194/2438  on Training is 64.4952928870293\n",
            "Epoch #2. Accuracy on batch 1195/2438  on Training is 64.49885033444816\n",
            "Epoch #2. Accuracy on batch 1196/2438  on Training is 64.49718045112782\n",
            "Epoch #2. Accuracy on batch 1197/2438  on Training is 64.5033388981636\n",
            "Epoch #2. Accuracy on batch 1198/2438  on Training is 64.50166805671392\n",
            "Epoch #2. Accuracy on batch 1199/2438  on Training is 64.49739583333333\n",
            "Batch Id 1200/2438 is having training loss of 1.3735854625701904\n",
            "1.2975494861602783\n",
            "Epoch #2. Accuracy on batch 1200/2438  on Training is 64.5009367194005\n",
            "Epoch #2. Accuracy on batch 1201/2438  on Training is 64.49927204658901\n",
            "Epoch #2. Accuracy on batch 1202/2438  on Training is 64.50280548628429\n",
            "Epoch #2. Accuracy on batch 1203/2438  on Training is 64.49854651162791\n",
            "Epoch #2. Accuracy on batch 1204/2438  on Training is 64.49948132780084\n",
            "Epoch #2. Accuracy on batch 1205/2438  on Training is 64.50818822553897\n",
            "Epoch #2. Accuracy on batch 1206/2438  on Training is 64.50652444076222\n",
            "Epoch #2. Accuracy on batch 1207/2438  on Training is 64.50227649006622\n",
            "Epoch #2. Accuracy on batch 1208/2438  on Training is 64.51095947063689\n",
            "Epoch #2. Accuracy on batch 1209/2438  on Training is 64.51446280991736\n",
            "Epoch #2. Accuracy on batch 1210/2438  on Training is 64.51279933938893\n",
            "Epoch #2. Accuracy on batch 1211/2438  on Training is 64.50598184818482\n",
            "Epoch #2. Accuracy on batch 1212/2438  on Training is 64.51205688375927\n",
            "Epoch #2. Accuracy on batch 1213/2438  on Training is 64.51554777594728\n",
            "Epoch #2. Accuracy on batch 1214/2438  on Training is 64.5190329218107\n",
            "Epoch #2. Accuracy on batch 1215/2438  on Training is 64.51737253289474\n",
            "Epoch #2. Accuracy on batch 1216/2438  on Training is 64.51057929334429\n",
            "Epoch #2. Accuracy on batch 1217/2438  on Training is 64.51149425287356\n",
            "Epoch #2. Accuracy on batch 1218/2438  on Training is 64.51497128794094\n",
            "Epoch #2. Accuracy on batch 1219/2438  on Training is 64.5235655737705\n",
            "Batch Id 1220/2438 is having training loss of 1.3727657794952393\n",
            "1.027803659439087\n",
            "Epoch #2. Accuracy on batch 1220/2438  on Training is 64.53214578214578\n",
            "Epoch #2. Accuracy on batch 1221/2438  on Training is 64.53048281505728\n",
            "Epoch #2. Accuracy on batch 1222/2438  on Training is 64.52882256745707\n",
            "Epoch #2. Accuracy on batch 1223/2438  on Training is 64.51950571895425\n",
            "Epoch #2. Accuracy on batch 1224/2438  on Training is 64.52295918367346\n",
            "Epoch #2. Accuracy on batch 1225/2438  on Training is 64.53660277324633\n",
            "Epoch #2. Accuracy on batch 1226/2438  on Training is 64.53239608801955\n",
            "Epoch #2. Accuracy on batch 1227/2438  on Training is 64.53837540716613\n",
            "Epoch #2. Accuracy on batch 1228/2438  on Training is 64.53671684296175\n",
            "Epoch #2. Accuracy on batch 1229/2438  on Training is 64.53506097560975\n",
            "Epoch #2. Accuracy on batch 1230/2438  on Training is 64.53086921202275\n",
            "Epoch #2. Accuracy on batch 1231/2438  on Training is 64.52414772727273\n",
            "Epoch #2. Accuracy on batch 1232/2438  on Training is 64.5301094890511\n",
            "Epoch #2. Accuracy on batch 1233/2438  on Training is 64.53099675850892\n",
            "Epoch #2. Accuracy on batch 1234/2438  on Training is 64.52935222672065\n",
            "Epoch #2. Accuracy on batch 1235/2438  on Training is 64.53276699029126\n",
            "Epoch #2. Accuracy on batch 1236/2438  on Training is 64.53364995957963\n",
            "Epoch #2. Accuracy on batch 1237/2438  on Training is 64.52191033925686\n",
            "Epoch #2. Accuracy on batch 1238/2438  on Training is 64.5253228410008\n",
            "Epoch #2. Accuracy on batch 1239/2438  on Training is 64.53881048387096\n",
            "Batch Id 1240/2438 is having training loss of 1.372127890586853\n",
            "1.7061513662338257\n",
            "Epoch #2. Accuracy on batch 1240/2438  on Training is 64.53716760676873\n",
            "Epoch #2. Accuracy on batch 1241/2438  on Training is 64.5330112721417\n",
            "Epoch #2. Accuracy on batch 1242/2438  on Training is 64.516291230893\n",
            "Epoch #2. Accuracy on batch 1243/2438  on Training is 64.5096463022508\n",
            "Epoch #2. Accuracy on batch 1244/2438  on Training is 64.5105421686747\n",
            "Epoch #2. Accuracy on batch 1245/2438  on Training is 64.52146869983949\n",
            "Epoch #2. Accuracy on batch 1246/2438  on Training is 64.51734161988773\n",
            "Epoch #2. Accuracy on batch 1247/2438  on Training is 64.50320512820512\n",
            "Epoch #2. Accuracy on batch 1248/2438  on Training is 64.50160128102482\n",
            "Epoch #2. Accuracy on batch 1249/2438  on Training is 64.4975\n",
            "Epoch #2. Accuracy on batch 1250/2438  on Training is 64.50089928057554\n",
            "Epoch #2. Accuracy on batch 1251/2438  on Training is 64.50179712460064\n",
            "Epoch #2. Accuracy on batch 1252/2438  on Training is 64.49770550678372\n",
            "Epoch #2. Accuracy on batch 1253/2438  on Training is 64.49112838915471\n",
            "Epoch #2. Accuracy on batch 1254/2438  on Training is 64.49701195219123\n",
            "Epoch #2. Accuracy on batch 1255/2438  on Training is 64.51035031847134\n",
            "Epoch #2. Accuracy on batch 1256/2438  on Training is 64.49880668257757\n",
            "Epoch #2. Accuracy on batch 1257/2438  on Training is 64.50963831478538\n",
            "Epoch #2. Accuracy on batch 1258/2438  on Training is 64.51052422557585\n",
            "Epoch #2. Accuracy on batch 1259/2438  on Training is 64.50892857142857\n",
            "Batch Id 1260/2438 is having training loss of 1.373552918434143\n",
            "1.2097294330596924\n",
            "Epoch #2. Accuracy on batch 1260/2438  on Training is 64.51477002379065\n",
            "Epoch #2. Accuracy on batch 1261/2438  on Training is 64.51812599049128\n",
            "Epoch #2. Accuracy on batch 1262/2438  on Training is 64.5190023752969\n",
            "Epoch #2. Accuracy on batch 1263/2438  on Training is 64.51740506329114\n",
            "Epoch #2. Accuracy on batch 1264/2438  on Training is 64.52322134387352\n",
            "Epoch #2. Accuracy on batch 1265/2438  on Training is 64.5240916271722\n",
            "Epoch #2. Accuracy on batch 1266/2438  on Training is 64.51016179952644\n",
            "Epoch #2. Accuracy on batch 1267/2438  on Training is 64.49871845425868\n",
            "Epoch #2. Accuracy on batch 1268/2438  on Training is 64.49221828211189\n",
            "Epoch #2. Accuracy on batch 1269/2438  on Training is 64.49803149606299\n",
            "Epoch #2. Accuracy on batch 1270/2438  on Training is 64.49400078678207\n",
            "Epoch #2. Accuracy on batch 1271/2438  on Training is 64.49980345911949\n",
            "Epoch #2. Accuracy on batch 1272/2438  on Training is 64.508051846033\n",
            "Epoch #2. Accuracy on batch 1273/2438  on Training is 64.51138147566719\n",
            "Epoch #2. Accuracy on batch 1274/2438  on Training is 64.5\n",
            "Epoch #2. Accuracy on batch 1275/2438  on Training is 64.50333072100314\n",
            "Epoch #2. Accuracy on batch 1276/2438  on Training is 64.48707909162098\n",
            "Epoch #2. Accuracy on batch 1277/2438  on Training is 64.49041471048513\n",
            "Epoch #2. Accuracy on batch 1278/2438  on Training is 64.48885848318999\n",
            "Epoch #2. Accuracy on batch 1279/2438  on Training is 64.49462890625\n",
            "Batch Id 1280/2438 is having training loss of 1.3730061054229736\n",
            "1.2132682800292969\n",
            "Epoch #2. Accuracy on batch 1280/2438  on Training is 64.49063231850117\n",
            "Epoch #2. Accuracy on batch 1281/2438  on Training is 64.48176677067083\n",
            "Epoch #2. Accuracy on batch 1282/2438  on Training is 64.47535074045207\n",
            "Epoch #2. Accuracy on batch 1283/2438  on Training is 64.476246105919\n",
            "Epoch #2. Accuracy on batch 1284/2438  on Training is 64.46741245136187\n",
            "Epoch #2. Accuracy on batch 1285/2438  on Training is 64.47074261275272\n",
            "Epoch #2. Accuracy on batch 1286/2438  on Training is 64.48135198135198\n",
            "Epoch #2. Accuracy on batch 1287/2438  on Training is 64.4822399068323\n",
            "Epoch #2. Accuracy on batch 1288/2438  on Training is 64.47585337470908\n",
            "Epoch #2. Accuracy on batch 1289/2438  on Training is 64.47432170542636\n",
            "Epoch #2. Accuracy on batch 1290/2438  on Training is 64.47279240898528\n",
            "Epoch #2. Accuracy on batch 1291/2438  on Training is 64.48819659442725\n",
            "Epoch #2. Accuracy on batch 1292/2438  on Training is 64.49390951276102\n",
            "Epoch #2. Accuracy on batch 1293/2438  on Training is 64.48029366306028\n",
            "Epoch #2. Accuracy on batch 1294/2438  on Training is 64.48841698841699\n",
            "Epoch #2. Accuracy on batch 1295/2438  on Training is 64.48688271604938\n",
            "Epoch #2. Accuracy on batch 1296/2438  on Training is 64.4757131842714\n",
            "Epoch #2. Accuracy on batch 1297/2438  on Training is 64.47178351309707\n",
            "Epoch #2. Accuracy on batch 1298/2438  on Training is 64.47507698229407\n",
            "Epoch #2. Accuracy on batch 1299/2438  on Training is 64.48076923076923\n",
            "Batch Id 1300/2438 is having training loss of 1.3733018636703491\n",
            "1.519482135772705\n",
            "Epoch #2. Accuracy on batch 1300/2438  on Training is 64.4792467332821\n",
            "Epoch #2. Accuracy on batch 1301/2438  on Training is 64.4801267281106\n",
            "Epoch #2. Accuracy on batch 1302/2438  on Training is 64.50259017651574\n",
            "Epoch #2. Accuracy on batch 1303/2438  on Training is 64.51303680981596\n",
            "Epoch #2. Accuracy on batch 1304/2438  on Training is 64.51149425287356\n",
            "Epoch #2. Accuracy on batch 1305/2438  on Training is 64.51473966309341\n",
            "Epoch #2. Accuracy on batch 1306/2438  on Training is 64.49407039020657\n",
            "Epoch #2. Accuracy on batch 1307/2438  on Training is 64.48298929663609\n",
            "Epoch #2. Accuracy on batch 1308/2438  on Training is 64.481474407945\n",
            "Epoch #2. Accuracy on batch 1309/2438  on Training is 64.47757633587786\n",
            "Epoch #2. Accuracy on batch 1310/2438  on Training is 64.47368421052632\n",
            "Epoch #2. Accuracy on batch 1311/2438  on Training is 64.47456173780488\n",
            "Epoch #2. Accuracy on batch 1312/2438  on Training is 64.46353769992383\n",
            "Epoch #2. Accuracy on batch 1313/2438  on Training is 64.46442161339422\n",
            "Epoch #2. Accuracy on batch 1314/2438  on Training is 64.46768060836501\n",
            "Epoch #2. Accuracy on batch 1315/2438  on Training is 64.45906155015197\n",
            "Epoch #2. Accuracy on batch 1316/2438  on Training is 64.46943811693242\n",
            "Epoch #2. Accuracy on batch 1317/2438  on Training is 64.46794385432473\n",
            "Epoch #2. Accuracy on batch 1318/2438  on Training is 64.4640826383624\n",
            "Epoch #2. Accuracy on batch 1319/2438  on Training is 64.46969696969697\n",
            "Batch Id 1320/2438 is having training loss of 1.3733516931533813\n",
            "1.0385137796401978\n",
            "Epoch #2. Accuracy on batch 1320/2438  on Training is 64.47530280090841\n",
            "Epoch #2. Accuracy on batch 1321/2438  on Training is 64.48090015128594\n",
            "Epoch #2. Accuracy on batch 1322/2438  on Training is 64.47704081632654\n",
            "Epoch #2. Accuracy on batch 1323/2438  on Training is 64.4684667673716\n",
            "Epoch #2. Accuracy on batch 1324/2438  on Training is 64.46462264150944\n",
            "Epoch #2. Accuracy on batch 1325/2438  on Training is 64.46078431372548\n",
            "Epoch #2. Accuracy on batch 1326/2438  on Training is 64.45224189902035\n",
            "Epoch #2. Accuracy on batch 1327/2438  on Training is 64.4601844879518\n",
            "Epoch #2. Accuracy on batch 1328/2438  on Training is 64.47046651617758\n",
            "Epoch #2. Accuracy on batch 1329/2438  on Training is 64.46193609022556\n",
            "Epoch #2. Accuracy on batch 1330/2438  on Training is 64.46280991735537\n",
            "Epoch #2. Accuracy on batch 1331/2438  on Training is 64.46837462462463\n",
            "Epoch #2. Accuracy on batch 1332/2438  on Training is 64.46220930232558\n",
            "Epoch #2. Accuracy on batch 1333/2438  on Training is 64.45605322338831\n",
            "Epoch #2. Accuracy on batch 1334/2438  on Training is 64.45926966292134\n",
            "Epoch #2. Accuracy on batch 1335/2438  on Training is 64.46248128742515\n",
            "Epoch #2. Accuracy on batch 1336/2438  on Training is 64.47270007479432\n",
            "Epoch #2. Accuracy on batch 1337/2438  on Training is 64.46889013452915\n",
            "Epoch #2. Accuracy on batch 1338/2438  on Training is 64.48142270351008\n",
            "Epoch #2. Accuracy on batch 1339/2438  on Training is 64.48460820895522\n",
            "Batch Id 1340/2438 is having training loss of 1.3734956979751587\n",
            "1.6075968742370605\n",
            "Epoch #2. Accuracy on batch 1340/2438  on Training is 64.48312826249068\n",
            "Epoch #2. Accuracy on batch 1341/2438  on Training is 64.48165052160954\n",
            "Epoch #2. Accuracy on batch 1342/2438  on Training is 64.47784810126582\n",
            "Epoch #2. Accuracy on batch 1343/2438  on Training is 64.48102678571429\n",
            "Epoch #2. Accuracy on batch 1344/2438  on Training is 64.48652416356877\n",
            "Epoch #2. Accuracy on batch 1345/2438  on Training is 64.48969167904903\n",
            "Epoch #2. Accuracy on batch 1346/2438  on Training is 64.49981440237565\n",
            "Epoch #2. Accuracy on batch 1347/2438  on Training is 64.50296735905044\n",
            "Epoch #2. Accuracy on batch 1348/2438  on Training is 64.50148257968866\n",
            "Epoch #2. Accuracy on batch 1349/2438  on Training is 64.50694444444444\n",
            "Epoch #2. Accuracy on batch 1350/2438  on Training is 64.51008512213176\n",
            "Epoch #2. Accuracy on batch 1351/2438  on Training is 64.51322115384616\n",
            "Epoch #2. Accuracy on batch 1352/2438  on Training is 64.5071138211382\n",
            "Epoch #2. Accuracy on batch 1353/2438  on Training is 64.5033234859675\n",
            "Epoch #2. Accuracy on batch 1354/2438  on Training is 64.49723247232473\n",
            "Epoch #2. Accuracy on batch 1355/2438  on Training is 64.49345501474926\n",
            "Epoch #2. Accuracy on batch 1356/2438  on Training is 64.4942888725129\n",
            "Epoch #2. Accuracy on batch 1357/2438  on Training is 64.48361561119293\n",
            "Epoch #2. Accuracy on batch 1358/2438  on Training is 64.48445548197203\n",
            "Epoch #2. Accuracy on batch 1359/2438  on Training is 64.4829963235294\n",
            "Batch Id 1360/2438 is having training loss of 1.3732255697250366\n",
            "1.5183196067810059\n",
            "Epoch #2. Accuracy on batch 1360/2438  on Training is 64.47924320352682\n",
            "Epoch #2. Accuracy on batch 1361/2438  on Training is 64.48008443465491\n",
            "Epoch #2. Accuracy on batch 1362/2438  on Training is 64.49009537784299\n",
            "Epoch #2. Accuracy on batch 1363/2438  on Training is 64.49780058651027\n",
            "Epoch #2. Accuracy on batch 1364/2438  on Training is 64.49175824175825\n",
            "Epoch #2. Accuracy on batch 1365/2438  on Training is 64.48801244509517\n",
            "Epoch #2. Accuracy on batch 1366/2438  on Training is 64.4751280175567\n",
            "Epoch #2. Accuracy on batch 1367/2438  on Training is 64.47825292397661\n",
            "Epoch #2. Accuracy on batch 1368/2438  on Training is 64.49050401753104\n",
            "Epoch #2. Accuracy on batch 1369/2438  on Training is 64.50045620437956\n",
            "Epoch #2. Accuracy on batch 1370/2438  on Training is 64.50127644055434\n",
            "Epoch #2. Accuracy on batch 1371/2438  on Training is 64.49981778425656\n",
            "Epoch #2. Accuracy on batch 1372/2438  on Training is 64.49608521485797\n",
            "Epoch #2. Accuracy on batch 1373/2438  on Training is 64.5082787481805\n",
            "Epoch #2. Accuracy on batch 1374/2438  on Training is 64.50454545454545\n",
            "Epoch #2. Accuracy on batch 1375/2438  on Training is 64.51444404069767\n",
            "Epoch #2. Accuracy on batch 1376/2438  on Training is 64.51978939724037\n",
            "Epoch #2. Accuracy on batch 1377/2438  on Training is 64.52285921625544\n",
            "Epoch #2. Accuracy on batch 1378/2438  on Training is 64.52592458303118\n",
            "Epoch #2. Accuracy on batch 1379/2438  on Training is 64.52445652173913\n",
            "Batch Id 1380/2438 is having training loss of 1.3718860149383545\n",
            "1.4405722618103027\n",
            "Epoch #2. Accuracy on batch 1380/2438  on Training is 64.52299058653149\n",
            "Epoch #2. Accuracy on batch 1381/2438  on Training is 64.52378798842257\n",
            "Epoch #2. Accuracy on batch 1382/2438  on Training is 64.51102675343456\n",
            "Epoch #2. Accuracy on batch 1383/2438  on Training is 64.50731575144509\n",
            "Epoch #2. Accuracy on batch 1384/2438  on Training is 64.51263537906136\n",
            "Epoch #2. Accuracy on batch 1385/2438  on Training is 64.49314574314575\n",
            "Epoch #2. Accuracy on batch 1386/2438  on Training is 64.49170872386446\n",
            "Epoch #2. Accuracy on batch 1387/2438  on Training is 64.48351945244957\n",
            "Epoch #2. Accuracy on batch 1388/2438  on Training is 64.47984161267098\n",
            "Epoch #2. Accuracy on batch 1389/2438  on Training is 64.4806654676259\n",
            "Epoch #2. Accuracy on batch 1390/2438  on Training is 64.4814881380302\n",
            "Epoch #2. Accuracy on batch 1391/2438  on Training is 64.48006465517241\n",
            "Epoch #2. Accuracy on batch 1392/2438  on Training is 64.49434673366834\n",
            "Epoch #2. Accuracy on batch 1393/2438  on Training is 64.49739956958393\n",
            "Epoch #2. Accuracy on batch 1394/2438  on Training is 64.50044802867383\n",
            "Epoch #2. Accuracy on batch 1395/2438  on Training is 64.50125358166189\n",
            "Epoch #2. Accuracy on batch 1396/2438  on Training is 64.5065318539728\n",
            "Epoch #2. Accuracy on batch 1397/2438  on Training is 64.50062589413447\n",
            "Epoch #2. Accuracy on batch 1398/2438  on Training is 64.50366333095067\n",
            "Epoch #2. Accuracy on batch 1399/2438  on Training is 64.50892857142857\n",
            "Batch Id 1400/2438 is having training loss of 1.3719611167907715\n",
            "1.9347118139266968\n",
            "Epoch #2. Accuracy on batch 1400/2438  on Training is 64.4941113490364\n",
            "Epoch #2. Accuracy on batch 1401/2438  on Training is 64.49714693295293\n",
            "Epoch #2. Accuracy on batch 1402/2438  on Training is 64.49572344975053\n",
            "Epoch #2. Accuracy on batch 1403/2438  on Training is 64.49430199430199\n",
            "Epoch #2. Accuracy on batch 1404/2438  on Training is 64.49065836298932\n",
            "Epoch #2. Accuracy on batch 1405/2438  on Training is 64.49146514935988\n",
            "Epoch #2. Accuracy on batch 1406/2438  on Training is 64.49893390191897\n",
            "Epoch #2. Accuracy on batch 1407/2438  on Training is 64.48419744318181\n",
            "Epoch #2. Accuracy on batch 1408/2438  on Training is 64.48278921220724\n",
            "Epoch #2. Accuracy on batch 1409/2438  on Training is 64.4747340425532\n",
            "Epoch #2. Accuracy on batch 1410/2438  on Training is 64.47776399716513\n",
            "Epoch #2. Accuracy on batch 1411/2438  on Training is 64.47857648725213\n",
            "Epoch #2. Accuracy on batch 1412/2438  on Training is 64.46390658174097\n",
            "Epoch #2. Accuracy on batch 1413/2438  on Training is 64.47135785007072\n",
            "Epoch #2. Accuracy on batch 1414/2438  on Training is 64.4743816254417\n",
            "Epoch #2. Accuracy on batch 1415/2438  on Training is 64.48181497175142\n",
            "Epoch #2. Accuracy on batch 1416/2438  on Training is 64.4870324629499\n",
            "Epoch #2. Accuracy on batch 1417/2438  on Training is 64.47681593794076\n",
            "Epoch #2. Accuracy on batch 1418/2438  on Training is 64.4710183227625\n",
            "Epoch #2. Accuracy on batch 1419/2438  on Training is 64.47183098591549\n",
            "Batch Id 1420/2438 is having training loss of 1.3719205856323242\n",
            "1.1540223360061646\n",
            "Epoch #2. Accuracy on batch 1420/2438  on Training is 64.47484166080226\n",
            "Epoch #2. Accuracy on batch 1421/2438  on Training is 64.47125527426161\n",
            "Epoch #2. Accuracy on batch 1422/2438  on Training is 64.47645818692902\n",
            "Epoch #2. Accuracy on batch 1423/2438  on Training is 64.47726474719101\n",
            "Epoch #2. Accuracy on batch 1424/2438  on Training is 64.46929824561404\n",
            "Epoch #2. Accuracy on batch 1425/2438  on Training is 64.47449158485273\n",
            "Epoch #2. Accuracy on batch 1426/2438  on Training is 64.48624737210932\n",
            "Epoch #2. Accuracy on batch 1427/2438  on Training is 64.49142156862744\n",
            "Epoch #2. Accuracy on batch 1428/2438  on Training is 64.49440167949615\n",
            "Epoch #2. Accuracy on batch 1429/2438  on Training is 64.49737762237763\n",
            "Epoch #2. Accuracy on batch 1430/2438  on Training is 64.49816561844864\n",
            "Epoch #2. Accuracy on batch 1431/2438  on Training is 64.49458798882682\n",
            "Epoch #2. Accuracy on batch 1432/2438  on Training is 64.49537683182136\n",
            "Epoch #2. Accuracy on batch 1433/2438  on Training is 64.50270223152022\n",
            "Epoch #2. Accuracy on batch 1434/2438  on Training is 64.50566202090593\n",
            "Epoch #2. Accuracy on batch 1435/2438  on Training is 64.49338440111421\n",
            "Epoch #2. Accuracy on batch 1436/2438  on Training is 64.4919972164231\n",
            "Epoch #2. Accuracy on batch 1437/2438  on Training is 64.48191933240612\n",
            "Epoch #2. Accuracy on batch 1438/2438  on Training is 64.48271369006254\n",
            "Epoch #2. Accuracy on batch 1439/2438  on Training is 64.47265625\n",
            "Batch Id 1440/2438 is having training loss of 1.3718624114990234\n",
            "1.133204698562622\n",
            "Epoch #2. Accuracy on batch 1440/2438  on Training is 64.47996183206106\n",
            "Epoch #2. Accuracy on batch 1441/2438  on Training is 64.49159153952843\n",
            "Epoch #2. Accuracy on batch 1442/2438  on Training is 64.49454261954261\n",
            "Epoch #2. Accuracy on batch 1443/2438  on Training is 64.49532548476455\n",
            "Epoch #2. Accuracy on batch 1444/2438  on Training is 64.49178200692042\n",
            "Epoch #2. Accuracy on batch 1445/2438  on Training is 64.4990491009682\n",
            "Epoch #2. Accuracy on batch 1446/2438  on Training is 64.49550794747753\n",
            "Epoch #2. Accuracy on batch 1447/2438  on Training is 64.49197168508287\n",
            "Epoch #2. Accuracy on batch 1448/2438  on Training is 64.4884403036577\n",
            "Epoch #2. Accuracy on batch 1449/2438  on Training is 64.5\n",
            "Epoch #2. Accuracy on batch 1450/2438  on Training is 64.49000689179876\n",
            "Epoch #2. Accuracy on batch 1451/2438  on Training is 64.49078856749311\n",
            "Epoch #2. Accuracy on batch 1452/2438  on Training is 64.48726772195458\n",
            "Epoch #2. Accuracy on batch 1453/2438  on Training is 64.48375171939477\n",
            "Epoch #2. Accuracy on batch 1454/2438  on Training is 64.4909793814433\n",
            "Epoch #2. Accuracy on batch 1455/2438  on Training is 64.48531936813187\n",
            "Epoch #2. Accuracy on batch 1456/2438  on Training is 64.48181194234729\n",
            "Epoch #2. Accuracy on batch 1457/2438  on Training is 64.47616598079561\n",
            "Epoch #2. Accuracy on batch 1458/2438  on Training is 64.47052775873887\n",
            "Epoch #2. Accuracy on batch 1459/2438  on Training is 64.4755993150685\n",
            "Batch Id 1460/2438 is having training loss of 1.3719373941421509\n",
            "1.2494916915893555\n",
            "Epoch #2. Accuracy on batch 1460/2438  on Training is 64.47852498288843\n",
            "Epoch #2. Accuracy on batch 1461/2438  on Training is 64.48144664842681\n",
            "Epoch #2. Accuracy on batch 1462/2438  on Training is 64.47154818865346\n",
            "Epoch #2. Accuracy on batch 1463/2438  on Training is 64.46379781420765\n",
            "Epoch #2. Accuracy on batch 1464/2438  on Training is 64.46032423208192\n",
            "Epoch #2. Accuracy on batch 1465/2438  on Training is 64.46325034106412\n",
            "Epoch #2. Accuracy on batch 1466/2438  on Training is 64.46404226312202\n",
            "Epoch #2. Accuracy on batch 1467/2438  on Training is 64.46483310626704\n",
            "Epoch #2. Accuracy on batch 1468/2438  on Training is 64.45924098025868\n",
            "Epoch #2. Accuracy on batch 1469/2438  on Training is 64.45578231292517\n",
            "Epoch #2. Accuracy on batch 1470/2438  on Training is 64.45445275322909\n",
            "Epoch #2. Accuracy on batch 1471/2438  on Training is 64.45100203804348\n",
            "Epoch #2. Accuracy on batch 1472/2438  on Training is 64.44967752885267\n",
            "Epoch #2. Accuracy on batch 1473/2438  on Training is 64.46107530529173\n",
            "Epoch #2. Accuracy on batch 1474/2438  on Training is 64.46610169491525\n",
            "Epoch #2. Accuracy on batch 1475/2438  on Training is 64.46476964769647\n",
            "Epoch #2. Accuracy on batch 1476/2438  on Training is 64.4740182802979\n",
            "Epoch #2. Accuracy on batch 1477/2438  on Training is 64.47691136671178\n",
            "Epoch #2. Accuracy on batch 1478/2438  on Training is 64.47980054090601\n",
            "Epoch #2. Accuracy on batch 1479/2438  on Training is 64.4826858108108\n",
            "Batch Id 1480/2438 is having training loss of 1.371272087097168\n",
            "1.5553337335586548\n",
            "Epoch #2. Accuracy on batch 1480/2438  on Training is 64.47290681971641\n",
            "Epoch #2. Accuracy on batch 1481/2438  on Training is 64.4694669365722\n",
            "Epoch #2. Accuracy on batch 1482/2438  on Training is 64.47235333782872\n",
            "Epoch #2. Accuracy on batch 1483/2438  on Training is 64.47102425876011\n",
            "Epoch #2. Accuracy on batch 1484/2438  on Training is 64.46338383838383\n",
            "Epoch #2. Accuracy on batch 1485/2438  on Training is 64.46837146702558\n",
            "Epoch #2. Accuracy on batch 1486/2438  on Training is 64.4586415601883\n",
            "Epoch #2. Accuracy on batch 1487/2438  on Training is 64.46152553763442\n",
            "Epoch #2. Accuracy on batch 1488/2438  on Training is 64.44761584956346\n",
            "Epoch #2. Accuracy on batch 1489/2438  on Training is 64.44840604026845\n",
            "Epoch #2. Accuracy on batch 1490/2438  on Training is 64.4554828973843\n",
            "Epoch #2. Accuracy on batch 1491/2438  on Training is 64.45417225201072\n",
            "Epoch #2. Accuracy on batch 1492/2438  on Training is 64.45914266577361\n",
            "Epoch #2. Accuracy on batch 1493/2438  on Training is 64.46619812583668\n",
            "Epoch #2. Accuracy on batch 1494/2438  on Training is 64.46070234113712\n",
            "Epoch #2. Accuracy on batch 1495/2438  on Training is 64.4656584224599\n",
            "Epoch #2. Accuracy on batch 1496/2438  on Training is 64.4622578490314\n",
            "Epoch #2. Accuracy on batch 1497/2438  on Training is 64.46512016021362\n",
            "Epoch #2. Accuracy on batch 1498/2438  on Training is 64.47006337558372\n",
            "Epoch #2. Accuracy on batch 1499/2438  on Training is 64.47291666666666\n",
            "Batch Id 1500/2438 is having training loss of 1.3707917928695679\n",
            "1.138379693031311\n",
            "Epoch #2. Accuracy on batch 1500/2438  on Training is 64.47160226515656\n",
            "Epoch #2. Accuracy on batch 1501/2438  on Training is 64.48069241011984\n",
            "Epoch #2. Accuracy on batch 1502/2438  on Training is 64.47105788423154\n",
            "Epoch #2. Accuracy on batch 1503/2438  on Training is 64.46559175531915\n",
            "Epoch #2. Accuracy on batch 1504/2438  on Training is 64.46636212624584\n",
            "Epoch #2. Accuracy on batch 1505/2438  on Training is 64.46298140770253\n",
            "Epoch #2. Accuracy on batch 1506/2438  on Training is 64.45545786330457\n",
            "Epoch #2. Accuracy on batch 1507/2438  on Training is 64.45623342175067\n",
            "Epoch #2. Accuracy on batch 1508/2438  on Training is 64.46736249171637\n",
            "Epoch #2. Accuracy on batch 1509/2438  on Training is 64.47019867549669\n",
            "Epoch #2. Accuracy on batch 1510/2438  on Training is 64.47096293845135\n",
            "Epoch #2. Accuracy on batch 1511/2438  on Training is 64.4655257936508\n",
            "Epoch #2. Accuracy on batch 1512/2438  on Training is 64.46629213483146\n",
            "Epoch #2. Accuracy on batch 1513/2438  on Training is 64.46086525759577\n",
            "Epoch #2. Accuracy on batch 1514/2438  on Training is 64.45750825082509\n",
            "Epoch #2. Accuracy on batch 1515/2438  on Training is 64.46033970976254\n",
            "Epoch #2. Accuracy on batch 1516/2438  on Training is 64.45080751483191\n",
            "Epoch #2. Accuracy on batch 1517/2438  on Training is 64.46599143610013\n",
            "Epoch #2. Accuracy on batch 1518/2438  on Training is 64.47292626728111\n",
            "Epoch #2. Accuracy on batch 1519/2438  on Training is 64.47574013157895\n",
            "Batch Id 1520/2438 is having training loss of 1.37020742893219\n",
            "1.255082368850708\n",
            "Epoch #2. Accuracy on batch 1520/2438  on Training is 64.4723865877712\n",
            "Epoch #2. Accuracy on batch 1521/2438  on Training is 64.46493101182655\n",
            "Epoch #2. Accuracy on batch 1522/2438  on Training is 64.46364084044649\n",
            "Epoch #2. Accuracy on batch 1523/2438  on Training is 64.45825131233596\n",
            "Epoch #2. Accuracy on batch 1524/2438  on Training is 64.46516393442623\n",
            "Epoch #2. Accuracy on batch 1525/2438  on Training is 64.47206749672345\n",
            "Epoch #2. Accuracy on batch 1526/2438  on Training is 64.47282252783235\n",
            "Epoch #2. Accuracy on batch 1527/2438  on Training is 64.47357657068063\n",
            "Epoch #2. Accuracy on batch 1528/2438  on Training is 64.47432962720733\n",
            "Epoch #2. Accuracy on batch 1529/2438  on Training is 64.47712418300654\n",
            "Epoch #2. Accuracy on batch 1530/2438  on Training is 64.4717504898759\n",
            "Epoch #2. Accuracy on batch 1531/2438  on Training is 64.46842362924282\n",
            "Epoch #2. Accuracy on batch 1532/2438  on Training is 64.47529354207437\n",
            "Epoch #2. Accuracy on batch 1533/2438  on Training is 64.47808018252934\n",
            "Epoch #2. Accuracy on batch 1534/2438  on Training is 64.4849348534202\n",
            "Epoch #2. Accuracy on batch 1535/2438  on Training is 64.48974609375\n",
            "Epoch #2. Accuracy on batch 1536/2438  on Training is 64.4925178919974\n",
            "Epoch #2. Accuracy on batch 1537/2438  on Training is 64.49934980494149\n",
            "Epoch #2. Accuracy on batch 1538/2438  on Training is 64.50820337881741\n",
            "Epoch #2. Accuracy on batch 1539/2438  on Training is 64.50689935064935\n",
            "Batch Id 1540/2438 is having training loss of 1.3686094284057617\n",
            "1.0541969537734985\n",
            "Epoch #2. Accuracy on batch 1540/2438  on Training is 64.51776443867618\n",
            "Epoch #2. Accuracy on batch 1541/2438  on Training is 64.5083495460441\n",
            "Epoch #2. Accuracy on batch 1542/2438  on Training is 64.5151490602722\n",
            "Epoch #2. Accuracy on batch 1543/2438  on Training is 64.50777202072538\n",
            "Epoch #2. Accuracy on batch 1544/2438  on Training is 64.51051779935275\n",
            "Epoch #2. Accuracy on batch 1545/2438  on Training is 64.51326002587322\n",
            "Epoch #2. Accuracy on batch 1546/2438  on Training is 64.50993859082094\n",
            "Epoch #2. Accuracy on batch 1547/2438  on Training is 64.50662144702842\n",
            "Epoch #2. Accuracy on batch 1548/2438  on Training is 64.50330858618463\n",
            "Epoch #2. Accuracy on batch 1549/2438  on Training is 64.49596774193549\n",
            "Epoch #2. Accuracy on batch 1550/2438  on Training is 64.49871050934881\n",
            "Epoch #2. Accuracy on batch 1551/2438  on Training is 64.4933956185567\n",
            "Epoch #2. Accuracy on batch 1552/2438  on Training is 64.49412427559562\n",
            "Epoch #2. Accuracy on batch 1553/2438  on Training is 64.49284105534106\n",
            "Epoch #2. Accuracy on batch 1554/2438  on Training is 64.48352090032154\n",
            "Epoch #2. Accuracy on batch 1555/2438  on Training is 64.48827120822622\n",
            "Epoch #2. Accuracy on batch 1556/2438  on Training is 64.48900128452152\n",
            "Epoch #2. Accuracy on batch 1557/2438  on Training is 64.49374197689345\n",
            "Epoch #2. Accuracy on batch 1558/2438  on Training is 64.50449005772931\n",
            "Epoch #2. Accuracy on batch 1559/2438  on Training is 64.49919871794872\n",
            "Batch Id 1560/2438 is having training loss of 1.3690413236618042\n",
            "1.1274362802505493\n",
            "Epoch #2. Accuracy on batch 1560/2438  on Training is 64.50392376681614\n",
            "Epoch #2. Accuracy on batch 1561/2438  on Training is 64.51464468629962\n",
            "Epoch #2. Accuracy on batch 1562/2438  on Training is 64.51535508637237\n",
            "Epoch #2. Accuracy on batch 1563/2438  on Training is 64.51606457800511\n",
            "Epoch #2. Accuracy on batch 1564/2438  on Training is 64.52076677316293\n",
            "Epoch #2. Accuracy on batch 1565/2438  on Training is 64.52147190293742\n",
            "Epoch #2. Accuracy on batch 1566/2438  on Training is 64.5181876196554\n",
            "Epoch #2. Accuracy on batch 1567/2438  on Training is 64.51690051020408\n",
            "Epoch #2. Accuracy on batch 1568/2438  on Training is 64.51362332695984\n",
            "Epoch #2. Accuracy on batch 1569/2438  on Training is 64.51831210191082\n",
            "Epoch #2. Accuracy on batch 1570/2438  on Training is 64.52100572883514\n",
            "Epoch #2. Accuracy on batch 1571/2438  on Training is 64.51773218829517\n",
            "Epoch #2. Accuracy on batch 1572/2438  on Training is 64.51446280991736\n",
            "Epoch #2. Accuracy on batch 1573/2438  on Training is 64.51516836086404\n",
            "Epoch #2. Accuracy on batch 1574/2438  on Training is 64.51587301587301\n",
            "Epoch #2. Accuracy on batch 1575/2438  on Training is 64.51855964467005\n",
            "Epoch #2. Accuracy on batch 1576/2438  on Training is 64.5232244768548\n",
            "Epoch #2. Accuracy on batch 1577/2438  on Training is 64.5239226869455\n",
            "Epoch #2. Accuracy on batch 1578/2438  on Training is 64.51868271057631\n",
            "Epoch #2. Accuracy on batch 1579/2438  on Training is 64.52729430379746\n",
            "Batch Id 1580/2438 is having training loss of 1.3680964708328247\n",
            "1.3837811946868896\n",
            "Epoch #2. Accuracy on batch 1580/2438  on Training is 64.53589500316255\n",
            "Epoch #2. Accuracy on batch 1581/2438  on Training is 64.53065739570164\n",
            "Epoch #2. Accuracy on batch 1582/2438  on Training is 64.52937460518004\n",
            "Epoch #2. Accuracy on batch 1583/2438  on Training is 64.5340119949495\n",
            "Epoch #2. Accuracy on batch 1584/2438  on Training is 64.53864353312302\n",
            "Epoch #2. Accuracy on batch 1585/2438  on Training is 64.5452395964691\n",
            "Epoch #2. Accuracy on batch 1586/2438  on Training is 64.54395085066163\n",
            "Epoch #2. Accuracy on batch 1587/2438  on Training is 64.55053526448363\n",
            "Epoch #2. Accuracy on batch 1588/2438  on Training is 64.55514474512272\n",
            "Epoch #2. Accuracy on batch 1589/2438  on Training is 64.55385220125787\n",
            "Epoch #2. Accuracy on batch 1590/2438  on Training is 64.55648962916405\n",
            "Epoch #2. Accuracy on batch 1591/2438  on Training is 64.56501256281408\n",
            "Epoch #2. Accuracy on batch 1592/2438  on Training is 64.56175455116133\n",
            "Epoch #2. Accuracy on batch 1593/2438  on Training is 64.56830301129234\n",
            "Epoch #2. Accuracy on batch 1594/2438  on Training is 64.56896551724138\n",
            "Epoch #2. Accuracy on batch 1595/2438  on Training is 64.56766917293233\n",
            "Epoch #2. Accuracy on batch 1596/2438  on Training is 64.56246086412023\n",
            "Epoch #2. Accuracy on batch 1597/2438  on Training is 64.56899249061327\n",
            "Epoch #2. Accuracy on batch 1598/2438  on Training is 64.56965290806754\n",
            "Epoch #2. Accuracy on batch 1599/2438  on Training is 64.56640625\n",
            "Batch Id 1600/2438 is having training loss of 1.3679801225662231\n",
            "1.2217131853103638\n",
            "Epoch #2. Accuracy on batch 1600/2438  on Training is 64.56706745783885\n",
            "Epoch #2. Accuracy on batch 1601/2438  on Training is 64.56772784019975\n",
            "Epoch #2. Accuracy on batch 1602/2438  on Training is 64.56253898939488\n",
            "Epoch #2. Accuracy on batch 1603/2438  on Training is 64.56904613466334\n",
            "Epoch #2. Accuracy on batch 1604/2438  on Training is 64.56580996884735\n",
            "Epoch #2. Accuracy on batch 1605/2438  on Training is 64.56452366127024\n",
            "Epoch #2. Accuracy on batch 1606/2438  on Training is 64.56323895457373\n",
            "Epoch #2. Accuracy on batch 1607/2438  on Training is 64.56972947761194\n",
            "Epoch #2. Accuracy on batch 1608/2438  on Training is 64.56067433188316\n",
            "Epoch #2. Accuracy on batch 1609/2438  on Training is 64.56327639751552\n",
            "Epoch #2. Accuracy on batch 1610/2438  on Training is 64.57557417752949\n",
            "Epoch #2. Accuracy on batch 1611/2438  on Training is 64.5704094292804\n",
            "Epoch #2. Accuracy on batch 1612/2438  on Training is 64.56331370117793\n",
            "Epoch #2. Accuracy on batch 1613/2438  on Training is 64.56009913258984\n",
            "Epoch #2. Accuracy on batch 1614/2438  on Training is 64.55688854489163\n",
            "Epoch #2. Accuracy on batch 1615/2438  on Training is 64.5575495049505\n",
            "Epoch #2. Accuracy on batch 1616/2438  on Training is 64.55627705627705\n",
            "Epoch #2. Accuracy on batch 1617/2438  on Training is 64.55886897404203\n",
            "Epoch #2. Accuracy on batch 1618/2438  on Training is 64.54601605929587\n",
            "Epoch #2. Accuracy on batch 1619/2438  on Training is 64.54282407407408\n",
            "Batch Id 1620/2438 is having training loss of 1.3670711517333984\n",
            "1.294783592224121\n",
            "Epoch #2. Accuracy on batch 1620/2438  on Training is 64.54349167180753\n",
            "Epoch #2. Accuracy on batch 1621/2438  on Training is 64.53645191122071\n",
            "Epoch #2. Accuracy on batch 1622/2438  on Training is 64.53904805914972\n",
            "Epoch #2. Accuracy on batch 1623/2438  on Training is 64.54356527093596\n",
            "Epoch #2. Accuracy on batch 1624/2438  on Training is 64.54615384615384\n",
            "Epoch #2. Accuracy on batch 1625/2438  on Training is 64.54873923739237\n",
            "Epoch #2. Accuracy on batch 1626/2438  on Training is 64.55516287645975\n",
            "Epoch #2. Accuracy on batch 1627/2438  on Training is 64.55198095823096\n",
            "Epoch #2. Accuracy on batch 1628/2438  on Training is 64.55263965623081\n",
            "Epoch #2. Accuracy on batch 1629/2438  on Training is 64.55329754601227\n",
            "Epoch #2. Accuracy on batch 1630/2438  on Training is 64.55395462906192\n",
            "Epoch #2. Accuracy on batch 1631/2438  on Training is 64.55652573529412\n",
            "Epoch #2. Accuracy on batch 1632/2438  on Training is 64.5514390691978\n",
            "Epoch #2. Accuracy on batch 1633/2438  on Training is 64.54827111383109\n",
            "Epoch #2. Accuracy on batch 1634/2438  on Training is 64.5565749235474\n",
            "Epoch #2. Accuracy on batch 1635/2438  on Training is 64.54958740831296\n",
            "Epoch #2. Accuracy on batch 1636/2438  on Training is 64.55024434941967\n",
            "Epoch #2. Accuracy on batch 1637/2438  on Training is 64.55662393162393\n",
            "Epoch #2. Accuracy on batch 1638/2438  on Training is 64.55918242830994\n",
            "Epoch #2. Accuracy on batch 1639/2438  on Training is 64.5579268292683\n",
            "Batch Id 1640/2438 is having training loss of 1.366133451461792\n",
            "1.1784553527832031\n",
            "Epoch #2. Accuracy on batch 1640/2438  on Training is 64.55667276051189\n",
            "Epoch #2. Accuracy on batch 1641/2438  on Training is 64.55351705237516\n",
            "Epoch #2. Accuracy on batch 1642/2438  on Training is 64.55607121119903\n",
            "Epoch #2. Accuracy on batch 1643/2438  on Training is 64.55672141119221\n",
            "Epoch #2. Accuracy on batch 1644/2438  on Training is 64.55927051671732\n",
            "Epoch #2. Accuracy on batch 1645/2438  on Training is 64.55801944106926\n",
            "Epoch #2. Accuracy on batch 1646/2438  on Training is 64.54918032786885\n",
            "Epoch #2. Accuracy on batch 1647/2438  on Training is 64.54604065533981\n",
            "Epoch #2. Accuracy on batch 1648/2438  on Training is 64.55048514251061\n",
            "Epoch #2. Accuracy on batch 1649/2438  on Training is 64.54924242424242\n",
            "Epoch #2. Accuracy on batch 1650/2438  on Training is 64.55746517262266\n",
            "Epoch #2. Accuracy on batch 1651/2438  on Training is 64.56378631961259\n",
            "Epoch #2. Accuracy on batch 1652/2438  on Training is 64.56253781004234\n",
            "Epoch #2. Accuracy on batch 1653/2438  on Training is 64.56506952841596\n",
            "Epoch #2. Accuracy on batch 1654/2438  on Training is 64.56004531722054\n",
            "Epoch #2. Accuracy on batch 1655/2438  on Training is 64.55880132850241\n",
            "Epoch #2. Accuracy on batch 1656/2438  on Training is 64.55944477972238\n",
            "Epoch #2. Accuracy on batch 1657/2438  on Training is 64.55443305186972\n",
            "Epoch #2. Accuracy on batch 1658/2438  on Training is 64.54377637130801\n",
            "Epoch #2. Accuracy on batch 1659/2438  on Training is 64.54442771084338\n",
            "Batch Id 1660/2438 is having training loss of 1.3668256998062134\n",
            "0.8355210423469543\n",
            "Epoch #2. Accuracy on batch 1660/2438  on Training is 64.55448524984949\n",
            "Epoch #2. Accuracy on batch 1661/2438  on Training is 64.54760830324909\n",
            "Epoch #2. Accuracy on batch 1662/2438  on Training is 64.55201443174985\n",
            "Epoch #2. Accuracy on batch 1663/2438  on Training is 64.54514723557692\n",
            "Epoch #2. Accuracy on batch 1664/2438  on Training is 64.5457957957958\n",
            "Epoch #2. Accuracy on batch 1665/2438  on Training is 64.54644357743098\n",
            "Epoch #2. Accuracy on batch 1666/2438  on Training is 64.54709058188362\n",
            "Epoch #2. Accuracy on batch 1667/2438  on Training is 64.53836930455635\n",
            "Epoch #2. Accuracy on batch 1668/2438  on Training is 64.53714799281006\n",
            "Epoch #2. Accuracy on batch 1669/2438  on Training is 64.53967065868264\n",
            "Epoch #2. Accuracy on batch 1670/2438  on Training is 64.54219030520646\n",
            "Epoch #2. Accuracy on batch 1671/2438  on Training is 64.53909988038278\n",
            "Epoch #2. Accuracy on batch 1672/2438  on Training is 64.53601315002989\n",
            "Epoch #2. Accuracy on batch 1673/2438  on Training is 64.52732974910394\n",
            "Epoch #2. Accuracy on batch 1674/2438  on Training is 64.5205223880597\n",
            "Epoch #2. Accuracy on batch 1675/2438  on Training is 64.5174522673031\n",
            "Epoch #2. Accuracy on batch 1676/2438  on Training is 64.51252236135957\n",
            "Epoch #2. Accuracy on batch 1677/2438  on Training is 64.51504767580452\n",
            "Epoch #2. Accuracy on batch 1678/2438  on Training is 64.51198630136986\n",
            "Epoch #2. Accuracy on batch 1679/2438  on Training is 64.5219494047619\n",
            "Batch Id 1680/2438 is having training loss of 1.3672707080841064\n",
            "1.4693074226379395\n",
            "Epoch #2. Accuracy on batch 1680/2438  on Training is 64.52260559190958\n",
            "Epoch #2. Accuracy on batch 1681/2438  on Training is 64.5195451843044\n",
            "Epoch #2. Accuracy on batch 1682/2438  on Training is 64.5239156268568\n",
            "Epoch #2. Accuracy on batch 1683/2438  on Training is 64.53013657957244\n",
            "Epoch #2. Accuracy on batch 1684/2438  on Training is 64.53635014836796\n",
            "Epoch #2. Accuracy on batch 1685/2438  on Training is 64.5388493475682\n",
            "Epoch #2. Accuracy on batch 1686/2438  on Training is 64.53949318316538\n",
            "Epoch #2. Accuracy on batch 1687/2438  on Training is 64.52902843601896\n",
            "Epoch #2. Accuracy on batch 1688/2438  on Training is 64.52597690941386\n",
            "Epoch #2. Accuracy on batch 1689/2438  on Training is 64.53032544378698\n",
            "Epoch #2. Accuracy on batch 1690/2438  on Training is 64.52173270254288\n",
            "Epoch #2. Accuracy on batch 1691/2438  on Training is 64.52053782505911\n",
            "Epoch #2. Accuracy on batch 1692/2438  on Training is 64.52119019492027\n",
            "Epoch #2. Accuracy on batch 1693/2438  on Training is 64.523686540732\n",
            "Epoch #2. Accuracy on batch 1694/2438  on Training is 64.5151179941003\n",
            "Epoch #2. Accuracy on batch 1695/2438  on Training is 64.52130011792453\n",
            "Epoch #2. Accuracy on batch 1696/2438  on Training is 64.5237919858574\n",
            "Epoch #2. Accuracy on batch 1697/2438  on Training is 64.52812131919906\n",
            "Epoch #2. Accuracy on batch 1698/2438  on Training is 64.5306062389641\n",
            "Epoch #2. Accuracy on batch 1699/2438  on Training is 64.52757352941177\n",
            "Batch Id 1700/2438 is having training loss of 1.3662461042404175\n",
            "1.4192242622375488\n",
            "Epoch #2. Accuracy on batch 1700/2438  on Training is 64.52638154027044\n",
            "Epoch #2. Accuracy on batch 1701/2438  on Training is 64.52519095182139\n",
            "Epoch #2. Accuracy on batch 1702/2438  on Training is 64.52216676453318\n",
            "Epoch #2. Accuracy on batch 1703/2438  on Training is 64.52281396713614\n",
            "Epoch #2. Accuracy on batch 1704/2438  on Training is 64.5216275659824\n",
            "Epoch #2. Accuracy on batch 1705/2438  on Training is 64.52227432590855\n",
            "Epoch #2. Accuracy on batch 1706/2438  on Training is 64.51742823667253\n",
            "Epoch #2. Accuracy on batch 1707/2438  on Training is 64.51990632318501\n",
            "Epoch #2. Accuracy on batch 1708/2438  on Training is 64.52603861907548\n",
            "Epoch #2. Accuracy on batch 1709/2438  on Training is 64.52302631578948\n",
            "Epoch #2. Accuracy on batch 1710/2438  on Training is 64.5218439509059\n",
            "Epoch #2. Accuracy on batch 1711/2438  on Training is 64.52248831775701\n",
            "Epoch #2. Accuracy on batch 1712/2438  on Training is 64.52313193228254\n",
            "Epoch #2. Accuracy on batch 1713/2438  on Training is 64.52924445740956\n",
            "Epoch #2. Accuracy on batch 1714/2438  on Training is 64.52806122448979\n",
            "Epoch #2. Accuracy on batch 1715/2438  on Training is 64.53052156177156\n",
            "Epoch #2. Accuracy on batch 1716/2438  on Training is 64.53297903319744\n",
            "Epoch #2. Accuracy on batch 1717/2438  on Training is 64.52997671711292\n",
            "Epoch #2. Accuracy on batch 1718/2438  on Training is 64.532431646306\n",
            "Epoch #2. Accuracy on batch 1719/2438  on Training is 64.53670058139535\n",
            "Batch Id 1720/2438 is having training loss of 1.3657565116882324\n",
            "1.0255783796310425\n",
            "Epoch #2. Accuracy on batch 1720/2438  on Training is 64.54278036025566\n",
            "Epoch #2. Accuracy on batch 1721/2438  on Training is 64.53796457607433\n",
            "Epoch #2. Accuracy on batch 1722/2438  on Training is 64.54222286709228\n",
            "Epoch #2. Accuracy on batch 1723/2438  on Training is 64.55010150812065\n",
            "Epoch #2. Accuracy on batch 1724/2438  on Training is 64.55072463768116\n",
            "Epoch #2. Accuracy on batch 1725/2438  on Training is 64.55134704519119\n",
            "Epoch #2. Accuracy on batch 1726/2438  on Training is 64.5429212507238\n",
            "Epoch #2. Accuracy on batch 1727/2438  on Training is 64.53812210648148\n",
            "Epoch #2. Accuracy on batch 1728/2438  on Training is 64.54055812608445\n",
            "Epoch #2. Accuracy on batch 1729/2438  on Training is 64.54118497109826\n",
            "Epoch #2. Accuracy on batch 1730/2438  on Training is 64.54361640670133\n",
            "Epoch #2. Accuracy on batch 1731/2438  on Training is 64.53521939953811\n",
            "Epoch #2. Accuracy on batch 1732/2438  on Training is 64.53224177726486\n",
            "Epoch #2. Accuracy on batch 1733/2438  on Training is 64.53647635524798\n",
            "Epoch #2. Accuracy on batch 1734/2438  on Training is 64.5335014409222\n",
            "Epoch #2. Accuracy on batch 1735/2438  on Training is 64.53953052995392\n",
            "Epoch #2. Accuracy on batch 1736/2438  on Training is 64.54555267702936\n",
            "Epoch #2. Accuracy on batch 1737/2438  on Training is 64.54437571921748\n",
            "Epoch #2. Accuracy on batch 1738/2438  on Training is 64.54140310523289\n",
            "Epoch #2. Accuracy on batch 1739/2438  on Training is 64.55280172413794\n",
            "Batch Id 1740/2438 is having training loss of 1.3649719953536987\n",
            "1.0379643440246582\n",
            "Epoch #2. Accuracy on batch 1740/2438  on Training is 64.55341757610569\n",
            "Epoch #2. Accuracy on batch 1741/2438  on Training is 64.56659012629162\n",
            "Epoch #2. Accuracy on batch 1742/2438  on Training is 64.563611589214\n",
            "Epoch #2. Accuracy on batch 1743/2438  on Training is 64.56601204128441\n",
            "Epoch #2. Accuracy on batch 1744/2438  on Training is 64.56840974212034\n",
            "Epoch #2. Accuracy on batch 1745/2438  on Training is 64.5743843069874\n",
            "Epoch #2. Accuracy on batch 1746/2438  on Training is 64.57319690898683\n",
            "Epoch #2. Accuracy on batch 1747/2438  on Training is 64.57379862700229\n",
            "Epoch #2. Accuracy on batch 1748/2438  on Training is 64.57439965694682\n",
            "Epoch #2. Accuracy on batch 1749/2438  on Training is 64.57857142857142\n",
            "Epoch #2. Accuracy on batch 1750/2438  on Training is 64.56667618503712\n",
            "Epoch #2. Accuracy on batch 1751/2438  on Training is 64.56192922374429\n",
            "Epoch #2. Accuracy on batch 1752/2438  on Training is 64.56788362806617\n",
            "Epoch #2. Accuracy on batch 1753/2438  on Training is 64.5720496009122\n",
            "Epoch #2. Accuracy on batch 1754/2438  on Training is 64.57264957264957\n",
            "Epoch #2. Accuracy on batch 1755/2438  on Training is 64.56968963553531\n",
            "Epoch #2. Accuracy on batch 1756/2438  on Training is 64.56673306772909\n",
            "Epoch #2. Accuracy on batch 1757/2438  on Training is 64.56377986348123\n",
            "Epoch #2. Accuracy on batch 1758/2438  on Training is 64.57326606026152\n",
            "Epoch #2. Accuracy on batch 1759/2438  on Training is 64.57386363636364\n",
            "Batch Id 1760/2438 is having training loss of 1.3641029596328735\n",
            "0.8376799821853638\n",
            "Epoch #2. Accuracy on batch 1760/2438  on Training is 64.58688245315162\n",
            "Epoch #2. Accuracy on batch 1761/2438  on Training is 64.58215096481271\n",
            "Epoch #2. Accuracy on batch 1762/2438  on Training is 64.59160521837777\n",
            "Epoch #2. Accuracy on batch 1763/2438  on Training is 64.5921910430839\n",
            "Epoch #2. Accuracy on batch 1764/2438  on Training is 64.59631728045326\n",
            "Epoch #2. Accuracy on batch 1765/2438  on Training is 64.59689977349943\n",
            "Epoch #2. Accuracy on batch 1766/2438  on Training is 64.60101867572156\n",
            "Epoch #2. Accuracy on batch 1767/2438  on Training is 64.60336538461539\n",
            "Epoch #2. Accuracy on batch 1768/2438  on Training is 64.6127755794234\n",
            "Epoch #2. Accuracy on batch 1769/2438  on Training is 64.60981638418079\n",
            "Epoch #2. Accuracy on batch 1770/2438  on Training is 64.60686053077357\n",
            "Epoch #2. Accuracy on batch 1771/2438  on Training is 64.6091986455982\n",
            "Epoch #2. Accuracy on batch 1772/2438  on Training is 64.60800902425268\n",
            "Epoch #2. Accuracy on batch 1773/2438  on Training is 64.60153607666291\n",
            "Epoch #2. Accuracy on batch 1774/2438  on Training is 64.60387323943662\n",
            "Epoch #2. Accuracy on batch 1775/2438  on Training is 64.6044481981982\n",
            "Epoch #2. Accuracy on batch 1776/2438  on Training is 64.59798818232977\n",
            "Epoch #2. Accuracy on batch 1777/2438  on Training is 64.59680821147357\n",
            "Epoch #2. Accuracy on batch 1778/2438  on Training is 64.58860314783587\n",
            "Epoch #2. Accuracy on batch 1779/2438  on Training is 64.59094101123596\n",
            "Batch Id 1780/2438 is having training loss of 1.3638197183609009\n",
            "1.2731120586395264\n",
            "Epoch #2. Accuracy on batch 1780/2438  on Training is 64.59152161706906\n",
            "Epoch #2. Accuracy on batch 1781/2438  on Training is 64.59736251402919\n",
            "Epoch #2. Accuracy on batch 1782/2438  on Training is 64.59618620302861\n",
            "Epoch #2. Accuracy on batch 1783/2438  on Training is 64.59501121076234\n",
            "Epoch #2. Accuracy on batch 1784/2438  on Training is 64.58858543417367\n",
            "Epoch #2. Accuracy on batch 1785/2438  on Training is 64.59091545352743\n",
            "Epoch #2. Accuracy on batch 1786/2438  on Training is 64.589745383324\n",
            "Epoch #2. Accuracy on batch 1787/2438  on Training is 64.5815855704698\n",
            "Epoch #2. Accuracy on batch 1788/2438  on Training is 64.59439631078816\n",
            "Epoch #2. Accuracy on batch 1789/2438  on Training is 64.59846368715084\n",
            "Epoch #2. Accuracy on batch 1790/2438  on Training is 64.60078168620882\n",
            "Epoch #2. Accuracy on batch 1791/2438  on Training is 64.59437779017857\n",
            "Epoch #2. Accuracy on batch 1792/2438  on Training is 64.603667038483\n",
            "Epoch #2. Accuracy on batch 1793/2438  on Training is 64.59901059085841\n",
            "Epoch #2. Accuracy on batch 1794/2438  on Training is 64.59610027855153\n",
            "Epoch #2. Accuracy on batch 1795/2438  on Training is 64.60363307349665\n",
            "Epoch #2. Accuracy on batch 1796/2438  on Training is 64.59550639955481\n",
            "Epoch #2. Accuracy on batch 1797/2438  on Training is 64.59607897664071\n",
            "Epoch #2. Accuracy on batch 1798/2438  on Training is 64.59143968871595\n",
            "Epoch #2. Accuracy on batch 1799/2438  on Training is 64.58680555555556\n",
            "Batch Id 1800/2438 is having training loss of 1.3636525869369507\n",
            "1.3719059228897095\n",
            "Epoch #2. Accuracy on batch 1800/2438  on Training is 64.58738200999444\n",
            "Epoch #2. Accuracy on batch 1801/2438  on Training is 64.58795782463929\n",
            "Epoch #2. Accuracy on batch 1802/2438  on Training is 64.59026622296173\n",
            "Epoch #2. Accuracy on batch 1803/2438  on Training is 64.58910753880266\n",
            "Epoch #2. Accuracy on batch 1804/2438  on Training is 64.59660664819944\n",
            "Epoch #2. Accuracy on batch 1805/2438  on Training is 64.59890642303434\n",
            "Epoch #2. Accuracy on batch 1806/2438  on Training is 64.60639180962922\n",
            "Epoch #2. Accuracy on batch 1807/2438  on Training is 64.60522676991151\n",
            "Epoch #2. Accuracy on batch 1808/2438  on Training is 64.60924543946932\n",
            "Epoch #2. Accuracy on batch 1809/2438  on Training is 64.60808011049724\n",
            "Epoch #2. Accuracy on batch 1810/2438  on Training is 64.61036720044174\n",
            "Epoch #2. Accuracy on batch 1811/2438  on Training is 64.60575331125828\n",
            "Epoch #2. Accuracy on batch 1812/2438  on Training is 64.60976282404854\n",
            "Epoch #2. Accuracy on batch 1813/2438  on Training is 64.60859977949283\n",
            "Epoch #2. Accuracy on batch 1814/2438  on Training is 64.60571625344353\n",
            "Epoch #2. Accuracy on batch 1815/2438  on Training is 64.6028359030837\n",
            "Epoch #2. Accuracy on batch 1816/2438  on Training is 64.60339845899834\n",
            "Epoch #2. Accuracy on batch 1817/2438  on Training is 64.60224147414742\n",
            "Epoch #2. Accuracy on batch 1818/2438  on Training is 64.59936778449698\n",
            "Epoch #2. Accuracy on batch 1819/2438  on Training is 64.60508241758242\n",
            "Batch Id 1820/2438 is having training loss of 1.3630094528198242\n",
            "1.092107892036438\n",
            "Epoch #2. Accuracy on batch 1820/2438  on Training is 64.60735859417902\n",
            "Epoch #2. Accuracy on batch 1821/2438  on Training is 64.61649286498353\n",
            "Epoch #2. Accuracy on batch 1822/2438  on Training is 64.61704607789358\n",
            "Epoch #2. Accuracy on batch 1823/2438  on Training is 64.61417214912281\n",
            "Epoch #2. Accuracy on batch 1824/2438  on Training is 64.62157534246575\n",
            "Epoch #2. Accuracy on batch 1825/2438  on Training is 64.62725903614458\n",
            "Epoch #2. Accuracy on batch 1826/2438  on Training is 64.63464696223316\n",
            "Epoch #2. Accuracy on batch 1827/2438  on Training is 64.63518873085339\n",
            "Epoch #2. Accuracy on batch 1828/2438  on Training is 64.63743849097868\n",
            "Epoch #2. Accuracy on batch 1829/2438  on Training is 64.6379781420765\n",
            "Epoch #2. Accuracy on batch 1830/2438  on Training is 64.63851720371382\n",
            "Epoch #2. Accuracy on batch 1831/2438  on Training is 64.63223253275109\n",
            "Epoch #2. Accuracy on batch 1832/2438  on Training is 64.63277414075286\n",
            "Epoch #2. Accuracy on batch 1833/2438  on Training is 64.63672300981462\n",
            "Epoch #2. Accuracy on batch 1834/2438  on Training is 64.64066757493188\n",
            "Epoch #2. Accuracy on batch 1835/2438  on Training is 64.64460784313725\n",
            "Epoch #2. Accuracy on batch 1836/2438  on Training is 64.64514153511159\n",
            "Epoch #2. Accuracy on batch 1837/2438  on Training is 64.64567464635473\n",
            "Epoch #2. Accuracy on batch 1838/2438  on Training is 64.64450788471996\n",
            "Epoch #2. Accuracy on batch 1839/2438  on Training is 64.64673913043478\n",
            "Batch Id 1840/2438 is having training loss of 1.3616530895233154\n",
            "1.2809278964996338\n",
            "Epoch #2. Accuracy on batch 1840/2438  on Training is 64.64727050516024\n",
            "Epoch #2. Accuracy on batch 1841/2438  on Training is 64.6444082519001\n",
            "Epoch #2. Accuracy on batch 1842/2438  on Training is 64.64154910472057\n",
            "Epoch #2. Accuracy on batch 1843/2438  on Training is 64.64208242950109\n",
            "Epoch #2. Accuracy on batch 1844/2438  on Training is 64.63753387533875\n",
            "Epoch #2. Accuracy on batch 1845/2438  on Training is 64.6397616468039\n",
            "Epoch #2. Accuracy on batch 1846/2438  on Training is 64.64537087168381\n",
            "Epoch #2. Accuracy on batch 1847/2438  on Training is 64.64082792207792\n",
            "Epoch #2. Accuracy on batch 1848/2438  on Training is 64.64643050297458\n",
            "Epoch #2. Accuracy on batch 1849/2438  on Training is 64.64527027027027\n",
            "Epoch #2. Accuracy on batch 1850/2438  on Training is 64.63398163155051\n",
            "Epoch #2. Accuracy on batch 1851/2438  on Training is 64.6294546436285\n",
            "Epoch #2. Accuracy on batch 1852/2438  on Training is 64.62155963302752\n",
            "Epoch #2. Accuracy on batch 1853/2438  on Training is 64.62210086299892\n",
            "Epoch #2. Accuracy on batch 1854/2438  on Training is 64.61927223719677\n",
            "Epoch #2. Accuracy on batch 1855/2438  on Training is 64.62486530172414\n",
            "Epoch #2. Accuracy on batch 1856/2438  on Training is 64.61867259019925\n",
            "Epoch #2. Accuracy on batch 1857/2438  on Training is 64.61921420882669\n",
            "Epoch #2. Accuracy on batch 1858/2438  on Training is 64.61639322216246\n",
            "Epoch #2. Accuracy on batch 1859/2438  on Training is 64.61189516129032\n",
            "Batch Id 1860/2438 is having training loss of 1.3626388311386108\n",
            "1.691569447517395\n",
            "Epoch #2. Accuracy on batch 1860/2438  on Training is 64.60236432025792\n",
            "Epoch #2. Accuracy on batch 1861/2438  on Training is 64.6062701396348\n",
            "Epoch #2. Accuracy on batch 1862/2438  on Training is 64.6051395598497\n",
            "Epoch #2. Accuracy on batch 1863/2438  on Training is 64.60233369098712\n",
            "Epoch #2. Accuracy on batch 1864/2438  on Training is 64.60288203753352\n",
            "Epoch #2. Accuracy on batch 1865/2438  on Training is 64.6067792068596\n",
            "Epoch #2. Accuracy on batch 1866/2438  on Training is 64.60230316014997\n",
            "Epoch #2. Accuracy on batch 1867/2438  on Training is 64.61288811563169\n",
            "Epoch #2. Accuracy on batch 1868/2438  on Training is 64.6067415730337\n",
            "Epoch #2. Accuracy on batch 1869/2438  on Training is 64.59893048128342\n",
            "Epoch #2. Accuracy on batch 1870/2438  on Training is 64.60615980758952\n",
            "Epoch #2. Accuracy on batch 1871/2438  on Training is 64.60670405982906\n",
            "Epoch #2. Accuracy on batch 1872/2438  on Training is 64.6105846235985\n",
            "Epoch #2. Accuracy on batch 1873/2438  on Training is 64.61112593383137\n",
            "Epoch #2. Accuracy on batch 1874/2438  on Training is 64.605\n",
            "Epoch #2. Accuracy on batch 1875/2438  on Training is 64.60387793176972\n",
            "Epoch #2. Accuracy on batch 1876/2438  on Training is 64.60109216835376\n",
            "Epoch #2. Accuracy on batch 1877/2438  on Training is 64.60163738019169\n",
            "Epoch #2. Accuracy on batch 1878/2438  on Training is 64.60883448642895\n",
            "Epoch #2. Accuracy on batch 1879/2438  on Training is 64.609375\n",
            "Batch Id 1880/2438 is having training loss of 1.361928939819336\n",
            "1.6552037000656128\n",
            "Epoch #2. Accuracy on batch 1880/2438  on Training is 64.61157628920787\n",
            "Epoch #2. Accuracy on batch 1881/2438  on Training is 64.60879383634432\n",
            "Epoch #2. Accuracy on batch 1882/2438  on Training is 64.60601433882103\n",
            "Epoch #2. Accuracy on batch 1883/2438  on Training is 64.60157908704883\n",
            "Epoch #2. Accuracy on batch 1884/2438  on Training is 64.59714854111405\n",
            "Epoch #2. Accuracy on batch 1885/2438  on Training is 64.59769353128314\n",
            "Epoch #2. Accuracy on batch 1886/2438  on Training is 64.59658187599364\n",
            "Epoch #2. Accuracy on batch 1887/2438  on Training is 64.59878177966101\n",
            "Epoch #2. Accuracy on batch 1888/2438  on Training is 64.58609052408681\n",
            "Epoch #2. Accuracy on batch 1889/2438  on Training is 64.59325396825396\n",
            "Epoch #2. Accuracy on batch 1890/2438  on Training is 64.59379957694341\n",
            "Epoch #2. Accuracy on batch 1891/2438  on Training is 64.59764799154334\n",
            "Epoch #2. Accuracy on batch 1892/2438  on Training is 64.59819070258848\n",
            "Epoch #2. Accuracy on batch 1893/2438  on Training is 64.5987328405491\n",
            "Epoch #2. Accuracy on batch 1894/2438  on Training is 64.60257255936675\n",
            "Epoch #2. Accuracy on batch 1895/2438  on Training is 64.59816719409282\n",
            "Epoch #2. Accuracy on batch 1896/2438  on Training is 64.60365050079072\n",
            "Epoch #2. Accuracy on batch 1897/2438  on Training is 64.60912802950475\n",
            "Epoch #2. Accuracy on batch 1898/2438  on Training is 64.60966298051606\n",
            "Epoch #2. Accuracy on batch 1899/2438  on Training is 64.60690789473684\n",
            "Batch Id 1900/2438 is having training loss of 1.362160086631775\n",
            "1.4260776042938232\n",
            "Epoch #2. Accuracy on batch 1900/2438  on Training is 64.60415570752235\n",
            "Epoch #2. Accuracy on batch 1901/2438  on Training is 64.60469242902208\n",
            "Epoch #2. Accuracy on batch 1902/2438  on Training is 64.60522858644246\n",
            "Epoch #2. Accuracy on batch 1903/2438  on Training is 64.60248161764706\n",
            "Epoch #2. Accuracy on batch 1904/2438  on Training is 64.5997375328084\n",
            "Epoch #2. Accuracy on batch 1905/2438  on Training is 64.5969963273872\n",
            "Epoch #2. Accuracy on batch 1906/2438  on Training is 64.5942579968537\n",
            "Epoch #2. Accuracy on batch 1907/2438  on Training is 64.59807389937107\n",
            "Epoch #2. Accuracy on batch 1908/2438  on Training is 64.59370089051859\n",
            "Epoch #2. Accuracy on batch 1909/2438  on Training is 64.59587696335079\n",
            "Epoch #2. Accuracy on batch 1910/2438  on Training is 64.59314495028781\n",
            "Epoch #2. Accuracy on batch 1911/2438  on Training is 64.59205020920503\n",
            "Epoch #2. Accuracy on batch 1912/2438  on Training is 64.59749085206482\n",
            "Epoch #2. Accuracy on batch 1913/2438  on Training is 64.59966039707419\n",
            "Epoch #2. Accuracy on batch 1914/2438  on Training is 64.5985639686684\n",
            "Epoch #2. Accuracy on batch 1915/2438  on Training is 64.60236169102296\n",
            "Epoch #2. Accuracy on batch 1916/2438  on Training is 64.59637454355764\n",
            "Epoch #2. Accuracy on batch 1917/2438  on Training is 64.60016944734097\n",
            "Epoch #2. Accuracy on batch 1918/2438  on Training is 64.60396039603961\n",
            "Epoch #2. Accuracy on batch 1919/2438  on Training is 64.61100260416667\n",
            "Batch Id 1920/2438 is having training loss of 1.3612860441207886\n",
            "1.2670389413833618\n",
            "Epoch #2. Accuracy on batch 1920/2438  on Training is 64.61641072358147\n",
            "Epoch #2. Accuracy on batch 1921/2438  on Training is 64.61205775234131\n",
            "Epoch #2. Accuracy on batch 1922/2438  on Training is 64.61095943837753\n",
            "Epoch #2. Accuracy on batch 1923/2438  on Training is 64.61148648648648\n",
            "Epoch #2. Accuracy on batch 1924/2438  on Training is 64.60876623376623\n",
            "Epoch #2. Accuracy on batch 1925/2438  on Training is 64.60604880581516\n",
            "Epoch #2. Accuracy on batch 1926/2438  on Training is 64.60171250648676\n",
            "Epoch #2. Accuracy on batch 1927/2438  on Training is 64.59575985477179\n",
            "Epoch #2. Accuracy on batch 1928/2438  on Training is 64.5898133748056\n",
            "Epoch #2. Accuracy on batch 1929/2438  on Training is 64.59034974093264\n",
            "Epoch #2. Accuracy on batch 1930/2438  on Training is 64.59250388399794\n",
            "Epoch #2. Accuracy on batch 1931/2438  on Training is 64.5898033126294\n",
            "Epoch #2. Accuracy on batch 1932/2438  on Training is 64.58548887739265\n",
            "Epoch #2. Accuracy on batch 1933/2438  on Training is 64.58441054808686\n",
            "Epoch #2. Accuracy on batch 1934/2438  on Training is 64.57848837209302\n",
            "Epoch #2. Accuracy on batch 1935/2438  on Training is 64.58709969008264\n",
            "Epoch #2. Accuracy on batch 1936/2438  on Training is 64.58763551884357\n",
            "Epoch #2. Accuracy on batch 1937/2438  on Training is 64.58978328173374\n",
            "Epoch #2. Accuracy on batch 1938/2438  on Training is 64.59031717380093\n",
            "Epoch #2. Accuracy on batch 1939/2438  on Training is 64.58118556701031\n",
            "Batch Id 1940/2438 is having training loss of 1.3619970083236694\n",
            "1.1405631303787231\n",
            "Epoch #2. Accuracy on batch 1940/2438  on Training is 64.5801133436373\n",
            "Epoch #2. Accuracy on batch 1941/2438  on Training is 64.57904222451081\n",
            "Epoch #2. Accuracy on batch 1942/2438  on Training is 64.58440555841483\n",
            "Epoch #2. Accuracy on batch 1943/2438  on Training is 64.5897633744856\n",
            "Epoch #2. Accuracy on batch 1944/2438  on Training is 64.59190231362467\n",
            "Epoch #2. Accuracy on batch 1945/2438  on Training is 64.5924331963001\n",
            "Epoch #2. Accuracy on batch 1946/2438  on Training is 64.5913585002568\n",
            "Epoch #2. Accuracy on batch 1947/2438  on Training is 64.59670174537987\n",
            "Epoch #2. Accuracy on batch 1948/2438  on Training is 64.59562596203182\n",
            "Epoch #2. Accuracy on batch 1949/2438  on Training is 64.59935897435898\n",
            "Epoch #2. Accuracy on batch 1950/2438  on Training is 64.59027421834956\n",
            "Epoch #2. Accuracy on batch 1951/2438  on Training is 64.58920338114754\n",
            "Epoch #2. Accuracy on batch 1952/2438  on Training is 64.59613415258576\n",
            "Epoch #2. Accuracy on batch 1953/2438  on Training is 64.59506141248721\n",
            "Epoch #2. Accuracy on batch 1954/2438  on Training is 64.59079283887468\n",
            "Epoch #2. Accuracy on batch 1955/2438  on Training is 64.59132157464212\n",
            "Epoch #2. Accuracy on batch 1956/2438  on Training is 64.59664026571282\n",
            "Epoch #2. Accuracy on batch 1957/2438  on Training is 64.59876149131767\n",
            "Epoch #2. Accuracy on batch 1958/2438  on Training is 64.60407095456866\n",
            "Epoch #2. Accuracy on batch 1959/2438  on Training is 64.60140306122449\n",
            "Batch Id 1960/2438 is having training loss of 1.3614139556884766\n",
            "2.115441083908081\n",
            "Epoch #2. Accuracy on batch 1960/2438  on Training is 64.59236359000509\n",
            "Epoch #2. Accuracy on batch 1961/2438  on Training is 64.59288990825688\n",
            "Epoch #2. Accuracy on batch 1962/2438  on Training is 64.59659959246052\n",
            "Epoch #2. Accuracy on batch 1963/2438  on Training is 64.5971232179226\n",
            "Epoch #2. Accuracy on batch 1964/2438  on Training is 64.59923664122137\n",
            "Epoch #2. Accuracy on batch 1965/2438  on Training is 64.59498982706002\n",
            "Epoch #2. Accuracy on batch 1966/2438  on Training is 64.59869089984748\n",
            "Epoch #2. Accuracy on batch 1967/2438  on Training is 64.60080030487805\n",
            "Epoch #2. Accuracy on batch 1968/2438  on Training is 64.5965591670899\n",
            "Epoch #2. Accuracy on batch 1969/2438  on Training is 64.59866751269035\n",
            "Epoch #2. Accuracy on batch 1970/2438  on Training is 64.6023592085236\n",
            "Epoch #2. Accuracy on batch 1971/2438  on Training is 64.6060471602434\n",
            "Epoch #2. Accuracy on batch 1972/2438  on Training is 64.61448302078054\n",
            "Epoch #2. Accuracy on batch 1973/2438  on Training is 64.61499493414387\n",
            "Epoch #2. Accuracy on batch 1974/2438  on Training is 64.61708860759494\n",
            "Epoch #2. Accuracy on batch 1975/2438  on Training is 64.61601720647774\n",
            "Epoch #2. Accuracy on batch 1976/2438  on Training is 64.62126960040466\n",
            "Epoch #2. Accuracy on batch 1977/2438  on Training is 64.63125631951466\n",
            "Epoch #2. Accuracy on batch 1978/2438  on Training is 64.63017938352704\n",
            "Epoch #2. Accuracy on batch 1979/2438  on Training is 64.63699494949495\n",
            "Batch Id 1980/2438 is having training loss of 1.36025071144104\n",
            "1.0947920083999634\n",
            "Epoch #2. Accuracy on batch 1980/2438  on Training is 64.63907117617364\n",
            "Epoch #2. Accuracy on batch 1981/2438  on Training is 64.64429868819374\n",
            "Epoch #2. Accuracy on batch 1982/2438  on Training is 64.64636913767019\n",
            "Epoch #2. Accuracy on batch 1983/2438  on Training is 64.64686239919355\n",
            "Epoch #2. Accuracy on batch 1984/2438  on Training is 64.64105793450882\n",
            "Epoch #2. Accuracy on batch 1985/2438  on Training is 64.64312688821752\n",
            "Epoch #2. Accuracy on batch 1986/2438  on Training is 64.64676648213387\n",
            "Epoch #2. Accuracy on batch 1987/2438  on Training is 64.6456866197183\n",
            "Epoch #2. Accuracy on batch 1988/2438  on Training is 64.64303670186023\n",
            "Epoch #2. Accuracy on batch 1989/2438  on Training is 64.64353015075378\n",
            "Epoch #2. Accuracy on batch 1990/2438  on Training is 64.64402310396785\n",
            "Epoch #2. Accuracy on batch 1991/2438  on Training is 64.6413780120482\n",
            "Epoch #2. Accuracy on batch 1992/2438  on Training is 64.64030356246865\n",
            "Epoch #2. Accuracy on batch 1993/2438  on Training is 64.64079739217652\n",
            "Epoch #2. Accuracy on batch 1994/2438  on Training is 64.63815789473684\n",
            "Epoch #2. Accuracy on batch 1995/2438  on Training is 64.63238977955912\n",
            "Epoch #2. Accuracy on batch 1996/2438  on Training is 64.63601652478718\n",
            "Epoch #2. Accuracy on batch 1997/2438  on Training is 64.63494744744744\n",
            "Epoch #2. Accuracy on batch 1998/2438  on Training is 64.63075287643822\n",
            "Epoch #2. Accuracy on batch 1999/2438  on Training is 64.6296875\n",
            "Batch Id 2000/2438 is having training loss of 1.359775424003601\n",
            "1.1478503942489624\n",
            "Epoch #2. Accuracy on batch 2000/2438  on Training is 64.63018490754622\n",
            "Epoch #2. Accuracy on batch 2001/2438  on Training is 64.64004745254745\n",
            "Epoch #2. Accuracy on batch 2002/2438  on Training is 64.64209935097354\n",
            "Epoch #2. Accuracy on batch 2003/2438  on Training is 64.6441492015968\n",
            "Epoch #2. Accuracy on batch 2004/2438  on Training is 64.64307980049875\n",
            "Epoch #2. Accuracy on batch 2005/2438  on Training is 64.64356929212363\n",
            "Epoch #2. Accuracy on batch 2006/2438  on Training is 64.64717239661186\n",
            "Epoch #2. Accuracy on batch 2007/2438  on Training is 64.652328187251\n",
            "Epoch #2. Accuracy on batch 2008/2438  on Training is 64.65592334494774\n",
            "Epoch #2. Accuracy on batch 2009/2438  on Training is 64.66262437810946\n",
            "Epoch #2. Accuracy on batch 2010/2438  on Training is 64.66621084037791\n",
            "Epoch #2. Accuracy on batch 2011/2438  on Training is 64.66824055666004\n",
            "Epoch #2. Accuracy on batch 2012/2438  on Training is 64.66871584699453\n",
            "Epoch #2. Accuracy on batch 2013/2438  on Training is 64.6691906653426\n",
            "Epoch #2. Accuracy on batch 2014/2438  on Training is 64.66346153846153\n",
            "Epoch #2. Accuracy on batch 2015/2438  on Training is 64.66238839285714\n",
            "Epoch #2. Accuracy on batch 2016/2438  on Training is 64.66286564204263\n",
            "Epoch #2. Accuracy on batch 2017/2438  on Training is 64.66489098116948\n",
            "Epoch #2. Accuracy on batch 2018/2438  on Training is 64.66691431401684\n",
            "Epoch #2. Accuracy on batch 2019/2438  on Training is 64.67048267326733\n",
            "Batch Id 2020/2438 is having training loss of 1.357837438583374\n",
            "1.184477686882019\n",
            "Epoch #2. Accuracy on batch 2020/2438  on Training is 64.67404750123701\n",
            "Epoch #2. Accuracy on batch 2021/2438  on Training is 64.67297230464887\n",
            "Epoch #2. Accuracy on batch 2022/2438  on Training is 64.67807711319821\n",
            "Epoch #2. Accuracy on batch 2023/2438  on Training is 64.68163290513834\n",
            "Epoch #2. Accuracy on batch 2024/2438  on Training is 64.68518518518519\n",
            "Epoch #2. Accuracy on batch 2025/2438  on Training is 64.68564906219152\n",
            "Epoch #2. Accuracy on batch 2026/2438  on Training is 64.68919585594475\n",
            "Epoch #2. Accuracy on batch 2027/2438  on Training is 64.69582100591715\n",
            "Epoch #2. Accuracy on batch 2028/2438  on Training is 64.69319862000985\n",
            "Epoch #2. Accuracy on batch 2029/2438  on Training is 64.69211822660098\n",
            "Epoch #2. Accuracy on batch 2030/2438  on Training is 64.69103889709503\n",
            "Epoch #2. Accuracy on batch 2031/2438  on Training is 64.68996062992126\n",
            "Epoch #2. Accuracy on batch 2032/2438  on Training is 64.6950319724545\n",
            "Epoch #2. Accuracy on batch 2033/2438  on Training is 64.69088003933136\n",
            "Epoch #2. Accuracy on batch 2034/2438  on Training is 64.68366093366093\n",
            "Epoch #2. Accuracy on batch 2035/2438  on Training is 64.68412328094303\n",
            "Epoch #2. Accuracy on batch 2036/2438  on Training is 64.68305105547374\n",
            "Epoch #2. Accuracy on batch 2037/2438  on Training is 64.68504661432777\n",
            "Epoch #2. Accuracy on batch 2038/2438  on Training is 64.6916380578715\n",
            "Epoch #2. Accuracy on batch 2039/2438  on Training is 64.69822303921569\n",
            "Batch Id 2040/2438 is having training loss of 1.357306718826294\n",
            "1.5266562700271606\n",
            "Epoch #2. Accuracy on batch 2040/2438  on Training is 64.69255267025967\n",
            "Epoch #2. Accuracy on batch 2041/2438  on Training is 64.6899485798237\n",
            "Epoch #2. Accuracy on batch 2042/2438  on Training is 64.68734703866862\n",
            "Epoch #2. Accuracy on batch 2043/2438  on Training is 64.69545009784736\n",
            "Epoch #2. Accuracy on batch 2044/2438  on Training is 64.6989608801956\n",
            "Epoch #2. Accuracy on batch 2045/2438  on Training is 64.70246823069404\n",
            "Epoch #2. Accuracy on batch 2046/2438  on Training is 64.70291890571568\n",
            "Epoch #2. Accuracy on batch 2047/2438  on Training is 64.69879150390625\n",
            "Epoch #2. Accuracy on batch 2048/2438  on Training is 64.69924353343094\n",
            "Epoch #2. Accuracy on batch 2049/2438  on Training is 64.69664634146342\n",
            "Epoch #2. Accuracy on batch 2050/2438  on Training is 64.69557532910775\n",
            "Epoch #2. Accuracy on batch 2051/2438  on Training is 64.69907407407408\n",
            "Epoch #2. Accuracy on batch 2052/2438  on Training is 64.70104724792986\n",
            "Epoch #2. Accuracy on batch 2053/2438  on Training is 64.69236854917234\n",
            "Epoch #2. Accuracy on batch 2054/2438  on Training is 64.69586374695864\n",
            "Epoch #2. Accuracy on batch 2055/2438  on Training is 64.69935554474708\n",
            "Epoch #2. Accuracy on batch 2056/2438  on Training is 64.70132474477394\n",
            "Epoch #2. Accuracy on batch 2057/2438  on Training is 64.70329203109816\n",
            "Epoch #2. Accuracy on batch 2058/2438  on Training is 64.70373967945605\n",
            "Epoch #2. Accuracy on batch 2059/2438  on Training is 64.70418689320388\n",
            "Batch Id 2060/2438 is having training loss of 1.3569427728652954\n",
            "1.4974437952041626\n",
            "Epoch #2. Accuracy on batch 2060/2438  on Training is 64.69856865599223\n",
            "Epoch #2. Accuracy on batch 2061/2438  on Training is 64.69144034917555\n",
            "Epoch #2. Accuracy on batch 2062/2438  on Training is 64.69189287445468\n",
            "Epoch #2. Accuracy on batch 2063/2438  on Training is 64.6953730620155\n",
            "Epoch #2. Accuracy on batch 2064/2438  on Training is 64.69733656174334\n",
            "Epoch #2. Accuracy on batch 2065/2438  on Training is 64.69022265246853\n",
            "Epoch #2. Accuracy on batch 2066/2438  on Training is 64.69218674407354\n",
            "Epoch #2. Accuracy on batch 2067/2438  on Training is 64.69112669245648\n",
            "Epoch #2. Accuracy on batch 2068/2438  on Training is 64.69459884001934\n",
            "Epoch #2. Accuracy on batch 2069/2438  on Training is 64.68900966183575\n",
            "Epoch #2. Accuracy on batch 2070/2438  on Training is 64.68946161274746\n",
            "Epoch #2. Accuracy on batch 2071/2438  on Training is 64.68991312741312\n",
            "Epoch #2. Accuracy on batch 2072/2438  on Training is 64.6948866377231\n",
            "Epoch #2. Accuracy on batch 2073/2438  on Training is 64.6968418514947\n",
            "Epoch #2. Accuracy on batch 2074/2438  on Training is 64.6987951807229\n",
            "Epoch #2. Accuracy on batch 2075/2438  on Training is 64.69773603082852\n",
            "Epoch #2. Accuracy on batch 2076/2438  on Training is 64.7011916225325\n",
            "Epoch #2. Accuracy on batch 2077/2438  on Training is 64.70163618864292\n",
            "Epoch #2. Accuracy on batch 2078/2438  on Training is 64.70208032708032\n",
            "Epoch #2. Accuracy on batch 2079/2438  on Training is 64.7040264423077\n",
            "Batch Id 2080/2438 is having training loss of 1.356846570968628\n",
            "1.7183446884155273\n",
            "Epoch #2. Accuracy on batch 2080/2438  on Training is 64.69545891398366\n",
            "Epoch #2. Accuracy on batch 2081/2438  on Training is 64.69590537944285\n",
            "Epoch #2. Accuracy on batch 2082/2438  on Training is 64.69935189630341\n",
            "Epoch #2. Accuracy on batch 2083/2438  on Training is 64.70279510556622\n",
            "Epoch #2. Accuracy on batch 2084/2438  on Training is 64.70023980815348\n",
            "Epoch #2. Accuracy on batch 2085/2438  on Training is 64.70367929050815\n",
            "Epoch #2. Accuracy on batch 2086/2438  on Training is 64.71011020603737\n",
            "Epoch #2. Accuracy on batch 2087/2438  on Training is 64.71503831417624\n",
            "Epoch #2. Accuracy on batch 2088/2438  on Training is 64.71547391096219\n",
            "Epoch #2. Accuracy on batch 2089/2438  on Training is 64.70992822966507\n",
            "Epoch #2. Accuracy on batch 2090/2438  on Training is 64.71036585365853\n",
            "Epoch #2. Accuracy on batch 2091/2438  on Training is 64.71080305927342\n",
            "Epoch #2. Accuracy on batch 2092/2438  on Training is 64.70676063067367\n",
            "Epoch #2. Accuracy on batch 2093/2438  on Training is 64.70421442215854\n",
            "Epoch #2. Accuracy on batch 2094/2438  on Training is 64.70912887828162\n",
            "Epoch #2. Accuracy on batch 2095/2438  on Training is 64.70360209923665\n",
            "Epoch #2. Accuracy on batch 2096/2438  on Training is 64.69659036719122\n",
            "Epoch #2. Accuracy on batch 2097/2438  on Training is 64.70150142993327\n",
            "Epoch #2. Accuracy on batch 2098/2438  on Training is 64.7004525964745\n",
            "Epoch #2. Accuracy on batch 2099/2438  on Training is 64.69940476190476\n",
            "Batch Id 2100/2438 is having training loss of 1.3568357229232788\n",
            "1.1257226467132568\n",
            "Epoch #2. Accuracy on batch 2100/2438  on Training is 64.6998453117563\n",
            "Epoch #2. Accuracy on batch 2101/2438  on Training is 64.70028544243577\n",
            "Epoch #2. Accuracy on batch 2102/2438  on Training is 64.70518307180218\n",
            "Epoch #2. Accuracy on batch 2103/2438  on Training is 64.70710551330798\n",
            "Epoch #2. Accuracy on batch 2104/2438  on Training is 64.71199524940617\n",
            "Epoch #2. Accuracy on batch 2105/2438  on Training is 64.70204178537512\n",
            "Epoch #2. Accuracy on batch 2106/2438  on Training is 64.70544613194114\n",
            "Epoch #2. Accuracy on batch 2107/2438  on Training is 64.71181214421253\n",
            "Epoch #2. Accuracy on batch 2108/2438  on Training is 64.70631816026552\n",
            "Epoch #2. Accuracy on batch 2109/2438  on Training is 64.70971563981043\n",
            "Epoch #2. Accuracy on batch 2110/2438  on Training is 64.70866887730934\n",
            "Epoch #2. Accuracy on batch 2111/2438  on Training is 64.71206202651516\n",
            "Epoch #2. Accuracy on batch 2112/2438  on Training is 64.70657832465689\n",
            "Epoch #2. Accuracy on batch 2113/2438  on Training is 64.70849101229896\n",
            "Epoch #2. Accuracy on batch 2114/2438  on Training is 64.72074468085107\n",
            "Epoch #2. Accuracy on batch 2115/2438  on Training is 64.72264886578449\n",
            "Epoch #2. Accuracy on batch 2116/2438  on Training is 64.72455125177137\n",
            "Epoch #2. Accuracy on batch 2117/2438  on Training is 64.72792728989613\n",
            "Epoch #2. Accuracy on batch 2118/2438  on Training is 64.7298253893346\n",
            "Epoch #2. Accuracy on batch 2119/2438  on Training is 64.72582547169812\n",
            "Batch Id 2120/2438 is having training loss of 1.3565994501113892\n",
            "1.9704196453094482\n",
            "Epoch #2. Accuracy on batch 2120/2438  on Training is 64.7233026874116\n",
            "Epoch #2. Accuracy on batch 2121/2438  on Training is 64.72372761545712\n",
            "Epoch #2. Accuracy on batch 2122/2438  on Training is 64.71826424870466\n",
            "Epoch #2. Accuracy on batch 2123/2438  on Training is 64.71869114877589\n",
            "Epoch #2. Accuracy on batch 2124/2438  on Training is 64.71911764705882\n",
            "Epoch #2. Accuracy on batch 2125/2438  on Training is 64.71660395108185\n",
            "Epoch #2. Accuracy on batch 2126/2438  on Training is 64.72143864598026\n",
            "Epoch #2. Accuracy on batch 2127/2438  on Training is 64.71892622180451\n",
            "Epoch #2. Accuracy on batch 2128/2438  on Training is 64.72081963363081\n",
            "Epoch #2. Accuracy on batch 2129/2438  on Training is 64.7256455399061\n",
            "Epoch #2. Accuracy on batch 2130/2438  on Training is 64.72460112623182\n",
            "Epoch #2. Accuracy on batch 2131/2438  on Training is 64.7250234521576\n",
            "Epoch #2. Accuracy on batch 2132/2438  on Training is 64.72398030942335\n",
            "Epoch #2. Accuracy on batch 2133/2438  on Training is 64.73026007497657\n",
            "Epoch #2. Accuracy on batch 2134/2438  on Training is 64.73360655737704\n",
            "Epoch #2. Accuracy on batch 2135/2438  on Training is 64.73841292134831\n",
            "Epoch #2. Accuracy on batch 2136/2438  on Training is 64.73882779597567\n",
            "Epoch #2. Accuracy on batch 2137/2438  on Training is 64.73924228250702\n",
            "Epoch #2. Accuracy on batch 2138/2438  on Training is 64.73527349228611\n",
            "Epoch #2. Accuracy on batch 2139/2438  on Training is 64.73860981308411\n",
            "Batch Id 2140/2438 is having training loss of 1.3559823036193848\n",
            "1.5343066453933716\n",
            "Epoch #2. Accuracy on batch 2140/2438  on Training is 64.73756422232601\n",
            "Epoch #2. Accuracy on batch 2141/2438  on Training is 64.73651960784314\n",
            "Epoch #2. Accuracy on batch 2142/2438  on Training is 64.73839244050397\n",
            "Epoch #2. Accuracy on batch 2143/2438  on Training is 64.73880597014926\n",
            "Epoch #2. Accuracy on batch 2144/2438  on Training is 64.73921911421911\n",
            "Epoch #2. Accuracy on batch 2145/2438  on Training is 64.73089468779123\n",
            "Epoch #2. Accuracy on batch 2146/2438  on Training is 64.72694457382394\n",
            "Epoch #2. Accuracy on batch 2147/2438  on Training is 64.72590782122904\n",
            "Epoch #2. Accuracy on batch 2148/2438  on Training is 64.72632619823173\n",
            "Epoch #2. Accuracy on batch 2149/2438  on Training is 64.72819767441861\n",
            "Epoch #2. Accuracy on batch 2150/2438  on Training is 64.73442584844258\n",
            "Epoch #2. Accuracy on batch 2151/2438  on Training is 64.73193540892193\n",
            "Epoch #2. Accuracy on batch 2152/2438  on Training is 64.73380167208546\n",
            "Epoch #2. Accuracy on batch 2153/2438  on Training is 64.7313138347261\n",
            "Epoch #2. Accuracy on batch 2154/2438  on Training is 64.7360788863109\n",
            "Epoch #2. Accuracy on batch 2155/2438  on Training is 64.74228896103897\n",
            "Epoch #2. Accuracy on batch 2156/2438  on Training is 64.74269819193324\n",
            "Epoch #2. Accuracy on batch 2157/2438  on Training is 64.73731464318814\n",
            "Epoch #2. Accuracy on batch 2158/2438  on Training is 64.73917322834646\n",
            "Epoch #2. Accuracy on batch 2159/2438  on Training is 64.73813657407408\n",
            "Batch Id 2160/2438 is having training loss of 1.3558745384216309\n",
            "1.1180986166000366\n",
            "Epoch #2. Accuracy on batch 2160/2438  on Training is 64.73854696899583\n",
            "Epoch #2. Accuracy on batch 2161/2438  on Training is 64.73317530064755\n",
            "Epoch #2. Accuracy on batch 2162/2438  on Training is 64.73069810448452\n",
            "Epoch #2. Accuracy on batch 2163/2438  on Training is 64.73111136783734\n",
            "Epoch #2. Accuracy on batch 2164/2438  on Training is 64.73008083140877\n",
            "Epoch #2. Accuracy on batch 2165/2438  on Training is 64.73049399815328\n",
            "Epoch #2. Accuracy on batch 2166/2438  on Training is 64.7294646977388\n",
            "Epoch #2. Accuracy on batch 2167/2438  on Training is 64.72987776752767\n",
            "Epoch #2. Accuracy on batch 2168/2438  on Training is 64.73893499308437\n",
            "Epoch #2. Accuracy on batch 2169/2438  on Training is 64.73790322580645\n",
            "Epoch #2. Accuracy on batch 2170/2438  on Training is 64.73543298019347\n",
            "Epoch #2. Accuracy on batch 2171/2438  on Training is 64.73440377532228\n",
            "Epoch #2. Accuracy on batch 2172/2438  on Training is 64.73049930971008\n",
            "Epoch #2. Accuracy on batch 2173/2438  on Training is 64.73522309107636\n",
            "Epoch #2. Accuracy on batch 2174/2438  on Training is 64.73275862068965\n",
            "Epoch #2. Accuracy on batch 2175/2438  on Training is 64.73029641544117\n",
            "Epoch #2. Accuracy on batch 2176/2438  on Training is 64.72353008727607\n",
            "Epoch #2. Accuracy on batch 2177/2438  on Training is 64.72107438016529\n",
            "Epoch #2. Accuracy on batch 2178/2438  on Training is 64.72148921523635\n",
            "Epoch #2. Accuracy on batch 2179/2438  on Training is 64.7276376146789\n",
            "Batch Id 2180/2438 is having training loss of 1.355610966682434\n",
            "1.1474100351333618\n",
            "Epoch #2. Accuracy on batch 2180/2438  on Training is 64.73091471801926\n",
            "Epoch #2. Accuracy on batch 2181/2438  on Training is 64.72846012832264\n",
            "Epoch #2. Accuracy on batch 2182/2438  on Training is 64.72887081997251\n",
            "Epoch #2. Accuracy on batch 2183/2438  on Training is 64.72785027472527\n",
            "Epoch #2. Accuracy on batch 2184/2438  on Training is 64.71824942791763\n",
            "Epoch #2. Accuracy on batch 2185/2438  on Training is 64.72152333028362\n",
            "Epoch #2. Accuracy on batch 2186/2438  on Training is 64.72193644261546\n",
            "Epoch #2. Accuracy on batch 2187/2438  on Training is 64.72520566727606\n",
            "Epoch #2. Accuracy on batch 2188/2438  on Training is 64.72561671996345\n",
            "Epoch #2. Accuracy on batch 2189/2438  on Training is 64.72602739726027\n",
            "Epoch #2. Accuracy on batch 2190/2438  on Training is 64.73499543587403\n",
            "Epoch #2. Accuracy on batch 2191/2438  on Training is 64.73112454379562\n",
            "Epoch #2. Accuracy on batch 2192/2438  on Training is 64.73010715914273\n",
            "Epoch #2. Accuracy on batch 2193/2438  on Training is 64.73336371923428\n",
            "Epoch #2. Accuracy on batch 2194/2438  on Training is 64.7366173120729\n",
            "Epoch #2. Accuracy on batch 2195/2438  on Training is 64.73844489981785\n",
            "Epoch #2. Accuracy on batch 2196/2438  on Training is 64.74027082385071\n",
            "Epoch #2. Accuracy on batch 2197/2438  on Training is 64.74209508644222\n",
            "Epoch #2. Accuracy on batch 2198/2438  on Training is 64.7424965893588\n",
            "Epoch #2. Accuracy on batch 2199/2438  on Training is 64.75\n",
            "Batch Id 2200/2438 is having training loss of 1.354399561882019\n",
            "0.977288544178009\n",
            "Epoch #2. Accuracy on batch 2200/2438  on Training is 64.75607678328032\n",
            "Epoch #2. Accuracy on batch 2201/2438  on Training is 64.76214804722979\n",
            "Epoch #2. Accuracy on batch 2202/2438  on Training is 64.75970267816614\n",
            "Epoch #2. Accuracy on batch 2203/2438  on Training is 64.76860254083485\n",
            "Epoch #2. Accuracy on batch 2204/2438  on Training is 64.76899092970521\n",
            "Epoch #2. Accuracy on batch 2205/2438  on Training is 64.76937896645512\n",
            "Epoch #2. Accuracy on batch 2206/2438  on Training is 64.76835070231083\n",
            "Epoch #2. Accuracy on batch 2207/2438  on Training is 64.77156929347827\n",
            "Epoch #2. Accuracy on batch 2208/2438  on Training is 64.77337030330466\n",
            "Epoch #2. Accuracy on batch 2209/2438  on Training is 64.77941176470588\n",
            "Epoch #2. Accuracy on batch 2210/2438  on Training is 64.77696743554952\n",
            "Epoch #2. Accuracy on batch 2211/2438  on Training is 64.78017631103074\n",
            "Epoch #2. Accuracy on batch 2212/2438  on Training is 64.78197017623135\n",
            "Epoch #2. Accuracy on batch 2213/2438  on Training is 64.78093947606143\n",
            "Epoch #2. Accuracy on batch 2214/2438  on Training is 64.77990970654628\n",
            "Epoch #2. Accuracy on batch 2215/2438  on Training is 64.78170126353791\n",
            "Epoch #2. Accuracy on batch 2216/2438  on Training is 64.78067207938656\n",
            "Epoch #2. Accuracy on batch 2217/2438  on Training is 64.78246167718666\n",
            "Epoch #2. Accuracy on batch 2218/2438  on Training is 64.78424966200991\n",
            "Epoch #2. Accuracy on batch 2219/2438  on Training is 64.78744369369369\n",
            "Batch Id 2220/2438 is having training loss of 1.3530977964401245\n",
            "1.2226492166519165\n",
            "Epoch #2. Accuracy on batch 2220/2438  on Training is 64.78359972985142\n",
            "Epoch #2. Accuracy on batch 2221/2438  on Training is 64.78819756975697\n",
            "Epoch #2. Accuracy on batch 2222/2438  on Training is 64.79279127305443\n",
            "Epoch #2. Accuracy on batch 2223/2438  on Training is 64.79176034172662\n",
            "Epoch #2. Accuracy on batch 2224/2438  on Training is 64.79775280898876\n",
            "Epoch #2. Accuracy on batch 2225/2438  on Training is 64.79672057502246\n",
            "Epoch #2. Accuracy on batch 2226/2438  on Training is 64.79288280197575\n",
            "Epoch #2. Accuracy on batch 2227/2438  on Training is 64.79465888689407\n",
            "Epoch #2. Accuracy on batch 2228/2438  on Training is 64.79783535217587\n",
            "Epoch #2. Accuracy on batch 2229/2438  on Training is 64.79400224215247\n",
            "Epoch #2. Accuracy on batch 2230/2438  on Training is 64.78597041685343\n",
            "Epoch #2. Accuracy on batch 2231/2438  on Training is 64.78774641577061\n",
            "Epoch #2. Accuracy on batch 2232/2438  on Training is 64.79092028660995\n",
            "Epoch #2. Accuracy on batch 2233/2438  on Training is 64.78709713518353\n",
            "Epoch #2. Accuracy on batch 2234/2438  on Training is 64.79026845637584\n",
            "Epoch #2. Accuracy on batch 2235/2438  on Training is 64.79203935599284\n",
            "Epoch #2. Accuracy on batch 2236/2438  on Training is 64.793808672329\n",
            "Epoch #2. Accuracy on batch 2237/2438  on Training is 64.79278373547811\n",
            "Epoch #2. Accuracy on batch 2238/2438  on Training is 64.7945511389013\n",
            "Epoch #2. Accuracy on batch 2239/2438  on Training is 64.80050223214286\n",
            "Batch Id 2240/2438 is having training loss of 1.3530092239379883\n",
            "1.6747691631317139\n",
            "Epoch #2. Accuracy on batch 2240/2438  on Training is 64.79668674698796\n",
            "Epoch #2. Accuracy on batch 2241/2438  on Training is 64.79984388938448\n",
            "Epoch #2. Accuracy on batch 2242/2438  on Training is 64.79881854658939\n",
            "Epoch #2. Accuracy on batch 2243/2438  on Training is 64.80614973262033\n",
            "Epoch #2. Accuracy on batch 2244/2438  on Training is 64.8065144766147\n",
            "Epoch #2. Accuracy on batch 2245/2438  on Training is 64.81383570792521\n",
            "Epoch #2. Accuracy on batch 2246/2438  on Training is 64.81141522029372\n",
            "Epoch #2. Accuracy on batch 2247/2438  on Training is 64.81038701067615\n",
            "Epoch #2. Accuracy on batch 2248/2438  on Training is 64.80797020898177\n",
            "Epoch #2. Accuracy on batch 2249/2438  on Training is 64.81388888888888\n",
            "Epoch #2. Accuracy on batch 2250/2438  on Training is 64.81841403820525\n",
            "Epoch #2. Accuracy on batch 2251/2438  on Training is 64.8229351687389\n",
            "Epoch #2. Accuracy on batch 2252/2438  on Training is 64.82467820683533\n",
            "Epoch #2. Accuracy on batch 2253/2438  on Training is 64.81810115350488\n",
            "Epoch #2. Accuracy on batch 2254/2438  on Training is 64.8170731707317\n",
            "Epoch #2. Accuracy on batch 2255/2438  on Training is 64.81881648936171\n",
            "Epoch #2. Accuracy on batch 2256/2438  on Training is 64.81778910057598\n",
            "Epoch #2. Accuracy on batch 2257/2438  on Training is 64.81537865367582\n",
            "Epoch #2. Accuracy on batch 2258/2438  on Training is 64.81435369632581\n",
            "Epoch #2. Accuracy on batch 2259/2438  on Training is 64.81886061946902\n",
            "Batch Id 2260/2438 is having training loss of 1.3519800901412964\n",
            "1.081005334854126\n",
            "Epoch #2. Accuracy on batch 2260/2438  on Training is 64.82059929234852\n",
            "Epoch #2. Accuracy on batch 2261/2438  on Training is 64.81957338638374\n",
            "Epoch #2. Accuracy on batch 2262/2438  on Training is 64.81992929739285\n",
            "Epoch #2. Accuracy on batch 2263/2438  on Training is 64.824425795053\n",
            "Epoch #2. Accuracy on batch 2264/2438  on Training is 64.82339955849889\n",
            "Epoch #2. Accuracy on batch 2265/2438  on Training is 64.81823698146513\n",
            "Epoch #2. Accuracy on batch 2266/2438  on Training is 64.8103220114689\n",
            "Epoch #2. Accuracy on batch 2267/2438  on Training is 64.80379188712521\n",
            "Epoch #2. Accuracy on batch 2268/2438  on Training is 64.80553107095636\n",
            "Epoch #2. Accuracy on batch 2269/2438  on Training is 64.8045154185022\n",
            "Epoch #2. Accuracy on batch 2270/2438  on Training is 64.80074856891237\n",
            "Epoch #2. Accuracy on batch 2271/2438  on Training is 64.79836047535211\n",
            "Epoch #2. Accuracy on batch 2272/2438  on Training is 64.80009898812142\n",
            "Epoch #2. Accuracy on batch 2273/2438  on Training is 64.80183597185577\n",
            "Epoch #2. Accuracy on batch 2274/2438  on Training is 64.79395604395604\n",
            "Epoch #2. Accuracy on batch 2275/2438  on Training is 64.7970672231986\n",
            "Epoch #2. Accuracy on batch 2276/2438  on Training is 64.79880324989021\n",
            "Epoch #2. Accuracy on batch 2277/2438  on Training is 64.79916593503073\n",
            "Epoch #2. Accuracy on batch 2278/2438  on Training is 64.79541465555069\n",
            "Epoch #2. Accuracy on batch 2279/2438  on Training is 64.80126096491227\n",
            "Batch Id 2280/2438 is having training loss of 1.3519352674484253\n",
            "0.9595623016357422\n",
            "Epoch #2. Accuracy on batch 2280/2438  on Training is 64.80436212187637\n",
            "Epoch #2. Accuracy on batch 2281/2438  on Training is 64.81019938650307\n",
            "Epoch #2. Accuracy on batch 2282/2438  on Training is 64.81329391151993\n",
            "Epoch #2. Accuracy on batch 2283/2438  on Training is 64.81912215411559\n",
            "Epoch #2. Accuracy on batch 2284/2438  on Training is 64.81537199124726\n",
            "Epoch #2. Accuracy on batch 2285/2438  on Training is 64.81982720909886\n",
            "Epoch #2. Accuracy on batch 2286/2438  on Training is 64.81608001749017\n",
            "Epoch #2. Accuracy on batch 2287/2438  on Training is 64.81370192307692\n",
            "Epoch #2. Accuracy on batch 2288/2438  on Training is 64.80859545653124\n",
            "Epoch #2. Accuracy on batch 2289/2438  on Training is 64.8089519650655\n",
            "Epoch #2. Accuracy on batch 2290/2438  on Training is 64.80794412920122\n",
            "Epoch #2. Accuracy on batch 2291/2438  on Training is 64.80830061082024\n",
            "Epoch #2. Accuracy on batch 2292/2438  on Training is 64.80865678150894\n",
            "Epoch #2. Accuracy on batch 2293/2438  on Training is 64.81309938971229\n",
            "Epoch #2. Accuracy on batch 2294/2438  on Training is 64.82162309368192\n",
            "Epoch #2. Accuracy on batch 2295/2438  on Training is 64.82605618466899\n",
            "Epoch #2. Accuracy on batch 2296/2438  on Training is 64.83184588593818\n",
            "Epoch #2. Accuracy on batch 2297/2438  on Training is 64.83219103568321\n",
            "Epoch #2. Accuracy on batch 2298/2438  on Training is 64.82845802522836\n",
            "Epoch #2. Accuracy on batch 2299/2438  on Training is 64.82065217391305\n",
            "Batch Id 2300/2438 is having training loss of 1.3516031503677368\n",
            "1.0870524644851685\n",
            "Epoch #2. Accuracy on batch 2300/2438  on Training is 64.82371794871794\n",
            "Epoch #2. Accuracy on batch 2301/2438  on Training is 64.82678105994788\n",
            "Epoch #2. Accuracy on batch 2302/2438  on Training is 64.81898610508033\n",
            "Epoch #2. Accuracy on batch 2303/2438  on Training is 64.82476128472223\n",
            "Epoch #2. Accuracy on batch 2304/2438  on Training is 64.82510845986985\n",
            "Epoch #2. Accuracy on batch 2305/2438  on Training is 64.82274501300954\n",
            "Epoch #2. Accuracy on batch 2306/2438  on Training is 64.82851105331599\n",
            "Epoch #2. Accuracy on batch 2307/2438  on Training is 64.83156412478336\n",
            "Epoch #2. Accuracy on batch 2308/2438  on Training is 64.8373213512343\n",
            "Epoch #2. Accuracy on batch 2309/2438  on Training is 64.83766233766234\n",
            "Epoch #2. Accuracy on batch 2310/2438  on Training is 64.83259411510168\n",
            "Epoch #2. Accuracy on batch 2311/2438  on Training is 64.83023356401384\n",
            "Epoch #2. Accuracy on batch 2312/2438  on Training is 64.82787505404237\n",
            "Epoch #2. Accuracy on batch 2313/2438  on Training is 64.82821953327571\n",
            "Epoch #2. Accuracy on batch 2314/2438  on Training is 64.82451403887688\n",
            "Epoch #2. Accuracy on batch 2315/2438  on Training is 64.81811312607945\n",
            "Epoch #2. Accuracy on batch 2316/2438  on Training is 64.8184613724644\n",
            "Epoch #2. Accuracy on batch 2317/2438  on Training is 64.81206859361518\n",
            "Epoch #2. Accuracy on batch 2318/2438  on Training is 64.81646183699871\n",
            "Epoch #2. Accuracy on batch 2319/2438  on Training is 64.81950431034483\n",
            "Batch Id 2320/2438 is having training loss of 1.3509008884429932\n",
            "0.5254611968994141\n",
            "Epoch #2. Accuracy on batch 2320/2438  on Training is 64.83062257647566\n",
            "Epoch #2. Accuracy on batch 2321/2438  on Training is 64.82961886304909\n",
            "Epoch #2. Accuracy on batch 2322/2438  on Training is 64.83534222987517\n",
            "Epoch #2. Accuracy on batch 2323/2438  on Training is 64.83702667814114\n",
            "Epoch #2. Accuracy on batch 2324/2438  on Training is 64.83602150537635\n",
            "Epoch #2. Accuracy on batch 2325/2438  on Training is 64.83367368873603\n",
            "Epoch #2. Accuracy on batch 2326/2438  on Training is 64.83804254404814\n",
            "Epoch #2. Accuracy on batch 2327/2438  on Training is 64.83972293814433\n",
            "Epoch #2. Accuracy on batch 2328/2438  on Training is 64.84006011163589\n",
            "Epoch #2. Accuracy on batch 2329/2438  on Training is 64.83637339055794\n",
            "Epoch #2. Accuracy on batch 2330/2438  on Training is 64.83805233805234\n",
            "Epoch #2. Accuracy on batch 2331/2438  on Training is 64.83704974271012\n",
            "Epoch #2. Accuracy on batch 2332/2438  on Training is 64.83604800685812\n",
            "Epoch #2. Accuracy on batch 2333/2438  on Training is 64.8350471293916\n",
            "Epoch #2. Accuracy on batch 2334/2438  on Training is 64.8340471092077\n",
            "Epoch #2. Accuracy on batch 2335/2438  on Training is 64.83304794520548\n",
            "Epoch #2. Accuracy on batch 2336/2438  on Training is 64.83739837398375\n",
            "Epoch #2. Accuracy on batch 2337/2438  on Training is 64.8350620188195\n",
            "Epoch #2. Accuracy on batch 2338/2438  on Training is 64.83807182556649\n",
            "Epoch #2. Accuracy on batch 2339/2438  on Training is 64.83707264957265\n",
            "Batch Id 2340/2438 is having training loss of 1.3508518934249878\n",
            "1.2827790975570679\n",
            "Epoch #2. Accuracy on batch 2340/2438  on Training is 64.84007902605724\n",
            "Epoch #2. Accuracy on batch 2341/2438  on Training is 64.84575149444919\n",
            "Epoch #2. Accuracy on batch 2342/2438  on Training is 64.85542040119505\n",
            "Epoch #2. Accuracy on batch 2343/2438  on Training is 64.8570819112628\n",
            "Epoch #2. Accuracy on batch 2344/2438  on Training is 64.85607675906184\n",
            "Epoch #2. Accuracy on batch 2345/2438  on Training is 64.85773657289002\n",
            "Epoch #2. Accuracy on batch 2346/2438  on Training is 64.86338943331913\n",
            "Epoch #2. Accuracy on batch 2347/2438  on Training is 64.86105195911414\n",
            "Epoch #2. Accuracy on batch 2348/2438  on Training is 64.86137718177947\n",
            "Epoch #2. Accuracy on batch 2349/2438  on Training is 64.86170212765957\n",
            "Epoch #2. Accuracy on batch 2350/2438  on Training is 64.86335601871544\n",
            "Epoch #2. Accuracy on batch 2351/2438  on Training is 64.8610225340136\n",
            "Epoch #2. Accuracy on batch 2352/2438  on Training is 64.8626753081173\n",
            "Epoch #2. Accuracy on batch 2353/2438  on Training is 64.8643266779949\n",
            "Epoch #2. Accuracy on batch 2354/2438  on Training is 64.8619957537155\n",
            "Epoch #2. Accuracy on batch 2355/2438  on Training is 64.866298811545\n",
            "Epoch #2. Accuracy on batch 2356/2438  on Training is 64.86794654221468\n",
            "Epoch #2. Accuracy on batch 2357/2438  on Training is 64.86561704834605\n",
            "Epoch #2. Accuracy on batch 2358/2438  on Training is 64.86461424332344\n",
            "Epoch #2. Accuracy on batch 2359/2438  on Training is 64.86228813559322\n",
            "Batch Id 2360/2438 is having training loss of 1.350088357925415\n",
            "1.2744741439819336\n",
            "Epoch #2. Accuracy on batch 2360/2438  on Training is 64.86128759000424\n",
            "Epoch #2. Accuracy on batch 2361/2438  on Training is 64.86161092294665\n",
            "Epoch #2. Accuracy on batch 2362/2438  on Training is 64.86722386796446\n",
            "Epoch #2. Accuracy on batch 2363/2438  on Training is 64.86754441624366\n",
            "Epoch #2. Accuracy on batch 2364/2438  on Training is 64.87315010570825\n",
            "Epoch #2. Accuracy on batch 2365/2438  on Training is 64.87610946745562\n",
            "Epoch #2. Accuracy on batch 2366/2438  on Training is 64.87510561892691\n",
            "Epoch #2. Accuracy on batch 2367/2438  on Training is 64.87410261824324\n",
            "Epoch #2. Accuracy on batch 2368/2438  on Training is 64.87441958632334\n",
            "Epoch #2. Accuracy on batch 2369/2438  on Training is 64.87605485232068\n",
            "Epoch #2. Accuracy on batch 2370/2438  on Training is 64.87505272037116\n",
            "Epoch #2. Accuracy on batch 2371/2438  on Training is 64.87536888701517\n",
            "Epoch #2. Accuracy on batch 2372/2438  on Training is 64.87305099030763\n",
            "Epoch #2. Accuracy on batch 2373/2438  on Training is 64.8707350463353\n",
            "Epoch #2. Accuracy on batch 2374/2438  on Training is 64.87236842105263\n",
            "Epoch #2. Accuracy on batch 2375/2438  on Training is 64.87531565656566\n",
            "Epoch #2. Accuracy on batch 2376/2438  on Training is 64.87431636516618\n",
            "Epoch #2. Accuracy on batch 2377/2438  on Training is 64.87331791421363\n",
            "Epoch #2. Accuracy on batch 2378/2438  on Training is 64.87494745691467\n",
            "Epoch #2. Accuracy on batch 2379/2438  on Training is 64.87394957983193\n",
            "Batch Id 2380/2438 is having training loss of 1.3496344089508057\n",
            "1.8391777276992798\n",
            "Epoch #2. Accuracy on batch 2380/2438  on Training is 64.86901511969761\n",
            "Epoch #2. Accuracy on batch 2381/2438  on Training is 64.87195633921074\n",
            "Epoch #2. Accuracy on batch 2382/2438  on Training is 64.86571548468318\n",
            "Epoch #2. Accuracy on batch 2383/2438  on Training is 64.86996644295301\n",
            "Epoch #2. Accuracy on batch 2384/2438  on Training is 64.86504192872117\n",
            "Epoch #2. Accuracy on batch 2385/2438  on Training is 64.86797988264878\n",
            "Epoch #2. Accuracy on batch 2386/2438  on Training is 64.86698785085882\n",
            "Epoch #2. Accuracy on batch 2387/2438  on Training is 64.86207077051927\n",
            "Epoch #2. Accuracy on batch 2388/2438  on Training is 64.86108204269568\n",
            "Epoch #2. Accuracy on batch 2389/2438  on Training is 64.8574790794979\n",
            "Epoch #2. Accuracy on batch 2390/2438  on Training is 64.8551861145964\n",
            "Epoch #2. Accuracy on batch 2391/2438  on Training is 64.86073369565217\n",
            "Epoch #2. Accuracy on batch 2392/2438  on Training is 64.86235896364396\n",
            "Epoch #2. Accuracy on batch 2393/2438  on Training is 64.8626775271512\n",
            "Epoch #2. Accuracy on batch 2394/2438  on Training is 64.8643006263048\n",
            "Epoch #2. Accuracy on batch 2395/2438  on Training is 64.86722662771285\n",
            "Epoch #2. Accuracy on batch 2396/2438  on Training is 64.86623904881101\n",
            "Epoch #2. Accuracy on batch 2397/2438  on Training is 64.86916180150125\n",
            "Epoch #2. Accuracy on batch 2398/2438  on Training is 64.86556898707795\n",
            "Epoch #2. Accuracy on batch 2399/2438  on Training is 64.859375\n",
            "Batch Id 2400/2438 is having training loss of 1.3494491577148438\n",
            "1.45176100730896\n",
            "Epoch #2. Accuracy on batch 2400/2438  on Training is 64.8557892544773\n",
            "Epoch #2. Accuracy on batch 2401/2438  on Training is 64.85220649458785\n",
            "Epoch #2. Accuracy on batch 2402/2438  on Training is 64.85382854764877\n",
            "Epoch #2. Accuracy on batch 2403/2438  on Training is 64.85154950083195\n",
            "Epoch #2. Accuracy on batch 2404/2438  on Training is 64.8518711018711\n",
            "Epoch #2. Accuracy on batch 2405/2438  on Training is 64.85349127182045\n",
            "Epoch #2. Accuracy on batch 2406/2438  on Training is 64.852513502285\n",
            "Epoch #2. Accuracy on batch 2407/2438  on Training is 64.8515365448505\n",
            "Epoch #2. Accuracy on batch 2408/2438  on Training is 64.85574927355749\n",
            "Epoch #2. Accuracy on batch 2409/2438  on Training is 64.85477178423237\n",
            "Epoch #2. Accuracy on batch 2410/2438  on Training is 64.84990667772709\n",
            "Epoch #2. Accuracy on batch 2411/2438  on Training is 64.85152363184079\n",
            "Epoch #2. Accuracy on batch 2412/2438  on Training is 64.85184417737257\n",
            "Epoch #2. Accuracy on batch 2413/2438  on Training is 64.84828086164043\n",
            "Epoch #2. Accuracy on batch 2414/2438  on Training is 64.84860248447205\n",
            "Epoch #2. Accuracy on batch 2415/2438  on Training is 64.84633692052981\n",
            "Epoch #2. Accuracy on batch 2416/2438  on Training is 64.84795200661978\n",
            "Epoch #2. Accuracy on batch 2417/2438  on Training is 64.85085814722912\n",
            "Epoch #2. Accuracy on batch 2418/2438  on Training is 64.85376188507648\n",
            "Epoch #2. Accuracy on batch 2419/2438  on Training is 64.85795454545455\n",
            "Batch Id 2420/2438 is having training loss of 1.3487106561660767\n",
            "0.8662562370300293\n",
            "Epoch #2. Accuracy on batch 2420/2438  on Training is 64.86214374225527\n",
            "Epoch #2. Accuracy on batch 2421/2438  on Training is 64.86632947976878\n",
            "Epoch #2. Accuracy on batch 2422/2438  on Training is 64.86664259182831\n",
            "Epoch #2. Accuracy on batch 2423/2438  on Training is 64.86566625412541\n",
            "Epoch #2. Accuracy on batch 2424/2438  on Training is 64.86726804123711\n",
            "Epoch #2. Accuracy on batch 2425/2438  on Training is 64.87144476504534\n",
            "Epoch #2. Accuracy on batch 2426/2438  on Training is 64.86531726411208\n",
            "Epoch #2. Accuracy on batch 2427/2438  on Training is 64.86048187808896\n",
            "Epoch #2. Accuracy on batch 2428/2438  on Training is 64.86465623713462\n",
            "Epoch #2. Accuracy on batch 2429/2438  on Training is 64.85982510288066\n",
            "Epoch #2. Accuracy on batch 2430/2438  on Training is 64.8562834224599\n",
            "Epoch #2. Accuracy on batch 2431/2438  on Training is 64.85274465460526\n",
            "Epoch #2. Accuracy on batch 2432/2438  on Training is 64.85177764077271\n",
            "Epoch #2. Accuracy on batch 2433/2438  on Training is 64.85466310599836\n",
            "Epoch #2. Accuracy on batch 2434/2438  on Training is 64.85754620123203\n",
            "Epoch #2. Accuracy on batch 2435/2438  on Training is 64.85914408866995\n",
            "Epoch #2. Accuracy on batch 2436/2438  on Training is 64.86330529339352\n",
            "Epoch #2. Accuracy on batch 2437/2438  on Training is 64.86538461538461\n",
            "Epoch #2. Batch Id 0/278  is having validation loss of 1.3438811302185059\n",
            "1.3438811302185059\n",
            "Epoch #2. Batch Id 0/278  is having validation accuracy of 56.25\n",
            "Epoch #2. Batch Id 1/278  is having validation loss of 1.4410605430603027\n",
            "1.5382400751113892\n",
            "Epoch #2. Batch Id 1/278  is having validation accuracy of 56.25\n",
            "Epoch #2. Batch Id 2/278  is having validation loss of 1.4143991470336914\n",
            "1.3610762357711792\n",
            "Epoch #2. Batch Id 2/278  is having validation accuracy of 57.291666666666664\n",
            "Epoch #2. Batch Id 3/278  is having validation loss of 1.3058174848556519\n",
            "0.9800724387168884\n",
            "Epoch #2. Batch Id 3/278  is having validation accuracy of 60.9375\n",
            "Epoch #2. Batch Id 4/278  is having validation loss of 1.5400367975234985\n",
            "2.476914167404175\n",
            "Epoch #2. Batch Id 4/278  is having validation accuracy of 55.625\n",
            "Epoch #2. Batch Id 5/278  is having validation loss of 1.5722174644470215\n",
            "1.7331204414367676\n",
            "Epoch #2. Batch Id 5/278  is having validation accuracy of 56.770833333333336\n",
            "Epoch #2. Batch Id 6/278  is having validation loss of 1.6236811876296997\n",
            "1.9324631690979004\n",
            "Epoch #2. Batch Id 6/278  is having validation accuracy of 55.357142857142854\n",
            "Epoch #2. Batch Id 7/278  is having validation loss of 1.6304218769073486\n",
            "1.6776070594787598\n",
            "Epoch #2. Batch Id 7/278  is having validation accuracy of 55.078125\n",
            "Epoch #2. Batch Id 8/278  is having validation loss of 1.609588623046875\n",
            "1.4429227113723755\n",
            "Epoch #2. Batch Id 8/278  is having validation accuracy of 54.861111111111114\n",
            "Epoch #2. Batch Id 9/278  is having validation loss of 1.5541973114013672\n",
            "1.0556753873825073\n",
            "Epoch #2. Batch Id 9/278  is having validation accuracy of 55.9375\n",
            "Epoch #2. Batch Id 10/278  is having validation loss of 1.5513354539871216\n",
            "1.5227165222167969\n",
            "Epoch #2. Batch Id 10/278  is having validation accuracy of 56.81818181818182\n",
            "Epoch #2. Batch Id 11/278  is having validation loss of 1.53902006149292\n",
            "1.403550386428833\n",
            "Epoch #2. Batch Id 11/278  is having validation accuracy of 57.03125\n",
            "Epoch #2. Batch Id 12/278  is having validation loss of 1.538705825805664\n",
            "1.5349345207214355\n",
            "Epoch #2. Batch Id 12/278  is having validation accuracy of 57.45192307692308\n",
            "Epoch #2. Batch Id 13/278  is having validation loss of 1.54373037815094\n",
            "1.6090500354766846\n",
            "Epoch #2. Batch Id 13/278  is having validation accuracy of 56.919642857142854\n",
            "Epoch #2. Batch Id 14/278  is having validation loss of 1.533040165901184\n",
            "1.3833773136138916\n",
            "Epoch #2. Batch Id 14/278  is having validation accuracy of 57.5\n",
            "Epoch #2. Batch Id 15/278  is having validation loss of 1.5326226949691772\n",
            "1.5263606309890747\n",
            "Epoch #2. Batch Id 15/278  is having validation accuracy of 57.8125\n",
            "Epoch #2. Batch Id 16/278  is having validation loss of 1.5397779941558838\n",
            "1.654261827468872\n",
            "Epoch #2. Batch Id 16/278  is having validation accuracy of 58.27205882352941\n",
            "Epoch #2. Batch Id 17/278  is having validation loss of 1.5465898513793945\n",
            "1.6623904705047607\n",
            "Epoch #2. Batch Id 17/278  is having validation accuracy of 57.986111111111114\n",
            "Epoch #2. Batch Id 18/278  is having validation loss of 1.5470179319381714\n",
            "1.5547243356704712\n",
            "Epoch #2. Batch Id 18/278  is having validation accuracy of 58.223684210526315\n",
            "Epoch #2. Batch Id 19/278  is having validation loss of 1.550022840499878\n",
            "1.6071151494979858\n",
            "Epoch #2. Batch Id 19/278  is having validation accuracy of 58.28125\n",
            "Epoch #2. Batch Id 20/278  is having validation loss of 1.5461710691452026\n",
            "1.4691352844238281\n",
            "Epoch #2. Batch Id 20/278  is having validation accuracy of 58.18452380952381\n",
            "Epoch #2. Batch Id 21/278  is having validation loss of 1.5461204051971436\n",
            "1.5450559854507446\n",
            "Epoch #2. Batch Id 21/278  is having validation accuracy of 58.23863636363637\n",
            "Epoch #2. Batch Id 22/278  is having validation loss of 1.5103768110275269\n",
            "0.7240188717842102\n",
            "Epoch #2. Batch Id 22/278  is having validation accuracy of 59.51086956521739\n",
            "Epoch #2. Batch Id 23/278  is having validation loss of 1.5186444520950317\n",
            "1.7087998390197754\n",
            "Epoch #2. Batch Id 23/278  is having validation accuracy of 59.375\n",
            "Epoch #2. Batch Id 24/278  is having validation loss of 1.5074235200881958\n",
            "1.2381207942962646\n",
            "Epoch #2. Batch Id 24/278  is having validation accuracy of 59.5\n",
            "Epoch #2. Batch Id 25/278  is having validation loss of 1.5131763219833374\n",
            "1.6569949388504028\n",
            "Epoch #2. Batch Id 25/278  is having validation accuracy of 59.61538461538461\n",
            "Epoch #2. Batch Id 26/278  is having validation loss of 1.5247929096221924\n",
            "1.8268239498138428\n",
            "Epoch #2. Batch Id 26/278  is having validation accuracy of 59.49074074074074\n",
            "Epoch #2. Batch Id 27/278  is having validation loss of 1.5200449228286743\n",
            "1.3918498754501343\n",
            "Epoch #2. Batch Id 27/278  is having validation accuracy of 59.933035714285715\n",
            "Epoch #2. Batch Id 28/278  is having validation loss of 1.5358552932739258\n",
            "1.9785457849502563\n",
            "Epoch #2. Batch Id 28/278  is having validation accuracy of 59.69827586206897\n",
            "Epoch #2. Batch Id 29/278  is having validation loss of 1.5321073532104492\n",
            "1.4234163761138916\n",
            "Epoch #2. Batch Id 29/278  is having validation accuracy of 59.479166666666664\n",
            "Epoch #2. Batch Id 30/278  is having validation loss of 1.5274308919906616\n",
            "1.387135624885559\n",
            "Epoch #2. Batch Id 30/278  is having validation accuracy of 59.57661290322581\n",
            "Epoch #2. Batch Id 31/278  is having validation loss of 1.5298388004302979\n",
            "1.604483723640442\n",
            "Epoch #2. Batch Id 31/278  is having validation accuracy of 59.47265625\n",
            "Epoch #2. Batch Id 32/278  is having validation loss of 1.5357327461242676\n",
            "1.724340796470642\n",
            "Epoch #2. Batch Id 32/278  is having validation accuracy of 59.46969696969697\n",
            "Epoch #2. Batch Id 33/278  is having validation loss of 1.5340912342071533\n",
            "1.4799212217330933\n",
            "Epoch #2. Batch Id 33/278  is having validation accuracy of 59.283088235294116\n",
            "Epoch #2. Batch Id 34/278  is having validation loss of 1.548345685005188\n",
            "2.0329971313476562\n",
            "Epoch #2. Batch Id 34/278  is having validation accuracy of 58.92857142857143\n",
            "Epoch #2. Batch Id 35/278  is having validation loss of 1.5410728454589844\n",
            "1.286523699760437\n",
            "Epoch #2. Batch Id 35/278  is having validation accuracy of 59.201388888888886\n",
            "Epoch #2. Batch Id 36/278  is having validation loss of 1.5350528955459595\n",
            "1.3183350563049316\n",
            "Epoch #2. Batch Id 36/278  is having validation accuracy of 59.375\n",
            "Epoch #2. Batch Id 37/278  is having validation loss of 1.5339282751083374\n",
            "1.492317795753479\n",
            "Epoch #2. Batch Id 37/278  is having validation accuracy of 59.21052631578947\n",
            "Epoch #2. Batch Id 38/278  is having validation loss of 1.5332609415054321\n",
            "1.5079008340835571\n",
            "Epoch #2. Batch Id 38/278  is having validation accuracy of 59.21474358974359\n",
            "Epoch #2. Batch Id 39/278  is having validation loss of 1.5266807079315186\n",
            "1.2700501680374146\n",
            "Epoch #2. Batch Id 39/278  is having validation accuracy of 59.375\n",
            "Epoch #2. Batch Id 40/278  is having validation loss of 1.530023217201233\n",
            "1.663724422454834\n",
            "Epoch #2. Batch Id 40/278  is having validation accuracy of 59.298780487804876\n",
            "Epoch #2. Batch Id 41/278  is having validation loss of 1.533326268196106\n",
            "1.668750286102295\n",
            "Epoch #2. Batch Id 41/278  is having validation accuracy of 59.226190476190474\n",
            "Epoch #2. Batch Id 42/278  is having validation loss of 1.5240823030471802\n",
            "1.135837197303772\n",
            "Epoch #2. Batch Id 42/278  is having validation accuracy of 59.6656976744186\n",
            "Epoch #2. Batch Id 43/278  is having validation loss of 1.5193157196044922\n",
            "1.3143552541732788\n",
            "Epoch #2. Batch Id 43/278  is having validation accuracy of 59.73011363636363\n",
            "Epoch #2. Batch Id 44/278  is having validation loss of 1.517748475074768\n",
            "1.4487916231155396\n",
            "Epoch #2. Batch Id 44/278  is having validation accuracy of 59.65277777777778\n",
            "Epoch #2. Batch Id 45/278  is having validation loss of 1.5192676782608032\n",
            "1.5876340866088867\n",
            "Epoch #2. Batch Id 45/278  is having validation accuracy of 59.578804347826086\n",
            "Epoch #2. Batch Id 46/278  is having validation loss of 1.5103492736816406\n",
            "1.1001046895980835\n",
            "Epoch #2. Batch Id 46/278  is having validation accuracy of 59.640957446808514\n",
            "Epoch #2. Batch Id 47/278  is having validation loss of 1.5073350667953491\n",
            "1.3656690120697021\n",
            "Epoch #2. Batch Id 47/278  is having validation accuracy of 59.830729166666664\n",
            "Epoch #2. Batch Id 48/278  is having validation loss of 1.5013071298599243\n",
            "1.21196448802948\n",
            "Epoch #2. Batch Id 48/278  is having validation accuracy of 59.94897959183673\n",
            "Epoch #2. Batch Id 49/278  is having validation loss of 1.5012277364730835\n",
            "1.497338891029358\n",
            "Epoch #2. Batch Id 49/278  is having validation accuracy of 59.9375\n",
            "Epoch #2. Batch Id 50/278  is having validation loss of 1.492859959602356\n",
            "1.074472427368164\n",
            "Epoch #2. Batch Id 50/278  is having validation accuracy of 59.9264705882353\n",
            "Epoch #2. Batch Id 51/278  is having validation loss of 1.4879263639450073\n",
            "1.2363111972808838\n",
            "Epoch #2. Batch Id 51/278  is having validation accuracy of 60.09615384615385\n",
            "Epoch #2. Batch Id 52/278  is having validation loss of 1.4867639541625977\n",
            "1.4263200759887695\n",
            "Epoch #2. Batch Id 52/278  is having validation accuracy of 60.08254716981132\n",
            "Epoch #2. Batch Id 53/278  is having validation loss of 1.4886410236358643\n",
            "1.5881237983703613\n",
            "Epoch #2. Batch Id 53/278  is having validation accuracy of 59.895833333333336\n",
            "Epoch #2. Batch Id 54/278  is having validation loss of 1.4882625341415405\n",
            "1.467826247215271\n",
            "Epoch #2. Batch Id 54/278  is having validation accuracy of 59.94318181818182\n",
            "Epoch #2. Batch Id 55/278  is having validation loss of 1.4878026247024536\n",
            "1.4625083208084106\n",
            "Epoch #2. Batch Id 55/278  is having validation accuracy of 59.877232142857146\n",
            "Epoch #2. Batch Id 56/278  is having validation loss of 1.492504596710205\n",
            "1.7558140754699707\n",
            "Epoch #2. Batch Id 56/278  is having validation accuracy of 59.86842105263158\n",
            "Epoch #2. Batch Id 57/278  is having validation loss of 1.4892581701278687\n",
            "1.3042097091674805\n",
            "Epoch #2. Batch Id 57/278  is having validation accuracy of 59.9676724137931\n",
            "Epoch #2. Batch Id 58/278  is having validation loss of 1.4885510206222534\n",
            "1.4475336074829102\n",
            "Epoch #2. Batch Id 58/278  is having validation accuracy of 59.95762711864407\n",
            "Epoch #2. Batch Id 59/278  is having validation loss of 1.4876203536987305\n",
            "1.432708978652954\n",
            "Epoch #2. Batch Id 59/278  is having validation accuracy of 60.052083333333336\n",
            "Epoch #2. Batch Id 60/278  is having validation loss of 1.4865936040878296\n",
            "1.4249898195266724\n",
            "Epoch #2. Batch Id 60/278  is having validation accuracy of 60.14344262295082\n",
            "Epoch #2. Batch Id 61/278  is having validation loss of 1.4888968467712402\n",
            "1.6293933391571045\n",
            "Epoch #2. Batch Id 61/278  is having validation accuracy of 60.03024193548387\n",
            "Epoch #2. Batch Id 62/278  is having validation loss of 1.4805326461791992\n",
            "0.9619529247283936\n",
            "Epoch #2. Batch Id 62/278  is having validation accuracy of 60.267857142857146\n",
            "Epoch #2. Batch Id 63/278  is having validation loss of 1.4840948581695557\n",
            "1.7085161209106445\n",
            "Epoch #2. Batch Id 63/278  is having validation accuracy of 60.15625\n",
            "Epoch #2. Batch Id 64/278  is having validation loss of 1.4902300834655762\n",
            "1.8828834295272827\n",
            "Epoch #2. Batch Id 64/278  is having validation accuracy of 60.14423076923077\n",
            "Epoch #2. Batch Id 65/278  is having validation loss of 1.4869366884231567\n",
            "1.2728679180145264\n",
            "Epoch #2. Batch Id 65/278  is having validation accuracy of 60.27462121212121\n",
            "Epoch #2. Batch Id 66/278  is having validation loss of 1.487054467201233\n",
            "1.4948290586471558\n",
            "Epoch #2. Batch Id 66/278  is having validation accuracy of 60.30783582089552\n",
            "Epoch #2. Batch Id 67/278  is having validation loss of 1.4891064167022705\n",
            "1.6265902519226074\n",
            "Epoch #2. Batch Id 67/278  is having validation accuracy of 60.20220588235294\n",
            "Epoch #2. Batch Id 68/278  is having validation loss of 1.4822050333023071\n",
            "1.0129079818725586\n",
            "Epoch #2. Batch Id 68/278  is having validation accuracy of 60.3713768115942\n",
            "Epoch #2. Batch Id 69/278  is having validation loss of 1.4799439907073975\n",
            "1.3239318132400513\n",
            "Epoch #2. Batch Id 69/278  is having validation accuracy of 60.49107142857143\n",
            "Epoch #2. Batch Id 70/278  is having validation loss of 1.4844353199005127\n",
            "1.7988245487213135\n",
            "Epoch #2. Batch Id 70/278  is having validation accuracy of 60.29929577464789\n",
            "Epoch #2. Batch Id 71/278  is having validation loss of 1.4772623777389526\n",
            "0.967985987663269\n",
            "Epoch #2. Batch Id 71/278  is having validation accuracy of 60.373263888888886\n",
            "Epoch #2. Batch Id 72/278  is having validation loss of 1.4809046983718872\n",
            "1.7431514263153076\n",
            "Epoch #2. Batch Id 72/278  is having validation accuracy of 60.14554794520548\n",
            "Epoch #2. Batch Id 73/278  is having validation loss of 1.4821473360061646\n",
            "1.5728641748428345\n",
            "Epoch #2. Batch Id 73/278  is having validation accuracy of 60.17736486486486\n",
            "Epoch #2. Batch Id 74/278  is having validation loss of 1.4862393140792847\n",
            "1.7890489101409912\n",
            "Epoch #2. Batch Id 74/278  is having validation accuracy of 60.125\n",
            "Epoch #2. Batch Id 75/278  is having validation loss of 1.4859189987182617\n",
            "1.4618982076644897\n",
            "Epoch #2. Batch Id 75/278  is having validation accuracy of 59.95065789473684\n",
            "Epoch #2. Batch Id 76/278  is having validation loss of 1.4884872436523438\n",
            "1.683676838874817\n",
            "Epoch #2. Batch Id 76/278  is having validation accuracy of 59.82142857142857\n",
            "Epoch #2. Batch Id 77/278  is having validation loss of 1.4844833612442017\n",
            "1.1761839389801025\n",
            "Epoch #2. Batch Id 77/278  is having validation accuracy of 60.056089743589745\n",
            "Epoch #2. Batch Id 78/278  is having validation loss of 1.4825806617736816\n",
            "1.3341679573059082\n",
            "Epoch #2. Batch Id 78/278  is having validation accuracy of 60.087025316455694\n",
            "Epoch #2. Batch Id 79/278  is having validation loss of 1.4816498756408691\n",
            "1.4081151485443115\n",
            "Epoch #2. Batch Id 79/278  is having validation accuracy of 59.9609375\n",
            "Epoch #2. Batch Id 80/278  is having validation loss of 1.4872819185256958\n",
            "1.9378448724746704\n",
            "Epoch #2. Batch Id 80/278  is having validation accuracy of 59.876543209876544\n",
            "Epoch #2. Batch Id 81/278  is having validation loss of 1.4885929822921753\n",
            "1.594785213470459\n",
            "Epoch #2. Batch Id 81/278  is having validation accuracy of 59.87042682926829\n",
            "Epoch #2. Batch Id 82/278  is having validation loss of 1.491707444190979\n",
            "1.7470930814743042\n",
            "Epoch #2. Batch Id 82/278  is having validation accuracy of 59.90210843373494\n",
            "Epoch #2. Batch Id 83/278  is having validation loss of 1.4898762702941895\n",
            "1.3378843069076538\n",
            "Epoch #2. Batch Id 83/278  is having validation accuracy of 59.970238095238095\n",
            "Epoch #2. Batch Id 84/278  is having validation loss of 1.4878607988357544\n",
            "1.3185606002807617\n",
            "Epoch #2. Batch Id 84/278  is having validation accuracy of 60.036764705882355\n",
            "Epoch #2. Batch Id 85/278  is having validation loss of 1.4856853485107422\n",
            "1.3007749319076538\n",
            "Epoch #2. Batch Id 85/278  is having validation accuracy of 60.10174418604651\n",
            "Epoch #2. Batch Id 86/278  is having validation loss of 1.4883055686950684\n",
            "1.7136398553848267\n",
            "Epoch #2. Batch Id 86/278  is having validation accuracy of 60.05747126436781\n",
            "Epoch #2. Batch Id 87/278  is having validation loss of 1.4863872528076172\n",
            "1.3194977045059204\n",
            "Epoch #2. Batch Id 87/278  is having validation accuracy of 60.12073863636363\n",
            "Epoch #2. Batch Id 88/278  is having validation loss of 1.4906591176986694\n",
            "1.8665835857391357\n",
            "Epoch #2. Batch Id 88/278  is having validation accuracy of 60.04213483146067\n",
            "Epoch #2. Batch Id 89/278  is having validation loss of 1.4862213134765625\n",
            "1.0912563800811768\n",
            "Epoch #2. Batch Id 89/278  is having validation accuracy of 60.173611111111114\n",
            "Epoch #2. Batch Id 90/278  is having validation loss of 1.4818817377090454\n",
            "1.0913164615631104\n",
            "Epoch #2. Batch Id 90/278  is having validation accuracy of 60.23351648351648\n",
            "Epoch #2. Batch Id 91/278  is having validation loss of 1.482516884803772\n",
            "1.540313720703125\n",
            "Epoch #2. Batch Id 91/278  is having validation accuracy of 60.25815217391305\n",
            "Epoch #2. Batch Id 92/278  is having validation loss of 1.4838981628417969\n",
            "1.610978126525879\n",
            "Epoch #2. Batch Id 92/278  is having validation accuracy of 60.181451612903224\n",
            "Epoch #2. Batch Id 93/278  is having validation loss of 1.482060432434082\n",
            "1.3111516237258911\n",
            "Epoch #2. Batch Id 93/278  is having validation accuracy of 60.305851063829785\n",
            "Epoch #2. Batch Id 94/278  is having validation loss of 1.4781392812728882\n",
            "1.1095460653305054\n",
            "Epoch #2. Batch Id 94/278  is having validation accuracy of 60.39473684210526\n",
            "Epoch #2. Batch Id 95/278  is having validation loss of 1.4755171537399292\n",
            "1.2264139652252197\n",
            "Epoch #2. Batch Id 95/278  is having validation accuracy of 60.416666666666664\n",
            "Epoch #2. Batch Id 96/278  is having validation loss of 1.4773730039596558\n",
            "1.655540108680725\n",
            "Epoch #2. Batch Id 96/278  is having validation accuracy of 60.34149484536083\n",
            "Epoch #2. Batch Id 97/278  is having validation loss of 1.4768511056900024\n",
            "1.4262275695800781\n",
            "Epoch #2. Batch Id 97/278  is having validation accuracy of 60.36352040816327\n",
            "Epoch #2. Batch Id 98/278  is having validation loss of 1.4776071310043335\n",
            "1.5516990423202515\n",
            "Epoch #2. Batch Id 98/278  is having validation accuracy of 60.29040404040404\n",
            "Epoch #2. Batch Id 99/278  is having validation loss of 1.475829005241394\n",
            "1.2997969388961792\n",
            "Epoch #2. Batch Id 99/278  is having validation accuracy of 60.40625\n",
            "Epoch #2. Batch Id 100/278  is having validation loss of 1.4753590822219849\n",
            "1.428366780281067\n",
            "Epoch #2. Batch Id 100/278  is having validation accuracy of 60.396039603960396\n",
            "Epoch #2. Batch Id 101/278  is having validation loss of 1.4752780199050903\n",
            "1.4670952558517456\n",
            "Epoch #2. Batch Id 101/278  is having validation accuracy of 60.416666666666664\n",
            "Epoch #2. Batch Id 102/278  is having validation loss of 1.4723795652389526\n",
            "1.1767336130142212\n",
            "Epoch #2. Batch Id 102/278  is having validation accuracy of 60.55825242718446\n",
            "Epoch #2. Batch Id 103/278  is having validation loss of 1.4743825197219849\n",
            "1.6806886196136475\n",
            "Epoch #2. Batch Id 103/278  is having validation accuracy of 60.45673076923077\n",
            "Epoch #2. Batch Id 104/278  is having validation loss of 1.472079873085022\n",
            "1.232602834701538\n",
            "Epoch #2. Batch Id 104/278  is having validation accuracy of 60.44642857142857\n",
            "Epoch #2. Batch Id 105/278  is having validation loss of 1.4686744213104248\n",
            "1.1111032962799072\n",
            "Epoch #2. Batch Id 105/278  is having validation accuracy of 60.465801886792455\n",
            "Epoch #2. Batch Id 106/278  is having validation loss of 1.465435266494751\n",
            "1.122079849243164\n",
            "Epoch #2. Batch Id 106/278  is having validation accuracy of 60.60163551401869\n",
            "Epoch #2. Batch Id 107/278  is having validation loss of 1.4609029293060303\n",
            "0.9759412407875061\n",
            "Epoch #2. Batch Id 107/278  is having validation accuracy of 60.763888888888886\n",
            "Epoch #2. Batch Id 108/278  is having validation loss of 1.4631428718566895\n",
            "1.705061912536621\n",
            "Epoch #2. Batch Id 108/278  is having validation accuracy of 60.6651376146789\n",
            "Epoch #2. Batch Id 109/278  is having validation loss of 1.4641755819320679\n",
            "1.5767345428466797\n",
            "Epoch #2. Batch Id 109/278  is having validation accuracy of 60.625\n",
            "Epoch #2. Batch Id 110/278  is having validation loss of 1.459671974182129\n",
            "0.9642685651779175\n",
            "Epoch #2. Batch Id 110/278  is having validation accuracy of 60.726351351351354\n",
            "Epoch #2. Batch Id 111/278  is having validation loss of 1.4563612937927246\n",
            "1.0888725519180298\n",
            "Epoch #2. Batch Id 111/278  is having validation accuracy of 60.853794642857146\n",
            "Epoch #2. Batch Id 112/278  is having validation loss of 1.4585713148117065\n",
            "1.7060960531234741\n",
            "Epoch #2. Batch Id 112/278  is having validation accuracy of 60.84070796460177\n",
            "Epoch #2. Batch Id 113/278  is having validation loss of 1.4588464498519897\n",
            "1.4899357557296753\n",
            "Epoch #2. Batch Id 113/278  is having validation accuracy of 60.77302631578947\n",
            "Epoch #2. Batch Id 114/278  is having validation loss of 1.4632097482681274\n",
            "1.9606273174285889\n",
            "Epoch #2. Batch Id 114/278  is having validation accuracy of 60.59782608695652\n",
            "Epoch #2. Batch Id 115/278  is having validation loss of 1.4665522575378418\n",
            "1.8509371280670166\n",
            "Epoch #2. Batch Id 115/278  is having validation accuracy of 60.533405172413794\n",
            "Epoch #2. Batch Id 116/278  is having validation loss of 1.4718133211135864\n",
            "2.0821006298065186\n",
            "Epoch #2. Batch Id 116/278  is having validation accuracy of 60.47008547008547\n",
            "Epoch #2. Batch Id 117/278  is having validation loss of 1.473737359046936\n",
            "1.6988545656204224\n",
            "Epoch #2. Batch Id 117/278  is having validation accuracy of 60.48728813559322\n",
            "Epoch #2. Batch Id 118/278  is having validation loss of 1.4733396768569946\n",
            "1.4264181852340698\n",
            "Epoch #2. Batch Id 118/278  is having validation accuracy of 60.58298319327731\n",
            "Epoch #2. Batch Id 119/278  is having validation loss of 1.473016619682312\n",
            "1.4345755577087402\n",
            "Epoch #2. Batch Id 119/278  is having validation accuracy of 60.598958333333336\n",
            "Epoch #2. Batch Id 120/278  is having validation loss of 1.4725538492202759\n",
            "1.4170234203338623\n",
            "Epoch #2. Batch Id 120/278  is having validation accuracy of 60.56301652892562\n",
            "Epoch #2. Batch Id 121/278  is having validation loss of 1.4733034372329712\n",
            "1.5640013217926025\n",
            "Epoch #2. Batch Id 121/278  is having validation accuracy of 60.502049180327866\n",
            "Epoch #2. Batch Id 122/278  is having validation loss of 1.4771467447280884\n",
            "1.9460262060165405\n",
            "Epoch #2. Batch Id 122/278  is having validation accuracy of 60.416666666666664\n",
            "Epoch #2. Batch Id 123/278  is having validation loss of 1.4802064895629883\n",
            "1.856550931930542\n",
            "Epoch #2. Batch Id 123/278  is having validation accuracy of 60.30745967741935\n",
            "Epoch #2. Batch Id 124/278  is having validation loss of 1.4791462421417236\n",
            "1.3476815223693848\n",
            "Epoch #2. Batch Id 124/278  is having validation accuracy of 60.325\n",
            "Epoch #2. Batch Id 125/278  is having validation loss of 1.4775148630142212\n",
            "1.2735955715179443\n",
            "Epoch #2. Batch Id 125/278  is having validation accuracy of 60.317460317460316\n",
            "Epoch #2. Batch Id 126/278  is having validation loss of 1.4747626781463623\n",
            "1.127991795539856\n",
            "Epoch #2. Batch Id 126/278  is having validation accuracy of 60.33464566929134\n",
            "Epoch #2. Batch Id 127/278  is having validation loss of 1.474228858947754\n",
            "1.4064315557479858\n",
            "Epoch #2. Batch Id 127/278  is having validation accuracy of 60.400390625\n",
            "Epoch #2. Batch Id 128/278  is having validation loss of 1.4719185829162598\n",
            "1.176206111907959\n",
            "Epoch #2. Batch Id 128/278  is having validation accuracy of 60.440891472868216\n",
            "Epoch #2. Batch Id 129/278  is having validation loss of 1.4718645811080933\n",
            "1.4649025201797485\n",
            "Epoch #2. Batch Id 129/278  is having validation accuracy of 60.48076923076923\n",
            "Epoch #2. Batch Id 130/278  is having validation loss of 1.4673998355865479\n",
            "0.8869809508323669\n",
            "Epoch #2. Batch Id 130/278  is having validation accuracy of 60.56774809160305\n",
            "Epoch #2. Batch Id 131/278  is having validation loss of 1.4683153629302979\n",
            "1.5882484912872314\n",
            "Epoch #2. Batch Id 131/278  is having validation accuracy of 60.558712121212125\n",
            "Epoch #2. Batch Id 132/278  is having validation loss of 1.468290090560913\n",
            "1.4649475812911987\n",
            "Epoch #2. Batch Id 132/278  is having validation accuracy of 60.596804511278194\n",
            "Epoch #2. Batch Id 133/278  is having validation loss of 1.4705591201782227\n",
            "1.7723402976989746\n",
            "Epoch #2. Batch Id 133/278  is having validation accuracy of 60.611007462686565\n",
            "Epoch #2. Batch Id 134/278  is having validation loss of 1.4736955165863037\n",
            "1.8939727544784546\n",
            "Epoch #2. Batch Id 134/278  is having validation accuracy of 60.532407407407405\n",
            "Epoch #2. Batch Id 135/278  is having validation loss of 1.4760736227035522\n",
            "1.7971141338348389\n",
            "Epoch #2. Batch Id 135/278  is having validation accuracy of 60.454963235294116\n",
            "Epoch #2. Batch Id 136/278  is having validation loss of 1.4761133193969727\n",
            "1.481506586074829\n",
            "Epoch #2. Batch Id 136/278  is having validation accuracy of 60.46989051094891\n",
            "Epoch #2. Batch Id 137/278  is having validation loss of 1.4766660928726196\n",
            "1.5523942708969116\n",
            "Epoch #2. Batch Id 137/278  is having validation accuracy of 60.416666666666664\n",
            "Epoch #2. Batch Id 138/278  is having validation loss of 1.4734338521957397\n",
            "1.027382493019104\n",
            "Epoch #2. Batch Id 138/278  is having validation accuracy of 60.49910071942446\n",
            "Epoch #2. Batch Id 139/278  is having validation loss of 1.4731864929199219\n",
            "1.4388000965118408\n",
            "Epoch #2. Batch Id 139/278  is having validation accuracy of 60.558035714285715\n",
            "Epoch #2. Batch Id 140/278  is having validation loss of 1.4741102457046509\n",
            "1.60343599319458\n",
            "Epoch #2. Batch Id 140/278  is having validation accuracy of 60.54964539007092\n",
            "Epoch #2. Batch Id 141/278  is having validation loss of 1.4723782539367676\n",
            "1.2281590700149536\n",
            "Epoch #2. Batch Id 141/278  is having validation accuracy of 60.541373239436616\n",
            "Epoch #2. Batch Id 142/278  is having validation loss of 1.4696409702301025\n",
            "1.080946922302246\n",
            "Epoch #2. Batch Id 142/278  is having validation accuracy of 60.62062937062937\n",
            "Epoch #2. Batch Id 143/278  is having validation loss of 1.471287727355957\n",
            "1.7067676782608032\n",
            "Epoch #2. Batch Id 143/278  is having validation accuracy of 60.546875\n",
            "Epoch #2. Batch Id 144/278  is having validation loss of 1.4738593101501465\n",
            "1.84415864944458\n",
            "Epoch #2. Batch Id 144/278  is having validation accuracy of 60.49568965517241\n",
            "Epoch #2. Batch Id 145/278  is having validation loss of 1.4752624034881592\n",
            "1.6787077188491821\n",
            "Epoch #2. Batch Id 145/278  is having validation accuracy of 60.4666095890411\n",
            "Epoch #2. Batch Id 146/278  is having validation loss of 1.4739702939987183\n",
            "1.2853144407272339\n",
            "Epoch #2. Batch Id 146/278  is having validation accuracy of 60.45918367346939\n",
            "Epoch #2. Batch Id 147/278  is having validation loss of 1.473768711090088\n",
            "1.4441413879394531\n",
            "Epoch #2. Batch Id 147/278  is having validation accuracy of 60.5152027027027\n",
            "Epoch #2. Batch Id 148/278  is having validation loss of 1.47553551197052\n",
            "1.7370213270187378\n",
            "Epoch #2. Batch Id 148/278  is having validation accuracy of 60.381711409395976\n",
            "Epoch #2. Batch Id 149/278  is having validation loss of 1.4762747287750244\n",
            "1.5864237546920776\n",
            "Epoch #2. Batch Id 149/278  is having validation accuracy of 60.354166666666664\n",
            "Epoch #2. Batch Id 150/278  is having validation loss of 1.4776114225387573\n",
            "1.678116798400879\n",
            "Epoch #2. Batch Id 150/278  is having validation accuracy of 60.347682119205295\n",
            "Epoch #2. Batch Id 151/278  is having validation loss of 1.478429913520813\n",
            "1.6020208597183228\n",
            "Epoch #2. Batch Id 151/278  is having validation accuracy of 60.30016447368421\n",
            "Epoch #2. Batch Id 152/278  is having validation loss of 1.4788240194320679\n",
            "1.538732886314392\n",
            "Epoch #2. Batch Id 152/278  is having validation accuracy of 60.33496732026144\n",
            "Epoch #2. Batch Id 153/278  is having validation loss of 1.4772179126739502\n",
            "1.2314904928207397\n",
            "Epoch #2. Batch Id 153/278  is having validation accuracy of 60.4099025974026\n",
            "Epoch #2. Batch Id 154/278  is having validation loss of 1.4796644449234009\n",
            "1.856431007385254\n",
            "Epoch #2. Batch Id 154/278  is having validation accuracy of 60.32258064516129\n",
            "Epoch #2. Batch Id 155/278  is having validation loss of 1.4789730310440063\n",
            "1.3717995882034302\n",
            "Epoch #2. Batch Id 155/278  is having validation accuracy of 60.37660256410256\n",
            "Epoch #2. Batch Id 156/278  is having validation loss of 1.480438470840454\n",
            "1.709040641784668\n",
            "Epoch #2. Batch Id 156/278  is having validation accuracy of 60.310509554140125\n",
            "Epoch #2. Batch Id 157/278  is having validation loss of 1.4806162118911743\n",
            "1.508522629737854\n",
            "Epoch #2. Batch Id 157/278  is having validation accuracy of 60.30458860759494\n",
            "Epoch #2. Batch Id 158/278  is having validation loss of 1.481645107269287\n",
            "1.644204020500183\n",
            "Epoch #2. Batch Id 158/278  is having validation accuracy of 60.318396226415096\n",
            "Epoch #2. Batch Id 159/278  is having validation loss of 1.482799768447876\n",
            "1.6663882732391357\n",
            "Epoch #2. Batch Id 159/278  is having validation accuracy of 60.29296875\n",
            "Epoch #2. Batch Id 160/278  is having validation loss of 1.4841727018356323\n",
            "1.7038357257843018\n",
            "Epoch #2. Batch Id 160/278  is having validation accuracy of 60.287267080745345\n",
            "Epoch #2. Batch Id 161/278  is having validation loss of 1.486273169517517\n",
            "1.8244446516036987\n",
            "Epoch #2. Batch Id 161/278  is having validation accuracy of 60.223765432098766\n",
            "Epoch #2. Batch Id 162/278  is having validation loss of 1.485115647315979\n",
            "1.2976067066192627\n",
            "Epoch #2. Batch Id 162/278  is having validation accuracy of 60.237730061349694\n",
            "Epoch #2. Batch Id 163/278  is having validation loss of 1.4835280179977417\n",
            "1.2247360944747925\n",
            "Epoch #2. Batch Id 163/278  is having validation accuracy of 60.30868902439025\n",
            "Epoch #2. Batch Id 164/278  is having validation loss of 1.486295461654663\n",
            "1.9401639699935913\n",
            "Epoch #2. Batch Id 164/278  is having validation accuracy of 60.246212121212125\n",
            "Epoch #2. Batch Id 165/278  is having validation loss of 1.4844046831130981\n",
            "1.1724210977554321\n",
            "Epoch #2. Batch Id 165/278  is having validation accuracy of 60.335090361445786\n",
            "Epoch #2. Batch Id 166/278  is having validation loss of 1.4820753335952759\n",
            "1.0953965187072754\n",
            "Epoch #2. Batch Id 166/278  is having validation accuracy of 60.441616766467064\n",
            "Epoch #2. Batch Id 167/278  is having validation loss of 1.4812557697296143\n",
            "1.3443882465362549\n",
            "Epoch #2. Batch Id 167/278  is having validation accuracy of 60.47247023809524\n",
            "Epoch #2. Batch Id 168/278  is having validation loss of 1.4781502485275269\n",
            "0.9564194679260254\n",
            "Epoch #2. Batch Id 168/278  is having validation accuracy of 60.539940828402365\n",
            "Epoch #2. Batch Id 169/278  is having validation loss of 1.4772427082061768\n",
            "1.323870062828064\n",
            "Epoch #2. Batch Id 169/278  is having validation accuracy of 60.625\n",
            "Epoch #2. Batch Id 170/278  is having validation loss of 1.4797197580337524\n",
            "1.900816798210144\n",
            "Epoch #2. Batch Id 170/278  is having validation accuracy of 60.61769005847953\n",
            "Epoch #2. Batch Id 171/278  is having validation loss of 1.4817124605178833\n",
            "1.8224717378616333\n",
            "Epoch #2. Batch Id 171/278  is having validation accuracy of 60.57412790697674\n",
            "Epoch #2. Batch Id 172/278  is having validation loss of 1.479058861732483\n",
            "1.022632360458374\n",
            "Epoch #2. Batch Id 172/278  is having validation accuracy of 60.63945086705202\n",
            "Epoch #2. Batch Id 173/278  is having validation loss of 1.477994680404663\n",
            "1.293886423110962\n",
            "Epoch #2. Batch Id 173/278  is having validation accuracy of 60.632183908045974\n",
            "Epoch #2. Batch Id 174/278  is having validation loss of 1.4795135259628296\n",
            "1.7437844276428223\n",
            "Epoch #2. Batch Id 174/278  is having validation accuracy of 60.607142857142854\n",
            "Epoch #2. Batch Id 175/278  is having validation loss of 1.4792506694793701\n",
            "1.4332417249679565\n",
            "Epoch #2. Batch Id 175/278  is having validation accuracy of 60.60014204545455\n",
            "Epoch #2. Batch Id 176/278  is having validation loss of 1.47817063331604\n",
            "1.2880752086639404\n",
            "Epoch #2. Batch Id 176/278  is having validation accuracy of 60.61087570621469\n",
            "Epoch #2. Batch Id 177/278  is having validation loss of 1.4796092510223389\n",
            "1.7342528104782104\n",
            "Epoch #2. Batch Id 177/278  is having validation accuracy of 60.62148876404494\n",
            "Epoch #2. Batch Id 178/278  is having validation loss of 1.483818769454956\n",
            "2.2331221103668213\n",
            "Epoch #2. Batch Id 178/278  is having validation accuracy of 60.49231843575419\n",
            "Epoch #2. Batch Id 179/278  is having validation loss of 1.4865062236785889\n",
            "1.967557668685913\n",
            "Epoch #2. Batch Id 179/278  is having validation accuracy of 60.39930555555556\n",
            "Epoch #2. Batch Id 180/278  is having validation loss of 1.4877123832702637\n",
            "1.7048256397247314\n",
            "Epoch #2. Batch Id 180/278  is having validation accuracy of 60.35911602209945\n",
            "Epoch #2. Batch Id 181/278  is having validation loss of 1.4870953559875488\n",
            "1.375408411026001\n",
            "Epoch #2. Batch Id 181/278  is having validation accuracy of 60.42239010989011\n",
            "Epoch #2. Batch Id 182/278  is having validation loss of 1.4871721267700195\n",
            "1.5011402368545532\n",
            "Epoch #2. Batch Id 182/278  is having validation accuracy of 60.416666666666664\n",
            "Epoch #2. Batch Id 183/278  is having validation loss of 1.48966646194458\n",
            "1.9461334943771362\n",
            "Epoch #2. Batch Id 183/278  is having validation accuracy of 60.360054347826086\n",
            "Epoch #2. Batch Id 184/278  is having validation loss of 1.48935866355896\n",
            "1.4327205419540405\n",
            "Epoch #2. Batch Id 184/278  is having validation accuracy of 60.33783783783784\n",
            "Epoch #2. Batch Id 185/278  is having validation loss of 1.4869849681854248\n",
            "1.0478497743606567\n",
            "Epoch #2. Batch Id 185/278  is having validation accuracy of 60.3494623655914\n",
            "Epoch #2. Batch Id 186/278  is having validation loss of 1.485534429550171\n",
            "1.2157353162765503\n",
            "Epoch #2. Batch Id 186/278  is having validation accuracy of 60.394385026737964\n",
            "Epoch #2. Batch Id 187/278  is having validation loss of 1.48432195186615\n",
            "1.257580041885376\n",
            "Epoch #2. Batch Id 187/278  is having validation accuracy of 60.43882978723404\n",
            "Epoch #2. Batch Id 188/278  is having validation loss of 1.486664056777954\n",
            "1.926970362663269\n",
            "Epoch #2. Batch Id 188/278  is having validation accuracy of 60.44973544973545\n",
            "Epoch #2. Batch Id 189/278  is having validation loss of 1.485024333000183\n",
            "1.1751151084899902\n",
            "Epoch #2. Batch Id 189/278  is having validation accuracy of 60.46052631578947\n",
            "Epoch #2. Batch Id 190/278  is having validation loss of 1.4839798212051392\n",
            "1.2855321168899536\n",
            "Epoch #2. Batch Id 190/278  is having validation accuracy of 60.45484293193717\n",
            "Epoch #2. Batch Id 191/278  is having validation loss of 1.486104130744934\n",
            "1.8918579816818237\n",
            "Epoch #2. Batch Id 191/278  is having validation accuracy of 60.416666666666664\n",
            "Epoch #2. Batch Id 192/278  is having validation loss of 1.4869698286056519\n",
            "1.6531752347946167\n",
            "Epoch #2. Batch Id 192/278  is having validation accuracy of 60.37888601036269\n",
            "Epoch #2. Batch Id 193/278  is having validation loss of 1.4878334999084473\n",
            "1.6545182466506958\n",
            "Epoch #2. Batch Id 193/278  is having validation accuracy of 60.373711340206185\n",
            "Epoch #2. Batch Id 194/278  is having validation loss of 1.4874929189682007\n",
            "1.421417474746704\n",
            "Epoch #2. Batch Id 194/278  is having validation accuracy of 60.33653846153846\n",
            "Epoch #2. Batch Id 195/278  is having validation loss of 1.487027645111084\n",
            "1.3962993621826172\n",
            "Epoch #2. Batch Id 195/278  is having validation accuracy of 60.29974489795919\n",
            "Epoch #2. Batch Id 196/278  is having validation loss of 1.486641764640808\n",
            "1.411001443862915\n",
            "Epoch #2. Batch Id 196/278  is having validation accuracy of 60.31091370558376\n",
            "Epoch #2. Batch Id 197/278  is having validation loss of 1.4871090650558472\n",
            "1.5791648626327515\n",
            "Epoch #2. Batch Id 197/278  is having validation accuracy of 60.29040404040404\n",
            "Epoch #2. Batch Id 198/278  is having validation loss of 1.4880846738815308\n",
            "1.6812489032745361\n",
            "Epoch #2. Batch Id 198/278  is having validation accuracy of 60.254396984924625\n",
            "Epoch #2. Batch Id 199/278  is having validation loss of 1.4870578050613403\n",
            "1.2827043533325195\n",
            "Epoch #2. Batch Id 199/278  is having validation accuracy of 60.328125\n",
            "Epoch #2. Batch Id 200/278  is having validation loss of 1.488520860671997\n",
            "1.7811379432678223\n",
            "Epoch #2. Batch Id 200/278  is having validation accuracy of 60.29228855721393\n",
            "Epoch #2. Batch Id 201/278  is having validation loss of 1.4878535270690918\n",
            "1.3537145853042603\n",
            "Epoch #2. Batch Id 201/278  is having validation accuracy of 60.34962871287129\n",
            "Epoch #2. Batch Id 202/278  is having validation loss of 1.4849696159362793\n",
            "0.9024213552474976\n",
            "Epoch #2. Batch Id 202/278  is having validation accuracy of 60.42179802955665\n",
            "Epoch #2. Batch Id 203/278  is having validation loss of 1.4853156805038452\n",
            "1.5555652379989624\n",
            "Epoch #2. Batch Id 203/278  is having validation accuracy of 60.35539215686274\n",
            "Epoch #2. Batch Id 204/278  is having validation loss of 1.4866864681243896\n",
            "1.7663180828094482\n",
            "Epoch #2. Batch Id 204/278  is having validation accuracy of 60.30487804878049\n",
            "Epoch #2. Batch Id 205/278  is having validation loss of 1.4863520860671997\n",
            "1.4177929162979126\n",
            "Epoch #2. Batch Id 205/278  is having validation accuracy of 60.33070388349515\n",
            "Epoch #2. Batch Id 206/278  is having validation loss of 1.4854328632354736\n",
            "1.2960805892944336\n",
            "Epoch #2. Batch Id 206/278  is having validation accuracy of 60.341183574879224\n",
            "Epoch #2. Batch Id 207/278  is having validation loss of 1.4853204488754272\n",
            "1.462054967880249\n",
            "Epoch #2. Batch Id 207/278  is having validation accuracy of 60.32151442307692\n",
            "Epoch #2. Batch Id 208/278  is having validation loss of 1.4855446815490723\n",
            "1.5321972370147705\n",
            "Epoch #2. Batch Id 208/278  is having validation accuracy of 60.36184210526316\n",
            "Epoch #2. Batch Id 209/278  is having validation loss of 1.4849631786346436\n",
            "1.363417625427246\n",
            "Epoch #2. Batch Id 209/278  is having validation accuracy of 60.37202380952381\n",
            "Epoch #2. Batch Id 210/278  is having validation loss of 1.4844683408737183\n",
            "1.3805550336837769\n",
            "Epoch #2. Batch Id 210/278  is having validation accuracy of 60.39691943127962\n",
            "Epoch #2. Batch Id 211/278  is having validation loss of 1.483421802520752\n",
            "1.2625925540924072\n",
            "Epoch #2. Batch Id 211/278  is having validation accuracy of 60.392099056603776\n",
            "Epoch #2. Batch Id 212/278  is having validation loss of 1.4837262630462646\n",
            "1.5482627153396606\n",
            "Epoch #2. Batch Id 212/278  is having validation accuracy of 60.38732394366197\n",
            "Epoch #2. Batch Id 213/278  is having validation loss of 1.4840389490127563\n",
            "1.5506407022476196\n",
            "Epoch #2. Batch Id 213/278  is having validation accuracy of 60.35338785046729\n",
            "Epoch #2. Batch Id 214/278  is having validation loss of 1.4840389490127563\n",
            "1.484047770500183\n",
            "Epoch #2. Batch Id 214/278  is having validation accuracy of 60.2906976744186\n",
            "Epoch #2. Batch Id 215/278  is having validation loss of 1.4867061376571655\n",
            "2.060159683227539\n",
            "Epoch #2. Batch Id 215/278  is having validation accuracy of 60.214120370370374\n",
            "Epoch #2. Batch Id 216/278  is having validation loss of 1.486796498298645\n",
            "1.5063115358352661\n",
            "Epoch #2. Batch Id 216/278  is having validation accuracy of 60.210253456221196\n",
            "Epoch #2. Batch Id 217/278  is having validation loss of 1.4858776330947876\n",
            "1.286484956741333\n",
            "Epoch #2. Batch Id 217/278  is having validation accuracy of 60.26376146788991\n",
            "Epoch #2. Batch Id 218/278  is having validation loss of 1.485251784324646\n",
            "1.348829746246338\n",
            "Epoch #2. Batch Id 218/278  is having validation accuracy of 60.28824200913242\n",
            "Epoch #2. Batch Id 219/278  is having validation loss of 1.4844491481781006\n",
            "1.3086681365966797\n",
            "Epoch #2. Batch Id 219/278  is having validation accuracy of 60.32670454545455\n",
            "Epoch #2. Batch Id 220/278  is having validation loss of 1.48544180393219\n",
            "1.7038177251815796\n",
            "Epoch #2. Batch Id 220/278  is having validation accuracy of 60.30825791855204\n",
            "Epoch #2. Batch Id 221/278  is having validation loss of 1.485901951789856\n",
            "1.5875962972640991\n",
            "Epoch #2. Batch Id 221/278  is having validation accuracy of 60.304054054054056\n",
            "Epoch #2. Batch Id 222/278  is having validation loss of 1.487342357635498\n",
            "1.8071024417877197\n",
            "Epoch #2. Batch Id 222/278  is having validation accuracy of 60.285874439461885\n",
            "Epoch #2. Batch Id 223/278  is having validation loss of 1.4880452156066895\n",
            "1.6447710990905762\n",
            "Epoch #2. Batch Id 223/278  is having validation accuracy of 60.239955357142854\n",
            "Epoch #2. Batch Id 224/278  is having validation loss of 1.4891496896743774\n",
            "1.7365548610687256\n",
            "Epoch #2. Batch Id 224/278  is having validation accuracy of 60.22222222222222\n",
            "Epoch #2. Batch Id 225/278  is having validation loss of 1.48954439163208\n",
            "1.5783568620681763\n",
            "Epoch #2. Batch Id 225/278  is having validation accuracy of 60.1908185840708\n",
            "Epoch #2. Batch Id 226/278  is having validation loss of 1.4888765811920166\n",
            "1.3379608392715454\n",
            "Epoch #2. Batch Id 226/278  is having validation accuracy of 60.2147577092511\n",
            "Epoch #2. Batch Id 227/278  is having validation loss of 1.490508794784546\n",
            "1.8610345125198364\n",
            "Epoch #2. Batch Id 227/278  is having validation accuracy of 60.19736842105263\n",
            "Epoch #2. Batch Id 228/278  is having validation loss of 1.4930025339126587\n",
            "2.061570405960083\n",
            "Epoch #2. Batch Id 228/278  is having validation accuracy of 60.16648471615721\n",
            "Epoch #2. Batch Id 229/278  is having validation loss of 1.4925403594970703\n",
            "1.3867019414901733\n",
            "Epoch #2. Batch Id 229/278  is having validation accuracy of 60.14945652173913\n",
            "Epoch #2. Batch Id 230/278  is having validation loss of 1.4932297468185425\n",
            "1.6517970561981201\n",
            "Epoch #2. Batch Id 230/278  is having validation accuracy of 60.13257575757576\n",
            "Epoch #2. Batch Id 231/278  is having validation loss of 1.4949822425842285\n",
            "1.8998132944107056\n",
            "Epoch #2. Batch Id 231/278  is having validation accuracy of 60.061961206896555\n",
            "Epoch #2. Batch Id 232/278  is having validation loss of 1.4964399337768555\n",
            "1.834623098373413\n",
            "Epoch #2. Batch Id 232/278  is having validation accuracy of 60.00536480686695\n",
            "Epoch #2. Batch Id 233/278  is having validation loss of 1.4956098794937134\n",
            "1.3022079467773438\n",
            "Epoch #2. Batch Id 233/278  is having validation accuracy of 60.02938034188034\n",
            "Epoch #2. Batch Id 234/278  is having validation loss of 1.494240641593933\n",
            "1.1738475561141968\n",
            "Epoch #2. Batch Id 234/278  is having validation accuracy of 60.03989361702128\n",
            "Epoch #2. Batch Id 235/278  is having validation loss of 1.496096134185791\n",
            "1.9321494102478027\n",
            "Epoch #2. Batch Id 235/278  is having validation accuracy of 60.01059322033898\n",
            "Epoch #2. Batch Id 236/278  is having validation loss of 1.4953889846801758\n",
            "1.3285071849822998\n",
            "Epoch #2. Batch Id 236/278  is having validation accuracy of 60.0210970464135\n",
            "Epoch #2. Batch Id 237/278  is having validation loss of 1.4954808950424194\n",
            "1.5172638893127441\n",
            "Epoch #2. Batch Id 237/278  is having validation accuracy of 60.03151260504202\n",
            "Epoch #2. Batch Id 238/278  is having validation loss of 1.4943914413452148\n",
            "1.2350962162017822\n",
            "Epoch #2. Batch Id 238/278  is having validation accuracy of 60.08106694560669\n",
            "Epoch #2. Batch Id 239/278  is having validation loss of 1.4972773790359497\n",
            "2.1870157718658447\n",
            "Epoch #2. Batch Id 239/278  is having validation accuracy of 59.9609375\n",
            "Epoch #2. Batch Id 240/278  is having validation loss of 1.4962284564971924\n",
            "1.2444947957992554\n",
            "Epoch #2. Batch Id 240/278  is having validation accuracy of 59.9844398340249\n",
            "Epoch #2. Batch Id 241/278  is having validation loss of 1.4967598915100098\n",
            "1.6248441934585571\n",
            "Epoch #2. Batch Id 241/278  is having validation accuracy of 59.9948347107438\n",
            "Epoch #2. Batch Id 242/278  is having validation loss of 1.496307611465454\n",
            "1.386842131614685\n",
            "Epoch #2. Batch Id 242/278  is having validation accuracy of 60.00514403292181\n",
            "Epoch #2. Batch Id 243/278  is having validation loss of 1.4956508874893188\n",
            "1.336072564125061\n",
            "Epoch #2. Batch Id 243/278  is having validation accuracy of 60.01536885245902\n",
            "Epoch #2. Batch Id 244/278  is having validation loss of 1.4960756301879883\n",
            "1.5997141599655151\n",
            "Epoch #2. Batch Id 244/278  is having validation accuracy of 59.98724489795919\n",
            "Epoch #2. Batch Id 245/278  is having validation loss of 1.4980883598327637\n",
            "1.9912021160125732\n",
            "Epoch #2. Batch Id 245/278  is having validation accuracy of 59.921239837398375\n",
            "Epoch #2. Batch Id 246/278  is having validation loss of 1.5000126361846924\n",
            "1.9733707904815674\n",
            "Epoch #2. Batch Id 246/278  is having validation accuracy of 59.881072874493924\n",
            "Epoch #2. Batch Id 247/278  is having validation loss of 1.5012348890304565\n",
            "1.8031336069107056\n",
            "Epoch #2. Batch Id 247/278  is having validation accuracy of 59.828629032258064\n",
            "Epoch #2. Batch Id 248/278  is having validation loss of 1.5016905069351196\n",
            "1.614678978919983\n",
            "Epoch #2. Batch Id 248/278  is having validation accuracy of 59.851907630522085\n",
            "Epoch #2. Batch Id 249/278  is having validation loss of 1.5013703107833862\n",
            "1.4216516017913818\n",
            "Epoch #2. Batch Id 249/278  is having validation accuracy of 59.875\n",
            "Epoch #2. Batch Id 250/278  is having validation loss of 1.5013550519943237\n",
            "1.4975473880767822\n",
            "Epoch #2. Batch Id 250/278  is having validation accuracy of 59.8605577689243\n",
            "Epoch #2. Batch Id 251/278  is having validation loss of 1.5034737586975098\n",
            "2.0352635383605957\n",
            "Epoch #2. Batch Id 251/278  is having validation accuracy of 59.82142857142857\n",
            "Epoch #2. Batch Id 252/278  is having validation loss of 1.503731608390808\n",
            "1.568699598312378\n",
            "Epoch #2. Batch Id 252/278  is having validation accuracy of 59.819664031620555\n",
            "Epoch #2. Batch Id 253/278  is having validation loss of 1.503818392753601\n",
            "1.5257893800735474\n",
            "Epoch #2. Batch Id 253/278  is having validation accuracy of 59.805610236220474\n",
            "Epoch #2. Batch Id 254/278  is having validation loss of 1.5029957294464111\n",
            "1.2940350770950317\n",
            "Epoch #2. Batch Id 254/278  is having validation accuracy of 59.82843137254902\n",
            "Epoch #2. Batch Id 255/278  is having validation loss of 1.5022557973861694\n",
            "1.3135606050491333\n",
            "Epoch #2. Batch Id 255/278  is having validation accuracy of 59.85107421875\n",
            "Epoch #2. Batch Id 256/278  is having validation loss of 1.5018799304962158\n",
            "1.4056634902954102\n",
            "Epoch #2. Batch Id 256/278  is having validation accuracy of 59.87354085603113\n",
            "Epoch #2. Batch Id 257/278  is having validation loss of 1.5016647577285767\n",
            "1.4463684558868408\n",
            "Epoch #2. Batch Id 257/278  is having validation accuracy of 59.85949612403101\n",
            "Epoch #2. Batch Id 258/278  is having validation loss of 1.5022798776626587\n",
            "1.6609914302825928\n",
            "Epoch #2. Batch Id 258/278  is having validation accuracy of 59.83349420849421\n",
            "Epoch #2. Batch Id 259/278  is having validation loss of 1.5014296770095825\n",
            "1.2812203168869019\n",
            "Epoch #2. Batch Id 259/278  is having validation accuracy of 59.84375\n",
            "Epoch #2. Batch Id 260/278  is having validation loss of 1.4992480278015137\n",
            "0.9320248365402222\n",
            "Epoch #2. Batch Id 260/278  is having validation accuracy of 59.877873563218394\n",
            "Epoch #2. Batch Id 261/278  is having validation loss of 1.4980109930038452\n",
            "1.1751551628112793\n",
            "Epoch #2. Batch Id 261/278  is having validation accuracy of 59.911736641221374\n",
            "Epoch #2. Batch Id 262/278  is having validation loss of 1.4997037649154663\n",
            "1.9432061910629272\n",
            "Epoch #2. Batch Id 262/278  is having validation accuracy of 59.874049429657795\n",
            "Epoch #2. Batch Id 263/278  is having validation loss of 1.5000128746032715\n",
            "1.5813218355178833\n",
            "Epoch #2. Batch Id 263/278  is having validation accuracy of 59.895833333333336\n",
            "Epoch #2. Batch Id 264/278  is having validation loss of 1.4988932609558105\n",
            "1.2033226490020752\n",
            "Epoch #2. Batch Id 264/278  is having validation accuracy of 59.905660377358494\n",
            "Epoch #2. Batch Id 265/278  is having validation loss of 1.4994148015975952\n",
            "1.637616753578186\n",
            "Epoch #2. Batch Id 265/278  is having validation accuracy of 59.891917293233085\n",
            "Epoch #2. Batch Id 266/278  is having validation loss of 1.498257040977478\n",
            "1.1903072595596313\n",
            "Epoch #2. Batch Id 266/278  is having validation accuracy of 59.936797752808985\n",
            "Epoch #2. Batch Id 267/278  is having validation loss of 1.4968069791793823\n",
            "1.1096256971359253\n",
            "Epoch #2. Batch Id 267/278  is having validation accuracy of 59.9696828358209\n",
            "Epoch #2. Batch Id 268/278  is having validation loss of 1.4950098991394043\n",
            "1.0133955478668213\n",
            "Epoch #2. Batch Id 268/278  is having validation accuracy of 60.02555762081784\n",
            "Epoch #2. Batch Id 269/278  is having validation loss of 1.493178129196167\n",
            "1.0004417896270752\n",
            "Epoch #2. Batch Id 269/278  is having validation accuracy of 60.06944444444444\n",
            "Epoch #2. Batch Id 270/278  is having validation loss of 1.493212342262268\n",
            "1.5024378299713135\n",
            "Epoch #2. Batch Id 270/278  is having validation accuracy of 60.066881918819185\n",
            "Epoch #2. Batch Id 271/278  is having validation loss of 1.4936567544937134\n",
            "1.6141011714935303\n",
            "Epoch #2. Batch Id 271/278  is having validation accuracy of 60.075827205882355\n",
            "Epoch #2. Batch Id 272/278  is having validation loss of 1.494701623916626\n",
            "1.7789098024368286\n",
            "Epoch #2. Batch Id 272/278  is having validation accuracy of 60.07326007326007\n",
            "Epoch #2. Batch Id 273/278  is having validation loss of 1.4956902265548706\n",
            "1.7655949592590332\n",
            "Epoch #2. Batch Id 273/278  is having validation accuracy of 60.03649635036496\n",
            "Epoch #2. Batch Id 274/278  is having validation loss of 1.4961165189743042\n",
            "1.612923502922058\n",
            "Epoch #2. Batch Id 274/278  is having validation accuracy of 60.03409090909091\n",
            "Epoch #2. Batch Id 275/278  is having validation loss of 1.4970226287841797\n",
            "1.7461954355239868\n",
            "Epoch #2. Batch Id 275/278  is having validation accuracy of 60.031702898550726\n",
            "Epoch #2. Batch Id 276/278  is having validation loss of 1.4963964223861694\n",
            "1.3235605955123901\n",
            "Epoch #2. Batch Id 276/278  is having validation accuracy of 60.0293321299639\n",
            "Epoch #2. Batch Id 277/278  is having validation loss of 1.4916489124298096\n",
            "0.17657770216464996\n",
            "Epoch #2. Batch Id 277/278  is having validation accuracy of 60.038348748026166\n",
            "Эпоха #2 train_loss: 1.7288191884290427e-05, val_loss: 0.000168243728694506\n",
            "Потрачено 27.9 минут на 2 эпоху\n",
            "Batch Id 0/2438 is having training loss of 2.066753387451172\n",
            "2.066753387451172\n",
            "Epoch #3. Accuracy on batch 0/2438  on Training is 46.875\n",
            "Epoch #3. Accuracy on batch 1/2438  on Training is 51.5625\n",
            "Epoch #3. Accuracy on batch 2/2438  on Training is 58.333333333333336\n",
            "Epoch #3. Accuracy on batch 3/2438  on Training is 62.5\n",
            "Epoch #3. Accuracy on batch 4/2438  on Training is 59.375\n",
            "Epoch #3. Accuracy on batch 5/2438  on Training is 60.416666666666664\n",
            "Epoch #3. Accuracy on batch 6/2438  on Training is 62.94642857142857\n",
            "Epoch #3. Accuracy on batch 7/2438  on Training is 66.40625\n",
            "Epoch #3. Accuracy on batch 8/2438  on Training is 66.66666666666667\n",
            "Epoch #3. Accuracy on batch 9/2438  on Training is 66.875\n",
            "Epoch #3. Accuracy on batch 10/2438  on Training is 65.9090909090909\n",
            "Epoch #3. Accuracy on batch 11/2438  on Training is 64.32291666666667\n",
            "Epoch #3. Accuracy on batch 12/2438  on Training is 65.625\n",
            "Epoch #3. Accuracy on batch 13/2438  on Training is 66.07142857142857\n",
            "Epoch #3. Accuracy on batch 14/2438  on Training is 66.66666666666667\n",
            "Epoch #3. Accuracy on batch 15/2438  on Training is 66.6015625\n",
            "Epoch #3. Accuracy on batch 16/2438  on Training is 65.625\n",
            "Epoch #3. Accuracy on batch 17/2438  on Training is 66.31944444444444\n",
            "Epoch #3. Accuracy on batch 18/2438  on Training is 65.78947368421052\n",
            "Epoch #3. Accuracy on batch 19/2438  on Training is 66.40625\n",
            "Batch Id 20/2438 is having training loss of 1.26431143283844\n",
            "1.2367722988128662\n",
            "Epoch #3. Accuracy on batch 20/2438  on Training is 66.2202380952381\n",
            "Epoch #3. Accuracy on batch 21/2438  on Training is 65.9090909090909\n",
            "Epoch #3. Accuracy on batch 22/2438  on Training is 65.89673913043478\n",
            "Epoch #3. Accuracy on batch 23/2438  on Training is 66.015625\n",
            "Epoch #3. Accuracy on batch 24/2438  on Training is 66.375\n",
            "Epoch #3. Accuracy on batch 25/2438  on Training is 65.7451923076923\n",
            "Epoch #3. Accuracy on batch 26/2438  on Training is 66.31944444444444\n",
            "Epoch #3. Accuracy on batch 27/2438  on Training is 66.18303571428571\n",
            "Epoch #3. Accuracy on batch 28/2438  on Training is 66.70258620689656\n",
            "Epoch #3. Accuracy on batch 29/2438  on Training is 66.25\n",
            "Epoch #3. Accuracy on batch 30/2438  on Training is 66.02822580645162\n",
            "Epoch #3. Accuracy on batch 31/2438  on Training is 66.015625\n",
            "Epoch #3. Accuracy on batch 32/2438  on Training is 65.9090909090909\n",
            "Epoch #3. Accuracy on batch 33/2438  on Training is 65.80882352941177\n",
            "Epoch #3. Accuracy on batch 34/2438  on Training is 65.98214285714286\n",
            "Epoch #3. Accuracy on batch 35/2438  on Training is 65.79861111111111\n",
            "Epoch #3. Accuracy on batch 36/2438  on Training is 65.70945945945945\n",
            "Epoch #3. Accuracy on batch 37/2438  on Training is 65.625\n",
            "Epoch #3. Accuracy on batch 38/2438  on Training is 65.7051282051282\n",
            "Epoch #3. Accuracy on batch 39/2438  on Training is 65.546875\n",
            "Batch Id 40/2438 is having training loss of 1.3133158683776855\n",
            "1.411226511001587\n",
            "Epoch #3. Accuracy on batch 40/2438  on Training is 65.54878048780488\n",
            "Epoch #3. Accuracy on batch 41/2438  on Training is 65.77380952380952\n",
            "Epoch #3. Accuracy on batch 42/2438  on Training is 65.98837209302326\n",
            "Epoch #3. Accuracy on batch 43/2438  on Training is 66.05113636363636\n",
            "Epoch #3. Accuracy on batch 44/2438  on Training is 65.97222222222223\n",
            "Epoch #3. Accuracy on batch 45/2438  on Training is 66.23641304347827\n",
            "Epoch #3. Accuracy on batch 46/2438  on Training is 66.15691489361703\n",
            "Epoch #3. Accuracy on batch 47/2438  on Training is 66.14583333333333\n",
            "Epoch #3. Accuracy on batch 48/2438  on Training is 66.13520408163265\n",
            "Epoch #3. Accuracy on batch 49/2438  on Training is 66.25\n",
            "Epoch #3. Accuracy on batch 50/2438  on Training is 66.42156862745098\n",
            "Epoch #3. Accuracy on batch 51/2438  on Training is 66.40625\n",
            "Epoch #3. Accuracy on batch 52/2438  on Training is 66.39150943396227\n",
            "Epoch #3. Accuracy on batch 53/2438  on Training is 66.20370370370371\n",
            "Epoch #3. Accuracy on batch 54/2438  on Training is 66.13636363636364\n",
            "Epoch #3. Accuracy on batch 55/2438  on Training is 66.23883928571429\n",
            "Epoch #3. Accuracy on batch 56/2438  on Training is 66.17324561403508\n",
            "Epoch #3. Accuracy on batch 57/2438  on Training is 66.21767241379311\n",
            "Epoch #3. Accuracy on batch 58/2438  on Training is 66.47245762711864\n",
            "Epoch #3. Accuracy on batch 59/2438  on Training is 66.30208333333333\n",
            "Batch Id 60/2438 is having training loss of 1.2956348657608032\n",
            "1.0369101762771606\n",
            "Epoch #3. Accuracy on batch 60/2438  on Training is 66.49590163934427\n",
            "Epoch #3. Accuracy on batch 61/2438  on Training is 66.48185483870968\n",
            "Epoch #3. Accuracy on batch 62/2438  on Training is 66.51785714285714\n",
            "Epoch #3. Accuracy on batch 63/2438  on Training is 66.357421875\n",
            "Epoch #3. Accuracy on batch 64/2438  on Training is 66.25\n",
            "Epoch #3. Accuracy on batch 65/2438  on Training is 66.14583333333333\n",
            "Epoch #3. Accuracy on batch 66/2438  on Training is 66.13805970149254\n",
            "Epoch #3. Accuracy on batch 67/2438  on Training is 66.26838235294117\n",
            "Epoch #3. Accuracy on batch 68/2438  on Training is 66.16847826086956\n",
            "Epoch #3. Accuracy on batch 69/2438  on Training is 66.20535714285714\n",
            "Epoch #3. Accuracy on batch 70/2438  on Training is 66.28521126760563\n",
            "Epoch #3. Accuracy on batch 71/2438  on Training is 66.23263888888889\n",
            "Epoch #3. Accuracy on batch 72/2438  on Training is 66.22431506849315\n",
            "Epoch #3. Accuracy on batch 73/2438  on Training is 66.25844594594595\n",
            "Epoch #3. Accuracy on batch 74/2438  on Training is 66.29166666666667\n",
            "Epoch #3. Accuracy on batch 75/2438  on Training is 66.32401315789474\n",
            "Epoch #3. Accuracy on batch 76/2438  on Training is 66.31493506493507\n",
            "Epoch #3. Accuracy on batch 77/2438  on Training is 66.50641025641026\n",
            "Epoch #3. Accuracy on batch 78/2438  on Training is 66.5743670886076\n",
            "Epoch #3. Accuracy on batch 79/2438  on Training is 66.6796875\n",
            "Batch Id 80/2438 is having training loss of 1.2765741348266602\n",
            "1.3565620183944702\n",
            "Epoch #3. Accuracy on batch 80/2438  on Training is 66.7824074074074\n",
            "Epoch #3. Accuracy on batch 81/2438  on Training is 66.76829268292683\n",
            "Epoch #3. Accuracy on batch 82/2438  on Training is 66.75451807228916\n",
            "Epoch #3. Accuracy on batch 83/2438  on Training is 66.81547619047619\n",
            "Epoch #3. Accuracy on batch 84/2438  on Training is 66.83823529411765\n",
            "Epoch #3. Accuracy on batch 85/2438  on Training is 66.93313953488372\n",
            "Epoch #3. Accuracy on batch 86/2438  on Training is 67.02586206896552\n",
            "Epoch #3. Accuracy on batch 87/2438  on Training is 67.04545454545455\n",
            "Epoch #3. Accuracy on batch 88/2438  on Training is 67.13483146067416\n",
            "Epoch #3. Accuracy on batch 89/2438  on Training is 67.08333333333333\n",
            "Epoch #3. Accuracy on batch 90/2438  on Training is 66.99862637362638\n",
            "Epoch #3. Accuracy on batch 91/2438  on Training is 66.81385869565217\n",
            "Epoch #3. Accuracy on batch 92/2438  on Training is 66.93548387096774\n",
            "Epoch #3. Accuracy on batch 93/2438  on Training is 66.92154255319149\n",
            "Epoch #3. Accuracy on batch 94/2438  on Training is 66.875\n",
            "Epoch #3. Accuracy on batch 95/2438  on Training is 66.92708333333333\n",
            "Epoch #3. Accuracy on batch 96/2438  on Training is 66.78479381443299\n",
            "Epoch #3. Accuracy on batch 97/2438  on Training is 66.70918367346938\n",
            "Epoch #3. Accuracy on batch 98/2438  on Training is 66.72979797979798\n",
            "Epoch #3. Accuracy on batch 99/2438  on Training is 66.65625\n",
            "Batch Id 100/2438 is having training loss of 1.2812501192092896\n",
            "1.336411714553833\n",
            "Epoch #3. Accuracy on batch 100/2438  on Training is 66.64603960396039\n",
            "Epoch #3. Accuracy on batch 101/2438  on Training is 66.54411764705883\n",
            "Epoch #3. Accuracy on batch 102/2438  on Training is 66.65655339805825\n",
            "Epoch #3. Accuracy on batch 103/2438  on Training is 66.64663461538461\n",
            "Epoch #3. Accuracy on batch 104/2438  on Training is 66.60714285714286\n",
            "Epoch #3. Accuracy on batch 105/2438  on Training is 66.65683962264151\n",
            "Epoch #3. Accuracy on batch 106/2438  on Training is 66.67640186915888\n",
            "Epoch #3. Accuracy on batch 107/2438  on Training is 66.66666666666667\n",
            "Epoch #3. Accuracy on batch 108/2438  on Training is 66.68577981651376\n",
            "Epoch #3. Accuracy on batch 109/2438  on Training is 66.70454545454545\n",
            "Epoch #3. Accuracy on batch 110/2438  on Training is 66.75112612612612\n",
            "Epoch #3. Accuracy on batch 111/2438  on Training is 66.65736607142857\n",
            "Epoch #3. Accuracy on batch 112/2438  on Training is 66.67588495575221\n",
            "Epoch #3. Accuracy on batch 113/2438  on Training is 66.61184210526316\n",
            "Epoch #3. Accuracy on batch 114/2438  on Training is 66.65760869565217\n",
            "Epoch #3. Accuracy on batch 115/2438  on Training is 66.62176724137932\n",
            "Epoch #3. Accuracy on batch 116/2438  on Training is 66.63995726495726\n",
            "Epoch #3. Accuracy on batch 117/2438  on Training is 66.79025423728814\n",
            "Epoch #3. Accuracy on batch 118/2438  on Training is 66.85924369747899\n",
            "Epoch #3. Accuracy on batch 119/2438  on Training is 66.796875\n",
            "Batch Id 120/2438 is having training loss of 1.2750880718231201\n",
            "1.1232802867889404\n",
            "Epoch #3. Accuracy on batch 120/2438  on Training is 66.8646694214876\n",
            "Epoch #3. Accuracy on batch 121/2438  on Training is 66.90573770491804\n",
            "Epoch #3. Accuracy on batch 122/2438  on Training is 66.92073170731707\n",
            "Epoch #3. Accuracy on batch 123/2438  on Training is 66.8850806451613\n",
            "Epoch #3. Accuracy on batch 124/2438  on Training is 66.75\n",
            "Epoch #3. Accuracy on batch 125/2438  on Training is 66.81547619047619\n",
            "Epoch #3. Accuracy on batch 126/2438  on Training is 66.85531496062993\n",
            "Epoch #3. Accuracy on batch 127/2438  on Training is 66.943359375\n",
            "Epoch #3. Accuracy on batch 128/2438  on Training is 66.93313953488372\n",
            "Epoch #3. Accuracy on batch 129/2438  on Training is 66.875\n",
            "Epoch #3. Accuracy on batch 130/2438  on Training is 66.77003816793894\n",
            "Epoch #3. Accuracy on batch 131/2438  on Training is 66.76136363636364\n",
            "Epoch #3. Accuracy on batch 132/2438  on Training is 66.70582706766918\n",
            "Epoch #3. Accuracy on batch 133/2438  on Training is 66.67444029850746\n",
            "Epoch #3. Accuracy on batch 134/2438  on Training is 66.71296296296296\n",
            "Epoch #3. Accuracy on batch 135/2438  on Training is 66.68198529411765\n",
            "Epoch #3. Accuracy on batch 136/2438  on Training is 66.85675182481752\n",
            "Epoch #3. Accuracy on batch 137/2438  on Training is 66.73460144927536\n",
            "Epoch #3. Accuracy on batch 138/2438  on Training is 66.72661870503597\n",
            "Epoch #3. Accuracy on batch 139/2438  on Training is 66.74107142857143\n",
            "Batch Id 140/2438 is having training loss of 1.2718561887741089\n",
            "1.2988919019699097\n",
            "Epoch #3. Accuracy on batch 140/2438  on Training is 66.71099290780141\n",
            "Epoch #3. Accuracy on batch 141/2438  on Training is 66.65933098591549\n",
            "Epoch #3. Accuracy on batch 142/2438  on Training is 66.7395104895105\n",
            "Epoch #3. Accuracy on batch 143/2438  on Training is 66.62326388888889\n",
            "Epoch #3. Accuracy on batch 144/2438  on Training is 66.61637931034483\n",
            "Epoch #3. Accuracy on batch 145/2438  on Training is 66.5667808219178\n",
            "Epoch #3. Accuracy on batch 146/2438  on Training is 66.51785714285714\n",
            "Epoch #3. Accuracy on batch 147/2438  on Training is 66.57516891891892\n",
            "Epoch #3. Accuracy on batch 148/2438  on Training is 66.52684563758389\n",
            "Epoch #3. Accuracy on batch 149/2438  on Training is 66.58333333333333\n",
            "Epoch #3. Accuracy on batch 150/2438  on Training is 66.57698675496688\n",
            "Epoch #3. Accuracy on batch 151/2438  on Training is 66.44736842105263\n",
            "Epoch #3. Accuracy on batch 152/2438  on Training is 66.44199346405229\n",
            "Epoch #3. Accuracy on batch 153/2438  on Training is 66.4163961038961\n",
            "Epoch #3. Accuracy on batch 154/2438  on Training is 66.49193548387096\n",
            "Epoch #3. Accuracy on batch 155/2438  on Training is 66.50641025641026\n",
            "Epoch #3. Accuracy on batch 156/2438  on Training is 66.48089171974522\n",
            "Epoch #3. Accuracy on batch 157/2438  on Training is 66.43591772151899\n",
            "Epoch #3. Accuracy on batch 158/2438  on Training is 66.39150943396227\n",
            "Epoch #3. Accuracy on batch 159/2438  on Training is 66.4453125\n",
            "Batch Id 160/2438 is having training loss of 1.278146743774414\n",
            "1.0726763010025024\n",
            "Epoch #3. Accuracy on batch 160/2438  on Training is 66.45962732919254\n",
            "Epoch #3. Accuracy on batch 161/2438  on Training is 66.51234567901234\n",
            "Epoch #3. Accuracy on batch 162/2438  on Training is 66.39187116564418\n",
            "Epoch #3. Accuracy on batch 163/2438  on Training is 66.44435975609755\n",
            "Epoch #3. Accuracy on batch 164/2438  on Training is 66.49621212121212\n",
            "Epoch #3. Accuracy on batch 165/2438  on Training is 66.43448795180723\n",
            "Epoch #3. Accuracy on batch 166/2438  on Training is 66.39221556886227\n",
            "Epoch #3. Accuracy on batch 167/2438  on Training is 66.33184523809524\n",
            "Epoch #3. Accuracy on batch 168/2438  on Training is 66.30917159763314\n",
            "Epoch #3. Accuracy on batch 169/2438  on Training is 66.28676470588235\n",
            "Epoch #3. Accuracy on batch 170/2438  on Training is 66.28289473684211\n",
            "Epoch #3. Accuracy on batch 171/2438  on Training is 66.29723837209302\n",
            "Epoch #3. Accuracy on batch 172/2438  on Training is 66.32947976878613\n",
            "Epoch #3. Accuracy on batch 173/2438  on Training is 66.39727011494253\n",
            "Epoch #3. Accuracy on batch 174/2438  on Training is 66.35714285714286\n",
            "Epoch #3. Accuracy on batch 175/2438  on Training is 66.33522727272727\n",
            "Epoch #3. Accuracy on batch 176/2438  on Training is 66.3135593220339\n",
            "Epoch #3. Accuracy on batch 177/2438  on Training is 66.29213483146067\n",
            "Epoch #3. Accuracy on batch 178/2438  on Training is 66.30586592178771\n",
            "Epoch #3. Accuracy on batch 179/2438  on Training is 66.40625\n",
            "Batch Id 180/2438 is having training loss of 1.2735604047775269\n",
            "1.498576045036316\n",
            "Epoch #3. Accuracy on batch 180/2438  on Training is 66.41919889502762\n",
            "Epoch #3. Accuracy on batch 181/2438  on Training is 66.43200549450549\n",
            "Epoch #3. Accuracy on batch 182/2438  on Training is 66.4275956284153\n",
            "Epoch #3. Accuracy on batch 183/2438  on Training is 66.3383152173913\n",
            "Epoch #3. Accuracy on batch 184/2438  on Training is 66.36824324324324\n",
            "Epoch #3. Accuracy on batch 185/2438  on Training is 66.3138440860215\n",
            "Epoch #3. Accuracy on batch 186/2438  on Training is 66.32687165775401\n",
            "Epoch #3. Accuracy on batch 187/2438  on Training is 66.28989361702128\n",
            "Epoch #3. Accuracy on batch 188/2438  on Training is 66.31944444444444\n",
            "Epoch #3. Accuracy on batch 189/2438  on Training is 66.26644736842105\n",
            "Epoch #3. Accuracy on batch 190/2438  on Training is 66.34489528795811\n",
            "Epoch #3. Accuracy on batch 191/2438  on Training is 66.357421875\n",
            "Epoch #3. Accuracy on batch 192/2438  on Training is 66.41839378238342\n",
            "Epoch #3. Accuracy on batch 193/2438  on Training is 66.46262886597938\n",
            "Epoch #3. Accuracy on batch 194/2438  on Training is 66.45833333333333\n",
            "Epoch #3. Accuracy on batch 195/2438  on Training is 66.42219387755102\n",
            "Epoch #3. Accuracy on batch 196/2438  on Training is 66.41814720812182\n",
            "Epoch #3. Accuracy on batch 197/2438  on Training is 66.42992424242425\n",
            "Epoch #3. Accuracy on batch 198/2438  on Training is 66.42587939698493\n",
            "Epoch #3. Accuracy on batch 199/2438  on Training is 66.453125\n",
            "Batch Id 200/2438 is having training loss of 1.270990252494812\n",
            "1.2737383842468262\n",
            "Epoch #3. Accuracy on batch 200/2438  on Training is 66.43345771144278\n",
            "Epoch #3. Accuracy on batch 201/2438  on Training is 66.36757425742574\n",
            "Epoch #3. Accuracy on batch 202/2438  on Training is 66.28694581280789\n",
            "Epoch #3. Accuracy on batch 203/2438  on Training is 66.3296568627451\n",
            "Epoch #3. Accuracy on batch 204/2438  on Training is 66.35670731707317\n",
            "Epoch #3. Accuracy on batch 205/2438  on Training is 66.36832524271844\n",
            "Epoch #3. Accuracy on batch 206/2438  on Training is 66.41002415458937\n",
            "Epoch #3. Accuracy on batch 207/2438  on Training is 66.40625\n",
            "Epoch #3. Accuracy on batch 208/2438  on Training is 66.43241626794259\n",
            "Epoch #3. Accuracy on batch 209/2438  on Training is 66.38392857142857\n",
            "Epoch #3. Accuracy on batch 210/2438  on Training is 66.36552132701422\n",
            "Epoch #3. Accuracy on batch 211/2438  on Training is 66.37676886792453\n",
            "Epoch #3. Accuracy on batch 212/2438  on Training is 66.40258215962442\n",
            "Epoch #3. Accuracy on batch 213/2438  on Training is 66.39894859813084\n",
            "Epoch #3. Accuracy on batch 214/2438  on Training is 66.38081395348837\n",
            "Epoch #3. Accuracy on batch 215/2438  on Training is 66.34837962962963\n",
            "Epoch #3. Accuracy on batch 216/2438  on Training is 66.28744239631337\n",
            "Epoch #3. Accuracy on batch 217/2438  on Training is 66.27006880733946\n",
            "Epoch #3. Accuracy on batch 218/2438  on Training is 66.23858447488584\n",
            "Epoch #3. Accuracy on batch 219/2438  on Training is 66.29261363636364\n",
            "Batch Id 220/2438 is having training loss of 1.2734819650650024\n",
            "1.1601901054382324\n",
            "Epoch #3. Accuracy on batch 220/2438  on Training is 66.30373303167421\n",
            "Epoch #3. Accuracy on batch 221/2438  on Training is 66.28659909909909\n",
            "Epoch #3. Accuracy on batch 222/2438  on Training is 66.26961883408072\n",
            "Epoch #3. Accuracy on batch 223/2438  on Training is 66.25279017857143\n",
            "Epoch #3. Accuracy on batch 224/2438  on Training is 66.25\n",
            "Epoch #3. Accuracy on batch 225/2438  on Training is 66.20575221238938\n",
            "Epoch #3. Accuracy on batch 226/2438  on Training is 66.18942731277534\n",
            "Epoch #3. Accuracy on batch 227/2438  on Training is 66.18695175438596\n",
            "Epoch #3. Accuracy on batch 228/2438  on Training is 66.17085152838428\n",
            "Epoch #3. Accuracy on batch 229/2438  on Training is 66.1820652173913\n",
            "Epoch #3. Accuracy on batch 230/2438  on Training is 66.15259740259741\n",
            "Epoch #3. Accuracy on batch 231/2438  on Training is 66.21767241379311\n",
            "Epoch #3. Accuracy on batch 232/2438  on Training is 66.20171673819742\n",
            "Epoch #3. Accuracy on batch 233/2438  on Training is 66.21260683760684\n",
            "Epoch #3. Accuracy on batch 234/2438  on Training is 66.21010638297872\n",
            "Epoch #3. Accuracy on batch 235/2438  on Training is 66.20762711864407\n",
            "Epoch #3. Accuracy on batch 236/2438  on Training is 66.165611814346\n",
            "Epoch #3. Accuracy on batch 237/2438  on Training is 66.1108193277311\n",
            "Epoch #3. Accuracy on batch 238/2438  on Training is 66.13493723849372\n",
            "Epoch #3. Accuracy on batch 239/2438  on Training is 66.10677083333333\n",
            "Batch Id 240/2438 is having training loss of 1.274901032447815\n",
            "1.1987800598144531\n",
            "Epoch #3. Accuracy on batch 240/2438  on Training is 66.09180497925311\n",
            "Epoch #3. Accuracy on batch 241/2438  on Training is 66.06404958677686\n",
            "Epoch #3. Accuracy on batch 242/2438  on Training is 66.03652263374485\n",
            "Epoch #3. Accuracy on batch 243/2438  on Training is 66.09887295081967\n",
            "Epoch #3. Accuracy on batch 244/2438  on Training is 66.04591836734694\n",
            "Epoch #3. Accuracy on batch 245/2438  on Training is 66.03150406504065\n",
            "Epoch #3. Accuracy on batch 246/2438  on Training is 65.97925101214575\n",
            "Epoch #3. Accuracy on batch 247/2438  on Training is 65.9148185483871\n",
            "Epoch #3. Accuracy on batch 248/2438  on Training is 65.96385542168674\n",
            "Epoch #3. Accuracy on batch 249/2438  on Training is 65.975\n",
            "Epoch #3. Accuracy on batch 250/2438  on Training is 65.97360557768924\n",
            "Epoch #3. Accuracy on batch 251/2438  on Training is 65.97222222222223\n",
            "Epoch #3. Accuracy on batch 252/2438  on Training is 65.9955533596838\n",
            "Epoch #3. Accuracy on batch 253/2438  on Training is 65.94488188976378\n",
            "Epoch #3. Accuracy on batch 254/2438  on Training is 65.96813725490196\n",
            "Epoch #3. Accuracy on batch 255/2438  on Training is 66.00341796875\n",
            "Epoch #3. Accuracy on batch 256/2438  on Training is 66.00194552529183\n",
            "Epoch #3. Accuracy on batch 257/2438  on Training is 65.97625968992249\n",
            "Epoch #3. Accuracy on batch 258/2438  on Training is 65.98696911196912\n",
            "Epoch #3. Accuracy on batch 259/2438  on Training is 65.96153846153847\n",
            "Batch Id 260/2438 is having training loss of 1.2835636138916016\n",
            "1.3094658851623535\n",
            "Epoch #3. Accuracy on batch 260/2438  on Training is 65.94827586206897\n",
            "Epoch #3. Accuracy on batch 261/2438  on Training is 65.92318702290076\n",
            "Epoch #3. Accuracy on batch 262/2438  on Training is 65.94581749049429\n",
            "Epoch #3. Accuracy on batch 263/2438  on Training is 65.93276515151516\n",
            "Epoch #3. Accuracy on batch 264/2438  on Training is 65.91981132075472\n",
            "Epoch #3. Accuracy on batch 265/2438  on Training is 65.90695488721805\n",
            "Epoch #3. Accuracy on batch 266/2438  on Training is 65.90589887640449\n",
            "Epoch #3. Accuracy on batch 267/2438  on Training is 65.89319029850746\n",
            "Epoch #3. Accuracy on batch 268/2438  on Training is 65.89219330855019\n",
            "Epoch #3. Accuracy on batch 269/2438  on Training is 65.86805555555556\n",
            "Epoch #3. Accuracy on batch 270/2438  on Training is 65.8440959409594\n",
            "Epoch #3. Accuracy on batch 271/2438  on Training is 65.86626838235294\n",
            "Epoch #3. Accuracy on batch 272/2438  on Training is 65.81959706959707\n",
            "Epoch #3. Accuracy on batch 273/2438  on Training is 65.80748175182482\n",
            "Epoch #3. Accuracy on batch 274/2438  on Training is 65.7840909090909\n",
            "Epoch #3. Accuracy on batch 275/2438  on Training is 65.7721920289855\n",
            "Epoch #3. Accuracy on batch 276/2438  on Training is 65.74909747292419\n",
            "Epoch #3. Accuracy on batch 277/2438  on Training is 65.73741007194245\n",
            "Epoch #3. Accuracy on batch 278/2438  on Training is 65.80421146953405\n",
            "Epoch #3. Accuracy on batch 279/2438  on Training is 65.79241071428571\n",
            "Batch Id 280/2438 is having training loss of 1.2866010665893555\n",
            "1.6859252452850342\n",
            "Epoch #3. Accuracy on batch 280/2438  on Training is 65.73620996441281\n",
            "Epoch #3. Accuracy on batch 281/2438  on Training is 65.7247340425532\n",
            "Epoch #3. Accuracy on batch 282/2438  on Training is 65.74646643109541\n",
            "Epoch #3. Accuracy on batch 283/2438  on Training is 65.74603873239437\n",
            "Epoch #3. Accuracy on batch 284/2438  on Training is 65.73464912280701\n",
            "Epoch #3. Accuracy on batch 285/2438  on Training is 65.75611888111888\n",
            "Epoch #3. Accuracy on batch 286/2438  on Training is 65.76655052264809\n",
            "Epoch #3. Accuracy on batch 287/2438  on Training is 65.73350694444444\n",
            "Epoch #3. Accuracy on batch 288/2438  on Training is 65.76557093425606\n",
            "Epoch #3. Accuracy on batch 289/2438  on Training is 65.82974137931035\n",
            "Epoch #3. Accuracy on batch 290/2438  on Training is 65.88273195876289\n",
            "Epoch #3. Accuracy on batch 291/2438  on Training is 65.90325342465754\n",
            "Epoch #3. Accuracy on batch 292/2438  on Training is 65.92363481228669\n",
            "Epoch #3. Accuracy on batch 293/2438  on Training is 65.95450680272108\n",
            "Epoch #3. Accuracy on batch 294/2438  on Training is 65.97457627118644\n",
            "Epoch #3. Accuracy on batch 295/2438  on Training is 66.00506756756756\n",
            "Epoch #3. Accuracy on batch 296/2438  on Training is 66.02483164983165\n",
            "Epoch #3. Accuracy on batch 297/2438  on Training is 66.03397651006712\n",
            "Epoch #3. Accuracy on batch 298/2438  on Training is 65.99080267558529\n",
            "Epoch #3. Accuracy on batch 299/2438  on Training is 66.04166666666667\n",
            "Batch Id 300/2438 is having training loss of 1.2757275104522705\n",
            "0.6703497171401978\n",
            "Epoch #3. Accuracy on batch 300/2438  on Training is 66.11295681063123\n",
            "Epoch #3. Accuracy on batch 301/2438  on Training is 66.11134105960265\n",
            "Epoch #3. Accuracy on batch 302/2438  on Training is 66.09942244224422\n",
            "Epoch #3. Accuracy on batch 303/2438  on Training is 66.04646381578948\n",
            "Epoch #3. Accuracy on batch 304/2438  on Training is 66.05532786885246\n",
            "Epoch #3. Accuracy on batch 305/2438  on Training is 66.04370915032679\n",
            "Epoch #3. Accuracy on batch 306/2438  on Training is 65.99144951140065\n",
            "Epoch #3. Accuracy on batch 307/2438  on Training is 66.00040584415585\n",
            "Epoch #3. Accuracy on batch 308/2438  on Training is 66.02953074433657\n",
            "Epoch #3. Accuracy on batch 309/2438  on Training is 66.08870967741936\n",
            "Epoch #3. Accuracy on batch 310/2438  on Training is 66.07717041800643\n",
            "Epoch #3. Accuracy on batch 311/2438  on Training is 66.07572115384616\n",
            "Epoch #3. Accuracy on batch 312/2438  on Training is 66.07428115015975\n",
            "Epoch #3. Accuracy on batch 313/2438  on Training is 66.06289808917198\n",
            "Epoch #3. Accuracy on batch 314/2438  on Training is 66.0515873015873\n",
            "Epoch #3. Accuracy on batch 315/2438  on Training is 66.04034810126582\n",
            "Epoch #3. Accuracy on batch 316/2438  on Training is 66.04889589905363\n",
            "Epoch #3. Accuracy on batch 317/2438  on Training is 66.06721698113208\n",
            "Epoch #3. Accuracy on batch 318/2438  on Training is 66.0462382445141\n",
            "Epoch #3. Accuracy on batch 319/2438  on Training is 66.015625\n",
            "Batch Id 320/2438 is having training loss of 1.2746503353118896\n",
            "0.9548401236534119\n",
            "Epoch #3. Accuracy on batch 320/2438  on Training is 66.0338785046729\n",
            "Epoch #3. Accuracy on batch 321/2438  on Training is 66.04231366459628\n",
            "Epoch #3. Accuracy on batch 322/2438  on Training is 66.04102167182663\n",
            "Epoch #3. Accuracy on batch 323/2438  on Training is 66.05902777777777\n",
            "Epoch #3. Accuracy on batch 324/2438  on Training is 66.04807692307692\n",
            "Epoch #3. Accuracy on batch 325/2438  on Training is 66.0467791411043\n",
            "Epoch #3. Accuracy on batch 326/2438  on Training is 66.02637614678899\n",
            "Epoch #3. Accuracy on batch 327/2438  on Training is 65.99657012195122\n",
            "Epoch #3. Accuracy on batch 328/2438  on Training is 66.00493920972644\n",
            "Epoch #3. Accuracy on batch 329/2438  on Training is 66.02272727272727\n",
            "Epoch #3. Accuracy on batch 330/2438  on Training is 66.02152567975831\n",
            "Epoch #3. Accuracy on batch 331/2438  on Training is 66.06739457831326\n",
            "Epoch #3. Accuracy on batch 332/2438  on Training is 66.07545045045045\n",
            "Epoch #3. Accuracy on batch 333/2438  on Training is 66.05538922155688\n",
            "Epoch #3. Accuracy on batch 334/2438  on Training is 66.06343283582089\n",
            "Epoch #3. Accuracy on batch 335/2438  on Training is 66.05282738095238\n",
            "Epoch #3. Accuracy on batch 336/2438  on Training is 66.07010385756676\n",
            "Epoch #3. Accuracy on batch 337/2438  on Training is 66.1150147928994\n",
            "Epoch #3. Accuracy on batch 338/2438  on Training is 66.11356932153393\n",
            "Epoch #3. Accuracy on batch 339/2438  on Training is 66.13970588235294\n",
            "Batch Id 340/2438 is having training loss of 1.2680943012237549\n",
            "1.2604002952575684\n",
            "Epoch #3. Accuracy on batch 340/2438  on Training is 66.09237536656892\n",
            "Epoch #3. Accuracy on batch 341/2438  on Training is 66.10014619883042\n",
            "Epoch #3. Accuracy on batch 342/2438  on Training is 66.07142857142857\n",
            "Epoch #3. Accuracy on batch 343/2438  on Training is 66.06104651162791\n",
            "Epoch #3. Accuracy on batch 344/2438  on Training is 66.04166666666667\n",
            "Epoch #3. Accuracy on batch 345/2438  on Training is 66.00433526011561\n",
            "Epoch #3. Accuracy on batch 346/2438  on Training is 66.03025936599424\n",
            "Epoch #3. Accuracy on batch 347/2438  on Training is 66.01113505747126\n",
            "Epoch #3. Accuracy on batch 348/2438  on Training is 66.04584527220631\n",
            "Epoch #3. Accuracy on batch 349/2438  on Training is 66.04464285714286\n",
            "Epoch #3. Accuracy on batch 350/2438  on Training is 65.98112535612536\n",
            "Epoch #3. Accuracy on batch 351/2438  on Training is 66.0245028409091\n",
            "Epoch #3. Accuracy on batch 352/2438  on Training is 65.99681303116148\n",
            "Epoch #3. Accuracy on batch 353/2438  on Training is 65.9957627118644\n",
            "Epoch #3. Accuracy on batch 354/2438  on Training is 65.99471830985915\n",
            "Epoch #3. Accuracy on batch 355/2438  on Training is 65.9936797752809\n",
            "Epoch #3. Accuracy on batch 356/2438  on Training is 65.94887955182072\n",
            "Epoch #3. Accuracy on batch 357/2438  on Training is 65.93051675977654\n",
            "Epoch #3. Accuracy on batch 358/2438  on Training is 65.95577994428969\n",
            "Epoch #3. Accuracy on batch 359/2438  on Training is 65.96354166666667\n",
            "Batch Id 360/2438 is having training loss of 1.2714109420776367\n",
            "1.1620038747787476\n",
            "Epoch #3. Accuracy on batch 360/2438  on Training is 65.98857340720221\n",
            "Epoch #3. Accuracy on batch 361/2438  on Training is 65.97893646408839\n",
            "Epoch #3. Accuracy on batch 362/2438  on Training is 65.9607438016529\n",
            "Epoch #3. Accuracy on batch 363/2438  on Training is 65.98557692307692\n",
            "Epoch #3. Accuracy on batch 364/2438  on Training is 65.96746575342466\n",
            "Epoch #3. Accuracy on batch 365/2438  on Training is 66.0006830601093\n",
            "Epoch #3. Accuracy on batch 366/2438  on Training is 66.03371934604904\n",
            "Epoch #3. Accuracy on batch 367/2438  on Training is 66.0835597826087\n",
            "Epoch #3. Accuracy on batch 368/2438  on Training is 66.10772357723577\n",
            "Epoch #3. Accuracy on batch 369/2438  on Training is 66.1233108108108\n",
            "Epoch #3. Accuracy on batch 370/2438  on Training is 66.1388140161725\n",
            "Epoch #3. Accuracy on batch 371/2438  on Training is 66.13743279569893\n",
            "Epoch #3. Accuracy on batch 372/2438  on Training is 66.12768096514745\n",
            "Epoch #3. Accuracy on batch 373/2438  on Training is 66.13469251336899\n",
            "Epoch #3. Accuracy on batch 374/2438  on Training is 66.11666666666666\n",
            "Epoch #3. Accuracy on batch 375/2438  on Training is 66.13198138297872\n",
            "Epoch #3. Accuracy on batch 376/2438  on Training is 66.11405835543766\n",
            "Epoch #3. Accuracy on batch 377/2438  on Training is 66.14583333333333\n",
            "Epoch #3. Accuracy on batch 378/2438  on Training is 66.16094986807389\n",
            "Epoch #3. Accuracy on batch 379/2438  on Training is 66.14309210526316\n",
            "Batch Id 380/2438 is having training loss of 1.2674392461776733\n",
            "1.3214951753616333\n",
            "Epoch #3. Accuracy on batch 380/2438  on Training is 66.15813648293964\n",
            "Epoch #3. Accuracy on batch 381/2438  on Training is 66.17310209424083\n",
            "Epoch #3. Accuracy on batch 382/2438  on Training is 66.16351174934726\n",
            "Epoch #3. Accuracy on batch 383/2438  on Training is 66.162109375\n",
            "Epoch #3. Accuracy on batch 384/2438  on Training is 66.16883116883118\n",
            "Epoch #3. Accuracy on batch 385/2438  on Training is 66.18361398963731\n",
            "Epoch #3. Accuracy on batch 386/2438  on Training is 66.18217054263566\n",
            "Epoch #3. Accuracy on batch 387/2438  on Training is 66.18878865979381\n",
            "Epoch #3. Accuracy on batch 388/2438  on Training is 66.19537275064268\n",
            "Epoch #3. Accuracy on batch 389/2438  on Training is 66.17788461538461\n",
            "Epoch #3. Accuracy on batch 390/2438  on Training is 66.20044757033249\n",
            "Epoch #3. Accuracy on batch 391/2438  on Training is 66.15911989795919\n",
            "Epoch #3. Accuracy on batch 392/2438  on Training is 66.16571246819339\n",
            "Epoch #3. Accuracy on batch 393/2438  on Training is 66.18020304568527\n",
            "Epoch #3. Accuracy on batch 394/2438  on Training is 66.15506329113924\n",
            "Epoch #3. Accuracy on batch 395/2438  on Training is 66.16161616161617\n",
            "Epoch #3. Accuracy on batch 396/2438  on Training is 66.1602644836272\n",
            "Epoch #3. Accuracy on batch 397/2438  on Training is 66.12751256281408\n",
            "Epoch #3. Accuracy on batch 398/2438  on Training is 66.13408521303258\n",
            "Epoch #3. Accuracy on batch 399/2438  on Training is 66.125\n",
            "Batch Id 400/2438 is having training loss of 1.2666095495224\n",
            "1.4705326557159424\n",
            "Epoch #3. Accuracy on batch 400/2438  on Training is 66.10816708229426\n",
            "Epoch #3. Accuracy on batch 401/2438  on Training is 66.09919154228855\n",
            "Epoch #3. Accuracy on batch 402/2438  on Training is 66.07475186104219\n",
            "Epoch #3. Accuracy on batch 403/2438  on Training is 66.07363861386139\n",
            "Epoch #3. Accuracy on batch 404/2438  on Training is 66.08796296296296\n",
            "Epoch #3. Accuracy on batch 405/2438  on Training is 66.0945197044335\n",
            "Epoch #3. Accuracy on batch 406/2438  on Training is 66.13175675675676\n",
            "Epoch #3. Accuracy on batch 407/2438  on Training is 66.13817401960785\n",
            "Epoch #3. Accuracy on batch 408/2438  on Training is 66.12163814180929\n",
            "Epoch #3. Accuracy on batch 409/2438  on Training is 66.08993902439025\n",
            "Epoch #3. Accuracy on batch 410/2438  on Training is 66.08880778588808\n",
            "Epoch #3. Accuracy on batch 411/2438  on Training is 66.11043689320388\n",
            "Epoch #3. Accuracy on batch 412/2438  on Training is 66.15466101694915\n",
            "Epoch #3. Accuracy on batch 413/2438  on Training is 66.14583333333333\n",
            "Epoch #3. Accuracy on batch 414/2438  on Training is 66.09186746987952\n",
            "Epoch #3. Accuracy on batch 415/2438  on Training is 66.09825721153847\n",
            "Epoch #3. Accuracy on batch 416/2438  on Training is 66.07464028776978\n",
            "Epoch #3. Accuracy on batch 417/2438  on Training is 66.04366028708134\n",
            "Epoch #3. Accuracy on batch 418/2438  on Training is 66.03520286396181\n",
            "Epoch #3. Accuracy on batch 419/2438  on Training is 66.04166666666667\n",
            "Batch Id 420/2438 is having training loss of 1.2691236734390259\n",
            "1.258012294769287\n",
            "Epoch #3. Accuracy on batch 420/2438  on Training is 66.04809976247031\n",
            "Epoch #3. Accuracy on batch 421/2438  on Training is 66.05450236966824\n",
            "Epoch #3. Accuracy on batch 422/2438  on Training is 66.06087470449172\n",
            "Epoch #3. Accuracy on batch 423/2438  on Training is 66.04510613207547\n",
            "Epoch #3. Accuracy on batch 424/2438  on Training is 66.03676470588235\n",
            "Epoch #3. Accuracy on batch 425/2438  on Training is 66.02846244131456\n",
            "Epoch #3. Accuracy on batch 426/2438  on Training is 66.02751756440281\n",
            "Epoch #3. Accuracy on batch 427/2438  on Training is 66.04117990654206\n",
            "Epoch #3. Accuracy on batch 428/2438  on Training is 66.0329254079254\n",
            "Epoch #3. Accuracy on batch 429/2438  on Training is 66.02470930232558\n",
            "Epoch #3. Accuracy on batch 430/2438  on Training is 66.06728538283063\n",
            "Epoch #3. Accuracy on batch 431/2438  on Training is 66.08796296296296\n",
            "Epoch #3. Accuracy on batch 432/2438  on Training is 66.09411085450347\n",
            "Epoch #3. Accuracy on batch 433/2438  on Training is 66.07142857142857\n",
            "Epoch #3. Accuracy on batch 434/2438  on Training is 66.09913793103448\n",
            "Epoch #3. Accuracy on batch 435/2438  on Training is 66.10521788990826\n",
            "Epoch #3. Accuracy on batch 436/2438  on Training is 66.13987414187643\n",
            "Epoch #3. Accuracy on batch 437/2438  on Training is 66.15296803652969\n",
            "Epoch #3. Accuracy on batch 438/2438  on Training is 66.15176537585421\n",
            "Epoch #3. Accuracy on batch 439/2438  on Training is 66.171875\n",
            "Batch Id 440/2438 is having training loss of 1.267261028289795\n",
            "1.4256700277328491\n",
            "Epoch #3. Accuracy on batch 440/2438  on Training is 66.16354875283447\n",
            "Epoch #3. Accuracy on batch 441/2438  on Training is 66.17647058823529\n",
            "Epoch #3. Accuracy on batch 442/2438  on Training is 66.18227990970655\n",
            "Epoch #3. Accuracy on batch 443/2438  on Training is 66.19510135135135\n",
            "Epoch #3. Accuracy on batch 444/2438  on Training is 66.17275280898876\n",
            "Epoch #3. Accuracy on batch 445/2438  on Training is 66.20655829596413\n",
            "Epoch #3. Accuracy on batch 446/2438  on Training is 66.21224832214764\n",
            "Epoch #3. Accuracy on batch 447/2438  on Training is 66.22488839285714\n",
            "Epoch #3. Accuracy on batch 448/2438  on Training is 66.24443207126949\n",
            "Epoch #3. Accuracy on batch 449/2438  on Training is 66.23611111111111\n",
            "Epoch #3. Accuracy on batch 450/2438  on Training is 66.22782705099779\n",
            "Epoch #3. Accuracy on batch 451/2438  on Training is 66.23340707964601\n",
            "Epoch #3. Accuracy on batch 452/2438  on Training is 66.21136865342163\n",
            "Epoch #3. Accuracy on batch 453/2438  on Training is 66.21007709251101\n",
            "Epoch #3. Accuracy on batch 454/2438  on Training is 66.24313186813187\n",
            "Epoch #3. Accuracy on batch 455/2438  on Training is 66.25548245614036\n",
            "Epoch #3. Accuracy on batch 456/2438  on Training is 66.2472647702407\n",
            "Epoch #3. Accuracy on batch 457/2438  on Training is 66.26637554585153\n",
            "Epoch #3. Accuracy on batch 458/2438  on Training is 66.32625272331154\n",
            "Epoch #3. Accuracy on batch 459/2438  on Training is 66.34510869565217\n",
            "Batch Id 460/2438 is having training loss of 1.2639424800872803\n",
            "1.2928798198699951\n",
            "Epoch #3. Accuracy on batch 460/2438  on Training is 66.33676789587852\n",
            "Epoch #3. Accuracy on batch 461/2438  on Training is 66.34875541125541\n",
            "Epoch #3. Accuracy on batch 462/2438  on Training is 66.36069114470843\n",
            "Epoch #3. Accuracy on batch 463/2438  on Training is 66.33216594827586\n",
            "Epoch #3. Accuracy on batch 464/2438  on Training is 66.3239247311828\n",
            "Epoch #3. Accuracy on batch 465/2438  on Training is 66.36266094420601\n",
            "Epoch #3. Accuracy on batch 466/2438  on Training is 66.37446466809422\n",
            "Epoch #3. Accuracy on batch 467/2438  on Training is 66.3795405982906\n",
            "Epoch #3. Accuracy on batch 468/2438  on Training is 66.35794243070363\n",
            "Epoch #3. Accuracy on batch 469/2438  on Training is 66.3563829787234\n",
            "Epoch #3. Accuracy on batch 470/2438  on Training is 66.34819532908705\n",
            "Epoch #3. Accuracy on batch 471/2438  on Training is 66.32018008474576\n",
            "Epoch #3. Accuracy on batch 472/2438  on Training is 66.31210359408034\n",
            "Epoch #3. Accuracy on batch 473/2438  on Training is 66.33043248945148\n",
            "Epoch #3. Accuracy on batch 474/2438  on Training is 66.32236842105263\n",
            "Epoch #3. Accuracy on batch 475/2438  on Training is 66.32746848739495\n",
            "Epoch #3. Accuracy on batch 476/2438  on Training is 66.33909853249476\n",
            "Epoch #3. Accuracy on batch 477/2438  on Training is 66.3702928870293\n",
            "Epoch #3. Accuracy on batch 478/2438  on Training is 66.39483298538622\n",
            "Epoch #3. Accuracy on batch 479/2438  on Training is 66.39973958333333\n",
            "Batch Id 480/2438 is having training loss of 1.2621842622756958\n",
            "1.1724238395690918\n",
            "Epoch #3. Accuracy on batch 480/2438  on Training is 66.41761954261955\n",
            "Epoch #3. Accuracy on batch 481/2438  on Training is 66.40949170124482\n",
            "Epoch #3. Accuracy on batch 482/2438  on Training is 66.40786749482402\n",
            "Epoch #3. Accuracy on batch 483/2438  on Training is 66.41270661157024\n",
            "Epoch #3. Accuracy on batch 484/2438  on Training is 66.42396907216495\n",
            "Epoch #3. Accuracy on batch 485/2438  on Training is 66.42875514403292\n",
            "Epoch #3. Accuracy on batch 486/2438  on Training is 66.43352156057495\n",
            "Epoch #3. Accuracy on batch 487/2438  on Training is 66.41905737704919\n",
            "Epoch #3. Accuracy on batch 488/2438  on Training is 66.40465235173824\n",
            "Epoch #3. Accuracy on batch 489/2438  on Training is 66.40943877551021\n",
            "Epoch #3. Accuracy on batch 490/2438  on Training is 66.45239307535641\n",
            "Epoch #3. Accuracy on batch 491/2438  on Training is 66.44435975609755\n",
            "Epoch #3. Accuracy on batch 492/2438  on Training is 66.44269776876268\n",
            "Epoch #3. Accuracy on batch 493/2438  on Training is 66.40941295546558\n",
            "Epoch #3. Accuracy on batch 494/2438  on Training is 66.38257575757575\n",
            "Epoch #3. Accuracy on batch 495/2438  on Training is 66.35584677419355\n",
            "Epoch #3. Accuracy on batch 496/2438  on Training is 66.35437625754527\n",
            "Epoch #3. Accuracy on batch 497/2438  on Training is 66.34036144578313\n",
            "Epoch #3. Accuracy on batch 498/2438  on Training is 66.34519038076152\n",
            "Epoch #3. Accuracy on batch 499/2438  on Training is 66.35\n",
            "Batch Id 500/2438 is having training loss of 1.2638452053070068\n",
            "0.8743297457695007\n",
            "Epoch #3. Accuracy on batch 500/2438  on Training is 66.37974051896208\n",
            "Epoch #3. Accuracy on batch 501/2438  on Training is 66.37201195219123\n",
            "Epoch #3. Accuracy on batch 502/2438  on Training is 66.3581013916501\n",
            "Epoch #3. Accuracy on batch 503/2438  on Training is 66.36284722222223\n",
            "Epoch #3. Accuracy on batch 504/2438  on Training is 66.39851485148515\n",
            "Epoch #3. Accuracy on batch 505/2438  on Training is 66.38463438735178\n",
            "Epoch #3. Accuracy on batch 506/2438  on Training is 66.38929980276134\n",
            "Epoch #3. Accuracy on batch 507/2438  on Training is 66.36318897637796\n",
            "Epoch #3. Accuracy on batch 508/2438  on Training is 66.36173870333988\n",
            "Epoch #3. Accuracy on batch 509/2438  on Training is 66.3296568627451\n",
            "Epoch #3. Accuracy on batch 510/2438  on Training is 66.35885518590997\n",
            "Epoch #3. Accuracy on batch 511/2438  on Training is 66.326904296875\n",
            "Epoch #3. Accuracy on batch 512/2438  on Training is 66.35599415204679\n",
            "Epoch #3. Accuracy on batch 513/2438  on Training is 66.3545719844358\n",
            "Epoch #3. Accuracy on batch 514/2438  on Training is 66.37742718446601\n",
            "Epoch #3. Accuracy on batch 515/2438  on Training is 66.38202519379846\n",
            "Epoch #3. Accuracy on batch 516/2438  on Training is 66.37451644100581\n",
            "Epoch #3. Accuracy on batch 517/2438  on Training is 66.38513513513513\n",
            "Epoch #3. Accuracy on batch 518/2438  on Training is 66.38969171483622\n",
            "Epoch #3. Accuracy on batch 519/2438  on Training is 66.3701923076923\n",
            "Batch Id 520/2438 is having training loss of 1.2623027563095093\n",
            "1.1182855367660522\n",
            "Epoch #3. Accuracy on batch 520/2438  on Training is 66.36276391554702\n",
            "Epoch #3. Accuracy on batch 521/2438  on Training is 66.33740421455938\n",
            "Epoch #3. Accuracy on batch 522/2438  on Training is 66.32409177820267\n",
            "Epoch #3. Accuracy on batch 523/2438  on Training is 66.33468511450381\n",
            "Epoch #3. Accuracy on batch 524/2438  on Training is 66.35119047619048\n",
            "Epoch #3. Accuracy on batch 525/2438  on Training is 66.32010456273764\n",
            "Epoch #3. Accuracy on batch 526/2438  on Training is 66.34250474383302\n",
            "Epoch #3. Accuracy on batch 527/2438  on Training is 66.32930871212122\n",
            "Epoch #3. Accuracy on batch 528/2438  on Training is 66.31025519848771\n",
            "Epoch #3. Accuracy on batch 529/2438  on Training is 66.30896226415095\n",
            "Epoch #3. Accuracy on batch 530/2438  on Training is 66.29001883239171\n",
            "Epoch #3. Accuracy on batch 531/2438  on Training is 66.30639097744361\n",
            "Epoch #3. Accuracy on batch 532/2438  on Training is 66.31683864915573\n",
            "Epoch #3. Accuracy on batch 533/2438  on Training is 66.29798689138576\n",
            "Epoch #3. Accuracy on batch 534/2438  on Training is 66.28504672897196\n",
            "Epoch #3. Accuracy on batch 535/2438  on Training is 66.27798507462687\n",
            "Epoch #3. Accuracy on batch 536/2438  on Training is 66.30004655493482\n",
            "Epoch #3. Accuracy on batch 537/2438  on Training is 66.31040892193309\n",
            "Epoch #3. Accuracy on batch 538/2438  on Training is 66.32073283858998\n",
            "Epoch #3. Accuracy on batch 539/2438  on Training is 66.33680555555556\n",
            "Batch Id 540/2438 is having training loss of 1.2626162767410278\n",
            "0.9760084748268127\n",
            "Epoch #3. Accuracy on batch 540/2438  on Training is 66.34126617375232\n",
            "Epoch #3. Accuracy on batch 541/2438  on Training is 66.3399446494465\n",
            "Epoch #3. Accuracy on batch 542/2438  on Training is 66.3616482504604\n",
            "Epoch #3. Accuracy on batch 543/2438  on Training is 66.37178308823529\n",
            "Epoch #3. Accuracy on batch 544/2438  on Training is 66.34747706422019\n",
            "Epoch #3. Accuracy on batch 545/2438  on Training is 66.32898351648352\n",
            "Epoch #3. Accuracy on batch 546/2438  on Training is 66.33340950639854\n",
            "Epoch #3. Accuracy on batch 547/2438  on Training is 66.33781934306569\n",
            "Epoch #3. Accuracy on batch 548/2438  on Training is 66.32513661202186\n",
            "Epoch #3. Accuracy on batch 549/2438  on Training is 66.32954545454545\n",
            "Epoch #3. Accuracy on batch 550/2438  on Training is 66.32259528130672\n",
            "Epoch #3. Accuracy on batch 551/2438  on Training is 66.33265398550725\n",
            "Epoch #3. Accuracy on batch 552/2438  on Training is 66.32572332730561\n",
            "Epoch #3. Accuracy on batch 553/2438  on Training is 66.34702166064982\n",
            "Epoch #3. Accuracy on batch 554/2438  on Training is 66.33445945945945\n",
            "Epoch #3. Accuracy on batch 555/2438  on Training is 66.34442446043165\n",
            "Epoch #3. Accuracy on batch 556/2438  on Training is 66.3431328545781\n",
            "Epoch #3. Accuracy on batch 557/2438  on Training is 66.32504480286738\n",
            "Epoch #3. Accuracy on batch 558/2438  on Training is 66.34056350626118\n",
            "Epoch #3. Accuracy on batch 559/2438  on Training is 66.33928571428571\n",
            "Batch Id 560/2438 is having training loss of 1.2631486654281616\n",
            "1.2024949789047241\n",
            "Epoch #3. Accuracy on batch 560/2438  on Training is 66.33801247771837\n",
            "Epoch #3. Accuracy on batch 561/2438  on Training is 66.32006227758008\n",
            "Epoch #3. Accuracy on batch 562/2438  on Training is 66.34103019538188\n",
            "Epoch #3. Accuracy on batch 563/2438  on Training is 66.35084219858156\n",
            "Epoch #3. Accuracy on batch 564/2438  on Training is 66.33849557522124\n",
            "Epoch #3. Accuracy on batch 565/2438  on Training is 66.34275618374558\n",
            "Epoch #3. Accuracy on batch 566/2438  on Training is 66.33597883597884\n",
            "Epoch #3. Accuracy on batch 567/2438  on Training is 66.33472711267606\n",
            "Epoch #3. Accuracy on batch 568/2438  on Training is 66.33347978910369\n",
            "Epoch #3. Accuracy on batch 569/2438  on Training is 66.36513157894737\n",
            "Epoch #3. Accuracy on batch 570/2438  on Training is 66.38025394045535\n",
            "Epoch #3. Accuracy on batch 571/2438  on Training is 66.39532342657343\n",
            "Epoch #3. Accuracy on batch 572/2438  on Training is 66.39943280977312\n",
            "Epoch #3. Accuracy on batch 573/2438  on Training is 66.38719512195122\n",
            "Epoch #3. Accuracy on batch 574/2438  on Training is 66.38586956521739\n",
            "Epoch #3. Accuracy on batch 575/2438  on Training is 66.39539930555556\n",
            "Epoch #3. Accuracy on batch 576/2438  on Training is 66.38864818024264\n",
            "Epoch #3. Accuracy on batch 577/2438  on Training is 66.38732698961938\n",
            "Epoch #3. Accuracy on batch 578/2438  on Training is 66.39140759930915\n",
            "Epoch #3. Accuracy on batch 579/2438  on Training is 66.41163793103448\n",
            "Batch Id 580/2438 is having training loss of 1.2610023021697998\n",
            "1.3850470781326294\n",
            "Epoch #3. Accuracy on batch 580/2438  on Training is 66.4210413080895\n",
            "Epoch #3. Accuracy on batch 581/2438  on Training is 66.38208762886597\n",
            "Epoch #3. Accuracy on batch 582/2438  on Training is 66.38614922813036\n",
            "Epoch #3. Accuracy on batch 583/2438  on Training is 66.40625\n",
            "Epoch #3. Accuracy on batch 584/2438  on Training is 66.42628205128206\n",
            "Epoch #3. Accuracy on batch 585/2438  on Training is 66.43024744027304\n",
            "Epoch #3. Accuracy on batch 586/2438  on Training is 66.45017035775128\n",
            "Epoch #3. Accuracy on batch 587/2438  on Training is 66.46471088435374\n",
            "Epoch #3. Accuracy on batch 588/2438  on Training is 66.48450764006792\n",
            "Epoch #3. Accuracy on batch 589/2438  on Training is 66.47775423728814\n",
            "Epoch #3. Accuracy on batch 590/2438  on Training is 66.47102368866328\n",
            "Epoch #3. Accuracy on batch 591/2438  on Training is 66.46431587837837\n",
            "Epoch #3. Accuracy on batch 592/2438  on Training is 66.45236087689713\n",
            "Epoch #3. Accuracy on batch 593/2438  on Training is 66.44044612794613\n",
            "Epoch #3. Accuracy on batch 594/2438  on Training is 66.4233193277311\n",
            "Epoch #3. Accuracy on batch 595/2438  on Training is 66.42197986577182\n",
            "Epoch #3. Accuracy on batch 596/2438  on Training is 66.43111390284757\n",
            "Epoch #3. Accuracy on batch 597/2438  on Training is 66.41408862876254\n",
            "Epoch #3. Accuracy on batch 598/2438  on Training is 66.42320534223707\n",
            "Epoch #3. Accuracy on batch 599/2438  on Training is 66.41666666666667\n",
            "Batch Id 600/2438 is having training loss of 1.2618056535720825\n",
            "1.2803773880004883\n",
            "Epoch #3. Accuracy on batch 600/2438  on Training is 66.41534941763727\n",
            "Epoch #3. Accuracy on batch 601/2438  on Training is 66.41922757475083\n",
            "Epoch #3. Accuracy on batch 602/2438  on Training is 66.4075456053068\n",
            "Epoch #3. Accuracy on batch 603/2438  on Training is 66.3907284768212\n",
            "Epoch #3. Accuracy on batch 604/2438  on Training is 66.37913223140495\n",
            "Epoch #3. Accuracy on batch 605/2438  on Training is 66.36241749174917\n",
            "Epoch #3. Accuracy on batch 606/2438  on Training is 66.36635090609555\n",
            "Epoch #3. Accuracy on batch 607/2438  on Training is 66.37027138157895\n",
            "Epoch #3. Accuracy on batch 608/2438  on Training is 66.37931034482759\n",
            "Epoch #3. Accuracy on batch 609/2438  on Training is 66.38831967213115\n",
            "Epoch #3. Accuracy on batch 610/2438  on Training is 66.37684124386251\n",
            "Epoch #3. Accuracy on batch 611/2438  on Training is 66.36540032679738\n",
            "Epoch #3. Accuracy on batch 612/2438  on Training is 66.37948613376835\n",
            "Epoch #3. Accuracy on batch 613/2438  on Training is 66.38334690553746\n",
            "Epoch #3. Accuracy on batch 614/2438  on Training is 66.39227642276423\n",
            "Epoch #3. Accuracy on batch 615/2438  on Training is 66.38595779220779\n",
            "Epoch #3. Accuracy on batch 616/2438  on Training is 66.36952998379255\n",
            "Epoch #3. Accuracy on batch 617/2438  on Training is 66.35821197411003\n",
            "Epoch #3. Accuracy on batch 618/2438  on Training is 66.32168820678514\n",
            "Epoch #3. Accuracy on batch 619/2438  on Training is 66.32056451612904\n",
            "Batch Id 620/2438 is having training loss of 1.264264464378357\n",
            "1.1853550672531128\n",
            "Epoch #3. Accuracy on batch 620/2438  on Training is 66.32950885668276\n",
            "Epoch #3. Accuracy on batch 621/2438  on Training is 66.32837620578778\n",
            "Epoch #3. Accuracy on batch 622/2438  on Training is 66.32724719101124\n",
            "Epoch #3. Accuracy on batch 623/2438  on Training is 66.34114583333333\n",
            "Epoch #3. Accuracy on batch 624/2438  on Training is 66.33\n",
            "Epoch #3. Accuracy on batch 625/2438  on Training is 66.32887380191693\n",
            "Epoch #3. Accuracy on batch 626/2438  on Training is 66.3427033492823\n",
            "Epoch #3. Accuracy on batch 627/2438  on Training is 66.34156050955414\n",
            "Epoch #3. Accuracy on batch 628/2438  on Training is 66.35532591414945\n",
            "Epoch #3. Accuracy on batch 629/2438  on Training is 66.34424603174604\n",
            "Epoch #3. Accuracy on batch 630/2438  on Training is 66.348058637084\n",
            "Epoch #3. Accuracy on batch 631/2438  on Training is 66.36669303797468\n",
            "Epoch #3. Accuracy on batch 632/2438  on Training is 66.3803317535545\n",
            "Epoch #3. Accuracy on batch 633/2438  on Training is 66.3791403785489\n",
            "Epoch #3. Accuracy on batch 634/2438  on Training is 66.36811023622047\n",
            "Epoch #3. Accuracy on batch 635/2438  on Training is 66.36694182389937\n",
            "Epoch #3. Accuracy on batch 636/2438  on Training is 66.37068288854003\n",
            "Epoch #3. Accuracy on batch 637/2438  on Training is 66.3548197492163\n",
            "Epoch #3. Accuracy on batch 638/2438  on Training is 66.3683489827856\n",
            "Epoch #3. Accuracy on batch 639/2438  on Training is 66.3818359375\n",
            "Batch Id 640/2438 is having training loss of 1.2634578943252563\n",
            "0.9405695796012878\n",
            "Epoch #3. Accuracy on batch 640/2438  on Training is 66.39528081123245\n",
            "Epoch #3. Accuracy on batch 641/2438  on Training is 66.37947819314641\n",
            "Epoch #3. Accuracy on batch 642/2438  on Training is 66.37830482115085\n",
            "Epoch #3. Accuracy on batch 643/2438  on Training is 66.36257763975155\n",
            "Epoch #3. Accuracy on batch 644/2438  on Training is 66.36627906976744\n",
            "Epoch #3. Accuracy on batch 645/2438  on Training is 66.36029411764706\n",
            "Epoch #3. Accuracy on batch 646/2438  on Training is 66.36398763523957\n",
            "Epoch #3. Accuracy on batch 647/2438  on Training is 66.36284722222223\n",
            "Epoch #3. Accuracy on batch 648/2438  on Training is 66.35208012326656\n",
            "Epoch #3. Accuracy on batch 649/2438  on Training is 66.34134615384616\n",
            "Epoch #3. Accuracy on batch 650/2438  on Training is 66.35464669738863\n",
            "Epoch #3. Accuracy on batch 651/2438  on Training is 66.37749233128834\n",
            "Epoch #3. Accuracy on batch 652/2438  on Training is 66.38112557427259\n",
            "Epoch #3. Accuracy on batch 653/2438  on Training is 66.36563455657492\n",
            "Epoch #3. Accuracy on batch 654/2438  on Training is 66.3645038167939\n",
            "Epoch #3. Accuracy on batch 655/2438  on Training is 66.33479420731707\n",
            "Epoch #3. Accuracy on batch 656/2438  on Training is 66.31944444444444\n",
            "Epoch #3. Accuracy on batch 657/2438  on Training is 66.34213525835867\n",
            "Epoch #3. Accuracy on batch 658/2438  on Training is 66.34578907435508\n",
            "Epoch #3. Accuracy on batch 659/2438  on Training is 66.34469696969697\n",
            "Batch Id 660/2438 is having training loss of 1.265616774559021\n",
            "1.4654057025909424\n",
            "Epoch #3. Accuracy on batch 660/2438  on Training is 66.33888048411498\n",
            "Epoch #3. Accuracy on batch 661/2438  on Training is 66.34724320241692\n",
            "Epoch #3. Accuracy on batch 662/2438  on Training is 66.35086726998492\n",
            "Epoch #3. Accuracy on batch 663/2438  on Training is 66.35918674698796\n",
            "Epoch #3. Accuracy on batch 664/2438  on Training is 66.35808270676692\n",
            "Epoch #3. Accuracy on batch 665/2438  on Training is 66.38513513513513\n",
            "Epoch #3. Accuracy on batch 666/2438  on Training is 66.38399550224888\n",
            "Epoch #3. Accuracy on batch 667/2438  on Training is 66.41092814371258\n",
            "Epoch #3. Accuracy on batch 668/2438  on Training is 66.4144245142003\n",
            "Epoch #3. Accuracy on batch 669/2438  on Training is 66.42723880597015\n",
            "Epoch #3. Accuracy on batch 670/2438  on Training is 66.43535767511177\n",
            "Epoch #3. Accuracy on batch 671/2438  on Training is 66.42020089285714\n",
            "Epoch #3. Accuracy on batch 672/2438  on Training is 66.41901931649332\n",
            "Epoch #3. Accuracy on batch 673/2438  on Training is 66.42247774480713\n",
            "Epoch #3. Accuracy on batch 674/2438  on Training is 66.42592592592592\n",
            "Epoch #3. Accuracy on batch 675/2438  on Training is 66.42474112426035\n",
            "Epoch #3. Accuracy on batch 676/2438  on Training is 66.41894387001477\n",
            "Epoch #3. Accuracy on batch 677/2438  on Training is 66.43620943952803\n",
            "Epoch #3. Accuracy on batch 678/2438  on Training is 66.4120029455081\n",
            "Epoch #3. Accuracy on batch 679/2438  on Training is 66.39246323529412\n",
            "Batch Id 680/2438 is having training loss of 1.2638497352600098\n",
            "1.2534611225128174\n",
            "Epoch #3. Accuracy on batch 680/2438  on Training is 66.40051395007342\n",
            "Epoch #3. Accuracy on batch 681/2438  on Training is 66.39937683284458\n",
            "Epoch #3. Accuracy on batch 682/2438  on Training is 66.40739385065886\n",
            "Epoch #3. Accuracy on batch 683/2438  on Training is 66.39711257309942\n",
            "Epoch #3. Accuracy on batch 684/2438  on Training is 66.40054744525547\n",
            "Epoch #3. Accuracy on batch 685/2438  on Training is 66.408527696793\n",
            "Epoch #3. Accuracy on batch 686/2438  on Training is 66.4164847161572\n",
            "Epoch #3. Accuracy on batch 687/2438  on Training is 66.42896075581395\n",
            "Epoch #3. Accuracy on batch 688/2438  on Training is 66.427793904209\n",
            "Epoch #3. Accuracy on batch 689/2438  on Training is 66.41304347826087\n",
            "Epoch #3. Accuracy on batch 690/2438  on Training is 66.42999276410998\n",
            "Epoch #3. Accuracy on batch 691/2438  on Training is 66.40625\n",
            "Epoch #3. Accuracy on batch 692/2438  on Training is 66.39159451659452\n",
            "Epoch #3. Accuracy on batch 693/2438  on Training is 66.39048991354467\n",
            "Epoch #3. Accuracy on batch 694/2438  on Training is 66.39838129496403\n",
            "Epoch #3. Accuracy on batch 695/2438  on Training is 66.41073994252874\n",
            "Epoch #3. Accuracy on batch 696/2438  on Training is 66.4006456241033\n",
            "Epoch #3. Accuracy on batch 697/2438  on Training is 66.38162607449857\n",
            "Epoch #3. Accuracy on batch 698/2438  on Training is 66.37160228898426\n",
            "Epoch #3. Accuracy on batch 699/2438  on Training is 66.36607142857143\n",
            "Batch Id 700/2438 is having training loss of 1.2649799585342407\n",
            "1.2095736265182495\n",
            "Epoch #3. Accuracy on batch 700/2438  on Training is 66.37393009985735\n",
            "Epoch #3. Accuracy on batch 701/2438  on Training is 66.37731481481481\n",
            "Epoch #3. Accuracy on batch 702/2438  on Training is 66.37179943100996\n",
            "Epoch #3. Accuracy on batch 703/2438  on Training is 66.37517755681819\n",
            "Epoch #3. Accuracy on batch 704/2438  on Training is 66.37411347517731\n",
            "Epoch #3. Accuracy on batch 705/2438  on Training is 66.39961048158641\n",
            "Epoch #3. Accuracy on batch 706/2438  on Training is 66.39851485148515\n",
            "Epoch #3. Accuracy on batch 707/2438  on Training is 66.39742231638418\n",
            "Epoch #3. Accuracy on batch 708/2438  on Training is 66.39633286318758\n",
            "Epoch #3. Accuracy on batch 709/2438  on Training is 66.39964788732394\n",
            "Epoch #3. Accuracy on batch 710/2438  on Training is 66.39855836849507\n",
            "Epoch #3. Accuracy on batch 711/2438  on Training is 66.41941713483146\n",
            "Epoch #3. Accuracy on batch 712/2438  on Training is 66.43145161290323\n",
            "Epoch #3. Accuracy on batch 713/2438  on Training is 66.43469887955182\n",
            "Epoch #3. Accuracy on batch 714/2438  on Training is 66.42482517482517\n",
            "Epoch #3. Accuracy on batch 715/2438  on Training is 66.41934357541899\n",
            "Epoch #3. Accuracy on batch 716/2438  on Training is 66.41823570432356\n",
            "Epoch #3. Accuracy on batch 717/2438  on Training is 66.41713091922006\n",
            "Epoch #3. Accuracy on batch 718/2438  on Training is 66.42472183588318\n",
            "Epoch #3. Accuracy on batch 719/2438  on Training is 66.43229166666667\n",
            "Batch Id 720/2438 is having training loss of 1.2634745836257935\n",
            "1.2218234539031982\n",
            "Epoch #3. Accuracy on batch 720/2438  on Training is 66.42250346740639\n",
            "Epoch #3. Accuracy on batch 721/2438  on Training is 66.43005540166205\n",
            "Epoch #3. Accuracy on batch 722/2438  on Training is 66.42461964038728\n",
            "Epoch #3. Accuracy on batch 723/2438  on Training is 66.44509668508287\n",
            "Epoch #3. Accuracy on batch 724/2438  on Training is 66.44396551724138\n",
            "Epoch #3. Accuracy on batch 725/2438  on Training is 66.43853305785125\n",
            "Epoch #3. Accuracy on batch 726/2438  on Training is 66.44601100412655\n",
            "Epoch #3. Accuracy on batch 727/2438  on Training is 66.44488324175825\n",
            "Epoch #3. Accuracy on batch 728/2438  on Training is 66.4394718792867\n",
            "Epoch #3. Accuracy on batch 729/2438  on Training is 66.45119863013699\n",
            "Epoch #3. Accuracy on batch 730/2438  on Training is 66.45434336525308\n",
            "Epoch #3. Accuracy on batch 731/2438  on Training is 66.46174863387978\n",
            "Epoch #3. Accuracy on batch 732/2438  on Training is 66.46913369713506\n",
            "Epoch #3. Accuracy on batch 733/2438  on Training is 66.47649863760218\n",
            "Epoch #3. Accuracy on batch 734/2438  on Training is 66.47534013605443\n",
            "Epoch #3. Accuracy on batch 735/2438  on Training is 66.48692255434783\n",
            "Epoch #3. Accuracy on batch 736/2438  on Training is 66.48151289009498\n",
            "Epoch #3. Accuracy on batch 737/2438  on Training is 66.48882113821138\n",
            "Epoch #3. Accuracy on batch 738/2438  on Training is 66.48765223274695\n",
            "Epoch #3. Accuracy on batch 739/2438  on Training is 66.47381756756756\n",
            "Batch Id 740/2438 is having training loss of 1.2614164352416992\n",
            "1.18381929397583\n",
            "Epoch #3. Accuracy on batch 740/2438  on Training is 66.48110661268556\n",
            "Epoch #3. Accuracy on batch 741/2438  on Training is 66.47574123989219\n",
            "Epoch #3. Accuracy on batch 742/2438  on Training is 66.47880215343203\n",
            "Epoch #3. Accuracy on batch 743/2438  on Training is 66.48185483870968\n",
            "Epoch #3. Accuracy on batch 744/2438  on Training is 66.47651006711409\n",
            "Epoch #3. Accuracy on batch 745/2438  on Training is 66.4586126005362\n",
            "Epoch #3. Accuracy on batch 746/2438  on Training is 66.470046854083\n",
            "Epoch #3. Accuracy on batch 747/2438  on Training is 66.45638368983957\n",
            "Epoch #3. Accuracy on batch 748/2438  on Training is 66.45527369826435\n",
            "Epoch #3. Accuracy on batch 749/2438  on Training is 66.4625\n",
            "Epoch #3. Accuracy on batch 750/2438  on Training is 66.46138482023969\n",
            "Epoch #3. Accuracy on batch 751/2438  on Training is 66.46027260638297\n",
            "Epoch #3. Accuracy on batch 752/2438  on Training is 66.46746347941567\n",
            "Epoch #3. Accuracy on batch 753/2438  on Training is 66.43318965517241\n",
            "Epoch #3. Accuracy on batch 754/2438  on Training is 66.43211920529801\n",
            "Epoch #3. Accuracy on batch 755/2438  on Training is 66.42278439153439\n",
            "Epoch #3. Accuracy on batch 756/2438  on Training is 66.41760237780713\n",
            "Epoch #3. Accuracy on batch 757/2438  on Training is 66.42067941952507\n",
            "Epoch #3. Accuracy on batch 758/2438  on Training is 66.42786561264822\n",
            "Epoch #3. Accuracy on batch 759/2438  on Training is 66.40213815789474\n",
            "Batch Id 760/2438 is having training loss of 1.2627416849136353\n",
            "1.2119052410125732\n",
            "Epoch #3. Accuracy on batch 760/2438  on Training is 66.39701051248358\n",
            "Epoch #3. Accuracy on batch 761/2438  on Training is 66.40009842519684\n",
            "Epoch #3. Accuracy on batch 762/2438  on Training is 66.40317824377458\n",
            "Epoch #3. Accuracy on batch 763/2438  on Training is 66.41034031413612\n",
            "Epoch #3. Accuracy on batch 764/2438  on Training is 66.41748366013071\n",
            "Epoch #3. Accuracy on batch 765/2438  on Training is 66.41236945169713\n",
            "Epoch #3. Accuracy on batch 766/2438  on Training is 66.40319426336376\n",
            "Epoch #3. Accuracy on batch 767/2438  on Training is 66.40625\n",
            "Epoch #3. Accuracy on batch 768/2438  on Training is 66.37678803641093\n",
            "Epoch #3. Accuracy on batch 769/2438  on Training is 66.3676948051948\n",
            "Epoch #3. Accuracy on batch 770/2438  on Training is 66.39105058365759\n",
            "Epoch #3. Accuracy on batch 771/2438  on Training is 66.39005829015544\n",
            "Epoch #3. Accuracy on batch 772/2438  on Training is 66.39311125485123\n",
            "Epoch #3. Accuracy on batch 773/2438  on Training is 66.40423126614986\n",
            "Epoch #3. Accuracy on batch 774/2438  on Training is 66.40322580645162\n",
            "Epoch #3. Accuracy on batch 775/2438  on Training is 66.41027706185567\n",
            "Epoch #3. Accuracy on batch 776/2438  on Training is 66.40122265122265\n",
            "Epoch #3. Accuracy on batch 777/2438  on Training is 66.40022493573265\n",
            "Epoch #3. Accuracy on batch 778/2438  on Training is 66.39120667522465\n",
            "Epoch #3. Accuracy on batch 779/2438  on Training is 66.39423076923077\n",
            "Batch Id 780/2438 is having training loss of 1.261801838874817\n",
            "1.2046971321105957\n",
            "Epoch #3. Accuracy on batch 780/2438  on Training is 66.40124839948784\n",
            "Epoch #3. Accuracy on batch 781/2438  on Training is 66.38826726342711\n",
            "Epoch #3. Accuracy on batch 782/2438  on Training is 66.3992656449553\n",
            "Epoch #3. Accuracy on batch 783/2438  on Training is 66.39030612244898\n",
            "Epoch #3. Accuracy on batch 784/2438  on Training is 66.40525477707007\n",
            "Epoch #3. Accuracy on batch 785/2438  on Training is 66.408237913486\n",
            "Epoch #3. Accuracy on batch 786/2438  on Training is 66.40724269377382\n",
            "Epoch #3. Accuracy on batch 787/2438  on Training is 66.40228426395939\n",
            "Epoch #3. Accuracy on batch 788/2438  on Training is 66.38941698352345\n",
            "Epoch #3. Accuracy on batch 789/2438  on Training is 66.40427215189874\n",
            "Epoch #3. Accuracy on batch 790/2438  on Training is 66.4072376738306\n",
            "Epoch #3. Accuracy on batch 791/2438  on Training is 66.41019570707071\n",
            "Epoch #3. Accuracy on batch 792/2438  on Training is 66.4092055485498\n",
            "Epoch #3. Accuracy on batch 793/2438  on Training is 66.4278967254408\n",
            "Epoch #3. Accuracy on batch 794/2438  on Training is 66.43867924528301\n",
            "Epoch #3. Accuracy on batch 795/2438  on Training is 66.4572864321608\n",
            "Epoch #3. Accuracy on batch 796/2438  on Training is 66.44840025094103\n",
            "Epoch #3. Accuracy on batch 797/2438  on Training is 66.44736842105263\n",
            "Epoch #3. Accuracy on batch 798/2438  on Training is 66.4424280350438\n",
            "Epoch #3. Accuracy on batch 799/2438  on Training is 66.44140625\n",
            "Batch Id 800/2438 is having training loss of 1.2607730627059937\n",
            "0.9657267332077026\n",
            "Epoch #3. Accuracy on batch 800/2438  on Training is 66.4403870162297\n",
            "Epoch #3. Accuracy on batch 801/2438  on Training is 66.45105985037407\n",
            "Epoch #3. Accuracy on batch 802/2438  on Training is 66.45781444582815\n",
            "Epoch #3. Accuracy on batch 803/2438  on Training is 66.46455223880596\n",
            "Epoch #3. Accuracy on batch 804/2438  on Training is 66.47903726708074\n",
            "Epoch #3. Accuracy on batch 805/2438  on Training is 66.49348635235732\n",
            "Epoch #3. Accuracy on batch 806/2438  on Training is 66.4846654275093\n",
            "Epoch #3. Accuracy on batch 807/2438  on Training is 66.47973391089108\n",
            "Epoch #3. Accuracy on batch 808/2438  on Training is 66.46322620519159\n",
            "Epoch #3. Accuracy on batch 809/2438  on Training is 66.4699074074074\n",
            "Epoch #3. Accuracy on batch 810/2438  on Training is 66.46115906288533\n",
            "Epoch #3. Accuracy on batch 811/2438  on Training is 66.4678263546798\n",
            "Epoch #3. Accuracy on batch 812/2438  on Training is 66.4629458794588\n",
            "Epoch #3. Accuracy on batch 813/2438  on Training is 66.48495085995086\n",
            "Epoch #3. Accuracy on batch 814/2438  on Training is 66.51073619631902\n",
            "Epoch #3. Accuracy on batch 815/2438  on Training is 66.51731004901961\n",
            "Epoch #3. Accuracy on batch 816/2438  on Training is 66.52004283965728\n",
            "Epoch #3. Accuracy on batch 817/2438  on Training is 66.52276894865525\n",
            "Epoch #3. Accuracy on batch 818/2438  on Training is 66.53311965811966\n",
            "Epoch #3. Accuracy on batch 819/2438  on Training is 66.5358231707317\n",
            "Batch Id 820/2438 is having training loss of 1.258650302886963\n",
            "1.5124129056930542\n",
            "Epoch #3. Accuracy on batch 820/2438  on Training is 66.52710109622411\n",
            "Epoch #3. Accuracy on batch 821/2438  on Training is 66.51459854014598\n",
            "Epoch #3. Accuracy on batch 822/2438  on Training is 66.52111178614824\n",
            "Epoch #3. Accuracy on batch 823/2438  on Training is 66.51243932038835\n",
            "Epoch #3. Accuracy on batch 824/2438  on Training is 66.51515151515152\n",
            "Epoch #3. Accuracy on batch 825/2438  on Training is 66.51785714285714\n",
            "Epoch #3. Accuracy on batch 826/2438  on Training is 66.50922007255139\n",
            "Epoch #3. Accuracy on batch 827/2438  on Training is 66.50437801932367\n",
            "Epoch #3. Accuracy on batch 828/2438  on Training is 66.48446924004826\n",
            "Epoch #3. Accuracy on batch 829/2438  on Training is 66.48343373493977\n",
            "Epoch #3. Accuracy on batch 830/2438  on Training is 66.48616125150421\n",
            "Epoch #3. Accuracy on batch 831/2438  on Training is 66.47385817307692\n",
            "Epoch #3. Accuracy on batch 832/2438  on Training is 66.46908763505402\n",
            "Epoch #3. Accuracy on batch 833/2438  on Training is 66.4568345323741\n",
            "Epoch #3. Accuracy on batch 834/2438  on Training is 66.45958083832335\n",
            "Epoch #3. Accuracy on batch 835/2438  on Training is 66.45484449760765\n",
            "Epoch #3. Accuracy on batch 836/2438  on Training is 66.4613201911589\n",
            "Epoch #3. Accuracy on batch 837/2438  on Training is 66.46405131264916\n",
            "Epoch #3. Accuracy on batch 838/2438  on Training is 66.46305125148987\n",
            "Epoch #3. Accuracy on batch 839/2438  on Training is 66.4546130952381\n",
            "Batch Id 840/2438 is having training loss of 1.2616568803787231\n",
            "1.200927495956421\n",
            "Epoch #3. Accuracy on batch 840/2438  on Training is 66.45734244946492\n",
            "Epoch #3. Accuracy on batch 841/2438  on Training is 66.44893111638955\n",
            "Epoch #3. Accuracy on batch 842/2438  on Training is 66.44053973902729\n",
            "Epoch #3. Accuracy on batch 843/2438  on Training is 66.43587085308057\n",
            "Epoch #3. Accuracy on batch 844/2438  on Training is 66.44970414201184\n",
            "Epoch #3. Accuracy on batch 845/2438  on Training is 66.43026004728132\n",
            "Epoch #3. Accuracy on batch 846/2438  on Training is 66.43668831168831\n",
            "Epoch #3. Accuracy on batch 847/2438  on Training is 66.43573113207547\n",
            "Epoch #3. Accuracy on batch 848/2438  on Training is 66.42741460541814\n",
            "Epoch #3. Accuracy on batch 849/2438  on Training is 66.43382352941177\n",
            "Epoch #3. Accuracy on batch 850/2438  on Training is 66.44388954171563\n",
            "Epoch #3. Accuracy on batch 851/2438  on Training is 66.44292840375587\n",
            "Epoch #3. Accuracy on batch 852/2438  on Training is 66.44563305978897\n",
            "Epoch #3. Accuracy on batch 853/2438  on Training is 66.44833138173303\n",
            "Epoch #3. Accuracy on batch 854/2438  on Training is 66.46929824561404\n",
            "Epoch #3. Accuracy on batch 855/2438  on Training is 66.46466121495327\n",
            "Epoch #3. Accuracy on batch 856/2438  on Training is 66.4855600933489\n",
            "Epoch #3. Accuracy on batch 857/2438  on Training is 66.50641025641026\n",
            "Epoch #3. Accuracy on batch 858/2438  on Training is 66.51993597206054\n",
            "Epoch #3. Accuracy on batch 859/2438  on Training is 66.5188953488372\n",
            "Batch Id 860/2438 is having training loss of 1.2618752717971802\n",
            "1.4920063018798828\n",
            "Epoch #3. Accuracy on batch 860/2438  on Training is 66.51059814169571\n",
            "Epoch #3. Accuracy on batch 861/2438  on Training is 66.50232018561485\n",
            "Epoch #3. Accuracy on batch 862/2438  on Training is 66.50492468134415\n",
            "Epoch #3. Accuracy on batch 863/2438  on Training is 66.50390625\n",
            "Epoch #3. Accuracy on batch 864/2438  on Training is 66.5028901734104\n",
            "Epoch #3. Accuracy on batch 865/2438  on Training is 66.49826789838338\n",
            "Epoch #3. Accuracy on batch 866/2438  on Training is 66.49005190311419\n",
            "Epoch #3. Accuracy on batch 867/2438  on Training is 66.49985599078342\n",
            "Epoch #3. Accuracy on batch 868/2438  on Training is 66.50604142692751\n",
            "Epoch #3. Accuracy on batch 869/2438  on Training is 66.5014367816092\n",
            "Epoch #3. Accuracy on batch 870/2438  on Training is 66.50401836969002\n",
            "Epoch #3. Accuracy on batch 871/2438  on Training is 66.50659403669725\n",
            "Epoch #3. Accuracy on batch 872/2438  on Training is 66.50916380297824\n",
            "Epoch #3. Accuracy on batch 873/2438  on Training is 66.51887871853548\n",
            "Epoch #3. Accuracy on batch 874/2438  on Training is 66.525\n",
            "Epoch #3. Accuracy on batch 875/2438  on Training is 66.5418093607306\n",
            "Epoch #3. Accuracy on batch 876/2438  on Training is 66.53363740022805\n",
            "Epoch #3. Accuracy on batch 877/2438  on Training is 66.53616173120729\n",
            "Epoch #3. Accuracy on batch 878/2438  on Training is 66.5386803185438\n",
            "Epoch #3. Accuracy on batch 879/2438  on Training is 66.54474431818181\n",
            "Batch Id 880/2438 is having training loss of 1.2605671882629395\n",
            "1.436419129371643\n",
            "Epoch #3. Accuracy on batch 880/2438  on Training is 66.53660612939841\n",
            "Epoch #3. Accuracy on batch 881/2438  on Training is 66.53202947845806\n",
            "Epoch #3. Accuracy on batch 882/2438  on Training is 66.52746319365798\n",
            "Epoch #3. Accuracy on batch 883/2438  on Training is 66.53351244343891\n",
            "Epoch #3. Accuracy on batch 884/2438  on Training is 66.52895480225989\n",
            "Epoch #3. Accuracy on batch 885/2438  on Training is 66.52793453724605\n",
            "Epoch #3. Accuracy on batch 886/2438  on Training is 66.52691657271703\n",
            "Epoch #3. Accuracy on batch 887/2438  on Training is 66.52942004504504\n",
            "Epoch #3. Accuracy on batch 888/2438  on Training is 66.51785714285714\n",
            "Epoch #3. Accuracy on batch 889/2438  on Training is 66.51334269662921\n",
            "Epoch #3. Accuracy on batch 890/2438  on Training is 66.51936026936026\n",
            "Epoch #3. Accuracy on batch 891/2438  on Training is 66.52536434977578\n",
            "Epoch #3. Accuracy on batch 892/2438  on Training is 66.52435610302352\n",
            "Epoch #3. Accuracy on batch 893/2438  on Training is 66.51635906040268\n",
            "Epoch #3. Accuracy on batch 894/2438  on Training is 66.53631284916202\n",
            "Epoch #3. Accuracy on batch 895/2438  on Training is 66.52483258928571\n",
            "Epoch #3. Accuracy on batch 896/2438  on Training is 66.5133779264214\n",
            "Epoch #3. Accuracy on batch 897/2438  on Training is 66.5228285077951\n",
            "Epoch #3. Accuracy on batch 898/2438  on Training is 66.51835372636262\n",
            "Epoch #3. Accuracy on batch 899/2438  on Training is 66.51736111111111\n",
            "Batch Id 900/2438 is having training loss of 1.2613645792007446\n",
            "1.2979371547698975\n",
            "Epoch #3. Accuracy on batch 900/2438  on Training is 66.52330743618202\n",
            "Epoch #3. Accuracy on batch 901/2438  on Training is 66.52231152993348\n",
            "Epoch #3. Accuracy on batch 902/2438  on Training is 66.50747508305648\n",
            "Epoch #3. Accuracy on batch 903/2438  on Training is 66.51341261061947\n",
            "Epoch #3. Accuracy on batch 904/2438  on Training is 66.51933701657458\n",
            "Epoch #3. Accuracy on batch 905/2438  on Training is 66.51145143487858\n",
            "Epoch #3. Accuracy on batch 906/2438  on Training is 66.51736493936053\n",
            "Epoch #3. Accuracy on batch 907/2438  on Training is 66.5232654185022\n",
            "Epoch #3. Accuracy on batch 908/2438  on Training is 66.52571507150715\n",
            "Epoch #3. Accuracy on batch 909/2438  on Training is 66.51442307692308\n",
            "Epoch #3. Accuracy on batch 910/2438  on Training is 66.52030735455543\n",
            "Epoch #3. Accuracy on batch 911/2438  on Training is 66.51589912280701\n",
            "Epoch #3. Accuracy on batch 912/2438  on Training is 66.50465498357065\n",
            "Epoch #3. Accuracy on batch 913/2438  on Training is 66.50711159737418\n",
            "Epoch #3. Accuracy on batch 914/2438  on Training is 66.49248633879782\n",
            "Epoch #3. Accuracy on batch 915/2438  on Training is 66.50859716157206\n",
            "Epoch #3. Accuracy on batch 916/2438  on Training is 66.51104143947656\n",
            "Epoch #3. Accuracy on batch 917/2438  on Training is 66.52369281045752\n",
            "Epoch #3. Accuracy on batch 918/2438  on Training is 66.51931447225245\n",
            "Epoch #3. Accuracy on batch 919/2438  on Training is 66.51834239130434\n",
            "Batch Id 920/2438 is having training loss of 1.260233998298645\n",
            "0.7004043459892273\n",
            "Epoch #3. Accuracy on batch 920/2438  on Training is 66.53773072747015\n",
            "Epoch #3. Accuracy on batch 921/2438  on Training is 66.52996203904556\n",
            "Epoch #3. Accuracy on batch 922/2438  on Training is 66.53575297941495\n",
            "Epoch #3. Accuracy on batch 923/2438  on Training is 66.53138528138528\n",
            "Epoch #3. Accuracy on batch 924/2438  on Training is 66.54391891891892\n",
            "Epoch #3. Accuracy on batch 925/2438  on Training is 66.54292656587474\n",
            "Epoch #3. Accuracy on batch 926/2438  on Training is 66.54867853290183\n",
            "Epoch #3. Accuracy on batch 927/2438  on Training is 66.55441810344827\n",
            "Epoch #3. Accuracy on batch 928/2438  on Training is 66.56014531754575\n",
            "Epoch #3. Accuracy on batch 929/2438  on Training is 66.55577956989248\n",
            "Epoch #3. Accuracy on batch 930/2438  on Training is 66.54470998925886\n",
            "Epoch #3. Accuracy on batch 931/2438  on Training is 66.56048819742489\n",
            "Epoch #3. Accuracy on batch 932/2438  on Training is 66.55613612004288\n",
            "Epoch #3. Accuracy on batch 933/2438  on Training is 66.54844753747324\n",
            "Epoch #3. Accuracy on batch 934/2438  on Training is 66.54077540106952\n",
            "Epoch #3. Accuracy on batch 935/2438  on Training is 66.53311965811966\n",
            "Epoch #3. Accuracy on batch 936/2438  on Training is 66.53215048025613\n",
            "Epoch #3. Accuracy on batch 937/2438  on Training is 66.53784648187633\n",
            "Epoch #3. Accuracy on batch 938/2438  on Training is 66.53687433439829\n",
            "Epoch #3. Accuracy on batch 939/2438  on Training is 66.52260638297872\n",
            "Batch Id 940/2438 is having training loss of 1.2610942125320435\n",
            "1.450642466545105\n",
            "Epoch #3. Accuracy on batch 940/2438  on Training is 66.5183315621679\n",
            "Epoch #3. Accuracy on batch 941/2438  on Training is 66.52733545647558\n",
            "Epoch #3. Accuracy on batch 942/2438  on Training is 66.52969247083776\n",
            "Epoch #3. Accuracy on batch 943/2438  on Training is 66.52211334745763\n",
            "Epoch #3. Accuracy on batch 944/2438  on Training is 66.51455026455027\n",
            "Epoch #3. Accuracy on batch 945/2438  on Training is 66.52021670190275\n",
            "Epoch #3. Accuracy on batch 946/2438  on Training is 66.52587117212249\n",
            "Epoch #3. Accuracy on batch 947/2438  on Training is 66.52162447257383\n",
            "Epoch #3. Accuracy on batch 948/2438  on Training is 66.52067966280295\n",
            "Epoch #3. Accuracy on batch 949/2438  on Training is 66.51973684210526\n",
            "Epoch #3. Accuracy on batch 950/2438  on Training is 66.5122239747634\n",
            "Epoch #3. Accuracy on batch 951/2438  on Training is 66.5047268907563\n",
            "Epoch #3. Accuracy on batch 952/2438  on Training is 66.50052465897167\n",
            "Epoch #3. Accuracy on batch 953/2438  on Training is 66.49305555555556\n",
            "Epoch #3. Accuracy on batch 954/2438  on Training is 66.49869109947645\n",
            "Epoch #3. Accuracy on batch 955/2438  on Training is 66.50758368200837\n",
            "Epoch #3. Accuracy on batch 956/2438  on Training is 66.49033437826542\n",
            "Epoch #3. Accuracy on batch 957/2438  on Training is 66.49269311064718\n",
            "Epoch #3. Accuracy on batch 958/2438  on Training is 66.4983055265902\n",
            "Epoch #3. Accuracy on batch 959/2438  on Training is 66.48111979166667\n",
            "Batch Id 960/2438 is having training loss of 1.2615165710449219\n",
            "1.2512385845184326\n",
            "Epoch #3. Accuracy on batch 960/2438  on Training is 66.4802289281998\n",
            "Epoch #3. Accuracy on batch 961/2438  on Training is 66.48583679833679\n",
            "Epoch #3. Accuracy on batch 962/2438  on Training is 66.47196261682242\n",
            "Epoch #3. Accuracy on batch 963/2438  on Training is 66.47756742738589\n",
            "Epoch #3. Accuracy on batch 964/2438  on Training is 66.48639896373057\n",
            "Epoch #3. Accuracy on batch 965/2438  on Training is 66.50491718426501\n",
            "Epoch #3. Accuracy on batch 966/2438  on Training is 66.50400723888315\n",
            "Epoch #3. Accuracy on batch 967/2438  on Training is 66.50309917355372\n",
            "Epoch #3. Accuracy on batch 968/2438  on Training is 66.49574303405572\n",
            "Epoch #3. Accuracy on batch 969/2438  on Training is 66.50773195876289\n",
            "Epoch #3. Accuracy on batch 970/2438  on Training is 66.50360453141091\n",
            "Epoch #3. Accuracy on batch 971/2438  on Training is 66.49627057613169\n",
            "Epoch #3. Accuracy on batch 972/2438  on Training is 66.49216341212744\n",
            "Epoch #3. Accuracy on batch 973/2438  on Training is 66.49768993839835\n",
            "Epoch #3. Accuracy on batch 974/2438  on Training is 66.49038461538461\n",
            "Epoch #3. Accuracy on batch 975/2438  on Training is 66.48309426229508\n",
            "Epoch #3. Accuracy on batch 976/2438  on Training is 66.49181166837256\n",
            "Epoch #3. Accuracy on batch 977/2438  on Training is 66.4877300613497\n",
            "Epoch #3. Accuracy on batch 978/2438  on Training is 66.48684882533198\n",
            "Epoch #3. Accuracy on batch 979/2438  on Training is 66.49234693877551\n",
            "Batch Id 980/2438 is having training loss of 1.262130856513977\n",
            "1.6154818534851074\n",
            "Epoch #3. Accuracy on batch 980/2438  on Training is 66.48827726809378\n",
            "Epoch #3. Accuracy on batch 981/2438  on Training is 66.49376272912424\n",
            "Epoch #3. Accuracy on batch 982/2438  on Training is 66.50241607324517\n",
            "Epoch #3. Accuracy on batch 983/2438  on Training is 66.51740345528455\n",
            "Epoch #3. Accuracy on batch 984/2438  on Training is 66.51332487309645\n",
            "Epoch #3. Accuracy on batch 985/2438  on Training is 66.52193204868153\n",
            "Epoch #3. Accuracy on batch 986/2438  on Training is 66.51152482269504\n",
            "Epoch #3. Accuracy on batch 987/2438  on Training is 66.50746457489879\n",
            "Epoch #3. Accuracy on batch 988/2438  on Training is 66.50657229524772\n",
            "Epoch #3. Accuracy on batch 989/2438  on Training is 66.49305555555556\n",
            "Epoch #3. Accuracy on batch 990/2438  on Training is 66.49848637739657\n",
            "Epoch #3. Accuracy on batch 991/2438  on Training is 66.50390625\n",
            "Epoch #3. Accuracy on batch 992/2438  on Training is 66.50616817724068\n",
            "Epoch #3. Accuracy on batch 993/2438  on Training is 66.50842555331992\n",
            "Epoch #3. Accuracy on batch 994/2438  on Training is 66.50125628140704\n",
            "Epoch #3. Accuracy on batch 995/2438  on Training is 66.5035140562249\n",
            "Epoch #3. Accuracy on batch 996/2438  on Training is 66.50890170511535\n",
            "Epoch #3. Accuracy on batch 997/2438  on Training is 66.51427855711422\n",
            "Epoch #3. Accuracy on batch 998/2438  on Training is 66.51338838838839\n",
            "Epoch #3. Accuracy on batch 999/2438  on Training is 66.521875\n",
            "Batch Id 1000/2438 is having training loss of 1.2607519626617432\n",
            "1.0501872301101685\n",
            "Epoch #3. Accuracy on batch 1000/2438  on Training is 66.5241008991009\n",
            "Epoch #3. Accuracy on batch 1001/2438  on Training is 66.52320359281437\n",
            "Epoch #3. Accuracy on batch 1002/2438  on Training is 66.53477068793619\n",
            "Epoch #3. Accuracy on batch 1003/2438  on Training is 66.54942729083665\n",
            "Epoch #3. Accuracy on batch 1004/2438  on Training is 66.5360696517413\n",
            "Epoch #3. Accuracy on batch 1005/2438  on Training is 66.5382703777336\n",
            "Epoch #3. Accuracy on batch 1006/2438  on Training is 66.54046673286992\n",
            "Epoch #3. Accuracy on batch 1007/2438  on Training is 66.53335813492063\n",
            "Epoch #3. Accuracy on batch 1008/2438  on Training is 66.52626362735381\n",
            "Epoch #3. Accuracy on batch 1009/2438  on Training is 66.53465346534654\n",
            "Epoch #3. Accuracy on batch 1010/2438  on Training is 66.5368447082097\n",
            "Epoch #3. Accuracy on batch 1011/2438  on Training is 66.5328557312253\n",
            "Epoch #3. Accuracy on batch 1012/2438  on Training is 66.53812931885489\n",
            "Epoch #3. Accuracy on batch 1013/2438  on Training is 66.54955621301775\n",
            "Epoch #3. Accuracy on batch 1014/2438  on Training is 66.53940886699507\n",
            "Epoch #3. Accuracy on batch 1015/2438  on Training is 66.54773622047244\n",
            "Epoch #3. Accuracy on batch 1016/2438  on Training is 66.54682890855457\n",
            "Epoch #3. Accuracy on batch 1017/2438  on Training is 66.54592337917485\n",
            "Epoch #3. Accuracy on batch 1018/2438  on Training is 66.55421982335623\n",
            "Epoch #3. Accuracy on batch 1019/2438  on Training is 66.5594362745098\n",
            "Batch Id 1020/2438 is having training loss of 1.2604305744171143\n",
            "1.1946344375610352\n",
            "Epoch #3. Accuracy on batch 1020/2438  on Training is 66.55852105778648\n",
            "Epoch #3. Accuracy on batch 1021/2438  on Training is 66.56372309197651\n",
            "Epoch #3. Accuracy on batch 1022/2438  on Training is 66.56891495601172\n",
            "Epoch #3. Accuracy on batch 1023/2438  on Training is 66.56494140625\n",
            "Epoch #3. Accuracy on batch 1024/2438  on Training is 66.5579268292683\n",
            "Epoch #3. Accuracy on batch 1025/2438  on Training is 66.56006335282652\n",
            "Epoch #3. Accuracy on batch 1026/2438  on Training is 66.55306718597858\n",
            "Epoch #3. Accuracy on batch 1027/2438  on Training is 66.5612840466926\n",
            "Epoch #3. Accuracy on batch 1028/2438  on Training is 66.55430029154519\n",
            "Epoch #3. Accuracy on batch 1029/2438  on Training is 66.56553398058253\n",
            "Epoch #3. Accuracy on batch 1030/2438  on Training is 66.57068380213386\n",
            "Epoch #3. Accuracy on batch 1031/2438  on Training is 66.56976744186046\n",
            "Epoch #3. Accuracy on batch 1032/2438  on Training is 66.57187802516941\n",
            "Epoch #3. Accuracy on batch 1033/2438  on Training is 66.57096228239845\n",
            "Epoch #3. Accuracy on batch 1034/2438  on Training is 66.56400966183575\n",
            "Epoch #3. Accuracy on batch 1035/2438  on Training is 66.57516891891892\n",
            "Epoch #3. Accuracy on batch 1036/2438  on Training is 66.5682256509161\n",
            "Epoch #3. Accuracy on batch 1037/2438  on Training is 66.5643063583815\n",
            "Epoch #3. Accuracy on batch 1038/2438  on Training is 66.56641000962463\n",
            "Epoch #3. Accuracy on batch 1039/2438  on Training is 66.57752403846153\n",
            "Batch Id 1040/2438 is having training loss of 1.2598437070846558\n",
            "1.3989379405975342\n",
            "Epoch #3. Accuracy on batch 1040/2438  on Training is 66.57060518731988\n",
            "Epoch #3. Accuracy on batch 1041/2438  on Training is 66.56969769673704\n",
            "Epoch #3. Accuracy on batch 1042/2438  on Training is 66.56879194630872\n",
            "Epoch #3. Accuracy on batch 1043/2438  on Training is 66.57088122605364\n",
            "Epoch #3. Accuracy on batch 1044/2438  on Training is 66.56399521531101\n",
            "Epoch #3. Accuracy on batch 1045/2438  on Training is 66.57504780114722\n",
            "Epoch #3. Accuracy on batch 1046/2438  on Training is 66.57712511938873\n",
            "Epoch #3. Accuracy on batch 1047/2438  on Training is 66.57323473282443\n",
            "Epoch #3. Accuracy on batch 1048/2438  on Training is 66.56339370829362\n",
            "Epoch #3. Accuracy on batch 1049/2438  on Training is 66.57440476190476\n",
            "Epoch #3. Accuracy on batch 1050/2438  on Training is 66.57647478591818\n",
            "Epoch #3. Accuracy on batch 1051/2438  on Training is 66.55774714828897\n",
            "Epoch #3. Accuracy on batch 1052/2438  on Training is 66.53905508072175\n",
            "Epoch #3. Accuracy on batch 1053/2438  on Training is 66.52929316888046\n",
            "Epoch #3. Accuracy on batch 1054/2438  on Training is 66.54028436018957\n",
            "Epoch #3. Accuracy on batch 1055/2438  on Training is 66.53941761363636\n",
            "Epoch #3. Accuracy on batch 1056/2438  on Training is 66.53855250709556\n",
            "Epoch #3. Accuracy on batch 1057/2438  on Training is 66.54655009451795\n",
            "Epoch #3. Accuracy on batch 1058/2438  on Training is 66.55453257790369\n",
            "Epoch #3. Accuracy on batch 1059/2438  on Training is 66.54775943396227\n",
            "Batch Id 1060/2438 is having training loss of 1.2611042261123657\n",
            "0.9527640342712402\n",
            "Epoch #3. Accuracy on batch 1060/2438  on Training is 66.55572573044297\n",
            "Epoch #3. Accuracy on batch 1061/2438  on Training is 66.5636770244821\n",
            "Epoch #3. Accuracy on batch 1062/2438  on Training is 66.56573377234243\n",
            "Epoch #3. Accuracy on batch 1063/2438  on Training is 66.55897556390977\n",
            "Epoch #3. Accuracy on batch 1064/2438  on Training is 66.5669014084507\n",
            "Epoch #3. Accuracy on batch 1065/2438  on Training is 66.58067542213884\n",
            "Epoch #3. Accuracy on batch 1066/2438  on Training is 66.57977975632615\n",
            "Epoch #3. Accuracy on batch 1067/2438  on Training is 66.56718164794007\n",
            "Epoch #3. Accuracy on batch 1068/2438  on Training is 66.55753040224509\n",
            "Epoch #3. Accuracy on batch 1069/2438  on Training is 66.55373831775701\n",
            "Epoch #3. Accuracy on batch 1070/2438  on Training is 66.56746031746032\n",
            "Epoch #3. Accuracy on batch 1071/2438  on Training is 66.57824160447761\n",
            "Epoch #3. Accuracy on batch 1072/2438  on Training is 66.58609040074558\n",
            "Epoch #3. Accuracy on batch 1073/2438  on Training is 66.59101489757914\n",
            "Epoch #3. Accuracy on batch 1074/2438  on Training is 66.59302325581395\n",
            "Epoch #3. Accuracy on batch 1075/2438  on Training is 66.6037407063197\n",
            "Epoch #3. Accuracy on batch 1076/2438  on Training is 66.60283194057567\n",
            "Epoch #3. Accuracy on batch 1077/2438  on Training is 66.59612708719851\n",
            "Epoch #3. Accuracy on batch 1078/2438  on Training is 66.60101946246525\n",
            "Epoch #3. Accuracy on batch 1079/2438  on Training is 66.60590277777777\n",
            "Batch Id 1080/2438 is having training loss of 1.2606265544891357\n",
            "1.1991772651672363\n",
            "Epoch #3. Accuracy on batch 1080/2438  on Training is 66.59921369102683\n",
            "Epoch #3. Accuracy on batch 1081/2438  on Training is 66.59542513863217\n",
            "Epoch #3. Accuracy on batch 1082/2438  on Training is 66.6003000923361\n",
            "Epoch #3. Accuracy on batch 1083/2438  on Training is 66.59363468634686\n",
            "Epoch #3. Accuracy on batch 1084/2438  on Training is 66.60138248847926\n",
            "Epoch #3. Accuracy on batch 1085/2438  on Training is 66.60623848987109\n",
            "Epoch #3. Accuracy on batch 1086/2438  on Training is 66.59671113155474\n",
            "Epoch #3. Accuracy on batch 1087/2438  on Training is 66.59869025735294\n",
            "Epoch #3. Accuracy on batch 1088/2438  on Training is 66.59779614325069\n",
            "Epoch #3. Accuracy on batch 1089/2438  on Training is 66.59690366972477\n",
            "Epoch #3. Accuracy on batch 1090/2438  on Training is 66.60460586617782\n",
            "Epoch #3. Accuracy on batch 1091/2438  on Training is 66.60084706959707\n",
            "Epoch #3. Accuracy on batch 1092/2438  on Training is 66.6056724611162\n",
            "Epoch #3. Accuracy on batch 1093/2438  on Training is 66.6047760511883\n",
            "Epoch #3. Accuracy on batch 1094/2438  on Training is 66.60102739726027\n",
            "Epoch #3. Accuracy on batch 1095/2438  on Training is 66.60583941605839\n",
            "Epoch #3. Accuracy on batch 1096/2438  on Training is 66.60494530537831\n",
            "Epoch #3. Accuracy on batch 1097/2438  on Training is 66.61259107468123\n",
            "Epoch #3. Accuracy on batch 1098/2438  on Training is 66.61737943585078\n",
            "Epoch #3. Accuracy on batch 1099/2438  on Training is 66.6278409090909\n",
            "Batch Id 1100/2438 is having training loss of 1.2598191499710083\n",
            "1.1284968852996826\n",
            "Epoch #3. Accuracy on batch 1100/2438  on Training is 66.63260672116257\n",
            "Epoch #3. Accuracy on batch 1101/2438  on Training is 66.6401996370236\n",
            "Epoch #3. Accuracy on batch 1102/2438  on Training is 66.63927923844062\n",
            "Epoch #3. Accuracy on batch 1103/2438  on Training is 66.63552989130434\n",
            "Epoch #3. Accuracy on batch 1104/2438  on Training is 66.63744343891403\n",
            "Epoch #3. Accuracy on batch 1105/2438  on Training is 66.63087703435805\n",
            "Epoch #3. Accuracy on batch 1106/2438  on Training is 66.62714543812105\n",
            "Epoch #3. Accuracy on batch 1107/2438  on Training is 66.61495938628158\n",
            "Epoch #3. Accuracy on batch 1108/2438  on Training is 66.6197024346258\n",
            "Epoch #3. Accuracy on batch 1109/2438  on Training is 66.62162162162163\n",
            "Epoch #3. Accuracy on batch 1110/2438  on Training is 66.62916291629163\n",
            "Epoch #3. Accuracy on batch 1111/2438  on Training is 66.6226393884892\n",
            "Epoch #3. Accuracy on batch 1112/2438  on Training is 66.6245507637017\n",
            "Epoch #3. Accuracy on batch 1113/2438  on Training is 66.61804308797127\n",
            "Epoch #3. Accuracy on batch 1114/2438  on Training is 66.60874439461884\n",
            "Epoch #3. Accuracy on batch 1115/2438  on Training is 66.61346326164875\n",
            "Epoch #3. Accuracy on batch 1116/2438  on Training is 66.61817367949865\n",
            "Epoch #3. Accuracy on batch 1117/2438  on Training is 66.62287567084078\n",
            "Epoch #3. Accuracy on batch 1118/2438  on Training is 66.61081322609473\n",
            "Epoch #3. Accuracy on batch 1119/2438  on Training is 66.62109375\n",
            "Batch Id 1120/2438 is having training loss of 1.2600711584091187\n",
            "1.1149044036865234\n",
            "Epoch #3. Accuracy on batch 1120/2438  on Training is 66.62299286351472\n",
            "Epoch #3. Accuracy on batch 1121/2438  on Training is 66.613747771836\n",
            "Epoch #3. Accuracy on batch 1122/2438  on Training is 66.61008459483526\n",
            "Epoch #3. Accuracy on batch 1123/2438  on Training is 66.60642793594306\n",
            "Epoch #3. Accuracy on batch 1124/2438  on Training is 66.6138888888889\n",
            "Epoch #3. Accuracy on batch 1125/2438  on Training is 66.61856127886324\n",
            "Epoch #3. Accuracy on batch 1126/2438  on Training is 66.61490683229813\n",
            "Epoch #3. Accuracy on batch 1127/2438  on Training is 66.61679964539007\n",
            "Epoch #3. Accuracy on batch 1128/2438  on Training is 66.60484942426926\n",
            "Epoch #3. Accuracy on batch 1129/2438  on Training is 66.60674778761062\n",
            "Epoch #3. Accuracy on batch 1130/2438  on Training is 66.61416887709991\n",
            "Epoch #3. Accuracy on batch 1131/2438  on Training is 66.61881625441696\n",
            "Epoch #3. Accuracy on batch 1132/2438  on Training is 66.6069064430715\n",
            "Epoch #3. Accuracy on batch 1133/2438  on Training is 66.62533068783068\n",
            "Epoch #3. Accuracy on batch 1134/2438  on Training is 66.6216960352423\n",
            "Epoch #3. Accuracy on batch 1135/2438  on Training is 66.6015625\n",
            "Epoch #3. Accuracy on batch 1136/2438  on Training is 66.60070360598066\n",
            "Epoch #3. Accuracy on batch 1137/2438  on Training is 66.61632249560633\n",
            "Epoch #3. Accuracy on batch 1138/2438  on Training is 66.62093942054433\n",
            "Epoch #3. Accuracy on batch 1139/2438  on Training is 66.60910087719299\n",
            "Batch Id 1140/2438 is having training loss of 1.2612637281417847\n",
            "1.7317440509796143\n",
            "Epoch #3. Accuracy on batch 1140/2438  on Training is 66.60276073619632\n",
            "Epoch #3. Accuracy on batch 1141/2438  on Training is 66.60190455341507\n",
            "Epoch #3. Accuracy on batch 1142/2438  on Training is 66.6065179352581\n",
            "Epoch #3. Accuracy on batch 1143/2438  on Training is 66.61931818181819\n",
            "Epoch #3. Accuracy on batch 1144/2438  on Training is 66.62117903930131\n",
            "Epoch #3. Accuracy on batch 1145/2438  on Training is 66.6203097731239\n",
            "Epoch #3. Accuracy on batch 1146/2438  on Training is 66.6112685265911\n",
            "Epoch #3. Accuracy on batch 1147/2438  on Training is 66.61313153310104\n",
            "Epoch #3. Accuracy on batch 1148/2438  on Training is 66.62587032201915\n",
            "Epoch #3. Accuracy on batch 1149/2438  on Training is 66.62771739130434\n",
            "Epoch #3. Accuracy on batch 1150/2438  on Training is 66.64313640312771\n",
            "Epoch #3. Accuracy on batch 1151/2438  on Training is 66.65310329861111\n",
            "Epoch #3. Accuracy on batch 1152/2438  on Training is 66.64679098005203\n",
            "Epoch #3. Accuracy on batch 1153/2438  on Training is 66.64319757365685\n",
            "Epoch #3. Accuracy on batch 1154/2438  on Training is 66.64231601731602\n",
            "Epoch #3. Accuracy on batch 1155/2438  on Training is 66.64684256055364\n",
            "Epoch #3. Accuracy on batch 1156/2438  on Training is 66.63515557476232\n",
            "Epoch #3. Accuracy on batch 1157/2438  on Training is 66.63698186528498\n",
            "Epoch #3. Accuracy on batch 1158/2438  on Training is 66.64419758412424\n",
            "Epoch #3. Accuracy on batch 1159/2438  on Training is 66.64870689655173\n",
            "Batch Id 1160/2438 is having training loss of 1.2608931064605713\n",
            "1.2693016529083252\n",
            "Epoch #3. Accuracy on batch 1160/2438  on Training is 66.65051679586563\n",
            "Epoch #3. Accuracy on batch 1161/2438  on Training is 66.64694492254733\n",
            "Epoch #3. Accuracy on batch 1162/2438  on Training is 66.64875322441961\n",
            "Epoch #3. Accuracy on batch 1163/2438  on Training is 66.65055841924399\n",
            "Epoch #3. Accuracy on batch 1164/2438  on Training is 66.65504291845494\n",
            "Epoch #3. Accuracy on batch 1165/2438  on Training is 66.65951972555746\n",
            "Epoch #3. Accuracy on batch 1166/2438  on Training is 66.65327763496144\n",
            "Epoch #3. Accuracy on batch 1167/2438  on Training is 66.65774828767124\n",
            "Epoch #3. Accuracy on batch 1168/2438  on Training is 66.6622112917023\n",
            "Epoch #3. Accuracy on batch 1169/2438  on Training is 66.65865384615384\n",
            "Epoch #3. Accuracy on batch 1170/2438  on Training is 66.66577711357814\n",
            "Epoch #3. Accuracy on batch 1171/2438  on Training is 66.65688993174061\n",
            "Epoch #3. Accuracy on batch 1172/2438  on Training is 66.6506820119352\n",
            "Epoch #3. Accuracy on batch 1173/2438  on Training is 66.65247018739353\n",
            "Epoch #3. Accuracy on batch 1174/2438  on Training is 66.65159574468085\n",
            "Epoch #3. Accuracy on batch 1175/2438  on Training is 66.65338010204081\n",
            "Epoch #3. Accuracy on batch 1176/2438  on Training is 66.64454120645709\n",
            "Epoch #3. Accuracy on batch 1177/2438  on Training is 66.6463285229202\n",
            "Epoch #3. Accuracy on batch 1178/2438  on Training is 66.6428117048346\n",
            "Epoch #3. Accuracy on batch 1179/2438  on Training is 66.63930084745763\n",
            "Batch Id 1180/2438 is having training loss of 1.2608641386032104\n",
            "1.0912178754806519\n",
            "Epoch #3. Accuracy on batch 1180/2438  on Training is 66.64108806096529\n",
            "Epoch #3. Accuracy on batch 1181/2438  on Training is 66.64287225042301\n",
            "Epoch #3. Accuracy on batch 1182/2438  on Training is 66.64993660185968\n",
            "Epoch #3. Accuracy on batch 1183/2438  on Training is 66.66226773648648\n",
            "Epoch #3. Accuracy on batch 1184/2438  on Training is 66.65611814345992\n",
            "Epoch #3. Accuracy on batch 1185/2438  on Training is 66.65261382799325\n",
            "Epoch #3. Accuracy on batch 1186/2438  on Training is 66.65174810446504\n",
            "Epoch #3. Accuracy on batch 1187/2438  on Training is 66.6535143097643\n",
            "Epoch #3. Accuracy on batch 1188/2438  on Training is 66.65002102607232\n",
            "Epoch #3. Accuracy on batch 1189/2438  on Training is 66.65441176470588\n",
            "Epoch #3. Accuracy on batch 1190/2438  on Training is 66.65879513014274\n",
            "Epoch #3. Accuracy on batch 1191/2438  on Training is 66.65006291946308\n",
            "Epoch #3. Accuracy on batch 1192/2438  on Training is 66.63872590108969\n",
            "Epoch #3. Accuracy on batch 1193/2438  on Training is 66.64311139028476\n",
            "Epoch #3. Accuracy on batch 1194/2438  on Training is 66.63964435146444\n",
            "Epoch #3. Accuracy on batch 1195/2438  on Training is 66.64140886287625\n",
            "Epoch #3. Accuracy on batch 1196/2438  on Training is 66.64578111946533\n",
            "Epoch #3. Accuracy on batch 1197/2438  on Training is 66.63449499165276\n",
            "Epoch #3. Accuracy on batch 1198/2438  on Training is 66.63886572143453\n",
            "Epoch #3. Accuracy on batch 1199/2438  on Training is 66.62760416666667\n",
            "Batch Id 1200/2438 is having training loss of 1.2611757516860962\n",
            "1.1165663003921509\n",
            "Epoch #3. Accuracy on batch 1200/2438  on Training is 66.6267693588676\n",
            "Epoch #3. Accuracy on batch 1201/2438  on Training is 66.62853577371048\n",
            "Epoch #3. Accuracy on batch 1202/2438  on Training is 66.63029925187033\n",
            "Epoch #3. Accuracy on batch 1203/2438  on Training is 66.63984634551495\n",
            "Epoch #3. Accuracy on batch 1204/2438  on Training is 66.64419087136929\n",
            "Epoch #3. Accuracy on batch 1205/2438  on Training is 66.64334577114428\n",
            "Epoch #3. Accuracy on batch 1206/2438  on Training is 66.6554473902237\n",
            "Epoch #3. Accuracy on batch 1207/2438  on Training is 66.65976821192054\n",
            "Epoch #3. Accuracy on batch 1208/2438  on Training is 66.66666666666667\n",
            "Epoch #3. Accuracy on batch 1209/2438  on Training is 66.67613636363636\n",
            "Epoch #3. Accuracy on batch 1210/2438  on Training is 66.66752683732453\n",
            "Epoch #3. Accuracy on batch 1211/2438  on Training is 66.67182343234323\n",
            "Epoch #3. Accuracy on batch 1212/2438  on Training is 66.66323165704864\n",
            "Epoch #3. Accuracy on batch 1213/2438  on Training is 66.66237644151565\n",
            "Epoch #3. Accuracy on batch 1214/2438  on Training is 66.67438271604938\n",
            "Epoch #3. Accuracy on batch 1215/2438  on Training is 66.67094983552632\n",
            "Epoch #3. Accuracy on batch 1216/2438  on Training is 66.66495480690222\n",
            "Epoch #3. Accuracy on batch 1217/2438  on Training is 66.6564039408867\n",
            "Epoch #3. Accuracy on batch 1218/2438  on Training is 66.64786710418376\n",
            "Epoch #3. Accuracy on batch 1219/2438  on Training is 66.63934426229508\n",
            "Batch Id 1220/2438 is having training loss of 1.259960412979126\n",
            "1.162369728088379\n",
            "Epoch #3. Accuracy on batch 1220/2438  on Training is 66.64363226863227\n",
            "Epoch #3. Accuracy on batch 1221/2438  on Training is 66.63768412438625\n",
            "Epoch #3. Accuracy on batch 1222/2438  on Training is 66.62152493867539\n",
            "Epoch #3. Accuracy on batch 1223/2438  on Training is 66.6156045751634\n",
            "Epoch #3. Accuracy on batch 1224/2438  on Training is 66.60714285714286\n",
            "Epoch #3. Accuracy on batch 1225/2438  on Training is 66.59869494290375\n",
            "Epoch #3. Accuracy on batch 1226/2438  on Training is 66.59790138549307\n",
            "Epoch #3. Accuracy on batch 1227/2438  on Training is 66.60474348534201\n",
            "Epoch #3. Accuracy on batch 1228/2438  on Training is 66.60903173311635\n",
            "Epoch #3. Accuracy on batch 1229/2438  on Training is 66.60315040650407\n",
            "Epoch #3. Accuracy on batch 1230/2438  on Training is 66.60489439480098\n",
            "Epoch #3. Accuracy on batch 1231/2438  on Training is 66.62439123376623\n",
            "Epoch #3. Accuracy on batch 1232/2438  on Training is 66.63118410381185\n",
            "Epoch #3. Accuracy on batch 1233/2438  on Training is 66.62783630470017\n",
            "Epoch #3. Accuracy on batch 1234/2438  on Training is 66.6244939271255\n",
            "Epoch #3. Accuracy on batch 1235/2438  on Training is 66.63127022653721\n",
            "Epoch #3. Accuracy on batch 1236/2438  on Training is 66.63298302344381\n",
            "Epoch #3. Accuracy on batch 1237/2438  on Training is 66.63721728594507\n",
            "Epoch #3. Accuracy on batch 1238/2438  on Training is 66.6338781275222\n",
            "Epoch #3. Accuracy on batch 1239/2438  on Training is 66.63558467741936\n",
            "Batch Id 1240/2438 is having training loss of 1.2609466314315796\n",
            "1.3170218467712402\n",
            "Epoch #3. Accuracy on batch 1240/2438  on Training is 66.63477034649476\n",
            "Epoch #3. Accuracy on batch 1241/2438  on Training is 66.64150563607086\n",
            "Epoch #3. Accuracy on batch 1242/2438  on Training is 66.64571600965407\n",
            "Epoch #3. Accuracy on batch 1243/2438  on Training is 66.63233520900322\n",
            "Epoch #3. Accuracy on batch 1244/2438  on Training is 66.63654618473896\n",
            "Epoch #3. Accuracy on batch 1245/2438  on Training is 66.64075040128411\n",
            "Epoch #3. Accuracy on batch 1246/2438  on Training is 66.64244186046511\n",
            "Epoch #3. Accuracy on batch 1247/2438  on Training is 66.64413060897436\n",
            "Epoch #3. Accuracy on batch 1248/2438  on Training is 66.64581665332265\n",
            "Epoch #3. Accuracy on batch 1249/2438  on Training is 66.65\n",
            "Epoch #3. Accuracy on batch 1250/2438  on Training is 66.66167066346922\n",
            "Epoch #3. Accuracy on batch 1251/2438  on Training is 66.66333865814697\n",
            "Epoch #3. Accuracy on batch 1252/2438  on Training is 66.66999201915404\n",
            "Epoch #3. Accuracy on batch 1253/2438  on Training is 66.67663476874003\n",
            "Epoch #3. Accuracy on batch 1254/2438  on Training is 66.67330677290836\n",
            "Epoch #3. Accuracy on batch 1255/2438  on Training is 66.68242436305732\n",
            "Epoch #3. Accuracy on batch 1256/2438  on Training is 66.67661097852029\n",
            "Epoch #3. Accuracy on batch 1257/2438  on Training is 66.67577503974563\n",
            "Epoch #3. Accuracy on batch 1258/2438  on Training is 66.66749404289118\n",
            "Epoch #3. Accuracy on batch 1259/2438  on Training is 66.67410714285714\n",
            "Batch Id 1260/2438 is having training loss of 1.2596098184585571\n",
            "0.8581870198249817\n",
            "Epoch #3. Accuracy on batch 1260/2438  on Training is 66.68566613798572\n",
            "Epoch #3. Accuracy on batch 1261/2438  on Training is 66.67987321711568\n",
            "Epoch #3. Accuracy on batch 1262/2438  on Training is 66.68151227236739\n",
            "Epoch #3. Accuracy on batch 1263/2438  on Training is 66.67573180379746\n",
            "Epoch #3. Accuracy on batch 1264/2438  on Training is 66.65760869565217\n",
            "Epoch #3. Accuracy on batch 1265/2438  on Training is 66.65679304897314\n",
            "Epoch #3. Accuracy on batch 1266/2438  on Training is 66.66091160220995\n",
            "Epoch #3. Accuracy on batch 1267/2438  on Training is 66.66502365930599\n",
            "Epoch #3. Accuracy on batch 1268/2438  on Training is 66.66666666666667\n",
            "Epoch #3. Accuracy on batch 1269/2438  on Training is 66.66584645669292\n",
            "Epoch #3. Accuracy on batch 1270/2438  on Training is 66.66502753737215\n",
            "Epoch #3. Accuracy on batch 1271/2438  on Training is 66.66912342767296\n",
            "Epoch #3. Accuracy on batch 1272/2438  on Training is 66.67321288295365\n",
            "Epoch #3. Accuracy on batch 1273/2438  on Training is 66.67729591836735\n",
            "Epoch #3. Accuracy on batch 1274/2438  on Training is 66.67401960784314\n",
            "Epoch #3. Accuracy on batch 1275/2438  on Training is 66.67809561128527\n",
            "Epoch #3. Accuracy on batch 1276/2438  on Training is 66.68705951448707\n",
            "Epoch #3. Accuracy on batch 1277/2438  on Training is 66.68378325508607\n",
            "Epoch #3. Accuracy on batch 1278/2438  on Training is 66.68295543393276\n",
            "Epoch #3. Accuracy on batch 1279/2438  on Training is 66.68212890625\n",
            "Batch Id 1280/2438 is having training loss of 1.2603042125701904\n",
            "1.1284725666046143\n",
            "Epoch #3. Accuracy on batch 1280/2438  on Training is 66.68862217017954\n",
            "Epoch #3. Accuracy on batch 1281/2438  on Training is 66.68535491419657\n",
            "Epoch #3. Accuracy on batch 1282/2438  on Training is 66.68452844894777\n",
            "Epoch #3. Accuracy on batch 1283/2438  on Training is 66.69343847352025\n",
            "Epoch #3. Accuracy on batch 1284/2438  on Training is 66.7023346303502\n",
            "Epoch #3. Accuracy on batch 1285/2438  on Training is 66.69906687402799\n",
            "Epoch #3. Accuracy on batch 1286/2438  on Training is 66.6958041958042\n",
            "Epoch #3. Accuracy on batch 1287/2438  on Training is 66.699825310559\n",
            "Epoch #3. Accuracy on batch 1288/2438  on Training is 66.70868890612878\n",
            "Epoch #3. Accuracy on batch 1289/2438  on Training is 66.69815891472868\n",
            "Epoch #3. Accuracy on batch 1290/2438  on Training is 66.69490704879938\n",
            "Epoch #3. Accuracy on batch 1291/2438  on Training is 66.68924148606811\n",
            "Epoch #3. Accuracy on batch 1292/2438  on Training is 66.68841840680588\n",
            "Epoch #3. Accuracy on batch 1293/2438  on Training is 66.67793663060279\n",
            "Epoch #3. Accuracy on batch 1294/2438  on Training is 66.67229729729729\n",
            "Epoch #3. Accuracy on batch 1295/2438  on Training is 66.67872299382717\n",
            "Epoch #3. Accuracy on batch 1296/2438  on Training is 66.68754818812644\n",
            "Epoch #3. Accuracy on batch 1297/2438  on Training is 66.68913713405239\n",
            "Epoch #3. Accuracy on batch 1298/2438  on Training is 66.69072363356428\n",
            "Epoch #3. Accuracy on batch 1299/2438  on Training is 66.68990384615384\n",
            "Batch Id 1300/2438 is having training loss of 1.2599048614501953\n",
            "0.8776547908782959\n",
            "Epoch #3. Accuracy on batch 1300/2438  on Training is 66.69869331283628\n",
            "Epoch #3. Accuracy on batch 1301/2438  on Training is 66.69546850998464\n",
            "Epoch #3. Accuracy on batch 1302/2438  on Training is 66.70663852647736\n",
            "Epoch #3. Accuracy on batch 1303/2438  on Training is 66.7082055214724\n",
            "Epoch #3. Accuracy on batch 1304/2438  on Training is 66.70258620689656\n",
            "Epoch #3. Accuracy on batch 1305/2438  on Training is 66.70654670750383\n",
            "Epoch #3. Accuracy on batch 1306/2438  on Training is 66.69137337413925\n",
            "Epoch #3. Accuracy on batch 1307/2438  on Training is 66.68100152905198\n",
            "Epoch #3. Accuracy on batch 1308/2438  on Training is 66.68735676088617\n",
            "Epoch #3. Accuracy on batch 1309/2438  on Training is 66.68416030534351\n",
            "Epoch #3. Accuracy on batch 1310/2438  on Training is 66.68573607932876\n",
            "Epoch #3. Accuracy on batch 1311/2438  on Training is 66.6920731707317\n",
            "Epoch #3. Accuracy on batch 1312/2438  on Training is 66.67936024371667\n",
            "Epoch #3. Accuracy on batch 1313/2438  on Training is 66.68093607305936\n",
            "Epoch #3. Accuracy on batch 1314/2438  on Training is 66.67775665399239\n",
            "Epoch #3. Accuracy on batch 1315/2438  on Training is 66.68170592705167\n",
            "Epoch #3. Accuracy on batch 1316/2438  on Training is 66.68564920273349\n",
            "Epoch #3. Accuracy on batch 1317/2438  on Training is 66.6801024279211\n",
            "Epoch #3. Accuracy on batch 1318/2438  on Training is 66.68404094010614\n",
            "Epoch #3. Accuracy on batch 1319/2438  on Training is 66.69507575757575\n",
            "Batch Id 1320/2438 is having training loss of 1.2586605548858643\n",
            "1.0043145418167114\n",
            "Epoch #3. Accuracy on batch 1320/2438  on Training is 66.70136260408782\n",
            "Epoch #3. Accuracy on batch 1321/2438  on Training is 66.7123676248109\n",
            "Epoch #3. Accuracy on batch 1322/2438  on Training is 66.72099395313681\n",
            "Epoch #3. Accuracy on batch 1323/2438  on Training is 66.7296072507553\n",
            "Epoch #3. Accuracy on batch 1324/2438  on Training is 66.72641509433963\n",
            "Epoch #3. Accuracy on batch 1325/2438  on Training is 66.7279411764706\n",
            "Epoch #3. Accuracy on batch 1326/2438  on Training is 66.71533534287867\n",
            "Epoch #3. Accuracy on batch 1327/2438  on Training is 66.70980798192771\n",
            "Epoch #3. Accuracy on batch 1328/2438  on Training is 66.71369450714823\n",
            "Epoch #3. Accuracy on batch 1329/2438  on Training is 66.71522556390977\n",
            "Epoch #3. Accuracy on batch 1330/2438  on Training is 66.72145003756575\n",
            "Epoch #3. Accuracy on batch 1331/2438  on Training is 66.72062687687688\n",
            "Epoch #3. Accuracy on batch 1332/2438  on Training is 66.72683795948987\n",
            "Epoch #3. Accuracy on batch 1333/2438  on Training is 66.72366941529235\n",
            "Epoch #3. Accuracy on batch 1334/2438  on Training is 66.7251872659176\n",
            "Epoch #3. Accuracy on batch 1335/2438  on Training is 66.72904191616766\n",
            "Epoch #3. Accuracy on batch 1336/2438  on Training is 66.72354151084518\n",
            "Epoch #3. Accuracy on batch 1337/2438  on Training is 66.71804932735427\n",
            "Epoch #3. Accuracy on batch 1338/2438  on Training is 66.72423450336072\n",
            "Epoch #3. Accuracy on batch 1339/2438  on Training is 66.72807835820896\n",
            "Batch Id 1340/2438 is having training loss of 1.2579506635665894\n",
            "0.8173566460609436\n",
            "Epoch #3. Accuracy on batch 1340/2438  on Training is 66.73191648023862\n",
            "Epoch #3. Accuracy on batch 1341/2438  on Training is 66.7310916542474\n",
            "Epoch #3. Accuracy on batch 1342/2438  on Training is 66.73026805658972\n",
            "Epoch #3. Accuracy on batch 1343/2438  on Training is 66.73642113095238\n",
            "Epoch #3. Accuracy on batch 1344/2438  on Training is 66.74721189591078\n",
            "Epoch #3. Accuracy on batch 1345/2438  on Training is 66.74405646359584\n",
            "Epoch #3. Accuracy on batch 1346/2438  on Training is 66.74322568671121\n",
            "Epoch #3. Accuracy on batch 1347/2438  on Training is 66.74935089020771\n",
            "Epoch #3. Accuracy on batch 1348/2438  on Training is 66.74851742031134\n",
            "Epoch #3. Accuracy on batch 1349/2438  on Training is 66.73842592592592\n",
            "Epoch #3. Accuracy on batch 1350/2438  on Training is 66.74454108068097\n",
            "Epoch #3. Accuracy on batch 1351/2438  on Training is 66.74833579881657\n",
            "Epoch #3. Accuracy on batch 1352/2438  on Training is 66.74981522542498\n",
            "Epoch #3. Accuracy on batch 1353/2438  on Training is 66.75590841949779\n",
            "Epoch #3. Accuracy on batch 1354/2438  on Training is 66.7619926199262\n",
            "Epoch #3. Accuracy on batch 1355/2438  on Training is 66.75884955752213\n",
            "Epoch #3. Accuracy on batch 1356/2438  on Training is 66.7557111274871\n",
            "Epoch #3. Accuracy on batch 1357/2438  on Training is 66.75487849779087\n",
            "Epoch #3. Accuracy on batch 1358/2438  on Training is 66.75864606328183\n",
            "Epoch #3. Accuracy on batch 1359/2438  on Training is 66.75321691176471\n",
            "Batch Id 1360/2438 is having training loss of 1.2570044994354248\n",
            "1.092422604560852\n",
            "Epoch #3. Accuracy on batch 1360/2438  on Training is 66.76157237325496\n",
            "Epoch #3. Accuracy on batch 1361/2438  on Training is 66.76073788546256\n",
            "Epoch #3. Accuracy on batch 1362/2438  on Training is 66.75990462215701\n",
            "Epoch #3. Accuracy on batch 1363/2438  on Training is 66.75907258064517\n",
            "Epoch #3. Accuracy on batch 1364/2438  on Training is 66.75824175824175\n",
            "Epoch #3. Accuracy on batch 1365/2438  on Training is 66.76198755490483\n",
            "Epoch #3. Accuracy on batch 1366/2438  on Training is 66.75429773226043\n",
            "Epoch #3. Accuracy on batch 1367/2438  on Training is 66.76032529239767\n",
            "Epoch #3. Accuracy on batch 1368/2438  on Training is 66.76406135865595\n",
            "Epoch #3. Accuracy on batch 1369/2438  on Training is 66.77007299270073\n",
            "Epoch #3. Accuracy on batch 1370/2438  on Training is 66.7692377826404\n",
            "Epoch #3. Accuracy on batch 1371/2438  on Training is 66.77295918367346\n",
            "Epoch #3. Accuracy on batch 1372/2438  on Training is 66.77667516387473\n",
            "Epoch #3. Accuracy on batch 1373/2438  on Training is 66.77583697234353\n",
            "Epoch #3. Accuracy on batch 1374/2438  on Training is 66.77272727272727\n",
            "Epoch #3. Accuracy on batch 1375/2438  on Training is 66.76735101744185\n",
            "Epoch #3. Accuracy on batch 1376/2438  on Training is 66.77106027596224\n",
            "Epoch #3. Accuracy on batch 1377/2438  on Training is 66.76796081277213\n",
            "Epoch #3. Accuracy on batch 1378/2438  on Training is 66.76033357505439\n",
            "Epoch #3. Accuracy on batch 1379/2438  on Training is 66.7572463768116\n",
            "Batch Id 1380/2438 is having training loss of 1.2571220397949219\n",
            "1.5355511903762817\n",
            "Epoch #3. Accuracy on batch 1380/2438  on Training is 66.74963794351919\n",
            "Epoch #3. Accuracy on batch 1381/2438  on Training is 66.75560781476122\n",
            "Epoch #3. Accuracy on batch 1382/2438  on Training is 66.7547903109183\n",
            "Epoch #3. Accuracy on batch 1383/2438  on Training is 66.75171604046243\n",
            "Epoch #3. Accuracy on batch 1384/2438  on Training is 66.75090252707581\n",
            "Epoch #3. Accuracy on batch 1385/2438  on Training is 66.7478354978355\n",
            "Epoch #3. Accuracy on batch 1386/2438  on Training is 66.75153208363375\n",
            "Epoch #3. Accuracy on batch 1387/2438  on Training is 66.74396613832853\n",
            "Epoch #3. Accuracy on batch 1388/2438  on Training is 66.74091072714182\n",
            "Epoch #3. Accuracy on batch 1389/2438  on Training is 66.74460431654676\n",
            "Epoch #3. Accuracy on batch 1390/2438  on Training is 66.74155283968368\n",
            "Epoch #3. Accuracy on batch 1391/2438  on Training is 66.7407507183908\n",
            "Epoch #3. Accuracy on batch 1392/2438  on Training is 66.74667982770998\n",
            "Epoch #3. Accuracy on batch 1393/2438  on Training is 66.74811692969871\n",
            "Epoch #3. Accuracy on batch 1394/2438  on Training is 66.75179211469533\n",
            "Epoch #3. Accuracy on batch 1395/2438  on Training is 66.75546203438395\n",
            "Epoch #3. Accuracy on batch 1396/2438  on Training is 66.74794201861131\n",
            "Epoch #3. Accuracy on batch 1397/2438  on Training is 66.75608011444922\n",
            "Epoch #3. Accuracy on batch 1398/2438  on Training is 66.75973909935668\n",
            "Epoch #3. Accuracy on batch 1399/2438  on Training is 66.76116071428571\n",
            "Batch Id 1400/2438 is having training loss of 1.25602126121521\n",
            "0.8723617792129517\n",
            "Epoch #3. Accuracy on batch 1400/2438  on Training is 66.76927194860814\n",
            "Epoch #3. Accuracy on batch 1401/2438  on Training is 66.77291369472182\n",
            "Epoch #3. Accuracy on batch 1402/2438  on Training is 66.77209550962223\n",
            "Epoch #3. Accuracy on batch 1403/2438  on Training is 66.78018162393163\n",
            "Epoch #3. Accuracy on batch 1404/2438  on Training is 66.77935943060498\n",
            "Epoch #3. Accuracy on batch 1405/2438  on Training is 66.7696479374111\n",
            "Epoch #3. Accuracy on batch 1406/2438  on Training is 66.76217128642502\n",
            "Epoch #3. Accuracy on batch 1407/2438  on Training is 66.7635830965909\n",
            "Epoch #3. Accuracy on batch 1408/2438  on Training is 66.7583392476934\n",
            "Epoch #3. Accuracy on batch 1409/2438  on Training is 66.74645390070921\n",
            "Epoch #3. Accuracy on batch 1410/2438  on Training is 66.75230333097095\n",
            "Epoch #3. Accuracy on batch 1411/2438  on Training is 66.75371813031161\n",
            "Epoch #3. Accuracy on batch 1412/2438  on Training is 66.75513092710545\n",
            "Epoch #3. Accuracy on batch 1413/2438  on Training is 66.76980198019803\n",
            "Epoch #3. Accuracy on batch 1414/2438  on Training is 66.76236749116607\n",
            "Epoch #3. Accuracy on batch 1415/2438  on Training is 66.76156426553672\n",
            "Epoch #3. Accuracy on batch 1416/2438  on Training is 66.76076217360621\n",
            "Epoch #3. Accuracy on batch 1417/2438  on Training is 66.75775740479548\n",
            "Epoch #3. Accuracy on batch 1418/2438  on Training is 66.75475687103594\n",
            "Epoch #3. Accuracy on batch 1419/2438  on Training is 66.75836267605634\n",
            "Batch Id 1420/2438 is having training loss of 1.255384087562561\n",
            "0.9345363974571228\n",
            "Epoch #3. Accuracy on batch 1420/2438  on Training is 66.76416256157636\n",
            "Epoch #3. Accuracy on batch 1421/2438  on Training is 66.75896624472574\n",
            "Epoch #3. Accuracy on batch 1422/2438  on Training is 66.76256148981027\n",
            "Epoch #3. Accuracy on batch 1423/2438  on Training is 66.76834620786516\n",
            "Epoch #3. Accuracy on batch 1424/2438  on Training is 66.76754385964912\n",
            "Epoch #3. Accuracy on batch 1425/2438  on Training is 66.77331697054699\n",
            "Epoch #3. Accuracy on batch 1426/2438  on Training is 66.76594253679048\n",
            "Epoch #3. Accuracy on batch 1427/2438  on Training is 66.76952030812325\n",
            "Epoch #3. Accuracy on batch 1428/2438  on Training is 66.77746675997201\n",
            "Epoch #3. Accuracy on batch 1429/2438  on Training is 66.78321678321679\n",
            "Epoch #3. Accuracy on batch 1430/2438  on Training is 66.78022361984627\n",
            "Epoch #3. Accuracy on batch 1431/2438  on Training is 66.77941689944134\n",
            "Epoch #3. Accuracy on batch 1432/2438  on Training is 66.77861130495464\n",
            "Epoch #3. Accuracy on batch 1433/2438  on Training is 66.77998605299861\n",
            "Epoch #3. Accuracy on batch 1434/2438  on Training is 66.77482578397212\n",
            "Epoch #3. Accuracy on batch 1435/2438  on Training is 66.78272980501393\n",
            "Epoch #3. Accuracy on batch 1436/2438  on Training is 66.78192414752958\n",
            "Epoch #3. Accuracy on batch 1437/2438  on Training is 66.77677329624478\n",
            "Epoch #3. Accuracy on batch 1438/2438  on Training is 66.77380125086866\n",
            "Epoch #3. Accuracy on batch 1439/2438  on Training is 66.77083333333333\n",
            "Batch Id 1440/2438 is having training loss of 1.256317138671875\n",
            "1.2429239749908447\n",
            "Epoch #3. Accuracy on batch 1440/2438  on Training is 66.77220680083275\n",
            "Epoch #3. Accuracy on batch 1441/2438  on Training is 66.76924410540916\n",
            "Epoch #3. Accuracy on batch 1442/2438  on Training is 66.77494802494803\n",
            "Epoch #3. Accuracy on batch 1443/2438  on Training is 66.77415166204986\n",
            "Epoch #3. Accuracy on batch 1444/2438  on Training is 66.77551903114187\n",
            "Epoch #3. Accuracy on batch 1445/2438  on Training is 66.78336791147994\n",
            "Epoch #3. Accuracy on batch 1446/2438  on Training is 66.78256738078784\n",
            "Epoch #3. Accuracy on batch 1447/2438  on Training is 66.77745165745857\n",
            "Epoch #3. Accuracy on batch 1448/2438  on Training is 66.77881297446515\n",
            "Epoch #3. Accuracy on batch 1449/2438  on Training is 66.77801724137932\n",
            "Epoch #3. Accuracy on batch 1450/2438  on Training is 66.7815299793246\n",
            "Epoch #3. Accuracy on batch 1451/2438  on Training is 66.78288567493112\n",
            "Epoch #3. Accuracy on batch 1452/2438  on Training is 66.79499311768754\n",
            "Epoch #3. Accuracy on batch 1453/2438  on Training is 66.79633768913342\n",
            "Epoch #3. Accuracy on batch 1454/2438  on Training is 66.79338487972508\n",
            "Epoch #3. Accuracy on batch 1455/2438  on Training is 66.79472870879121\n",
            "Epoch #3. Accuracy on batch 1456/2438  on Training is 66.79178105696637\n",
            "Epoch #3. Accuracy on batch 1457/2438  on Training is 66.79526748971193\n",
            "Epoch #3. Accuracy on batch 1458/2438  on Training is 66.79660726525017\n",
            "Epoch #3. Accuracy on batch 1459/2438  on Training is 66.79794520547945\n",
            "Batch Id 1460/2438 is having training loss of 1.2548247575759888\n",
            "1.4484885931015015\n",
            "Epoch #3. Accuracy on batch 1460/2438  on Training is 66.79286447638604\n",
            "Epoch #3. Accuracy on batch 1461/2438  on Training is 66.7984781121751\n",
            "Epoch #3. Accuracy on batch 1462/2438  on Training is 66.7934039644566\n",
            "Epoch #3. Accuracy on batch 1463/2438  on Training is 66.79474043715847\n",
            "Epoch #3. Accuracy on batch 1464/2438  on Training is 66.79394197952219\n",
            "Epoch #3. Accuracy on batch 1465/2438  on Training is 66.7931446111869\n",
            "Epoch #3. Accuracy on batch 1466/2438  on Training is 66.79873892297205\n",
            "Epoch #3. Accuracy on batch 1467/2438  on Training is 66.797939373297\n",
            "Epoch #3. Accuracy on batch 1468/2438  on Training is 66.79501361470388\n",
            "Epoch #3. Accuracy on batch 1469/2438  on Training is 66.78784013605443\n",
            "Epoch #3. Accuracy on batch 1470/2438  on Training is 66.79767165193746\n",
            "Epoch #3. Accuracy on batch 1471/2438  on Training is 66.79050611413044\n",
            "Epoch #3. Accuracy on batch 1472/2438  on Training is 66.7897148676171\n",
            "Epoch #3. Accuracy on batch 1473/2438  on Training is 66.78680461329715\n",
            "Epoch #3. Accuracy on batch 1474/2438  on Training is 66.79661016949153\n",
            "Epoch #3. Accuracy on batch 1475/2438  on Training is 66.79581639566396\n",
            "Epoch #3. Accuracy on batch 1476/2438  on Training is 66.80348679756263\n",
            "Epoch #3. Accuracy on batch 1477/2438  on Training is 66.80903247631935\n",
            "Epoch #3. Accuracy on batch 1478/2438  on Training is 66.80611899932387\n",
            "Epoch #3. Accuracy on batch 1479/2438  on Training is 66.80532094594595\n",
            "Batch Id 1480/2438 is having training loss of 1.254616379737854\n",
            "1.0377986431121826\n",
            "Epoch #3. Accuracy on batch 1480/2438  on Training is 66.81085415259959\n",
            "Epoch #3. Accuracy on batch 1481/2438  on Training is 66.81637989203779\n",
            "Epoch #3. Accuracy on batch 1482/2438  on Training is 66.82400539447067\n",
            "Epoch #3. Accuracy on batch 1483/2438  on Training is 66.82530323450135\n",
            "Epoch #3. Accuracy on batch 1484/2438  on Training is 66.82870370370371\n",
            "Epoch #3. Accuracy on batch 1485/2438  on Training is 66.82158479138627\n",
            "Epoch #3. Accuracy on batch 1486/2438  on Training is 66.82288164088769\n",
            "Epoch #3. Accuracy on batch 1487/2438  on Training is 66.82837701612904\n",
            "Epoch #3. Accuracy on batch 1488/2438  on Training is 66.82966756212222\n",
            "Epoch #3. Accuracy on batch 1489/2438  on Training is 66.83305369127517\n",
            "Epoch #3. Accuracy on batch 1490/2438  on Training is 66.83643527833668\n",
            "Epoch #3. Accuracy on batch 1491/2438  on Training is 66.84609584450402\n",
            "Epoch #3. Accuracy on batch 1492/2438  on Training is 66.84109176155391\n",
            "Epoch #3. Accuracy on batch 1493/2438  on Training is 66.83818607764391\n",
            "Epoch #3. Accuracy on batch 1494/2438  on Training is 66.84364548494983\n",
            "Epoch #3. Accuracy on batch 1495/2438  on Training is 66.84074197860963\n",
            "Epoch #3. Accuracy on batch 1496/2438  on Training is 66.84201736806948\n",
            "Epoch #3. Accuracy on batch 1497/2438  on Training is 66.84329105473965\n",
            "Epoch #3. Accuracy on batch 1498/2438  on Training is 66.8341394262842\n",
            "Epoch #3. Accuracy on batch 1499/2438  on Training is 66.8375\n",
            "Batch Id 1500/2438 is having training loss of 1.253976583480835\n",
            "1.45112943649292\n",
            "Epoch #3. Accuracy on batch 1500/2438  on Training is 66.8387741505663\n",
            "Epoch #3. Accuracy on batch 1501/2438  on Training is 66.83588548601864\n",
            "Epoch #3. Accuracy on batch 1502/2438  on Training is 66.83507984031937\n",
            "Epoch #3. Accuracy on batch 1503/2438  on Training is 66.82804188829788\n",
            "Epoch #3. Accuracy on batch 1504/2438  on Training is 66.82101328903654\n",
            "Epoch #3. Accuracy on batch 1505/2438  on Training is 66.83059428950864\n",
            "Epoch #3. Accuracy on batch 1506/2438  on Training is 66.82772063702721\n",
            "Epoch #3. Accuracy on batch 1507/2438  on Training is 66.82277851458886\n",
            "Epoch #3. Accuracy on batch 1508/2438  on Training is 66.81991385023194\n",
            "Epoch #3. Accuracy on batch 1509/2438  on Training is 66.81705298013244\n",
            "Epoch #3. Accuracy on batch 1510/2438  on Training is 66.81005956320318\n",
            "Epoch #3. Accuracy on batch 1511/2438  on Training is 66.81547619047619\n",
            "Epoch #3. Accuracy on batch 1512/2438  on Training is 66.81262392597489\n",
            "Epoch #3. Accuracy on batch 1513/2438  on Training is 66.8097754293263\n",
            "Epoch #3. Accuracy on batch 1514/2438  on Training is 66.8069306930693\n",
            "Epoch #3. Accuracy on batch 1515/2438  on Training is 66.81027374670185\n",
            "Epoch #3. Accuracy on batch 1516/2438  on Training is 66.8115524060646\n",
            "Epoch #3. Accuracy on batch 1517/2438  on Training is 66.8066534914361\n",
            "Epoch #3. Accuracy on batch 1518/2438  on Training is 66.81410467412772\n",
            "Epoch #3. Accuracy on batch 1519/2438  on Training is 66.82976973684211\n",
            "Batch Id 1520/2438 is having training loss of 1.2552217245101929\n",
            "1.7453688383102417\n",
            "Epoch #3. Accuracy on batch 1520/2438  on Training is 66.81665023011176\n",
            "Epoch #3. Accuracy on batch 1521/2438  on Training is 66.81997371879106\n",
            "Epoch #3. Accuracy on batch 1522/2438  on Training is 66.81918910045962\n",
            "Epoch #3. Accuracy on batch 1523/2438  on Training is 66.82045603674541\n",
            "Epoch #3. Accuracy on batch 1524/2438  on Training is 66.81557377049181\n",
            "Epoch #3. Accuracy on batch 1525/2438  on Training is 66.81888925294889\n",
            "Epoch #3. Accuracy on batch 1526/2438  on Training is 66.80582842174198\n",
            "Epoch #3. Accuracy on batch 1527/2438  on Training is 66.79892015706807\n",
            "Epoch #3. Accuracy on batch 1528/2438  on Training is 66.80019620667103\n",
            "Epoch #3. Accuracy on batch 1529/2438  on Training is 66.80147058823529\n",
            "Epoch #3. Accuracy on batch 1530/2438  on Training is 66.79253755715219\n",
            "Epoch #3. Accuracy on batch 1531/2438  on Training is 66.79585509138381\n",
            "Epoch #3. Accuracy on batch 1532/2438  on Training is 66.79509132420091\n",
            "Epoch #3. Accuracy on batch 1533/2438  on Training is 66.79025423728814\n",
            "Epoch #3. Accuracy on batch 1534/2438  on Training is 66.78542345276873\n",
            "Epoch #3. Accuracy on batch 1535/2438  on Training is 66.77652994791667\n",
            "Epoch #3. Accuracy on batch 1536/2438  on Training is 66.77374756018217\n",
            "Epoch #3. Accuracy on batch 1537/2438  on Training is 66.77300065019506\n",
            "Epoch #3. Accuracy on batch 1538/2438  on Training is 66.77022417153997\n",
            "Epoch #3. Accuracy on batch 1539/2438  on Training is 66.7674512987013\n",
            "Batch Id 1540/2438 is having training loss of 1.2556722164154053\n",
            "0.9588714241981506\n",
            "Epoch #3. Accuracy on batch 1540/2438  on Training is 66.77279364049319\n",
            "Epoch #3. Accuracy on batch 1541/2438  on Training is 66.77407587548637\n",
            "Epoch #3. Accuracy on batch 1542/2438  on Training is 66.78143227478937\n",
            "Epoch #3. Accuracy on batch 1543/2438  on Training is 66.77663536269431\n",
            "Epoch #3. Accuracy on batch 1544/2438  on Training is 66.7799352750809\n",
            "Epoch #3. Accuracy on batch 1545/2438  on Training is 66.78323091849936\n",
            "Epoch #3. Accuracy on batch 1546/2438  on Training is 66.78248222365869\n",
            "Epoch #3. Accuracy on batch 1547/2438  on Training is 66.77769702842377\n",
            "Epoch #3. Accuracy on batch 1548/2438  on Training is 66.77897030342156\n",
            "Epoch #3. Accuracy on batch 1549/2438  on Training is 66.78427419354838\n",
            "Epoch #3. Accuracy on batch 1550/2438  on Training is 66.78352675693101\n",
            "Epoch #3. Accuracy on batch 1551/2438  on Training is 66.78680734536083\n",
            "Epoch #3. Accuracy on batch 1552/2438  on Training is 66.79008370895042\n",
            "Epoch #3. Accuracy on batch 1553/2438  on Training is 66.79134491634491\n",
            "Epoch #3. Accuracy on batch 1554/2438  on Training is 66.79662379421222\n",
            "Epoch #3. Accuracy on batch 1555/2438  on Training is 66.79386246786632\n",
            "Epoch #3. Accuracy on batch 1556/2438  on Training is 66.79712588310854\n",
            "Epoch #3. Accuracy on batch 1557/2438  on Training is 66.79637355584082\n",
            "Epoch #3. Accuracy on batch 1558/2438  on Training is 66.79562219371392\n",
            "Epoch #3. Accuracy on batch 1559/2438  on Training is 66.78685897435898\n",
            "Batch Id 1560/2438 is having training loss of 1.2546532154083252\n",
            "1.024224877357483\n",
            "Epoch #3. Accuracy on batch 1560/2438  on Training is 66.78811659192826\n",
            "Epoch #3. Accuracy on batch 1561/2438  on Training is 66.79537451984635\n",
            "Epoch #3. Accuracy on batch 1562/2438  on Training is 66.7966250799744\n",
            "Epoch #3. Accuracy on batch 1563/2438  on Training is 66.78188938618926\n",
            "Epoch #3. Accuracy on batch 1564/2438  on Training is 66.78714057507987\n",
            "Epoch #3. Accuracy on batch 1565/2438  on Training is 66.7824074074074\n",
            "Epoch #3. Accuracy on batch 1566/2438  on Training is 66.78166879387365\n",
            "Epoch #3. Accuracy on batch 1567/2438  on Training is 66.78292410714286\n",
            "Epoch #3. Accuracy on batch 1568/2438  on Training is 66.78417782026769\n",
            "Epoch #3. Accuracy on batch 1569/2438  on Training is 66.77547770700637\n",
            "Epoch #3. Accuracy on batch 1570/2438  on Training is 66.77474538510504\n",
            "Epoch #3. Accuracy on batch 1571/2438  on Training is 66.77798982188295\n",
            "Epoch #3. Accuracy on batch 1572/2438  on Training is 66.77924348378893\n",
            "Epoch #3. Accuracy on batch 1573/2438  on Training is 66.78645171537484\n",
            "Epoch #3. Accuracy on batch 1574/2438  on Training is 66.7797619047619\n",
            "Epoch #3. Accuracy on batch 1575/2438  on Training is 66.77902918781726\n",
            "Epoch #3. Accuracy on batch 1576/2438  on Training is 66.78622384273937\n",
            "Epoch #3. Accuracy on batch 1577/2438  on Training is 66.79142902408111\n",
            "Epoch #3. Accuracy on batch 1578/2438  on Training is 66.80256491450285\n",
            "Epoch #3. Accuracy on batch 1579/2438  on Training is 66.7998417721519\n",
            "Batch Id 1580/2438 is having training loss of 1.2530913352966309\n",
            "0.6394450068473816\n",
            "Epoch #3. Accuracy on batch 1580/2438  on Training is 66.81095825426945\n",
            "Epoch #3. Accuracy on batch 1581/2438  on Training is 66.81020859671303\n",
            "Epoch #3. Accuracy on batch 1582/2438  on Training is 66.81340808591283\n",
            "Epoch #3. Accuracy on batch 1583/2438  on Training is 66.81265782828282\n",
            "Epoch #3. Accuracy on batch 1584/2438  on Training is 66.80796529968454\n",
            "Epoch #3. Accuracy on batch 1585/2438  on Training is 66.79736759142497\n",
            "Epoch #3. Accuracy on batch 1586/2438  on Training is 66.7966288594833\n",
            "Epoch #3. Accuracy on batch 1587/2438  on Training is 66.79982682619648\n",
            "Epoch #3. Accuracy on batch 1588/2438  on Training is 66.80498741346759\n",
            "Epoch #3. Accuracy on batch 1589/2438  on Training is 66.80621069182389\n",
            "Epoch #3. Accuracy on batch 1590/2438  on Training is 66.80939660590823\n",
            "Epoch #3. Accuracy on batch 1591/2438  on Training is 66.81846733668341\n",
            "Epoch #3. Accuracy on batch 1592/2438  on Training is 66.81183301946014\n",
            "Epoch #3. Accuracy on batch 1593/2438  on Training is 66.80912797992472\n",
            "Epoch #3. Accuracy on batch 1594/2438  on Training is 66.80838557993731\n",
            "Epoch #3. Accuracy on batch 1595/2438  on Training is 66.80764411027569\n",
            "Epoch #3. Accuracy on batch 1596/2438  on Training is 66.80690356919223\n",
            "Epoch #3. Accuracy on batch 1597/2438  on Training is 66.80616395494368\n",
            "Epoch #3. Accuracy on batch 1598/2438  on Training is 66.81128830519074\n",
            "Epoch #3. Accuracy on batch 1599/2438  on Training is 66.810546875\n",
            "Batch Id 1600/2438 is having training loss of 1.2534842491149902\n",
            "1.1089791059494019\n",
            "Epoch #3. Accuracy on batch 1600/2438  on Training is 66.81566208619613\n",
            "Epoch #3. Accuracy on batch 1601/2438  on Training is 66.81296816479401\n",
            "Epoch #3. Accuracy on batch 1602/2438  on Training is 66.82002495321272\n",
            "Epoch #3. Accuracy on batch 1603/2438  on Training is 66.81733167082294\n",
            "Epoch #3. Accuracy on batch 1604/2438  on Training is 66.81658878504673\n",
            "Epoch #3. Accuracy on batch 1605/2438  on Training is 66.81390099626401\n",
            "Epoch #3. Accuracy on batch 1606/2438  on Training is 66.82093963907903\n",
            "Epoch #3. Accuracy on batch 1607/2438  on Training is 66.8143656716418\n",
            "Epoch #3. Accuracy on batch 1608/2438  on Training is 66.8233374766936\n",
            "Epoch #3. Accuracy on batch 1609/2438  on Training is 66.82065217391305\n",
            "Epoch #3. Accuracy on batch 1610/2438  on Training is 66.82766914959653\n",
            "Epoch #3. Accuracy on batch 1611/2438  on Training is 66.81723014888337\n",
            "Epoch #3. Accuracy on batch 1612/2438  on Training is 66.8145536267824\n",
            "Epoch #3. Accuracy on batch 1613/2438  on Training is 66.80413568773234\n",
            "Epoch #3. Accuracy on batch 1614/2438  on Training is 66.81501547987617\n",
            "Epoch #3. Accuracy on batch 1615/2438  on Training is 66.81041150990099\n",
            "Epoch #3. Accuracy on batch 1616/2438  on Training is 66.81354359925788\n",
            "Epoch #3. Accuracy on batch 1617/2438  on Training is 66.81087762669964\n",
            "Epoch #3. Accuracy on batch 1618/2438  on Training is 66.8120753551575\n",
            "Epoch #3. Accuracy on batch 1619/2438  on Training is 66.80555555555556\n",
            "Batch Id 1620/2438 is having training loss of 1.253480315208435\n",
            "1.6394544839859009\n",
            "Epoch #3. Accuracy on batch 1620/2438  on Training is 66.79904380012339\n",
            "Epoch #3. Accuracy on batch 1621/2438  on Training is 66.7944667077682\n",
            "Epoch #3. Accuracy on batch 1622/2438  on Training is 66.80144793592113\n",
            "Epoch #3. Accuracy on batch 1623/2438  on Training is 66.796875\n",
            "Epoch #3. Accuracy on batch 1624/2438  on Training is 66.8\n",
            "Epoch #3. Accuracy on batch 1625/2438  on Training is 66.78390221402213\n",
            "Epoch #3. Accuracy on batch 1626/2438  on Training is 66.78318992009834\n",
            "Epoch #3. Accuracy on batch 1627/2438  on Training is 66.7824785012285\n",
            "Epoch #3. Accuracy on batch 1628/2438  on Training is 66.79135972989565\n",
            "Epoch #3. Accuracy on batch 1629/2438  on Training is 66.79639570552148\n",
            "Epoch #3. Accuracy on batch 1630/2438  on Training is 66.80142550582465\n",
            "Epoch #3. Accuracy on batch 1631/2438  on Training is 66.81219362745098\n",
            "Epoch #3. Accuracy on batch 1632/2438  on Training is 66.811466625842\n",
            "Epoch #3. Accuracy on batch 1633/2438  on Training is 66.82221542227663\n",
            "Epoch #3. Accuracy on batch 1634/2438  on Training is 66.82721712538226\n",
            "Epoch #3. Accuracy on batch 1635/2438  on Training is 66.8283924205379\n",
            "Epoch #3. Accuracy on batch 1636/2438  on Training is 66.83147525962126\n",
            "Epoch #3. Accuracy on batch 1637/2438  on Training is 66.83455433455434\n",
            "Epoch #3. Accuracy on batch 1638/2438  on Training is 66.8338163514338\n",
            "Epoch #3. Accuracy on batch 1639/2438  on Training is 66.83498475609755\n",
            "Batch Id 1640/2438 is having training loss of 1.2526007890701294\n",
            "1.0272767543792725\n",
            "Epoch #3. Accuracy on batch 1640/2438  on Training is 66.83805606337599\n",
            "Epoch #3. Accuracy on batch 1641/2438  on Training is 66.84112362971986\n",
            "Epoch #3. Accuracy on batch 1642/2438  on Training is 66.83848143639683\n",
            "Epoch #3. Accuracy on batch 1643/2438  on Training is 66.84534671532846\n",
            "Epoch #3. Accuracy on batch 1644/2438  on Training is 66.85030395136778\n",
            "Epoch #3. Accuracy on batch 1645/2438  on Training is 66.8476609963548\n",
            "Epoch #3. Accuracy on batch 1646/2438  on Training is 66.85261080752883\n",
            "Epoch #3. Accuracy on batch 1647/2438  on Training is 66.85945084951456\n",
            "Epoch #3. Accuracy on batch 1648/2438  on Training is 66.85301697998787\n",
            "Epoch #3. Accuracy on batch 1649/2438  on Training is 66.85795454545455\n",
            "Epoch #3. Accuracy on batch 1650/2438  on Training is 66.85531496062993\n",
            "Epoch #3. Accuracy on batch 1651/2438  on Training is 66.8621368038741\n",
            "Epoch #3. Accuracy on batch 1652/2438  on Training is 66.86516938898971\n",
            "Epoch #3. Accuracy on batch 1653/2438  on Training is 66.86630894800484\n",
            "Epoch #3. Accuracy on batch 1654/2438  on Training is 66.87688821752266\n",
            "Epoch #3. Accuracy on batch 1655/2438  on Training is 66.86103562801932\n",
            "Epoch #3. Accuracy on batch 1656/2438  on Training is 66.8565178032589\n",
            "Epoch #3. Accuracy on batch 1657/2438  on Training is 66.85577503015682\n",
            "Epoch #3. Accuracy on batch 1658/2438  on Training is 66.85126582278481\n",
            "Epoch #3. Accuracy on batch 1659/2438  on Training is 66.85240963855422\n",
            "Batch Id 1660/2438 is having training loss of 1.2522705793380737\n",
            "0.8136780261993408\n",
            "Epoch #3. Accuracy on batch 1660/2438  on Training is 66.85543347381096\n",
            "Epoch #3. Accuracy on batch 1661/2438  on Training is 66.8565734055355\n",
            "Epoch #3. Accuracy on batch 1662/2438  on Training is 66.8558328322309\n",
            "Epoch #3. Accuracy on batch 1663/2438  on Training is 66.85884915865384\n",
            "Epoch #3. Accuracy on batch 1664/2438  on Training is 66.85810810810811\n",
            "Epoch #3. Accuracy on batch 1665/2438  on Training is 66.85174069627851\n",
            "Epoch #3. Accuracy on batch 1666/2438  on Training is 66.8510047990402\n",
            "Epoch #3. Accuracy on batch 1667/2438  on Training is 66.8427757793765\n",
            "Epoch #3. Accuracy on batch 1668/2438  on Training is 66.8383013780707\n",
            "Epoch #3. Accuracy on batch 1669/2438  on Training is 66.8375748502994\n",
            "Epoch #3. Accuracy on batch 1670/2438  on Training is 66.83310891681627\n",
            "Epoch #3. Accuracy on batch 1671/2438  on Training is 66.82677930622009\n",
            "Epoch #3. Accuracy on batch 1672/2438  on Training is 66.81858936043037\n",
            "Epoch #3. Accuracy on batch 1673/2438  on Training is 66.82160991636798\n",
            "Epoch #3. Accuracy on batch 1674/2438  on Training is 66.82276119402985\n",
            "Epoch #3. Accuracy on batch 1675/2438  on Training is 66.82950477326969\n",
            "Epoch #3. Accuracy on batch 1676/2438  on Training is 66.83437686344664\n",
            "Epoch #3. Accuracy on batch 1677/2438  on Training is 66.83179380214541\n",
            "Epoch #3. Accuracy on batch 1678/2438  on Training is 66.82735259082787\n",
            "Epoch #3. Accuracy on batch 1679/2438  on Training is 66.8266369047619\n",
            "Batch Id 1680/2438 is having training loss of 1.2530858516693115\n",
            "1.2150518894195557\n",
            "Epoch #3. Accuracy on batch 1680/2438  on Training is 66.82778108268887\n",
            "Epoch #3. Accuracy on batch 1681/2438  on Training is 66.82706599286564\n",
            "Epoch #3. Accuracy on batch 1682/2438  on Training is 66.82263814616756\n",
            "Epoch #3. Accuracy on batch 1683/2438  on Training is 66.82007125890736\n",
            "Epoch #3. Accuracy on batch 1684/2438  on Training is 66.82121661721068\n",
            "Epoch #3. Accuracy on batch 1685/2438  on Training is 66.81680011862396\n",
            "Epoch #3. Accuracy on batch 1686/2438  on Training is 66.810536455246\n",
            "Epoch #3. Accuracy on batch 1687/2438  on Training is 66.80428021327015\n",
            "Epoch #3. Accuracy on batch 1688/2438  on Training is 66.79433096506808\n",
            "Epoch #3. Accuracy on batch 1689/2438  on Training is 66.80103550295858\n",
            "Epoch #3. Accuracy on batch 1690/2438  on Training is 66.80588409225311\n",
            "Epoch #3. Accuracy on batch 1691/2438  on Training is 66.80149231678487\n",
            "Epoch #3. Accuracy on batch 1692/2438  on Training is 66.8007974010632\n",
            "Epoch #3. Accuracy on batch 1693/2438  on Training is 66.80010330578513\n",
            "Epoch #3. Accuracy on batch 1694/2438  on Training is 66.79941002949853\n",
            "Epoch #3. Accuracy on batch 1695/2438  on Training is 66.80608785377359\n",
            "Epoch #3. Accuracy on batch 1696/2438  on Training is 66.80907483794932\n",
            "Epoch #3. Accuracy on batch 1697/2438  on Training is 66.81757950530036\n",
            "Epoch #3. Accuracy on batch 1698/2438  on Training is 66.81871689228959\n",
            "Epoch #3. Accuracy on batch 1699/2438  on Training is 66.81801470588235\n",
            "Batch Id 1700/2438 is having training loss of 1.2529627084732056\n",
            "1.2540520429611206\n",
            "Epoch #3. Accuracy on batch 1700/2438  on Training is 66.81915049970605\n",
            "Epoch #3. Accuracy on batch 1701/2438  on Training is 66.82212103407755\n",
            "Epoch #3. Accuracy on batch 1702/2438  on Training is 66.82508807985907\n",
            "Epoch #3. Accuracy on batch 1703/2438  on Training is 66.81704812206573\n",
            "Epoch #3. Accuracy on batch 1704/2438  on Training is 66.81634897360703\n",
            "Epoch #3. Accuracy on batch 1705/2438  on Training is 66.8101553341149\n",
            "Epoch #3. Accuracy on batch 1706/2438  on Training is 66.81495313415348\n",
            "Epoch #3. Accuracy on batch 1707/2438  on Training is 66.81608606557377\n",
            "Epoch #3. Accuracy on batch 1708/2438  on Training is 66.82270333528379\n",
            "Epoch #3. Accuracy on batch 1709/2438  on Training is 66.82748538011695\n",
            "Epoch #3. Accuracy on batch 1710/2438  on Training is 66.82130333138515\n",
            "Epoch #3. Accuracy on batch 1711/2438  on Training is 66.81695385514018\n",
            "Epoch #3. Accuracy on batch 1712/2438  on Training is 66.80348803269119\n",
            "Epoch #3. Accuracy on batch 1713/2438  on Training is 66.80462368728121\n",
            "Epoch #3. Accuracy on batch 1714/2438  on Training is 66.7984693877551\n",
            "Epoch #3. Accuracy on batch 1715/2438  on Training is 66.79596445221445\n",
            "Epoch #3. Accuracy on batch 1716/2438  on Training is 66.80074257425743\n",
            "Epoch #3. Accuracy on batch 1717/2438  on Training is 66.8055151338766\n",
            "Epoch #3. Accuracy on batch 1718/2438  on Training is 66.80301047120419\n",
            "Epoch #3. Accuracy on batch 1719/2438  on Training is 66.80959302325581\n",
            "Batch Id 1720/2438 is having training loss of 1.253178596496582\n",
            "1.1829655170440674\n",
            "Epoch #3. Accuracy on batch 1720/2438  on Training is 66.80890470656595\n",
            "Epoch #3. Accuracy on batch 1721/2438  on Training is 66.81003193960511\n",
            "Epoch #3. Accuracy on batch 1722/2438  on Training is 66.81115786419036\n",
            "Epoch #3. Accuracy on batch 1723/2438  on Training is 66.8122824825986\n",
            "Epoch #3. Accuracy on batch 1724/2438  on Training is 66.81884057971014\n",
            "Epoch #3. Accuracy on batch 1725/2438  on Training is 66.81271726535341\n",
            "Epoch #3. Accuracy on batch 1726/2438  on Training is 66.81564852345107\n",
            "Epoch #3. Accuracy on batch 1727/2438  on Training is 66.81857638888889\n",
            "Epoch #3. Accuracy on batch 1728/2438  on Training is 66.82330827067669\n",
            "Epoch #3. Accuracy on batch 1729/2438  on Training is 66.82442196531792\n",
            "Epoch #3. Accuracy on batch 1730/2438  on Training is 66.83636626227614\n",
            "Epoch #3. Accuracy on batch 1731/2438  on Training is 66.83025404157044\n",
            "Epoch #3. Accuracy on batch 1732/2438  on Training is 66.83136180034622\n",
            "Epoch #3. Accuracy on batch 1733/2438  on Training is 66.82345732410612\n",
            "Epoch #3. Accuracy on batch 1734/2438  on Training is 66.82636887608069\n",
            "Epoch #3. Accuracy on batch 1735/2438  on Training is 66.81487615207374\n",
            "Epoch #3. Accuracy on batch 1736/2438  on Training is 66.82138744962579\n",
            "Epoch #3. Accuracy on batch 1737/2438  on Training is 66.82249712313003\n",
            "Epoch #3. Accuracy on batch 1738/2438  on Training is 66.82180851063829\n",
            "Epoch #3. Accuracy on batch 1739/2438  on Training is 66.82291666666667\n",
            "Batch Id 1740/2438 is having training loss of 1.2524627447128296\n",
            "1.2417840957641602\n",
            "Epoch #3. Accuracy on batch 1740/2438  on Training is 66.82402354968409\n",
            "Epoch #3. Accuracy on batch 1741/2438  on Training is 66.83051090700344\n",
            "Epoch #3. Accuracy on batch 1742/2438  on Training is 66.82802639127941\n",
            "Epoch #3. Accuracy on batch 1743/2438  on Training is 66.82912844036697\n",
            "Epoch #3. Accuracy on batch 1744/2438  on Training is 66.82485673352436\n",
            "Epoch #3. Accuracy on batch 1745/2438  on Training is 66.82595933562429\n",
            "Epoch #3. Accuracy on batch 1746/2438  on Training is 66.83421579851174\n",
            "Epoch #3. Accuracy on batch 1747/2438  on Training is 66.83352402745996\n",
            "Epoch #3. Accuracy on batch 1748/2438  on Training is 66.82747284162379\n",
            "Epoch #3. Accuracy on batch 1749/2438  on Training is 66.82142857142857\n",
            "Epoch #3. Accuracy on batch 1750/2438  on Training is 66.82431467732724\n",
            "Epoch #3. Accuracy on batch 1751/2438  on Training is 66.82541381278538\n",
            "Epoch #3. Accuracy on batch 1752/2438  on Training is 66.81759840273817\n",
            "Epoch #3. Accuracy on batch 1753/2438  on Training is 66.8080102622577\n",
            "Epoch #3. Accuracy on batch 1754/2438  on Training is 66.80911680911682\n",
            "Epoch #3. Accuracy on batch 1755/2438  on Training is 66.81200170842824\n",
            "Epoch #3. Accuracy on batch 1756/2438  on Training is 66.80599032441661\n",
            "Epoch #3. Accuracy on batch 1757/2438  on Training is 66.8035409556314\n",
            "Epoch #3. Accuracy on batch 1758/2438  on Training is 66.80287094940307\n",
            "Epoch #3. Accuracy on batch 1759/2438  on Training is 66.8057528409091\n",
            "Batch Id 1760/2438 is having training loss of 1.2532581090927124\n",
            "1.1474285125732422\n",
            "Epoch #3. Accuracy on batch 1760/2438  on Training is 66.80863145939807\n",
            "Epoch #3. Accuracy on batch 1761/2438  on Training is 66.79909194097617\n",
            "Epoch #3. Accuracy on batch 1762/2438  on Training is 66.80019852524107\n",
            "Epoch #3. Accuracy on batch 1763/2438  on Training is 66.80661848072562\n",
            "Epoch #3. Accuracy on batch 1764/2438  on Training is 66.80949008498584\n",
            "Epoch #3. Accuracy on batch 1765/2438  on Training is 66.80881936579841\n",
            "Epoch #3. Accuracy on batch 1766/2438  on Training is 66.81168647425014\n",
            "Epoch #3. Accuracy on batch 1767/2438  on Training is 66.81278280542986\n",
            "Epoch #3. Accuracy on batch 1768/2438  on Training is 66.82271057094404\n",
            "Epoch #3. Accuracy on batch 1769/2438  on Training is 66.82203389830508\n",
            "Epoch #3. Accuracy on batch 1770/2438  on Training is 66.81782891022021\n",
            "Epoch #3. Accuracy on batch 1771/2438  on Training is 66.81362866817156\n",
            "Epoch #3. Accuracy on batch 1772/2438  on Training is 66.81824591088551\n",
            "Epoch #3. Accuracy on batch 1773/2438  on Training is 66.82109639233371\n",
            "Epoch #3. Accuracy on batch 1774/2438  on Training is 66.82394366197182\n",
            "Epoch #3. Accuracy on batch 1775/2438  on Training is 66.82678772522523\n",
            "Epoch #3. Accuracy on batch 1776/2438  on Training is 66.82611142374789\n",
            "Epoch #3. Accuracy on batch 1777/2438  on Training is 66.83246625421822\n",
            "Epoch #3. Accuracy on batch 1778/2438  on Training is 66.83705733558179\n",
            "Epoch #3. Accuracy on batch 1779/2438  on Training is 66.84164325842697\n",
            "Batch Id 1780/2438 is having training loss of 1.2525345087051392\n",
            "1.2390573024749756\n",
            "Epoch #3. Accuracy on batch 1780/2438  on Training is 66.84446939921392\n",
            "Epoch #3. Accuracy on batch 1781/2438  on Training is 66.84553872053873\n",
            "Epoch #3. Accuracy on batch 1782/2438  on Training is 66.83784352215368\n",
            "Epoch #3. Accuracy on batch 1783/2438  on Training is 66.83716367713005\n",
            "Epoch #3. Accuracy on batch 1784/2438  on Training is 66.84173669467788\n",
            "Epoch #3. Accuracy on batch 1785/2438  on Training is 66.84105543113102\n",
            "Epoch #3. Accuracy on batch 1786/2438  on Training is 66.84037493005036\n",
            "Epoch #3. Accuracy on batch 1787/2438  on Training is 66.84144295302013\n",
            "Epoch #3. Accuracy on batch 1788/2438  on Training is 66.8494969256568\n",
            "Epoch #3. Accuracy on batch 1789/2438  on Training is 66.84532122905028\n",
            "Epoch #3. Accuracy on batch 1790/2438  on Training is 66.84812953657175\n",
            "Epoch #3. Accuracy on batch 1791/2438  on Training is 66.84395926339286\n",
            "Epoch #3. Accuracy on batch 1792/2438  on Training is 66.83282208588957\n",
            "Epoch #3. Accuracy on batch 1793/2438  on Training is 66.82866499442586\n",
            "Epoch #3. Accuracy on batch 1794/2438  on Training is 66.82277158774373\n",
            "Epoch #3. Accuracy on batch 1795/2438  on Training is 66.81688474387528\n",
            "Epoch #3. Accuracy on batch 1796/2438  on Training is 66.81274346132443\n",
            "Epoch #3. Accuracy on batch 1797/2438  on Training is 66.81382091212458\n",
            "Epoch #3. Accuracy on batch 1798/2438  on Training is 66.81837131739856\n",
            "Epoch #3. Accuracy on batch 1799/2438  on Training is 66.81597222222223\n",
            "Batch Id 1800/2438 is having training loss of 1.2531142234802246\n",
            "1.3097563982009888\n",
            "Epoch #3. Accuracy on batch 1800/2438  on Training is 66.81531093836757\n",
            "Epoch #3. Accuracy on batch 1801/2438  on Training is 66.81291620421753\n",
            "Epoch #3. Accuracy on batch 1802/2438  on Training is 66.8087909040488\n",
            "Epoch #3. Accuracy on batch 1803/2438  on Training is 66.80293791574279\n",
            "Epoch #3. Accuracy on batch 1804/2438  on Training is 66.81094182825485\n",
            "Epoch #3. Accuracy on batch 1805/2438  on Training is 66.81547619047619\n",
            "Epoch #3. Accuracy on batch 1806/2438  on Training is 66.81481737686774\n",
            "Epoch #3. Accuracy on batch 1807/2438  on Training is 66.80551714601769\n",
            "Epoch #3. Accuracy on batch 1808/2438  on Training is 66.80659203980099\n",
            "Epoch #3. Accuracy on batch 1809/2438  on Training is 66.80593922651934\n",
            "Epoch #3. Accuracy on batch 1810/2438  on Training is 66.8087382661513\n",
            "Epoch #3. Accuracy on batch 1811/2438  on Training is 66.79773730684327\n",
            "Epoch #3. Accuracy on batch 1812/2438  on Training is 66.81087975730833\n",
            "Epoch #3. Accuracy on batch 1813/2438  on Training is 66.8050578831312\n",
            "Epoch #3. Accuracy on batch 1814/2438  on Training is 66.80785123966942\n",
            "Epoch #3. Accuracy on batch 1815/2438  on Training is 66.80375825991189\n",
            "Epoch #3. Accuracy on batch 1816/2438  on Training is 66.80482938910292\n",
            "Epoch #3. Accuracy on batch 1817/2438  on Training is 66.80761826182618\n",
            "Epoch #3. Accuracy on batch 1818/2438  on Training is 66.80009620670698\n",
            "Epoch #3. Accuracy on batch 1819/2438  on Training is 66.79773351648352\n",
            "Batch Id 1820/2438 is having training loss of 1.2529653310775757\n",
            "1.2128303050994873\n",
            "Epoch #3. Accuracy on batch 1820/2438  on Training is 66.80052169137836\n",
            "Epoch #3. Accuracy on batch 1821/2438  on Training is 66.80330680570802\n",
            "Epoch #3. Accuracy on batch 1822/2438  on Training is 66.80780307185957\n",
            "Epoch #3. Accuracy on batch 1823/2438  on Training is 66.8140076754386\n",
            "Epoch #3. Accuracy on batch 1824/2438  on Training is 66.81849315068493\n",
            "Epoch #3. Accuracy on batch 1825/2438  on Training is 66.82297371303396\n",
            "Epoch #3. Accuracy on batch 1826/2438  on Training is 66.8240284619595\n",
            "Epoch #3. Accuracy on batch 1827/2438  on Training is 66.8148249452954\n",
            "Epoch #3. Accuracy on batch 1828/2438  on Training is 66.81930016402406\n",
            "Epoch #3. Accuracy on batch 1829/2438  on Training is 66.81693989071039\n",
            "Epoch #3. Accuracy on batch 1830/2438  on Training is 66.81628891316221\n",
            "Epoch #3. Accuracy on batch 1831/2438  on Training is 66.8190502183406\n",
            "Epoch #3. Accuracy on batch 1832/2438  on Training is 66.82351336606656\n",
            "Epoch #3. Accuracy on batch 1833/2438  on Training is 66.8228598691385\n",
            "Epoch #3. Accuracy on batch 1834/2438  on Training is 66.81709809264305\n",
            "Epoch #3. Accuracy on batch 1835/2438  on Training is 66.8113425925926\n",
            "Epoch #3. Accuracy on batch 1836/2438  on Training is 66.80729450190528\n",
            "Epoch #3. Accuracy on batch 1837/2438  on Training is 66.79985038084875\n",
            "Epoch #3. Accuracy on batch 1838/2438  on Training is 66.79411364872213\n",
            "Epoch #3. Accuracy on batch 1839/2438  on Training is 66.79857336956522\n",
            "Batch Id 1840/2438 is having training loss of 1.252410650253296\n",
            "0.6883724331855774\n",
            "Epoch #3. Accuracy on batch 1840/2438  on Training is 66.80642313959804\n",
            "Epoch #3. Accuracy on batch 1841/2438  on Training is 66.81087133550488\n",
            "Epoch #3. Accuracy on batch 1842/2438  on Training is 66.81022788931091\n",
            "Epoch #3. Accuracy on batch 1843/2438  on Training is 66.80619577006507\n",
            "Epoch #3. Accuracy on batch 1844/2438  on Training is 66.80216802168022\n",
            "Epoch #3. Accuracy on batch 1845/2438  on Training is 66.80322318526544\n",
            "Epoch #3. Accuracy on batch 1846/2438  on Training is 66.80427720628046\n",
            "Epoch #3. Accuracy on batch 1847/2438  on Training is 66.80025703463204\n",
            "Epoch #3. Accuracy on batch 1848/2438  on Training is 66.79624121146566\n",
            "Epoch #3. Accuracy on batch 1849/2438  on Training is 66.79729729729729\n",
            "Epoch #3. Accuracy on batch 1850/2438  on Training is 66.79497568881686\n",
            "Epoch #3. Accuracy on batch 1851/2438  on Training is 66.79096922246221\n",
            "Epoch #3. Accuracy on batch 1852/2438  on Training is 66.78865353480842\n",
            "Epoch #3. Accuracy on batch 1853/2438  on Training is 66.79139697950377\n",
            "Epoch #3. Accuracy on batch 1854/2438  on Training is 66.79076819407008\n",
            "Epoch #3. Accuracy on batch 1855/2438  on Training is 66.78508890086206\n",
            "Epoch #3. Accuracy on batch 1856/2438  on Training is 66.78278136779753\n",
            "Epoch #3. Accuracy on batch 1857/2438  on Training is 66.78047631862218\n",
            "Epoch #3. Accuracy on batch 1858/2438  on Training is 66.78489779451318\n",
            "Epoch #3. Accuracy on batch 1859/2438  on Training is 66.78931451612904\n",
            "Batch Id 1860/2438 is having training loss of 1.252475619316101\n",
            "1.4306671619415283\n",
            "Epoch #3. Accuracy on batch 1860/2438  on Training is 66.78700967221924\n",
            "Epoch #3. Accuracy on batch 1861/2438  on Training is 66.78470730397422\n",
            "Epoch #3. Accuracy on batch 1862/2438  on Training is 66.78911701556629\n",
            "Epoch #3. Accuracy on batch 1863/2438  on Training is 66.78849248927038\n",
            "Epoch #3. Accuracy on batch 1864/2438  on Training is 66.77949061662198\n",
            "Epoch #3. Accuracy on batch 1865/2438  on Training is 66.78557073954984\n",
            "Epoch #3. Accuracy on batch 1866/2438  on Training is 66.78997054097482\n",
            "Epoch #3. Accuracy on batch 1867/2438  on Training is 66.79603854389721\n",
            "Epoch #3. Accuracy on batch 1868/2438  on Training is 66.79206795077582\n",
            "Epoch #3. Accuracy on batch 1869/2438  on Training is 66.78810160427807\n",
            "Epoch #3. Accuracy on batch 1870/2438  on Training is 66.7858097274185\n",
            "Epoch #3. Accuracy on batch 1871/2438  on Training is 66.7835202991453\n",
            "Epoch #3. Accuracy on batch 1872/2438  on Training is 66.78123331553657\n",
            "Epoch #3. Accuracy on batch 1873/2438  on Training is 66.78561899679829\n",
            "Epoch #3. Accuracy on batch 1874/2438  on Training is 66.78333333333333\n",
            "Epoch #3. Accuracy on batch 1875/2438  on Training is 66.7827158848614\n",
            "Epoch #3. Accuracy on batch 1876/2438  on Training is 66.78709376664891\n",
            "Epoch #3. Accuracy on batch 1877/2438  on Training is 66.79146698615548\n",
            "Epoch #3. Accuracy on batch 1878/2438  on Training is 66.78918307610431\n",
            "Epoch #3. Accuracy on batch 1879/2438  on Training is 66.79022606382979\n",
            "Batch Id 1880/2438 is having training loss of 1.2522801160812378\n",
            "1.3090968132019043\n",
            "Epoch #3. Accuracy on batch 1880/2438  on Training is 66.79126794258373\n",
            "Epoch #3. Accuracy on batch 1881/2438  on Training is 66.78898777895856\n",
            "Epoch #3. Accuracy on batch 1882/2438  on Training is 66.78505045140733\n",
            "Epoch #3. Accuracy on batch 1883/2438  on Training is 66.7844347133758\n",
            "Epoch #3. Accuracy on batch 1884/2438  on Training is 66.78216180371352\n",
            "Epoch #3. Accuracy on batch 1885/2438  on Training is 66.77989130434783\n",
            "Epoch #3. Accuracy on batch 1886/2438  on Training is 66.78093534711182\n",
            "Epoch #3. Accuracy on batch 1887/2438  on Training is 66.78197828389831\n",
            "Epoch #3. Accuracy on batch 1888/2438  on Training is 66.78632874536792\n",
            "Epoch #3. Accuracy on batch 1889/2438  on Training is 66.78406084656085\n",
            "Epoch #3. Accuracy on batch 1890/2438  on Training is 66.78179534637758\n",
            "Epoch #3. Accuracy on batch 1891/2438  on Training is 66.79109408033827\n",
            "Epoch #3. Accuracy on batch 1892/2438  on Training is 66.79047807712625\n",
            "Epoch #3. Accuracy on batch 1893/2438  on Training is 66.7915126715945\n",
            "Epoch #3. Accuracy on batch 1894/2438  on Training is 66.78924802110818\n",
            "Epoch #3. Accuracy on batch 1895/2438  on Training is 66.79028217299577\n",
            "Epoch #3. Accuracy on batch 1896/2438  on Training is 66.79625724828676\n",
            "Epoch #3. Accuracy on batch 1897/2438  on Training is 66.79893308746048\n",
            "Epoch #3. Accuracy on batch 1898/2438  on Training is 66.80325171142707\n",
            "Epoch #3. Accuracy on batch 1899/2438  on Training is 66.80756578947368\n",
            "Batch Id 1900/2438 is having training loss of 1.2518086433410645\n",
            "1.1375330686569214\n",
            "Epoch #3. Accuracy on batch 1900/2438  on Training is 66.81187532877433\n",
            "Epoch #3. Accuracy on batch 1901/2438  on Training is 66.80632229232387\n",
            "Epoch #3. Accuracy on batch 1902/2438  on Training is 66.80570152390962\n",
            "Epoch #3. Accuracy on batch 1903/2438  on Training is 66.80836397058823\n",
            "Epoch #3. Accuracy on batch 1904/2438  on Training is 66.80118110236221\n",
            "Epoch #3. Accuracy on batch 1905/2438  on Training is 66.79728488982161\n",
            "Epoch #3. Accuracy on batch 1906/2438  on Training is 66.80158626114316\n",
            "Epoch #3. Accuracy on batch 1907/2438  on Training is 66.80096960167715\n",
            "Epoch #3. Accuracy on batch 1908/2438  on Training is 66.79544264012571\n",
            "Epoch #3. Accuracy on batch 1909/2438  on Training is 66.79482984293193\n",
            "Epoch #3. Accuracy on batch 1910/2438  on Training is 66.78931187859759\n",
            "Epoch #3. Accuracy on batch 1911/2438  on Training is 66.78706851464435\n",
            "Epoch #3. Accuracy on batch 1912/2438  on Training is 66.78809461578672\n",
            "Epoch #3. Accuracy on batch 1913/2438  on Training is 66.78095611285266\n",
            "Epoch #3. Accuracy on batch 1914/2438  on Training is 66.77545691906005\n",
            "Epoch #3. Accuracy on batch 1915/2438  on Training is 66.77648747390397\n",
            "Epoch #3. Accuracy on batch 1916/2438  on Training is 66.77588680229525\n",
            "Epoch #3. Accuracy on batch 1917/2438  on Training is 66.76876955161627\n",
            "Epoch #3. Accuracy on batch 1918/2438  on Training is 66.77957269411152\n",
            "Epoch #3. Accuracy on batch 1919/2438  on Training is 66.77897135416667\n",
            "Batch Id 1920/2438 is having training loss of 1.2525954246520996\n",
            "0.9963902235031128\n",
            "Epoch #3. Accuracy on batch 1920/2438  on Training is 66.77674388339406\n",
            "Epoch #3. Accuracy on batch 1921/2438  on Training is 66.77451873048908\n",
            "Epoch #3. Accuracy on batch 1922/2438  on Training is 66.77392095683827\n",
            "Epoch #3. Accuracy on batch 1923/2438  on Training is 66.77169958419958\n",
            "Epoch #3. Accuracy on batch 1924/2438  on Training is 66.77759740259741\n",
            "Epoch #3. Accuracy on batch 1925/2438  on Training is 66.7721313603323\n",
            "Epoch #3. Accuracy on batch 1926/2438  on Training is 66.77315775817333\n",
            "Epoch #3. Accuracy on batch 1927/2438  on Training is 66.7709413900415\n",
            "Epoch #3. Accuracy on batch 1928/2438  on Training is 66.76872731985485\n",
            "Epoch #3. Accuracy on batch 1929/2438  on Training is 66.76813471502591\n",
            "Epoch #3. Accuracy on batch 1930/2438  on Training is 66.77077938891766\n",
            "Epoch #3. Accuracy on batch 1931/2438  on Training is 66.76533385093168\n",
            "Epoch #3. Accuracy on batch 1932/2438  on Training is 66.76636057941025\n",
            "Epoch #3. Accuracy on batch 1933/2438  on Training is 66.77223371251293\n",
            "Epoch #3. Accuracy on batch 1934/2438  on Training is 66.77325581395348\n",
            "Epoch #3. Accuracy on batch 1935/2438  on Training is 66.77104855371901\n",
            "Epoch #3. Accuracy on batch 1936/2438  on Training is 66.7752968508002\n",
            "Epoch #3. Accuracy on batch 1937/2438  on Training is 66.77631578947368\n",
            "Epoch #3. Accuracy on batch 1938/2438  on Training is 66.77411036616813\n",
            "Epoch #3. Accuracy on batch 1939/2438  on Training is 66.77673969072166\n",
            "Batch Id 1940/2438 is having training loss of 1.252049446105957\n",
            "1.0800195932388306\n",
            "Epoch #3. Accuracy on batch 1940/2438  on Training is 66.77936630602782\n",
            "Epoch #3. Accuracy on batch 1941/2438  on Training is 66.78359938208033\n",
            "Epoch #3. Accuracy on batch 1942/2438  on Training is 66.781394750386\n",
            "Epoch #3. Accuracy on batch 1943/2438  on Training is 66.77919238683127\n",
            "Epoch #3. Accuracy on batch 1944/2438  on Training is 66.78181233933162\n",
            "Epoch #3. Accuracy on batch 1945/2438  on Training is 66.78121788283659\n",
            "Epoch #3. Accuracy on batch 1946/2438  on Training is 66.78062403697997\n",
            "Epoch #3. Accuracy on batch 1947/2438  on Training is 66.78323921971253\n",
            "Epoch #3. Accuracy on batch 1948/2438  on Training is 66.7842483324782\n",
            "Epoch #3. Accuracy on batch 1949/2438  on Training is 66.7900641025641\n",
            "Epoch #3. Accuracy on batch 1950/2438  on Training is 66.79267042542286\n",
            "Epoch #3. Accuracy on batch 1951/2438  on Training is 66.79047131147541\n",
            "Epoch #3. Accuracy on batch 1952/2438  on Training is 66.78667434715821\n",
            "Epoch #3. Accuracy on batch 1953/2438  on Training is 66.79407625383828\n",
            "Epoch #3. Accuracy on batch 1954/2438  on Training is 66.79667519181585\n",
            "Epoch #3. Accuracy on batch 1955/2438  on Training is 66.8008691206544\n",
            "Epoch #3. Accuracy on batch 1956/2438  on Training is 66.79707460398569\n",
            "Epoch #3. Accuracy on batch 1957/2438  on Training is 66.80286006128702\n",
            "Epoch #3. Accuracy on batch 1958/2438  on Training is 66.80544920877999\n",
            "Epoch #3. Accuracy on batch 1959/2438  on Training is 66.80006377551021\n",
            "Batch Id 1960/2438 is having training loss of 1.2517907619476318\n",
            "0.926184892654419\n",
            "Epoch #3. Accuracy on batch 1960/2438  on Training is 66.80424528301887\n",
            "Epoch #3. Accuracy on batch 1961/2438  on Training is 66.79886595310907\n",
            "Epoch #3. Accuracy on batch 1962/2438  on Training is 66.79508405501782\n",
            "Epoch #3. Accuracy on batch 1963/2438  on Training is 66.79607942973523\n",
            "Epoch #3. Accuracy on batch 1964/2438  on Training is 66.80025445292621\n",
            "Epoch #3. Accuracy on batch 1965/2438  on Training is 66.8012461851475\n",
            "Epoch #3. Accuracy on batch 1966/2438  on Training is 66.79111591255719\n",
            "Epoch #3. Accuracy on batch 1967/2438  on Training is 66.79052337398375\n",
            "Epoch #3. Accuracy on batch 1968/2438  on Training is 66.78199593702386\n",
            "Epoch #3. Accuracy on batch 1969/2438  on Training is 66.7734771573604\n",
            "Epoch #3. Accuracy on batch 1970/2438  on Training is 66.77765093860984\n",
            "Epoch #3. Accuracy on batch 1971/2438  on Training is 66.77706643002028\n",
            "Epoch #3. Accuracy on batch 1972/2438  on Training is 66.77014698428789\n",
            "Epoch #3. Accuracy on batch 1973/2438  on Training is 66.76640070921985\n",
            "Epoch #3. Accuracy on batch 1974/2438  on Training is 66.7753164556962\n",
            "Epoch #3. Accuracy on batch 1975/2438  on Training is 66.7715713562753\n",
            "Epoch #3. Accuracy on batch 1976/2438  on Training is 66.76466868993424\n",
            "Epoch #3. Accuracy on batch 1977/2438  on Training is 66.76725227502527\n",
            "Epoch #3. Accuracy on batch 1978/2438  on Training is 66.76983324911572\n",
            "Epoch #3. Accuracy on batch 1979/2438  on Training is 66.77872474747475\n",
            "Batch Id 1980/2438 is having training loss of 1.252518653869629\n",
            "1.5008838176727295\n",
            "Epoch #3. Accuracy on batch 1980/2438  on Training is 66.77340989399293\n",
            "Epoch #3. Accuracy on batch 1981/2438  on Training is 66.7696770938446\n",
            "Epoch #3. Accuracy on batch 1982/2438  on Training is 66.76909984871406\n",
            "Epoch #3. Accuracy on batch 1983/2438  on Training is 66.76379788306451\n",
            "Epoch #3. Accuracy on batch 1984/2438  on Training is 66.764798488665\n",
            "Epoch #3. Accuracy on batch 1985/2438  on Training is 66.76422457200403\n",
            "Epoch #3. Accuracy on batch 1986/2438  on Training is 66.76522395571213\n",
            "Epoch #3. Accuracy on batch 1987/2438  on Training is 66.76465040241449\n",
            "Epoch #3. Accuracy on batch 1988/2438  on Training is 66.77193313222725\n",
            "Epoch #3. Accuracy on batch 1989/2438  on Training is 66.76821608040201\n",
            "Epoch #3. Accuracy on batch 1990/2438  on Training is 66.76764188849825\n",
            "Epoch #3. Accuracy on batch 1991/2438  on Training is 66.76079317269077\n",
            "Epoch #3. Accuracy on batch 1992/2438  on Training is 66.76492724535875\n",
            "Epoch #3. Accuracy on batch 1993/2438  on Training is 66.75965396188566\n",
            "Epoch #3. Accuracy on batch 1994/2438  on Training is 66.76378446115288\n",
            "Epoch #3. Accuracy on batch 1995/2438  on Training is 66.76477955911824\n",
            "Epoch #3. Accuracy on batch 1996/2438  on Training is 66.76890335503255\n",
            "Epoch #3. Accuracy on batch 1997/2438  on Training is 66.76676676676676\n",
            "Epoch #3. Accuracy on batch 1998/2438  on Training is 66.75837918959479\n",
            "Epoch #3. Accuracy on batch 1999/2438  on Training is 66.75625\n",
            "Batch Id 2000/2438 is having training loss of 1.252660870552063\n",
            "0.8308875560760498\n",
            "Epoch #3. Accuracy on batch 2000/2438  on Training is 66.76193153423289\n",
            "Epoch #3. Accuracy on batch 2001/2438  on Training is 66.75824175824175\n",
            "Epoch #3. Accuracy on batch 2002/2438  on Training is 66.75455566650025\n",
            "Epoch #3. Accuracy on batch 2003/2438  on Training is 66.7555513972056\n",
            "Epoch #3. Accuracy on batch 2004/2438  on Training is 66.75498753117208\n",
            "Epoch #3. Accuracy on batch 2005/2438  on Training is 66.75598205383848\n",
            "Epoch #3. Accuracy on batch 2006/2438  on Training is 66.76164673642252\n",
            "Epoch #3. Accuracy on batch 2007/2438  on Training is 66.76574950199203\n",
            "Epoch #3. Accuracy on batch 2008/2438  on Training is 66.76673718267794\n",
            "Epoch #3. Accuracy on batch 2009/2438  on Training is 66.76772388059702\n",
            "Epoch #3. Accuracy on batch 2010/2438  on Training is 66.76870959721532\n",
            "Epoch #3. Accuracy on batch 2011/2438  on Training is 66.76037524850895\n",
            "Epoch #3. Accuracy on batch 2012/2438  on Training is 66.76291604570294\n",
            "Epoch #3. Accuracy on batch 2013/2438  on Training is 66.76390268123139\n",
            "Epoch #3. Accuracy on batch 2014/2438  on Training is 66.76023573200993\n",
            "Epoch #3. Accuracy on batch 2015/2438  on Training is 66.76122271825396\n",
            "Epoch #3. Accuracy on batch 2016/2438  on Training is 66.76220872583045\n",
            "Epoch #3. Accuracy on batch 2017/2438  on Training is 66.76629088206144\n",
            "Epoch #3. Accuracy on batch 2018/2438  on Training is 66.76417781079742\n",
            "Epoch #3. Accuracy on batch 2019/2438  on Training is 66.75897277227723\n",
            "Batch Id 2020/2438 is having training loss of 1.252855658531189\n",
            "1.3620187044143677\n",
            "Epoch #3. Accuracy on batch 2020/2438  on Training is 66.75995794161307\n",
            "Epoch #3. Accuracy on batch 2021/2438  on Training is 66.76712413452027\n",
            "Epoch #3. Accuracy on batch 2022/2438  on Training is 66.76964903608503\n",
            "Epoch #3. Accuracy on batch 2023/2438  on Training is 66.77525938735178\n",
            "Epoch #3. Accuracy on batch 2024/2438  on Training is 66.76697530864197\n",
            "Epoch #3. Accuracy on batch 2025/2438  on Training is 66.75869940769991\n",
            "Epoch #3. Accuracy on batch 2026/2438  on Training is 66.75814010853477\n",
            "Epoch #3. Accuracy on batch 2027/2438  on Training is 66.75912228796844\n",
            "Epoch #3. Accuracy on batch 2028/2438  on Training is 66.76318383440119\n",
            "Epoch #3. Accuracy on batch 2029/2438  on Training is 66.76262315270937\n",
            "Epoch #3. Accuracy on batch 2030/2438  on Training is 66.76206302314131\n",
            "Epoch #3. Accuracy on batch 2031/2438  on Training is 66.75842765748031\n",
            "Epoch #3. Accuracy on batch 2032/2438  on Training is 66.75940727988194\n",
            "Epoch #3. Accuracy on batch 2033/2438  on Training is 66.76192232055064\n",
            "Epoch #3. Accuracy on batch 2034/2438  on Training is 66.7644348894349\n",
            "Epoch #3. Accuracy on batch 2035/2438  on Training is 66.75620088408644\n",
            "Epoch #3. Accuracy on batch 2036/2438  on Training is 66.75257731958763\n",
            "Epoch #3. Accuracy on batch 2037/2438  on Training is 66.75202404317959\n",
            "Epoch #3. Accuracy on batch 2038/2438  on Training is 66.74840608141245\n",
            "Epoch #3. Accuracy on batch 2039/2438  on Training is 66.74632352941177\n",
            "Batch Id 2040/2438 is having training loss of 1.2528871297836304\n",
            "0.8964244723320007\n",
            "Epoch #3. Accuracy on batch 2040/2438  on Training is 66.75189857912788\n",
            "Epoch #3. Accuracy on batch 2041/2438  on Training is 66.74522526934378\n",
            "Epoch #3. Accuracy on batch 2042/2438  on Training is 66.74467694566813\n",
            "Epoch #3. Accuracy on batch 2043/2438  on Training is 66.74718688845401\n",
            "Epoch #3. Accuracy on batch 2044/2438  on Training is 66.7481662591687\n",
            "Epoch #3. Accuracy on batch 2045/2438  on Training is 66.74456256109482\n",
            "Epoch #3. Accuracy on batch 2046/2438  on Training is 66.75012212994626\n",
            "Epoch #3. Accuracy on batch 2047/2438  on Training is 66.75262451171875\n",
            "Epoch #3. Accuracy on batch 2048/2438  on Training is 66.7581747193753\n",
            "Epoch #3. Accuracy on batch 2049/2438  on Training is 66.7576219512195\n",
            "Epoch #3. Accuracy on batch 2050/2438  on Training is 66.75554607508532\n",
            "Epoch #3. Accuracy on batch 2051/2438  on Training is 66.75956384015595\n",
            "Epoch #3. Accuracy on batch 2052/2438  on Training is 66.75748904042864\n",
            "Epoch #3. Accuracy on batch 2053/2438  on Training is 66.74933057448881\n",
            "Epoch #3. Accuracy on batch 2054/2438  on Training is 66.75182481751825\n",
            "Epoch #3. Accuracy on batch 2055/2438  on Training is 66.752796692607\n",
            "Epoch #3. Accuracy on batch 2056/2438  on Training is 66.74921001458435\n",
            "Epoch #3. Accuracy on batch 2057/2438  on Training is 66.7471452866861\n",
            "Epoch #3. Accuracy on batch 2058/2438  on Training is 66.75267119961146\n",
            "Epoch #3. Accuracy on batch 2059/2438  on Training is 66.76122572815534\n",
            "Batch Id 2060/2438 is having training loss of 1.2526285648345947\n",
            "1.199372410774231\n",
            "Epoch #3. Accuracy on batch 2060/2438  on Training is 66.7591581756429\n",
            "Epoch #3. Accuracy on batch 2061/2438  on Training is 66.76163918525704\n",
            "Epoch #3. Accuracy on batch 2062/2438  on Training is 66.76260300533204\n",
            "Epoch #3. Accuracy on batch 2063/2438  on Training is 66.75902374031008\n",
            "Epoch #3. Accuracy on batch 2064/2438  on Training is 66.76906779661017\n",
            "Epoch #3. Accuracy on batch 2065/2438  on Training is 66.77456437560504\n",
            "Epoch #3. Accuracy on batch 2066/2438  on Training is 66.76644895984519\n",
            "Epoch #3. Accuracy on batch 2067/2438  on Training is 66.76891924564796\n",
            "Epoch #3. Accuracy on batch 2068/2438  on Training is 66.76836636056066\n",
            "Epoch #3. Accuracy on batch 2069/2438  on Training is 66.77083333333333\n",
            "Epoch #3. Accuracy on batch 2070/2438  on Training is 66.77631578947368\n",
            "Epoch #3. Accuracy on batch 2071/2438  on Training is 66.77726833976834\n",
            "Epoch #3. Accuracy on batch 2072/2438  on Training is 66.7767124939701\n",
            "Epoch #3. Accuracy on batch 2073/2438  on Training is 66.77615718418515\n",
            "Epoch #3. Accuracy on batch 2074/2438  on Training is 66.78313253012048\n",
            "Epoch #3. Accuracy on batch 2075/2438  on Training is 66.78859585741812\n",
            "Epoch #3. Accuracy on batch 2076/2438  on Training is 66.78352190659605\n",
            "Epoch #3. Accuracy on batch 2077/2438  on Training is 66.77845283926852\n",
            "Epoch #3. Accuracy on batch 2078/2438  on Training is 66.77789802789803\n",
            "Epoch #3. Accuracy on batch 2079/2438  on Training is 66.77584134615384\n",
            "Batch Id 2080/2438 is having training loss of 1.2516127824783325\n",
            "1.3068468570709229\n",
            "Epoch #3. Accuracy on batch 2080/2438  on Training is 66.77078327727054\n",
            "Epoch #3. Accuracy on batch 2081/2438  on Training is 66.7762367915466\n",
            "Epoch #3. Accuracy on batch 2082/2438  on Training is 66.77868458953432\n",
            "Epoch #3. Accuracy on batch 2083/2438  on Training is 66.78562859884836\n",
            "Epoch #3. Accuracy on batch 2084/2438  on Training is 66.78207434052757\n",
            "Epoch #3. Accuracy on batch 2085/2438  on Training is 66.77702540747843\n",
            "Epoch #3. Accuracy on batch 2086/2438  on Training is 66.7794681360805\n",
            "Epoch #3. Accuracy on batch 2087/2438  on Training is 66.78041187739464\n",
            "Epoch #3. Accuracy on batch 2088/2438  on Training is 66.7888343705122\n",
            "Epoch #3. Accuracy on batch 2089/2438  on Training is 66.79126794258373\n",
            "Epoch #3. Accuracy on batch 2090/2438  on Training is 66.79369918699187\n",
            "Epoch #3. Accuracy on batch 2091/2438  on Training is 66.79762189292543\n",
            "Epoch #3. Accuracy on batch 2092/2438  on Training is 66.80303392259914\n",
            "Epoch #3. Accuracy on batch 2093/2438  on Training is 66.79948662846228\n",
            "Epoch #3. Accuracy on batch 2094/2438  on Training is 66.79295942720763\n",
            "Epoch #3. Accuracy on batch 2095/2438  on Training is 66.79389312977099\n",
            "Epoch #3. Accuracy on batch 2096/2438  on Training is 66.79482594182166\n",
            "Epoch #3. Accuracy on batch 2097/2438  on Training is 66.79873689227836\n",
            "Epoch #3. Accuracy on batch 2098/2438  on Training is 66.80562172463078\n",
            "Epoch #3. Accuracy on batch 2099/2438  on Training is 66.79910714285714\n",
            "Batch Id 2100/2438 is having training loss of 1.2506330013275146\n",
            "1.501033067703247\n",
            "Epoch #3. Accuracy on batch 2100/2438  on Training is 66.79557353641123\n",
            "Epoch #3. Accuracy on batch 2101/2438  on Training is 66.79501665080875\n",
            "Epoch #3. Accuracy on batch 2102/2438  on Training is 66.79891821207798\n",
            "Epoch #3. Accuracy on batch 2103/2438  on Training is 66.80133079847909\n",
            "Epoch #3. Accuracy on batch 2104/2438  on Training is 66.80671021377673\n",
            "Epoch #3. Accuracy on batch 2105/2438  on Training is 66.8016975308642\n",
            "Epoch #3. Accuracy on batch 2106/2438  on Training is 66.80558851447556\n",
            "Epoch #3. Accuracy on batch 2107/2438  on Training is 66.80799335863378\n",
            "Epoch #3. Accuracy on batch 2108/2438  on Training is 66.80743243243244\n",
            "Epoch #3. Accuracy on batch 2109/2438  on Training is 66.80539099526067\n",
            "Epoch #3. Accuracy on batch 2110/2438  on Training is 66.81075319753671\n",
            "Epoch #3. Accuracy on batch 2111/2438  on Training is 66.81019176136364\n",
            "Epoch #3. Accuracy on batch 2112/2438  on Training is 66.8170255560814\n",
            "Epoch #3. Accuracy on batch 2113/2438  on Training is 66.82089640491958\n",
            "Epoch #3. Accuracy on batch 2114/2438  on Training is 66.81737588652483\n",
            "Epoch #3. Accuracy on batch 2115/2438  on Training is 66.81976606805293\n",
            "Epoch #3. Accuracy on batch 2116/2438  on Training is 66.8236301369863\n",
            "Epoch #3. Accuracy on batch 2117/2438  on Training is 66.8201133144476\n",
            "Epoch #3. Accuracy on batch 2118/2438  on Training is 66.81807456347333\n",
            "Epoch #3. Accuracy on batch 2119/2438  on Training is 66.81751179245283\n",
            "Batch Id 2120/2438 is having training loss of 1.2502665519714355\n",
            "1.379162311553955\n",
            "Epoch #3. Accuracy on batch 2120/2438  on Training is 66.81252946723244\n",
            "Epoch #3. Accuracy on batch 2121/2438  on Training is 66.8149151743638\n",
            "Epoch #3. Accuracy on batch 2122/2438  on Training is 66.81288271314178\n",
            "Epoch #3. Accuracy on batch 2123/2438  on Training is 66.81379472693033\n",
            "Epoch #3. Accuracy on batch 2124/2438  on Training is 66.81470588235294\n",
            "Epoch #3. Accuracy on batch 2125/2438  on Training is 66.82002587017874\n",
            "Epoch #3. Accuracy on batch 2126/2438  on Training is 66.82093323930418\n",
            "Epoch #3. Accuracy on batch 2127/2438  on Training is 66.8203712406015\n",
            "Epoch #3. Accuracy on batch 2128/2438  on Training is 66.82421324565524\n",
            "Epoch #3. Accuracy on batch 2129/2438  on Training is 66.8280516431925\n",
            "Epoch #3. Accuracy on batch 2130/2438  on Training is 66.82455419990615\n",
            "Epoch #3. Accuracy on batch 2131/2438  on Training is 66.8313203564728\n",
            "Epoch #3. Accuracy on batch 2132/2438  on Training is 66.82489451476793\n",
            "Epoch #3. Accuracy on batch 2133/2438  on Training is 66.83311855670104\n",
            "Epoch #3. Accuracy on batch 2134/2438  on Training is 66.836943793911\n",
            "Epoch #3. Accuracy on batch 2135/2438  on Training is 66.84222846441948\n",
            "Epoch #3. Accuracy on batch 2136/2438  on Training is 66.838734206832\n",
            "Epoch #3. Accuracy on batch 2137/2438  on Training is 66.84108980355472\n",
            "Epoch #3. Accuracy on batch 2138/2438  on Training is 66.84198223468911\n",
            "Epoch #3. Accuracy on batch 2139/2438  on Training is 66.84433411214954\n",
            "Batch Id 2140/2438 is having training loss of 1.248986840248108\n",
            "0.9447982311248779\n",
            "Epoch #3. Accuracy on batch 2140/2438  on Training is 66.84522419430172\n",
            "Epoch #3. Accuracy on batch 2141/2438  on Training is 66.85194911297853\n",
            "Epoch #3. Accuracy on batch 2142/2438  on Training is 66.84991833877741\n",
            "Epoch #3. Accuracy on batch 2143/2438  on Training is 66.85080457089552\n",
            "Epoch #3. Accuracy on batch 2144/2438  on Training is 66.85606060606061\n",
            "Epoch #3. Accuracy on batch 2145/2438  on Training is 66.85985554520038\n",
            "Epoch #3. Accuracy on batch 2146/2438  on Training is 66.85491383325571\n",
            "Epoch #3. Accuracy on batch 2147/2438  on Training is 66.85143156424581\n",
            "Epoch #3. Accuracy on batch 2148/2438  on Training is 66.84795253606329\n",
            "Epoch #3. Accuracy on batch 2149/2438  on Training is 66.84883720930233\n",
            "Epoch #3. Accuracy on batch 2150/2438  on Training is 66.85262668526266\n",
            "Epoch #3. Accuracy on batch 2151/2438  on Training is 66.85496050185874\n",
            "Epoch #3. Accuracy on batch 2152/2438  on Training is 66.85584068741291\n",
            "Epoch #3. Accuracy on batch 2153/2438  on Training is 66.86397400185702\n",
            "Epoch #3. Accuracy on batch 2154/2438  on Training is 66.86339907192576\n",
            "Epoch #3. Accuracy on batch 2155/2438  on Training is 66.86282467532467\n",
            "Epoch #3. Accuracy on batch 2156/2438  on Training is 66.86514835419564\n",
            "Epoch #3. Accuracy on batch 2157/2438  on Training is 66.86891797961076\n",
            "Epoch #3. Accuracy on batch 2158/2438  on Training is 66.8668943955535\n",
            "Epoch #3. Accuracy on batch 2159/2438  on Training is 66.87210648148148\n",
            "Batch Id 2160/2438 is having training loss of 1.247859239578247\n",
            "1.1785871982574463\n",
            "Epoch #3. Accuracy on batch 2160/2438  on Training is 66.86863720499768\n",
            "Epoch #3. Accuracy on batch 2161/2438  on Training is 66.86661655874191\n",
            "Epoch #3. Accuracy on batch 2162/2438  on Training is 66.86026352288488\n",
            "Epoch #3. Accuracy on batch 2163/2438  on Training is 66.86113678373383\n",
            "Epoch #3. Accuracy on batch 2164/2438  on Training is 66.85334872979215\n",
            "Epoch #3. Accuracy on batch 2165/2438  on Training is 66.85133887349954\n",
            "Epoch #3. Accuracy on batch 2166/2438  on Training is 66.84644670050761\n",
            "Epoch #3. Accuracy on batch 2167/2438  on Training is 66.84588330258302\n",
            "Epoch #3. Accuracy on batch 2168/2438  on Training is 66.84964269248502\n",
            "Epoch #3. Accuracy on batch 2169/2438  on Training is 66.84619815668202\n",
            "Epoch #3. Accuracy on batch 2170/2438  on Training is 66.84707508060802\n",
            "Epoch #3. Accuracy on batch 2171/2438  on Training is 66.8479511970534\n",
            "Epoch #3. Accuracy on batch 2172/2438  on Training is 66.85026461113668\n",
            "Epoch #3. Accuracy on batch 2173/2438  on Training is 66.85113845446182\n",
            "Epoch #3. Accuracy on batch 2174/2438  on Training is 66.85057471264368\n",
            "Epoch #3. Accuracy on batch 2175/2438  on Training is 66.84283088235294\n",
            "Epoch #3. Accuracy on batch 2176/2438  on Training is 66.84801332108407\n",
            "Epoch #3. Accuracy on batch 2177/2438  on Training is 66.84601698806244\n",
            "Epoch #3. Accuracy on batch 2178/2438  on Training is 66.84975906379073\n",
            "Epoch #3. Accuracy on batch 2179/2438  on Training is 66.8520642201835\n",
            "Batch Id 2180/2438 is having training loss of 1.2477678060531616\n",
            "1.1686073541641235\n",
            "Epoch #3. Accuracy on batch 2180/2438  on Training is 66.85293443374599\n",
            "Epoch #3. Accuracy on batch 2181/2438  on Training is 66.84950733272227\n",
            "Epoch #3. Accuracy on batch 2182/2438  on Training is 66.84751488776912\n",
            "Epoch #3. Accuracy on batch 2183/2438  on Training is 66.84552426739927\n",
            "Epoch #3. Accuracy on batch 2184/2438  on Training is 66.84067505720824\n",
            "Epoch #3. Accuracy on batch 2185/2438  on Training is 66.83297118023788\n",
            "Epoch #3. Accuracy on batch 2186/2438  on Training is 66.83384773662551\n",
            "Epoch #3. Accuracy on batch 2187/2438  on Training is 66.83329524680073\n",
            "Epoch #3. Accuracy on batch 2188/2438  on Training is 66.83559844677936\n",
            "Epoch #3. Accuracy on batch 2189/2438  on Training is 66.83361872146119\n",
            "Epoch #3. Accuracy on batch 2190/2438  on Training is 66.83306709265176\n",
            "Epoch #3. Accuracy on batch 2191/2438  on Training is 66.83394160583941\n",
            "Epoch #3. Accuracy on batch 2192/2438  on Training is 66.8376652986776\n",
            "Epoch #3. Accuracy on batch 2193/2438  on Training is 66.8399612579763\n",
            "Epoch #3. Accuracy on batch 2194/2438  on Training is 66.8379840546697\n",
            "Epoch #3. Accuracy on batch 2195/2438  on Training is 66.83885473588343\n",
            "Epoch #3. Accuracy on batch 2196/2438  on Training is 66.83972462448794\n",
            "Epoch #3. Accuracy on batch 2197/2438  on Training is 66.84059372156506\n",
            "Epoch #3. Accuracy on batch 2198/2438  on Training is 66.84714643019554\n",
            "Epoch #3. Accuracy on batch 2199/2438  on Training is 66.84801136363636\n",
            "Batch Id 2200/2438 is having training loss of 1.2481361627578735\n",
            "1.3565082550048828\n",
            "Epoch #3. Accuracy on batch 2200/2438  on Training is 66.84603589277602\n",
            "Epoch #3. Accuracy on batch 2201/2438  on Training is 66.84690054495913\n",
            "Epoch #3. Accuracy on batch 2202/2438  on Training is 66.84350885156604\n",
            "Epoch #3. Accuracy on batch 2203/2438  on Training is 66.83728448275862\n",
            "Epoch #3. Accuracy on batch 2204/2438  on Training is 66.83673469387755\n",
            "Epoch #3. Accuracy on batch 2205/2438  on Training is 66.83476881233001\n",
            "Epoch #3. Accuracy on batch 2206/2438  on Training is 66.83563661078387\n",
            "Epoch #3. Accuracy on batch 2207/2438  on Training is 66.83367300724638\n",
            "Epoch #3. Accuracy on batch 2208/2438  on Training is 66.83595518334087\n",
            "Epoch #3. Accuracy on batch 2209/2438  on Training is 66.83823529411765\n",
            "Epoch #3. Accuracy on batch 2210/2438  on Training is 66.83344640434193\n",
            "Epoch #3. Accuracy on batch 2211/2438  on Training is 66.83148734177215\n",
            "Epoch #3. Accuracy on batch 2212/2438  on Training is 66.83376638047899\n",
            "Epoch #3. Accuracy on batch 2213/2438  on Training is 66.83039747064137\n",
            "Epoch #3. Accuracy on batch 2214/2438  on Training is 66.83408577878104\n",
            "Epoch #3. Accuracy on batch 2215/2438  on Training is 66.83777075812274\n",
            "Epoch #3. Accuracy on batch 2216/2438  on Training is 66.83581416328371\n",
            "Epoch #3. Accuracy on batch 2217/2438  on Training is 66.83949504057709\n",
            "Epoch #3. Accuracy on batch 2218/2438  on Training is 66.84176430824695\n",
            "Epoch #3. Accuracy on batch 2219/2438  on Training is 66.84403153153153\n",
            "Batch Id 2220/2438 is having training loss of 1.2483630180358887\n",
            "1.1330726146697998\n",
            "Epoch #3. Accuracy on batch 2220/2438  on Training is 66.84348266546601\n",
            "Epoch #3. Accuracy on batch 2221/2438  on Training is 66.84715346534654\n",
            "Epoch #3. Accuracy on batch 2222/2438  on Training is 66.84800944669365\n",
            "Epoch #3. Accuracy on batch 2223/2438  on Training is 66.84464928057554\n",
            "Epoch #3. Accuracy on batch 2224/2438  on Training is 66.84269662921348\n",
            "Epoch #3. Accuracy on batch 2225/2438  on Training is 66.84355345911949\n",
            "Epoch #3. Accuracy on batch 2226/2438  on Training is 66.844409519533\n",
            "Epoch #3. Accuracy on batch 2227/2438  on Training is 66.84105700179533\n",
            "Epoch #3. Accuracy on batch 2228/2438  on Training is 66.83770749214895\n",
            "Epoch #3. Accuracy on batch 2229/2438  on Training is 66.84276905829596\n",
            "Epoch #3. Accuracy on batch 2230/2438  on Training is 66.84222321828776\n",
            "Epoch #3. Accuracy on batch 2231/2438  on Training is 66.84027777777777\n",
            "Epoch #3. Accuracy on batch 2232/2438  on Training is 66.84393193013882\n",
            "Epoch #3. Accuracy on batch 2233/2438  on Training is 66.837790957923\n",
            "Epoch #3. Accuracy on batch 2234/2438  on Training is 66.83585011185683\n",
            "Epoch #3. Accuracy on batch 2235/2438  on Training is 66.84089892665475\n",
            "Epoch #3. Accuracy on batch 2236/2438  on Training is 66.83616450603486\n",
            "Epoch #3. Accuracy on batch 2237/2438  on Training is 66.83422698838248\n",
            "Epoch #3. Accuracy on batch 2238/2438  on Training is 66.84066547565878\n",
            "Epoch #3. Accuracy on batch 2239/2438  on Training is 66.83733258928571\n",
            "Batch Id 2240/2438 is having training loss of 1.2486916780471802\n",
            "1.3883525133132935\n",
            "Epoch #3. Accuracy on batch 2240/2438  on Training is 66.83539714413209\n",
            "Epoch #3. Accuracy on batch 2241/2438  on Training is 66.83625111507583\n",
            "Epoch #3. Accuracy on batch 2242/2438  on Training is 66.83431787784218\n",
            "Epoch #3. Accuracy on batch 2243/2438  on Training is 66.8337789661319\n",
            "Epoch #3. Accuracy on batch 2244/2438  on Training is 66.83463251670379\n",
            "Epoch #3. Accuracy on batch 2245/2438  on Training is 66.83131121994657\n",
            "Epoch #3. Accuracy on batch 2246/2438  on Training is 66.83494659546061\n",
            "Epoch #3. Accuracy on batch 2247/2438  on Training is 66.83579848754448\n",
            "Epoch #3. Accuracy on batch 2248/2438  on Training is 66.8297020898177\n",
            "Epoch #3. Accuracy on batch 2249/2438  on Training is 66.83055555555555\n",
            "Epoch #3. Accuracy on batch 2250/2438  on Training is 66.82307863171924\n",
            "Epoch #3. Accuracy on batch 2251/2438  on Training is 66.82948490230906\n",
            "Epoch #3. Accuracy on batch 2252/2438  on Training is 66.82340213049268\n",
            "Epoch #3. Accuracy on batch 2253/2438  on Training is 66.81593833185448\n",
            "Epoch #3. Accuracy on batch 2254/2438  on Training is 66.81263858093126\n",
            "Epoch #3. Accuracy on batch 2255/2438  on Training is 66.81349734042553\n",
            "Epoch #3. Accuracy on batch 2256/2438  on Training is 66.81573992024812\n",
            "Epoch #3. Accuracy on batch 2257/2438  on Training is 66.8165965456156\n",
            "Epoch #3. Accuracy on batch 2258/2438  on Training is 66.8146857016379\n",
            "Epoch #3. Accuracy on batch 2259/2438  on Training is 66.8141592920354\n",
            "Batch Id 2260/2438 is having training loss of 1.2495388984680176\n",
            "1.3723993301391602\n",
            "Epoch #3. Accuracy on batch 2260/2438  on Training is 66.81363334807607\n",
            "Epoch #3. Accuracy on batch 2261/2438  on Training is 66.81863395225464\n",
            "Epoch #3. Accuracy on batch 2262/2438  on Training is 66.82086831639417\n",
            "Epoch #3. Accuracy on batch 2263/2438  on Training is 66.82172040636043\n",
            "Epoch #3. Accuracy on batch 2264/2438  on Training is 66.82395143487858\n",
            "Epoch #3. Accuracy on batch 2265/2438  on Training is 66.81928508384819\n",
            "Epoch #3. Accuracy on batch 2266/2438  on Training is 66.8160013233348\n",
            "Epoch #3. Accuracy on batch 2267/2438  on Training is 66.82236552028219\n",
            "Epoch #3. Accuracy on batch 2268/2438  on Training is 66.82321507271926\n",
            "Epoch #3. Accuracy on batch 2269/2438  on Training is 66.82268722466961\n",
            "Epoch #3. Accuracy on batch 2270/2438  on Training is 66.8180317040951\n",
            "Epoch #3. Accuracy on batch 2271/2438  on Training is 66.81338028169014\n",
            "Epoch #3. Accuracy on batch 2272/2438  on Training is 66.81285745710515\n",
            "Epoch #3. Accuracy on batch 2273/2438  on Training is 66.80821240105541\n",
            "Epoch #3. Accuracy on batch 2274/2438  on Training is 66.81318681318682\n",
            "Epoch #3. Accuracy on batch 2275/2438  on Training is 66.81678383128295\n",
            "Epoch #3. Accuracy on batch 2276/2438  on Training is 66.81077075098814\n",
            "Epoch #3. Accuracy on batch 2277/2438  on Training is 66.8143656716418\n",
            "Epoch #3. Accuracy on batch 2278/2438  on Training is 66.81658622202721\n",
            "Epoch #3. Accuracy on batch 2279/2438  on Training is 66.81743421052632\n",
            "Batch Id 2280/2438 is having training loss of 1.2494641542434692\n",
            "1.2642687559127808\n",
            "Epoch #3. Accuracy on batch 2280/2438  on Training is 66.81280140289347\n",
            "Epoch #3. Accuracy on batch 2281/2438  on Training is 66.81228089395267\n",
            "Epoch #3. Accuracy on batch 2282/2438  on Training is 66.81449846692948\n",
            "Epoch #3. Accuracy on batch 2283/2438  on Training is 66.81260945709282\n",
            "Epoch #3. Accuracy on batch 2284/2438  on Training is 66.81072210065645\n",
            "Epoch #3. Accuracy on batch 2285/2438  on Training is 66.81977252843394\n",
            "Epoch #3. Accuracy on batch 2286/2438  on Training is 66.81515085264539\n",
            "Epoch #3. Accuracy on batch 2287/2438  on Training is 66.81053321678321\n",
            "Epoch #3. Accuracy on batch 2288/2438  on Training is 66.81547619047619\n",
            "Epoch #3. Accuracy on batch 2289/2438  on Training is 66.81359170305677\n",
            "Epoch #3. Accuracy on batch 2290/2438  on Training is 66.81716499345264\n",
            "Epoch #3. Accuracy on batch 2291/2438  on Training is 66.81664485165794\n",
            "Epoch #3. Accuracy on batch 2292/2438  on Training is 66.81612516354122\n",
            "Epoch #3. Accuracy on batch 2293/2438  on Training is 66.80879468177855\n",
            "Epoch #3. Accuracy on batch 2294/2438  on Training is 66.80964052287581\n",
            "Epoch #3. Accuracy on batch 2295/2438  on Training is 66.81592987804878\n",
            "Epoch #3. Accuracy on batch 2296/2438  on Training is 66.81269046582499\n",
            "Epoch #3. Accuracy on batch 2297/2438  on Training is 66.8108137510879\n",
            "Epoch #3. Accuracy on batch 2298/2438  on Training is 66.81029795563289\n",
            "Epoch #3. Accuracy on batch 2299/2438  on Training is 66.81114130434783\n",
            "Batch Id 2300/2438 is having training loss of 1.248923897743225\n",
            "1.0555808544158936\n",
            "Epoch #3. Accuracy on batch 2300/2438  on Training is 66.8106258148631\n",
            "Epoch #3. Accuracy on batch 2301/2438  on Training is 66.80739574283231\n",
            "Epoch #3. Accuracy on batch 2302/2438  on Training is 66.81231003039514\n",
            "Epoch #3. Accuracy on batch 2303/2438  on Training is 66.81450737847223\n",
            "Epoch #3. Accuracy on batch 2304/2438  on Training is 66.81399132321042\n",
            "Epoch #3. Accuracy on batch 2305/2438  on Training is 66.81889635732871\n",
            "Epoch #3. Accuracy on batch 2306/2438  on Training is 66.82244256610316\n",
            "Epoch #3. Accuracy on batch 2307/2438  on Training is 66.81515381282496\n",
            "Epoch #3. Accuracy on batch 2308/2438  on Training is 66.81869857080987\n",
            "Epoch #3. Accuracy on batch 2309/2438  on Training is 66.81953463203463\n",
            "Epoch #3. Accuracy on batch 2310/2438  on Training is 66.82307442665513\n",
            "Epoch #3. Accuracy on batch 2311/2438  on Training is 66.82525951557093\n",
            "Epoch #3. Accuracy on batch 2312/2438  on Training is 66.82744271508862\n",
            "Epoch #3. Accuracy on batch 2313/2438  on Training is 66.83097450302506\n",
            "Epoch #3. Accuracy on batch 2314/2438  on Training is 66.83585313174946\n",
            "Epoch #3. Accuracy on batch 2315/2438  on Training is 66.84882340241796\n",
            "Epoch #3. Accuracy on batch 2316/2438  on Training is 66.8442490289167\n",
            "Epoch #3. Accuracy on batch 2317/2438  on Training is 66.84776747195859\n",
            "Epoch #3. Accuracy on batch 2318/2438  on Training is 66.84993531694695\n",
            "Epoch #3. Accuracy on batch 2319/2438  on Training is 66.85210129310344\n",
            "Batch Id 2320/2438 is having training loss of 1.2475612163543701\n",
            "1.0466331243515015\n",
            "Epoch #3. Accuracy on batch 2320/2438  on Training is 66.8515725980181\n",
            "Epoch #3. Accuracy on batch 2321/2438  on Training is 66.8510443583118\n",
            "Epoch #3. Accuracy on batch 2322/2438  on Training is 66.84648084373654\n",
            "Epoch #3. Accuracy on batch 2323/2438  on Training is 66.84461058519794\n",
            "Epoch #3. Accuracy on batch 2324/2438  on Training is 66.84946236559139\n",
            "Epoch #3. Accuracy on batch 2325/2438  on Training is 66.85296646603611\n",
            "Epoch #3. Accuracy on batch 2326/2438  on Training is 66.85646755479158\n",
            "Epoch #3. Accuracy on batch 2327/2438  on Training is 66.86130798969072\n",
            "Epoch #3. Accuracy on batch 2328/2438  on Training is 66.85675182481752\n",
            "Epoch #3. Accuracy on batch 2329/2438  on Training is 66.85890557939913\n",
            "Epoch #3. Accuracy on batch 2330/2438  on Training is 66.86105748605749\n",
            "Epoch #3. Accuracy on batch 2331/2438  on Training is 66.86186749571183\n",
            "Epoch #3. Accuracy on batch 2332/2438  on Training is 66.86401628804114\n",
            "Epoch #3. Accuracy on batch 2333/2438  on Training is 66.86080762639246\n",
            "Epoch #3. Accuracy on batch 2334/2438  on Training is 66.86295503211991\n",
            "Epoch #3. Accuracy on batch 2335/2438  on Training is 66.85707405821918\n",
            "Epoch #3. Accuracy on batch 2336/2438  on Training is 66.85922122379118\n",
            "Epoch #3. Accuracy on batch 2337/2438  on Training is 66.85735671514115\n",
            "Epoch #3. Accuracy on batch 2338/2438  on Training is 66.8595019238991\n",
            "Epoch #3. Accuracy on batch 2339/2438  on Training is 66.86030982905983\n",
            "Batch Id 2340/2438 is having training loss of 1.2472243309020996\n",
            "1.0902268886566162\n",
            "Epoch #3. Accuracy on batch 2340/2438  on Training is 66.86645664246049\n",
            "Epoch #3. Accuracy on batch 2341/2438  on Training is 66.8672608881298\n",
            "Epoch #3. Accuracy on batch 2342/2438  on Training is 66.87073196756296\n",
            "Epoch #3. Accuracy on batch 2343/2438  on Training is 66.87286689419795\n",
            "Epoch #3. Accuracy on batch 2344/2438  on Training is 66.87100213219617\n",
            "Epoch #3. Accuracy on batch 2345/2438  on Training is 66.8691389599318\n",
            "Epoch #3. Accuracy on batch 2346/2438  on Training is 66.87127183638688\n",
            "Epoch #3. Accuracy on batch 2347/2438  on Training is 66.86807921635435\n",
            "Epoch #3. Accuracy on batch 2348/2438  on Training is 66.8688803746275\n",
            "Epoch #3. Accuracy on batch 2349/2438  on Training is 66.87367021276596\n",
            "Epoch #3. Accuracy on batch 2350/2438  on Training is 66.87845597618035\n",
            "Epoch #3. Accuracy on batch 2351/2438  on Training is 66.87393707482993\n",
            "Epoch #3. Accuracy on batch 2352/2438  on Training is 66.87739056523587\n",
            "Epoch #3. Accuracy on batch 2353/2438  on Training is 66.87287595581988\n",
            "Epoch #3. Accuracy on batch 2354/2438  on Training is 66.875\n",
            "Epoch #3. Accuracy on batch 2355/2438  on Training is 66.88110144312394\n",
            "Epoch #3. Accuracy on batch 2356/2438  on Training is 66.87659100551548\n",
            "Epoch #3. Accuracy on batch 2357/2438  on Training is 66.87208439355386\n",
            "Epoch #3. Accuracy on batch 2358/2438  on Training is 66.8715557439593\n",
            "Epoch #3. Accuracy on batch 2359/2438  on Training is 66.86705508474576\n",
            "Batch Id 2360/2438 is having training loss of 1.2467870712280273\n",
            "1.063444972038269\n",
            "Epoch #3. Accuracy on batch 2360/2438  on Training is 66.86652901313003\n",
            "Epoch #3. Accuracy on batch 2361/2438  on Training is 66.8739415749365\n",
            "Epoch #3. Accuracy on batch 2362/2438  on Training is 66.8760579771477\n",
            "Epoch #3. Accuracy on batch 2363/2438  on Training is 66.87685067681895\n",
            "Epoch #3. Accuracy on batch 2364/2438  on Training is 66.875\n",
            "Epoch #3. Accuracy on batch 2365/2438  on Training is 66.86654691462384\n",
            "Epoch #3. Accuracy on batch 2366/2438  on Training is 66.86206168145331\n",
            "Epoch #3. Accuracy on batch 2367/2438  on Training is 66.86285895270271\n",
            "Epoch #3. Accuracy on batch 2368/2438  on Training is 66.86101730688054\n",
            "Epoch #3. Accuracy on batch 2369/2438  on Training is 66.85917721518987\n",
            "Epoch #3. Accuracy on batch 2370/2438  on Training is 66.85733867566428\n",
            "Epoch #3. Accuracy on batch 2371/2438  on Training is 66.8620889544688\n",
            "Epoch #3. Accuracy on batch 2372/2438  on Training is 66.85761694058154\n",
            "Epoch #3. Accuracy on batch 2373/2438  on Training is 66.85973041280539\n",
            "Epoch #3. Accuracy on batch 2374/2438  on Training is 66.8578947368421\n",
            "Epoch #3. Accuracy on batch 2375/2438  on Training is 66.85737584175084\n",
            "Epoch #3. Accuracy on batch 2376/2438  on Training is 66.85422801851072\n",
            "Epoch #3. Accuracy on batch 2377/2438  on Training is 66.8563393608074\n",
            "Epoch #3. Accuracy on batch 2378/2438  on Training is 66.85582177385456\n",
            "Epoch #3. Accuracy on batch 2379/2438  on Training is 66.85530462184875\n",
            "Batch Id 2380/2438 is having training loss of 1.2465994358062744\n",
            "1.1317555904388428\n",
            "Epoch #3. Accuracy on batch 2380/2438  on Training is 66.86003779924401\n",
            "Epoch #3. Accuracy on batch 2381/2438  on Training is 66.86083123425692\n",
            "Epoch #3. Accuracy on batch 2382/2438  on Training is 66.85244439781788\n",
            "Epoch #3. Accuracy on batch 2383/2438  on Training is 66.85192953020135\n",
            "Epoch #3. Accuracy on batch 2384/2438  on Training is 66.85272536687631\n",
            "Epoch #3. Accuracy on batch 2385/2438  on Training is 66.85221081307628\n",
            "Epoch #3. Accuracy on batch 2386/2438  on Training is 66.8543150397989\n",
            "Epoch #3. Accuracy on batch 2387/2438  on Training is 66.85118299832496\n",
            "Epoch #3. Accuracy on batch 2388/2438  on Training is 66.85066973629134\n",
            "Epoch #3. Accuracy on batch 2389/2438  on Training is 66.85930962343096\n",
            "Epoch #3. Accuracy on batch 2390/2438  on Training is 66.86402132998745\n",
            "Epoch #3. Accuracy on batch 2391/2438  on Training is 66.86872909698997\n",
            "Epoch #3. Accuracy on batch 2392/2438  on Training is 66.8721270371918\n",
            "Epoch #3. Accuracy on batch 2393/2438  on Training is 66.87682748538012\n",
            "Epoch #3. Accuracy on batch 2394/2438  on Training is 66.87239039665971\n",
            "Epoch #3. Accuracy on batch 2395/2438  on Training is 66.8692612687813\n",
            "Epoch #3. Accuracy on batch 2396/2438  on Training is 66.86743846474761\n",
            "Epoch #3. Accuracy on batch 2397/2438  on Training is 66.8669203502919\n",
            "Epoch #3. Accuracy on batch 2398/2438  on Training is 66.86379741558983\n",
            "Epoch #3. Accuracy on batch 2399/2438  on Training is 66.86328125\n",
            "Batch Id 2400/2438 is having training loss of 1.2465459108352661\n",
            "1.2076448202133179\n",
            "Epoch #3. Accuracy on batch 2400/2438  on Training is 66.86146397334444\n",
            "Epoch #3. Accuracy on batch 2401/2438  on Training is 66.86355120732723\n",
            "Epoch #3. Accuracy on batch 2402/2438  on Training is 66.86303578859759\n",
            "Epoch #3. Accuracy on batch 2403/2438  on Training is 66.86902038269551\n",
            "Epoch #3. Accuracy on batch 2404/2438  on Training is 66.87110187110187\n",
            "Epoch #3. Accuracy on batch 2405/2438  on Training is 66.87318162926019\n",
            "Epoch #3. Accuracy on batch 2406/2438  on Training is 66.86487328624844\n",
            "Epoch #3. Accuracy on batch 2407/2438  on Training is 66.86695390365449\n",
            "Epoch #3. Accuracy on batch 2408/2438  on Training is 66.86384391863844\n",
            "Epoch #3. Accuracy on batch 2409/2438  on Training is 66.8646265560166\n",
            "Epoch #3. Accuracy on batch 2410/2438  on Training is 66.86540854417254\n",
            "Epoch #3. Accuracy on batch 2411/2438  on Training is 66.85971185737976\n",
            "Epoch #3. Accuracy on batch 2412/2438  on Training is 66.86308537090758\n",
            "Epoch #3. Accuracy on batch 2413/2438  on Training is 66.86127796188899\n",
            "Epoch #3. Accuracy on batch 2414/2438  on Training is 66.8646480331263\n",
            "Epoch #3. Accuracy on batch 2415/2438  on Training is 66.86154801324503\n",
            "Epoch #3. Accuracy on batch 2416/2438  on Training is 66.85974348365743\n",
            "Epoch #3. Accuracy on batch 2417/2438  on Training is 66.86311000827129\n",
            "Epoch #3. Accuracy on batch 2418/2438  on Training is 66.85872261264986\n",
            "Epoch #3. Accuracy on batch 2419/2438  on Training is 66.86337809917356\n",
            "Batch Id 2420/2438 is having training loss of 1.2462953329086304\n",
            "1.3691850900650024\n",
            "Epoch #3. Accuracy on batch 2420/2438  on Training is 66.86415737298637\n",
            "Epoch #3. Accuracy on batch 2421/2438  on Training is 66.86622625928985\n",
            "Epoch #3. Accuracy on batch 2422/2438  on Training is 66.86829343788692\n",
            "Epoch #3. Accuracy on batch 2423/2438  on Training is 66.87293729372938\n",
            "Epoch #3. Accuracy on batch 2424/2438  on Training is 66.86984536082474\n",
            "Epoch #3. Accuracy on batch 2425/2438  on Training is 66.87190849134377\n",
            "Epoch #3. Accuracy on batch 2426/2438  on Training is 66.87139472599918\n",
            "Epoch #3. Accuracy on batch 2427/2438  on Training is 66.8670201812191\n",
            "Epoch #3. Accuracy on batch 2428/2438  on Training is 66.86393577603953\n",
            "Epoch #3. Accuracy on batch 2429/2438  on Training is 66.85956790123457\n",
            "Epoch #3. Accuracy on batch 2430/2438  on Training is 66.8642019744961\n",
            "Epoch #3. Accuracy on batch 2431/2438  on Training is 66.86369243421052\n",
            "Epoch #3. Accuracy on batch 2432/2438  on Training is 66.85804562268804\n",
            "Epoch #3. Accuracy on batch 2433/2438  on Training is 66.86267460969597\n",
            "Epoch #3. Accuracy on batch 2434/2438  on Training is 66.86344969199179\n",
            "Epoch #3. Accuracy on batch 2435/2438  on Training is 66.86165845648604\n",
            "Epoch #3. Accuracy on batch 2436/2438  on Training is 66.86628026261798\n",
            "Epoch #3. Accuracy on batch 2437/2438  on Training is 66.86666666666666\n",
            "Epoch #3. Batch Id 0/278  is having validation loss of 1.295388102531433\n",
            "1.295388102531433\n",
            "Epoch #3. Batch Id 0/278  is having validation accuracy of 59.375\n",
            "Epoch #3. Batch Id 1/278  is having validation loss of 1.3330297470092773\n",
            "1.370671272277832\n",
            "Epoch #3. Batch Id 1/278  is having validation accuracy of 62.5\n",
            "Epoch #3. Batch Id 2/278  is having validation loss of 1.3151389360427856\n",
            "1.2793574333190918\n",
            "Epoch #3. Batch Id 2/278  is having validation accuracy of 62.5\n",
            "Epoch #3. Batch Id 3/278  is having validation loss of 1.2107131481170654\n",
            "0.8974356651306152\n",
            "Epoch #3. Batch Id 3/278  is having validation accuracy of 64.0625\n",
            "Epoch #3. Batch Id 4/278  is having validation loss of 1.410446286201477\n",
            "2.209378957748413\n",
            "Epoch #3. Batch Id 4/278  is having validation accuracy of 59.375\n",
            "Epoch #3. Batch Id 5/278  is having validation loss of 1.4498825073242188\n",
            "1.6470634937286377\n",
            "Epoch #3. Batch Id 5/278  is having validation accuracy of 60.9375\n",
            "Epoch #3. Batch Id 6/278  is having validation loss of 1.4771926403045654\n",
            "1.6410536766052246\n",
            "Epoch #3. Batch Id 6/278  is having validation accuracy of 60.714285714285715\n",
            "Epoch #3. Batch Id 7/278  is having validation loss of 1.4779633283615112\n",
            "1.483358383178711\n",
            "Epoch #3. Batch Id 7/278  is having validation accuracy of 59.375\n",
            "Epoch #3. Batch Id 8/278  is having validation loss of 1.4545998573303223\n",
            "1.2676923274993896\n",
            "Epoch #3. Batch Id 8/278  is having validation accuracy of 58.333333333333336\n",
            "Epoch #3. Batch Id 9/278  is having validation loss of 1.4057705402374268\n",
            "0.9663065075874329\n",
            "Epoch #3. Batch Id 9/278  is having validation accuracy of 59.6875\n",
            "Epoch #3. Batch Id 10/278  is having validation loss of 1.40959894657135\n",
            "1.4478833675384521\n",
            "Epoch #3. Batch Id 10/278  is having validation accuracy of 59.65909090909091\n",
            "Epoch #3. Batch Id 11/278  is having validation loss of 1.3925584554672241\n",
            "1.205113172531128\n",
            "Epoch #3. Batch Id 11/278  is having validation accuracy of 59.895833333333336\n",
            "Epoch #3. Batch Id 12/278  is having validation loss of 1.3960812091827393\n",
            "1.438354253768921\n",
            "Epoch #3. Batch Id 12/278  is having validation accuracy of 60.09615384615385\n",
            "Epoch #3. Batch Id 13/278  is having validation loss of 1.4072290658950806\n",
            "1.5521506071090698\n",
            "Epoch #3. Batch Id 13/278  is having validation accuracy of 59.598214285714285\n",
            "Epoch #3. Batch Id 14/278  is having validation loss of 1.3955271244049072\n",
            "1.231699824333191\n",
            "Epoch #3. Batch Id 14/278  is having validation accuracy of 60.416666666666664\n",
            "Epoch #3. Batch Id 15/278  is having validation loss of 1.3962786197662354\n",
            "1.4075514078140259\n",
            "Epoch #3. Batch Id 15/278  is having validation accuracy of 60.7421875\n",
            "Epoch #3. Batch Id 16/278  is having validation loss of 1.4084877967834473\n",
            "1.6038343906402588\n",
            "Epoch #3. Batch Id 16/278  is having validation accuracy of 60.661764705882355\n",
            "Epoch #3. Batch Id 17/278  is having validation loss of 1.4213478565216064\n",
            "1.6399691104888916\n",
            "Epoch #3. Batch Id 17/278  is having validation accuracy of 60.24305555555556\n",
            "Epoch #3. Batch Id 18/278  is having validation loss of 1.415396809577942\n",
            "1.3082787990570068\n",
            "Epoch #3. Batch Id 18/278  is having validation accuracy of 61.01973684210526\n",
            "Epoch #3. Batch Id 19/278  is having validation loss of 1.4177511930465698\n",
            "1.4624842405319214\n",
            "Epoch #3. Batch Id 19/278  is having validation accuracy of 61.25\n",
            "Epoch #3. Batch Id 20/278  is having validation loss of 1.417581558227539\n",
            "1.4141877889633179\n",
            "Epoch #3. Batch Id 20/278  is having validation accuracy of 61.01190476190476\n",
            "Epoch #3. Batch Id 21/278  is having validation loss of 1.4178507328033447\n",
            "1.4235047101974487\n",
            "Epoch #3. Batch Id 21/278  is having validation accuracy of 61.22159090909091\n",
            "Epoch #3. Batch Id 22/278  is having validation loss of 1.3844047784805298\n",
            "0.6485931277275085\n",
            "Epoch #3. Batch Id 22/278  is having validation accuracy of 62.09239130434783\n",
            "Epoch #3. Batch Id 23/278  is having validation loss of 1.3908922672271729\n",
            "1.5401052236557007\n",
            "Epoch #3. Batch Id 23/278  is having validation accuracy of 62.369791666666664\n",
            "Epoch #3. Batch Id 24/278  is having validation loss of 1.3751226663589478\n",
            "0.9966510534286499\n",
            "Epoch #3. Batch Id 24/278  is having validation accuracy of 62.75\n",
            "Epoch #3. Batch Id 25/278  is having validation loss of 1.3816490173339844\n",
            "1.544808030128479\n",
            "Epoch #3. Batch Id 25/278  is having validation accuracy of 62.62019230769231\n",
            "Epoch #3. Batch Id 26/278  is having validation loss of 1.3971257209777832\n",
            "1.7995202541351318\n",
            "Epoch #3. Batch Id 26/278  is having validation accuracy of 62.26851851851852\n",
            "Epoch #3. Batch Id 27/278  is having validation loss of 1.3946857452392578\n",
            "1.3288078308105469\n",
            "Epoch #3. Batch Id 27/278  is having validation accuracy of 62.611607142857146\n",
            "Epoch #3. Batch Id 28/278  is having validation loss of 1.4092239141464233\n",
            "1.816292405128479\n",
            "Epoch #3. Batch Id 28/278  is having validation accuracy of 62.17672413793103\n",
            "Epoch #3. Batch Id 29/278  is having validation loss of 1.4061520099639893\n",
            "1.3170682191848755\n",
            "Epoch #3. Batch Id 29/278  is having validation accuracy of 61.770833333333336\n",
            "Epoch #3. Batch Id 30/278  is having validation loss of 1.403191328048706\n",
            "1.31437087059021\n",
            "Epoch #3. Batch Id 30/278  is having validation accuracy of 62.096774193548384\n",
            "Epoch #3. Batch Id 31/278  is having validation loss of 1.4040448665618896\n",
            "1.4305061101913452\n",
            "Epoch #3. Batch Id 31/278  is having validation accuracy of 62.3046875\n",
            "Epoch #3. Batch Id 32/278  is having validation loss of 1.4071500301361084\n",
            "1.5065171718597412\n",
            "Epoch #3. Batch Id 32/278  is having validation accuracy of 62.40530303030303\n",
            "Epoch #3. Batch Id 33/278  is having validation loss of 1.4058514833450317\n",
            "1.3630000352859497\n",
            "Epoch #3. Batch Id 33/278  is having validation accuracy of 62.591911764705884\n",
            "Epoch #3. Batch Id 34/278  is having validation loss of 1.4213882684707642\n",
            "1.9496409893035889\n",
            "Epoch #3. Batch Id 34/278  is having validation accuracy of 62.32142857142857\n",
            "Epoch #3. Batch Id 35/278  is having validation loss of 1.4157565832138062\n",
            "1.2186464071273804\n",
            "Epoch #3. Batch Id 35/278  is having validation accuracy of 62.5\n",
            "Epoch #3. Batch Id 36/278  is having validation loss of 1.4087903499603271\n",
            "1.1580047607421875\n",
            "Epoch #3. Batch Id 36/278  is having validation accuracy of 62.83783783783784\n",
            "Epoch #3. Batch Id 37/278  is having validation loss of 1.407517910003662\n",
            "1.3604390621185303\n",
            "Epoch #3. Batch Id 37/278  is having validation accuracy of 62.828947368421055\n",
            "Epoch #3. Batch Id 38/278  is having validation loss of 1.4078254699707031\n",
            "1.4195104837417603\n",
            "Epoch #3. Batch Id 38/278  is having validation accuracy of 62.90064102564103\n",
            "Epoch #3. Batch Id 39/278  is having validation loss of 1.4035823345184326\n",
            "1.2381024360656738\n",
            "Epoch #3. Batch Id 39/278  is having validation accuracy of 63.125\n",
            "Epoch #3. Batch Id 40/278  is having validation loss of 1.4104523658752441\n",
            "1.6852545738220215\n",
            "Epoch #3. Batch Id 40/278  is having validation accuracy of 63.109756097560975\n",
            "Epoch #3. Batch Id 41/278  is having validation loss of 1.4135159254074097\n",
            "1.539119839668274\n",
            "Epoch #3. Batch Id 41/278  is having validation accuracy of 63.24404761904762\n",
            "Epoch #3. Batch Id 42/278  is having validation loss of 1.4036961793899536\n",
            "0.9912672638893127\n",
            "Epoch #3. Batch Id 42/278  is having validation accuracy of 63.59011627906977\n",
            "Epoch #3. Batch Id 43/278  is having validation loss of 1.4011486768722534\n",
            "1.2916069030761719\n",
            "Epoch #3. Batch Id 43/278  is having validation accuracy of 63.56534090909091\n",
            "Epoch #3. Batch Id 44/278  is having validation loss of 1.3977817296981812\n",
            "1.249634027481079\n",
            "Epoch #3. Batch Id 44/278  is having validation accuracy of 63.47222222222222\n",
            "Epoch #3. Batch Id 45/278  is having validation loss of 1.3982905149459839\n",
            "1.4211865663528442\n",
            "Epoch #3. Batch Id 45/278  is having validation accuracy of 63.31521739130435\n",
            "Epoch #3. Batch Id 46/278  is having validation loss of 1.3900225162506104\n",
            "1.0096960067749023\n",
            "Epoch #3. Batch Id 46/278  is having validation accuracy of 63.56382978723404\n",
            "Epoch #3. Batch Id 47/278  is having validation loss of 1.3855772018432617\n",
            "1.1766462326049805\n",
            "Epoch #3. Batch Id 47/278  is having validation accuracy of 63.802083333333336\n",
            "Epoch #3. Batch Id 48/278  is having validation loss of 1.3813421726226807\n",
            "1.1780589818954468\n",
            "Epoch #3. Batch Id 48/278  is having validation accuracy of 63.9030612244898\n",
            "Epoch #3. Batch Id 49/278  is having validation loss of 1.3846102952957153\n",
            "1.5447511672973633\n",
            "Epoch #3. Batch Id 49/278  is having validation accuracy of 63.9375\n",
            "Epoch #3. Batch Id 50/278  is having validation loss of 1.3789349794387817\n",
            "1.0951684713363647\n",
            "Epoch #3. Batch Id 50/278  is having validation accuracy of 63.84803921568628\n",
            "Epoch #3. Batch Id 51/278  is having validation loss of 1.3755130767822266\n",
            "1.2009947299957275\n",
            "Epoch #3. Batch Id 51/278  is having validation accuracy of 63.76201923076923\n",
            "Epoch #3. Batch Id 52/278  is having validation loss of 1.376524567604065\n",
            "1.429122805595398\n",
            "Epoch #3. Batch Id 52/278  is having validation accuracy of 63.679245283018865\n",
            "Epoch #3. Batch Id 53/278  is having validation loss of 1.3769009113311768\n",
            "1.3968470096588135\n",
            "Epoch #3. Batch Id 53/278  is having validation accuracy of 63.71527777777778\n",
            "Epoch #3. Batch Id 54/278  is having validation loss of 1.3757158517837524\n",
            "1.3117245435714722\n",
            "Epoch #3. Batch Id 54/278  is having validation accuracy of 63.86363636363637\n",
            "Epoch #3. Batch Id 55/278  is having validation loss of 1.3756070137023926\n",
            "1.369620442390442\n",
            "Epoch #3. Batch Id 55/278  is having validation accuracy of 63.895089285714285\n",
            "Epoch #3. Batch Id 56/278  is having validation loss of 1.3781888484954834\n",
            "1.5227711200714111\n",
            "Epoch #3. Batch Id 56/278  is having validation accuracy of 63.98026315789474\n",
            "Epoch #3. Batch Id 57/278  is having validation loss of 1.3756555318832397\n",
            "1.2312595844268799\n",
            "Epoch #3. Batch Id 57/278  is having validation accuracy of 64.0625\n",
            "Epoch #3. Batch Id 58/278  is having validation loss of 1.379516363143921\n",
            "1.6034419536590576\n",
            "Epoch #3. Batch Id 58/278  is having validation accuracy of 63.93008474576271\n",
            "Epoch #3. Batch Id 59/278  is having validation loss of 1.3770655393600464\n",
            "1.2324663400650024\n",
            "Epoch #3. Batch Id 59/278  is having validation accuracy of 64.11458333333333\n",
            "Epoch #3. Batch Id 60/278  is having validation loss of 1.3749691247940063\n",
            "1.2491810321807861\n",
            "Epoch #3. Batch Id 60/278  is having validation accuracy of 64.24180327868852\n",
            "Epoch #3. Batch Id 61/278  is having validation loss of 1.3760560750961304\n",
            "1.442360520362854\n",
            "Epoch #3. Batch Id 61/278  is having validation accuracy of 64.31451612903226\n",
            "Epoch #3. Batch Id 62/278  is having validation loss of 1.367737054824829\n",
            "0.8519589304924011\n",
            "Epoch #3. Batch Id 62/278  is having validation accuracy of 64.58333333333333\n",
            "Epoch #3. Batch Id 63/278  is having validation loss of 1.37320876121521\n",
            "1.7179278135299683\n",
            "Epoch #3. Batch Id 63/278  is having validation accuracy of 64.55078125\n",
            "Epoch #3. Batch Id 64/278  is having validation loss of 1.379818320274353\n",
            "1.8028312921524048\n",
            "Epoch #3. Batch Id 64/278  is having validation accuracy of 64.47115384615384\n",
            "Epoch #3. Batch Id 65/278  is having validation loss of 1.3766872882843018\n",
            "1.1731741428375244\n",
            "Epoch #3. Batch Id 65/278  is having validation accuracy of 64.53598484848484\n",
            "Epoch #3. Batch Id 66/278  is having validation loss of 1.3772082328796387\n",
            "1.411594271659851\n",
            "Epoch #3. Batch Id 66/278  is having validation accuracy of 64.4589552238806\n",
            "Epoch #3. Batch Id 67/278  is having validation loss of 1.3794159889221191\n",
            "1.5273393392562866\n",
            "Epoch #3. Batch Id 67/278  is having validation accuracy of 64.47610294117646\n",
            "Epoch #3. Batch Id 68/278  is having validation loss of 1.3732866048812866\n",
            "0.9564876556396484\n",
            "Epoch #3. Batch Id 68/278  is having validation accuracy of 64.71920289855072\n",
            "Epoch #3. Batch Id 69/278  is having validation loss of 1.3704943656921387\n",
            "1.1778275966644287\n",
            "Epoch #3. Batch Id 69/278  is having validation accuracy of 64.91071428571429\n",
            "Epoch #3. Batch Id 70/278  is having validation loss of 1.3734346628189087\n",
            "1.5792570114135742\n",
            "Epoch #3. Batch Id 70/278  is having validation accuracy of 64.70070422535211\n",
            "Epoch #3. Batch Id 71/278  is having validation loss of 1.3666902780532837\n",
            "0.8878402709960938\n",
            "Epoch #3. Batch Id 71/278  is having validation accuracy of 64.80034722222223\n",
            "Epoch #3. Batch Id 72/278  is having validation loss of 1.3705023527145386\n",
            "1.6449694633483887\n",
            "Epoch #3. Batch Id 72/278  is having validation accuracy of 64.55479452054794\n",
            "Epoch #3. Batch Id 73/278  is having validation loss of 1.3716495037078857\n",
            "1.45539128780365\n",
            "Epoch #3. Batch Id 73/278  is having validation accuracy of 64.56925675675676\n",
            "Epoch #3. Batch Id 74/278  is having validation loss of 1.3756107091903687\n",
            "1.6687431335449219\n",
            "Epoch #3. Batch Id 74/278  is having validation accuracy of 64.41666666666667\n",
            "Epoch #3. Batch Id 75/278  is having validation loss of 1.3758370876312256\n",
            "1.3928159475326538\n",
            "Epoch #3. Batch Id 75/278  is having validation accuracy of 64.51480263157895\n",
            "Epoch #3. Batch Id 76/278  is having validation loss of 1.3772929906845093\n",
            "1.4879436492919922\n",
            "Epoch #3. Batch Id 76/278  is having validation accuracy of 64.40746753246754\n",
            "Epoch #3. Batch Id 77/278  is having validation loss of 1.374085545539856\n",
            "1.1271147727966309\n",
            "Epoch #3. Batch Id 77/278  is having validation accuracy of 64.46314102564102\n",
            "Epoch #3. Batch Id 78/278  is having validation loss of 1.3705793619155884\n",
            "1.0970929861068726\n",
            "Epoch #3. Batch Id 78/278  is having validation accuracy of 64.55696202531645\n",
            "Epoch #3. Batch Id 79/278  is having validation loss of 1.3688371181488037\n",
            "1.2311981916427612\n",
            "Epoch #3. Batch Id 79/278  is having validation accuracy of 64.53125\n",
            "Epoch #3. Batch Id 80/278  is having validation loss of 1.3759629726409912\n",
            "1.9460326433181763\n",
            "Epoch #3. Batch Id 80/278  is having validation accuracy of 64.42901234567901\n",
            "Epoch #3. Batch Id 81/278  is having validation loss of 1.3785866498947144\n",
            "1.59110426902771\n",
            "Epoch #3. Batch Id 81/278  is having validation accuracy of 64.32926829268293\n",
            "Epoch #3. Batch Id 82/278  is having validation loss of 1.3823416233062744\n",
            "1.6902474164962769\n",
            "Epoch #3. Batch Id 82/278  is having validation accuracy of 64.34487951807229\n",
            "Epoch #3. Batch Id 83/278  is having validation loss of 1.3808186054229736\n",
            "1.2544130086898804\n",
            "Epoch #3. Batch Id 83/278  is having validation accuracy of 64.39732142857143\n",
            "Epoch #3. Batch Id 84/278  is having validation loss of 1.3783440589904785\n",
            "1.1704825162887573\n",
            "Epoch #3. Batch Id 84/278  is having validation accuracy of 64.48529411764706\n",
            "Epoch #3. Batch Id 85/278  is having validation loss of 1.3769692182540894\n",
            "1.2601091861724854\n",
            "Epoch #3. Batch Id 85/278  is having validation accuracy of 64.57122093023256\n",
            "Epoch #3. Batch Id 86/278  is having validation loss of 1.3790932893753052\n",
            "1.5617681741714478\n",
            "Epoch #3. Batch Id 86/278  is having validation accuracy of 64.4396551724138\n",
            "Epoch #3. Batch Id 87/278  is having validation loss of 1.3749803304672241\n",
            "1.0171513557434082\n",
            "Epoch #3. Batch Id 87/278  is having validation accuracy of 64.5596590909091\n",
            "Epoch #3. Batch Id 88/278  is having validation loss of 1.3785511255264282\n",
            "1.6927827596664429\n",
            "Epoch #3. Batch Id 88/278  is having validation accuracy of 64.4311797752809\n",
            "Epoch #3. Batch Id 89/278  is having validation loss of 1.3768365383148193\n",
            "1.2242369651794434\n",
            "Epoch #3. Batch Id 89/278  is having validation accuracy of 64.47916666666667\n",
            "Epoch #3. Batch Id 90/278  is having validation loss of 1.371057391166687\n",
            "0.8509381413459778\n",
            "Epoch #3. Batch Id 90/278  is having validation accuracy of 64.59478021978022\n",
            "Epoch #3. Batch Id 91/278  is having validation loss of 1.371381402015686\n",
            "1.4008634090423584\n",
            "Epoch #3. Batch Id 91/278  is having validation accuracy of 64.70788043478261\n",
            "Epoch #3. Batch Id 92/278  is having validation loss of 1.3722821474075317\n",
            "1.4551469087600708\n",
            "Epoch #3. Batch Id 92/278  is having validation accuracy of 64.61693548387096\n",
            "Epoch #3. Batch Id 93/278  is having validation loss of 1.3705427646636963\n",
            "1.2087761163711548\n",
            "Epoch #3. Batch Id 93/278  is having validation accuracy of 64.66090425531915\n",
            "Epoch #3. Batch Id 94/278  is having validation loss of 1.3671109676361084\n",
            "1.0445213317871094\n",
            "Epoch #3. Batch Id 94/278  is having validation accuracy of 64.70394736842105\n",
            "Epoch #3. Batch Id 95/278  is having validation loss of 1.365984320640564\n",
            "1.258954644203186\n",
            "Epoch #3. Batch Id 95/278  is having validation accuracy of 64.77864583333333\n",
            "Epoch #3. Batch Id 96/278  is having validation loss of 1.3692021369934082\n",
            "1.6781142950057983\n",
            "Epoch #3. Batch Id 96/278  is having validation accuracy of 64.65850515463917\n",
            "Epoch #3. Batch Id 97/278  is having validation loss of 1.368784785270691\n",
            "1.3282984495162964\n",
            "Epoch #3. Batch Id 97/278  is having validation accuracy of 64.63647959183673\n",
            "Epoch #3. Batch Id 98/278  is having validation loss of 1.3693040609359741\n",
            "1.4201983213424683\n",
            "Epoch #3. Batch Id 98/278  is having validation accuracy of 64.58333333333333\n",
            "Epoch #3. Batch Id 99/278  is having validation loss of 1.366884708404541\n",
            "1.1273661851882935\n",
            "Epoch #3. Batch Id 99/278  is having validation accuracy of 64.71875\n",
            "Epoch #3. Batch Id 100/278  is having validation loss of 1.3681100606918335\n",
            "1.4906446933746338\n",
            "Epoch #3. Batch Id 100/278  is having validation accuracy of 64.60396039603961\n",
            "Epoch #3. Batch Id 101/278  is having validation loss of 1.3673348426818848\n",
            "1.2890360355377197\n",
            "Epoch #3. Batch Id 101/278  is having validation accuracy of 64.58333333333333\n",
            "Epoch #3. Batch Id 102/278  is having validation loss of 1.3636301755905151\n",
            "0.9857504367828369\n",
            "Epoch #3. Batch Id 102/278  is having validation accuracy of 64.74514563106796\n",
            "Epoch #3. Batch Id 103/278  is having validation loss of 1.3673650026321411\n",
            "1.75205659866333\n",
            "Epoch #3. Batch Id 103/278  is having validation accuracy of 64.7235576923077\n",
            "Epoch #3. Batch Id 104/278  is having validation loss of 1.3651570081710815\n",
            "1.1355223655700684\n",
            "Epoch #3. Batch Id 104/278  is having validation accuracy of 64.73214285714286\n",
            "Epoch #3. Batch Id 105/278  is having validation loss of 1.3624595403671265\n",
            "1.0792286396026611\n",
            "Epoch #3. Batch Id 105/278  is having validation accuracy of 64.7995283018868\n",
            "Epoch #3. Batch Id 106/278  is having validation loss of 1.3605881929397583\n",
            "1.1622307300567627\n",
            "Epoch #3. Batch Id 106/278  is having validation accuracy of 64.83644859813084\n",
            "Epoch #3. Batch Id 107/278  is having validation loss of 1.3573269844055176\n",
            "1.0083822011947632\n",
            "Epoch #3. Batch Id 107/278  is having validation accuracy of 64.90162037037037\n",
            "Epoch #3. Batch Id 108/278  is having validation loss of 1.3591506481170654\n",
            "1.5561002492904663\n",
            "Epoch #3. Batch Id 108/278  is having validation accuracy of 64.79357798165138\n",
            "Epoch #3. Batch Id 109/278  is having validation loss of 1.3585011959075928\n",
            "1.2877050638198853\n",
            "Epoch #3. Batch Id 109/278  is having validation accuracy of 64.77272727272727\n",
            "Epoch #3. Batch Id 110/278  is having validation loss of 1.3533321619033813\n",
            "0.7847405672073364\n",
            "Epoch #3. Batch Id 110/278  is having validation accuracy of 64.92117117117117\n",
            "Epoch #3. Batch Id 111/278  is having validation loss of 1.3491125106811523\n",
            "0.8807322978973389\n",
            "Epoch #3. Batch Id 111/278  is having validation accuracy of 65.06696428571429\n",
            "Epoch #3. Batch Id 112/278  is having validation loss of 1.349619746208191\n",
            "1.406436800956726\n",
            "Epoch #3. Batch Id 112/278  is having validation accuracy of 64.98893805309734\n",
            "Epoch #3. Batch Id 113/278  is having validation loss of 1.3490631580352783\n",
            "1.2861651182174683\n",
            "Epoch #3. Batch Id 113/278  is having validation accuracy of 64.99451754385964\n",
            "Epoch #3. Batch Id 114/278  is having validation loss of 1.3541147708892822\n",
            "1.9300020933151245\n",
            "Epoch #3. Batch Id 114/278  is having validation accuracy of 64.80978260869566\n",
            "Epoch #3. Batch Id 115/278  is having validation loss of 1.3572993278503418\n",
            "1.7235208749771118\n",
            "Epoch #3. Batch Id 115/278  is having validation accuracy of 64.73599137931035\n",
            "Epoch #3. Batch Id 116/278  is having validation loss of 1.3628123998641968\n",
            "2.0023350715637207\n",
            "Epoch #3. Batch Id 116/278  is having validation accuracy of 64.63675213675214\n",
            "Epoch #3. Batch Id 117/278  is having validation loss of 1.3649507761001587\n",
            "1.6151463985443115\n",
            "Epoch #3. Batch Id 117/278  is having validation accuracy of 64.64512711864407\n",
            "Epoch #3. Batch Id 118/278  is having validation loss of 1.3646728992462158\n",
            "1.33187735080719\n",
            "Epoch #3. Batch Id 118/278  is having validation accuracy of 64.65336134453781\n",
            "Epoch #3. Batch Id 119/278  is having validation loss of 1.3650027513504028\n",
            "1.4042555093765259\n",
            "Epoch #3. Batch Id 119/278  is having validation accuracy of 64.66145833333333\n",
            "Epoch #3. Batch Id 120/278  is having validation loss of 1.3646466732025146\n",
            "1.3219202756881714\n",
            "Epoch #3. Batch Id 120/278  is having validation accuracy of 64.61776859504133\n",
            "Epoch #3. Batch Id 121/278  is having validation loss of 1.3656795024871826\n",
            "1.4906562566757202\n",
            "Epoch #3. Batch Id 121/278  is having validation accuracy of 64.54918032786885\n",
            "Epoch #3. Batch Id 122/278  is having validation loss of 1.3693928718566895\n",
            "1.8224259614944458\n",
            "Epoch #3. Batch Id 122/278  is having validation accuracy of 64.4308943089431\n",
            "Epoch #3. Batch Id 123/278  is having validation loss of 1.3741979598999023\n",
            "1.965229868888855\n",
            "Epoch #3. Batch Id 123/278  is having validation accuracy of 64.28931451612904\n",
            "Epoch #3. Batch Id 124/278  is having validation loss of 1.3731353282928467\n",
            "1.2413644790649414\n",
            "Epoch #3. Batch Id 124/278  is having validation accuracy of 64.3\n",
            "Epoch #3. Batch Id 125/278  is having validation loss of 1.3718794584274292\n",
            "1.214896559715271\n",
            "Epoch #3. Batch Id 125/278  is having validation accuracy of 64.40972222222223\n",
            "Epoch #3. Batch Id 126/278  is having validation loss of 1.3693418502807617\n",
            "1.0495984554290771\n",
            "Epoch #3. Batch Id 126/278  is having validation accuracy of 64.41929133858268\n",
            "Epoch #3. Batch Id 127/278  is having validation loss of 1.3693665266036987\n",
            "1.3725051879882812\n",
            "Epoch #3. Batch Id 127/278  is having validation accuracy of 64.404296875\n",
            "Epoch #3. Batch Id 128/278  is having validation loss of 1.366804599761963\n",
            "1.038872480392456\n",
            "Epoch #3. Batch Id 128/278  is having validation accuracy of 64.48643410852713\n",
            "Epoch #3. Batch Id 129/278  is having validation loss of 1.3662980794906616\n",
            "1.3009570837020874\n",
            "Epoch #3. Batch Id 129/278  is having validation accuracy of 64.4951923076923\n",
            "Epoch #3. Batch Id 130/278  is having validation loss of 1.3611571788787842\n",
            "0.6928449273109436\n",
            "Epoch #3. Batch Id 130/278  is having validation accuracy of 64.67080152671755\n",
            "Epoch #3. Batch Id 131/278  is having validation loss of 1.361983299255371\n",
            "1.4702023267745972\n",
            "Epoch #3. Batch Id 131/278  is having validation accuracy of 64.65435606060606\n",
            "Epoch #3. Batch Id 132/278  is having validation loss of 1.3618748188018799\n",
            "1.3475571870803833\n",
            "Epoch #3. Batch Id 132/278  is having validation accuracy of 64.61466165413533\n",
            "Epoch #3. Batch Id 133/278  is having validation loss of 1.364012360572815\n",
            "1.6483017206192017\n",
            "Epoch #3. Batch Id 133/278  is having validation accuracy of 64.57555970149254\n",
            "Epoch #3. Batch Id 134/278  is having validation loss of 1.368303656578064\n",
            "1.9433420896530151\n",
            "Epoch #3. Batch Id 134/278  is having validation accuracy of 64.42129629629629\n",
            "Epoch #3. Batch Id 135/278  is having validation loss of 1.3707340955734253\n",
            "1.698845624923706\n",
            "Epoch #3. Batch Id 135/278  is having validation accuracy of 64.36121323529412\n",
            "Epoch #3. Batch Id 136/278  is having validation loss of 1.3700976371765137\n",
            "1.2835333347320557\n",
            "Epoch #3. Batch Id 136/278  is having validation accuracy of 64.37043795620438\n",
            "Epoch #3. Batch Id 137/278  is having validation loss of 1.3705904483795166\n",
            "1.4381134510040283\n",
            "Epoch #3. Batch Id 137/278  is having validation accuracy of 64.31159420289855\n",
            "Epoch #3. Batch Id 138/278  is having validation loss of 1.366692304611206\n",
            "0.8287521600723267\n",
            "Epoch #3. Batch Id 138/278  is having validation accuracy of 64.47841726618705\n",
            "Epoch #3. Batch Id 139/278  is having validation loss of 1.3662211894989014\n",
            "1.300742745399475\n",
            "Epoch #3. Batch Id 139/278  is having validation accuracy of 64.48660714285714\n",
            "Epoch #3. Batch Id 140/278  is having validation loss of 1.3666547536849976\n",
            "1.4273537397384644\n",
            "Epoch #3. Batch Id 140/278  is having validation accuracy of 64.49468085106383\n",
            "Epoch #3. Batch Id 141/278  is having validation loss of 1.3652145862579346\n",
            "1.1621588468551636\n",
            "Epoch #3. Batch Id 141/278  is having validation accuracy of 64.4806338028169\n",
            "Epoch #3. Batch Id 142/278  is having validation loss of 1.362889051437378\n",
            "1.0326669216156006\n",
            "Epoch #3. Batch Id 142/278  is having validation accuracy of 64.5104895104895\n",
            "Epoch #3. Batch Id 143/278  is having validation loss of 1.3639473915100098\n",
            "1.5152976512908936\n",
            "Epoch #3. Batch Id 143/278  is having validation accuracy of 64.49652777777777\n",
            "Epoch #3. Batch Id 144/278  is having validation loss of 1.3665157556533813\n",
            "1.7363557815551758\n",
            "Epoch #3. Batch Id 144/278  is having validation accuracy of 64.41810344827586\n",
            "Epoch #3. Batch Id 145/278  is having validation loss of 1.3687965869903564\n",
            "1.6995235681533813\n",
            "Epoch #3. Batch Id 145/278  is having validation accuracy of 64.34075342465754\n",
            "Epoch #3. Batch Id 146/278  is having validation loss of 1.3669525384902954\n",
            "1.0977293252944946\n",
            "Epoch #3. Batch Id 146/278  is having validation accuracy of 64.34948979591837\n",
            "Epoch #3. Batch Id 147/278  is having validation loss of 1.367106556892395\n",
            "1.3897509574890137\n",
            "Epoch #3. Batch Id 147/278  is having validation accuracy of 64.37922297297297\n",
            "Epoch #3. Batch Id 148/278  is having validation loss of 1.3699951171875\n",
            "1.7974963188171387\n",
            "Epoch #3. Batch Id 148/278  is having validation accuracy of 64.26174496644295\n",
            "Epoch #3. Batch Id 149/278  is having validation loss of 1.3713502883911133\n",
            "1.5732638835906982\n",
            "Epoch #3. Batch Id 149/278  is having validation accuracy of 64.22916666666667\n",
            "Epoch #3. Batch Id 150/278  is having validation loss of 1.3713325262069702\n",
            "1.3686636686325073\n",
            "Epoch #3. Batch Id 150/278  is having validation accuracy of 64.23841059602648\n",
            "Epoch #3. Batch Id 151/278  is having validation loss of 1.3725274801254272\n",
            "1.5529592037200928\n",
            "Epoch #3. Batch Id 151/278  is having validation accuracy of 64.2064144736842\n",
            "Epoch #3. Batch Id 152/278  is having validation loss of 1.3718369007110596\n",
            "1.26687753200531\n",
            "Epoch #3. Batch Id 152/278  is having validation accuracy of 64.1952614379085\n",
            "Epoch #3. Batch Id 153/278  is having validation loss of 1.3695321083068848\n",
            "1.0168994665145874\n",
            "Epoch #3. Batch Id 153/278  is having validation accuracy of 64.22483766233766\n",
            "Epoch #3. Batch Id 154/278  is having validation loss of 1.3719333410263062\n",
            "1.741716980934143\n",
            "Epoch #3. Batch Id 154/278  is having validation accuracy of 64.13306451612904\n",
            "Epoch #3. Batch Id 155/278  is having validation loss of 1.3701776266098022\n",
            "1.0980364084243774\n",
            "Epoch #3. Batch Id 155/278  is having validation accuracy of 64.22275641025641\n",
            "Epoch #3. Batch Id 156/278  is having validation loss of 1.3724249601364136\n",
            "1.7230051755905151\n",
            "Epoch #3. Batch Id 156/278  is having validation accuracy of 64.15207006369427\n",
            "Epoch #3. Batch Id 157/278  is having validation loss of 1.3723384141921997\n",
            "1.3587576150894165\n",
            "Epoch #3. Batch Id 157/278  is having validation accuracy of 64.12183544303798\n",
            "Epoch #3. Batch Id 158/278  is having validation loss of 1.3738211393356323\n",
            "1.6080842018127441\n",
            "Epoch #3. Batch Id 158/278  is having validation accuracy of 64.15094339622641\n",
            "Epoch #3. Batch Id 159/278  is having validation loss of 1.3741458654403687\n",
            "1.4257813692092896\n",
            "Epoch #3. Batch Id 159/278  is having validation accuracy of 64.1796875\n",
            "Epoch #3. Batch Id 160/278  is having validation loss of 1.3761382102966309\n",
            "1.6949143409729004\n",
            "Epoch #3. Batch Id 160/278  is having validation accuracy of 64.1498447204969\n",
            "Epoch #3. Batch Id 161/278  is having validation loss of 1.3780022859573364\n",
            "1.67811918258667\n",
            "Epoch #3. Batch Id 161/278  is having validation accuracy of 64.08179012345678\n",
            "Epoch #3. Batch Id 162/278  is having validation loss of 1.3761558532714844\n",
            "1.0770342350006104\n",
            "Epoch #3. Batch Id 162/278  is having validation accuracy of 64.12960122699387\n",
            "Epoch #3. Batch Id 163/278  is having validation loss of 1.3747940063476562\n",
            "1.15281343460083\n",
            "Epoch #3. Batch Id 163/278  is having validation accuracy of 64.19588414634147\n",
            "Epoch #3. Batch Id 164/278  is having validation loss of 1.377851128578186\n",
            "1.8792115449905396\n",
            "Epoch #3. Batch Id 164/278  is having validation accuracy of 64.0909090909091\n",
            "Epoch #3. Batch Id 165/278  is having validation loss of 1.3766311407089233\n",
            "1.175325632095337\n",
            "Epoch #3. Batch Id 165/278  is having validation accuracy of 64.11897590361446\n",
            "Epoch #3. Batch Id 166/278  is having validation loss of 1.3744679689407349\n",
            "1.0153796672821045\n",
            "Epoch #3. Batch Id 166/278  is having validation accuracy of 64.20284431137725\n",
            "Epoch #3. Batch Id 167/278  is having validation loss of 1.3738552331924438\n",
            "1.27153742313385\n",
            "Epoch #3. Batch Id 167/278  is having validation accuracy of 64.19270833333333\n",
            "Epoch #3. Batch Id 168/278  is having validation loss of 1.3709830045700073\n",
            "0.8884451985359192\n",
            "Epoch #3. Batch Id 168/278  is having validation accuracy of 64.23816568047337\n",
            "Epoch #3. Batch Id 169/278  is having validation loss of 1.3697799444198608\n",
            "1.166462779045105\n",
            "Epoch #3. Batch Id 169/278  is having validation accuracy of 64.30147058823529\n",
            "Epoch #3. Batch Id 170/278  is having validation loss of 1.372174620628357\n",
            "1.7792677879333496\n",
            "Epoch #3. Batch Id 170/278  is having validation accuracy of 64.3092105263158\n",
            "Epoch #3. Batch Id 171/278  is having validation loss of 1.373289942741394\n",
            "1.5640110969543457\n",
            "Epoch #3. Batch Id 171/278  is having validation accuracy of 64.29869186046511\n",
            "Epoch #3. Batch Id 172/278  is having validation loss of 1.3702279329299927\n",
            "0.8435619473457336\n",
            "Epoch #3. Batch Id 172/278  is having validation accuracy of 64.41473988439306\n",
            "Epoch #3. Batch Id 173/278  is having validation loss of 1.3689472675323486\n",
            "1.1473991870880127\n",
            "Epoch #3. Batch Id 173/278  is having validation accuracy of 64.45761494252874\n",
            "Epoch #3. Batch Id 174/278  is having validation loss of 1.370462417602539\n",
            "1.6340926885604858\n",
            "Epoch #3. Batch Id 174/278  is having validation accuracy of 64.42857142857143\n",
            "Epoch #3. Batch Id 175/278  is having validation loss of 1.3705321550369263\n",
            "1.3827259540557861\n",
            "Epoch #3. Batch Id 175/278  is having validation accuracy of 64.38210227272727\n",
            "Epoch #3. Batch Id 176/278  is having validation loss of 1.369634747505188\n",
            "1.2116978168487549\n",
            "Epoch #3. Batch Id 176/278  is having validation accuracy of 64.40677966101696\n",
            "Epoch #3. Batch Id 177/278  is having validation loss of 1.3709375858306885\n",
            "1.6015350818634033\n",
            "Epoch #3. Batch Id 177/278  is having validation accuracy of 64.36095505617978\n",
            "Epoch #3. Batch Id 178/278  is having validation loss of 1.3744534254074097\n",
            "2.000277280807495\n",
            "Epoch #3. Batch Id 178/278  is having validation accuracy of 64.2108938547486\n",
            "Epoch #3. Batch Id 179/278  is having validation loss of 1.3772454261779785\n",
            "1.877018928527832\n",
            "Epoch #3. Batch Id 179/278  is having validation accuracy of 64.13194444444444\n",
            "Epoch #3. Batch Id 180/278  is having validation loss of 1.3783609867095947\n",
            "1.57915461063385\n",
            "Epoch #3. Batch Id 180/278  is having validation accuracy of 64.05386740331491\n",
            "Epoch #3. Batch Id 181/278  is having validation loss of 1.3777329921722412\n",
            "1.264064073562622\n",
            "Epoch #3. Batch Id 181/278  is having validation accuracy of 64.07967032967034\n",
            "Epoch #3. Batch Id 182/278  is having validation loss of 1.378403663635254\n",
            "1.5004634857177734\n",
            "Epoch #3. Batch Id 182/278  is having validation accuracy of 64.03688524590164\n",
            "Epoch #3. Batch Id 183/278  is having validation loss of 1.3805557489395142\n",
            "1.7743933200836182\n",
            "Epoch #3. Batch Id 183/278  is having validation accuracy of 64.02853260869566\n",
            "Epoch #3. Batch Id 184/278  is having validation loss of 1.379886269569397\n",
            "1.2566933631896973\n",
            "Epoch #3. Batch Id 184/278  is having validation accuracy of 64.03716216216216\n",
            "Epoch #3. Batch Id 185/278  is having validation loss of 1.3779897689819336\n",
            "1.0271309614181519\n",
            "Epoch #3. Batch Id 185/278  is having validation accuracy of 64.07930107526882\n",
            "Epoch #3. Batch Id 186/278  is having validation loss of 1.3771286010742188\n",
            "1.216944932937622\n",
            "Epoch #3. Batch Id 186/278  is having validation accuracy of 64.07085561497327\n",
            "Epoch #3. Batch Id 187/278  is having validation loss of 1.3755886554718018\n",
            "1.087611436843872\n",
            "Epoch #3. Batch Id 187/278  is having validation accuracy of 64.12898936170212\n",
            "Epoch #3. Batch Id 188/278  is having validation loss of 1.3780250549316406\n",
            "1.8360671997070312\n",
            "Epoch #3. Batch Id 188/278  is having validation accuracy of 64.15343915343915\n",
            "Epoch #3. Batch Id 189/278  is having validation loss of 1.3759548664093018\n",
            "0.984696626663208\n",
            "Epoch #3. Batch Id 189/278  is having validation accuracy of 64.21052631578948\n",
            "Epoch #3. Batch Id 190/278  is having validation loss of 1.374805212020874\n",
            "1.156373143196106\n",
            "Epoch #3. Batch Id 190/278  is having validation accuracy of 64.20157068062828\n",
            "Epoch #3. Batch Id 191/278  is having validation loss of 1.376317024230957\n",
            "1.6650785207748413\n",
            "Epoch #3. Batch Id 191/278  is having validation accuracy of 64.17643229166667\n",
            "Epoch #3. Batch Id 192/278  is having validation loss of 1.37677800655365\n",
            "1.4652776718139648\n",
            "Epoch #3. Batch Id 192/278  is having validation accuracy of 64.1839378238342\n",
            "Epoch #3. Batch Id 193/278  is having validation loss of 1.3763171434402466\n",
            "1.28736412525177\n",
            "Epoch #3. Batch Id 193/278  is having validation accuracy of 64.20747422680412\n",
            "Epoch #3. Batch Id 194/278  is having validation loss of 1.3765615224838257\n",
            "1.42397940158844\n",
            "Epoch #3. Batch Id 194/278  is having validation accuracy of 64.16666666666667\n",
            "Epoch #3. Batch Id 195/278  is having validation loss of 1.376448392868042\n",
            "1.3543874025344849\n",
            "Epoch #3. Batch Id 195/278  is having validation accuracy of 64.11033163265306\n",
            "Epoch #3. Batch Id 196/278  is having validation loss of 1.3754866123199463\n",
            "1.1869869232177734\n",
            "Epoch #3. Batch Id 196/278  is having validation accuracy of 64.11802030456853\n",
            "Epoch #3. Batch Id 197/278  is having validation loss of 1.375166893005371\n",
            "1.312172532081604\n",
            "Epoch #3. Batch Id 197/278  is having validation accuracy of 64.07828282828282\n",
            "Epoch #3. Batch Id 198/278  is having validation loss of 1.3760665655136108\n",
            "1.5542056560516357\n",
            "Epoch #3. Batch Id 198/278  is having validation accuracy of 64.05464824120602\n",
            "Epoch #3. Batch Id 199/278  is having validation loss of 1.3742892742156982\n",
            "1.020603895187378\n",
            "Epoch #3. Batch Id 199/278  is having validation accuracy of 64.15625\n",
            "Epoch #3. Batch Id 200/278  is having validation loss of 1.3763195276260376\n",
            "1.7823795080184937\n",
            "Epoch #3. Batch Id 200/278  is having validation accuracy of 64.07027363184079\n",
            "Epoch #3. Batch Id 201/278  is having validation loss of 1.3761142492294312\n",
            "1.3348480463027954\n",
            "Epoch #3. Batch Id 201/278  is having validation accuracy of 64.07797029702971\n",
            "Epoch #3. Batch Id 202/278  is having validation loss of 1.373073935508728\n",
            "0.7589419484138489\n",
            "Epoch #3. Batch Id 202/278  is having validation accuracy of 64.13177339901478\n",
            "Epoch #3. Batch Id 203/278  is having validation loss of 1.3733587265014648\n",
            "1.4311625957489014\n",
            "Epoch #3. Batch Id 203/278  is having validation accuracy of 64.09313725490196\n",
            "Epoch #3. Batch Id 204/278  is having validation loss of 1.374835729598999\n",
            "1.676148772239685\n",
            "Epoch #3. Batch Id 204/278  is having validation accuracy of 64.0548780487805\n",
            "Epoch #3. Batch Id 205/278  is having validation loss of 1.37485933303833\n",
            "1.3797093629837036\n",
            "Epoch #3. Batch Id 205/278  is having validation accuracy of 64.04733009708738\n",
            "Epoch #3. Batch Id 206/278  is having validation loss of 1.3747460842132568\n",
            "1.351415753364563\n",
            "Epoch #3. Batch Id 206/278  is having validation accuracy of 63.994565217391305\n",
            "Epoch #3. Batch Id 207/278  is having validation loss of 1.3751412630081177\n",
            "1.4569480419158936\n",
            "Epoch #3. Batch Id 207/278  is having validation accuracy of 63.98737980769231\n",
            "Epoch #3. Batch Id 208/278  is having validation loss of 1.3754256963729858\n",
            "1.4345989227294922\n",
            "Epoch #3. Batch Id 208/278  is having validation accuracy of 63.995215311004785\n",
            "Epoch #3. Batch Id 209/278  is having validation loss of 1.3749728202819824\n",
            "1.2803205251693726\n",
            "Epoch #3. Batch Id 209/278  is having validation accuracy of 63.973214285714285\n",
            "Epoch #3. Batch Id 210/278  is having validation loss of 1.3749299049377441\n",
            "1.3659127950668335\n",
            "Epoch #3. Batch Id 210/278  is having validation accuracy of 63.96623222748815\n",
            "Epoch #3. Batch Id 211/278  is having validation loss of 1.3743269443511963\n",
            "1.247099757194519\n",
            "Epoch #3. Batch Id 211/278  is having validation accuracy of 63.944575471698116\n",
            "Epoch #3. Batch Id 212/278  is having validation loss of 1.3748178482055664\n",
            "1.478898286819458\n",
            "Epoch #3. Batch Id 212/278  is having validation accuracy of 63.923122065727696\n",
            "Epoch #3. Batch Id 213/278  is having validation loss of 1.3752304315567017\n",
            "1.4631173610687256\n",
            "Epoch #3. Batch Id 213/278  is having validation accuracy of 63.87266355140187\n",
            "Epoch #3. Batch Id 214/278  is having validation loss of 1.374930739402771\n",
            "1.3107894659042358\n",
            "Epoch #3. Batch Id 214/278  is having validation accuracy of 63.866279069767444\n",
            "Epoch #3. Batch Id 215/278  is having validation loss of 1.3769561052322388\n",
            "1.812401533126831\n",
            "Epoch #3. Batch Id 215/278  is having validation accuracy of 63.75868055555556\n",
            "Epoch #3. Batch Id 216/278  is having validation loss of 1.3778220415115356\n",
            "1.5648698806762695\n",
            "Epoch #3. Batch Id 216/278  is having validation accuracy of 63.73847926267281\n",
            "Epoch #3. Batch Id 217/278  is having validation loss of 1.37665855884552\n",
            "1.124191403388977\n",
            "Epoch #3. Batch Id 217/278  is having validation accuracy of 63.77580275229358\n",
            "Epoch #3. Batch Id 218/278  is having validation loss of 1.3767427206039429\n",
            "1.395086646080017\n",
            "Epoch #3. Batch Id 218/278  is having validation accuracy of 63.76997716894977\n",
            "Epoch #3. Batch Id 219/278  is having validation loss of 1.3761913776397705\n",
            "1.2554373741149902\n",
            "Epoch #3. Batch Id 219/278  is having validation accuracy of 63.79261363636363\n",
            "Epoch #3. Batch Id 220/278  is having validation loss of 1.3767694234848022\n",
            "1.5039355754852295\n",
            "Epoch #3. Batch Id 220/278  is having validation accuracy of 63.758484162895925\n",
            "Epoch #3. Batch Id 221/278  is having validation loss of 1.3770734071731567\n",
            "1.4442434310913086\n",
            "Epoch #3. Batch Id 221/278  is having validation accuracy of 63.73873873873874\n",
            "Epoch #3. Batch Id 222/278  is having validation loss of 1.3775562047958374\n",
            "1.4847346544265747\n",
            "Epoch #3. Batch Id 222/278  is having validation accuracy of 63.733183856502244\n",
            "Epoch #3. Batch Id 223/278  is having validation loss of 1.3780474662780762\n",
            "1.487597107887268\n",
            "Epoch #3. Batch Id 223/278  is having validation accuracy of 63.657924107142854\n",
            "Epoch #3. Batch Id 224/278  is having validation loss of 1.3786072731018066\n",
            "1.504015326499939\n",
            "Epoch #3. Batch Id 224/278  is having validation accuracy of 63.625\n",
            "Epoch #3. Batch Id 225/278  is having validation loss of 1.378648042678833\n",
            "1.3878202438354492\n",
            "Epoch #3. Batch Id 225/278  is having validation accuracy of 63.59236725663717\n",
            "Epoch #3. Batch Id 226/278  is having validation loss of 1.3773690462112427\n",
            "1.0883206129074097\n",
            "Epoch #3. Batch Id 226/278  is having validation accuracy of 63.64262114537445\n",
            "Epoch #3. Batch Id 227/278  is having validation loss of 1.3792191743850708\n",
            "1.7992068529129028\n",
            "Epoch #3. Batch Id 227/278  is having validation accuracy of 63.651315789473685\n",
            "Epoch #3. Batch Id 228/278  is having validation loss of 1.3823333978652954\n",
            "2.09237003326416\n",
            "Epoch #3. Batch Id 228/278  is having validation accuracy of 63.57805676855895\n",
            "Epoch #3. Batch Id 229/278  is having validation loss of 1.3818925619125366\n",
            "1.2809480428695679\n",
            "Epoch #3. Batch Id 229/278  is having validation accuracy of 63.58695652173913\n",
            "Epoch #3. Batch Id 230/278  is having validation loss of 1.3817859888076782\n",
            "1.357284665107727\n",
            "Epoch #3. Batch Id 230/278  is having validation accuracy of 63.568722943722946\n",
            "Epoch #3. Batch Id 231/278  is having validation loss of 1.3828723430633545\n",
            "1.6338329315185547\n",
            "Epoch #3. Batch Id 231/278  is having validation accuracy of 63.52370689655172\n",
            "Epoch #3. Batch Id 232/278  is having validation loss of 1.38393235206604\n",
            "1.6298539638519287\n",
            "Epoch #3. Batch Id 232/278  is having validation accuracy of 63.492489270386265\n",
            "Epoch #3. Batch Id 233/278  is having validation loss of 1.3825976848602295\n",
            "1.0716196298599243\n",
            "Epoch #3. Batch Id 233/278  is having validation accuracy of 63.51495726495727\n",
            "Epoch #3. Batch Id 234/278  is having validation loss of 1.3809783458709717\n",
            "1.0020618438720703\n",
            "Epoch #3. Batch Id 234/278  is having validation accuracy of 63.577127659574465\n",
            "Epoch #3. Batch Id 235/278  is having validation loss of 1.3822964429855347\n",
            "1.692043662071228\n",
            "Epoch #3. Batch Id 235/278  is having validation accuracy of 63.572563559322035\n",
            "Epoch #3. Batch Id 236/278  is having validation loss of 1.381340742111206\n",
            "1.1558045148849487\n",
            "Epoch #3. Batch Id 236/278  is having validation accuracy of 63.607594936708864\n",
            "Epoch #3. Batch Id 237/278  is having validation loss of 1.3813062906265259\n",
            "1.3731361627578735\n",
            "Epoch #3. Batch Id 237/278  is having validation accuracy of 63.61607142857143\n",
            "Epoch #3. Batch Id 238/278  is having validation loss of 1.3798503875732422\n",
            "1.0333455801010132\n",
            "Epoch #3. Batch Id 238/278  is having validation accuracy of 63.65062761506276\n",
            "Epoch #3. Batch Id 239/278  is having validation loss of 1.3829643726348877\n",
            "2.127206802368164\n",
            "Epoch #3. Batch Id 239/278  is having validation accuracy of 63.580729166666664\n",
            "Epoch #3. Batch Id 240/278  is having validation loss of 1.381752610206604\n",
            "1.0909429788589478\n",
            "Epoch #3. Batch Id 240/278  is having validation accuracy of 63.602178423236516\n",
            "Epoch #3. Batch Id 241/278  is having validation loss of 1.3827085494995117\n",
            "1.613075613975525\n",
            "Epoch #3. Batch Id 241/278  is having validation accuracy of 63.62345041322314\n",
            "Epoch #3. Batch Id 242/278  is having validation loss of 1.3825243711471558\n",
            "1.3379524946212769\n",
            "Epoch #3. Batch Id 242/278  is having validation accuracy of 63.63168724279836\n",
            "Epoch #3. Batch Id 243/278  is having validation loss of 1.3812540769577026\n",
            "1.0725722312927246\n",
            "Epoch #3. Batch Id 243/278  is having validation accuracy of 63.67827868852459\n",
            "Epoch #3. Batch Id 244/278  is having validation loss of 1.3821629285812378\n",
            "1.6039133071899414\n",
            "Epoch #3. Batch Id 244/278  is having validation accuracy of 63.64795918367347\n",
            "Epoch #3. Batch Id 245/278  is having validation loss of 1.3844836950302124\n",
            "1.9530812501907349\n",
            "Epoch #3. Batch Id 245/278  is having validation accuracy of 63.52896341463415\n",
            "Epoch #3. Batch Id 246/278  is having validation loss of 1.3862284421920776\n",
            "1.8154233694076538\n",
            "Epoch #3. Batch Id 246/278  is having validation accuracy of 63.512145748987855\n",
            "Epoch #3. Batch Id 247/278  is having validation loss of 1.3869394063949585\n",
            "1.5625478029251099\n",
            "Epoch #3. Batch Id 247/278  is having validation accuracy of 63.48286290322581\n",
            "Epoch #3. Batch Id 248/278  is having validation loss of 1.3873467445373535\n",
            "1.4883767366409302\n",
            "Epoch #3. Batch Id 248/278  is having validation accuracy of 63.4789156626506\n",
            "Epoch #3. Batch Id 249/278  is having validation loss of 1.3867536783218384\n",
            "1.2390741109848022\n",
            "Epoch #3. Batch Id 249/278  is having validation accuracy of 63.5125\n",
            "Epoch #3. Batch Id 250/278  is having validation loss of 1.3875113725662231\n",
            "1.5769352912902832\n",
            "Epoch #3. Batch Id 250/278  is having validation accuracy of 63.433764940239044\n",
            "Epoch #3. Batch Id 251/278  is having validation loss of 1.39009428024292\n",
            "2.0384061336517334\n",
            "Epoch #3. Batch Id 251/278  is having validation accuracy of 63.36805555555556\n",
            "Epoch #3. Batch Id 252/278  is having validation loss of 1.3897008895874023\n",
            "1.2905548810958862\n",
            "Epoch #3. Batch Id 252/278  is having validation accuracy of 63.36462450592885\n",
            "Epoch #3. Batch Id 253/278  is having validation loss of 1.3904781341552734\n",
            "1.5871161222457886\n",
            "Epoch #3. Batch Id 253/278  is having validation accuracy of 63.348917322834644\n",
            "Epoch #3. Batch Id 254/278  is having validation loss of 1.389391541481018\n",
            "1.1133896112442017\n",
            "Epoch #3. Batch Id 254/278  is having validation accuracy of 63.39460784313726\n",
            "Epoch #3. Batch Id 255/278  is having validation loss of 1.3889541625976562\n",
            "1.2774103879928589\n",
            "Epoch #3. Batch Id 255/278  is having validation accuracy of 63.41552734375\n",
            "Epoch #3. Batch Id 256/278  is having validation loss of 1.3887087106704712\n",
            "1.3258812427520752\n",
            "Epoch #3. Batch Id 256/278  is having validation accuracy of 63.39980544747082\n",
            "Epoch #3. Batch Id 257/278  is having validation loss of 1.3879538774490356\n",
            "1.1939725875854492\n",
            "Epoch #3. Batch Id 257/278  is having validation accuracy of 63.39631782945737\n",
            "Epoch #3. Batch Id 258/278  is having validation loss of 1.3888972997665405\n",
            "1.632287859916687\n",
            "Epoch #3. Batch Id 258/278  is having validation accuracy of 63.35666023166023\n",
            "Epoch #3. Batch Id 259/278  is having validation loss of 1.387861967086792\n",
            "1.119720697402954\n",
            "Epoch #3. Batch Id 259/278  is having validation accuracy of 63.35336538461539\n",
            "Epoch #3. Batch Id 260/278  is having validation loss of 1.385642170906067\n",
            "0.8084855675697327\n",
            "Epoch #3. Batch Id 260/278  is having validation accuracy of 63.39798850574713\n",
            "Epoch #3. Batch Id 261/278  is having validation loss of 1.3847721815109253\n",
            "1.1577068567276\n",
            "Epoch #3. Batch Id 261/278  is having validation accuracy of 63.41841603053435\n",
            "Epoch #3. Batch Id 262/278  is having validation loss of 1.38629150390625\n",
            "1.7843565940856934\n",
            "Epoch #3. Batch Id 262/278  is having validation accuracy of 63.36739543726236\n",
            "Epoch #3. Batch Id 263/278  is having validation loss of 1.3867746591567993\n",
            "1.5138479471206665\n",
            "Epoch #3. Batch Id 263/278  is having validation accuracy of 63.37594696969697\n",
            "Epoch #3. Batch Id 264/278  is having validation loss of 1.385605812072754\n",
            "1.0770174264907837\n",
            "Epoch #3. Batch Id 264/278  is having validation accuracy of 63.431603773584904\n",
            "Epoch #3. Batch Id 265/278  is having validation loss of 1.3858901262283325\n",
            "1.4612468481063843\n",
            "Epoch #3. Batch Id 265/278  is having validation accuracy of 63.4281015037594\n",
            "Epoch #3. Batch Id 266/278  is having validation loss of 1.3847016096115112\n",
            "1.068556547164917\n",
            "Epoch #3. Batch Id 266/278  is having validation accuracy of 63.45973782771536\n",
            "Epoch #3. Batch Id 267/278  is having validation loss of 1.383457064628601\n",
            "1.0511711835861206\n",
            "Epoch #3. Batch Id 267/278  is having validation accuracy of 63.49113805970149\n",
            "Epoch #3. Batch Id 268/278  is having validation loss of 1.3817826509475708\n",
            "0.933051347732544\n",
            "Epoch #3. Batch Id 268/278  is having validation accuracy of 63.56877323420074\n",
            "Epoch #3. Batch Id 269/278  is having validation loss of 1.3800824880599976\n",
            "0.9227425456047058\n",
            "Epoch #3. Batch Id 269/278  is having validation accuracy of 63.611111111111114\n",
            "Epoch #3. Batch Id 270/278  is having validation loss of 1.3807251453399658\n",
            "1.5542428493499756\n",
            "Epoch #3. Batch Id 270/278  is having validation accuracy of 63.6070110701107\n",
            "Epoch #3. Batch Id 271/278  is having validation loss of 1.3819172382354736\n",
            "1.7049885988235474\n",
            "Epoch #3. Batch Id 271/278  is having validation accuracy of 63.568474264705884\n",
            "Epoch #3. Batch Id 272/278  is having validation loss of 1.3831987380981445\n",
            "1.7317798137664795\n",
            "Epoch #3. Batch Id 272/278  is having validation accuracy of 63.541666666666664\n",
            "Epoch #3. Batch Id 273/278  is having validation loss of 1.3840173482894897\n",
            "1.6074955463409424\n",
            "Epoch #3. Batch Id 273/278  is having validation accuracy of 63.503649635036496\n",
            "Epoch #3. Batch Id 274/278  is having validation loss of 1.3834402561187744\n",
            "1.2253063917160034\n",
            "Epoch #3. Batch Id 274/278  is having validation accuracy of 63.53409090909091\n",
            "Epoch #3. Batch Id 275/278  is having validation loss of 1.3845775127410889\n",
            "1.6973226070404053\n",
            "Epoch #3. Batch Id 275/278  is having validation accuracy of 63.53034420289855\n",
            "Epoch #3. Batch Id 276/278  is having validation loss of 1.384107232093811\n",
            "1.2542939186096191\n",
            "Epoch #3. Batch Id 276/278  is having validation accuracy of 63.537906137184116\n",
            "Epoch #3. Batch Id 277/278  is having validation loss of 1.3793507814407349\n",
            "0.06181609630584717\n",
            "Epoch #3. Batch Id 277/278  is having validation accuracy of 63.546131288066775\n",
            "Эпоха #3 train_loss: 1.5976527720340528e-05, val_loss: 0.00015557756705675274\n",
            "Потрачено 27.0 минут на 3 эпоху\n",
            "Batch Id 0/2438 is having training loss of 1.0343743562698364\n",
            "1.0343743562698364\n",
            "Epoch #4. Accuracy on batch 0/2438  on Training is 75.0\n",
            "Epoch #4. Accuracy on batch 1/2438  on Training is 76.5625\n",
            "Epoch #4. Accuracy on batch 2/2438  on Training is 73.95833333333333\n",
            "Epoch #4. Accuracy on batch 3/2438  on Training is 71.875\n",
            "Epoch #4. Accuracy on batch 4/2438  on Training is 70.0\n",
            "Epoch #4. Accuracy on batch 5/2438  on Training is 69.27083333333333\n",
            "Epoch #4. Accuracy on batch 6/2438  on Training is 69.19642857142857\n",
            "Epoch #4. Accuracy on batch 7/2438  on Training is 69.53125\n",
            "Epoch #4. Accuracy on batch 8/2438  on Training is 69.44444444444444\n",
            "Epoch #4. Accuracy on batch 9/2438  on Training is 69.0625\n",
            "Epoch #4. Accuracy on batch 10/2438  on Training is 70.45454545454545\n",
            "Epoch #4. Accuracy on batch 11/2438  on Training is 70.05208333333333\n",
            "Epoch #4. Accuracy on batch 12/2438  on Training is 70.67307692307692\n",
            "Epoch #4. Accuracy on batch 13/2438  on Training is 69.86607142857143\n",
            "Epoch #4. Accuracy on batch 14/2438  on Training is 69.375\n",
            "Epoch #4. Accuracy on batch 15/2438  on Training is 70.1171875\n",
            "Epoch #4. Accuracy on batch 16/2438  on Training is 70.03676470588235\n",
            "Epoch #4. Accuracy on batch 17/2438  on Training is 69.61805555555556\n",
            "Epoch #4. Accuracy on batch 18/2438  on Training is 70.23026315789474\n",
            "Epoch #4. Accuracy on batch 19/2438  on Training is 69.6875\n",
            "Batch Id 20/2438 is having training loss of 1.239327073097229\n",
            "1.545949101448059\n",
            "Epoch #4. Accuracy on batch 20/2438  on Training is 68.75\n",
            "Epoch #4. Accuracy on batch 21/2438  on Training is 68.75\n",
            "Epoch #4. Accuracy on batch 22/2438  on Training is 68.07065217391305\n",
            "Epoch #4. Accuracy on batch 23/2438  on Training is 67.83854166666667\n",
            "Epoch #4. Accuracy on batch 24/2438  on Training is 68.0\n",
            "Epoch #4. Accuracy on batch 25/2438  on Training is 67.66826923076923\n",
            "Epoch #4. Accuracy on batch 26/2438  on Training is 68.51851851851852\n",
            "Epoch #4. Accuracy on batch 27/2438  on Training is 68.30357142857143\n",
            "Epoch #4. Accuracy on batch 28/2438  on Training is 67.67241379310344\n",
            "Epoch #4. Accuracy on batch 29/2438  on Training is 67.39583333333333\n",
            "Epoch #4. Accuracy on batch 30/2438  on Training is 67.84274193548387\n",
            "Epoch #4. Accuracy on batch 31/2438  on Training is 67.96875\n",
            "Epoch #4. Accuracy on batch 32/2438  on Training is 68.27651515151516\n",
            "Epoch #4. Accuracy on batch 33/2438  on Training is 68.47426470588235\n",
            "Epoch #4. Accuracy on batch 34/2438  on Training is 68.21428571428571\n",
            "Epoch #4. Accuracy on batch 35/2438  on Training is 68.14236111111111\n",
            "Epoch #4. Accuracy on batch 36/2438  on Training is 68.07432432432432\n",
            "Epoch #4. Accuracy on batch 37/2438  on Training is 68.25657894736842\n",
            "Epoch #4. Accuracy on batch 38/2438  on Training is 68.34935897435898\n",
            "Epoch #4. Accuracy on batch 39/2438  on Training is 68.28125\n",
            "Batch Id 40/2438 is having training loss of 1.203720211982727\n",
            "1.0690027475357056\n",
            "Epoch #4. Accuracy on batch 40/2438  on Training is 68.3689024390244\n",
            "Epoch #4. Accuracy on batch 41/2438  on Training is 68.75\n",
            "Epoch #4. Accuracy on batch 42/2438  on Training is 68.82267441860465\n",
            "Epoch #4. Accuracy on batch 43/2438  on Training is 69.0340909090909\n",
            "Epoch #4. Accuracy on batch 44/2438  on Training is 68.95833333333333\n",
            "Epoch #4. Accuracy on batch 45/2438  on Training is 69.02173913043478\n",
            "Epoch #4. Accuracy on batch 46/2438  on Training is 68.88297872340425\n",
            "Epoch #4. Accuracy on batch 47/2438  on Training is 68.75\n",
            "Epoch #4. Accuracy on batch 48/2438  on Training is 68.94132653061224\n",
            "Epoch #4. Accuracy on batch 49/2438  on Training is 69.0625\n",
            "Epoch #4. Accuracy on batch 50/2438  on Training is 68.99509803921569\n",
            "Epoch #4. Accuracy on batch 51/2438  on Training is 69.17067307692308\n",
            "Epoch #4. Accuracy on batch 52/2438  on Training is 68.98584905660377\n",
            "Epoch #4. Accuracy on batch 53/2438  on Training is 68.86574074074075\n",
            "Epoch #4. Accuracy on batch 54/2438  on Training is 68.97727272727273\n",
            "Epoch #4. Accuracy on batch 55/2438  on Training is 68.91741071428571\n",
            "Epoch #4. Accuracy on batch 56/2438  on Training is 68.8048245614035\n",
            "Epoch #4. Accuracy on batch 57/2438  on Training is 68.85775862068965\n",
            "Epoch #4. Accuracy on batch 58/2438  on Training is 68.96186440677967\n",
            "Epoch #4. Accuracy on batch 59/2438  on Training is 69.01041666666667\n",
            "Batch Id 60/2438 is having training loss of 1.1886688470840454\n",
            "1.5348964929580688\n",
            "Epoch #4. Accuracy on batch 60/2438  on Training is 68.85245901639344\n",
            "Epoch #4. Accuracy on batch 61/2438  on Training is 69.0524193548387\n",
            "Epoch #4. Accuracy on batch 62/2438  on Training is 68.89880952380952\n",
            "Epoch #4. Accuracy on batch 63/2438  on Training is 69.04296875\n",
            "Epoch #4. Accuracy on batch 64/2438  on Training is 69.1826923076923\n",
            "Epoch #4. Accuracy on batch 65/2438  on Training is 69.27083333333333\n",
            "Epoch #4. Accuracy on batch 66/2438  on Training is 69.16977611940298\n",
            "Epoch #4. Accuracy on batch 67/2438  on Training is 69.11764705882354\n",
            "Epoch #4. Accuracy on batch 68/2438  on Training is 69.2481884057971\n",
            "Epoch #4. Accuracy on batch 69/2438  on Training is 69.33035714285714\n",
            "Epoch #4. Accuracy on batch 70/2438  on Training is 69.32218309859155\n",
            "Epoch #4. Accuracy on batch 71/2438  on Training is 69.40104166666667\n",
            "Epoch #4. Accuracy on batch 72/2438  on Training is 69.34931506849315\n",
            "Epoch #4. Accuracy on batch 73/2438  on Training is 69.42567567567568\n",
            "Epoch #4. Accuracy on batch 74/2438  on Training is 69.29166666666667\n",
            "Epoch #4. Accuracy on batch 75/2438  on Training is 69.12006578947368\n",
            "Epoch #4. Accuracy on batch 76/2438  on Training is 69.11525974025975\n",
            "Epoch #4. Accuracy on batch 77/2438  on Training is 68.99038461538461\n",
            "Epoch #4. Accuracy on batch 78/2438  on Training is 68.90822784810126\n",
            "Epoch #4. Accuracy on batch 79/2438  on Training is 69.0234375\n",
            "Batch Id 80/2438 is having training loss of 1.1989458799362183\n",
            "1.242171287536621\n",
            "Epoch #4. Accuracy on batch 80/2438  on Training is 69.02006172839506\n",
            "Epoch #4. Accuracy on batch 81/2438  on Training is 69.09298780487805\n",
            "Epoch #4. Accuracy on batch 82/2438  on Training is 69.08885542168674\n",
            "Epoch #4. Accuracy on batch 83/2438  on Training is 69.01041666666667\n",
            "Epoch #4. Accuracy on batch 84/2438  on Training is 69.11764705882354\n",
            "Epoch #4. Accuracy on batch 85/2438  on Training is 69.22238372093024\n",
            "Epoch #4. Accuracy on batch 86/2438  on Training is 69.25287356321839\n",
            "Epoch #4. Accuracy on batch 87/2438  on Training is 69.140625\n",
            "Epoch #4. Accuracy on batch 88/2438  on Training is 69.10112359550561\n",
            "Epoch #4. Accuracy on batch 89/2438  on Training is 69.09722222222223\n",
            "Epoch #4. Accuracy on batch 90/2438  on Training is 68.81868131868131\n",
            "Epoch #4. Accuracy on batch 91/2438  on Training is 68.9538043478261\n",
            "Epoch #4. Accuracy on batch 92/2438  on Training is 68.98521505376344\n",
            "Epoch #4. Accuracy on batch 93/2438  on Training is 68.98271276595744\n",
            "Epoch #4. Accuracy on batch 94/2438  on Training is 68.94736842105263\n",
            "Epoch #4. Accuracy on batch 95/2438  on Training is 69.01041666666667\n",
            "Epoch #4. Accuracy on batch 96/2438  on Training is 69.00773195876289\n",
            "Epoch #4. Accuracy on batch 97/2438  on Training is 68.97321428571429\n",
            "Epoch #4. Accuracy on batch 98/2438  on Training is 68.84469696969697\n",
            "Epoch #4. Accuracy on batch 99/2438  on Training is 68.78125\n",
            "Batch Id 100/2438 is having training loss of 1.1901628971099854\n",
            "1.363840937614441\n",
            "Epoch #4. Accuracy on batch 100/2438  on Training is 68.75\n",
            "Epoch #4. Accuracy on batch 101/2438  on Training is 68.84191176470588\n",
            "Epoch #4. Accuracy on batch 102/2438  on Training is 68.90169902912622\n",
            "Epoch #4. Accuracy on batch 103/2438  on Training is 68.93028846153847\n",
            "Epoch #4. Accuracy on batch 104/2438  on Training is 68.92857142857143\n",
            "Epoch #4. Accuracy on batch 105/2438  on Training is 68.95636792452831\n",
            "Epoch #4. Accuracy on batch 106/2438  on Training is 68.92523364485982\n",
            "Epoch #4. Accuracy on batch 107/2438  on Training is 68.92361111111111\n",
            "Epoch #4. Accuracy on batch 108/2438  on Training is 68.89334862385321\n",
            "Epoch #4. Accuracy on batch 109/2438  on Training is 68.89204545454545\n",
            "Epoch #4. Accuracy on batch 110/2438  on Training is 68.91891891891892\n",
            "Epoch #4. Accuracy on batch 111/2438  on Training is 68.91741071428571\n",
            "Epoch #4. Accuracy on batch 112/2438  on Training is 68.86061946902655\n",
            "Epoch #4. Accuracy on batch 113/2438  on Training is 68.85964912280701\n",
            "Epoch #4. Accuracy on batch 114/2438  on Training is 68.9945652173913\n",
            "Epoch #4. Accuracy on batch 115/2438  on Training is 69.10021551724138\n",
            "Epoch #4. Accuracy on batch 116/2438  on Training is 69.20405982905983\n",
            "Epoch #4. Accuracy on batch 117/2438  on Training is 69.1207627118644\n",
            "Epoch #4. Accuracy on batch 118/2438  on Training is 69.14390756302521\n",
            "Epoch #4. Accuracy on batch 119/2438  on Training is 69.27083333333333\n",
            "Batch Id 120/2438 is having training loss of 1.176138162612915\n",
            "1.4633874893188477\n",
            "Epoch #4. Accuracy on batch 120/2438  on Training is 69.21487603305785\n",
            "Epoch #4. Accuracy on batch 121/2438  on Training is 69.2110655737705\n",
            "Epoch #4. Accuracy on batch 122/2438  on Training is 69.1310975609756\n",
            "Epoch #4. Accuracy on batch 123/2438  on Training is 69.10282258064517\n",
            "Epoch #4. Accuracy on batch 124/2438  on Training is 69.175\n",
            "Epoch #4. Accuracy on batch 125/2438  on Training is 69.22123015873017\n",
            "Epoch #4. Accuracy on batch 126/2438  on Training is 69.16830708661418\n",
            "Epoch #4. Accuracy on batch 127/2438  on Training is 69.1650390625\n",
            "Epoch #4. Accuracy on batch 128/2438  on Training is 69.0891472868217\n",
            "Epoch #4. Accuracy on batch 129/2438  on Training is 68.99038461538461\n",
            "Epoch #4. Accuracy on batch 130/2438  on Training is 68.94083969465649\n",
            "Epoch #4. Accuracy on batch 131/2438  on Training is 69.01041666666667\n",
            "Epoch #4. Accuracy on batch 132/2438  on Training is 68.98496240601504\n",
            "Epoch #4. Accuracy on batch 133/2438  on Training is 69.02985074626865\n",
            "Epoch #4. Accuracy on batch 134/2438  on Training is 68.98148148148148\n",
            "Epoch #4. Accuracy on batch 135/2438  on Training is 68.93382352941177\n",
            "Epoch #4. Accuracy on batch 136/2438  on Training is 68.95529197080292\n",
            "Epoch #4. Accuracy on batch 137/2438  on Training is 68.99909420289855\n",
            "Epoch #4. Accuracy on batch 138/2438  on Training is 68.92985611510791\n",
            "Epoch #4. Accuracy on batch 139/2438  on Training is 68.99553571428571\n",
            "Batch Id 140/2438 is having training loss of 1.1850429773330688\n",
            "1.4502582550048828\n",
            "Epoch #4. Accuracy on batch 140/2438  on Training is 68.99379432624113\n",
            "Epoch #4. Accuracy on batch 141/2438  on Training is 69.0580985915493\n",
            "Epoch #4. Accuracy on batch 142/2438  on Training is 69.01223776223776\n",
            "Epoch #4. Accuracy on batch 143/2438  on Training is 69.01041666666667\n",
            "Epoch #4. Accuracy on batch 144/2438  on Training is 68.96551724137932\n",
            "Epoch #4. Accuracy on batch 145/2438  on Training is 68.98544520547945\n",
            "Epoch #4. Accuracy on batch 146/2438  on Training is 69.00510204081633\n",
            "Epoch #4. Accuracy on batch 147/2438  on Training is 68.94003378378379\n",
            "Epoch #4. Accuracy on batch 148/2438  on Training is 68.93875838926175\n",
            "Epoch #4. Accuracy on batch 149/2438  on Training is 68.875\n",
            "Epoch #4. Accuracy on batch 150/2438  on Training is 68.81208609271523\n",
            "Epoch #4. Accuracy on batch 151/2438  on Training is 68.87335526315789\n",
            "Epoch #4. Accuracy on batch 152/2438  on Training is 68.97467320261438\n",
            "Epoch #4. Accuracy on batch 153/2438  on Training is 69.0340909090909\n",
            "Epoch #4. Accuracy on batch 154/2438  on Training is 69.01209677419355\n",
            "Epoch #4. Accuracy on batch 155/2438  on Training is 69.03044871794872\n",
            "Epoch #4. Accuracy on batch 156/2438  on Training is 68.96894904458598\n",
            "Epoch #4. Accuracy on batch 157/2438  on Training is 68.92800632911393\n",
            "Epoch #4. Accuracy on batch 158/2438  on Training is 69.04481132075472\n",
            "Epoch #4. Accuracy on batch 159/2438  on Training is 69.0625\n",
            "Batch Id 160/2438 is having training loss of 1.1719273328781128\n",
            "1.070015549659729\n",
            "Epoch #4. Accuracy on batch 160/2438  on Training is 69.07996894409938\n",
            "Epoch #4. Accuracy on batch 161/2438  on Training is 69.07793209876543\n",
            "Epoch #4. Accuracy on batch 162/2438  on Training is 69.03757668711657\n",
            "Epoch #4. Accuracy on batch 163/2438  on Training is 68.9405487804878\n",
            "Epoch #4. Accuracy on batch 164/2438  on Training is 68.86363636363636\n",
            "Epoch #4. Accuracy on batch 165/2438  on Training is 68.8441265060241\n",
            "Epoch #4. Accuracy on batch 166/2438  on Training is 68.8997005988024\n",
            "Epoch #4. Accuracy on batch 167/2438  on Training is 68.91741071428571\n",
            "Epoch #4. Accuracy on batch 168/2438  on Training is 68.97189349112426\n",
            "Epoch #4. Accuracy on batch 169/2438  on Training is 69.00735294117646\n",
            "Epoch #4. Accuracy on batch 170/2438  on Training is 69.02412280701755\n",
            "Epoch #4. Accuracy on batch 171/2438  on Training is 68.96802325581395\n",
            "Epoch #4. Accuracy on batch 172/2438  on Training is 68.9306358381503\n",
            "Epoch #4. Accuracy on batch 173/2438  on Training is 68.91163793103448\n",
            "Epoch #4. Accuracy on batch 174/2438  on Training is 68.85714285714286\n",
            "Epoch #4. Accuracy on batch 175/2438  on Training is 68.92755681818181\n",
            "Epoch #4. Accuracy on batch 176/2438  on Training is 68.90889830508475\n",
            "Epoch #4. Accuracy on batch 177/2438  on Training is 68.94311797752809\n",
            "Epoch #4. Accuracy on batch 178/2438  on Training is 68.92458100558659\n",
            "Epoch #4. Accuracy on batch 179/2438  on Training is 69.02777777777777\n",
            "Batch Id 180/2438 is having training loss of 1.1724333763122559\n",
            "1.1159964799880981\n",
            "Epoch #4. Accuracy on batch 180/2438  on Training is 69.07803867403315\n",
            "Epoch #4. Accuracy on batch 181/2438  on Training is 69.11057692307692\n",
            "Epoch #4. Accuracy on batch 182/2438  on Training is 69.14275956284153\n",
            "Epoch #4. Accuracy on batch 183/2438  on Training is 69.140625\n",
            "Epoch #4. Accuracy on batch 184/2438  on Training is 69.1554054054054\n",
            "Epoch #4. Accuracy on batch 185/2438  on Training is 69.10282258064517\n",
            "Epoch #4. Accuracy on batch 186/2438  on Training is 69.15106951871658\n",
            "Epoch #4. Accuracy on batch 187/2438  on Training is 69.08244680851064\n",
            "Epoch #4. Accuracy on batch 188/2438  on Training is 69.14682539682539\n",
            "Epoch #4. Accuracy on batch 189/2438  on Training is 69.0625\n",
            "Epoch #4. Accuracy on batch 190/2438  on Training is 69.14267015706807\n",
            "Epoch #4. Accuracy on batch 191/2438  on Training is 69.12434895833333\n",
            "Epoch #4. Accuracy on batch 192/2438  on Training is 69.09002590673575\n",
            "Epoch #4. Accuracy on batch 193/2438  on Training is 69.02384020618557\n",
            "Epoch #4. Accuracy on batch 194/2438  on Training is 69.07051282051282\n",
            "Epoch #4. Accuracy on batch 195/2438  on Training is 69.05293367346938\n",
            "Epoch #4. Accuracy on batch 196/2438  on Training is 69.01967005076142\n",
            "Epoch #4. Accuracy on batch 197/2438  on Training is 69.04987373737374\n",
            "Epoch #4. Accuracy on batch 198/2438  on Training is 69.11118090452261\n",
            "Epoch #4. Accuracy on batch 199/2438  on Training is 69.046875\n",
            "Batch Id 200/2438 is having training loss of 1.164531946182251\n",
            "0.7572999000549316\n",
            "Epoch #4. Accuracy on batch 200/2438  on Training is 69.07649253731343\n",
            "Epoch #4. Accuracy on batch 201/2438  on Training is 69.09034653465346\n",
            "Epoch #4. Accuracy on batch 202/2438  on Training is 69.13485221674877\n",
            "Epoch #4. Accuracy on batch 203/2438  on Training is 69.11764705882354\n",
            "Epoch #4. Accuracy on batch 204/2438  on Training is 69.11585365853658\n",
            "Epoch #4. Accuracy on batch 205/2438  on Training is 69.08373786407768\n",
            "Epoch #4. Accuracy on batch 206/2438  on Training is 69.09722222222223\n",
            "Epoch #4. Accuracy on batch 207/2438  on Training is 69.17067307692308\n",
            "Epoch #4. Accuracy on batch 208/2438  on Training is 69.18361244019138\n",
            "Epoch #4. Accuracy on batch 209/2438  on Training is 69.19642857142857\n",
            "Epoch #4. Accuracy on batch 210/2438  on Training is 69.19431279620854\n",
            "Epoch #4. Accuracy on batch 211/2438  on Training is 69.1185141509434\n",
            "Epoch #4. Accuracy on batch 212/2438  on Training is 69.14612676056338\n",
            "Epoch #4. Accuracy on batch 213/2438  on Training is 69.10046728971963\n",
            "Epoch #4. Accuracy on batch 214/2438  on Training is 69.08430232558139\n",
            "Epoch #4. Accuracy on batch 215/2438  on Training is 69.06828703703704\n",
            "Epoch #4. Accuracy on batch 216/2438  on Training is 69.09562211981567\n",
            "Epoch #4. Accuracy on batch 217/2438  on Training is 69.06536697247707\n",
            "Epoch #4. Accuracy on batch 218/2438  on Training is 69.10673515981735\n",
            "Epoch #4. Accuracy on batch 219/2438  on Training is 69.11931818181819\n",
            "Batch Id 220/2438 is having training loss of 1.1665061712265015\n",
            "1.2819454669952393\n",
            "Epoch #4. Accuracy on batch 220/2438  on Training is 69.11764705882354\n",
            "Epoch #4. Accuracy on batch 221/2438  on Training is 69.14414414414415\n",
            "Epoch #4. Accuracy on batch 222/2438  on Training is 69.10033632286995\n",
            "Epoch #4. Accuracy on batch 223/2438  on Training is 69.04296875\n",
            "Epoch #4. Accuracy on batch 224/2438  on Training is 69.02777777777777\n",
            "Epoch #4. Accuracy on batch 225/2438  on Training is 69.02654867256638\n",
            "Epoch #4. Accuracy on batch 226/2438  on Training is 69.01156387665198\n",
            "Epoch #4. Accuracy on batch 227/2438  on Training is 69.02412280701755\n",
            "Epoch #4. Accuracy on batch 228/2438  on Training is 69.02292576419214\n",
            "Epoch #4. Accuracy on batch 229/2438  on Training is 68.9945652173913\n",
            "Epoch #4. Accuracy on batch 230/2438  on Training is 68.91233766233766\n",
            "Epoch #4. Accuracy on batch 231/2438  on Training is 68.88469827586206\n",
            "Epoch #4. Accuracy on batch 232/2438  on Training is 68.8975321888412\n",
            "Epoch #4. Accuracy on batch 233/2438  on Training is 68.8969017094017\n",
            "Epoch #4. Accuracy on batch 234/2438  on Training is 68.90957446808511\n",
            "Epoch #4. Accuracy on batch 235/2438  on Training is 68.8426906779661\n",
            "Epoch #4. Accuracy on batch 236/2438  on Training is 68.82911392405063\n",
            "Epoch #4. Accuracy on batch 237/2438  on Training is 68.78939075630252\n",
            "Epoch #4. Accuracy on batch 238/2438  on Training is 68.81537656903765\n",
            "Epoch #4. Accuracy on batch 239/2438  on Training is 68.81510416666667\n",
            "Batch Id 240/2438 is having training loss of 1.1724966764450073\n",
            "1.116150140762329\n",
            "Epoch #4. Accuracy on batch 240/2438  on Training is 68.80186721991701\n",
            "Epoch #4. Accuracy on batch 241/2438  on Training is 68.80165289256199\n",
            "Epoch #4. Accuracy on batch 242/2438  on Training is 68.78858024691358\n",
            "Epoch #4. Accuracy on batch 243/2438  on Training is 68.76280737704919\n",
            "Epoch #4. Accuracy on batch 244/2438  on Training is 68.80102040816327\n",
            "Epoch #4. Accuracy on batch 245/2438  on Training is 68.80081300813008\n",
            "Epoch #4. Accuracy on batch 246/2438  on Training is 68.7753036437247\n",
            "Epoch #4. Accuracy on batch 247/2438  on Training is 68.72479838709677\n",
            "Epoch #4. Accuracy on batch 248/2438  on Training is 68.68724899598394\n",
            "Epoch #4. Accuracy on batch 249/2438  on Training is 68.65\n",
            "Epoch #4. Accuracy on batch 250/2438  on Training is 68.61304780876495\n",
            "Epoch #4. Accuracy on batch 251/2438  on Training is 68.67559523809524\n",
            "Epoch #4. Accuracy on batch 252/2438  on Training is 68.63883399209486\n",
            "Epoch #4. Accuracy on batch 253/2438  on Training is 68.67618110236221\n",
            "Epoch #4. Accuracy on batch 254/2438  on Training is 68.65196078431373\n",
            "Epoch #4. Accuracy on batch 255/2438  on Training is 68.6279296875\n",
            "Epoch #4. Accuracy on batch 256/2438  on Training is 68.65272373540856\n",
            "Epoch #4. Accuracy on batch 257/2438  on Training is 68.6046511627907\n",
            "Epoch #4. Accuracy on batch 258/2438  on Training is 68.58108108108108\n",
            "Epoch #4. Accuracy on batch 259/2438  on Training is 68.59375\n",
            "Batch Id 260/2438 is having training loss of 1.1750460863113403\n",
            "1.2102549076080322\n",
            "Epoch #4. Accuracy on batch 260/2438  on Training is 68.63026819923371\n",
            "Epoch #4. Accuracy on batch 261/2438  on Training is 68.65458015267176\n",
            "Epoch #4. Accuracy on batch 262/2438  on Training is 68.63117870722434\n",
            "Epoch #4. Accuracy on batch 263/2438  on Training is 68.53693181818181\n",
            "Epoch #4. Accuracy on batch 264/2438  on Training is 68.51415094339623\n",
            "Epoch #4. Accuracy on batch 265/2438  on Training is 68.55028195488721\n",
            "Epoch #4. Accuracy on batch 266/2438  on Training is 68.5744382022472\n",
            "Epoch #4. Accuracy on batch 267/2438  on Training is 68.56343283582089\n",
            "Epoch #4. Accuracy on batch 268/2438  on Training is 68.59897769516729\n",
            "Epoch #4. Accuracy on batch 269/2438  on Training is 68.57638888888889\n",
            "Epoch #4. Accuracy on batch 270/2438  on Training is 68.61162361623616\n",
            "Epoch #4. Accuracy on batch 271/2438  on Training is 68.56617647058823\n",
            "Epoch #4. Accuracy on batch 272/2438  on Training is 68.5782967032967\n",
            "Epoch #4. Accuracy on batch 273/2438  on Training is 68.57892335766424\n",
            "Epoch #4. Accuracy on batch 274/2438  on Training is 68.56818181818181\n",
            "Epoch #4. Accuracy on batch 275/2438  on Training is 68.6028079710145\n",
            "Epoch #4. Accuracy on batch 276/2438  on Training is 68.63718411552347\n",
            "Epoch #4. Accuracy on batch 277/2438  on Training is 68.59262589928058\n",
            "Epoch #4. Accuracy on batch 278/2438  on Training is 68.48118279569893\n",
            "Epoch #4. Accuracy on batch 279/2438  on Training is 68.45982142857143\n",
            "Batch Id 280/2438 is having training loss of 1.1793930530548096\n",
            "1.4287166595458984\n",
            "Epoch #4. Accuracy on batch 280/2438  on Training is 68.44973309608541\n",
            "Epoch #4. Accuracy on batch 281/2438  on Training is 68.43971631205673\n",
            "Epoch #4. Accuracy on batch 282/2438  on Training is 68.45185512367492\n",
            "Epoch #4. Accuracy on batch 283/2438  on Training is 68.4419014084507\n",
            "Epoch #4. Accuracy on batch 284/2438  on Training is 68.46491228070175\n",
            "Epoch #4. Accuracy on batch 285/2438  on Training is 68.48776223776224\n",
            "Epoch #4. Accuracy on batch 286/2438  on Training is 68.51045296167247\n",
            "Epoch #4. Accuracy on batch 287/2438  on Training is 68.50043402777777\n",
            "Epoch #4. Accuracy on batch 288/2438  on Training is 68.46885813148789\n",
            "Epoch #4. Accuracy on batch 289/2438  on Training is 68.49137931034483\n",
            "Epoch #4. Accuracy on batch 290/2438  on Training is 68.50300687285224\n",
            "Epoch #4. Accuracy on batch 291/2438  on Training is 68.50385273972603\n",
            "Epoch #4. Accuracy on batch 292/2438  on Training is 68.48336177474403\n",
            "Epoch #4. Accuracy on batch 293/2438  on Training is 68.50552721088435\n",
            "Epoch #4. Accuracy on batch 294/2438  on Training is 68.47457627118644\n",
            "Epoch #4. Accuracy on batch 295/2438  on Training is 68.4860641891892\n",
            "Epoch #4. Accuracy on batch 296/2438  on Training is 68.51851851851852\n",
            "Epoch #4. Accuracy on batch 297/2438  on Training is 68.52978187919463\n",
            "Epoch #4. Accuracy on batch 298/2438  on Training is 68.45735785953177\n",
            "Epoch #4. Accuracy on batch 299/2438  on Training is 68.47916666666667\n",
            "Batch Id 300/2438 is having training loss of 1.1793700456619263\n",
            "1.571300983428955\n",
            "Epoch #4. Accuracy on batch 300/2438  on Training is 68.46968438538207\n",
            "Epoch #4. Accuracy on batch 301/2438  on Training is 68.42922185430463\n",
            "Epoch #4. Accuracy on batch 302/2438  on Training is 68.45090759075907\n",
            "Epoch #4. Accuracy on batch 303/2438  on Training is 68.48273026315789\n",
            "Epoch #4. Accuracy on batch 304/2438  on Training is 68.48360655737704\n",
            "Epoch #4. Accuracy on batch 305/2438  on Training is 68.53553921568627\n",
            "Epoch #4. Accuracy on batch 306/2438  on Training is 68.53623778501628\n",
            "Epoch #4. Accuracy on batch 307/2438  on Training is 68.52678571428571\n",
            "Epoch #4. Accuracy on batch 308/2438  on Training is 68.50728155339806\n",
            "Epoch #4. Accuracy on batch 309/2438  on Training is 68.48790322580645\n",
            "Epoch #4. Accuracy on batch 310/2438  on Training is 68.46864951768488\n",
            "Epoch #4. Accuracy on batch 311/2438  on Training is 68.4795673076923\n",
            "Epoch #4. Accuracy on batch 312/2438  on Training is 68.46046325878594\n",
            "Epoch #4. Accuracy on batch 313/2438  on Training is 68.42157643312102\n",
            "Epoch #4. Accuracy on batch 314/2438  on Training is 68.43253968253968\n",
            "Epoch #4. Accuracy on batch 315/2438  on Training is 68.45332278481013\n",
            "Epoch #4. Accuracy on batch 316/2438  on Training is 68.47397476340694\n",
            "Epoch #4. Accuracy on batch 317/2438  on Training is 68.4748427672956\n",
            "Epoch #4. Accuracy on batch 318/2438  on Training is 68.49529780564264\n",
            "Epoch #4. Accuracy on batch 319/2438  on Training is 68.486328125\n",
            "Batch Id 320/2438 is having training loss of 1.177391529083252\n",
            "0.8916860222816467\n",
            "Epoch #4. Accuracy on batch 320/2438  on Training is 68.51635514018692\n",
            "Epoch #4. Accuracy on batch 321/2438  on Training is 68.43944099378882\n",
            "Epoch #4. Accuracy on batch 322/2438  on Training is 68.4500773993808\n",
            "Epoch #4. Accuracy on batch 323/2438  on Training is 68.44135802469135\n",
            "Epoch #4. Accuracy on batch 324/2438  on Training is 68.45192307692308\n",
            "Epoch #4. Accuracy on batch 325/2438  on Training is 68.5295245398773\n",
            "Epoch #4. Accuracy on batch 326/2438  on Training is 68.5684250764526\n",
            "Epoch #4. Accuracy on batch 327/2438  on Training is 68.57850609756098\n",
            "Epoch #4. Accuracy on batch 328/2438  on Training is 68.58852583586626\n",
            "Epoch #4. Accuracy on batch 329/2438  on Training is 68.55113636363636\n",
            "Epoch #4. Accuracy on batch 330/2438  on Training is 68.55173716012085\n",
            "Epoch #4. Accuracy on batch 331/2438  on Training is 68.58057228915662\n",
            "Epoch #4. Accuracy on batch 332/2438  on Training is 68.60923423423424\n",
            "Epoch #4. Accuracy on batch 333/2438  on Training is 68.62836826347305\n",
            "Epoch #4. Accuracy on batch 334/2438  on Training is 68.58208955223881\n",
            "Epoch #4. Accuracy on batch 335/2438  on Training is 68.5453869047619\n",
            "Epoch #4. Accuracy on batch 336/2438  on Training is 68.56454005934718\n",
            "Epoch #4. Accuracy on batch 337/2438  on Training is 68.56508875739645\n",
            "Epoch #4. Accuracy on batch 338/2438  on Training is 68.60250737463127\n",
            "Epoch #4. Accuracy on batch 339/2438  on Training is 68.6029411764706\n",
            "Batch Id 340/2438 is having training loss of 1.1735613346099854\n",
            "1.0132132768630981\n",
            "Epoch #4. Accuracy on batch 340/2438  on Training is 68.6033724340176\n",
            "Epoch #4. Accuracy on batch 341/2438  on Training is 68.63121345029239\n",
            "Epoch #4. Accuracy on batch 342/2438  on Training is 68.64978134110787\n",
            "Epoch #4. Accuracy on batch 343/2438  on Training is 68.65007267441861\n",
            "Epoch #4. Accuracy on batch 344/2438  on Training is 68.65036231884058\n",
            "Epoch #4. Accuracy on batch 345/2438  on Training is 68.6235549132948\n",
            "Epoch #4. Accuracy on batch 346/2438  on Training is 68.61491354466858\n",
            "Epoch #4. Accuracy on batch 347/2438  on Training is 68.63326149425288\n",
            "Epoch #4. Accuracy on batch 348/2438  on Training is 68.63359598853869\n",
            "Epoch #4. Accuracy on batch 349/2438  on Training is 68.58928571428571\n",
            "Epoch #4. Accuracy on batch 350/2438  on Training is 68.58084045584046\n",
            "Epoch #4. Accuracy on batch 351/2438  on Training is 68.57244318181819\n",
            "Epoch #4. Accuracy on batch 352/2438  on Training is 68.51983002832861\n",
            "Epoch #4. Accuracy on batch 353/2438  on Training is 68.49399717514125\n",
            "Epoch #4. Accuracy on batch 354/2438  on Training is 68.50352112676056\n",
            "Epoch #4. Accuracy on batch 355/2438  on Training is 68.48665730337079\n",
            "Epoch #4. Accuracy on batch 356/2438  on Training is 68.4873949579832\n",
            "Epoch #4. Accuracy on batch 357/2438  on Training is 68.47067039106145\n",
            "Epoch #4. Accuracy on batch 358/2438  on Training is 68.46274373259052\n",
            "Epoch #4. Accuracy on batch 359/2438  on Training is 68.47222222222223\n",
            "Batch Id 360/2438 is having training loss of 1.1798830032348633\n",
            "1.3183636665344238\n",
            "Epoch #4. Accuracy on batch 360/2438  on Training is 68.4643351800554\n",
            "Epoch #4. Accuracy on batch 361/2438  on Training is 68.48238950276243\n",
            "Epoch #4. Accuracy on batch 362/2438  on Training is 68.4659090909091\n",
            "Epoch #4. Accuracy on batch 363/2438  on Training is 68.48385989010988\n",
            "Epoch #4. Accuracy on batch 364/2438  on Training is 68.50171232876713\n",
            "Epoch #4. Accuracy on batch 365/2438  on Training is 68.46823770491804\n",
            "Epoch #4. Accuracy on batch 366/2438  on Training is 68.48603542234332\n",
            "Epoch #4. Accuracy on batch 367/2438  on Training is 68.45278532608695\n",
            "Epoch #4. Accuracy on batch 368/2438  on Training is 68.43665311653116\n",
            "Epoch #4. Accuracy on batch 369/2438  on Training is 68.4375\n",
            "Epoch #4. Accuracy on batch 370/2438  on Training is 68.4383423180593\n",
            "Epoch #4. Accuracy on batch 371/2438  on Training is 68.43077956989248\n",
            "Epoch #4. Accuracy on batch 372/2438  on Training is 68.41487935656836\n",
            "Epoch #4. Accuracy on batch 373/2438  on Training is 68.42413101604278\n",
            "Epoch #4. Accuracy on batch 374/2438  on Training is 68.45\n",
            "Epoch #4. Accuracy on batch 375/2438  on Training is 68.45079787234043\n",
            "Epoch #4. Accuracy on batch 376/2438  on Training is 68.41014588859416\n",
            "Epoch #4. Accuracy on batch 377/2438  on Training is 68.41931216931216\n",
            "Epoch #4. Accuracy on batch 378/2438  on Training is 68.44492084432717\n",
            "Epoch #4. Accuracy on batch 379/2438  on Training is 68.42927631578948\n",
            "Batch Id 380/2438 is having training loss of 1.1830159425735474\n",
            "1.2531580924987793\n",
            "Epoch #4. Accuracy on batch 380/2438  on Training is 68.43011811023622\n",
            "Epoch #4. Accuracy on batch 381/2438  on Training is 68.47185863874346\n",
            "Epoch #4. Accuracy on batch 382/2438  on Training is 68.48890339425587\n",
            "Epoch #4. Accuracy on batch 383/2438  on Training is 68.52213541666667\n",
            "Epoch #4. Accuracy on batch 384/2438  on Training is 68.52272727272727\n",
            "Epoch #4. Accuracy on batch 385/2438  on Training is 68.5071243523316\n",
            "Epoch #4. Accuracy on batch 386/2438  on Training is 68.54005167958657\n",
            "Epoch #4. Accuracy on batch 387/2438  on Training is 68.54059278350516\n",
            "Epoch #4. Accuracy on batch 388/2438  on Training is 68.58129820051414\n",
            "Epoch #4. Accuracy on batch 389/2438  on Training is 68.54967948717949\n",
            "Epoch #4. Accuracy on batch 390/2438  on Training is 68.55019181585678\n",
            "Epoch #4. Accuracy on batch 391/2438  on Training is 68.54272959183673\n",
            "Epoch #4. Accuracy on batch 392/2438  on Training is 68.55120865139949\n",
            "Epoch #4. Accuracy on batch 393/2438  on Training is 68.55171319796955\n",
            "Epoch #4. Accuracy on batch 394/2438  on Training is 68.60759493670886\n",
            "Epoch #4. Accuracy on batch 395/2438  on Training is 68.61584595959596\n",
            "Epoch #4. Accuracy on batch 396/2438  on Training is 68.5925692695214\n",
            "Epoch #4. Accuracy on batch 397/2438  on Training is 68.63222361809045\n",
            "Epoch #4. Accuracy on batch 398/2438  on Training is 68.61685463659148\n",
            "Epoch #4. Accuracy on batch 399/2438  on Training is 68.640625\n",
            "Batch Id 400/2438 is having training loss of 1.1776599884033203\n",
            "0.8601803779602051\n",
            "Epoch #4. Accuracy on batch 400/2438  on Training is 68.67206982543641\n",
            "Epoch #4. Accuracy on batch 401/2438  on Training is 68.69558457711443\n",
            "Epoch #4. Accuracy on batch 402/2438  on Training is 68.72673697270471\n",
            "Epoch #4. Accuracy on batch 403/2438  on Training is 68.72679455445545\n",
            "Epoch #4. Accuracy on batch 404/2438  on Training is 68.72685185185185\n",
            "Epoch #4. Accuracy on batch 405/2438  on Training is 68.7192118226601\n",
            "Epoch #4. Accuracy on batch 406/2438  on Training is 68.7039312039312\n",
            "Epoch #4. Accuracy on batch 407/2438  on Training is 68.69638480392157\n",
            "Epoch #4. Accuracy on batch 408/2438  on Training is 68.7041564792176\n",
            "Epoch #4. Accuracy on batch 409/2438  on Training is 68.6890243902439\n",
            "Epoch #4. Accuracy on batch 410/2438  on Training is 68.68917274939173\n",
            "Epoch #4. Accuracy on batch 411/2438  on Training is 68.70449029126213\n",
            "Epoch #4. Accuracy on batch 412/2438  on Training is 68.68190072639226\n",
            "Epoch #4. Accuracy on batch 413/2438  on Training is 68.69716183574879\n",
            "Epoch #4. Accuracy on batch 414/2438  on Training is 68.70481927710843\n",
            "Epoch #4. Accuracy on batch 415/2438  on Training is 68.68239182692308\n",
            "Epoch #4. Accuracy on batch 416/2438  on Training is 68.66756594724221\n",
            "Epoch #4. Accuracy on batch 417/2438  on Training is 68.66776315789474\n",
            "Epoch #4. Accuracy on batch 418/2438  on Training is 68.65304295942721\n",
            "Epoch #4. Accuracy on batch 419/2438  on Training is 68.63839285714286\n",
            "Batch Id 420/2438 is having training loss of 1.1775368452072144\n",
            "1.1481510400772095\n",
            "Epoch #4. Accuracy on batch 420/2438  on Training is 68.62381235154395\n",
            "Epoch #4. Accuracy on batch 421/2438  on Training is 68.6093009478673\n",
            "Epoch #4. Accuracy on batch 422/2438  on Training is 68.60963356973996\n",
            "Epoch #4. Accuracy on batch 423/2438  on Training is 68.58785377358491\n",
            "Epoch #4. Accuracy on batch 424/2438  on Training is 68.59558823529412\n",
            "Epoch #4. Accuracy on batch 425/2438  on Training is 68.58861502347418\n",
            "Epoch #4. Accuracy on batch 426/2438  on Training is 68.58899297423888\n",
            "Epoch #4. Accuracy on batch 427/2438  on Training is 68.58936915887851\n",
            "Epoch #4. Accuracy on batch 428/2438  on Training is 68.58974358974359\n",
            "Epoch #4. Accuracy on batch 429/2438  on Training is 68.56104651162791\n",
            "Epoch #4. Accuracy on batch 430/2438  on Training is 68.5614849187935\n",
            "Epoch #4. Accuracy on batch 431/2438  on Training is 68.5691550925926\n",
            "Epoch #4. Accuracy on batch 432/2438  on Training is 68.56235565819861\n",
            "Epoch #4. Accuracy on batch 433/2438  on Training is 68.56278801843318\n",
            "Epoch #4. Accuracy on batch 434/2438  on Training is 68.55603448275862\n",
            "Epoch #4. Accuracy on batch 435/2438  on Training is 68.53497706422019\n",
            "Epoch #4. Accuracy on batch 436/2438  on Training is 68.54977116704805\n",
            "Epoch #4. Accuracy on batch 437/2438  on Training is 68.52882420091325\n",
            "Epoch #4. Accuracy on batch 438/2438  on Training is 68.52220956719817\n",
            "Epoch #4. Accuracy on batch 439/2438  on Training is 68.5440340909091\n",
            "Batch Id 440/2438 is having training loss of 1.176137089729309\n",
            "1.2265167236328125\n",
            "Epoch #4. Accuracy on batch 440/2438  on Training is 68.53032879818593\n",
            "Epoch #4. Accuracy on batch 441/2438  on Training is 68.51668552036199\n",
            "Epoch #4. Accuracy on batch 442/2438  on Training is 68.51721218961626\n",
            "Epoch #4. Accuracy on batch 443/2438  on Training is 68.53181306306307\n",
            "Epoch #4. Accuracy on batch 444/2438  on Training is 68.53230337078652\n",
            "Epoch #4. Accuracy on batch 445/2438  on Training is 68.55381165919283\n",
            "Epoch #4. Accuracy on batch 446/2438  on Training is 68.54026845637584\n",
            "Epoch #4. Accuracy on batch 447/2438  on Training is 68.54073660714286\n",
            "Epoch #4. Accuracy on batch 448/2438  on Training is 68.54120267260579\n",
            "Epoch #4. Accuracy on batch 449/2438  on Training is 68.5\n",
            "Epoch #4. Accuracy on batch 450/2438  on Training is 68.50055432372505\n",
            "Epoch #4. Accuracy on batch 451/2438  on Training is 68.52184734513274\n",
            "Epoch #4. Accuracy on batch 452/2438  on Training is 68.52235099337749\n",
            "Epoch #4. Accuracy on batch 453/2438  on Training is 68.55038546255507\n",
            "Epoch #4. Accuracy on batch 454/2438  on Training is 68.55082417582418\n",
            "Epoch #4. Accuracy on batch 455/2438  on Training is 68.57867324561404\n",
            "Epoch #4. Accuracy on batch 456/2438  on Training is 68.56537199124726\n",
            "Epoch #4. Accuracy on batch 457/2438  on Training is 68.54530567685589\n",
            "Epoch #4. Accuracy on batch 458/2438  on Training is 68.54575163398692\n",
            "Epoch #4. Accuracy on batch 459/2438  on Training is 68.56657608695652\n",
            "Batch Id 460/2438 is having training loss of 1.176692247390747\n",
            "1.3048490285873413\n",
            "Epoch #4. Accuracy on batch 460/2438  on Training is 68.55341648590021\n",
            "Epoch #4. Accuracy on batch 461/2438  on Training is 68.56060606060606\n",
            "Epoch #4. Accuracy on batch 462/2438  on Training is 68.5542656587473\n",
            "Epoch #4. Accuracy on batch 463/2438  on Training is 68.53448275862068\n",
            "Epoch #4. Accuracy on batch 464/2438  on Training is 68.56854838709677\n",
            "Epoch #4. Accuracy on batch 465/2438  on Training is 68.56893776824035\n",
            "Epoch #4. Accuracy on batch 466/2438  on Training is 68.58270877944325\n",
            "Epoch #4. Accuracy on batch 467/2438  on Training is 68.57638888888889\n",
            "Epoch #4. Accuracy on batch 468/2438  on Training is 68.56343283582089\n",
            "Epoch #4. Accuracy on batch 469/2438  on Training is 68.55053191489361\n",
            "Epoch #4. Accuracy on batch 470/2438  on Training is 68.55759023354565\n",
            "Epoch #4. Accuracy on batch 471/2438  on Training is 68.57123940677967\n",
            "Epoch #4. Accuracy on batch 472/2438  on Training is 68.55179704016913\n",
            "Epoch #4. Accuracy on batch 473/2438  on Training is 68.52584388185655\n",
            "Epoch #4. Accuracy on batch 474/2438  on Training is 68.54605263157895\n",
            "Epoch #4. Accuracy on batch 475/2438  on Training is 68.53335084033614\n",
            "Epoch #4. Accuracy on batch 476/2438  on Training is 68.56001048218029\n",
            "Epoch #4. Accuracy on batch 477/2438  on Training is 68.57348326359832\n",
            "Epoch #4. Accuracy on batch 478/2438  on Training is 68.580375782881\n",
            "Epoch #4. Accuracy on batch 479/2438  on Training is 68.57421875\n",
            "Batch Id 480/2438 is having training loss of 1.1779322624206543\n",
            "1.0897680521011353\n",
            "Epoch #4. Accuracy on batch 480/2438  on Training is 68.5745841995842\n",
            "Epoch #4. Accuracy on batch 481/2438  on Training is 68.58791493775934\n",
            "Epoch #4. Accuracy on batch 482/2438  on Training is 68.58825051759834\n",
            "Epoch #4. Accuracy on batch 483/2438  on Training is 68.60795454545455\n",
            "Epoch #4. Accuracy on batch 484/2438  on Training is 68.62113402061856\n",
            "Epoch #4. Accuracy on batch 485/2438  on Training is 68.64068930041152\n",
            "Epoch #4. Accuracy on batch 486/2438  on Training is 68.63449691991786\n",
            "Epoch #4. Accuracy on batch 487/2438  on Training is 68.6155225409836\n",
            "Epoch #4. Accuracy on batch 488/2438  on Training is 68.61579754601227\n",
            "Epoch #4. Accuracy on batch 489/2438  on Training is 68.64795918367346\n",
            "Epoch #4. Accuracy on batch 490/2438  on Training is 68.65453156822811\n",
            "Epoch #4. Accuracy on batch 491/2438  on Training is 68.67378048780488\n",
            "Epoch #4. Accuracy on batch 492/2438  on Training is 68.69295131845841\n",
            "Epoch #4. Accuracy on batch 493/2438  on Training is 68.6993927125506\n",
            "Epoch #4. Accuracy on batch 494/2438  on Training is 68.69318181818181\n",
            "Epoch #4. Accuracy on batch 495/2438  on Training is 68.70589717741936\n",
            "Epoch #4. Accuracy on batch 496/2438  on Training is 68.71856136820925\n",
            "Epoch #4. Accuracy on batch 497/2438  on Training is 68.71862449799197\n",
            "Epoch #4. Accuracy on batch 498/2438  on Training is 68.7124248496994\n",
            "Epoch #4. Accuracy on batch 499/2438  on Training is 68.7375\n",
            "Batch Id 500/2438 is having training loss of 1.1737438440322876\n",
            "1.111093282699585\n",
            "Epoch #4. Accuracy on batch 500/2438  on Training is 68.7375249500998\n",
            "Epoch #4. Accuracy on batch 501/2438  on Training is 68.73754980079681\n",
            "Epoch #4. Accuracy on batch 502/2438  on Training is 68.74378727634195\n",
            "Epoch #4. Accuracy on batch 503/2438  on Training is 68.74379960317461\n",
            "Epoch #4. Accuracy on batch 504/2438  on Training is 68.73762376237623\n",
            "Epoch #4. Accuracy on batch 505/2438  on Training is 68.71912055335969\n",
            "Epoch #4. Accuracy on batch 506/2438  on Training is 68.71918145956607\n",
            "Epoch #4. Accuracy on batch 507/2438  on Training is 68.72539370078741\n",
            "Epoch #4. Accuracy on batch 508/2438  on Training is 68.7315815324165\n",
            "Epoch #4. Accuracy on batch 509/2438  on Training is 68.73774509803921\n",
            "Epoch #4. Accuracy on batch 510/2438  on Training is 68.72553816046967\n",
            "Epoch #4. Accuracy on batch 511/2438  on Training is 68.71337890625\n",
            "Epoch #4. Accuracy on batch 512/2438  on Training is 68.70126705653021\n",
            "Epoch #4. Accuracy on batch 513/2438  on Training is 68.65272373540856\n",
            "Epoch #4. Accuracy on batch 514/2438  on Training is 68.64684466019418\n",
            "Epoch #4. Accuracy on batch 515/2438  on Training is 68.65310077519379\n",
            "Epoch #4. Accuracy on batch 516/2438  on Training is 68.65933268858801\n",
            "Epoch #4. Accuracy on batch 517/2438  on Training is 68.67157335907336\n",
            "Epoch #4. Accuracy on batch 518/2438  on Training is 68.6837668593449\n",
            "Epoch #4. Accuracy on batch 519/2438  on Training is 68.65384615384616\n",
            "Batch Id 520/2438 is having training loss of 1.1772559881210327\n",
            "1.3416178226470947\n",
            "Epoch #4. Accuracy on batch 520/2438  on Training is 68.65403071017275\n",
            "Epoch #4. Accuracy on batch 521/2438  on Training is 68.65421455938697\n",
            "Epoch #4. Accuracy on batch 522/2438  on Training is 68.66037284894837\n",
            "Epoch #4. Accuracy on batch 523/2438  on Training is 68.66650763358778\n",
            "Epoch #4. Accuracy on batch 524/2438  on Training is 68.69047619047619\n",
            "Epoch #4. Accuracy on batch 525/2438  on Training is 68.6787072243346\n",
            "Epoch #4. Accuracy on batch 526/2438  on Training is 68.66698292220114\n",
            "Epoch #4. Accuracy on batch 527/2438  on Training is 68.67305871212122\n",
            "Epoch #4. Accuracy on batch 528/2438  on Training is 68.66138941398866\n",
            "Epoch #4. Accuracy on batch 529/2438  on Training is 68.65566037735849\n",
            "Epoch #4. Accuracy on batch 530/2438  on Training is 68.6734934086629\n",
            "Epoch #4. Accuracy on batch 531/2438  on Training is 68.67951127819549\n",
            "Epoch #4. Accuracy on batch 532/2438  on Training is 68.6796435272045\n",
            "Epoch #4. Accuracy on batch 533/2438  on Training is 68.67977528089888\n",
            "Epoch #4. Accuracy on batch 534/2438  on Training is 68.6857476635514\n",
            "Epoch #4. Accuracy on batch 535/2438  on Training is 68.68003731343283\n",
            "Epoch #4. Accuracy on batch 536/2438  on Training is 68.6627094972067\n",
            "Epoch #4. Accuracy on batch 537/2438  on Training is 68.62802044609666\n",
            "Epoch #4. Accuracy on batch 538/2438  on Training is 68.610853432282\n",
            "Epoch #4. Accuracy on batch 539/2438  on Training is 68.61111111111111\n",
            "Batch Id 540/2438 is having training loss of 1.1776989698410034\n",
            "0.9264950752258301\n",
            "Epoch #4. Accuracy on batch 540/2438  on Training is 68.62292051756008\n",
            "Epoch #4. Accuracy on batch 541/2438  on Training is 68.62315498154982\n",
            "Epoch #4. Accuracy on batch 542/2438  on Training is 68.62914364640883\n",
            "Epoch #4. Accuracy on batch 543/2438  on Training is 68.62936580882354\n",
            "Epoch #4. Accuracy on batch 544/2438  on Training is 68.6295871559633\n",
            "Epoch #4. Accuracy on batch 545/2438  on Training is 68.6183608058608\n",
            "Epoch #4. Accuracy on batch 546/2438  on Training is 68.6414533820841\n",
            "Epoch #4. Accuracy on batch 547/2438  on Training is 68.63594890510949\n",
            "Epoch #4. Accuracy on batch 548/2438  on Training is 68.584927140255\n",
            "Epoch #4. Accuracy on batch 549/2438  on Training is 68.5625\n",
            "Epoch #4. Accuracy on batch 550/2438  on Training is 68.56851179673322\n",
            "Epoch #4. Accuracy on batch 551/2438  on Training is 68.58016304347827\n",
            "Epoch #4. Accuracy on batch 552/2438  on Training is 68.56916817359856\n",
            "Epoch #4. Accuracy on batch 553/2438  on Training is 68.53564981949458\n",
            "Epoch #4. Accuracy on batch 554/2438  on Training is 68.54166666666667\n",
            "Epoch #4. Accuracy on batch 555/2438  on Training is 68.50831834532374\n",
            "Epoch #4. Accuracy on batch 556/2438  on Training is 68.50875224416517\n",
            "Epoch #4. Accuracy on batch 557/2438  on Training is 68.5203853046595\n",
            "Epoch #4. Accuracy on batch 558/2438  on Training is 68.49843470483006\n",
            "Epoch #4. Accuracy on batch 559/2438  on Training is 68.52120535714286\n",
            "Batch Id 560/2438 is having training loss of 1.1797523498535156\n",
            "1.4706171751022339\n",
            "Epoch #4. Accuracy on batch 560/2438  on Training is 68.5104723707665\n",
            "Epoch #4. Accuracy on batch 561/2438  on Training is 68.5442615658363\n",
            "Epoch #4. Accuracy on batch 562/2438  on Training is 68.55017761989343\n",
            "Epoch #4. Accuracy on batch 563/2438  on Training is 68.55053191489361\n",
            "Epoch #4. Accuracy on batch 564/2438  on Training is 68.55641592920354\n",
            "Epoch #4. Accuracy on batch 565/2438  on Training is 68.56780035335689\n",
            "Epoch #4. Accuracy on batch 566/2438  on Training is 68.5681216931217\n",
            "Epoch #4. Accuracy on batch 567/2438  on Training is 68.56844190140845\n",
            "Epoch #4. Accuracy on batch 568/2438  on Training is 68.57974516695958\n",
            "Epoch #4. Accuracy on batch 569/2438  on Training is 68.58552631578948\n",
            "Epoch #4. Accuracy on batch 570/2438  on Training is 68.6077057793345\n",
            "Epoch #4. Accuracy on batch 571/2438  on Training is 68.59702797202797\n",
            "Epoch #4. Accuracy on batch 572/2438  on Training is 68.58638743455498\n",
            "Epoch #4. Accuracy on batch 573/2438  on Training is 68.59756097560975\n",
            "Epoch #4. Accuracy on batch 574/2438  on Training is 68.59782608695652\n",
            "Epoch #4. Accuracy on batch 575/2438  on Training is 68.61979166666667\n",
            "Epoch #4. Accuracy on batch 576/2438  on Training is 68.59293760831889\n",
            "Epoch #4. Accuracy on batch 577/2438  on Training is 68.59861591695501\n",
            "Epoch #4. Accuracy on batch 578/2438  on Training is 68.62046632124353\n",
            "Epoch #4. Accuracy on batch 579/2438  on Training is 68.62068965517241\n",
            "Batch Id 580/2438 is having training loss of 1.1750023365020752\n",
            "0.9122533202171326\n",
            "Epoch #4. Accuracy on batch 580/2438  on Training is 68.63704819277109\n",
            "Epoch #4. Accuracy on batch 581/2438  on Training is 68.64798109965636\n",
            "Epoch #4. Accuracy on batch 582/2438  on Training is 68.65887650085763\n",
            "Epoch #4. Accuracy on batch 583/2438  on Training is 68.68043664383562\n",
            "Epoch #4. Accuracy on batch 584/2438  on Training is 68.67521367521367\n",
            "Epoch #4. Accuracy on batch 585/2438  on Training is 68.68600682593856\n",
            "Epoch #4. Accuracy on batch 586/2438  on Training is 68.6914395229983\n",
            "Epoch #4. Accuracy on batch 587/2438  on Training is 68.6968537414966\n",
            "Epoch #4. Accuracy on batch 588/2438  on Training is 68.71816638370119\n",
            "Epoch #4. Accuracy on batch 589/2438  on Training is 68.70762711864407\n",
            "Epoch #4. Accuracy on batch 590/2438  on Training is 68.69712351945854\n",
            "Epoch #4. Accuracy on batch 591/2438  on Training is 68.71304898648648\n",
            "Epoch #4. Accuracy on batch 592/2438  on Training is 68.69203204047217\n",
            "Epoch #4. Accuracy on batch 593/2438  on Training is 68.6763468013468\n",
            "Epoch #4. Accuracy on batch 594/2438  on Training is 68.66071428571429\n",
            "Epoch #4. Accuracy on batch 595/2438  on Training is 68.67659395973155\n",
            "Epoch #4. Accuracy on batch 596/2438  on Training is 68.69765494137353\n",
            "Epoch #4. Accuracy on batch 597/2438  on Training is 68.67683946488295\n",
            "Epoch #4. Accuracy on batch 598/2438  on Training is 68.68217863105176\n",
            "Epoch #4. Accuracy on batch 599/2438  on Training is 68.6875\n",
            "Batch Id 600/2438 is having training loss of 1.173799991607666\n",
            "0.9533594250679016\n",
            "Epoch #4. Accuracy on batch 600/2438  on Training is 68.70840266222962\n",
            "Epoch #4. Accuracy on batch 601/2438  on Training is 68.67732558139535\n",
            "Epoch #4. Accuracy on batch 602/2438  on Training is 68.68781094527363\n",
            "Epoch #4. Accuracy on batch 603/2438  on Training is 68.70860927152317\n",
            "Epoch #4. Accuracy on batch 604/2438  on Training is 68.70351239669421\n",
            "Epoch #4. Accuracy on batch 605/2438  on Training is 68.72421617161716\n",
            "Epoch #4. Accuracy on batch 606/2438  on Training is 68.70366556836903\n",
            "Epoch #4. Accuracy on batch 607/2438  on Training is 68.72430098684211\n",
            "Epoch #4. Accuracy on batch 608/2438  on Training is 68.74486863711002\n",
            "Epoch #4. Accuracy on batch 609/2438  on Training is 68.75512295081967\n",
            "Epoch #4. Accuracy on batch 610/2438  on Training is 68.75511456628477\n",
            "Epoch #4. Accuracy on batch 611/2438  on Training is 68.76531862745098\n",
            "Epoch #4. Accuracy on batch 612/2438  on Training is 68.76529363784665\n",
            "Epoch #4. Accuracy on batch 613/2438  on Training is 68.77544788273616\n",
            "Epoch #4. Accuracy on batch 614/2438  on Training is 68.76524390243902\n",
            "Epoch #4. Accuracy on batch 615/2438  on Training is 68.78551136363636\n",
            "Epoch #4. Accuracy on batch 616/2438  on Training is 68.7803889789303\n",
            "Epoch #4. Accuracy on batch 617/2438  on Training is 68.78033980582525\n",
            "Epoch #4. Accuracy on batch 618/2438  on Training is 68.78533925686591\n",
            "Epoch #4. Accuracy on batch 619/2438  on Training is 68.78528225806451\n",
            "Batch Id 620/2438 is having training loss of 1.1719353199005127\n",
            "0.846467137336731\n",
            "Epoch #4. Accuracy on batch 620/2438  on Training is 68.79528985507247\n",
            "Epoch #4. Accuracy on batch 621/2438  on Training is 68.79521704180064\n",
            "Epoch #4. Accuracy on batch 622/2438  on Training is 68.7951444622793\n",
            "Epoch #4. Accuracy on batch 623/2438  on Training is 68.80508814102564\n",
            "Epoch #4. Accuracy on batch 624/2438  on Training is 68.825\n",
            "Epoch #4. Accuracy on batch 625/2438  on Training is 68.80990415335464\n",
            "Epoch #4. Accuracy on batch 626/2438  on Training is 68.82476076555024\n",
            "Epoch #4. Accuracy on batch 627/2438  on Training is 68.81966560509554\n",
            "Epoch #4. Accuracy on batch 628/2438  on Training is 68.80961844197138\n",
            "Epoch #4. Accuracy on batch 629/2438  on Training is 68.8045634920635\n",
            "Epoch #4. Accuracy on batch 630/2438  on Training is 68.76980982567353\n",
            "Epoch #4. Accuracy on batch 631/2438  on Training is 68.74505537974683\n",
            "Epoch #4. Accuracy on batch 632/2438  on Training is 68.74012638230647\n",
            "Epoch #4. Accuracy on batch 633/2438  on Training is 68.71549684542586\n",
            "Epoch #4. Accuracy on batch 634/2438  on Training is 68.72539370078741\n",
            "Epoch #4. Accuracy on batch 635/2438  on Training is 68.72543238993711\n",
            "Epoch #4. Accuracy on batch 636/2438  on Training is 68.73037676609106\n",
            "Epoch #4. Accuracy on batch 637/2438  on Training is 68.74510188087774\n",
            "Epoch #4. Accuracy on batch 638/2438  on Training is 68.74021909233177\n",
            "Epoch #4. Accuracy on batch 639/2438  on Training is 68.75\n",
            "Batch Id 640/2438 is having training loss of 1.1723496913909912\n",
            "1.2725657224655151\n",
            "Epoch #4. Accuracy on batch 640/2438  on Training is 68.7451248049922\n",
            "Epoch #4. Accuracy on batch 641/2438  on Training is 68.7451323987539\n",
            "Epoch #4. Accuracy on batch 642/2438  on Training is 68.76944012441679\n",
            "Epoch #4. Accuracy on batch 643/2438  on Training is 68.7694099378882\n",
            "Epoch #4. Accuracy on batch 644/2438  on Training is 68.76937984496124\n",
            "Epoch #4. Accuracy on batch 645/2438  on Training is 68.75483746130031\n",
            "Epoch #4. Accuracy on batch 646/2438  on Training is 68.75\n",
            "Epoch #4. Accuracy on batch 647/2438  on Training is 68.7548225308642\n",
            "Epoch #4. Accuracy on batch 648/2438  on Training is 68.74036979969183\n",
            "Epoch #4. Accuracy on batch 649/2438  on Training is 68.75\n",
            "Epoch #4. Accuracy on batch 650/2438  on Training is 68.74519969278033\n",
            "Epoch #4. Accuracy on batch 651/2438  on Training is 68.75\n",
            "Epoch #4. Accuracy on batch 652/2438  on Training is 68.75\n",
            "Epoch #4. Accuracy on batch 653/2438  on Training is 68.73566513761467\n",
            "Epoch #4. Accuracy on batch 654/2438  on Training is 68.74045801526718\n",
            "Epoch #4. Accuracy on batch 655/2438  on Training is 68.7547637195122\n",
            "Epoch #4. Accuracy on batch 656/2438  on Training is 68.75\n",
            "Epoch #4. Accuracy on batch 657/2438  on Training is 68.75474924012158\n",
            "Epoch #4. Accuracy on batch 658/2438  on Training is 68.73103186646433\n",
            "Epoch #4. Accuracy on batch 659/2438  on Training is 68.73106060606061\n",
            "Batch Id 660/2438 is having training loss of 1.1719938516616821\n",
            "0.9194182753562927\n",
            "Epoch #4. Accuracy on batch 660/2438  on Training is 68.75\n",
            "Epoch #4. Accuracy on batch 661/2438  on Training is 68.75\n",
            "Epoch #4. Accuracy on batch 662/2438  on Training is 68.75471342383108\n",
            "Epoch #4. Accuracy on batch 663/2438  on Training is 68.73117469879519\n",
            "Epoch #4. Accuracy on batch 664/2438  on Training is 68.7312030075188\n",
            "Epoch #4. Accuracy on batch 665/2438  on Training is 68.7546921921922\n",
            "Epoch #4. Accuracy on batch 666/2438  on Training is 68.75\n",
            "Epoch #4. Accuracy on batch 667/2438  on Training is 68.74064371257485\n",
            "Epoch #4. Accuracy on batch 668/2438  on Training is 68.7453288490284\n",
            "Epoch #4. Accuracy on batch 669/2438  on Training is 68.75466417910448\n",
            "Epoch #4. Accuracy on batch 670/2438  on Training is 68.74534277198211\n",
            "Epoch #4. Accuracy on batch 671/2438  on Training is 68.74534970238095\n",
            "Epoch #4. Accuracy on batch 672/2438  on Training is 68.7407132243685\n",
            "Epoch #4. Accuracy on batch 673/2438  on Training is 68.74536350148368\n",
            "Epoch #4. Accuracy on batch 674/2438  on Training is 68.73148148148148\n",
            "Epoch #4. Accuracy on batch 675/2438  on Training is 68.74075443786982\n",
            "Epoch #4. Accuracy on batch 676/2438  on Training is 68.74076809453472\n",
            "Epoch #4. Accuracy on batch 677/2438  on Training is 68.72234513274336\n",
            "Epoch #4. Accuracy on batch 678/2438  on Training is 68.72238586156112\n",
            "Epoch #4. Accuracy on batch 679/2438  on Training is 68.71323529411765\n",
            "Batch Id 680/2438 is having training loss of 1.1739897727966309\n",
            "1.2424464225769043\n",
            "Epoch #4. Accuracy on batch 680/2438  on Training is 68.72705580029368\n",
            "Epoch #4. Accuracy on batch 681/2438  on Training is 68.7408357771261\n",
            "Epoch #4. Accuracy on batch 682/2438  on Training is 68.7637262079063\n",
            "Epoch #4. Accuracy on batch 683/2438  on Training is 68.76827485380117\n",
            "Epoch #4. Accuracy on batch 684/2438  on Training is 68.78193430656934\n",
            "Epoch #4. Accuracy on batch 685/2438  on Training is 68.78188775510205\n",
            "Epoch #4. Accuracy on batch 686/2438  on Training is 68.8000363901019\n",
            "Epoch #4. Accuracy on batch 687/2438  on Training is 68.78179505813954\n",
            "Epoch #4. Accuracy on batch 688/2438  on Training is 68.77721335268505\n",
            "Epoch #4. Accuracy on batch 689/2438  on Training is 68.77264492753623\n",
            "Epoch #4. Accuracy on batch 690/2438  on Training is 68.7590448625181\n",
            "Epoch #4. Accuracy on batch 691/2438  on Training is 68.75451589595376\n",
            "Epoch #4. Accuracy on batch 692/2438  on Training is 68.76352813852814\n",
            "Epoch #4. Accuracy on batch 693/2438  on Training is 68.74099423631124\n",
            "Epoch #4. Accuracy on batch 694/2438  on Training is 68.7410071942446\n",
            "Epoch #4. Accuracy on batch 695/2438  on Training is 68.72755028735632\n",
            "Epoch #4. Accuracy on batch 696/2438  on Training is 68.7051649928264\n",
            "Epoch #4. Accuracy on batch 697/2438  on Training is 68.71866045845272\n",
            "Epoch #4. Accuracy on batch 698/2438  on Training is 68.70976394849785\n",
            "Epoch #4. Accuracy on batch 699/2438  on Training is 68.72321428571429\n",
            "Batch Id 700/2438 is having training loss of 1.175140380859375\n",
            "1.0674467086791992\n",
            "Epoch #4. Accuracy on batch 700/2438  on Training is 68.72771041369472\n",
            "Epoch #4. Accuracy on batch 701/2438  on Training is 68.71883903133903\n",
            "Epoch #4. Accuracy on batch 702/2438  on Training is 68.70999288762447\n",
            "Epoch #4. Accuracy on batch 703/2438  on Training is 68.72336647727273\n",
            "Epoch #4. Accuracy on batch 704/2438  on Training is 68.75443262411348\n",
            "Epoch #4. Accuracy on batch 705/2438  on Training is 68.73229461756374\n",
            "Epoch #4. Accuracy on batch 706/2438  on Training is 68.7190594059406\n",
            "Epoch #4. Accuracy on batch 707/2438  on Training is 68.72351694915254\n",
            "Epoch #4. Accuracy on batch 708/2438  on Training is 68.72355430183357\n",
            "Epoch #4. Accuracy on batch 709/2438  on Training is 68.74119718309859\n",
            "Epoch #4. Accuracy on batch 710/2438  on Training is 68.74120956399437\n",
            "Epoch #4. Accuracy on batch 711/2438  on Training is 68.72366573033707\n",
            "Epoch #4. Accuracy on batch 712/2438  on Training is 68.71055399719495\n",
            "Epoch #4. Accuracy on batch 713/2438  on Training is 68.71498599439776\n",
            "Epoch #4. Accuracy on batch 714/2438  on Training is 68.7062937062937\n",
            "Epoch #4. Accuracy on batch 715/2438  on Training is 68.71944832402235\n",
            "Epoch #4. Accuracy on batch 716/2438  on Training is 68.69769874476988\n",
            "Epoch #4. Accuracy on batch 717/2438  on Training is 68.70212395543176\n",
            "Epoch #4. Accuracy on batch 718/2438  on Training is 68.71088317107093\n",
            "Epoch #4. Accuracy on batch 719/2438  on Training is 68.70225694444444\n",
            "Batch Id 720/2438 is having training loss of 1.1760333776474\n",
            "1.056682825088501\n",
            "Epoch #4. Accuracy on batch 720/2438  on Training is 68.70232316227462\n",
            "Epoch #4. Accuracy on batch 721/2438  on Training is 68.71537396121883\n",
            "Epoch #4. Accuracy on batch 722/2438  on Training is 68.71974412171508\n",
            "Epoch #4. Accuracy on batch 723/2438  on Training is 68.71978591160222\n",
            "Epoch #4. Accuracy on batch 724/2438  on Training is 68.71120689655173\n",
            "Epoch #4. Accuracy on batch 725/2438  on Training is 68.70695592286502\n",
            "Epoch #4. Accuracy on batch 726/2438  on Training is 68.685522696011\n",
            "Epoch #4. Accuracy on batch 727/2438  on Training is 68.69848901098901\n",
            "Epoch #4. Accuracy on batch 728/2438  on Training is 68.69427297668038\n",
            "Epoch #4. Accuracy on batch 729/2438  on Training is 68.67722602739725\n",
            "Epoch #4. Accuracy on batch 730/2438  on Training is 68.67305061559507\n",
            "Epoch #4. Accuracy on batch 731/2438  on Training is 68.6859631147541\n",
            "Epoch #4. Accuracy on batch 732/2438  on Training is 68.68178717598909\n",
            "Epoch #4. Accuracy on batch 733/2438  on Training is 68.68613760217984\n",
            "Epoch #4. Accuracy on batch 734/2438  on Training is 68.66496598639456\n",
            "Epoch #4. Accuracy on batch 735/2438  on Training is 68.6608355978261\n",
            "Epoch #4. Accuracy on batch 736/2438  on Training is 68.6694369063772\n",
            "Epoch #4. Accuracy on batch 737/2438  on Training is 68.66954607046071\n",
            "Epoch #4. Accuracy on batch 738/2438  on Training is 68.66119756427605\n",
            "Epoch #4. Accuracy on batch 739/2438  on Training is 68.66976351351352\n",
            "Batch Id 740/2438 is having training loss of 1.1781890392303467\n",
            "1.295102834701538\n",
            "Epoch #4. Accuracy on batch 740/2438  on Training is 68.67408906882591\n",
            "Epoch #4. Accuracy on batch 741/2438  on Training is 68.69524932614556\n",
            "Epoch #4. Accuracy on batch 742/2438  on Training is 68.68691117092867\n",
            "Epoch #4. Accuracy on batch 743/2438  on Training is 68.69119623655914\n",
            "Epoch #4. Accuracy on batch 744/2438  on Training is 68.67030201342281\n",
            "Epoch #4. Accuracy on batch 745/2438  on Training is 68.6536528150134\n",
            "Epoch #4. Accuracy on batch 746/2438  on Training is 68.6495983935743\n",
            "Epoch #4. Accuracy on batch 747/2438  on Training is 68.65808823529412\n",
            "Epoch #4. Accuracy on batch 748/2438  on Training is 68.64569425901202\n",
            "Epoch #4. Accuracy on batch 749/2438  on Training is 68.62916666666666\n",
            "Epoch #4. Accuracy on batch 750/2438  on Training is 68.62516644474034\n",
            "Epoch #4. Accuracy on batch 751/2438  on Training is 68.62533244680851\n",
            "Epoch #4. Accuracy on batch 752/2438  on Training is 68.62964807436919\n",
            "Epoch #4. Accuracy on batch 753/2438  on Training is 68.63395225464191\n",
            "Epoch #4. Accuracy on batch 754/2438  on Training is 68.64652317880795\n",
            "Epoch #4. Accuracy on batch 755/2438  on Training is 68.64666005291005\n",
            "Epoch #4. Accuracy on batch 756/2438  on Training is 68.6509247027741\n",
            "Epoch #4. Accuracy on batch 757/2438  on Training is 68.64281002638522\n",
            "Epoch #4. Accuracy on batch 758/2438  on Training is 68.65118577075098\n",
            "Epoch #4. Accuracy on batch 759/2438  on Training is 68.65131578947368\n",
            "Batch Id 760/2438 is having training loss of 1.178425669670105\n",
            "0.995334804058075\n",
            "Epoch #4. Accuracy on batch 760/2438  on Training is 68.65555190538765\n",
            "Epoch #4. Accuracy on batch 761/2438  on Training is 68.65567585301837\n",
            "Epoch #4. Accuracy on batch 762/2438  on Training is 68.64760812581913\n",
            "Epoch #4. Accuracy on batch 763/2438  on Training is 68.64774214659685\n",
            "Epoch #4. Accuracy on batch 764/2438  on Training is 68.63153594771242\n",
            "Epoch #4. Accuracy on batch 765/2438  on Training is 68.60721279373368\n",
            "Epoch #4. Accuracy on batch 766/2438  on Training is 68.60739895697523\n",
            "Epoch #4. Accuracy on batch 767/2438  on Training is 68.60758463541667\n",
            "Epoch #4. Accuracy on batch 768/2438  on Training is 68.59964239271781\n",
            "Epoch #4. Accuracy on batch 769/2438  on Training is 68.57548701298701\n",
            "Epoch #4. Accuracy on batch 770/2438  on Training is 68.57166018158236\n",
            "Epoch #4. Accuracy on batch 771/2438  on Training is 68.57189119170984\n",
            "Epoch #4. Accuracy on batch 772/2438  on Training is 68.57212160413971\n",
            "Epoch #4. Accuracy on batch 773/2438  on Training is 68.58042635658914\n",
            "Epoch #4. Accuracy on batch 774/2438  on Training is 68.58870967741936\n",
            "Epoch #4. Accuracy on batch 775/2438  on Training is 68.59697164948453\n",
            "Epoch #4. Accuracy on batch 776/2438  on Training is 68.61325611325611\n",
            "Epoch #4. Accuracy on batch 777/2438  on Training is 68.59736503856041\n",
            "Epoch #4. Accuracy on batch 778/2438  on Training is 68.58151476251605\n",
            "Epoch #4. Accuracy on batch 779/2438  on Training is 68.57772435897436\n",
            "Batch Id 780/2438 is having training loss of 1.1800073385238647\n",
            "1.1236374378204346\n",
            "Epoch #4. Accuracy on batch 780/2438  on Training is 68.57794494238156\n",
            "Epoch #4. Accuracy on batch 781/2438  on Training is 68.5701726342711\n",
            "Epoch #4. Accuracy on batch 782/2438  on Training is 68.55842911877394\n",
            "Epoch #4. Accuracy on batch 783/2438  on Training is 68.53077168367346\n",
            "Epoch #4. Accuracy on batch 784/2438  on Training is 68.546974522293\n",
            "Epoch #4. Accuracy on batch 785/2438  on Training is 68.53928117048346\n",
            "Epoch #4. Accuracy on batch 786/2438  on Training is 68.53160736975858\n",
            "Epoch #4. Accuracy on batch 787/2438  on Training is 68.51205583756345\n",
            "Epoch #4. Accuracy on batch 788/2438  on Training is 68.51235741444867\n",
            "Epoch #4. Accuracy on batch 789/2438  on Training is 68.52056962025317\n",
            "Epoch #4. Accuracy on batch 790/2438  on Training is 68.50505689001264\n",
            "Epoch #4. Accuracy on batch 791/2438  on Training is 68.5290404040404\n",
            "Epoch #4. Accuracy on batch 792/2438  on Training is 68.54114123581337\n",
            "Epoch #4. Accuracy on batch 793/2438  on Training is 68.5492758186398\n",
            "Epoch #4. Accuracy on batch 794/2438  on Training is 68.55345911949685\n",
            "Epoch #4. Accuracy on batch 795/2438  on Training is 68.55370603015075\n",
            "Epoch #4. Accuracy on batch 796/2438  on Training is 68.55395232120452\n",
            "Epoch #4. Accuracy on batch 797/2438  on Training is 68.55811403508773\n",
            "Epoch #4. Accuracy on batch 798/2438  on Training is 68.55053191489361\n",
            "Epoch #4. Accuracy on batch 799/2438  on Training is 68.55859375\n",
            "Batch Id 800/2438 is having training loss of 1.1814380884170532\n",
            "1.2820082902908325\n",
            "Epoch #4. Accuracy on batch 800/2438  on Training is 68.55493133583022\n",
            "Epoch #4. Accuracy on batch 801/2438  on Training is 68.53179551122194\n",
            "Epoch #4. Accuracy on batch 802/2438  on Training is 68.53595890410959\n",
            "Epoch #4. Accuracy on batch 803/2438  on Training is 68.5362251243781\n",
            "Epoch #4. Accuracy on batch 804/2438  on Training is 68.53260869565217\n",
            "Epoch #4. Accuracy on batch 805/2438  on Training is 68.53287841191067\n",
            "Epoch #4. Accuracy on batch 806/2438  on Training is 68.54476456009914\n",
            "Epoch #4. Accuracy on batch 807/2438  on Training is 68.53728341584159\n",
            "Epoch #4. Accuracy on batch 808/2438  on Training is 68.53368355995056\n",
            "Epoch #4. Accuracy on batch 809/2438  on Training is 68.5300925925926\n",
            "Epoch #4. Accuracy on batch 810/2438  on Training is 68.53421701602959\n",
            "Epoch #4. Accuracy on batch 811/2438  on Training is 68.51908866995073\n",
            "Epoch #4. Accuracy on batch 812/2438  on Training is 68.5309040590406\n",
            "Epoch #4. Accuracy on batch 813/2438  on Training is 68.51965601965603\n",
            "Epoch #4. Accuracy on batch 814/2438  on Training is 68.52377300613497\n",
            "Epoch #4. Accuracy on batch 815/2438  on Training is 68.52022058823529\n",
            "Epoch #4. Accuracy on batch 816/2438  on Training is 68.5281517747858\n",
            "Epoch #4. Accuracy on batch 817/2438  on Training is 68.51314180929096\n",
            "Epoch #4. Accuracy on batch 818/2438  on Training is 68.51724664224665\n",
            "Epoch #4. Accuracy on batch 819/2438  on Training is 68.5251524390244\n",
            "Batch Id 820/2438 is having training loss of 1.1829065084457397\n",
            "1.2110135555267334\n",
            "Epoch #4. Accuracy on batch 820/2438  on Training is 68.52923264311815\n",
            "Epoch #4. Accuracy on batch 821/2438  on Training is 68.51809610705597\n",
            "Epoch #4. Accuracy on batch 822/2438  on Training is 68.49559538274605\n",
            "Epoch #4. Accuracy on batch 823/2438  on Training is 68.49590412621359\n",
            "Epoch #4. Accuracy on batch 824/2438  on Training is 68.49621212121212\n",
            "Epoch #4. Accuracy on batch 825/2438  on Training is 68.50030266343826\n",
            "Epoch #4. Accuracy on batch 826/2438  on Training is 68.5119407496977\n",
            "Epoch #4. Accuracy on batch 827/2438  on Training is 68.47826086956522\n",
            "Epoch #4. Accuracy on batch 828/2438  on Training is 68.47104945717732\n",
            "Epoch #4. Accuracy on batch 829/2438  on Training is 68.46385542168674\n",
            "Epoch #4. Accuracy on batch 830/2438  on Training is 68.47924187725631\n",
            "Epoch #4. Accuracy on batch 831/2438  on Training is 68.47581129807692\n",
            "Epoch #4. Accuracy on batch 832/2438  on Training is 68.4873949579832\n",
            "Epoch #4. Accuracy on batch 833/2438  on Training is 68.49895083932854\n",
            "Epoch #4. Accuracy on batch 834/2438  on Training is 68.4880239520958\n",
            "Epoch #4. Accuracy on batch 835/2438  on Training is 68.48833732057416\n",
            "Epoch #4. Accuracy on batch 836/2438  on Training is 68.46624850657109\n",
            "Epoch #4. Accuracy on batch 837/2438  on Training is 68.47031622911695\n",
            "Epoch #4. Accuracy on batch 838/2438  on Training is 68.47064958283671\n",
            "Epoch #4. Accuracy on batch 839/2438  on Training is 68.47098214285714\n",
            "Batch Id 840/2438 is having training loss of 1.1847461462020874\n",
            "1.1703110933303833\n",
            "Epoch #4. Accuracy on batch 840/2438  on Training is 68.47502972651606\n",
            "Epoch #4. Accuracy on batch 841/2438  on Training is 68.47535629453682\n",
            "Epoch #4. Accuracy on batch 842/2438  on Training is 68.47938908659549\n",
            "Epoch #4. Accuracy on batch 843/2438  on Training is 68.46119668246446\n",
            "Epoch #4. Accuracy on batch 844/2438  on Training is 68.47263313609467\n",
            "Epoch #4. Accuracy on batch 845/2438  on Training is 68.46926713947991\n",
            "Epoch #4. Accuracy on batch 846/2438  on Training is 68.45115112160566\n",
            "Epoch #4. Accuracy on batch 847/2438  on Training is 68.44044811320755\n",
            "Epoch #4. Accuracy on batch 848/2438  on Training is 68.42240871613663\n",
            "Epoch #4. Accuracy on batch 849/2438  on Training is 68.41911764705883\n",
            "Epoch #4. Accuracy on batch 850/2438  on Training is 68.423178613396\n",
            "Epoch #4. Accuracy on batch 851/2438  on Training is 68.41255868544602\n",
            "Epoch #4. Accuracy on batch 852/2438  on Training is 68.41661781946073\n",
            "Epoch #4. Accuracy on batch 853/2438  on Training is 68.41700819672131\n",
            "Epoch #4. Accuracy on batch 854/2438  on Training is 68.42470760233918\n",
            "Epoch #4. Accuracy on batch 855/2438  on Training is 68.42508761682242\n",
            "Epoch #4. Accuracy on batch 856/2438  on Training is 68.42546674445741\n",
            "Epoch #4. Accuracy on batch 857/2438  on Training is 68.43312937062937\n",
            "Epoch #4. Accuracy on batch 858/2438  on Training is 68.44077415599534\n",
            "Epoch #4. Accuracy on batch 859/2438  on Training is 68.43023255813954\n",
            "Batch Id 860/2438 is having training loss of 1.1860761642456055\n",
            "1.4222873449325562\n",
            "Epoch #4. Accuracy on batch 860/2438  on Training is 68.41608594657374\n",
            "Epoch #4. Accuracy on batch 861/2438  on Training is 68.40559744779583\n",
            "Epoch #4. Accuracy on batch 862/2438  on Training is 68.41685979142527\n",
            "Epoch #4. Accuracy on batch 863/2438  on Training is 68.41724537037037\n",
            "Epoch #4. Accuracy on batch 864/2438  on Training is 68.40317919075144\n",
            "Epoch #4. Accuracy on batch 865/2438  on Training is 68.39275404157044\n",
            "Epoch #4. Accuracy on batch 866/2438  on Training is 68.39677047289504\n",
            "Epoch #4. Accuracy on batch 867/2438  on Training is 68.40437788018433\n",
            "Epoch #4. Accuracy on batch 868/2438  on Training is 68.4047756041427\n",
            "Epoch #4. Accuracy on batch 869/2438  on Training is 68.40876436781609\n",
            "Epoch #4. Accuracy on batch 870/2438  on Training is 68.40556831228473\n",
            "Epoch #4. Accuracy on batch 871/2438  on Training is 68.39879587155963\n",
            "Epoch #4. Accuracy on batch 872/2438  on Training is 68.39561855670104\n",
            "Epoch #4. Accuracy on batch 873/2438  on Training is 68.4174771167048\n",
            "Epoch #4. Accuracy on batch 874/2438  on Training is 68.425\n",
            "Epoch #4. Accuracy on batch 875/2438  on Training is 68.4146689497717\n",
            "Epoch #4. Accuracy on batch 876/2438  on Training is 68.38654503990878\n",
            "Epoch #4. Accuracy on batch 877/2438  on Training is 68.3762813211845\n",
            "Epoch #4. Accuracy on batch 878/2438  on Training is 68.36959613196815\n",
            "Epoch #4. Accuracy on batch 879/2438  on Training is 68.3877840909091\n",
            "Batch Id 880/2438 is having training loss of 1.1859325170516968\n",
            "1.481119990348816\n",
            "Epoch #4. Accuracy on batch 880/2438  on Training is 68.38819523269012\n",
            "Epoch #4. Accuracy on batch 881/2438  on Training is 68.38151927437642\n",
            "Epoch #4. Accuracy on batch 882/2438  on Training is 68.39609286523216\n",
            "Epoch #4. Accuracy on batch 883/2438  on Training is 68.4106334841629\n",
            "Epoch #4. Accuracy on batch 884/2438  on Training is 68.40748587570621\n",
            "Epoch #4. Accuracy on batch 885/2438  on Training is 68.41492663656885\n",
            "Epoch #4. Accuracy on batch 886/2438  on Training is 68.40473506200676\n",
            "Epoch #4. Accuracy on batch 887/2438  on Training is 68.41568130630631\n",
            "Epoch #4. Accuracy on batch 888/2438  on Training is 68.41957255343083\n",
            "Epoch #4. Accuracy on batch 889/2438  on Training is 68.41643258426966\n",
            "Epoch #4. Accuracy on batch 890/2438  on Training is 68.39927048260381\n",
            "Epoch #4. Accuracy on batch 891/2438  on Training is 68.39966367713005\n",
            "Epoch #4. Accuracy on batch 892/2438  on Training is 68.39655655095184\n",
            "Epoch #4. Accuracy on batch 893/2438  on Training is 68.39345637583892\n",
            "Epoch #4. Accuracy on batch 894/2438  on Training is 68.41480446927375\n",
            "Epoch #4. Accuracy on batch 895/2438  on Training is 68.408203125\n",
            "Epoch #4. Accuracy on batch 896/2438  on Training is 68.40510033444816\n",
            "Epoch #4. Accuracy on batch 897/2438  on Training is 68.40896436525613\n",
            "Epoch #4. Accuracy on batch 898/2438  on Training is 68.41281979977754\n",
            "Epoch #4. Accuracy on batch 899/2438  on Training is 68.41319444444444\n",
            "Batch Id 900/2438 is having training loss of 1.1842615604400635\n",
            "1.1587793827056885\n",
            "Epoch #4. Accuracy on batch 900/2438  on Training is 68.40663152053274\n",
            "Epoch #4. Accuracy on batch 901/2438  on Training is 68.40354767184036\n",
            "Epoch #4. Accuracy on batch 902/2438  on Training is 68.42123477297896\n",
            "Epoch #4. Accuracy on batch 903/2438  on Training is 68.42505530973452\n",
            "Epoch #4. Accuracy on batch 904/2438  on Training is 68.41160220994475\n",
            "Epoch #4. Accuracy on batch 905/2438  on Training is 68.40507726269315\n",
            "Epoch #4. Accuracy on batch 906/2438  on Training is 68.41234840132304\n",
            "Epoch #4. Accuracy on batch 907/2438  on Training is 68.41272026431719\n",
            "Epoch #4. Accuracy on batch 908/2438  on Training is 68.41652915291529\n",
            "Epoch #4. Accuracy on batch 909/2438  on Training is 68.4065934065934\n",
            "Epoch #4. Accuracy on batch 910/2438  on Training is 68.41040065861691\n",
            "Epoch #4. Accuracy on batch 911/2438  on Training is 68.4141995614035\n",
            "Epoch #4. Accuracy on batch 912/2438  on Training is 68.40772179627601\n",
            "Epoch #4. Accuracy on batch 913/2438  on Training is 68.4046772428884\n",
            "Epoch #4. Accuracy on batch 914/2438  on Training is 68.4084699453552\n",
            "Epoch #4. Accuracy on batch 915/2438  on Training is 68.40201965065502\n",
            "Epoch #4. Accuracy on batch 916/2438  on Training is 68.40921483097055\n",
            "Epoch #4. Accuracy on batch 917/2438  on Training is 68.41299019607843\n",
            "Epoch #4. Accuracy on batch 918/2438  on Training is 68.41675734494015\n",
            "Epoch #4. Accuracy on batch 919/2438  on Training is 68.43070652173913\n",
            "Batch Id 920/2438 is having training loss of 1.1832081079483032\n",
            "1.0855435132980347\n",
            "Epoch #4. Accuracy on batch 920/2438  on Training is 68.43444625407166\n",
            "Epoch #4. Accuracy on batch 921/2438  on Training is 68.43139913232105\n",
            "Epoch #4. Accuracy on batch 922/2438  on Training is 68.42835861321777\n",
            "Epoch #4. Accuracy on batch 923/2438  on Training is 68.41856060606061\n",
            "Epoch #4. Accuracy on batch 924/2438  on Training is 68.39864864864865\n",
            "Epoch #4. Accuracy on batch 925/2438  on Training is 68.39227861771059\n",
            "Epoch #4. Accuracy on batch 926/2438  on Training is 68.38929341963322\n",
            "Epoch #4. Accuracy on batch 927/2438  on Training is 68.37621228448276\n",
            "Epoch #4. Accuracy on batch 928/2438  on Training is 68.37325080731969\n",
            "Epoch #4. Accuracy on batch 929/2438  on Training is 68.35685483870968\n",
            "Epoch #4. Accuracy on batch 930/2438  on Training is 68.34720730397422\n",
            "Epoch #4. Accuracy on batch 931/2438  on Training is 68.35099248927038\n",
            "Epoch #4. Accuracy on batch 932/2438  on Training is 68.33467309753483\n",
            "Epoch #4. Accuracy on batch 933/2438  on Training is 68.33511777301928\n",
            "Epoch #4. Accuracy on batch 934/2438  on Training is 68.3288770053476\n",
            "Epoch #4. Accuracy on batch 935/2438  on Training is 68.32932692307692\n",
            "Epoch #4. Accuracy on batch 936/2438  on Training is 68.32977588046958\n",
            "Epoch #4. Accuracy on batch 937/2438  on Training is 68.33688699360341\n",
            "Epoch #4. Accuracy on batch 938/2438  on Training is 68.33732694355697\n",
            "Epoch #4. Accuracy on batch 939/2438  on Training is 68.34441489361703\n",
            "Batch Id 940/2438 is having training loss of 1.186645746231079\n",
            "1.226017713546753\n",
            "Epoch #4. Accuracy on batch 940/2438  on Training is 68.34484590860787\n",
            "Epoch #4. Accuracy on batch 941/2438  on Training is 68.34195859872611\n",
            "Epoch #4. Accuracy on batch 942/2438  on Training is 68.33907741251326\n",
            "Epoch #4. Accuracy on batch 943/2438  on Training is 68.33289194915254\n",
            "Epoch #4. Accuracy on batch 944/2438  on Training is 68.31349206349206\n",
            "Epoch #4. Accuracy on batch 945/2438  on Training is 68.32386363636364\n",
            "Epoch #4. Accuracy on batch 946/2438  on Training is 68.33421330517423\n",
            "Epoch #4. Accuracy on batch 947/2438  on Training is 68.34124472573839\n",
            "Epoch #4. Accuracy on batch 948/2438  on Training is 68.33838250790306\n",
            "Epoch #4. Accuracy on batch 949/2438  on Training is 68.33223684210526\n",
            "Epoch #4. Accuracy on batch 950/2438  on Training is 68.33267613038906\n",
            "Epoch #4. Accuracy on batch 951/2438  on Training is 68.32326680672269\n",
            "Epoch #4. Accuracy on batch 952/2438  on Training is 68.32699370409235\n",
            "Epoch #4. Accuracy on batch 953/2438  on Training is 68.33398846960168\n",
            "Epoch #4. Accuracy on batch 954/2438  on Training is 68.33115183246073\n",
            "Epoch #4. Accuracy on batch 955/2438  on Training is 68.3283211297071\n",
            "Epoch #4. Accuracy on batch 956/2438  on Training is 68.33529258098224\n",
            "Epoch #4. Accuracy on batch 957/2438  on Training is 68.3357254697286\n",
            "Epoch #4. Accuracy on batch 958/2438  on Training is 68.3296402502607\n",
            "Epoch #4. Accuracy on batch 959/2438  on Training is 68.330078125\n",
            "Batch Id 960/2438 is having training loss of 1.1861851215362549\n",
            "0.7999727725982666\n",
            "Epoch #4. Accuracy on batch 960/2438  on Training is 68.34027055150885\n",
            "Epoch #4. Accuracy on batch 961/2438  on Training is 68.34069646569647\n",
            "Epoch #4. Accuracy on batch 962/2438  on Training is 68.3443665628245\n",
            "Epoch #4. Accuracy on batch 963/2438  on Training is 68.34802904564316\n",
            "Epoch #4. Accuracy on batch 964/2438  on Training is 68.35492227979275\n",
            "Epoch #4. Accuracy on batch 965/2438  on Training is 68.35209627329192\n",
            "Epoch #4. Accuracy on batch 966/2438  on Training is 68.34927611168563\n",
            "Epoch #4. Accuracy on batch 967/2438  on Training is 68.34969008264463\n",
            "Epoch #4. Accuracy on batch 968/2438  on Training is 68.3533281733746\n",
            "Epoch #4. Accuracy on batch 969/2438  on Training is 68.34407216494846\n",
            "Epoch #4. Accuracy on batch 970/2438  on Training is 68.35092687950566\n",
            "Epoch #4. Accuracy on batch 971/2438  on Training is 68.35133744855968\n",
            "Epoch #4. Accuracy on batch 972/2438  on Training is 68.37101747173689\n",
            "Epoch #4. Accuracy on batch 973/2438  on Training is 68.36498973305955\n",
            "Epoch #4. Accuracy on batch 974/2438  on Training is 68.36858974358974\n",
            "Epoch #4. Accuracy on batch 975/2438  on Training is 68.36898053278688\n",
            "Epoch #4. Accuracy on batch 976/2438  on Training is 68.35017911975434\n",
            "Epoch #4. Accuracy on batch 977/2438  on Training is 68.35058793456032\n",
            "Epoch #4. Accuracy on batch 978/2438  on Training is 68.3605720122574\n",
            "Epoch #4. Accuracy on batch 979/2438  on Training is 68.3577806122449\n",
            "Batch Id 980/2438 is having training loss of 1.185158610343933\n",
            "0.7950883507728577\n",
            "Epoch #4. Accuracy on batch 980/2438  on Training is 68.36773700305811\n",
            "Epoch #4. Accuracy on batch 981/2438  on Training is 68.3617617107943\n",
            "Epoch #4. Accuracy on batch 982/2438  on Training is 68.36851475076297\n",
            "Epoch #4. Accuracy on batch 983/2438  on Training is 68.36255081300813\n",
            "Epoch #4. Accuracy on batch 984/2438  on Training is 68.36294416243655\n",
            "Epoch #4. Accuracy on batch 985/2438  on Training is 68.35699797160244\n",
            "Epoch #4. Accuracy on batch 986/2438  on Training is 68.34156534954407\n",
            "Epoch #4. Accuracy on batch 987/2438  on Training is 68.33881578947368\n",
            "Epoch #4. Accuracy on batch 988/2438  on Training is 68.33291203235592\n",
            "Epoch #4. Accuracy on batch 989/2438  on Training is 68.33333333333333\n",
            "Epoch #4. Accuracy on batch 990/2438  on Training is 68.32744702320888\n",
            "Epoch #4. Accuracy on batch 991/2438  on Training is 68.32472278225806\n",
            "Epoch #4. Accuracy on batch 992/2438  on Training is 68.32515105740181\n",
            "Epoch #4. Accuracy on batch 993/2438  on Training is 68.32557847082495\n",
            "Epoch #4. Accuracy on batch 994/2438  on Training is 68.32600502512562\n",
            "Epoch #4. Accuracy on batch 995/2438  on Training is 68.33584337349397\n",
            "Epoch #4. Accuracy on batch 996/2438  on Training is 68.3049147442327\n",
            "Epoch #4. Accuracy on batch 997/2438  on Training is 68.31162324649299\n",
            "Epoch #4. Accuracy on batch 998/2438  on Training is 68.3151901901902\n",
            "Epoch #4. Accuracy on batch 999/2438  on Training is 68.303125\n",
            "Batch Id 1000/2438 is having training loss of 1.1874983310699463\n",
            "0.920336902141571\n",
            "Epoch #4. Accuracy on batch 1000/2438  on Training is 68.31918081918081\n",
            "Epoch #4. Accuracy on batch 1001/2438  on Training is 68.30401696606786\n",
            "Epoch #4. Accuracy on batch 1002/2438  on Training is 68.3106929212363\n",
            "Epoch #4. Accuracy on batch 1003/2438  on Training is 68.31424302788845\n",
            "Epoch #4. Accuracy on batch 1004/2438  on Training is 68.30845771144278\n",
            "Epoch #4. Accuracy on batch 1005/2438  on Training is 68.31200298210736\n",
            "Epoch #4. Accuracy on batch 1006/2438  on Training is 68.30623138033764\n",
            "Epoch #4. Accuracy on batch 1007/2438  on Training is 68.29427083333333\n",
            "Epoch #4. Accuracy on batch 1008/2438  on Training is 68.27923686818632\n",
            "Epoch #4. Accuracy on batch 1009/2438  on Training is 68.27660891089108\n",
            "Epoch #4. Accuracy on batch 1010/2438  on Training is 68.26780415430267\n",
            "Epoch #4. Accuracy on batch 1011/2438  on Training is 68.26828063241106\n",
            "Epoch #4. Accuracy on batch 1012/2438  on Training is 68.27801085883515\n",
            "Epoch #4. Accuracy on batch 1013/2438  on Training is 68.27847633136095\n",
            "Epoch #4. Accuracy on batch 1014/2438  on Training is 68.27278325123153\n",
            "Epoch #4. Accuracy on batch 1015/2438  on Training is 68.27632874015748\n",
            "Epoch #4. Accuracy on batch 1016/2438  on Training is 68.27372173058014\n",
            "Epoch #4. Accuracy on batch 1017/2438  on Training is 68.28646856581533\n",
            "Epoch #4. Accuracy on batch 1018/2438  on Training is 68.28692345436703\n",
            "Epoch #4. Accuracy on batch 1019/2438  on Training is 68.29963235294117\n",
            "Batch Id 1020/2438 is having training loss of 1.1870688199996948\n",
            "1.0774645805358887\n",
            "Epoch #4. Accuracy on batch 1020/2438  on Training is 68.30313418217433\n",
            "Epoch #4. Accuracy on batch 1021/2438  on Training is 68.30051369863014\n",
            "Epoch #4. Accuracy on batch 1022/2438  on Training is 68.30706256109482\n",
            "Epoch #4. Accuracy on batch 1023/2438  on Training is 68.292236328125\n",
            "Epoch #4. Accuracy on batch 1024/2438  on Training is 68.29268292682927\n",
            "Epoch #4. Accuracy on batch 1025/2438  on Training is 68.2900828460039\n",
            "Epoch #4. Accuracy on batch 1026/2438  on Training is 68.28140214216164\n",
            "Epoch #4. Accuracy on batch 1027/2438  on Training is 68.27577821011673\n",
            "Epoch #4. Accuracy on batch 1028/2438  on Training is 68.27927599611273\n",
            "Epoch #4. Accuracy on batch 1029/2438  on Training is 68.26759708737865\n",
            "Epoch #4. Accuracy on batch 1030/2438  on Training is 68.26503394762366\n",
            "Epoch #4. Accuracy on batch 1031/2438  on Training is 68.26853197674419\n",
            "Epoch #4. Accuracy on batch 1032/2438  on Training is 68.27807357212004\n",
            "Epoch #4. Accuracy on batch 1033/2438  on Training is 68.2664410058027\n",
            "Epoch #4. Accuracy on batch 1034/2438  on Training is 68.2578502415459\n",
            "Epoch #4. Accuracy on batch 1035/2438  on Training is 68.24927606177606\n",
            "Epoch #4. Accuracy on batch 1036/2438  on Training is 68.2587994214079\n",
            "Epoch #4. Accuracy on batch 1037/2438  on Training is 68.26228323699422\n",
            "Epoch #4. Accuracy on batch 1038/2438  on Training is 68.25673724735323\n",
            "Epoch #4. Accuracy on batch 1039/2438  on Training is 68.24819711538461\n",
            "Batch Id 1040/2438 is having training loss of 1.1885343790054321\n",
            "0.9136290550231934\n",
            "Epoch #4. Accuracy on batch 1040/2438  on Training is 68.25468299711815\n",
            "Epoch #4. Accuracy on batch 1041/2438  on Training is 68.24916026871401\n",
            "Epoch #4. Accuracy on batch 1042/2438  on Training is 68.25862895493768\n",
            "Epoch #4. Accuracy on batch 1043/2438  on Training is 68.26807950191571\n",
            "Epoch #4. Accuracy on batch 1044/2438  on Training is 68.26255980861244\n",
            "Epoch #4. Accuracy on batch 1045/2438  on Training is 68.27198852772466\n",
            "Epoch #4. Accuracy on batch 1046/2438  on Training is 68.28736867239732\n",
            "Epoch #4. Accuracy on batch 1047/2438  on Training is 68.26991889312977\n",
            "Epoch #4. Accuracy on batch 1048/2438  on Training is 68.26441849380362\n",
            "Epoch #4. Accuracy on batch 1049/2438  on Training is 68.2827380952381\n",
            "Epoch #4. Accuracy on batch 1050/2438  on Training is 68.28615604186488\n",
            "Epoch #4. Accuracy on batch 1051/2438  on Training is 68.28362642585552\n",
            "Epoch #4. Accuracy on batch 1052/2438  on Training is 68.28110161443495\n",
            "Epoch #4. Accuracy on batch 1053/2438  on Training is 68.2904411764706\n",
            "Epoch #4. Accuracy on batch 1054/2438  on Training is 68.2968009478673\n",
            "Epoch #4. Accuracy on batch 1055/2438  on Training is 68.29723011363636\n",
            "Epoch #4. Accuracy on batch 1056/2438  on Training is 68.29765846736045\n",
            "Epoch #4. Accuracy on batch 1057/2438  on Training is 68.29808601134215\n",
            "Epoch #4. Accuracy on batch 1058/2438  on Training is 68.28670915958452\n",
            "Epoch #4. Accuracy on batch 1059/2438  on Training is 68.28419811320755\n",
            "Batch Id 1060/2438 is having training loss of 1.1883175373077393\n",
            "1.5364892482757568\n",
            "Epoch #4. Accuracy on batch 1060/2438  on Training is 68.2846371347785\n",
            "Epoch #4. Accuracy on batch 1061/2438  on Training is 68.27330508474576\n",
            "Epoch #4. Accuracy on batch 1062/2438  on Training is 68.2884524929445\n",
            "Epoch #4. Accuracy on batch 1063/2438  on Training is 68.28888627819549\n",
            "Epoch #4. Accuracy on batch 1064/2438  on Training is 68.27758215962442\n",
            "Epoch #4. Accuracy on batch 1065/2438  on Training is 68.27216228893059\n",
            "Epoch #4. Accuracy on batch 1066/2438  on Training is 68.26968134957826\n",
            "Epoch #4. Accuracy on batch 1067/2438  on Training is 68.26427902621722\n",
            "Epoch #4. Accuracy on batch 1068/2438  on Training is 68.26473339569691\n",
            "Epoch #4. Accuracy on batch 1069/2438  on Training is 68.26226635514018\n",
            "Epoch #4. Accuracy on batch 1070/2438  on Training is 68.24813258636787\n",
            "Epoch #4. Accuracy on batch 1071/2438  on Training is 68.24568563432835\n",
            "Epoch #4. Accuracy on batch 1072/2438  on Training is 68.24615563839701\n",
            "Epoch #4. Accuracy on batch 1073/2438  on Training is 68.23498603351955\n",
            "Epoch #4. Accuracy on batch 1074/2438  on Training is 68.23837209302326\n",
            "Epoch #4. Accuracy on batch 1075/2438  on Training is 68.24175185873607\n",
            "Epoch #4. Accuracy on batch 1076/2438  on Training is 68.24512534818942\n",
            "Epoch #4. Accuracy on batch 1077/2438  on Training is 68.23399814471243\n",
            "Epoch #4. Accuracy on batch 1078/2438  on Training is 68.24316496756256\n",
            "Epoch #4. Accuracy on batch 1079/2438  on Training is 68.24652777777777\n",
            "Batch Id 1080/2438 is having training loss of 1.1902382373809814\n",
            "1.0653821229934692\n",
            "Epoch #4. Accuracy on batch 1080/2438  on Training is 68.24988436632748\n",
            "Epoch #4. Accuracy on batch 1081/2438  on Training is 68.25323475046211\n",
            "Epoch #4. Accuracy on batch 1082/2438  on Training is 68.24503693444137\n",
            "Epoch #4. Accuracy on batch 1083/2438  on Training is 68.24838560885608\n",
            "Epoch #4. Accuracy on batch 1084/2438  on Training is 68.23732718894009\n",
            "Epoch #4. Accuracy on batch 1085/2438  on Training is 68.24067679558011\n",
            "Epoch #4. Accuracy on batch 1086/2438  on Training is 68.23827046918123\n",
            "Epoch #4. Accuracy on batch 1087/2438  on Training is 68.24448529411765\n",
            "Epoch #4. Accuracy on batch 1088/2438  on Training is 68.2363406795225\n",
            "Epoch #4. Accuracy on batch 1089/2438  on Training is 68.23967889908256\n",
            "Epoch #4. Accuracy on batch 1090/2438  on Training is 68.24587534372135\n",
            "Epoch #4. Accuracy on batch 1091/2438  on Training is 68.25492216117216\n",
            "Epoch #4. Accuracy on batch 1092/2438  on Training is 68.25251601097895\n",
            "Epoch #4. Accuracy on batch 1093/2438  on Training is 68.24154478976234\n",
            "Epoch #4. Accuracy on batch 1094/2438  on Training is 68.24486301369863\n",
            "Epoch #4. Accuracy on batch 1095/2438  on Training is 68.23391879562044\n",
            "Epoch #4. Accuracy on batch 1096/2438  on Training is 68.23723792160438\n",
            "Epoch #4. Accuracy on batch 1097/2438  on Training is 68.22632058287796\n",
            "Epoch #4. Accuracy on batch 1098/2438  on Training is 68.22679708826206\n",
            "Epoch #4. Accuracy on batch 1099/2438  on Training is 68.2215909090909\n",
            "Batch Id 1100/2438 is having training loss of 1.1904704570770264\n",
            "1.2234114408493042\n",
            "Epoch #4. Accuracy on batch 1100/2438  on Training is 68.21923251589465\n",
            "Epoch #4. Accuracy on batch 1101/2438  on Training is 68.21971415607986\n",
            "Epoch #4. Accuracy on batch 1102/2438  on Training is 68.2116953762466\n",
            "Epoch #4. Accuracy on batch 1103/2438  on Training is 68.20935235507247\n",
            "Epoch #4. Accuracy on batch 1104/2438  on Training is 68.20701357466064\n",
            "Epoch #4. Accuracy on batch 1105/2438  on Training is 68.2131555153707\n",
            "Epoch #4. Accuracy on batch 1106/2438  on Training is 68.2079945799458\n",
            "Epoch #4. Accuracy on batch 1107/2438  on Training is 68.2225857400722\n",
            "Epoch #4. Accuracy on batch 1108/2438  on Training is 68.23715058611361\n",
            "Epoch #4. Accuracy on batch 1109/2438  on Training is 68.24324324324324\n",
            "Epoch #4. Accuracy on batch 1110/2438  on Training is 68.2352610261026\n",
            "Epoch #4. Accuracy on batch 1111/2438  on Training is 68.23291366906474\n",
            "Epoch #4. Accuracy on batch 1112/2438  on Training is 68.23057053009883\n",
            "Epoch #4. Accuracy on batch 1113/2438  on Training is 68.2282315978456\n",
            "Epoch #4. Accuracy on batch 1114/2438  on Training is 68.23150224215247\n",
            "Epoch #4. Accuracy on batch 1115/2438  on Training is 68.23476702508961\n",
            "Epoch #4. Accuracy on batch 1116/2438  on Training is 68.22683527305281\n",
            "Epoch #4. Accuracy on batch 1117/2438  on Training is 68.23568872987478\n",
            "Epoch #4. Accuracy on batch 1118/2438  on Training is 68.23056300268097\n",
            "Epoch #4. Accuracy on batch 1119/2438  on Training is 68.21986607142857\n",
            "Batch Id 1120/2438 is having training loss of 1.1897368431091309\n",
            "0.9431988000869751\n",
            "Epoch #4. Accuracy on batch 1120/2438  on Training is 68.22033898305085\n",
            "Epoch #4. Accuracy on batch 1121/2438  on Training is 68.21245543672015\n",
            "Epoch #4. Accuracy on batch 1122/2438  on Training is 68.20458593054319\n",
            "Epoch #4. Accuracy on batch 1123/2438  on Training is 68.19395017793595\n",
            "Epoch #4. Accuracy on batch 1124/2438  on Training is 68.19722222222222\n",
            "Epoch #4. Accuracy on batch 1125/2438  on Training is 68.20881438721136\n",
            "Epoch #4. Accuracy on batch 1126/2438  on Training is 68.21484028393967\n",
            "Epoch #4. Accuracy on batch 1127/2438  on Training is 68.21254432624113\n",
            "Epoch #4. Accuracy on batch 1128/2438  on Training is 68.20471656333038\n",
            "Epoch #4. Accuracy on batch 1129/2438  on Training is 68.20243362831859\n",
            "Epoch #4. Accuracy on batch 1130/2438  on Training is 68.18910256410257\n",
            "Epoch #4. Accuracy on batch 1131/2438  on Training is 68.19787985865725\n",
            "Epoch #4. Accuracy on batch 1132/2438  on Training is 68.20388349514563\n",
            "Epoch #4. Accuracy on batch 1133/2438  on Training is 68.20987654320987\n",
            "Epoch #4. Accuracy on batch 1134/2438  on Training is 68.21310572687224\n",
            "Epoch #4. Accuracy on batch 1135/2438  on Training is 68.21632922535211\n",
            "Epoch #4. Accuracy on batch 1136/2438  on Training is 68.22229551451187\n",
            "Epoch #4. Accuracy on batch 1137/2438  on Training is 68.21452108963094\n",
            "Epoch #4. Accuracy on batch 1138/2438  on Training is 68.20676031606672\n",
            "Epoch #4. Accuracy on batch 1139/2438  on Training is 68.21271929824562\n",
            "Batch Id 1140/2438 is having training loss of 1.1898249387741089\n",
            "1.2153105735778809\n",
            "Epoch #4. Accuracy on batch 1140/2438  on Training is 68.20771253286591\n",
            "Epoch #4. Accuracy on batch 1141/2438  on Training is 68.19724168126095\n",
            "Epoch #4. Accuracy on batch 1142/2438  on Training is 68.19772528433946\n",
            "Epoch #4. Accuracy on batch 1143/2438  on Training is 68.20367132867133\n",
            "Epoch #4. Accuracy on batch 1144/2438  on Training is 68.20687772925764\n",
            "Epoch #4. Accuracy on batch 1145/2438  on Training is 68.20462478184992\n",
            "Epoch #4. Accuracy on batch 1146/2438  on Training is 68.19692676547515\n",
            "Epoch #4. Accuracy on batch 1147/2438  on Training is 68.20285278745645\n",
            "Epoch #4. Accuracy on batch 1148/2438  on Training is 68.20332898172323\n",
            "Epoch #4. Accuracy on batch 1149/2438  on Training is 68.20108695652173\n",
            "Epoch #4. Accuracy on batch 1150/2438  on Training is 68.20699391833189\n",
            "Epoch #4. Accuracy on batch 1151/2438  on Training is 68.21560329861111\n",
            "Epoch #4. Accuracy on batch 1152/2438  on Training is 68.21606678230702\n",
            "Epoch #4. Accuracy on batch 1153/2438  on Training is 68.21111351819758\n",
            "Epoch #4. Accuracy on batch 1154/2438  on Training is 68.19534632034632\n",
            "Epoch #4. Accuracy on batch 1155/2438  on Training is 68.19852941176471\n",
            "Epoch #4. Accuracy on batch 1156/2438  on Training is 68.20440795159897\n",
            "Epoch #4. Accuracy on batch 1157/2438  on Training is 68.19138601036269\n",
            "Epoch #4. Accuracy on batch 1158/2438  on Training is 68.18108283002589\n",
            "Epoch #4. Accuracy on batch 1159/2438  on Training is 68.17887931034483\n",
            "Batch Id 1160/2438 is having training loss of 1.1900808811187744\n",
            "1.2158383131027222\n",
            "Epoch #4. Accuracy on batch 1160/2438  on Training is 68.17937123169682\n",
            "Epoch #4. Accuracy on batch 1161/2438  on Training is 68.16910499139415\n",
            "Epoch #4. Accuracy on batch 1162/2438  on Training is 68.15348237317284\n",
            "Epoch #4. Accuracy on batch 1163/2438  on Training is 68.16204896907216\n",
            "Epoch #4. Accuracy on batch 1164/2438  on Training is 68.15718884120172\n",
            "Epoch #4. Accuracy on batch 1165/2438  on Training is 68.16037735849056\n",
            "Epoch #4. Accuracy on batch 1166/2438  on Training is 68.17427163667523\n",
            "Epoch #4. Accuracy on batch 1167/2438  on Training is 68.17476455479452\n",
            "Epoch #4. Accuracy on batch 1168/2438  on Training is 68.17792985457656\n",
            "Epoch #4. Accuracy on batch 1169/2438  on Training is 68.18643162393163\n",
            "Epoch #4. Accuracy on batch 1170/2438  on Training is 68.17623825789923\n",
            "Epoch #4. Accuracy on batch 1171/2438  on Training is 68.17672781569966\n",
            "Epoch #4. Accuracy on batch 1172/2438  on Training is 68.17721653878942\n",
            "Epoch #4. Accuracy on batch 1173/2438  on Training is 68.18568994889267\n",
            "Epoch #4. Accuracy on batch 1174/2438  on Training is 68.17553191489361\n",
            "Epoch #4. Accuracy on batch 1175/2438  on Training is 68.18664965986395\n",
            "Epoch #4. Accuracy on batch 1176/2438  on Training is 68.18712829226848\n",
            "Epoch #4. Accuracy on batch 1177/2438  on Training is 68.1849533106961\n",
            "Epoch #4. Accuracy on batch 1178/2438  on Training is 68.18543256997455\n",
            "Epoch #4. Accuracy on batch 1179/2438  on Training is 68.19120762711864\n",
            "Batch Id 1180/2438 is having training loss of 1.189874291419983\n",
            "1.099022626876831\n",
            "Epoch #4. Accuracy on batch 1180/2438  on Training is 68.19432684165962\n",
            "Epoch #4. Accuracy on batch 1181/2438  on Training is 68.20537225042301\n",
            "Epoch #4. Accuracy on batch 1182/2438  on Training is 68.2031910397295\n",
            "Epoch #4. Accuracy on batch 1183/2438  on Training is 68.19573479729729\n",
            "Epoch #4. Accuracy on batch 1184/2438  on Training is 68.19883966244726\n",
            "Epoch #4. Accuracy on batch 1185/2438  on Training is 68.1887647554806\n",
            "Epoch #4. Accuracy on batch 1186/2438  on Training is 68.1866048862679\n",
            "Epoch #4. Accuracy on batch 1187/2438  on Training is 68.18444865319866\n",
            "Epoch #4. Accuracy on batch 1188/2438  on Training is 68.1849243061396\n",
            "Epoch #4. Accuracy on batch 1189/2438  on Training is 68.1906512605042\n",
            "Epoch #4. Accuracy on batch 1190/2438  on Training is 68.191120906801\n",
            "Epoch #4. Accuracy on batch 1191/2438  on Training is 68.18896812080537\n",
            "Epoch #4. Accuracy on batch 1192/2438  on Training is 68.19729673093043\n",
            "Epoch #4. Accuracy on batch 1193/2438  on Training is 68.18205611390285\n",
            "Epoch #4. Accuracy on batch 1194/2438  on Training is 68.17991631799163\n",
            "Epoch #4. Accuracy on batch 1195/2438  on Training is 68.16732859531773\n",
            "Epoch #4. Accuracy on batch 1196/2438  on Training is 68.17042606516291\n",
            "Epoch #4. Accuracy on batch 1197/2438  on Training is 68.16830133555926\n",
            "Epoch #4. Accuracy on batch 1198/2438  on Training is 68.17139282735613\n",
            "Epoch #4. Accuracy on batch 1199/2438  on Training is 68.16927083333333\n",
            "Batch Id 1200/2438 is having training loss of 1.1898155212402344\n",
            "0.9900619387626648\n",
            "Epoch #4. Accuracy on batch 1200/2438  on Training is 68.1697543713572\n",
            "Epoch #4. Accuracy on batch 1201/2438  on Training is 68.16763727121464\n",
            "Epoch #4. Accuracy on batch 1202/2438  on Training is 68.17331670822942\n",
            "Epoch #4. Accuracy on batch 1203/2438  on Training is 68.17639119601328\n",
            "Epoch #4. Accuracy on batch 1204/2438  on Training is 68.17427385892117\n",
            "Epoch #4. Accuracy on batch 1205/2438  on Training is 68.1695688225539\n",
            "Epoch #4. Accuracy on batch 1206/2438  on Training is 68.1648715824358\n",
            "Epoch #4. Accuracy on batch 1207/2438  on Training is 68.1731167218543\n",
            "Epoch #4. Accuracy on batch 1208/2438  on Training is 68.17100909842846\n",
            "Epoch #4. Accuracy on batch 1209/2438  on Training is 68.15857438016529\n",
            "Epoch #4. Accuracy on batch 1210/2438  on Training is 68.15906275805119\n",
            "Epoch #4. Accuracy on batch 1211/2438  on Training is 68.16470709570957\n",
            "Epoch #4. Accuracy on batch 1212/2438  on Training is 68.16776586974443\n",
            "Epoch #4. Accuracy on batch 1213/2438  on Training is 68.16052306425041\n",
            "Epoch #4. Accuracy on batch 1214/2438  on Training is 68.15586419753086\n",
            "Epoch #4. Accuracy on batch 1215/2438  on Training is 68.15378289473684\n",
            "Epoch #4. Accuracy on batch 1216/2438  on Training is 68.15940838126541\n",
            "Epoch #4. Accuracy on batch 1217/2438  on Training is 68.1547619047619\n",
            "Epoch #4. Accuracy on batch 1218/2438  on Training is 68.15781378178835\n",
            "Epoch #4. Accuracy on batch 1219/2438  on Training is 68.15573770491804\n",
            "Batch Id 1220/2438 is having training loss of 1.1906232833862305\n",
            "1.1832635402679443\n",
            "Epoch #4. Accuracy on batch 1220/2438  on Training is 68.15878378378379\n",
            "Epoch #4. Accuracy on batch 1221/2438  on Training is 68.15926759410802\n",
            "Epoch #4. Accuracy on batch 1222/2438  on Training is 68.15975061324612\n",
            "Epoch #4. Accuracy on batch 1223/2438  on Training is 68.16023284313725\n",
            "Epoch #4. Accuracy on batch 1224/2438  on Training is 68.15561224489795\n",
            "Epoch #4. Accuracy on batch 1225/2438  on Training is 68.15354812398043\n",
            "Epoch #4. Accuracy on batch 1226/2438  on Training is 68.13875305623472\n",
            "Epoch #4. Accuracy on batch 1227/2438  on Training is 68.13416123778502\n",
            "Epoch #4. Accuracy on batch 1228/2438  on Training is 68.12449145646868\n",
            "Epoch #4. Accuracy on batch 1229/2438  on Training is 68.1275406504065\n",
            "Epoch #4. Accuracy on batch 1230/2438  on Training is 68.12550771730301\n",
            "Epoch #4. Accuracy on batch 1231/2438  on Training is 68.13108766233766\n",
            "Epoch #4. Accuracy on batch 1232/2438  on Training is 68.13919302514194\n",
            "Epoch #4. Accuracy on batch 1233/2438  on Training is 68.1447528363047\n",
            "Epoch #4. Accuracy on batch 1234/2438  on Training is 68.14271255060729\n",
            "Epoch #4. Accuracy on batch 1235/2438  on Training is 68.13056229773463\n",
            "Epoch #4. Accuracy on batch 1236/2438  on Training is 68.13864187550526\n",
            "Epoch #4. Accuracy on batch 1237/2438  on Training is 68.14165993537965\n",
            "Epoch #4. Accuracy on batch 1238/2438  on Training is 68.12449556093624\n",
            "Epoch #4. Accuracy on batch 1239/2438  on Training is 68.13004032258064\n",
            "Batch Id 1240/2438 is having training loss of 1.1908361911773682\n",
            "0.8613283634185791\n",
            "Epoch #4. Accuracy on batch 1240/2438  on Training is 68.13557614826753\n",
            "Epoch #4. Accuracy on batch 1241/2438  on Training is 68.1436191626409\n",
            "Epoch #4. Accuracy on batch 1242/2438  on Training is 68.14913515687851\n",
            "Epoch #4. Accuracy on batch 1243/2438  on Training is 68.15464228295819\n",
            "Epoch #4. Accuracy on batch 1244/2438  on Training is 68.15010040160642\n",
            "Epoch #4. Accuracy on batch 1245/2438  on Training is 68.16312199036918\n",
            "Epoch #4. Accuracy on batch 1246/2438  on Training is 68.15607457898957\n",
            "Epoch #4. Accuracy on batch 1247/2438  on Training is 68.16155849358974\n",
            "Epoch #4. Accuracy on batch 1248/2438  on Training is 68.1695356285028\n",
            "Epoch #4. Accuracy on batch 1249/2438  on Training is 68.175\n",
            "Epoch #4. Accuracy on batch 1250/2438  on Training is 68.167965627498\n",
            "Epoch #4. Accuracy on batch 1251/2438  on Training is 68.16343849840256\n",
            "Epoch #4. Accuracy on batch 1252/2438  on Training is 68.15642458100558\n",
            "Epoch #4. Accuracy on batch 1253/2438  on Training is 68.16188197767146\n",
            "Epoch #4. Accuracy on batch 1254/2438  on Training is 68.15986055776892\n",
            "Epoch #4. Accuracy on batch 1255/2438  on Training is 68.16033041401273\n",
            "Epoch #4. Accuracy on batch 1256/2438  on Training is 68.15085521081942\n",
            "Epoch #4. Accuracy on batch 1257/2438  on Training is 68.14884737678855\n",
            "Epoch #4. Accuracy on batch 1258/2438  on Training is 68.14187847498015\n",
            "Epoch #4. Accuracy on batch 1259/2438  on Training is 68.13988095238095\n",
            "Batch Id 1260/2438 is having training loss of 1.1909245252609253\n",
            "1.7890828847885132\n",
            "Epoch #4. Accuracy on batch 1260/2438  on Training is 68.12797383029341\n",
            "Epoch #4. Accuracy on batch 1261/2438  on Training is 68.12846671949286\n",
            "Epoch #4. Accuracy on batch 1262/2438  on Training is 68.12648456057008\n",
            "Epoch #4. Accuracy on batch 1263/2438  on Training is 68.11956091772151\n",
            "Epoch #4. Accuracy on batch 1264/2438  on Training is 68.11017786561264\n",
            "Epoch #4. Accuracy on batch 1265/2438  on Training is 68.11562006319116\n",
            "Epoch #4. Accuracy on batch 1266/2438  on Training is 68.11118784530387\n",
            "Epoch #4. Accuracy on batch 1267/2438  on Training is 68.11415615141956\n",
            "Epoch #4. Accuracy on batch 1268/2438  on Training is 68.11465721040189\n",
            "Epoch #4. Accuracy on batch 1269/2438  on Training is 68.12253937007874\n",
            "Epoch #4. Accuracy on batch 1270/2438  on Training is 68.11811565696303\n",
            "Epoch #4. Accuracy on batch 1271/2438  on Training is 68.1284394654088\n",
            "Epoch #4. Accuracy on batch 1272/2438  on Training is 68.12401806755695\n",
            "Epoch #4. Accuracy on batch 1273/2438  on Training is 68.1269623233909\n",
            "Epoch #4. Accuracy on batch 1274/2438  on Training is 68.13725490196079\n",
            "Epoch #4. Accuracy on batch 1275/2438  on Training is 68.14263322884013\n",
            "Epoch #4. Accuracy on batch 1276/2438  on Training is 68.14555599060297\n",
            "Epoch #4. Accuracy on batch 1277/2438  on Training is 68.15336463223787\n",
            "Epoch #4. Accuracy on batch 1278/2438  on Training is 68.15871774824082\n",
            "Epoch #4. Accuracy on batch 1279/2438  on Training is 68.15185546875\n",
            "Batch Id 1280/2438 is having training loss of 1.1896240711212158\n",
            "0.5813649296760559\n",
            "Epoch #4. Accuracy on batch 1280/2438  on Training is 68.1669594067135\n",
            "Epoch #4. Accuracy on batch 1281/2438  on Training is 68.16497659906396\n",
            "Epoch #4. Accuracy on batch 1282/2438  on Training is 68.16543257989088\n",
            "Epoch #4. Accuracy on batch 1283/2438  on Training is 68.17075545171339\n",
            "Epoch #4. Accuracy on batch 1284/2438  on Training is 68.17120622568093\n",
            "Epoch #4. Accuracy on batch 1285/2438  on Training is 68.17651632970451\n",
            "Epoch #4. Accuracy on batch 1286/2438  on Training is 68.1745337995338\n",
            "Epoch #4. Accuracy on batch 1287/2438  on Training is 68.17012810559007\n",
            "Epoch #4. Accuracy on batch 1288/2438  on Training is 68.17300232738557\n",
            "Epoch #4. Accuracy on batch 1289/2438  on Training is 68.15891472868218\n",
            "Epoch #4. Accuracy on batch 1290/2438  on Training is 68.16179318357862\n",
            "Epoch #4. Accuracy on batch 1291/2438  on Training is 68.15982972136223\n",
            "Epoch #4. Accuracy on batch 1292/2438  on Training is 68.16028615622584\n",
            "Epoch #4. Accuracy on batch 1293/2438  on Training is 68.16798686244204\n",
            "Epoch #4. Accuracy on batch 1294/2438  on Training is 68.1780888030888\n",
            "Epoch #4. Accuracy on batch 1295/2438  on Training is 68.18335262345678\n",
            "Epoch #4. Accuracy on batch 1296/2438  on Training is 68.19342713955281\n",
            "Epoch #4. Accuracy on batch 1297/2438  on Training is 68.19867103235747\n",
            "Epoch #4. Accuracy on batch 1298/2438  on Training is 68.20631254811393\n",
            "Epoch #4. Accuracy on batch 1299/2438  on Training is 68.20673076923077\n",
            "Batch Id 1300/2438 is having training loss of 1.1882092952728271\n",
            "0.8678937554359436\n",
            "Epoch #4. Accuracy on batch 1300/2438  on Training is 68.2119523443505\n",
            "Epoch #4. Accuracy on batch 1301/2438  on Training is 68.20996543778801\n",
            "Epoch #4. Accuracy on batch 1302/2438  on Training is 68.21757482732157\n",
            "Epoch #4. Accuracy on batch 1303/2438  on Training is 68.2275690184049\n",
            "Epoch #4. Accuracy on batch 1304/2438  on Training is 68.2375478927203\n",
            "Epoch #4. Accuracy on batch 1305/2438  on Training is 68.2427258805513\n",
            "Epoch #4. Accuracy on batch 1306/2438  on Training is 68.2526778882938\n",
            "Epoch #4. Accuracy on batch 1307/2438  on Training is 68.25305810397553\n",
            "Epoch #4. Accuracy on batch 1308/2438  on Training is 68.25105042016807\n",
            "Epoch #4. Accuracy on batch 1309/2438  on Training is 68.25143129770993\n",
            "Epoch #4. Accuracy on batch 1310/2438  on Training is 68.2518115942029\n",
            "Epoch #4. Accuracy on batch 1311/2438  on Training is 68.2498094512195\n",
            "Epoch #4. Accuracy on batch 1312/2438  on Training is 68.23829017517136\n",
            "Epoch #4. Accuracy on batch 1313/2438  on Training is 68.23154490106545\n",
            "Epoch #4. Accuracy on batch 1314/2438  on Training is 68.22956273764258\n",
            "Epoch #4. Accuracy on batch 1315/2438  on Training is 68.22995820668693\n",
            "Epoch #4. Accuracy on batch 1316/2438  on Training is 68.22560744115414\n",
            "Epoch #4. Accuracy on batch 1317/2438  on Training is 68.22600531107739\n",
            "Epoch #4. Accuracy on batch 1318/2438  on Training is 68.22877179681576\n",
            "Epoch #4. Accuracy on batch 1319/2438  on Training is 68.23626893939394\n",
            "Batch Id 1320/2438 is having training loss of 1.1866323947906494\n",
            "1.1043766736984253\n",
            "Epoch #4. Accuracy on batch 1320/2438  on Training is 68.2366578349735\n",
            "Epoch #4. Accuracy on batch 1321/2438  on Training is 68.22286308623298\n",
            "Epoch #4. Accuracy on batch 1322/2438  on Training is 68.21853741496598\n",
            "Epoch #4. Accuracy on batch 1323/2438  on Training is 68.21893882175226\n",
            "Epoch #4. Accuracy on batch 1324/2438  on Training is 68.20990566037736\n",
            "Epoch #4. Accuracy on batch 1325/2438  on Training is 68.20795625942685\n",
            "Epoch #4. Accuracy on batch 1326/2438  on Training is 68.20600979653354\n",
            "Epoch #4. Accuracy on batch 1327/2438  on Training is 68.20877259036145\n",
            "Epoch #4. Accuracy on batch 1328/2438  on Training is 68.1997742663657\n",
            "Epoch #4. Accuracy on batch 1329/2438  on Training is 68.20253759398496\n",
            "Epoch #4. Accuracy on batch 1330/2438  on Training is 68.19825319308791\n",
            "Epoch #4. Accuracy on batch 1331/2438  on Training is 68.19162912912913\n",
            "Epoch #4. Accuracy on batch 1332/2438  on Training is 68.19439234808702\n",
            "Epoch #4. Accuracy on batch 1333/2438  on Training is 68.19246626686656\n",
            "Epoch #4. Accuracy on batch 1334/2438  on Training is 68.20692883895131\n",
            "Epoch #4. Accuracy on batch 1335/2438  on Training is 68.21669161676647\n",
            "Epoch #4. Accuracy on batch 1336/2438  on Training is 68.21475317875841\n",
            "Epoch #4. Accuracy on batch 1337/2438  on Training is 68.21048206278027\n",
            "Epoch #4. Accuracy on batch 1338/2438  on Training is 68.21088498879762\n",
            "Epoch #4. Accuracy on batch 1339/2438  on Training is 68.21361940298507\n",
            "Batch Id 1340/2438 is having training loss of 1.1871085166931152\n",
            "1.2404417991638184\n",
            "Epoch #4. Accuracy on batch 1340/2438  on Training is 68.22101043997017\n",
            "Epoch #4. Accuracy on batch 1341/2438  on Training is 68.21674739195231\n",
            "Epoch #4. Accuracy on batch 1342/2438  on Training is 68.21016381236039\n",
            "Epoch #4. Accuracy on batch 1343/2438  on Training is 68.21056547619048\n",
            "Epoch #4. Accuracy on batch 1344/2438  on Training is 68.20399628252788\n",
            "Epoch #4. Accuracy on batch 1345/2438  on Training is 68.21136701337295\n",
            "Epoch #4. Accuracy on batch 1346/2438  on Training is 68.20712694877506\n",
            "Epoch #4. Accuracy on batch 1347/2438  on Training is 68.2075296735905\n",
            "Epoch #4. Accuracy on batch 1348/2438  on Training is 68.20329873980727\n",
            "Epoch #4. Accuracy on batch 1349/2438  on Training is 68.21064814814815\n",
            "Epoch #4. Accuracy on batch 1350/2438  on Training is 68.21336047372317\n",
            "Epoch #4. Accuracy on batch 1351/2438  on Training is 68.21144600591715\n",
            "Epoch #4. Accuracy on batch 1352/2438  on Training is 68.21184405025869\n",
            "Epoch #4. Accuracy on batch 1353/2438  on Training is 68.21685745937961\n",
            "Epoch #4. Accuracy on batch 1354/2438  on Training is 68.2149446494465\n",
            "Epoch #4. Accuracy on batch 1355/2438  on Training is 68.21994837758112\n",
            "Epoch #4. Accuracy on batch 1356/2438  on Training is 68.21112748710391\n",
            "Epoch #4. Accuracy on batch 1357/2438  on Training is 68.2161266568483\n",
            "Epoch #4. Accuracy on batch 1358/2438  on Training is 68.2142200147167\n",
            "Epoch #4. Accuracy on batch 1359/2438  on Training is 68.21001838235294\n",
            "Batch Id 1360/2438 is having training loss of 1.1869758367538452\n",
            "1.2962075471878052\n",
            "Epoch #4. Accuracy on batch 1360/2438  on Training is 68.20582292432036\n",
            "Epoch #4. Accuracy on batch 1361/2438  on Training is 68.19704478707783\n",
            "Epoch #4. Accuracy on batch 1362/2438  on Training is 68.1951577402788\n",
            "Epoch #4. Accuracy on batch 1363/2438  on Training is 68.2070197947214\n",
            "Epoch #4. Accuracy on batch 1364/2438  on Training is 68.21199633699634\n",
            "Epoch #4. Accuracy on batch 1365/2438  on Training is 68.21467789165446\n",
            "Epoch #4. Accuracy on batch 1366/2438  on Training is 68.20592538405268\n",
            "Epoch #4. Accuracy on batch 1367/2438  on Training is 68.2108918128655\n",
            "Epoch #4. Accuracy on batch 1368/2438  on Training is 68.22041636230826\n",
            "Epoch #4. Accuracy on batch 1369/2438  on Training is 68.22308394160584\n",
            "Epoch #4. Accuracy on batch 1370/2438  on Training is 68.2234682713348\n",
            "Epoch #4. Accuracy on batch 1371/2438  on Training is 68.22612973760933\n",
            "Epoch #4. Accuracy on batch 1372/2438  on Training is 68.22878732702112\n",
            "Epoch #4. Accuracy on batch 1373/2438  on Training is 68.22461790393012\n",
            "Epoch #4. Accuracy on batch 1374/2438  on Training is 68.22045454545454\n",
            "Epoch #4. Accuracy on batch 1375/2438  on Training is 68.2117550872093\n",
            "Epoch #4. Accuracy on batch 1376/2438  on Training is 68.20760711692084\n",
            "Epoch #4. Accuracy on batch 1377/2438  on Training is 68.20573294629898\n",
            "Epoch #4. Accuracy on batch 1378/2438  on Training is 68.20386149383611\n",
            "Epoch #4. Accuracy on batch 1379/2438  on Training is 68.20199275362319\n",
            "Batch Id 1380/2438 is having training loss of 1.1865966320037842\n",
            "0.8886783123016357\n",
            "Epoch #4. Accuracy on batch 1380/2438  on Training is 68.20238957277336\n",
            "Epoch #4. Accuracy on batch 1381/2438  on Training is 68.20052460202605\n",
            "Epoch #4. Accuracy on batch 1382/2438  on Training is 68.19188358640636\n",
            "Epoch #4. Accuracy on batch 1383/2438  on Training is 68.18777095375722\n",
            "Epoch #4. Accuracy on batch 1384/2438  on Training is 68.19268953068593\n",
            "Epoch #4. Accuracy on batch 1385/2438  on Training is 68.2021103896104\n",
            "Epoch #4. Accuracy on batch 1386/2438  on Training is 68.19349315068493\n",
            "Epoch #4. Accuracy on batch 1387/2438  on Training is 68.19389409221903\n",
            "Epoch #4. Accuracy on batch 1388/2438  on Training is 68.18754499640029\n",
            "Epoch #4. Accuracy on batch 1389/2438  on Training is 68.19019784172662\n",
            "Epoch #4. Accuracy on batch 1390/2438  on Training is 68.17936736161035\n",
            "Epoch #4. Accuracy on batch 1391/2438  on Training is 68.17079741379311\n",
            "Epoch #4. Accuracy on batch 1392/2438  on Training is 68.16896984924622\n",
            "Epoch #4. Accuracy on batch 1393/2438  on Training is 68.17162840746055\n",
            "Epoch #4. Accuracy on batch 1394/2438  on Training is 68.16532258064517\n",
            "Epoch #4. Accuracy on batch 1395/2438  on Training is 68.16126432664757\n",
            "Epoch #4. Accuracy on batch 1396/2438  on Training is 68.16392269148174\n",
            "Epoch #4. Accuracy on batch 1397/2438  on Training is 68.16657725321889\n",
            "Epoch #4. Accuracy on batch 1398/2438  on Training is 68.16029306647606\n",
            "Epoch #4. Accuracy on batch 1399/2438  on Training is 68.15401785714286\n",
            "Batch Id 1400/2438 is having training loss of 1.1874216794967651\n",
            "1.164577841758728\n",
            "Epoch #4. Accuracy on batch 1400/2438  on Training is 68.15890435403283\n",
            "Epoch #4. Accuracy on batch 1401/2438  on Training is 68.15932596291013\n",
            "Epoch #4. Accuracy on batch 1402/2438  on Training is 68.1642017106201\n",
            "Epoch #4. Accuracy on batch 1403/2438  on Training is 68.15349002849003\n",
            "Epoch #4. Accuracy on batch 1404/2438  on Training is 68.14724199288256\n",
            "Epoch #4. Accuracy on batch 1405/2438  on Training is 68.1476706970128\n",
            "Epoch #4. Accuracy on batch 1406/2438  on Training is 68.13921464108032\n",
            "Epoch #4. Accuracy on batch 1407/2438  on Training is 68.13742897727273\n",
            "Epoch #4. Accuracy on batch 1408/2438  on Training is 68.13121007806956\n",
            "Epoch #4. Accuracy on batch 1409/2438  on Training is 68.13386524822695\n",
            "Epoch #4. Accuracy on batch 1410/2438  on Training is 68.1343019135365\n",
            "Epoch #4. Accuracy on batch 1411/2438  on Training is 68.14359065155807\n",
            "Epoch #4. Accuracy on batch 1412/2438  on Training is 68.13738499646144\n",
            "Epoch #4. Accuracy on batch 1413/2438  on Training is 68.14002828854314\n",
            "Epoch #4. Accuracy on batch 1414/2438  on Training is 68.1404593639576\n",
            "Epoch #4. Accuracy on batch 1415/2438  on Training is 68.14088983050847\n",
            "Epoch #4. Accuracy on batch 1416/2438  on Training is 68.13249823570925\n",
            "Epoch #4. Accuracy on batch 1417/2438  on Training is 68.13513751763047\n",
            "Epoch #4. Accuracy on batch 1418/2438  on Training is 68.13557082452431\n",
            "Epoch #4. Accuracy on batch 1419/2438  on Training is 68.14040492957747\n",
            "Batch Id 1420/2438 is having training loss of 1.1878169775009155\n",
            "1.1151026487350464\n",
            "Epoch #4. Accuracy on batch 1420/2438  on Training is 68.13863476425053\n",
            "Epoch #4. Accuracy on batch 1421/2438  on Training is 68.1368670886076\n",
            "Epoch #4. Accuracy on batch 1422/2438  on Training is 68.13070976809557\n",
            "Epoch #4. Accuracy on batch 1423/2438  on Training is 68.13553370786516\n",
            "Epoch #4. Accuracy on batch 1424/2438  on Training is 68.13377192982456\n",
            "Epoch #4. Accuracy on batch 1425/2438  on Training is 68.13858695652173\n",
            "Epoch #4. Accuracy on batch 1426/2438  on Training is 68.13901541695866\n",
            "Epoch #4. Accuracy on batch 1427/2438  on Training is 68.1328781512605\n",
            "Epoch #4. Accuracy on batch 1428/2438  on Training is 68.15080475857243\n",
            "Epoch #4. Accuracy on batch 1429/2438  on Training is 68.16433566433567\n",
            "Epoch #4. Accuracy on batch 1430/2438  on Training is 68.17566387141859\n",
            "Epoch #4. Accuracy on batch 1431/2438  on Training is 68.18042946927375\n",
            "Epoch #4. Accuracy on batch 1432/2438  on Training is 68.17210397766922\n",
            "Epoch #4. Accuracy on batch 1433/2438  on Training is 68.1725069735007\n",
            "Epoch #4. Accuracy on batch 1434/2438  on Training is 68.1794425087108\n",
            "Epoch #4. Accuracy on batch 1435/2438  on Training is 68.18854456824512\n",
            "Epoch #4. Accuracy on batch 1436/2438  on Training is 68.18676061238692\n",
            "Epoch #4. Accuracy on batch 1437/2438  on Training is 68.17845966620305\n",
            "Epoch #4. Accuracy on batch 1438/2438  on Training is 68.17885684503128\n",
            "Epoch #4. Accuracy on batch 1439/2438  on Training is 68.17925347222223\n",
            "Batch Id 1440/2438 is having training loss of 1.1863644123077393\n",
            "0.928493857383728\n",
            "Epoch #4. Accuracy on batch 1440/2438  on Training is 68.1753122831367\n",
            "Epoch #4. Accuracy on batch 1441/2438  on Training is 68.17137656033287\n",
            "Epoch #4. Accuracy on batch 1442/2438  on Training is 68.18044005544006\n",
            "Epoch #4. Accuracy on batch 1443/2438  on Training is 68.18083448753463\n",
            "Epoch #4. Accuracy on batch 1444/2438  on Training is 68.17906574394463\n",
            "Epoch #4. Accuracy on batch 1445/2438  on Training is 68.18162171507608\n",
            "Epoch #4. Accuracy on batch 1446/2438  on Training is 68.18417415342087\n",
            "Epoch #4. Accuracy on batch 1447/2438  on Training is 68.1888812154696\n",
            "Epoch #4. Accuracy on batch 1448/2438  on Training is 68.19142512077295\n",
            "Epoch #4. Accuracy on batch 1449/2438  on Training is 68.20043103448276\n",
            "Epoch #4. Accuracy on batch 1450/2438  on Training is 68.19434872501724\n",
            "Epoch #4. Accuracy on batch 1451/2438  on Training is 68.19257920110194\n",
            "Epoch #4. Accuracy on batch 1452/2438  on Training is 68.18651066758432\n",
            "Epoch #4. Accuracy on batch 1453/2438  on Training is 68.18045048143054\n",
            "Epoch #4. Accuracy on batch 1454/2438  on Training is 68.18298969072166\n",
            "Epoch #4. Accuracy on batch 1455/2438  on Training is 68.18552541208791\n",
            "Epoch #4. Accuracy on batch 1456/2438  on Training is 68.18162319835278\n",
            "Epoch #4. Accuracy on batch 1457/2438  on Training is 68.17986968449931\n",
            "Epoch #4. Accuracy on batch 1458/2438  on Training is 68.18454420836188\n",
            "Epoch #4. Accuracy on batch 1459/2438  on Training is 68.17422945205479\n",
            "Batch Id 1460/2438 is having training loss of 1.1860729455947876\n",
            "1.3547660112380981\n",
            "Epoch #4. Accuracy on batch 1460/2438  on Training is 68.16820670773443\n",
            "Epoch #4. Accuracy on batch 1461/2438  on Training is 68.1750170998632\n",
            "Epoch #4. Accuracy on batch 1462/2438  on Training is 68.17754613807246\n",
            "Epoch #4. Accuracy on batch 1463/2438  on Training is 68.18007172131148\n",
            "Epoch #4. Accuracy on batch 1464/2438  on Training is 68.1740614334471\n",
            "Epoch #4. Accuracy on batch 1465/2438  on Training is 68.17232264665758\n",
            "Epoch #4. Accuracy on batch 1466/2438  on Training is 68.15993524199045\n",
            "Epoch #4. Accuracy on batch 1467/2438  on Training is 68.15820844686648\n",
            "Epoch #4. Accuracy on batch 1468/2438  on Training is 68.1607385976855\n",
            "Epoch #4. Accuracy on batch 1469/2438  on Training is 68.16751700680273\n",
            "Epoch #4. Accuracy on batch 1470/2438  on Training is 68.15304214819851\n",
            "Epoch #4. Accuracy on batch 1471/2438  on Training is 68.16193953804348\n",
            "Epoch #4. Accuracy on batch 1472/2438  on Training is 68.15597420230822\n",
            "Epoch #4. Accuracy on batch 1473/2438  on Training is 68.15425712347354\n",
            "Epoch #4. Accuracy on batch 1474/2438  on Training is 68.16101694915254\n",
            "Epoch #4. Accuracy on batch 1475/2438  on Training is 68.16353319783198\n",
            "Epoch #4. Accuracy on batch 1476/2438  on Training is 68.16393026404874\n",
            "Epoch #4. Accuracy on batch 1477/2438  on Training is 68.15798376184033\n",
            "Epoch #4. Accuracy on batch 1478/2438  on Training is 68.16260987153483\n",
            "Epoch #4. Accuracy on batch 1479/2438  on Training is 68.16300675675676\n",
            "Batch Id 1480/2438 is having training loss of 1.1862668991088867\n",
            "1.5365006923675537\n",
            "Epoch #4. Accuracy on batch 1480/2438  on Training is 68.15496286293045\n",
            "Epoch #4. Accuracy on batch 1481/2438  on Training is 68.15325573549258\n",
            "Epoch #4. Accuracy on batch 1482/2438  on Training is 68.15365812542144\n",
            "Epoch #4. Accuracy on batch 1483/2438  on Training is 68.15616576819407\n",
            "Epoch #4. Accuracy on batch 1484/2438  on Training is 68.15025252525253\n",
            "Epoch #4. Accuracy on batch 1485/2438  on Training is 68.14645020188425\n",
            "Epoch #4. Accuracy on batch 1486/2438  on Training is 68.14895763281775\n",
            "Epoch #4. Accuracy on batch 1487/2438  on Training is 68.15356182795699\n",
            "Epoch #4. Accuracy on batch 1488/2438  on Training is 68.14766621893888\n",
            "Epoch #4. Accuracy on batch 1489/2438  on Training is 68.13758389261746\n",
            "Epoch #4. Accuracy on batch 1490/2438  on Training is 68.1421864520456\n",
            "Epoch #4. Accuracy on batch 1491/2438  on Training is 68.14259383378015\n",
            "Epoch #4. Accuracy on batch 1492/2438  on Training is 68.13881446751508\n",
            "Epoch #4. Accuracy on batch 1493/2438  on Training is 68.13713186077644\n",
            "Epoch #4. Accuracy on batch 1494/2438  on Training is 68.1438127090301\n",
            "Epoch #4. Accuracy on batch 1495/2438  on Training is 68.1442179144385\n",
            "Epoch #4. Accuracy on batch 1496/2438  on Training is 68.13627254509018\n",
            "Epoch #4. Accuracy on batch 1497/2438  on Training is 68.13876835781042\n",
            "Epoch #4. Accuracy on batch 1498/2438  on Training is 68.13709139426284\n",
            "Epoch #4. Accuracy on batch 1499/2438  on Training is 68.13541666666667\n",
            "Batch Id 1500/2438 is having training loss of 1.1871998310089111\n",
            "1.1217516660690308\n",
            "Epoch #4. Accuracy on batch 1500/2438  on Training is 68.13999000666223\n",
            "Epoch #4. Accuracy on batch 1501/2438  on Training is 68.13415446071905\n",
            "Epoch #4. Accuracy on batch 1502/2438  on Training is 68.13040585495675\n",
            "Epoch #4. Accuracy on batch 1503/2438  on Training is 68.12458444148936\n",
            "Epoch #4. Accuracy on batch 1504/2438  on Training is 68.1312292358804\n",
            "Epoch #4. Accuracy on batch 1505/2438  on Training is 68.12333997343957\n",
            "Epoch #4. Accuracy on batch 1506/2438  on Training is 68.12375580623755\n",
            "Epoch #4. Accuracy on batch 1507/2438  on Training is 68.12209880636605\n",
            "Epoch #4. Accuracy on batch 1508/2438  on Training is 68.13079854208085\n",
            "Epoch #4. Accuracy on batch 1509/2438  on Training is 68.13948675496688\n",
            "Epoch #4. Accuracy on batch 1510/2438  on Training is 68.12954996690934\n",
            "Epoch #4. Accuracy on batch 1511/2438  on Training is 68.14029431216932\n",
            "Epoch #4. Accuracy on batch 1512/2438  on Training is 68.1345009914078\n",
            "Epoch #4. Accuracy on batch 1513/2438  on Training is 68.139035667107\n",
            "Epoch #4. Accuracy on batch 1514/2438  on Training is 68.1476897689769\n",
            "Epoch #4. Accuracy on batch 1515/2438  on Training is 68.14602572559367\n",
            "Epoch #4. Accuracy on batch 1516/2438  on Training is 68.15054383651945\n",
            "Epoch #4. Accuracy on batch 1517/2438  on Training is 68.15093873517786\n",
            "Epoch #4. Accuracy on batch 1518/2438  on Training is 68.15339038841343\n",
            "Epoch #4. Accuracy on batch 1519/2438  on Training is 68.16200657894737\n",
            "Batch Id 1520/2438 is having training loss of 1.186486005783081\n",
            "0.9688873887062073\n",
            "Epoch #4. Accuracy on batch 1520/2438  on Training is 68.16239316239316\n",
            "Epoch #4. Accuracy on batch 1521/2438  on Training is 68.17099211563732\n",
            "Epoch #4. Accuracy on batch 1522/2438  on Training is 68.17137229152988\n",
            "Epoch #4. Accuracy on batch 1523/2438  on Training is 68.17380249343832\n",
            "Epoch #4. Accuracy on batch 1524/2438  on Training is 68.18032786885246\n",
            "Epoch #4. Accuracy on batch 1525/2438  on Training is 68.182749017038\n",
            "Epoch #4. Accuracy on batch 1526/2438  on Training is 68.18516699410608\n",
            "Epoch #4. Accuracy on batch 1527/2438  on Training is 68.18553664921465\n",
            "Epoch #4. Accuracy on batch 1528/2438  on Training is 68.17977436232832\n",
            "Epoch #4. Accuracy on batch 1529/2438  on Training is 68.18014705882354\n",
            "Epoch #4. Accuracy on batch 1530/2438  on Training is 68.18051926845199\n",
            "Epoch #4. Accuracy on batch 1531/2438  on Training is 68.18293080939948\n",
            "Epoch #4. Accuracy on batch 1532/2438  on Training is 68.1771852576647\n",
            "Epoch #4. Accuracy on batch 1533/2438  on Training is 68.18163298565841\n",
            "Epoch #4. Accuracy on batch 1534/2438  on Training is 68.18403908794788\n",
            "Epoch #4. Accuracy on batch 1535/2438  on Training is 68.182373046875\n",
            "Epoch #4. Accuracy on batch 1536/2438  on Training is 68.18274235523748\n",
            "Epoch #4. Accuracy on batch 1537/2438  on Training is 68.1892067620286\n",
            "Epoch #4. Accuracy on batch 1538/2438  on Training is 68.17941845354126\n",
            "Epoch #4. Accuracy on batch 1539/2438  on Training is 68.18384740259741\n",
            "Batch Id 1540/2438 is having training loss of 1.1866247653961182\n",
            "1.2925792932510376\n",
            "Epoch #4. Accuracy on batch 1540/2438  on Training is 68.17813108371188\n",
            "Epoch #4. Accuracy on batch 1541/2438  on Training is 68.18052853437095\n",
            "Epoch #4. Accuracy on batch 1542/2438  on Training is 68.18899870382371\n",
            "Epoch #4. Accuracy on batch 1543/2438  on Training is 68.19340997409327\n",
            "Epoch #4. Accuracy on batch 1544/2438  on Training is 68.19377022653721\n",
            "Epoch #4. Accuracy on batch 1545/2438  on Training is 68.1860446313066\n",
            "Epoch #4. Accuracy on batch 1546/2438  on Training is 68.18842921784098\n",
            "Epoch #4. Accuracy on batch 1547/2438  on Training is 68.19282945736434\n",
            "Epoch #4. Accuracy on batch 1548/2438  on Training is 68.18915429309232\n",
            "Epoch #4. Accuracy on batch 1549/2438  on Training is 68.1875\n",
            "Epoch #4. Accuracy on batch 1550/2438  on Training is 68.20196647324308\n",
            "Epoch #4. Accuracy on batch 1551/2438  on Training is 68.21037371134021\n",
            "Epoch #4. Accuracy on batch 1552/2438  on Training is 68.2006600128783\n",
            "Epoch #4. Accuracy on batch 1553/2438  on Training is 68.20704633204633\n",
            "Epoch #4. Accuracy on batch 1554/2438  on Training is 68.20136655948554\n",
            "Epoch #4. Accuracy on batch 1555/2438  on Training is 68.19971079691517\n",
            "Epoch #4. Accuracy on batch 1556/2438  on Training is 68.1960500963391\n",
            "Epoch #4. Accuracy on batch 1557/2438  on Training is 68.196405648267\n",
            "Epoch #4. Accuracy on batch 1558/2438  on Training is 68.20477870429762\n",
            "Epoch #4. Accuracy on batch 1559/2438  on Training is 68.203125\n",
            "Batch Id 1560/2438 is having training loss of 1.185854196548462\n",
            "0.9728460311889648\n",
            "Epoch #4. Accuracy on batch 1560/2438  on Training is 68.20948110185779\n",
            "Epoch #4. Accuracy on batch 1561/2438  on Training is 68.21182778489117\n",
            "Epoch #4. Accuracy on batch 1562/2438  on Training is 68.21417146513116\n",
            "Epoch #4. Accuracy on batch 1563/2438  on Training is 68.2165121483376\n",
            "Epoch #4. Accuracy on batch 1564/2438  on Training is 68.21884984025559\n",
            "Epoch #4. Accuracy on batch 1565/2438  on Training is 68.21120689655173\n",
            "Epoch #4. Accuracy on batch 1566/2438  on Training is 68.2175335035099\n",
            "Epoch #4. Accuracy on batch 1567/2438  on Training is 68.22385204081633\n",
            "Epoch #4. Accuracy on batch 1568/2438  on Training is 68.22617909496495\n",
            "Epoch #4. Accuracy on batch 1569/2438  on Training is 68.22054140127389\n",
            "Epoch #4. Accuracy on batch 1570/2438  on Training is 68.21690006365372\n",
            "Epoch #4. Accuracy on batch 1571/2438  on Training is 68.21525127226464\n",
            "Epoch #4. Accuracy on batch 1572/2438  on Training is 68.2096312778131\n",
            "Epoch #4. Accuracy on batch 1573/2438  on Training is 68.20203303684879\n",
            "Epoch #4. Accuracy on batch 1574/2438  on Training is 68.20436507936508\n",
            "Epoch #4. Accuracy on batch 1575/2438  on Training is 68.20074555837563\n",
            "Epoch #4. Accuracy on batch 1576/2438  on Training is 68.2090202916931\n",
            "Epoch #4. Accuracy on batch 1577/2438  on Training is 68.20540240811154\n",
            "Epoch #4. Accuracy on batch 1578/2438  on Training is 68.20574730842306\n",
            "Epoch #4. Accuracy on batch 1579/2438  on Training is 68.2001582278481\n",
            "Batch Id 1580/2438 is having training loss of 1.186058759689331\n",
            "1.3089996576309204\n",
            "Epoch #4. Accuracy on batch 1580/2438  on Training is 68.19655281467426\n",
            "Epoch #4. Accuracy on batch 1581/2438  on Training is 68.19690265486726\n",
            "Epoch #4. Accuracy on batch 1582/2438  on Training is 68.1972520530638\n",
            "Epoch #4. Accuracy on batch 1583/2438  on Training is 68.20746527777777\n",
            "Epoch #4. Accuracy on batch 1584/2438  on Training is 68.21372239747635\n",
            "Epoch #4. Accuracy on batch 1585/2438  on Training is 68.21603089533417\n",
            "Epoch #4. Accuracy on batch 1586/2438  on Training is 68.22227473219911\n",
            "Epoch #4. Accuracy on batch 1587/2438  on Training is 68.22654282115869\n",
            "Epoch #4. Accuracy on batch 1588/2438  on Training is 68.22883889238514\n",
            "Epoch #4. Accuracy on batch 1589/2438  on Training is 68.22916666666667\n",
            "Epoch #4. Accuracy on batch 1590/2438  on Training is 68.23538654934003\n",
            "Epoch #4. Accuracy on batch 1591/2438  on Training is 68.23178391959799\n",
            "Epoch #4. Accuracy on batch 1592/2438  on Training is 68.23407093534212\n",
            "Epoch #4. Accuracy on batch 1593/2438  on Training is 68.22851317440401\n",
            "Epoch #4. Accuracy on batch 1594/2438  on Training is 68.23667711598746\n",
            "Epoch #4. Accuracy on batch 1595/2438  on Training is 68.23308270676692\n",
            "Epoch #4. Accuracy on batch 1596/2438  on Training is 68.22557921102066\n",
            "Epoch #4. Accuracy on batch 1597/2438  on Training is 68.2337296620776\n",
            "Epoch #4. Accuracy on batch 1598/2438  on Training is 68.24186991869918\n",
            "Epoch #4. Accuracy on batch 1599/2438  on Training is 68.244140625\n",
            "Batch Id 1600/2438 is having training loss of 1.1837007999420166\n",
            "0.7608308792114258\n",
            "Epoch #4. Accuracy on batch 1600/2438  on Training is 68.2503123048095\n",
            "Epoch #4. Accuracy on batch 1601/2438  on Training is 68.24477215980025\n",
            "Epoch #4. Accuracy on batch 1602/2438  on Training is 68.24508733624454\n",
            "Epoch #4. Accuracy on batch 1603/2438  on Training is 68.24540211970074\n",
            "Epoch #4. Accuracy on batch 1604/2438  on Training is 68.24376947040498\n",
            "Epoch #4. Accuracy on batch 1605/2438  on Training is 68.23630136986301\n",
            "Epoch #4. Accuracy on batch 1606/2438  on Training is 68.23856565028002\n",
            "Epoch #4. Accuracy on batch 1607/2438  on Training is 68.24082711442786\n",
            "Epoch #4. Accuracy on batch 1608/2438  on Training is 68.2392013673089\n",
            "Epoch #4. Accuracy on batch 1609/2438  on Training is 68.23951863354037\n",
            "Epoch #4. Accuracy on batch 1610/2438  on Training is 68.23207635009311\n",
            "Epoch #4. Accuracy on batch 1611/2438  on Training is 68.22464330024813\n",
            "Epoch #4. Accuracy on batch 1612/2438  on Training is 68.22109423434594\n",
            "Epoch #4. Accuracy on batch 1613/2438  on Training is 68.22723048327137\n",
            "Epoch #4. Accuracy on batch 1614/2438  on Training is 68.22948916408669\n",
            "Epoch #4. Accuracy on batch 1615/2438  on Training is 68.22014232673267\n",
            "Epoch #4. Accuracy on batch 1616/2438  on Training is 68.22820037105751\n",
            "Epoch #4. Accuracy on batch 1617/2438  on Training is 68.2304542645241\n",
            "Epoch #4. Accuracy on batch 1618/2438  on Training is 68.21726374305126\n",
            "Epoch #4. Accuracy on batch 1619/2438  on Training is 68.22145061728395\n",
            "Batch Id 1620/2438 is having training loss of 1.1842001676559448\n",
            "0.9268518090248108\n",
            "Epoch #4. Accuracy on batch 1620/2438  on Training is 68.22756014805675\n",
            "Epoch #4. Accuracy on batch 1621/2438  on Training is 68.22017570900124\n",
            "Epoch #4. Accuracy on batch 1622/2438  on Training is 68.22242760320394\n",
            "Epoch #4. Accuracy on batch 1623/2438  on Training is 68.22467672413794\n",
            "Epoch #4. Accuracy on batch 1624/2438  on Training is 68.22884615384615\n",
            "Epoch #4. Accuracy on batch 1625/2438  on Training is 68.23301045510455\n",
            "Epoch #4. Accuracy on batch 1626/2438  on Training is 68.23140749846343\n",
            "Epoch #4. Accuracy on batch 1627/2438  on Training is 68.22596744471744\n",
            "Epoch #4. Accuracy on batch 1628/2438  on Training is 68.22820748925722\n",
            "Epoch #4. Accuracy on batch 1629/2438  on Training is 68.2361963190184\n",
            "Epoch #4. Accuracy on batch 1630/2438  on Training is 68.23267933782955\n",
            "Epoch #4. Accuracy on batch 1631/2438  on Training is 68.2406556372549\n",
            "Epoch #4. Accuracy on batch 1632/2438  on Training is 68.23522657685241\n",
            "Epoch #4. Accuracy on batch 1633/2438  on Training is 68.24892900856793\n",
            "Epoch #4. Accuracy on batch 1634/2438  on Training is 68.25688073394495\n",
            "Epoch #4. Accuracy on batch 1635/2438  on Training is 68.25909229828851\n",
            "Epoch #4. Accuracy on batch 1636/2438  on Training is 68.2498472816127\n",
            "Epoch #4. Accuracy on batch 1637/2438  on Training is 68.25396825396825\n",
            "Epoch #4. Accuracy on batch 1638/2438  on Training is 68.24473764490543\n",
            "Epoch #4. Accuracy on batch 1639/2438  on Training is 68.23170731707317\n",
            "Batch Id 1640/2438 is having training loss of 1.1835919618606567\n",
            "1.1091188192367554\n",
            "Epoch #4. Accuracy on batch 1640/2438  on Training is 68.23202315661182\n",
            "Epoch #4. Accuracy on batch 1641/2438  on Training is 68.24185444579781\n",
            "Epoch #4. Accuracy on batch 1642/2438  on Training is 68.23835970785149\n",
            "Epoch #4. Accuracy on batch 1643/2438  on Training is 68.23867092457421\n",
            "Epoch #4. Accuracy on batch 1644/2438  on Training is 68.24088145896657\n",
            "Epoch #4. Accuracy on batch 1645/2438  on Training is 68.23929222357229\n",
            "Epoch #4. Accuracy on batch 1646/2438  on Training is 68.24719186399514\n",
            "Epoch #4. Accuracy on batch 1647/2438  on Training is 68.24560072815534\n",
            "Epoch #4. Accuracy on batch 1648/2438  on Training is 68.24780169799878\n",
            "Epoch #4. Accuracy on batch 1649/2438  on Training is 68.2405303030303\n",
            "Epoch #4. Accuracy on batch 1650/2438  on Training is 68.24841005451242\n",
            "Epoch #4. Accuracy on batch 1651/2438  on Training is 68.23736380145279\n",
            "Epoch #4. Accuracy on batch 1652/2438  on Training is 68.23578342407744\n",
            "Epoch #4. Accuracy on batch 1653/2438  on Training is 68.23987303506651\n",
            "Epoch #4. Accuracy on batch 1654/2438  on Training is 68.23262839879155\n",
            "Epoch #4. Accuracy on batch 1655/2438  on Training is 68.24048913043478\n",
            "Epoch #4. Accuracy on batch 1656/2438  on Training is 68.23702474351238\n",
            "Epoch #4. Accuracy on batch 1657/2438  on Training is 68.23167973462003\n",
            "Epoch #4. Accuracy on batch 1658/2438  on Training is 68.22634116937914\n",
            "Epoch #4. Accuracy on batch 1659/2438  on Training is 68.22853915662651\n",
            "Batch Id 1660/2438 is having training loss of 1.1847574710845947\n",
            "1.5395901203155518\n",
            "Epoch #4. Accuracy on batch 1660/2438  on Training is 68.21944611679712\n",
            "Epoch #4. Accuracy on batch 1661/2438  on Training is 68.21224428399519\n",
            "Epoch #4. Accuracy on batch 1662/2438  on Training is 68.21632591701744\n",
            "Epoch #4. Accuracy on batch 1663/2438  on Training is 68.21852463942308\n",
            "Epoch #4. Accuracy on batch 1664/2438  on Training is 68.21884384384384\n",
            "Epoch #4. Accuracy on batch 1665/2438  on Training is 68.22666566626651\n",
            "Epoch #4. Accuracy on batch 1666/2438  on Training is 68.21573185362928\n",
            "Epoch #4. Accuracy on batch 1667/2438  on Training is 68.21605215827338\n",
            "Epoch #4. Accuracy on batch 1668/2438  on Training is 68.22573397243859\n",
            "Epoch #4. Accuracy on batch 1669/2438  on Training is 68.22417664670658\n",
            "Epoch #4. Accuracy on batch 1670/2438  on Training is 68.21327049670856\n",
            "Epoch #4. Accuracy on batch 1671/2438  on Training is 68.21172248803828\n",
            "Epoch #4. Accuracy on batch 1672/2438  on Training is 68.21578003586372\n",
            "Epoch #4. Accuracy on batch 1673/2438  on Training is 68.2179659498208\n",
            "Epoch #4. Accuracy on batch 1674/2438  on Training is 68.21455223880596\n",
            "Epoch #4. Accuracy on batch 1675/2438  on Training is 68.21487171837708\n",
            "Epoch #4. Accuracy on batch 1676/2438  on Training is 68.21146392367322\n",
            "Epoch #4. Accuracy on batch 1677/2438  on Training is 68.22482121573302\n",
            "Epoch #4. Accuracy on batch 1678/2438  on Training is 68.22885646217986\n",
            "Epoch #4. Accuracy on batch 1679/2438  on Training is 68.22544642857143\n",
            "Batch Id 1680/2438 is having training loss of 1.1850656270980835\n",
            "1.2320950031280518\n",
            "Epoch #4. Accuracy on batch 1680/2438  on Training is 68.22761748958953\n",
            "Epoch #4. Accuracy on batch 1681/2438  on Training is 68.22792806183115\n",
            "Epoch #4. Accuracy on batch 1682/2438  on Training is 68.22452465834819\n",
            "Epoch #4. Accuracy on batch 1683/2438  on Training is 68.21555819477435\n",
            "Epoch #4. Accuracy on batch 1684/2438  on Training is 68.2177299703264\n",
            "Epoch #4. Accuracy on batch 1685/2438  on Training is 68.21804567022538\n",
            "Epoch #4. Accuracy on batch 1686/2438  on Training is 68.21836099585062\n",
            "Epoch #4. Accuracy on batch 1687/2438  on Training is 68.21497334123222\n",
            "Epoch #4. Accuracy on batch 1688/2438  on Training is 68.21158969804618\n",
            "Epoch #4. Accuracy on batch 1689/2438  on Training is 68.20451183431953\n",
            "Epoch #4. Accuracy on batch 1690/2438  on Training is 68.20853045535186\n",
            "Epoch #4. Accuracy on batch 1691/2438  on Training is 68.2033096926714\n",
            "Epoch #4. Accuracy on batch 1692/2438  on Training is 68.20732427643237\n",
            "Epoch #4. Accuracy on batch 1693/2438  on Training is 68.20026564344747\n",
            "Epoch #4. Accuracy on batch 1694/2438  on Training is 68.20243362831859\n",
            "Epoch #4. Accuracy on batch 1695/2438  on Training is 68.20275648584905\n",
            "Epoch #4. Accuracy on batch 1696/2438  on Training is 68.20860341779611\n",
            "Epoch #4. Accuracy on batch 1697/2438  on Training is 68.21444346289752\n",
            "Epoch #4. Accuracy on batch 1698/2438  on Training is 68.2147586815774\n",
            "Epoch #4. Accuracy on batch 1699/2438  on Training is 68.21507352941177\n",
            "Batch Id 1700/2438 is having training loss of 1.1854418516159058\n",
            "1.1114099025726318\n",
            "Epoch #4. Accuracy on batch 1700/2438  on Training is 68.20987654320987\n",
            "Epoch #4. Accuracy on batch 1701/2438  on Training is 68.21937426556991\n",
            "Epoch #4. Accuracy on batch 1702/2438  on Training is 68.22152084556664\n",
            "Epoch #4. Accuracy on batch 1703/2438  on Training is 68.22733274647888\n",
            "Epoch #4. Accuracy on batch 1704/2438  on Training is 68.2258064516129\n",
            "Epoch #4. Accuracy on batch 1705/2438  on Training is 68.22794548651817\n",
            "Epoch #4. Accuracy on batch 1706/2438  on Training is 68.2300820152314\n",
            "Epoch #4. Accuracy on batch 1707/2438  on Training is 68.22306791569086\n",
            "Epoch #4. Accuracy on batch 1708/2438  on Training is 68.23069046225864\n",
            "Epoch #4. Accuracy on batch 1709/2438  on Training is 68.23099415204679\n",
            "Epoch #4. Accuracy on batch 1710/2438  on Training is 68.23495032144945\n",
            "Epoch #4. Accuracy on batch 1711/2438  on Training is 68.2352511682243\n",
            "Epoch #4. Accuracy on batch 1712/2438  on Training is 68.23007880910683\n",
            "Epoch #4. Accuracy on batch 1713/2438  on Training is 68.2303821470245\n",
            "Epoch #4. Accuracy on batch 1714/2438  on Training is 68.22886297376094\n",
            "Epoch #4. Accuracy on batch 1715/2438  on Training is 68.22188228438229\n",
            "Epoch #4. Accuracy on batch 1716/2438  on Training is 68.22036983110075\n",
            "Epoch #4. Accuracy on batch 1717/2438  on Training is 68.21885913853318\n",
            "Epoch #4. Accuracy on batch 1718/2438  on Training is 68.21007853403141\n",
            "Epoch #4. Accuracy on batch 1719/2438  on Training is 68.2140261627907\n",
            "Batch Id 1720/2438 is having training loss of 1.1851297616958618\n",
            "1.0957826375961304\n",
            "Epoch #4. Accuracy on batch 1720/2438  on Training is 68.21615339918652\n",
            "Epoch #4. Accuracy on batch 1721/2438  on Training is 68.21646341463415\n",
            "Epoch #4. Accuracy on batch 1722/2438  on Training is 68.22221416134649\n",
            "Epoch #4. Accuracy on batch 1723/2438  on Training is 68.22252030162413\n",
            "Epoch #4. Accuracy on batch 1724/2438  on Training is 68.22101449275362\n",
            "Epoch #4. Accuracy on batch 1725/2438  on Training is 68.22132097334878\n",
            "Epoch #4. Accuracy on batch 1726/2438  on Training is 68.22886508396063\n",
            "Epoch #4. Accuracy on batch 1727/2438  on Training is 68.23459201388889\n",
            "Epoch #4. Accuracy on batch 1728/2438  on Training is 68.23850491613649\n",
            "Epoch #4. Accuracy on batch 1729/2438  on Training is 68.23518786127168\n",
            "Epoch #4. Accuracy on batch 1730/2438  on Training is 68.23729058347776\n",
            "Epoch #4. Accuracy on batch 1731/2438  on Training is 68.24299942263279\n",
            "Epoch #4. Accuracy on batch 1732/2438  on Training is 68.24689844200807\n",
            "Epoch #4. Accuracy on batch 1733/2438  on Training is 68.2489907727797\n",
            "Epoch #4. Accuracy on batch 1734/2438  on Training is 68.2528818443804\n",
            "Epoch #4. Accuracy on batch 1735/2438  on Training is 68.25496831797236\n",
            "Epoch #4. Accuracy on batch 1736/2438  on Training is 68.25345423143351\n",
            "Epoch #4. Accuracy on batch 1737/2438  on Training is 68.25014384349828\n",
            "Epoch #4. Accuracy on batch 1738/2438  on Training is 68.25043128234617\n",
            "Epoch #4. Accuracy on batch 1739/2438  on Training is 68.25431034482759\n",
            "Batch Id 1740/2438 is having training loss of 1.1841946840286255\n",
            "0.7765001058578491\n",
            "Epoch #4. Accuracy on batch 1740/2438  on Training is 68.25997989661114\n",
            "Epoch #4. Accuracy on batch 1741/2438  on Training is 68.25487944890929\n",
            "Epoch #4. Accuracy on batch 1742/2438  on Training is 68.25337062535857\n",
            "Epoch #4. Accuracy on batch 1743/2438  on Training is 68.25365538990826\n",
            "Epoch #4. Accuracy on batch 1744/2438  on Training is 68.25393982808023\n",
            "Epoch #4. Accuracy on batch 1745/2438  on Training is 68.25422394043528\n",
            "Epoch #4. Accuracy on batch 1746/2438  on Training is 68.25808528906697\n",
            "Epoch #4. Accuracy on batch 1747/2438  on Training is 68.25479118993135\n",
            "Epoch #4. Accuracy on batch 1748/2438  on Training is 68.25686106346484\n",
            "Epoch #4. Accuracy on batch 1749/2438  on Training is 68.26071428571429\n",
            "Epoch #4. Accuracy on batch 1750/2438  on Training is 68.2592090234152\n",
            "Epoch #4. Accuracy on batch 1751/2438  on Training is 68.26305650684931\n",
            "Epoch #4. Accuracy on batch 1752/2438  on Training is 68.25976896748432\n",
            "Epoch #4. Accuracy on batch 1753/2438  on Training is 68.26004846066135\n",
            "Epoch #4. Accuracy on batch 1754/2438  on Training is 68.26210826210826\n",
            "Epoch #4. Accuracy on batch 1755/2438  on Training is 68.26594533029613\n",
            "Epoch #4. Accuracy on batch 1756/2438  on Training is 68.26622083096187\n",
            "Epoch #4. Accuracy on batch 1757/2438  on Training is 68.26294084186576\n",
            "Epoch #4. Accuracy on batch 1758/2438  on Training is 68.26677089255259\n",
            "Epoch #4. Accuracy on batch 1759/2438  on Training is 68.25994318181819\n",
            "Batch Id 1760/2438 is having training loss of 1.1838756799697876\n",
            "1.2328364849090576\n",
            "Epoch #4. Accuracy on batch 1760/2438  on Training is 68.25489778534923\n",
            "Epoch #4. Accuracy on batch 1761/2438  on Training is 68.25872587968217\n",
            "Epoch #4. Accuracy on batch 1762/2438  on Training is 68.26254963131026\n",
            "Epoch #4. Accuracy on batch 1763/2438  on Training is 68.25573979591837\n",
            "Epoch #4. Accuracy on batch 1764/2438  on Training is 68.25070821529745\n",
            "Epoch #4. Accuracy on batch 1765/2438  on Training is 68.25629954699886\n",
            "Epoch #4. Accuracy on batch 1766/2438  on Training is 68.2548104131296\n",
            "Epoch #4. Accuracy on batch 1767/2438  on Training is 68.2497878959276\n",
            "Epoch #4. Accuracy on batch 1768/2438  on Training is 68.25183719615602\n",
            "Epoch #4. Accuracy on batch 1769/2438  on Training is 68.25741525423729\n",
            "Epoch #4. Accuracy on batch 1770/2438  on Training is 68.25945793337098\n",
            "Epoch #4. Accuracy on batch 1771/2438  on Training is 68.26149830699774\n",
            "Epoch #4. Accuracy on batch 1772/2438  on Training is 68.26001128031585\n",
            "Epoch #4. Accuracy on batch 1773/2438  on Training is 68.2532412626832\n",
            "Epoch #4. Accuracy on batch 1774/2438  on Training is 68.25\n",
            "Epoch #4. Accuracy on batch 1775/2438  on Training is 68.24148367117117\n",
            "Epoch #4. Accuracy on batch 1776/2438  on Training is 68.2417698368036\n",
            "Epoch #4. Accuracy on batch 1777/2438  on Training is 68.23502530933634\n",
            "Epoch #4. Accuracy on batch 1778/2438  on Training is 68.23707138842046\n",
            "Epoch #4. Accuracy on batch 1779/2438  on Training is 68.23209269662921\n",
            "Batch Id 1780/2438 is having training loss of 1.1845506429672241\n",
            "1.155972957611084\n",
            "Epoch #4. Accuracy on batch 1780/2438  on Training is 68.23940202133633\n",
            "Epoch #4. Accuracy on batch 1781/2438  on Training is 68.2449494949495\n",
            "Epoch #4. Accuracy on batch 1782/2438  on Training is 68.25399607403253\n",
            "Epoch #4. Accuracy on batch 1783/2438  on Training is 68.25602578475336\n",
            "Epoch #4. Accuracy on batch 1784/2438  on Training is 68.25630252100841\n",
            "Epoch #4. Accuracy on batch 1785/2438  on Training is 68.25657894736842\n",
            "Epoch #4. Accuracy on batch 1786/2438  on Training is 68.25860380526021\n",
            "Epoch #4. Accuracy on batch 1787/2438  on Training is 68.26761744966443\n",
            "Epoch #4. Accuracy on batch 1788/2438  on Training is 68.26089994410285\n",
            "Epoch #4. Accuracy on batch 1789/2438  on Training is 68.26466480446928\n",
            "Epoch #4. Accuracy on batch 1790/2438  on Training is 68.26319095477388\n",
            "Epoch #4. Accuracy on batch 1791/2438  on Training is 68.27043805803571\n",
            "Epoch #4. Accuracy on batch 1792/2438  on Training is 68.26721974344673\n",
            "Epoch #4. Accuracy on batch 1793/2438  on Training is 68.25529542920847\n",
            "Epoch #4. Accuracy on batch 1794/2438  on Training is 68.25557103064067\n",
            "Epoch #4. Accuracy on batch 1795/2438  on Training is 68.2488864142539\n",
            "Epoch #4. Accuracy on batch 1796/2438  on Training is 68.25786032276015\n",
            "Epoch #4. Accuracy on batch 1797/2438  on Training is 68.26161012235818\n",
            "Epoch #4. Accuracy on batch 1798/2438  on Training is 68.26709282934964\n",
            "Epoch #4. Accuracy on batch 1799/2438  on Training is 68.27083333333333\n",
            "Batch Id 1800/2438 is having training loss of 1.1839162111282349\n",
            "1.2492495775222778\n",
            "Epoch #4. Accuracy on batch 1800/2438  on Training is 68.26589394780677\n",
            "Epoch #4. Accuracy on batch 1801/2438  on Training is 68.26616259711432\n",
            "Epoch #4. Accuracy on batch 1802/2438  on Training is 68.2646977260122\n",
            "Epoch #4. Accuracy on batch 1803/2438  on Training is 68.2649667405765\n",
            "Epoch #4. Accuracy on batch 1804/2438  on Training is 68.26004155124653\n",
            "Epoch #4. Accuracy on batch 1805/2438  on Training is 68.249930786268\n",
            "Epoch #4. Accuracy on batch 1806/2438  on Training is 68.25366629773104\n",
            "Epoch #4. Accuracy on batch 1807/2438  on Training is 68.250483960177\n",
            "Epoch #4. Accuracy on batch 1808/2438  on Training is 68.24903261470426\n",
            "Epoch #4. Accuracy on batch 1809/2438  on Training is 68.24930939226519\n",
            "Epoch #4. Accuracy on batch 1810/2438  on Training is 68.25131143014909\n",
            "Epoch #4. Accuracy on batch 1811/2438  on Training is 68.24986203090508\n",
            "Epoch #4. Accuracy on batch 1812/2438  on Training is 68.24669056811913\n",
            "Epoch #4. Accuracy on batch 1813/2438  on Training is 68.24524531422271\n",
            "Epoch #4. Accuracy on batch 1814/2438  on Training is 68.24724517906336\n",
            "Epoch #4. Accuracy on batch 1815/2438  on Training is 68.24752202643172\n",
            "Epoch #4. Accuracy on batch 1816/2438  on Training is 68.2477985690699\n",
            "Epoch #4. Accuracy on batch 1817/2438  on Training is 68.24291804180417\n",
            "Epoch #4. Accuracy on batch 1818/2438  on Training is 68.23804288070369\n",
            "Epoch #4. Accuracy on batch 1819/2438  on Training is 68.23832417582418\n",
            "Batch Id 1820/2438 is having training loss of 1.185179352760315\n",
            "1.3308327198028564\n",
            "Epoch #4. Accuracy on batch 1820/2438  on Training is 68.2386051619989\n",
            "Epoch #4. Accuracy on batch 1821/2438  on Training is 68.23888583973655\n",
            "Epoch #4. Accuracy on batch 1822/2438  on Training is 68.24430883159627\n",
            "Epoch #4. Accuracy on batch 1823/2438  on Training is 68.2445860745614\n",
            "Epoch #4. Accuracy on batch 1824/2438  on Training is 68.25171232876713\n",
            "Epoch #4. Accuracy on batch 1825/2438  on Training is 68.24685104052574\n",
            "Epoch #4. Accuracy on batch 1826/2438  on Training is 68.24199507389163\n",
            "Epoch #4. Accuracy on batch 1827/2438  on Training is 68.24227297592998\n",
            "Epoch #4. Accuracy on batch 1828/2438  on Training is 68.2425505740842\n",
            "Epoch #4. Accuracy on batch 1829/2438  on Training is 68.23941256830601\n",
            "Epoch #4. Accuracy on batch 1830/2438  on Training is 68.23457127252867\n",
            "Epoch #4. Accuracy on batch 1831/2438  on Training is 68.23655840611353\n",
            "Epoch #4. Accuracy on batch 1832/2438  on Training is 68.24365793780687\n",
            "Epoch #4. Accuracy on batch 1833/2438  on Training is 68.23711832061069\n",
            "Epoch #4. Accuracy on batch 1834/2438  on Training is 68.23058583106267\n",
            "Epoch #4. Accuracy on batch 1835/2438  on Training is 68.23257080610021\n",
            "Epoch #4. Accuracy on batch 1836/2438  on Training is 68.23285247686445\n",
            "Epoch #4. Accuracy on batch 1837/2438  on Training is 68.23653427638737\n",
            "Epoch #4. Accuracy on batch 1838/2438  on Training is 68.23341489940185\n",
            "Epoch #4. Accuracy on batch 1839/2438  on Training is 68.2319972826087\n",
            "Batch Id 1840/2438 is having training loss of 1.1855921745300293\n",
            "1.3426684141159058\n",
            "Epoch #4. Accuracy on batch 1840/2438  on Training is 68.22718631178707\n",
            "Epoch #4. Accuracy on batch 1841/2438  on Training is 68.23086319218241\n",
            "Epoch #4. Accuracy on batch 1842/2438  on Training is 68.2311448724905\n",
            "Epoch #4. Accuracy on batch 1843/2438  on Training is 68.22634219088937\n",
            "Epoch #4. Accuracy on batch 1844/2438  on Training is 68.22662601626017\n",
            "Epoch #4. Accuracy on batch 1845/2438  on Training is 68.22183098591549\n",
            "Epoch #4. Accuracy on batch 1846/2438  on Training is 68.22211694639957\n",
            "Epoch #4. Accuracy on batch 1847/2438  on Training is 68.21902056277057\n",
            "Epoch #4. Accuracy on batch 1848/2438  on Training is 68.21254732287723\n",
            "Epoch #4. Accuracy on batch 1849/2438  on Training is 68.20945945945945\n",
            "Epoch #4. Accuracy on batch 1850/2438  on Training is 68.20131010264721\n",
            "Epoch #4. Accuracy on batch 1851/2438  on Training is 68.20329373650108\n",
            "Epoch #4. Accuracy on batch 1852/2438  on Training is 68.20021586616298\n",
            "Epoch #4. Accuracy on batch 1853/2438  on Training is 68.19714131607336\n",
            "Epoch #4. Accuracy on batch 1854/2438  on Training is 68.19743935309972\n",
            "Epoch #4. Accuracy on batch 1855/2438  on Training is 68.20447198275862\n",
            "Epoch #4. Accuracy on batch 1856/2438  on Training is 68.20644857296715\n",
            "Epoch #4. Accuracy on batch 1857/2438  on Training is 68.20842303552206\n",
            "Epoch #4. Accuracy on batch 1858/2438  on Training is 68.20535233996772\n",
            "Epoch #4. Accuracy on batch 1859/2438  on Training is 68.20228494623656\n",
            "Batch Id 1860/2438 is having training loss of 1.1861611604690552\n",
            "0.9980334639549255\n",
            "Epoch #4. Accuracy on batch 1860/2438  on Training is 68.20593766792047\n",
            "Epoch #4. Accuracy on batch 1861/2438  on Training is 68.20119495166487\n",
            "Epoch #4. Accuracy on batch 1862/2438  on Training is 68.19142512077295\n",
            "Epoch #4. Accuracy on batch 1863/2438  on Training is 68.1900482832618\n",
            "Epoch #4. Accuracy on batch 1864/2438  on Training is 68.19034852546918\n",
            "Epoch #4. Accuracy on batch 1865/2438  on Training is 68.19064844587352\n",
            "Epoch #4. Accuracy on batch 1866/2438  on Training is 68.19094804499197\n",
            "Epoch #4. Accuracy on batch 1867/2438  on Training is 68.1895744111349\n",
            "Epoch #4. Accuracy on batch 1868/2438  on Training is 68.18820224719101\n",
            "Epoch #4. Accuracy on batch 1869/2438  on Training is 68.18348930481284\n",
            "Epoch #4. Accuracy on batch 1870/2438  on Training is 68.17377071084981\n",
            "Epoch #4. Accuracy on batch 1871/2438  on Training is 68.17908653846153\n",
            "Epoch #4. Accuracy on batch 1872/2438  on Training is 68.17104911906033\n",
            "Epoch #4. Accuracy on batch 1873/2438  on Training is 68.17802828175027\n",
            "Epoch #4. Accuracy on batch 1874/2438  on Training is 68.17333333333333\n",
            "Epoch #4. Accuracy on batch 1875/2438  on Training is 68.1786380597015\n",
            "Epoch #4. Accuracy on batch 1876/2438  on Training is 68.1806073521577\n",
            "Epoch #4. Accuracy on batch 1877/2438  on Training is 68.17924653887114\n",
            "Epoch #4. Accuracy on batch 1878/2438  on Training is 68.18952900478978\n",
            "Epoch #4. Accuracy on batch 1879/2438  on Training is 68.19315159574468\n",
            "Batch Id 1880/2438 is having training loss of 1.186578392982483\n",
            "1.4662787914276123\n",
            "Epoch #4. Accuracy on batch 1880/2438  on Training is 68.18846358320043\n",
            "Epoch #4. Accuracy on batch 1881/2438  on Training is 68.18378055260361\n",
            "Epoch #4. Accuracy on batch 1882/2438  on Training is 68.18408125331918\n",
            "Epoch #4. Accuracy on batch 1883/2438  on Training is 68.18935774946921\n",
            "Epoch #4. Accuracy on batch 1884/2438  on Training is 68.18633952254642\n",
            "Epoch #4. Accuracy on batch 1885/2438  on Training is 68.18829533404029\n",
            "Epoch #4. Accuracy on batch 1886/2438  on Training is 68.19190514043456\n",
            "Epoch #4. Accuracy on batch 1887/2438  on Training is 68.19716631355932\n",
            "Epoch #4. Accuracy on batch 1888/2438  on Training is 68.19084171519323\n",
            "Epoch #4. Accuracy on batch 1889/2438  on Training is 68.19775132275132\n",
            "Epoch #4. Accuracy on batch 1890/2438  on Training is 68.1963907985193\n",
            "Epoch #4. Accuracy on batch 1891/2438  on Training is 68.18512156448203\n",
            "Epoch #4. Accuracy on batch 1892/2438  on Training is 68.18211833069202\n",
            "Epoch #4. Accuracy on batch 1893/2438  on Training is 68.18406810982049\n",
            "Epoch #4. Accuracy on batch 1894/2438  on Training is 68.17777044854881\n",
            "Epoch #4. Accuracy on batch 1895/2438  on Training is 68.17807225738396\n",
            "Epoch #4. Accuracy on batch 1896/2438  on Training is 68.18166842382709\n",
            "Epoch #4. Accuracy on batch 1897/2438  on Training is 68.17208904109589\n",
            "Epoch #4. Accuracy on batch 1898/2438  on Training is 68.17239336492891\n",
            "Epoch #4. Accuracy on batch 1899/2438  on Training is 68.16940789473684\n",
            "Batch Id 1900/2438 is having training loss of 1.1865620613098145\n",
            "1.123942255973816\n",
            "Epoch #4. Accuracy on batch 1900/2438  on Training is 68.17464492372436\n",
            "Epoch #4. Accuracy on batch 1901/2438  on Training is 68.16673238696109\n",
            "Epoch #4. Accuracy on batch 1902/2438  on Training is 68.16703888596952\n",
            "Epoch #4. Accuracy on batch 1903/2438  on Training is 68.16734506302521\n",
            "Epoch #4. Accuracy on batch 1904/2438  on Training is 68.16929133858268\n",
            "Epoch #4. Accuracy on batch 1905/2438  on Training is 68.1745146904512\n",
            "Epoch #4. Accuracy on batch 1906/2438  on Training is 68.18137126376507\n",
            "Epoch #4. Accuracy on batch 1907/2438  on Training is 68.18003144654088\n",
            "Epoch #4. Accuracy on batch 1908/2438  on Training is 68.18033001571503\n",
            "Epoch #4. Accuracy on batch 1909/2438  on Training is 68.17408376963351\n",
            "Epoch #4. Accuracy on batch 1910/2438  on Training is 68.17274986917845\n",
            "Epoch #4. Accuracy on batch 1911/2438  on Training is 68.1697829497908\n",
            "Epoch #4. Accuracy on batch 1912/2438  on Training is 68.16355201254574\n",
            "Epoch #4. Accuracy on batch 1913/2438  on Training is 68.16875653082549\n",
            "Epoch #4. Accuracy on batch 1914/2438  on Training is 68.16742819843343\n",
            "Epoch #4. Accuracy on batch 1915/2438  on Training is 68.17751826722338\n",
            "Epoch #4. Accuracy on batch 1916/2438  on Training is 68.17944705268648\n",
            "Epoch #4. Accuracy on batch 1917/2438  on Training is 68.18137382690303\n",
            "Epoch #4. Accuracy on batch 1918/2438  on Training is 68.17841323606045\n",
            "Epoch #4. Accuracy on batch 1919/2438  on Training is 68.18033854166667\n",
            "Batch Id 1920/2438 is having training loss of 1.1867332458496094\n",
            "1.0355522632598877\n",
            "Epoch #4. Accuracy on batch 1920/2438  on Training is 68.18226184279021\n",
            "Epoch #4. Accuracy on batch 1921/2438  on Training is 68.18255723204994\n",
            "Epoch #4. Accuracy on batch 1922/2438  on Training is 68.18610244409777\n",
            "Epoch #4. Accuracy on batch 1923/2438  on Training is 68.1831470893971\n",
            "Epoch #4. Accuracy on batch 1924/2438  on Training is 68.18181818181819\n",
            "Epoch #4. Accuracy on batch 1925/2438  on Training is 68.18698078920042\n",
            "Epoch #4. Accuracy on batch 1926/2438  on Training is 68.18727296315517\n",
            "Epoch #4. Accuracy on batch 1927/2438  on Training is 68.19404823651452\n",
            "Epoch #4. Accuracy on batch 1928/2438  on Training is 68.18947641264904\n",
            "Epoch #4. Accuracy on batch 1929/2438  on Training is 68.18814766839378\n",
            "Epoch #4. Accuracy on batch 1930/2438  on Training is 68.18520196789228\n",
            "Epoch #4. Accuracy on batch 1931/2438  on Training is 68.18549430641822\n",
            "Epoch #4. Accuracy on batch 1932/2438  on Training is 68.18416968442835\n",
            "Epoch #4. Accuracy on batch 1933/2438  on Training is 68.18607807652533\n",
            "Epoch #4. Accuracy on batch 1934/2438  on Training is 68.17990956072352\n",
            "Epoch #4. Accuracy on batch 1935/2438  on Training is 68.18181818181819\n",
            "Epoch #4. Accuracy on batch 1936/2438  on Training is 68.19340474961281\n",
            "Epoch #4. Accuracy on batch 1937/2438  on Training is 68.1936919504644\n",
            "Epoch #4. Accuracy on batch 1938/2438  on Training is 68.19559051057246\n",
            "Epoch #4. Accuracy on batch 1939/2438  on Training is 68.19426546391753\n",
            "Batch Id 1940/2438 is having training loss of 1.1855264902114868\n",
            "0.7804653644561768\n",
            "Epoch #4. Accuracy on batch 1940/2438  on Training is 68.19938176197836\n",
            "Epoch #4. Accuracy on batch 1941/2438  on Training is 68.19644696189495\n",
            "Epoch #4. Accuracy on batch 1942/2438  on Training is 68.19994853319609\n",
            "Epoch #4. Accuracy on batch 1943/2438  on Training is 68.19701646090535\n",
            "Epoch #4. Accuracy on batch 1944/2438  on Training is 68.20051413881748\n",
            "Epoch #4. Accuracy on batch 1945/2438  on Training is 68.19919064748201\n",
            "Epoch #4. Accuracy on batch 1946/2438  on Training is 68.19947354904983\n",
            "Epoch #4. Accuracy on batch 1947/2438  on Training is 68.19333932238193\n",
            "Epoch #4. Accuracy on batch 1948/2438  on Training is 68.18560800410467\n",
            "Epoch #4. Accuracy on batch 1949/2438  on Training is 68.19391025641026\n",
            "Epoch #4. Accuracy on batch 1950/2438  on Training is 68.19579702716555\n",
            "Epoch #4. Accuracy on batch 1951/2438  on Training is 68.19928278688525\n",
            "Epoch #4. Accuracy on batch 1952/2438  on Training is 68.19476446492575\n",
            "Epoch #4. Accuracy on batch 1953/2438  on Training is 68.198247185261\n",
            "Epoch #4. Accuracy on batch 1954/2438  on Training is 68.20012787723785\n",
            "Epoch #4. Accuracy on batch 1955/2438  on Training is 68.19561605316973\n",
            "Epoch #4. Accuracy on batch 1956/2438  on Training is 68.19589933571794\n",
            "Epoch #4. Accuracy on batch 1957/2438  on Training is 68.19618232890704\n",
            "Epoch #4. Accuracy on batch 1958/2438  on Training is 68.20125063808065\n",
            "Epoch #4. Accuracy on batch 1959/2438  on Training is 68.2047193877551\n",
            "Batch Id 1960/2438 is having training loss of 1.1852840185165405\n",
            "1.2604938745498657\n",
            "Epoch #4. Accuracy on batch 1960/2438  on Training is 68.20340387557368\n",
            "Epoch #4. Accuracy on batch 1961/2438  on Training is 68.21005351681957\n",
            "Epoch #4. Accuracy on batch 1962/2438  on Training is 68.21351248089658\n",
            "Epoch #4. Accuracy on batch 1963/2438  on Training is 68.21696792260693\n",
            "Epoch #4. Accuracy on batch 1964/2438  on Training is 68.22041984732824\n",
            "Epoch #4. Accuracy on batch 1965/2438  on Training is 68.22704730417091\n",
            "Epoch #4. Accuracy on batch 1966/2438  on Training is 68.22731316725978\n",
            "Epoch #4. Accuracy on batch 1967/2438  on Training is 68.22440294715447\n",
            "Epoch #4. Accuracy on batch 1968/2438  on Training is 68.22466988318943\n",
            "Epoch #4. Accuracy on batch 1969/2438  on Training is 68.22969543147208\n",
            "Epoch #4. Accuracy on batch 1970/2438  on Training is 68.2252029426687\n",
            "Epoch #4. Accuracy on batch 1971/2438  on Training is 68.22071501014199\n",
            "Epoch #4. Accuracy on batch 1972/2438  on Training is 68.22415103902686\n",
            "Epoch #4. Accuracy on batch 1973/2438  on Training is 68.22758358662614\n",
            "Epoch #4. Accuracy on batch 1974/2438  on Training is 68.22151898734177\n",
            "Epoch #4. Accuracy on batch 1975/2438  on Training is 68.22336791497976\n",
            "Epoch #4. Accuracy on batch 1976/2438  on Training is 68.2220536165908\n",
            "Epoch #4. Accuracy on batch 1977/2438  on Training is 68.22548028311425\n",
            "Epoch #4. Accuracy on batch 1978/2438  on Training is 68.2289034866094\n",
            "Epoch #4. Accuracy on batch 1979/2438  on Training is 68.23390151515152\n",
            "Batch Id 1980/2438 is having training loss of 1.1840529441833496\n",
            "1.580934762954712\n",
            "Epoch #4. Accuracy on batch 1980/2438  on Training is 68.23100706713781\n",
            "Epoch #4. Accuracy on batch 1981/2438  on Training is 68.22653884964681\n",
            "Epoch #4. Accuracy on batch 1982/2438  on Training is 68.23468229954614\n",
            "Epoch #4. Accuracy on batch 1983/2438  on Training is 68.23966733870968\n",
            "Epoch #4. Accuracy on batch 1984/2438  on Training is 68.24464735516372\n",
            "Epoch #4. Accuracy on batch 1985/2438  on Training is 68.24804884189325\n",
            "Epoch #4. Accuracy on batch 1986/2438  on Training is 68.25144690488173\n",
            "Epoch #4. Accuracy on batch 1987/2438  on Training is 68.25641348088531\n",
            "Epoch #4. Accuracy on batch 1988/2438  on Training is 68.26137506284564\n",
            "Epoch #4. Accuracy on batch 1989/2438  on Training is 68.2537688442211\n",
            "Epoch #4. Accuracy on batch 1990/2438  on Training is 68.2524485183325\n",
            "Epoch #4. Accuracy on batch 1991/2438  on Training is 68.25112951807229\n",
            "Epoch #4. Accuracy on batch 1992/2438  on Training is 68.25294781736076\n",
            "Epoch #4. Accuracy on batch 1993/2438  on Training is 68.25633149448345\n",
            "Epoch #4. Accuracy on batch 1994/2438  on Training is 68.25971177944862\n",
            "Epoch #4. Accuracy on batch 1995/2438  on Training is 68.25839178356713\n",
            "Epoch #4. Accuracy on batch 1996/2438  on Training is 68.25237856785178\n",
            "Epoch #4. Accuracy on batch 1997/2438  on Training is 68.25106356356356\n",
            "Epoch #4. Accuracy on batch 1998/2438  on Training is 68.25131315657829\n",
            "Epoch #4. Accuracy on batch 1999/2438  on Training is 68.2453125\n",
            "Batch Id 2000/2438 is having training loss of 1.1834778785705566\n",
            "0.7383442521095276\n",
            "Epoch #4. Accuracy on batch 2000/2438  on Training is 68.25493503248376\n",
            "Epoch #4. Accuracy on batch 2001/2438  on Training is 68.26298701298701\n",
            "Epoch #4. Accuracy on batch 2002/2438  on Training is 68.26010983524714\n",
            "Epoch #4. Accuracy on batch 2003/2438  on Training is 68.26191367265469\n",
            "Epoch #4. Accuracy on batch 2004/2438  on Training is 68.26371571072319\n",
            "Epoch #4. Accuracy on batch 2005/2438  on Training is 68.27174725822532\n",
            "Epoch #4. Accuracy on batch 2006/2438  on Training is 68.27509965122073\n",
            "Epoch #4. Accuracy on batch 2007/2438  on Training is 68.2722236055777\n",
            "Epoch #4. Accuracy on batch 2008/2438  on Training is 68.27557242409159\n",
            "Epoch #4. Accuracy on batch 2009/2438  on Training is 68.27425373134328\n",
            "Epoch #4. Accuracy on batch 2010/2438  on Training is 68.27449030333167\n",
            "Epoch #4. Accuracy on batch 2011/2438  on Training is 68.2809393638171\n",
            "Epoch #4. Accuracy on batch 2012/2438  on Training is 68.27961997019374\n",
            "Epoch #4. Accuracy on batch 2013/2438  on Training is 68.28916335650447\n",
            "Epoch #4. Accuracy on batch 2014/2438  on Training is 68.2909429280397\n",
            "Epoch #4. Accuracy on batch 2015/2438  on Training is 68.28497023809524\n",
            "Epoch #4. Accuracy on batch 2016/2438  on Training is 68.27900347050074\n",
            "Epoch #4. Accuracy on batch 2017/2438  on Training is 68.27923686818632\n",
            "Epoch #4. Accuracy on batch 2018/2438  on Training is 68.27482664685488\n",
            "Epoch #4. Accuracy on batch 2019/2438  on Training is 68.27351485148515\n",
            "Batch Id 2020/2438 is having training loss of 1.1826105117797852\n",
            "1.0447866916656494\n",
            "Epoch #4. Accuracy on batch 2020/2438  on Training is 68.27684314695695\n",
            "Epoch #4. Accuracy on batch 2021/2438  on Training is 68.2770771513353\n",
            "Epoch #4. Accuracy on batch 2022/2438  on Training is 68.28348986653485\n",
            "Epoch #4. Accuracy on batch 2023/2438  on Training is 68.28372035573122\n",
            "Epoch #4. Accuracy on batch 2024/2438  on Training is 68.28395061728395\n",
            "Epoch #4. Accuracy on batch 2025/2438  on Training is 68.29035044422507\n",
            "Epoch #4. Accuracy on batch 2026/2438  on Training is 68.2874938332511\n",
            "Epoch #4. Accuracy on batch 2027/2438  on Training is 68.29080374753451\n",
            "Epoch #4. Accuracy on batch 2028/2438  on Training is 68.2925702316412\n",
            "Epoch #4. Accuracy on batch 2029/2438  on Training is 68.29279556650246\n",
            "Epoch #4. Accuracy on batch 2030/2438  on Training is 68.29455933037913\n",
            "Epoch #4. Accuracy on batch 2031/2438  on Training is 68.29170767716535\n",
            "Epoch #4. Accuracy on batch 2032/2438  on Training is 68.29654451549435\n",
            "Epoch #4. Accuracy on batch 2033/2438  on Training is 68.30444936086529\n",
            "Epoch #4. Accuracy on batch 2034/2438  on Training is 68.30466830466831\n",
            "Epoch #4. Accuracy on batch 2035/2438  on Training is 68.30028241650295\n",
            "Epoch #4. Accuracy on batch 2036/2438  on Training is 68.30357142857143\n",
            "Epoch #4. Accuracy on batch 2037/2438  on Training is 68.3037904808636\n",
            "Epoch #4. Accuracy on batch 2038/2438  on Training is 68.31013977439922\n",
            "Epoch #4. Accuracy on batch 2039/2438  on Training is 68.30116421568627\n",
            "Batch Id 2040/2438 is having training loss of 1.181806206703186\n",
            "1.4834147691726685\n",
            "Epoch #4. Accuracy on batch 2040/2438  on Training is 68.30138412542871\n",
            "Epoch #4. Accuracy on batch 2041/2438  on Training is 68.29701273261509\n",
            "Epoch #4. Accuracy on batch 2042/2438  on Training is 68.29876407244248\n",
            "Epoch #4. Accuracy on batch 2043/2438  on Training is 68.30204256360078\n",
            "Epoch #4. Accuracy on batch 2044/2438  on Training is 68.30226161369193\n",
            "Epoch #4. Accuracy on batch 2045/2438  on Training is 68.30248044965786\n",
            "Epoch #4. Accuracy on batch 2046/2438  on Training is 68.30117244748412\n",
            "Epoch #4. Accuracy on batch 2047/2438  on Training is 68.29833984375\n",
            "Epoch #4. Accuracy on batch 2048/2438  on Training is 68.29856027330405\n",
            "Epoch #4. Accuracy on batch 2049/2438  on Training is 68.29268292682927\n",
            "Epoch #4. Accuracy on batch 2050/2438  on Training is 68.29442954656265\n",
            "Epoch #4. Accuracy on batch 2051/2438  on Training is 68.29312865497076\n",
            "Epoch #4. Accuracy on batch 2052/2438  on Training is 68.29030686799805\n",
            "Epoch #4. Accuracy on batch 2053/2438  on Training is 68.29053067185978\n",
            "Epoch #4. Accuracy on batch 2054/2438  on Training is 68.29075425790754\n",
            "Epoch #4. Accuracy on batch 2055/2438  on Training is 68.29401750972762\n",
            "Epoch #4. Accuracy on batch 2056/2438  on Training is 68.29271998055421\n",
            "Epoch #4. Accuracy on batch 2057/2438  on Training is 68.29294217687075\n",
            "Epoch #4. Accuracy on batch 2058/2438  on Training is 68.29923506556581\n",
            "Epoch #4. Accuracy on batch 2059/2438  on Training is 68.30097087378641\n",
            "Batch Id 2060/2438 is having training loss of 1.1820104122161865\n",
            "1.341686487197876\n",
            "Epoch #4. Accuracy on batch 2060/2438  on Training is 68.29815623483746\n",
            "Epoch #4. Accuracy on batch 2061/2438  on Training is 68.29837536372455\n",
            "Epoch #4. Accuracy on batch 2062/2438  on Training is 68.29707949587979\n",
            "Epoch #4. Accuracy on batch 2063/2438  on Training is 68.30335513565892\n",
            "Epoch #4. Accuracy on batch 2064/2438  on Training is 68.30508474576271\n",
            "Epoch #4. Accuracy on batch 2065/2438  on Training is 68.30530009680542\n",
            "Epoch #4. Accuracy on batch 2066/2438  on Training is 68.30702709240445\n",
            "Epoch #4. Accuracy on batch 2067/2438  on Training is 68.30875241779498\n",
            "Epoch #4. Accuracy on batch 2068/2438  on Training is 68.30594490091832\n",
            "Epoch #4. Accuracy on batch 2069/2438  on Training is 68.30012077294685\n",
            "Epoch #4. Accuracy on batch 2070/2438  on Training is 68.30335586673105\n",
            "Epoch #4. Accuracy on batch 2071/2438  on Training is 68.30658783783784\n",
            "Epoch #4. Accuracy on batch 2072/2438  on Training is 68.31132416787266\n",
            "Epoch #4. Accuracy on batch 2073/2438  on Training is 68.3130424300868\n",
            "Epoch #4. Accuracy on batch 2074/2438  on Training is 68.31024096385542\n",
            "Epoch #4. Accuracy on batch 2075/2438  on Training is 68.3104527938343\n",
            "Epoch #4. Accuracy on batch 2076/2438  on Training is 68.30765527202696\n",
            "Epoch #4. Accuracy on batch 2077/2438  on Training is 68.30636429258902\n",
            "Epoch #4. Accuracy on batch 2078/2438  on Training is 68.30507455507455\n",
            "Epoch #4. Accuracy on batch 2079/2438  on Training is 68.30679086538461\n",
            "Batch Id 2080/2438 is having training loss of 1.181270718574524\n",
            "0.9637542366981506\n",
            "Epoch #4. Accuracy on batch 2080/2438  on Training is 68.30850552618934\n",
            "Epoch #4. Accuracy on batch 2081/2438  on Training is 68.30721661863593\n",
            "Epoch #4. Accuracy on batch 2082/2438  on Training is 68.30592894863179\n",
            "Epoch #4. Accuracy on batch 2083/2438  on Training is 68.29564539347409\n",
            "Epoch #4. Accuracy on batch 2084/2438  on Training is 68.29886091127098\n",
            "Epoch #4. Accuracy on batch 2085/2438  on Training is 68.29907718120805\n",
            "Epoch #4. Accuracy on batch 2086/2438  on Training is 68.30378533780546\n",
            "Epoch #4. Accuracy on batch 2087/2438  on Training is 68.29950909961686\n",
            "Epoch #4. Accuracy on batch 2088/2438  on Training is 68.29972474868359\n",
            "Epoch #4. Accuracy on batch 2089/2438  on Training is 68.29694976076556\n",
            "Epoch #4. Accuracy on batch 2090/2438  on Training is 68.28670492587278\n",
            "Epoch #4. Accuracy on batch 2091/2438  on Training is 68.28692638623328\n",
            "Epoch #4. Accuracy on batch 2092/2438  on Training is 68.28416149068323\n",
            "Epoch #4. Accuracy on batch 2093/2438  on Training is 68.28139923591213\n",
            "Epoch #4. Accuracy on batch 2094/2438  on Training is 68.27714797136038\n",
            "Epoch #4. Accuracy on batch 2095/2438  on Training is 68.27290076335878\n",
            "Epoch #4. Accuracy on batch 2096/2438  on Training is 68.27163805436338\n",
            "Epoch #4. Accuracy on batch 2097/2438  on Training is 68.27186606291707\n",
            "Epoch #4. Accuracy on batch 2098/2438  on Training is 68.26018342067651\n",
            "Epoch #4. Accuracy on batch 2099/2438  on Training is 68.25744047619048\n",
            "Batch Id 2100/2438 is having training loss of 1.1825587749481201\n",
            "0.8647899627685547\n",
            "Epoch #4. Accuracy on batch 2100/2438  on Training is 68.26064969062351\n",
            "Epoch #4. Accuracy on batch 2101/2438  on Training is 68.25939581351095\n",
            "Epoch #4. Accuracy on batch 2102/2438  on Training is 68.26111507370423\n",
            "Epoch #4. Accuracy on batch 2103/2438  on Training is 68.26431796577947\n",
            "Epoch #4. Accuracy on batch 2104/2438  on Training is 68.27048693586698\n",
            "Epoch #4. Accuracy on batch 2105/2438  on Training is 68.27219848053181\n",
            "Epoch #4. Accuracy on batch 2106/2438  on Training is 68.27094209776934\n",
            "Epoch #4. Accuracy on batch 2107/2438  on Training is 68.27265180265654\n",
            "Epoch #4. Accuracy on batch 2108/2438  on Training is 68.27880512091038\n",
            "Epoch #4. Accuracy on batch 2109/2438  on Training is 68.2760663507109\n",
            "Epoch #4. Accuracy on batch 2110/2438  on Training is 68.28221222169587\n",
            "Epoch #4. Accuracy on batch 2111/2438  on Training is 68.28243371212122\n",
            "Epoch #4. Accuracy on batch 2112/2438  on Training is 68.28265499290109\n",
            "Epoch #4. Accuracy on batch 2113/2438  on Training is 68.28287606433302\n",
            "Epoch #4. Accuracy on batch 2114/2438  on Training is 68.28457446808511\n",
            "Epoch #4. Accuracy on batch 2115/2438  on Training is 68.28627126654064\n",
            "Epoch #4. Accuracy on batch 2116/2438  on Training is 68.2835380255078\n",
            "Epoch #4. Accuracy on batch 2117/2438  on Training is 68.28228281397544\n",
            "Epoch #4. Accuracy on batch 2118/2438  on Training is 68.29135205285512\n",
            "Epoch #4. Accuracy on batch 2119/2438  on Training is 68.29156839622641\n",
            "Batch Id 2120/2438 is having training loss of 1.181428074836731\n",
            "1.1845344305038452\n",
            "Epoch #4. Accuracy on batch 2120/2438  on Training is 68.2932578972183\n",
            "Epoch #4. Accuracy on batch 2121/2438  on Training is 68.28610980207351\n",
            "Epoch #4. Accuracy on batch 2122/2438  on Training is 68.28338436175224\n",
            "Epoch #4. Accuracy on batch 2123/2438  on Training is 68.28213276836158\n",
            "Epoch #4. Accuracy on batch 2124/2438  on Training is 68.27794117647059\n",
            "Epoch #4. Accuracy on batch 2125/2438  on Training is 68.2781632173095\n",
            "Epoch #4. Accuracy on batch 2126/2438  on Training is 68.28279266572638\n",
            "Epoch #4. Accuracy on batch 2127/2438  on Training is 68.28007518796993\n",
            "Epoch #4. Accuracy on batch 2128/2438  on Training is 68.27736026303428\n",
            "Epoch #4. Accuracy on batch 2129/2438  on Training is 68.28198356807512\n",
            "Epoch #4. Accuracy on batch 2130/2438  on Training is 68.28366963866729\n",
            "Epoch #4. Accuracy on batch 2131/2438  on Training is 68.28388836772983\n",
            "Epoch #4. Accuracy on batch 2132/2438  on Training is 68.28117674636663\n",
            "Epoch #4. Accuracy on batch 2133/2438  on Training is 68.28286082474227\n",
            "Epoch #4. Accuracy on batch 2134/2438  on Training is 68.28307962529274\n",
            "Epoch #4. Accuracy on batch 2135/2438  on Training is 68.28037219101124\n",
            "Epoch #4. Accuracy on batch 2136/2438  on Training is 68.2776672905943\n",
            "Epoch #4. Accuracy on batch 2137/2438  on Training is 68.27496492048644\n",
            "Epoch #4. Accuracy on batch 2138/2438  on Training is 68.26934315100515\n",
            "Epoch #4. Accuracy on batch 2139/2438  on Training is 68.27102803738318\n",
            "Batch Id 2140/2438 is having training loss of 1.1817928552627563\n",
            "1.1418501138687134\n",
            "Epoch #4. Accuracy on batch 2140/2438  on Training is 68.27271134983653\n",
            "Epoch #4. Accuracy on batch 2141/2438  on Training is 68.27876984126983\n",
            "Epoch #4. Accuracy on batch 2142/2438  on Training is 68.27753149790014\n",
            "Epoch #4. Accuracy on batch 2143/2438  on Training is 68.27775186567165\n",
            "Epoch #4. Accuracy on batch 2144/2438  on Training is 68.27797202797203\n",
            "Epoch #4. Accuracy on batch 2145/2438  on Training is 68.27673578751165\n",
            "Epoch #4. Accuracy on batch 2146/2438  on Training is 68.27550069864928\n",
            "Epoch #4. Accuracy on batch 2147/2438  on Training is 68.27426675977654\n",
            "Epoch #4. Accuracy on batch 2148/2438  on Training is 68.27739646347138\n",
            "Epoch #4. Accuracy on batch 2149/2438  on Training is 68.27470930232558\n",
            "Epoch #4. Accuracy on batch 2150/2438  on Training is 68.27928870292887\n",
            "Epoch #4. Accuracy on batch 2151/2438  on Training is 68.2809595724907\n",
            "Epoch #4. Accuracy on batch 2152/2438  on Training is 68.28698327914537\n",
            "Epoch #4. Accuracy on batch 2153/2438  on Training is 68.2871982358403\n",
            "Epoch #4. Accuracy on batch 2154/2438  on Training is 68.290313225058\n",
            "Epoch #4. Accuracy on batch 2155/2438  on Training is 68.28617810760667\n",
            "Epoch #4. Accuracy on batch 2156/2438  on Training is 68.28784191006027\n",
            "Epoch #4. Accuracy on batch 2157/2438  on Training is 68.27791936978684\n",
            "Epoch #4. Accuracy on batch 2158/2438  on Training is 68.27813802686428\n",
            "Epoch #4. Accuracy on batch 2159/2438  on Training is 68.27835648148148\n",
            "Batch Id 2160/2438 is having training loss of 1.1815093755722046\n",
            "1.272714376449585\n",
            "Epoch #4. Accuracy on batch 2160/2438  on Training is 68.27712864414623\n",
            "Epoch #4. Accuracy on batch 2161/2438  on Training is 68.27734736355227\n",
            "Epoch #4. Accuracy on batch 2162/2438  on Training is 68.27467637540452\n",
            "Epoch #4. Accuracy on batch 2163/2438  on Training is 68.27489602587801\n",
            "Epoch #4. Accuracy on batch 2164/2438  on Training is 68.2751154734411\n",
            "Epoch #4. Accuracy on batch 2165/2438  on Training is 68.27100646352724\n",
            "Epoch #4. Accuracy on batch 2166/2438  on Training is 68.26401707429626\n",
            "Epoch #4. Accuracy on batch 2167/2438  on Training is 68.26712407749078\n",
            "Epoch #4. Accuracy on batch 2168/2438  on Training is 68.26590594744121\n",
            "Epoch #4. Accuracy on batch 2169/2438  on Training is 68.26468894009217\n",
            "Epoch #4. Accuracy on batch 2170/2438  on Training is 68.26491248272686\n",
            "Epoch #4. Accuracy on batch 2171/2438  on Training is 68.263697053407\n",
            "Epoch #4. Accuracy on batch 2172/2438  on Training is 68.26535895075932\n",
            "Epoch #4. Accuracy on batch 2173/2438  on Training is 68.26558187672494\n",
            "Epoch #4. Accuracy on batch 2174/2438  on Training is 68.27011494252874\n",
            "Epoch #4. Accuracy on batch 2175/2438  on Training is 68.26315487132354\n",
            "Epoch #4. Accuracy on batch 2176/2438  on Training is 68.26050757923748\n",
            "Epoch #4. Accuracy on batch 2177/2438  on Training is 68.26360192837465\n",
            "Epoch #4. Accuracy on batch 2178/2438  on Training is 68.26812758145938\n",
            "Epoch #4. Accuracy on batch 2179/2438  on Training is 68.26978211009174\n",
            "Batch Id 2180/2438 is having training loss of 1.1814297437667847\n",
            "0.6417706608772278\n",
            "Epoch #4. Accuracy on batch 2180/2438  on Training is 68.2757336084365\n",
            "Epoch #4. Accuracy on batch 2181/2438  on Training is 68.2816796516957\n",
            "Epoch #4. Accuracy on batch 2182/2438  on Training is 68.27759963353184\n",
            "Epoch #4. Accuracy on batch 2183/2438  on Training is 68.27781593406593\n",
            "Epoch #4. Accuracy on batch 2184/2438  on Training is 68.27803203661327\n",
            "Epoch #4. Accuracy on batch 2185/2438  on Training is 68.27967749313815\n",
            "Epoch #4. Accuracy on batch 2186/2438  on Training is 68.2856081390032\n",
            "Epoch #4. Accuracy on batch 2187/2438  on Training is 68.29153336380256\n",
            "Epoch #4. Accuracy on batch 2188/2438  on Training is 68.29031521242577\n",
            "Epoch #4. Accuracy on batch 2189/2438  on Training is 68.29195205479452\n",
            "Epoch #4. Accuracy on batch 2190/2438  on Training is 68.29358740301232\n",
            "Epoch #4. Accuracy on batch 2191/2438  on Training is 68.29664689781022\n",
            "Epoch #4. Accuracy on batch 2192/2438  on Training is 68.296853625171\n",
            "Epoch #4. Accuracy on batch 2193/2438  on Training is 68.29706016408386\n",
            "Epoch #4. Accuracy on batch 2194/2438  on Training is 68.29441913439635\n",
            "Epoch #4. Accuracy on batch 2195/2438  on Training is 68.29889571948998\n",
            "Epoch #4. Accuracy on batch 2196/2438  on Training is 68.30621301775147\n",
            "Epoch #4. Accuracy on batch 2197/2438  on Training is 68.30357142857143\n",
            "Epoch #4. Accuracy on batch 2198/2438  on Training is 68.30661664392906\n",
            "Epoch #4. Accuracy on batch 2199/2438  on Training is 68.30397727272727\n",
            "Batch Id 2200/2438 is having training loss of 1.1806464195251465\n",
            "1.1658790111541748\n",
            "Epoch #4. Accuracy on batch 2200/2438  on Training is 68.30417991821899\n",
            "Epoch #4. Accuracy on batch 2201/2438  on Training is 68.30580154405087\n",
            "Epoch #4. Accuracy on batch 2202/2438  on Training is 68.30742169768497\n",
            "Epoch #4. Accuracy on batch 2203/2438  on Training is 68.30620462794919\n",
            "Epoch #4. Accuracy on batch 2204/2438  on Training is 68.30357142857143\n",
            "Epoch #4. Accuracy on batch 2205/2438  on Training is 68.29669084315503\n",
            "Epoch #4. Accuracy on batch 2206/2438  on Training is 68.29972813774354\n",
            "Epoch #4. Accuracy on batch 2207/2438  on Training is 68.3013473731884\n",
            "Epoch #4. Accuracy on batch 2208/2438  on Training is 68.30296514259847\n",
            "Epoch #4. Accuracy on batch 2209/2438  on Training is 68.30033936651584\n",
            "Epoch #4. Accuracy on batch 2210/2438  on Training is 68.30336951605608\n",
            "Epoch #4. Accuracy on batch 2211/2438  on Training is 68.30357142857143\n",
            "Epoch #4. Accuracy on batch 2212/2438  on Training is 68.3051852688658\n",
            "Epoch #4. Accuracy on batch 2213/2438  on Training is 68.31103206865401\n",
            "Epoch #4. Accuracy on batch 2214/2438  on Training is 68.31264108352144\n",
            "Epoch #4. Accuracy on batch 2215/2438  on Training is 68.31424864620939\n",
            "Epoch #4. Accuracy on batch 2216/2438  on Training is 68.3158547586829\n",
            "Epoch #4. Accuracy on batch 2217/2438  on Training is 68.31886834986474\n",
            "Epoch #4. Accuracy on batch 2218/2438  on Training is 68.31765434880577\n",
            "Epoch #4. Accuracy on batch 2219/2438  on Training is 68.31784909909909\n",
            "Batch Id 2220/2438 is having training loss of 1.1800564527511597\n",
            "0.7053939700126648\n",
            "Epoch #4. Accuracy on batch 2220/2438  on Training is 68.32226474561008\n",
            "Epoch #4. Accuracy on batch 2221/2438  on Training is 68.32386363636364\n",
            "Epoch #4. Accuracy on batch 2222/2438  on Training is 68.31983805668017\n",
            "Epoch #4. Accuracy on batch 2223/2438  on Training is 68.32565197841727\n",
            "Epoch #4. Accuracy on batch 2224/2438  on Training is 68.32162921348315\n",
            "Epoch #4. Accuracy on batch 2225/2438  on Training is 68.32603324348608\n",
            "Epoch #4. Accuracy on batch 2226/2438  on Training is 68.32482038616973\n",
            "Epoch #4. Accuracy on batch 2227/2438  on Training is 68.32501122082586\n",
            "Epoch #4. Accuracy on batch 2228/2438  on Training is 68.32940780619111\n",
            "Epoch #4. Accuracy on batch 2229/2438  on Training is 68.32819506726457\n",
            "Epoch #4. Accuracy on batch 2230/2438  on Training is 68.32838413267594\n",
            "Epoch #4. Accuracy on batch 2231/2438  on Training is 68.3271729390681\n",
            "Epoch #4. Accuracy on batch 2232/2438  on Training is 68.3287617554859\n",
            "Epoch #4. Accuracy on batch 2233/2438  on Training is 68.33314682184422\n",
            "Epoch #4. Accuracy on batch 2234/2438  on Training is 68.3417225950783\n",
            "Epoch #4. Accuracy on batch 2235/2438  on Training is 68.34330277280858\n",
            "Epoch #4. Accuracy on batch 2236/2438  on Training is 68.3448815377738\n",
            "Epoch #4. Accuracy on batch 2237/2438  on Training is 68.34506255585345\n",
            "Epoch #4. Accuracy on batch 2238/2438  on Training is 68.3466391246092\n",
            "Epoch #4. Accuracy on batch 2239/2438  on Training is 68.34402901785714\n",
            "Batch Id 2240/2438 is having training loss of 1.1795399188995361\n",
            "1.3324365615844727\n",
            "Epoch #4. Accuracy on batch 2240/2438  on Training is 68.34560464078537\n",
            "Epoch #4. Accuracy on batch 2241/2438  on Training is 68.35136039250669\n",
            "Epoch #4. Accuracy on batch 2242/2438  on Training is 68.34875167186803\n",
            "Epoch #4. Accuracy on batch 2243/2438  on Training is 68.34475267379679\n",
            "Epoch #4. Accuracy on batch 2244/2438  on Training is 68.34075723830735\n",
            "Epoch #4. Accuracy on batch 2245/2438  on Training is 68.3395480854853\n",
            "Epoch #4. Accuracy on batch 2246/2438  on Training is 68.3411214953271\n",
            "Epoch #4. Accuracy on batch 2247/2438  on Training is 68.34269350533808\n",
            "Epoch #4. Accuracy on batch 2248/2438  on Training is 68.3442641173855\n",
            "Epoch #4. Accuracy on batch 2249/2438  on Training is 68.33888888888889\n",
            "Epoch #4. Accuracy on batch 2250/2438  on Training is 68.33629498000889\n",
            "Epoch #4. Accuracy on batch 2251/2438  on Training is 68.33509103019539\n",
            "Epoch #4. Accuracy on batch 2252/2438  on Training is 68.32972703062583\n",
            "Epoch #4. Accuracy on batch 2253/2438  on Training is 68.32852706299911\n",
            "Epoch #4. Accuracy on batch 2254/2438  on Training is 68.33148558758315\n",
            "Epoch #4. Accuracy on batch 2255/2438  on Training is 68.32890070921985\n",
            "Epoch #4. Accuracy on batch 2256/2438  on Training is 68.32631812140009\n",
            "Epoch #4. Accuracy on batch 2257/2438  on Training is 68.32512178919397\n",
            "Epoch #4. Accuracy on batch 2258/2438  on Training is 68.32254316069057\n",
            "Epoch #4. Accuracy on batch 2259/2438  on Training is 68.32411504424779\n",
            "Batch Id 2260/2438 is having training loss of 1.1800612211227417\n",
            "1.2606122493743896\n",
            "Epoch #4. Accuracy on batch 2260/2438  on Training is 68.3201570101725\n",
            "Epoch #4. Accuracy on batch 2261/2438  on Training is 68.3231100795756\n",
            "Epoch #4. Accuracy on batch 2262/2438  on Training is 68.33020326999558\n",
            "Epoch #4. Accuracy on batch 2263/2438  on Training is 68.32486749116607\n",
            "Epoch #4. Accuracy on batch 2264/2438  on Training is 68.32919426048565\n",
            "Epoch #4. Accuracy on batch 2265/2438  on Training is 68.32800088261253\n",
            "Epoch #4. Accuracy on batch 2266/2438  on Training is 68.3254300838112\n",
            "Epoch #4. Accuracy on batch 2267/2438  on Training is 68.31735008818342\n",
            "Epoch #4. Accuracy on batch 2268/2438  on Training is 68.3202952842662\n",
            "Epoch #4. Accuracy on batch 2269/2438  on Training is 68.32461453744493\n",
            "Epoch #4. Accuracy on batch 2270/2438  on Training is 68.32617789520035\n",
            "Epoch #4. Accuracy on batch 2271/2438  on Training is 68.3318661971831\n",
            "Epoch #4. Accuracy on batch 2272/2438  on Training is 68.32655081390233\n",
            "Epoch #4. Accuracy on batch 2273/2438  on Training is 68.32261433597185\n",
            "Epoch #4. Accuracy on batch 2274/2438  on Training is 68.3228021978022\n",
            "Epoch #4. Accuracy on batch 2275/2438  on Training is 68.31887082601054\n",
            "Epoch #4. Accuracy on batch 2276/2438  on Training is 68.32729468599034\n",
            "Epoch #4. Accuracy on batch 2277/2438  on Training is 68.33022388059702\n",
            "Epoch #4. Accuracy on batch 2278/2438  on Training is 68.33040807371654\n",
            "Epoch #4. Accuracy on batch 2279/2438  on Training is 68.32785087719299\n",
            "Batch Id 2280/2438 is having training loss of 1.179769515991211\n",
            "0.987941324710846\n",
            "Epoch #4. Accuracy on batch 2280/2438  on Training is 68.3321459886015\n",
            "Epoch #4. Accuracy on batch 2281/2438  on Training is 68.33232909728308\n",
            "Epoch #4. Accuracy on batch 2282/2438  on Training is 68.3325120455541\n",
            "Epoch #4. Accuracy on batch 2283/2438  on Training is 68.33679947460595\n",
            "Epoch #4. Accuracy on batch 2284/2438  on Training is 68.33834792122538\n",
            "Epoch #4. Accuracy on batch 2285/2438  on Training is 68.33305993000874\n",
            "Epoch #4. Accuracy on batch 2286/2438  on Training is 68.33187581985133\n",
            "Epoch #4. Accuracy on batch 2287/2438  on Training is 68.33479020979021\n",
            "Epoch #4. Accuracy on batch 2288/2438  on Training is 68.33224115334207\n",
            "Epoch #4. Accuracy on batch 2289/2438  on Training is 68.333788209607\n",
            "Epoch #4. Accuracy on batch 2290/2438  on Training is 68.33124181580096\n",
            "Epoch #4. Accuracy on batch 2291/2438  on Training is 68.32869764397905\n",
            "Epoch #4. Accuracy on batch 2292/2438  on Training is 68.3234300043611\n",
            "Epoch #4. Accuracy on batch 2293/2438  on Training is 68.3208914559721\n",
            "Epoch #4. Accuracy on batch 2294/2438  on Training is 68.32244008714596\n",
            "Epoch #4. Accuracy on batch 2295/2438  on Training is 68.3185431184669\n",
            "Epoch #4. Accuracy on batch 2296/2438  on Training is 68.320091423596\n",
            "Epoch #4. Accuracy on batch 2297/2438  on Training is 68.32027850304613\n",
            "Epoch #4. Accuracy on batch 2298/2438  on Training is 68.31774684645498\n",
            "Epoch #4. Accuracy on batch 2299/2438  on Training is 68.3179347826087\n",
            "Batch Id 2300/2438 is having training loss of 1.1805788278579712\n",
            "1.3549706935882568\n",
            "Epoch #4. Accuracy on batch 2300/2438  on Training is 68.31540634506736\n",
            "Epoch #4. Accuracy on batch 2301/2438  on Training is 68.31423761946134\n",
            "Epoch #4. Accuracy on batch 2302/2438  on Training is 68.3076422058185\n",
            "Epoch #4. Accuracy on batch 2303/2438  on Training is 68.30919053819444\n",
            "Epoch #4. Accuracy on batch 2304/2438  on Training is 68.30395878524946\n",
            "Epoch #4. Accuracy on batch 2305/2438  on Training is 68.29873156981786\n",
            "Epoch #4. Accuracy on batch 2306/2438  on Training is 68.29486345903771\n",
            "Epoch #4. Accuracy on batch 2307/2438  on Training is 68.2909987001733\n",
            "Epoch #4. Accuracy on batch 2308/2438  on Training is 68.28984408834994\n",
            "Epoch #4. Accuracy on batch 2309/2438  on Training is 68.28869047619048\n",
            "Epoch #4. Accuracy on batch 2310/2438  on Training is 68.28348117697966\n",
            "Epoch #4. Accuracy on batch 2311/2438  on Training is 68.28368295847751\n",
            "Epoch #4. Accuracy on batch 2312/2438  on Training is 68.28793774319067\n",
            "Epoch #4. Accuracy on batch 2313/2438  on Training is 68.2894878997407\n",
            "Epoch #4. Accuracy on batch 2314/2438  on Training is 68.28563714902808\n",
            "Epoch #4. Accuracy on batch 2315/2438  on Training is 68.28853626943005\n",
            "Epoch #4. Accuracy on batch 2316/2438  on Training is 68.29008416055244\n",
            "Epoch #4. Accuracy on batch 2317/2438  on Training is 68.2889344262295\n",
            "Epoch #4. Accuracy on batch 2318/2438  on Training is 68.29452350150927\n",
            "Epoch #4. Accuracy on batch 2319/2438  on Training is 68.29876077586206\n",
            "Batch Id 2320/2438 is having training loss of 1.1806366443634033\n",
            "0.8611432909965515\n",
            "Epoch #4. Accuracy on batch 2320/2438  on Training is 68.30164799655321\n",
            "Epoch #4. Accuracy on batch 2321/2438  on Training is 68.2964577950043\n",
            "Epoch #4. Accuracy on batch 2322/2438  on Training is 68.29396254842875\n",
            "Epoch #4. Accuracy on batch 2323/2438  on Training is 68.28340146299483\n",
            "Epoch #4. Accuracy on batch 2324/2438  on Training is 68.28360215053763\n",
            "Epoch #4. Accuracy on batch 2325/2438  on Training is 68.28111564918315\n",
            "Epoch #4. Accuracy on batch 2326/2438  on Training is 68.277288354104\n",
            "Epoch #4. Accuracy on batch 2327/2438  on Training is 68.27614905498282\n",
            "Epoch #4. Accuracy on batch 2328/2438  on Training is 68.28037784456849\n",
            "Epoch #4. Accuracy on batch 2329/2438  on Training is 68.28192060085837\n",
            "Epoch #4. Accuracy on batch 2330/2438  on Training is 68.28212140712141\n",
            "Epoch #4. Accuracy on batch 2331/2438  on Training is 68.28366209262435\n",
            "Epoch #4. Accuracy on batch 2332/2438  on Training is 68.28520145735105\n",
            "Epoch #4. Accuracy on batch 2333/2438  on Training is 68.28138389031706\n",
            "Epoch #4. Accuracy on batch 2334/2438  on Training is 68.28024625267666\n",
            "Epoch #4. Accuracy on batch 2335/2438  on Training is 68.28312285958904\n",
            "Epoch #4. Accuracy on batch 2336/2438  on Training is 68.28599700470689\n",
            "Epoch #4. Accuracy on batch 2337/2438  on Training is 68.28619546621043\n",
            "Epoch #4. Accuracy on batch 2338/2438  on Training is 68.29040188114578\n",
            "Epoch #4. Accuracy on batch 2339/2438  on Training is 68.28926282051282\n",
            "Batch Id 2340/2438 is having training loss of 1.181130051612854\n",
            "1.2096465826034546\n",
            "Epoch #4. Accuracy on batch 2340/2438  on Training is 68.29079453225117\n",
            "Epoch #4. Accuracy on batch 2341/2438  on Training is 68.2883219470538\n",
            "Epoch #4. Accuracy on batch 2342/2438  on Training is 68.28851899274434\n",
            "Epoch #4. Accuracy on batch 2343/2438  on Training is 68.28871587030717\n",
            "Epoch #4. Accuracy on batch 2344/2438  on Training is 68.29291044776119\n",
            "Epoch #4. Accuracy on batch 2345/2438  on Training is 68.28910912190963\n",
            "Epoch #4. Accuracy on batch 2346/2438  on Training is 68.28664252236898\n",
            "Epoch #4. Accuracy on batch 2347/2438  on Training is 68.2775234241908\n",
            "Epoch #4. Accuracy on batch 2348/2438  on Training is 68.27107279693486\n",
            "Epoch #4. Accuracy on batch 2349/2438  on Training is 68.26994680851064\n",
            "Epoch #4. Accuracy on batch 2350/2438  on Training is 68.27015099957465\n",
            "Epoch #4. Accuracy on batch 2351/2438  on Training is 68.27566964285714\n",
            "Epoch #4. Accuracy on batch 2352/2438  on Training is 68.27852741181471\n",
            "Epoch #4. Accuracy on batch 2353/2438  on Training is 68.27740016992354\n",
            "Epoch #4. Accuracy on batch 2354/2438  on Training is 68.27892781316348\n",
            "Epoch #4. Accuracy on batch 2355/2438  on Training is 68.28708616298812\n",
            "Epoch #4. Accuracy on batch 2356/2438  on Training is 68.28993423843869\n",
            "Epoch #4. Accuracy on batch 2357/2438  on Training is 68.28747879558948\n",
            "Epoch #4. Accuracy on batch 2358/2438  on Training is 68.28370072064435\n",
            "Epoch #4. Accuracy on batch 2359/2438  on Training is 68.27992584745763\n",
            "Batch Id 2360/2438 is having training loss of 1.1813377141952515\n",
            "1.4586772918701172\n",
            "Epoch #4. Accuracy on batch 2360/2438  on Training is 68.2788013553579\n",
            "Epoch #4. Accuracy on batch 2361/2438  on Training is 68.28032387806944\n",
            "Epoch #4. Accuracy on batch 2362/2438  on Training is 68.2831675835802\n",
            "Epoch #4. Accuracy on batch 2363/2438  on Training is 68.29129653130288\n",
            "Epoch #4. Accuracy on batch 2364/2438  on Training is 68.28488372093024\n",
            "Epoch #4. Accuracy on batch 2365/2438  on Training is 68.28375950972105\n",
            "Epoch #4. Accuracy on batch 2366/2438  on Training is 68.28395648500211\n",
            "Epoch #4. Accuracy on batch 2367/2438  on Training is 68.28679265202703\n",
            "Epoch #4. Accuracy on batch 2368/2438  on Training is 68.28171169269734\n",
            "Epoch #4. Accuracy on batch 2369/2438  on Training is 68.28059071729957\n",
            "Epoch #4. Accuracy on batch 2370/2438  on Training is 68.27288064107971\n",
            "Epoch #4. Accuracy on batch 2371/2438  on Training is 68.27308178752108\n",
            "Epoch #4. Accuracy on batch 2372/2438  on Training is 68.27855035819637\n",
            "Epoch #4. Accuracy on batch 2373/2438  on Training is 68.27216722830666\n",
            "Epoch #4. Accuracy on batch 2374/2438  on Training is 68.26842105263158\n",
            "Epoch #4. Accuracy on batch 2375/2438  on Training is 68.26467803030303\n",
            "Epoch #4. Accuracy on batch 2376/2438  on Training is 68.26751156920488\n",
            "Epoch #4. Accuracy on batch 2377/2438  on Training is 68.26377207737595\n",
            "Epoch #4. Accuracy on batch 2378/2438  on Training is 68.26791719209751\n",
            "Epoch #4. Accuracy on batch 2379/2438  on Training is 68.26549369747899\n",
            "Batch Id 2380/2438 is having training loss of 1.1817964315414429\n",
            "1.068910837173462\n",
            "Epoch #4. Accuracy on batch 2380/2438  on Training is 68.26832213355733\n",
            "Epoch #4. Accuracy on batch 2381/2438  on Training is 68.26590050377834\n",
            "Epoch #4. Accuracy on batch 2382/2438  on Training is 68.26348090642048\n",
            "Epoch #4. Accuracy on batch 2383/2438  on Training is 68.26761744966443\n",
            "Epoch #4. Accuracy on batch 2384/2438  on Training is 68.27044025157232\n",
            "Epoch #4. Accuracy on batch 2385/2438  on Training is 68.2654023470243\n",
            "Epoch #4. Accuracy on batch 2386/2438  on Training is 68.2682237117721\n",
            "Epoch #4. Accuracy on batch 2387/2438  on Training is 68.27104271356784\n",
            "Epoch #4. Accuracy on batch 2388/2438  on Training is 68.27255127668481\n",
            "Epoch #4. Accuracy on batch 2389/2438  on Training is 68.27144351464435\n",
            "Epoch #4. Accuracy on batch 2390/2438  on Training is 68.27556461731493\n",
            "Epoch #4. Accuracy on batch 2391/2438  on Training is 68.27445652173913\n",
            "Epoch #4. Accuracy on batch 2392/2438  on Training is 68.26943167572085\n",
            "Epoch #4. Accuracy on batch 2393/2438  on Training is 68.26963241436926\n",
            "Epoch #4. Accuracy on batch 2394/2438  on Training is 68.26852818371607\n",
            "Epoch #4. Accuracy on batch 2395/2438  on Training is 68.27133764607679\n",
            "Epoch #4. Accuracy on batch 2396/2438  on Training is 68.27153733833958\n",
            "Epoch #4. Accuracy on batch 2397/2438  on Training is 68.27043369474562\n",
            "Epoch #4. Accuracy on batch 2398/2438  on Training is 68.27193622342642\n",
            "Epoch #4. Accuracy on batch 2399/2438  on Training is 68.27734375\n",
            "Batch Id 2400/2438 is having training loss of 1.1813867092132568\n",
            "1.1718628406524658\n",
            "Epoch #4. Accuracy on batch 2400/2438  on Training is 68.27493752603083\n",
            "Epoch #4. Accuracy on batch 2401/2438  on Training is 68.27643630308077\n",
            "Epoch #4. Accuracy on batch 2402/2438  on Training is 68.27403245942571\n",
            "Epoch #4. Accuracy on batch 2403/2438  on Training is 68.27943011647254\n",
            "Epoch #4. Accuracy on batch 2404/2438  on Training is 68.27962577962577\n",
            "Epoch #4. Accuracy on batch 2405/2438  on Training is 68.27852244389027\n",
            "Epoch #4. Accuracy on batch 2406/2438  on Training is 68.27871832156211\n",
            "Epoch #4. Accuracy on batch 2407/2438  on Training is 68.2828073089701\n",
            "Epoch #4. Accuracy on batch 2408/2438  on Training is 68.28170402656704\n",
            "Epoch #4. Accuracy on batch 2409/2438  on Training is 68.28060165975104\n",
            "Epoch #4. Accuracy on batch 2410/2438  on Training is 68.2820924927416\n",
            "Epoch #4. Accuracy on batch 2411/2438  on Training is 68.28617330016584\n",
            "Epoch #4. Accuracy on batch 2412/2438  on Training is 68.28895565685868\n",
            "Epoch #4. Accuracy on batch 2413/2438  on Training is 68.28655758077879\n",
            "Epoch #4. Accuracy on batch 2414/2438  on Training is 68.2906314699793\n",
            "Epoch #4. Accuracy on batch 2415/2438  on Training is 68.29082160596026\n",
            "Epoch #4. Accuracy on batch 2416/2438  on Training is 68.28842573438146\n",
            "Epoch #4. Accuracy on batch 2417/2438  on Training is 68.2821546732837\n",
            "Epoch #4. Accuracy on batch 2418/2438  on Training is 68.28105622157916\n",
            "Epoch #4. Accuracy on batch 2419/2438  on Training is 68.28512396694215\n",
            "Batch Id 2420/2438 is having training loss of 1.1810778379440308\n",
            "1.5575988292694092\n",
            "Epoch #4. Accuracy on batch 2420/2438  on Training is 68.28015282940933\n",
            "Epoch #4. Accuracy on batch 2421/2438  on Training is 68.28034682080924\n",
            "Epoch #4. Accuracy on batch 2422/2438  on Training is 68.28183037556748\n",
            "Epoch #4. Accuracy on batch 2423/2438  on Training is 68.2884694719472\n",
            "Epoch #4. Accuracy on batch 2424/2438  on Training is 68.28994845360825\n",
            "Epoch #4. Accuracy on batch 2425/2438  on Training is 68.28240931574608\n",
            "Epoch #4. Accuracy on batch 2426/2438  on Training is 68.2826019777503\n",
            "Epoch #4. Accuracy on batch 2427/2438  on Training is 68.28536861614498\n",
            "Epoch #4. Accuracy on batch 2428/2438  on Training is 68.28427336352408\n",
            "Epoch #4. Accuracy on batch 2429/2438  on Training is 68.27932098765432\n",
            "Epoch #4. Accuracy on batch 2430/2438  on Training is 68.28080008227067\n",
            "Epoch #4. Accuracy on batch 2431/2438  on Training is 68.28227796052632\n",
            "Epoch #4. Accuracy on batch 2432/2438  on Training is 68.28118577887382\n",
            "Epoch #4. Accuracy on batch 2433/2438  on Training is 68.28137838948233\n",
            "Epoch #4. Accuracy on batch 2434/2438  on Training is 68.28028747433265\n",
            "Epoch #4. Accuracy on batch 2435/2438  on Training is 68.27791461412151\n",
            "Epoch #4. Accuracy on batch 2436/2438  on Training is 68.27554370127206\n",
            "Epoch #4. Accuracy on batch 2437/2438  on Training is 68.27692307692308\n",
            "Epoch #4. Batch Id 0/278  is having validation loss of 1.2261874675750732\n",
            "1.2261874675750732\n",
            "Epoch #4. Batch Id 0/278  is having validation accuracy of 56.25\n",
            "Epoch #4. Batch Id 1/278  is having validation loss of 1.2696337699890137\n",
            "1.3130801916122437\n",
            "Epoch #4. Batch Id 1/278  is having validation accuracy of 62.5\n",
            "Epoch #4. Batch Id 2/278  is having validation loss of 1.2998930215835571\n",
            "1.3604114055633545\n",
            "Epoch #4. Batch Id 2/278  is having validation accuracy of 63.541666666666664\n",
            "Epoch #4. Batch Id 3/278  is having validation loss of 1.1741654872894287\n",
            "0.7969830632209778\n",
            "Epoch #4. Batch Id 3/278  is having validation accuracy of 66.40625\n",
            "Epoch #4. Batch Id 4/278  is having validation loss of 1.3959016799926758\n",
            "2.282846689224243\n",
            "Epoch #4. Batch Id 4/278  is having validation accuracy of 61.875\n",
            "Epoch #4. Batch Id 5/278  is having validation loss of 1.4343907833099365\n",
            "1.6268366575241089\n",
            "Epoch #4. Batch Id 5/278  is having validation accuracy of 62.5\n",
            "Epoch #4. Batch Id 6/278  is having validation loss of 1.4470897912979126\n",
            "1.5232834815979004\n",
            "Epoch #4. Batch Id 6/278  is having validation accuracy of 62.5\n",
            "Epoch #4. Batch Id 7/278  is having validation loss of 1.4422225952148438\n",
            "1.4081522226333618\n",
            "Epoch #4. Batch Id 7/278  is having validation accuracy of 61.71875\n",
            "Epoch #4. Batch Id 8/278  is having validation loss of 1.4191545248031616\n",
            "1.2346104383468628\n",
            "Epoch #4. Batch Id 8/278  is having validation accuracy of 62.15277777777778\n",
            "Epoch #4. Batch Id 9/278  is having validation loss of 1.377974271774292\n",
            "1.0073519945144653\n",
            "Epoch #4. Batch Id 9/278  is having validation accuracy of 62.1875\n",
            "Epoch #4. Batch Id 10/278  is having validation loss of 1.3885048627853394\n",
            "1.4938102960586548\n",
            "Epoch #4. Batch Id 10/278  is having validation accuracy of 61.36363636363637\n",
            "Epoch #4. Batch Id 11/278  is having validation loss of 1.3772019147872925\n",
            "1.2528693675994873\n",
            "Epoch #4. Batch Id 11/278  is having validation accuracy of 61.979166666666664\n",
            "Epoch #4. Batch Id 12/278  is having validation loss of 1.37507963180542\n",
            "1.349612832069397\n",
            "Epoch #4. Batch Id 12/278  is having validation accuracy of 62.74038461538461\n",
            "Epoch #4. Batch Id 13/278  is having validation loss of 1.3897104263305664\n",
            "1.579910159111023\n",
            "Epoch #4. Batch Id 13/278  is having validation accuracy of 62.276785714285715\n",
            "Epoch #4. Batch Id 14/278  is having validation loss of 1.3806382417678833\n",
            "1.2536275386810303\n",
            "Epoch #4. Batch Id 14/278  is having validation accuracy of 62.916666666666664\n",
            "Epoch #4. Batch Id 15/278  is having validation loss of 1.3885343074798584\n",
            "1.506974458694458\n",
            "Epoch #4. Batch Id 15/278  is having validation accuracy of 63.28125\n",
            "Epoch #4. Batch Id 16/278  is having validation loss of 1.4035481214523315\n",
            "1.64376962184906\n",
            "Epoch #4. Batch Id 16/278  is having validation accuracy of 63.0514705882353\n",
            "Epoch #4. Batch Id 17/278  is having validation loss of 1.4205938577651978\n",
            "1.7103723287582397\n",
            "Epoch #4. Batch Id 17/278  is having validation accuracy of 62.5\n",
            "Epoch #4. Batch Id 18/278  is having validation loss of 1.4227522611618042\n",
            "1.4616039991378784\n",
            "Epoch #4. Batch Id 18/278  is having validation accuracy of 62.5\n",
            "Epoch #4. Batch Id 19/278  is having validation loss of 1.4277915954589844\n",
            "1.5235395431518555\n",
            "Epoch #4. Batch Id 19/278  is having validation accuracy of 62.65625\n",
            "Epoch #4. Batch Id 20/278  is having validation loss of 1.4205131530761719\n",
            "1.274944543838501\n",
            "Epoch #4. Batch Id 20/278  is having validation accuracy of 62.351190476190474\n",
            "Epoch #4. Batch Id 21/278  is having validation loss of 1.4173134565353394\n",
            "1.3501200675964355\n",
            "Epoch #4. Batch Id 21/278  is having validation accuracy of 62.5\n",
            "Epoch #4. Batch Id 22/278  is having validation loss of 1.3820348978042603\n",
            "0.6059075593948364\n",
            "Epoch #4. Batch Id 22/278  is having validation accuracy of 63.58695652173913\n",
            "Epoch #4. Batch Id 23/278  is having validation loss of 1.3888213634490967\n",
            "1.5449094772338867\n",
            "Epoch #4. Batch Id 23/278  is having validation accuracy of 63.671875\n",
            "Epoch #4. Batch Id 24/278  is having validation loss of 1.3814057111740112\n",
            "1.2034308910369873\n",
            "Epoch #4. Batch Id 24/278  is having validation accuracy of 63.625\n",
            "Epoch #4. Batch Id 25/278  is having validation loss of 1.3860443830490112\n",
            "1.502011775970459\n",
            "Epoch #4. Batch Id 25/278  is having validation accuracy of 63.46153846153846\n",
            "Epoch #4. Batch Id 26/278  is having validation loss of 1.405461311340332\n",
            "1.9103025197982788\n",
            "Epoch #4. Batch Id 26/278  is having validation accuracy of 62.96296296296296\n",
            "Epoch #4. Batch Id 27/278  is having validation loss of 1.4070762395858765\n",
            "1.4506791830062866\n",
            "Epoch #4. Batch Id 27/278  is having validation accuracy of 62.94642857142857\n",
            "Epoch #4. Batch Id 28/278  is having validation loss of 1.4263076782226562\n",
            "1.9647879600524902\n",
            "Epoch #4. Batch Id 28/278  is having validation accuracy of 62.39224137931034\n",
            "Epoch #4. Batch Id 29/278  is having validation loss of 1.4202470779418945\n",
            "1.244491457939148\n",
            "Epoch #4. Batch Id 29/278  is having validation accuracy of 62.291666666666664\n",
            "Epoch #4. Batch Id 30/278  is having validation loss of 1.4119869470596313\n",
            "1.1641839742660522\n",
            "Epoch #4. Batch Id 30/278  is having validation accuracy of 62.600806451612904\n",
            "Epoch #4. Batch Id 31/278  is having validation loss of 1.4139349460601807\n",
            "1.4743244647979736\n",
            "Epoch #4. Batch Id 31/278  is having validation accuracy of 62.79296875\n",
            "Epoch #4. Batch Id 32/278  is having validation loss of 1.4203729629516602\n",
            "1.6263914108276367\n",
            "Epoch #4. Batch Id 32/278  is having validation accuracy of 62.78409090909091\n",
            "Epoch #4. Batch Id 33/278  is having validation loss of 1.4144624471664429\n",
            "1.219416856765747\n",
            "Epoch #4. Batch Id 33/278  is having validation accuracy of 63.0514705882353\n",
            "Epoch #4. Batch Id 34/278  is having validation loss of 1.4269012212753296\n",
            "1.8498198986053467\n",
            "Epoch #4. Batch Id 34/278  is having validation accuracy of 62.67857142857143\n",
            "Epoch #4. Batch Id 35/278  is having validation loss of 1.4237114191055298\n",
            "1.3120687007904053\n",
            "Epoch #4. Batch Id 35/278  is having validation accuracy of 62.93402777777778\n",
            "Epoch #4. Batch Id 36/278  is having validation loss of 1.41652512550354\n",
            "1.15781831741333\n",
            "Epoch #4. Batch Id 36/278  is having validation accuracy of 63.17567567567568\n",
            "Epoch #4. Batch Id 37/278  is having validation loss of 1.4117934703826904\n",
            "1.2367225885391235\n",
            "Epoch #4. Batch Id 37/278  is having validation accuracy of 63.1578947368421\n",
            "Epoch #4. Batch Id 38/278  is having validation loss of 1.4127740859985352\n",
            "1.4500365257263184\n",
            "Epoch #4. Batch Id 38/278  is having validation accuracy of 63.14102564102564\n",
            "Epoch #4. Batch Id 39/278  is having validation loss of 1.4060308933258057\n",
            "1.1430467367172241\n",
            "Epoch #4. Batch Id 39/278  is having validation accuracy of 63.359375\n",
            "Epoch #4. Batch Id 40/278  is having validation loss of 1.4102610349655151\n",
            "1.5794649124145508\n",
            "Epoch #4. Batch Id 40/278  is having validation accuracy of 63.33841463414634\n",
            "Epoch #4. Batch Id 41/278  is having validation loss of 1.4087879657745361\n",
            "1.3483898639678955\n",
            "Epoch #4. Batch Id 41/278  is having validation accuracy of 63.31845238095238\n",
            "Epoch #4. Batch Id 42/278  is having validation loss of 1.398798942565918\n",
            "0.9792615175247192\n",
            "Epoch #4. Batch Id 42/278  is having validation accuracy of 63.66279069767442\n",
            "Epoch #4. Batch Id 43/278  is having validation loss of 1.3952269554138184\n",
            "1.241631031036377\n",
            "Epoch #4. Batch Id 43/278  is having validation accuracy of 63.63636363636363\n",
            "Epoch #4. Batch Id 44/278  is having validation loss of 1.3975396156311035\n",
            "1.4992958307266235\n",
            "Epoch #4. Batch Id 44/278  is having validation accuracy of 63.40277777777778\n",
            "Epoch #4. Batch Id 45/278  is having validation loss of 1.3955954313278198\n",
            "1.3081068992614746\n",
            "Epoch #4. Batch Id 45/278  is having validation accuracy of 63.51902173913044\n",
            "Epoch #4. Batch Id 46/278  is having validation loss of 1.3859007358551025\n",
            "0.9399449229240417\n",
            "Epoch #4. Batch Id 46/278  is having validation accuracy of 63.89627659574468\n",
            "Epoch #4. Batch Id 47/278  is having validation loss of 1.3845170736312866\n",
            "1.3194868564605713\n",
            "Epoch #4. Batch Id 47/278  is having validation accuracy of 63.997395833333336\n",
            "Epoch #4. Batch Id 48/278  is having validation loss of 1.377646565437317\n",
            "1.047859787940979\n",
            "Epoch #4. Batch Id 48/278  is having validation accuracy of 64.34948979591837\n",
            "Epoch #4. Batch Id 49/278  is having validation loss of 1.3811243772506714\n",
            "1.5515384674072266\n",
            "Epoch #4. Batch Id 49/278  is having validation accuracy of 64.3125\n",
            "Epoch #4. Batch Id 50/278  is having validation loss of 1.3754774332046509\n",
            "1.0931288003921509\n",
            "Epoch #4. Batch Id 50/278  is having validation accuracy of 64.33823529411765\n",
            "Epoch #4. Batch Id 51/278  is having validation loss of 1.3720546960830688\n",
            "1.1974974870681763\n",
            "Epoch #4. Batch Id 51/278  is having validation accuracy of 64.36298076923077\n",
            "Epoch #4. Batch Id 52/278  is having validation loss of 1.3718736171722412\n",
            "1.3624603748321533\n",
            "Epoch #4. Batch Id 52/278  is having validation accuracy of 64.32783018867924\n",
            "Epoch #4. Batch Id 53/278  is having validation loss of 1.3708604574203491\n",
            "1.3171658515930176\n",
            "Epoch #4. Batch Id 53/278  is having validation accuracy of 64.35185185185185\n",
            "Epoch #4. Batch Id 54/278  is having validation loss of 1.366930365562439\n",
            "1.1547043323516846\n",
            "Epoch #4. Batch Id 54/278  is having validation accuracy of 64.43181818181819\n",
            "Epoch #4. Batch Id 55/278  is having validation loss of 1.3666456937789917\n",
            "1.3509881496429443\n",
            "Epoch #4. Batch Id 55/278  is having validation accuracy of 64.28571428571429\n",
            "Epoch #4. Batch Id 56/278  is having validation loss of 1.3712730407714844\n",
            "1.630401849746704\n",
            "Epoch #4. Batch Id 56/278  is having validation accuracy of 64.25438596491227\n",
            "Epoch #4. Batch Id 57/278  is having validation loss of 1.3674298524856567\n",
            "1.1483685970306396\n",
            "Epoch #4. Batch Id 57/278  is having validation accuracy of 64.38577586206897\n",
            "Epoch #4. Batch Id 58/278  is having validation loss of 1.370639681816101\n",
            "1.5568126440048218\n",
            "Epoch #4. Batch Id 58/278  is having validation accuracy of 64.24788135593221\n",
            "Epoch #4. Batch Id 59/278  is having validation loss of 1.3662333488464355\n",
            "1.106256127357483\n",
            "Epoch #4. Batch Id 59/278  is having validation accuracy of 64.42708333333333\n",
            "Epoch #4. Batch Id 60/278  is having validation loss of 1.3619766235351562\n",
            "1.1065746545791626\n",
            "Epoch #4. Batch Id 60/278  is having validation accuracy of 64.60040983606558\n",
            "Epoch #4. Batch Id 61/278  is having validation loss of 1.364755630493164\n",
            "1.534273386001587\n",
            "Epoch #4. Batch Id 61/278  is having validation accuracy of 64.51612903225806\n",
            "Epoch #4. Batch Id 62/278  is having validation loss of 1.356462001800537\n",
            "0.8422550559043884\n",
            "Epoch #4. Batch Id 62/278  is having validation accuracy of 64.73214285714286\n",
            "Epoch #4. Batch Id 63/278  is having validation loss of 1.3596452474594116\n",
            "1.5601900815963745\n",
            "Epoch #4. Batch Id 63/278  is having validation accuracy of 64.6484375\n",
            "Epoch #4. Batch Id 64/278  is having validation loss of 1.3660279512405396\n",
            "1.7745239734649658\n",
            "Epoch #4. Batch Id 64/278  is having validation accuracy of 64.47115384615384\n",
            "Epoch #4. Batch Id 65/278  is having validation loss of 1.3614671230316162\n",
            "1.0650135278701782\n",
            "Epoch #4. Batch Id 65/278  is having validation accuracy of 64.63068181818181\n",
            "Epoch #4. Batch Id 66/278  is having validation loss of 1.3632310628890991\n",
            "1.479649543762207\n",
            "Epoch #4. Batch Id 66/278  is having validation accuracy of 64.59888059701493\n",
            "Epoch #4. Batch Id 67/278  is having validation loss of 1.3671326637268066\n",
            "1.6285369396209717\n",
            "Epoch #4. Batch Id 67/278  is having validation accuracy of 64.5220588235294\n",
            "Epoch #4. Batch Id 68/278  is having validation loss of 1.3612064123153687\n",
            "0.9582224488258362\n",
            "Epoch #4. Batch Id 68/278  is having validation accuracy of 64.6286231884058\n",
            "Epoch #4. Batch Id 69/278  is having validation loss of 1.359858512878418\n",
            "1.2668497562408447\n",
            "Epoch #4. Batch Id 69/278  is having validation accuracy of 64.73214285714286\n",
            "Epoch #4. Batch Id 70/278  is having validation loss of 1.3617993593215942\n",
            "1.4976603984832764\n",
            "Epoch #4. Batch Id 70/278  is having validation accuracy of 64.61267605633803\n",
            "Epoch #4. Batch Id 71/278  is having validation loss of 1.3569129705429077\n",
            "1.0099760293960571\n",
            "Epoch #4. Batch Id 71/278  is having validation accuracy of 64.58333333333333\n",
            "Epoch #4. Batch Id 72/278  is having validation loss of 1.3642497062683105\n",
            "1.8924953937530518\n",
            "Epoch #4. Batch Id 72/278  is having validation accuracy of 64.29794520547945\n",
            "Epoch #4. Batch Id 73/278  is having validation loss of 1.3669859170913696\n",
            "1.566726565361023\n",
            "Epoch #4. Batch Id 73/278  is having validation accuracy of 64.23141891891892\n",
            "Epoch #4. Batch Id 74/278  is having validation loss of 1.3713607788085938\n",
            "1.6951005458831787\n",
            "Epoch #4. Batch Id 74/278  is having validation accuracy of 64.125\n",
            "Epoch #4. Batch Id 75/278  is having validation loss of 1.369599461555481\n",
            "1.237502098083496\n",
            "Epoch #4. Batch Id 75/278  is having validation accuracy of 64.0625\n",
            "Epoch #4. Batch Id 76/278  is having validation loss of 1.3676906824111938\n",
            "1.222627878189087\n",
            "Epoch #4. Batch Id 76/278  is having validation accuracy of 64.16396103896103\n",
            "Epoch #4. Batch Id 77/278  is having validation loss of 1.3640851974487305\n",
            "1.0864639282226562\n",
            "Epoch #4. Batch Id 77/278  is having validation accuracy of 64.26282051282051\n",
            "Epoch #4. Batch Id 78/278  is having validation loss of 1.361809492111206\n",
            "1.1843057870864868\n",
            "Epoch #4. Batch Id 78/278  is having validation accuracy of 64.28006329113924\n",
            "Epoch #4. Batch Id 79/278  is having validation loss of 1.3596577644348145\n",
            "1.189668893814087\n",
            "Epoch #4. Batch Id 79/278  is having validation accuracy of 64.3359375\n",
            "Epoch #4. Batch Id 80/278  is having validation loss of 1.3681484460830688\n",
            "2.0474061965942383\n",
            "Epoch #4. Batch Id 80/278  is having validation accuracy of 64.2746913580247\n",
            "Epoch #4. Batch Id 81/278  is having validation loss of 1.3707551956176758\n",
            "1.5819066762924194\n",
            "Epoch #4. Batch Id 81/278  is having validation accuracy of 64.13871951219512\n",
            "Epoch #4. Batch Id 82/278  is having validation loss of 1.3736822605133057\n",
            "1.6137033700942993\n",
            "Epoch #4. Batch Id 82/278  is having validation accuracy of 64.1566265060241\n",
            "Epoch #4. Batch Id 83/278  is having validation loss of 1.3709567785263062\n",
            "1.1447432041168213\n",
            "Epoch #4. Batch Id 83/278  is having validation accuracy of 64.21130952380952\n",
            "Epoch #4. Batch Id 84/278  is having validation loss of 1.3681161403656006\n",
            "1.1294978857040405\n",
            "Epoch #4. Batch Id 84/278  is having validation accuracy of 64.15441176470588\n",
            "Epoch #4. Batch Id 85/278  is having validation loss of 1.3666530847549438\n",
            "1.2422908544540405\n",
            "Epoch #4. Batch Id 85/278  is having validation accuracy of 64.24418604651163\n",
            "Epoch #4. Batch Id 86/278  is having validation loss of 1.370383381843567\n",
            "1.6911894083023071\n",
            "Epoch #4. Batch Id 86/278  is having validation accuracy of 64.08045977011494\n",
            "Epoch #4. Batch Id 87/278  is having validation loss of 1.36675226688385\n",
            "1.0508421659469604\n",
            "Epoch #4. Batch Id 87/278  is having validation accuracy of 64.13352272727273\n",
            "Epoch #4. Batch Id 88/278  is having validation loss of 1.3678392171859741\n",
            "1.4634933471679688\n",
            "Epoch #4. Batch Id 88/278  is having validation accuracy of 64.1502808988764\n",
            "Epoch #4. Batch Id 89/278  is having validation loss of 1.365562915802002\n",
            "1.1629676818847656\n",
            "Epoch #4. Batch Id 89/278  is having validation accuracy of 64.27083333333333\n",
            "Epoch #4. Batch Id 90/278  is having validation loss of 1.3599430322647095\n",
            "0.8541496992111206\n",
            "Epoch #4. Batch Id 90/278  is having validation accuracy of 64.28571428571429\n",
            "Epoch #4. Batch Id 91/278  is having validation loss of 1.3592830896377563\n",
            "1.2992241382598877\n",
            "Epoch #4. Batch Id 91/278  is having validation accuracy of 64.40217391304348\n",
            "Epoch #4. Batch Id 92/278  is having validation loss of 1.3603887557983398\n",
            "1.4621062278747559\n",
            "Epoch #4. Batch Id 92/278  is having validation accuracy of 64.38172043010752\n",
            "Epoch #4. Batch Id 93/278  is having validation loss of 1.3587929010391235\n",
            "1.2103791236877441\n",
            "Epoch #4. Batch Id 93/278  is having validation accuracy of 64.49468085106383\n",
            "Epoch #4. Batch Id 94/278  is having validation loss of 1.3552073240280151\n",
            "1.0181655883789062\n",
            "Epoch #4. Batch Id 94/278  is having validation accuracy of 64.53947368421052\n",
            "Epoch #4. Batch Id 95/278  is having validation loss of 1.3543915748596191\n",
            "1.2768930196762085\n",
            "Epoch #4. Batch Id 95/278  is having validation accuracy of 64.55078125\n",
            "Epoch #4. Batch Id 96/278  is having validation loss of 1.357245683670044\n",
            "1.6312384605407715\n",
            "Epoch #4. Batch Id 96/278  is having validation accuracy of 64.49742268041237\n",
            "Epoch #4. Batch Id 97/278  is having validation loss of 1.3567512035369873\n",
            "1.3087859153747559\n",
            "Epoch #4. Batch Id 97/278  is having validation accuracy of 64.54081632653062\n",
            "Epoch #4. Batch Id 98/278  is having validation loss of 1.357757806777954\n",
            "1.4563994407653809\n",
            "Epoch #4. Batch Id 98/278  is having validation accuracy of 64.42550505050505\n",
            "Epoch #4. Batch Id 99/278  is having validation loss of 1.3549765348434448\n",
            "1.079626441001892\n",
            "Epoch #4. Batch Id 99/278  is having validation accuracy of 64.53125\n",
            "Epoch #4. Batch Id 100/278  is having validation loss of 1.3562458753585815\n",
            "1.4831854104995728\n",
            "Epoch #4. Batch Id 100/278  is having validation accuracy of 64.41831683168317\n",
            "Epoch #4. Batch Id 101/278  is having validation loss of 1.3562830686569214\n",
            "1.3600430488586426\n",
            "Epoch #4. Batch Id 101/278  is having validation accuracy of 64.27696078431373\n",
            "Epoch #4. Batch Id 102/278  is having validation loss of 1.3544316291809082\n",
            "1.1655889749526978\n",
            "Epoch #4. Batch Id 102/278  is having validation accuracy of 64.32038834951456\n",
            "Epoch #4. Batch Id 103/278  is having validation loss of 1.359032392501831\n",
            "1.832910180091858\n",
            "Epoch #4. Batch Id 103/278  is having validation accuracy of 64.1826923076923\n",
            "Epoch #4. Batch Id 104/278  is having validation loss of 1.3573100566864014\n",
            "1.1781928539276123\n",
            "Epoch #4. Batch Id 104/278  is having validation accuracy of 64.13690476190476\n",
            "Epoch #4. Batch Id 105/278  is having validation loss of 1.3544831275939941\n",
            "1.0576536655426025\n",
            "Epoch #4. Batch Id 105/278  is having validation accuracy of 64.12146226415095\n",
            "Epoch #4. Batch Id 106/278  is having validation loss of 1.3523352146148682\n",
            "1.1246516704559326\n",
            "Epoch #4. Batch Id 106/278  is having validation accuracy of 64.22313084112149\n",
            "Epoch #4. Batch Id 107/278  is having validation loss of 1.349692940711975\n",
            "1.066965937614441\n",
            "Epoch #4. Batch Id 107/278  is having validation accuracy of 64.23611111111111\n",
            "Epoch #4. Batch Id 108/278  is having validation loss of 1.3522611856460571\n",
            "1.629632592201233\n",
            "Epoch #4. Batch Id 108/278  is having validation accuracy of 64.16284403669725\n",
            "Epoch #4. Batch Id 109/278  is having validation loss of 1.3506395816802979\n",
            "1.1738812923431396\n",
            "Epoch #4. Batch Id 109/278  is having validation accuracy of 64.17613636363636\n",
            "Epoch #4. Batch Id 110/278  is having validation loss of 1.346360683441162\n",
            "0.8756790161132812\n",
            "Epoch #4. Batch Id 110/278  is having validation accuracy of 64.24549549549549\n",
            "Epoch #4. Batch Id 111/278  is having validation loss of 1.3431949615478516\n",
            "0.9918054342269897\n",
            "Epoch #4. Batch Id 111/278  is having validation accuracy of 64.28571428571429\n",
            "Epoch #4. Batch Id 112/278  is having validation loss of 1.3427534103393555\n",
            "1.2932988405227661\n",
            "Epoch #4. Batch Id 112/278  is having validation accuracy of 64.29756637168141\n",
            "Epoch #4. Batch Id 113/278  is having validation loss of 1.3430880308151245\n",
            "1.3808947801589966\n",
            "Epoch #4. Batch Id 113/278  is having validation accuracy of 64.25438596491227\n",
            "Epoch #4. Batch Id 114/278  is having validation loss of 1.3476660251617432\n",
            "1.8695626258850098\n",
            "Epoch #4. Batch Id 114/278  is having validation accuracy of 64.07608695652173\n",
            "Epoch #4. Batch Id 115/278  is having validation loss of 1.3496593236923218\n",
            "1.5788894891738892\n",
            "Epoch #4. Batch Id 115/278  is having validation accuracy of 64.08943965517241\n",
            "Epoch #4. Batch Id 116/278  is having validation loss of 1.3550630807876587\n",
            "1.981904149055481\n",
            "Epoch #4. Batch Id 116/278  is having validation accuracy of 63.94230769230769\n",
            "Epoch #4. Batch Id 117/278  is having validation loss of 1.356223225593567\n",
            "1.4919617176055908\n",
            "Epoch #4. Batch Id 117/278  is having validation accuracy of 63.956567796610166\n",
            "Epoch #4. Batch Id 118/278  is having validation loss of 1.3553043603897095\n",
            "1.2468757629394531\n",
            "Epoch #4. Batch Id 118/278  is having validation accuracy of 63.996848739495796\n",
            "Epoch #4. Batch Id 119/278  is having validation loss of 1.3548439741134644\n",
            "1.3000575304031372\n",
            "Epoch #4. Batch Id 119/278  is having validation accuracy of 63.958333333333336\n",
            "Epoch #4. Batch Id 120/278  is having validation loss of 1.35325288772583\n",
            "1.1623289585113525\n",
            "Epoch #4. Batch Id 120/278  is having validation accuracy of 63.92045454545455\n",
            "Epoch #4. Batch Id 121/278  is having validation loss of 1.3556426763534546\n",
            "1.6448063850402832\n",
            "Epoch #4. Batch Id 121/278  is having validation accuracy of 63.78073770491803\n",
            "Epoch #4. Batch Id 122/278  is having validation loss of 1.3581963777542114\n",
            "1.6697537899017334\n",
            "Epoch #4. Batch Id 122/278  is having validation accuracy of 63.64329268292683\n",
            "Epoch #4. Batch Id 123/278  is having validation loss of 1.3609215021133423\n",
            "1.696108102798462\n",
            "Epoch #4. Batch Id 123/278  is having validation accuracy of 63.608870967741936\n",
            "Epoch #4. Batch Id 124/278  is having validation loss of 1.3593186140060425\n",
            "1.1605640649795532\n",
            "Epoch #4. Batch Id 124/278  is having validation accuracy of 63.65\n",
            "Epoch #4. Batch Id 125/278  is having validation loss of 1.3582890033721924\n",
            "1.2295894622802734\n",
            "Epoch #4. Batch Id 125/278  is having validation accuracy of 63.69047619047619\n",
            "Epoch #4. Batch Id 126/278  is having validation loss of 1.3556677103042603\n",
            "1.0253907442092896\n",
            "Epoch #4. Batch Id 126/278  is having validation accuracy of 63.73031496062992\n",
            "Epoch #4. Batch Id 127/278  is having validation loss of 1.3570690155029297\n",
            "1.5350412130355835\n",
            "Epoch #4. Batch Id 127/278  is having validation accuracy of 63.720703125\n",
            "Epoch #4. Batch Id 128/278  is having validation loss of 1.3538761138916016\n",
            "0.9451896548271179\n",
            "Epoch #4. Batch Id 128/278  is having validation accuracy of 63.80813953488372\n",
            "Epoch #4. Batch Id 129/278  is having validation loss of 1.3534742593765259\n",
            "1.3016380071640015\n",
            "Epoch #4. Batch Id 129/278  is having validation accuracy of 63.79807692307692\n",
            "Epoch #4. Batch Id 130/278  is having validation loss of 1.347662091255188\n",
            "0.5920878648757935\n",
            "Epoch #4. Batch Id 130/278  is having validation accuracy of 63.95515267175573\n",
            "Epoch #4. Batch Id 131/278  is having validation loss of 1.3486605882644653\n",
            "1.4794628620147705\n",
            "Epoch #4. Batch Id 131/278  is having validation accuracy of 63.896780303030305\n",
            "Epoch #4. Batch Id 132/278  is having validation loss of 1.3482449054718018\n",
            "1.2933810949325562\n",
            "Epoch #4. Batch Id 132/278  is having validation accuracy of 63.95676691729323\n",
            "Epoch #4. Batch Id 133/278  is having validation loss of 1.3513323068618774\n",
            "1.7619571685791016\n",
            "Epoch #4. Batch Id 133/278  is having validation accuracy of 63.8759328358209\n",
            "Epoch #4. Batch Id 134/278  is having validation loss of 1.3560872077941895\n",
            "1.9932384490966797\n",
            "Epoch #4. Batch Id 134/278  is having validation accuracy of 63.773148148148145\n",
            "Epoch #4. Batch Id 135/278  is having validation loss of 1.3574001789093018\n",
            "1.534643530845642\n",
            "Epoch #4. Batch Id 135/278  is having validation accuracy of 63.671875\n",
            "Epoch #4. Batch Id 136/278  is having validation loss of 1.358149528503418\n",
            "1.4600602388381958\n",
            "Epoch #4. Batch Id 136/278  is having validation accuracy of 63.61770072992701\n",
            "Epoch #4. Batch Id 137/278  is having validation loss of 1.360312581062317\n",
            "1.656651258468628\n",
            "Epoch #4. Batch Id 137/278  is having validation accuracy of 63.4963768115942\n",
            "Epoch #4. Batch Id 138/278  is having validation loss of 1.356953740119934\n",
            "0.8934274315834045\n",
            "Epoch #4. Batch Id 138/278  is having validation accuracy of 63.53417266187051\n",
            "Epoch #4. Batch Id 139/278  is having validation loss of 1.3570010662078857\n",
            "1.363574504852295\n",
            "Epoch #4. Batch Id 139/278  is having validation accuracy of 63.549107142857146\n",
            "Epoch #4. Batch Id 140/278  is having validation loss of 1.356727123260498\n",
            "1.3183701038360596\n",
            "Epoch #4. Batch Id 140/278  is having validation accuracy of 63.58599290780142\n",
            "Epoch #4. Batch Id 141/278  is having validation loss of 1.355044960975647\n",
            "1.117859959602356\n",
            "Epoch #4. Batch Id 141/278  is having validation accuracy of 63.666373239436616\n",
            "Epoch #4. Batch Id 142/278  is having validation loss of 1.3526320457458496\n",
            "1.0099960565567017\n",
            "Epoch #4. Batch Id 142/278  is having validation accuracy of 63.72377622377623\n",
            "Epoch #4. Batch Id 143/278  is having validation loss of 1.3551692962646484\n",
            "1.7180029153823853\n",
            "Epoch #4. Batch Id 143/278  is having validation accuracy of 63.671875\n",
            "Epoch #4. Batch Id 144/278  is having validation loss of 1.3578077554702759\n",
            "1.7377450466156006\n",
            "Epoch #4. Batch Id 144/278  is having validation accuracy of 63.62068965517241\n",
            "Epoch #4. Batch Id 145/278  is having validation loss of 1.3603103160858154\n",
            "1.7231872081756592\n",
            "Epoch #4. Batch Id 145/278  is having validation accuracy of 63.5916095890411\n",
            "Epoch #4. Batch Id 146/278  is having validation loss of 1.3588247299194336\n",
            "1.1419274806976318\n",
            "Epoch #4. Batch Id 146/278  is having validation accuracy of 63.62670068027211\n",
            "Epoch #4. Batch Id 147/278  is having validation loss of 1.358728289604187\n",
            "1.3445520401000977\n",
            "Epoch #4. Batch Id 147/278  is having validation accuracy of 63.661317567567565\n",
            "Epoch #4. Batch Id 148/278  is having validation loss of 1.3604040145874023\n",
            "1.6084051132202148\n",
            "Epoch #4. Batch Id 148/278  is having validation accuracy of 63.54865771812081\n",
            "Epoch #4. Batch Id 149/278  is having validation loss of 1.3610180616378784\n",
            "1.4525164365768433\n",
            "Epoch #4. Batch Id 149/278  is having validation accuracy of 63.520833333333336\n",
            "Epoch #4. Batch Id 150/278  is having validation loss of 1.3614211082458496\n",
            "1.4218742847442627\n",
            "Epoch #4. Batch Id 150/278  is having validation accuracy of 63.51407284768212\n",
            "Epoch #4. Batch Id 151/278  is having validation loss of 1.3621819019317627\n",
            "1.4770578145980835\n",
            "Epoch #4. Batch Id 151/278  is having validation accuracy of 63.5485197368421\n",
            "Epoch #4. Batch Id 152/278  is having validation loss of 1.3616626262664795\n",
            "1.2827415466308594\n",
            "Epoch #4. Batch Id 152/278  is having validation accuracy of 63.52124183006536\n",
            "Epoch #4. Batch Id 153/278  is having validation loss of 1.359472632408142\n",
            "1.0244042873382568\n",
            "Epoch #4. Batch Id 153/278  is having validation accuracy of 63.5551948051948\n",
            "Epoch #4. Batch Id 154/278  is having validation loss of 1.3634166717529297\n",
            "1.9707988500595093\n",
            "Epoch #4. Batch Id 154/278  is having validation accuracy of 63.42741935483871\n",
            "Epoch #4. Batch Id 155/278  is having validation loss of 1.3621224164962769\n",
            "1.161521553993225\n",
            "Epoch #4. Batch Id 155/278  is having validation accuracy of 63.50160256410256\n",
            "Epoch #4. Batch Id 156/278  is having validation loss of 1.363499402999878\n",
            "1.5783032178878784\n",
            "Epoch #4. Batch Id 156/278  is having validation accuracy of 63.455414012738856\n",
            "Epoch #4. Batch Id 157/278  is having validation loss of 1.3636634349822998\n",
            "1.3894085884094238\n",
            "Epoch #4. Batch Id 157/278  is having validation accuracy of 63.449367088607595\n",
            "Epoch #4. Batch Id 158/278  is having validation loss of 1.3642678260803223\n",
            "1.4597669839859009\n",
            "Epoch #4. Batch Id 158/278  is having validation accuracy of 63.48270440251572\n",
            "Epoch #4. Batch Id 159/278  is having validation loss of 1.3637213706970215\n",
            "1.2768434286117554\n",
            "Epoch #4. Batch Id 159/278  is having validation accuracy of 63.515625\n",
            "Epoch #4. Batch Id 160/278  is having validation loss of 1.3659826517105103\n",
            "1.7277945280075073\n",
            "Epoch #4. Batch Id 160/278  is having validation accuracy of 63.47049689440994\n",
            "Epoch #4. Batch Id 161/278  is having validation loss of 1.367836833000183\n",
            "1.6663628816604614\n",
            "Epoch #4. Batch Id 161/278  is having validation accuracy of 63.36805555555556\n",
            "Epoch #4. Batch Id 162/278  is having validation loss of 1.3670296669006348\n",
            "1.2362757921218872\n",
            "Epoch #4. Batch Id 162/278  is having validation accuracy of 63.4010736196319\n",
            "Epoch #4. Batch Id 163/278  is having validation loss of 1.3658769130706787\n",
            "1.1779704093933105\n",
            "Epoch #4. Batch Id 163/278  is having validation accuracy of 63.43368902439025\n",
            "Epoch #4. Batch Id 164/278  is having validation loss of 1.368569016456604\n",
            "1.8100720643997192\n",
            "Epoch #4. Batch Id 164/278  is having validation accuracy of 63.371212121212125\n",
            "Epoch #4. Batch Id 165/278  is having validation loss of 1.3668614625930786\n",
            "1.0851072072982788\n",
            "Epoch #4. Batch Id 165/278  is having validation accuracy of 63.403614457831324\n",
            "Epoch #4. Batch Id 166/278  is having validation loss of 1.3642657995224\n",
            "0.9333781599998474\n",
            "Epoch #4. Batch Id 166/278  is having validation accuracy of 63.491766467065865\n",
            "Epoch #4. Batch Id 167/278  is having validation loss of 1.3638395071029663\n",
            "1.2926416397094727\n",
            "Epoch #4. Batch Id 167/278  is having validation accuracy of 63.541666666666664\n",
            "Epoch #4. Batch Id 168/278  is having validation loss of 1.360711693763733\n",
            "0.8352298140525818\n",
            "Epoch #4. Batch Id 168/278  is having validation accuracy of 63.646449704142015\n",
            "Epoch #4. Batch Id 169/278  is having validation loss of 1.3589104413986206\n",
            "1.054494023323059\n",
            "Epoch #4. Batch Id 169/278  is having validation accuracy of 63.713235294117645\n",
            "Epoch #4. Batch Id 170/278  is having validation loss of 1.3599884510040283\n",
            "1.5432490110397339\n",
            "Epoch #4. Batch Id 170/278  is having validation accuracy of 63.724415204678365\n",
            "Epoch #4. Batch Id 171/278  is having validation loss of 1.3621023893356323\n",
            "1.7235772609710693\n",
            "Epoch #4. Batch Id 171/278  is having validation accuracy of 63.69912790697674\n",
            "Epoch #4. Batch Id 172/278  is having validation loss of 1.3583842515945435\n",
            "0.7188683152198792\n",
            "Epoch #4. Batch Id 172/278  is having validation accuracy of 63.83670520231214\n",
            "Epoch #4. Batch Id 173/278  is having validation loss of 1.357262134552002\n",
            "1.1631368398666382\n",
            "Epoch #4. Batch Id 173/278  is having validation accuracy of 63.86494252873563\n",
            "Epoch #4. Batch Id 174/278  is having validation loss of 1.3587626218795776\n",
            "1.619843602180481\n",
            "Epoch #4. Batch Id 174/278  is having validation accuracy of 63.82142857142857\n",
            "Epoch #4. Batch Id 175/278  is having validation loss of 1.358944296836853\n",
            "1.390729546546936\n",
            "Epoch #4. Batch Id 175/278  is having validation accuracy of 63.74289772727273\n",
            "Epoch #4. Batch Id 176/278  is having validation loss of 1.3581732511520386\n",
            "1.2224724292755127\n",
            "Epoch #4. Batch Id 176/278  is having validation accuracy of 63.753531073446325\n",
            "Epoch #4. Batch Id 177/278  is having validation loss of 1.3592398166656494\n",
            "1.5480319261550903\n",
            "Epoch #4. Batch Id 177/278  is having validation accuracy of 63.764044943820224\n",
            "Epoch #4. Batch Id 178/278  is having validation loss of 1.3624080419540405\n",
            "1.926351547241211\n",
            "Epoch #4. Batch Id 178/278  is having validation accuracy of 63.63477653631285\n",
            "Epoch #4. Batch Id 179/278  is having validation loss of 1.3643863201141357\n",
            "1.7184913158416748\n",
            "Epoch #4. Batch Id 179/278  is having validation accuracy of 63.55902777777778\n",
            "Epoch #4. Batch Id 180/278  is having validation loss of 1.3645449876785278\n",
            "1.3931063413619995\n",
            "Epoch #4. Batch Id 180/278  is having validation accuracy of 63.53591160220994\n",
            "Epoch #4. Batch Id 181/278  is having validation loss of 1.3636338710784912\n",
            "1.1987321376800537\n",
            "Epoch #4. Batch Id 181/278  is having validation accuracy of 63.54739010989011\n",
            "Epoch #4. Batch Id 182/278  is having validation loss of 1.3637855052947998\n",
            "1.3913918733596802\n",
            "Epoch #4. Batch Id 182/278  is having validation accuracy of 63.52459016393443\n",
            "Epoch #4. Batch Id 183/278  is having validation loss of 1.3658920526504517\n",
            "1.7513842582702637\n",
            "Epoch #4. Batch Id 183/278  is having validation accuracy of 63.50203804347826\n",
            "Epoch #4. Batch Id 184/278  is having validation loss of 1.364962100982666\n",
            "1.1938555240631104\n",
            "Epoch #4. Batch Id 184/278  is having validation accuracy of 63.5304054054054\n",
            "Epoch #4. Batch Id 185/278  is having validation loss of 1.363010287284851\n",
            "1.0019149780273438\n",
            "Epoch #4. Batch Id 185/278  is having validation accuracy of 63.59206989247312\n",
            "Epoch #4. Batch Id 186/278  is having validation loss of 1.3631666898727417\n",
            "1.3922662734985352\n",
            "Epoch #4. Batch Id 186/278  is having validation accuracy of 63.63636363636363\n",
            "Epoch #4. Batch Id 187/278  is having validation loss of 1.3611682653427124\n",
            "0.9874688386917114\n",
            "Epoch #4. Batch Id 187/278  is having validation accuracy of 63.663563829787236\n",
            "Epoch #4. Batch Id 188/278  is having validation loss of 1.3628545999526978\n",
            "1.6798946857452393\n",
            "Epoch #4. Batch Id 188/278  is having validation accuracy of 63.6739417989418\n",
            "Epoch #4. Batch Id 189/278  is having validation loss of 1.3604356050491333\n",
            "0.9032467603683472\n",
            "Epoch #4. Batch Id 189/278  is having validation accuracy of 63.75\n",
            "Epoch #4. Batch Id 190/278  is having validation loss of 1.35938560962677\n",
            "1.1598798036575317\n",
            "Epoch #4. Batch Id 190/278  is having validation accuracy of 63.776178010471206\n",
            "Epoch #4. Batch Id 191/278  is having validation loss of 1.3613117933273315\n",
            "1.729204535484314\n",
            "Epoch #4. Batch Id 191/278  is having validation accuracy of 63.753255208333336\n",
            "Epoch #4. Batch Id 192/278  is having validation loss of 1.3612828254699707\n",
            "1.3557114601135254\n",
            "Epoch #4. Batch Id 192/278  is having validation accuracy of 63.69818652849741\n",
            "Epoch #4. Batch Id 193/278  is having validation loss of 1.3614097833633423\n",
            "1.3859210014343262\n",
            "Epoch #4. Batch Id 193/278  is having validation accuracy of 63.65979381443299\n",
            "Epoch #4. Batch Id 194/278  is having validation loss of 1.3614100217819214\n",
            "1.3614609241485596\n",
            "Epoch #4. Batch Id 194/278  is having validation accuracy of 63.62179487179487\n",
            "Epoch #4. Batch Id 195/278  is having validation loss of 1.3616595268249512\n",
            "1.4103190898895264\n",
            "Epoch #4. Batch Id 195/278  is having validation accuracy of 63.55229591836735\n",
            "Epoch #4. Batch Id 196/278  is having validation loss of 1.3617273569107056\n",
            "1.3750228881835938\n",
            "Epoch #4. Batch Id 196/278  is having validation accuracy of 63.546954314720814\n",
            "Epoch #4. Batch Id 197/278  is having validation loss of 1.3614492416381836\n",
            "1.306672215461731\n",
            "Epoch #4. Batch Id 197/278  is having validation accuracy of 63.541666666666664\n",
            "Epoch #4. Batch Id 198/278  is having validation loss of 1.3630067110061646\n",
            "1.6713885068893433\n",
            "Epoch #4. Batch Id 198/278  is having validation accuracy of 63.4893216080402\n",
            "Epoch #4. Batch Id 199/278  is having validation loss of 1.3618381023406982\n",
            "1.1292810440063477\n",
            "Epoch #4. Batch Id 199/278  is having validation accuracy of 63.53125\n",
            "Epoch #4. Batch Id 200/278  is having validation loss of 1.3637371063232422\n",
            "1.7435274124145508\n",
            "Epoch #4. Batch Id 200/278  is having validation accuracy of 63.4794776119403\n",
            "Epoch #4. Batch Id 201/278  is having validation loss of 1.3631712198257446\n",
            "1.249435544013977\n",
            "Epoch #4. Batch Id 201/278  is having validation accuracy of 63.49009900990099\n",
            "Epoch #4. Batch Id 202/278  is having validation loss of 1.360876441001892\n",
            "0.8973414897918701\n",
            "Epoch #4. Batch Id 202/278  is having validation accuracy of 63.54679802955665\n",
            "Epoch #4. Batch Id 203/278  is having validation loss of 1.3607760667800903\n",
            "1.340406060218811\n",
            "Epoch #4. Batch Id 203/278  is having validation accuracy of 63.526348039215684\n",
            "Epoch #4. Batch Id 204/278  is having validation loss of 1.361816167831421\n",
            "1.5739973783493042\n",
            "Epoch #4. Batch Id 204/278  is having validation accuracy of 63.50609756097561\n",
            "Epoch #4. Batch Id 205/278  is having validation loss of 1.3623980283737183\n",
            "1.4816807508468628\n",
            "Epoch #4. Batch Id 205/278  is having validation accuracy of 63.470873786407765\n",
            "Epoch #4. Batch Id 206/278  is having validation loss of 1.3619052171707153\n",
            "1.2603870630264282\n",
            "Epoch #4. Batch Id 206/278  is having validation accuracy of 63.481280193236714\n",
            "Epoch #4. Batch Id 207/278  is having validation loss of 1.3628439903259277\n",
            "1.557170033454895\n",
            "Epoch #4. Batch Id 207/278  is having validation accuracy of 63.44651442307692\n",
            "Epoch #4. Batch Id 208/278  is having validation loss of 1.3636646270751953\n",
            "1.534348487854004\n",
            "Epoch #4. Batch Id 208/278  is having validation accuracy of 63.441985645933016\n",
            "Epoch #4. Batch Id 209/278  is having validation loss of 1.3627599477767944\n",
            "1.1736838817596436\n",
            "Epoch #4. Batch Id 209/278  is having validation accuracy of 63.407738095238095\n",
            "Epoch #4. Batch Id 210/278  is having validation loss of 1.363381028175354\n",
            "1.493818998336792\n",
            "Epoch #4. Batch Id 210/278  is having validation accuracy of 63.433056872037916\n",
            "Epoch #4. Batch Id 211/278  is having validation loss of 1.3626420497894287\n",
            "1.2067211866378784\n",
            "Epoch #4. Batch Id 211/278  is having validation accuracy of 63.458136792452834\n",
            "Epoch #4. Batch Id 212/278  is having validation loss of 1.3625763654708862\n",
            "1.3486605882644653\n",
            "Epoch #4. Batch Id 212/278  is having validation accuracy of 63.48298122065728\n",
            "Epoch #4. Batch Id 213/278  is having validation loss of 1.3624955415725708\n",
            "1.345287561416626\n",
            "Epoch #4. Batch Id 213/278  is having validation accuracy of 63.47838785046729\n",
            "Epoch #4. Batch Id 214/278  is having validation loss of 1.3621739149093628\n",
            "1.2933547496795654\n",
            "Epoch #4. Batch Id 214/278  is having validation accuracy of 63.502906976744185\n",
            "Epoch #4. Batch Id 215/278  is having validation loss of 1.3642089366912842\n",
            "1.8017494678497314\n",
            "Epoch #4. Batch Id 215/278  is having validation accuracy of 63.425925925925924\n",
            "Epoch #4. Batch Id 216/278  is having validation loss of 1.3648126125335693\n",
            "1.4952033758163452\n",
            "Epoch #4. Batch Id 216/278  is having validation accuracy of 63.40725806451613\n",
            "Epoch #4. Batch Id 217/278  is having validation loss of 1.3648546934127808\n",
            "1.3739765882492065\n",
            "Epoch #4. Batch Id 217/278  is having validation accuracy of 63.40309633027523\n",
            "Epoch #4. Batch Id 218/278  is having validation loss of 1.3641366958618164\n",
            "1.2076224088668823\n",
            "Epoch #4. Batch Id 218/278  is having validation accuracy of 63.44178082191781\n",
            "Epoch #4. Batch Id 219/278  is having validation loss of 1.3637986183166504\n",
            "1.2897552251815796\n",
            "Epoch #4. Batch Id 219/278  is having validation accuracy of 63.46590909090909\n",
            "Epoch #4. Batch Id 220/278  is having validation loss of 1.3645069599151611\n",
            "1.5203293561935425\n",
            "Epoch #4. Batch Id 220/278  is having validation accuracy of 63.419117647058826\n",
            "Epoch #4. Batch Id 221/278  is having validation loss of 1.3654520511627197\n",
            "1.5743143558502197\n",
            "Epoch #4. Batch Id 221/278  is having validation accuracy of 63.38682432432432\n",
            "Epoch #4. Batch Id 222/278  is having validation loss of 1.3662008047103882\n",
            "1.5324307680130005\n",
            "Epoch #4. Batch Id 222/278  is having validation accuracy of 63.36883408071749\n",
            "Epoch #4. Batch Id 223/278  is having validation loss of 1.366837501525879\n",
            "1.508820652961731\n",
            "Epoch #4. Batch Id 223/278  is having validation accuracy of 63.28125\n",
            "Epoch #4. Batch Id 224/278  is having validation loss of 1.3674930334091187\n",
            "1.514341115951538\n",
            "Epoch #4. Batch Id 224/278  is having validation accuracy of 63.27777777777778\n",
            "Epoch #4. Batch Id 225/278  is having validation loss of 1.3671985864639282\n",
            "1.3009587526321411\n",
            "Epoch #4. Batch Id 225/278  is having validation accuracy of 63.260508849557525\n",
            "Epoch #4. Batch Id 226/278  is having validation loss of 1.3662817478179932\n",
            "1.159088134765625\n",
            "Epoch #4. Batch Id 226/278  is having validation accuracy of 63.298458149779734\n",
            "Epoch #4. Batch Id 227/278  is having validation loss of 1.3676871061325073\n",
            "1.686708927154541\n",
            "Epoch #4. Batch Id 227/278  is having validation accuracy of 63.28125\n",
            "Epoch #4. Batch Id 228/278  is having validation loss of 1.3702762126922607\n",
            "1.9605920314788818\n",
            "Epoch #4. Batch Id 228/278  is having validation accuracy of 63.23689956331878\n",
            "Epoch #4. Batch Id 229/278  is having validation loss of 1.3693184852600098\n",
            "1.1499916315078735\n",
            "Epoch #4. Batch Id 229/278  is having validation accuracy of 63.233695652173914\n",
            "Epoch #4. Batch Id 230/278  is having validation loss of 1.3689396381378174\n",
            "1.2817984819412231\n",
            "Epoch #4. Batch Id 230/278  is having validation accuracy of 63.24404761904762\n",
            "Epoch #4. Batch Id 231/278  is having validation loss of 1.3701152801513672\n",
            "1.641676902770996\n",
            "Epoch #4. Batch Id 231/278  is having validation accuracy of 63.25431034482759\n",
            "Epoch #4. Batch Id 232/278  is having validation loss of 1.3710087537765503\n",
            "1.5782850980758667\n",
            "Epoch #4. Batch Id 232/278  is having validation accuracy of 63.18401287553648\n",
            "Epoch #4. Batch Id 233/278  is having validation loss of 1.3697463274002075\n",
            "1.0755871534347534\n",
            "Epoch #4. Batch Id 233/278  is having validation accuracy of 63.234508547008545\n",
            "Epoch #4. Batch Id 234/278  is having validation loss of 1.367789387702942\n",
            "0.9098716974258423\n",
            "Epoch #4. Batch Id 234/278  is having validation accuracy of 63.27127659574468\n",
            "Epoch #4. Batch Id 235/278  is having validation loss of 1.3700604438781738\n",
            "1.903772234916687\n",
            "Epoch #4. Batch Id 235/278  is having validation accuracy of 63.22828389830509\n",
            "Epoch #4. Batch Id 236/278  is having validation loss of 1.3696340322494507\n",
            "1.2689905166625977\n",
            "Epoch #4. Batch Id 236/278  is having validation accuracy of 63.23839662447257\n",
            "Epoch #4. Batch Id 237/278  is having validation loss of 1.370190978050232\n",
            "1.5021836757659912\n",
            "Epoch #4. Batch Id 237/278  is having validation accuracy of 63.20903361344538\n",
            "Epoch #4. Batch Id 238/278  is having validation loss of 1.3691327571868896\n",
            "1.1172864437103271\n",
            "Epoch #4. Batch Id 238/278  is having validation accuracy of 63.23221757322176\n",
            "Epoch #4. Batch Id 239/278  is having validation loss of 1.371511697769165\n",
            "1.9400731325149536\n",
            "Epoch #4. Batch Id 239/278  is having validation accuracy of 63.151041666666664\n",
            "Epoch #4. Batch Id 240/278  is having validation loss of 1.3699619770050049\n",
            "0.9980271458625793\n",
            "Epoch #4. Batch Id 240/278  is having validation accuracy of 63.21317427385892\n",
            "Epoch #4. Batch Id 241/278  is having validation loss of 1.3704484701156616\n",
            "1.4876883029937744\n",
            "Epoch #4. Batch Id 241/278  is having validation accuracy of 63.23605371900826\n",
            "Epoch #4. Batch Id 242/278  is having validation loss of 1.370335340499878\n",
            "1.3429628610610962\n",
            "Epoch #4. Batch Id 242/278  is having validation accuracy of 63.27160493827161\n",
            "Epoch #4. Batch Id 243/278  is having validation loss of 1.368915319442749\n",
            "1.0238513946533203\n",
            "Epoch #4. Batch Id 243/278  is having validation accuracy of 63.31967213114754\n",
            "Epoch #4. Batch Id 244/278  is having validation loss of 1.3703298568725586\n",
            "1.7154737710952759\n",
            "Epoch #4. Batch Id 244/278  is having validation accuracy of 63.265306122448976\n",
            "Epoch #4. Batch Id 245/278  is having validation loss of 1.3720881938934326\n",
            "1.802880883216858\n",
            "Epoch #4. Batch Id 245/278  is having validation accuracy of 63.1859756097561\n",
            "Epoch #4. Batch Id 246/278  is having validation loss of 1.3734869956970215\n",
            "1.7175875902175903\n",
            "Epoch #4. Batch Id 246/278  is having validation accuracy of 63.1578947368421\n",
            "Epoch #4. Batch Id 247/278  is having validation loss of 1.3745838403701782\n",
            "1.6455159187316895\n",
            "Epoch #4. Batch Id 247/278  is having validation accuracy of 63.13004032258065\n",
            "Epoch #4. Batch Id 248/278  is having validation loss of 1.375195026397705\n",
            "1.5267550945281982\n",
            "Epoch #4. Batch Id 248/278  is having validation accuracy of 63.102409638554214\n",
            "Epoch #4. Batch Id 249/278  is having validation loss of 1.3742188215255737\n",
            "1.1311571598052979\n",
            "Epoch #4. Batch Id 249/278  is having validation accuracy of 63.15\n",
            "Epoch #4. Batch Id 250/278  is having validation loss of 1.374293565750122\n",
            "1.3929872512817383\n",
            "Epoch #4. Batch Id 250/278  is having validation accuracy of 63.13496015936255\n",
            "Epoch #4. Batch Id 251/278  is having validation loss of 1.3771753311157227\n",
            "2.1004981994628906\n",
            "Epoch #4. Batch Id 251/278  is having validation accuracy of 63.082837301587304\n",
            "Epoch #4. Batch Id 252/278  is having validation loss of 1.3777706623077393\n",
            "1.5277906656265259\n",
            "Epoch #4. Batch Id 252/278  is having validation accuracy of 63.080533596837945\n",
            "Epoch #4. Batch Id 253/278  is having validation loss of 1.3781962394714355\n",
            "1.4858814477920532\n",
            "Epoch #4. Batch Id 253/278  is having validation accuracy of 63.09055118110236\n",
            "Epoch #4. Batch Id 254/278  is having validation loss of 1.376915693283081\n",
            "1.0516636371612549\n",
            "Epoch #4. Batch Id 254/278  is having validation accuracy of 63.14950980392157\n",
            "Epoch #4. Batch Id 255/278  is having validation loss of 1.375602126121521\n",
            "1.0406337976455688\n",
            "Epoch #4. Batch Id 255/278  is having validation accuracy of 63.2080078125\n",
            "Epoch #4. Batch Id 256/278  is having validation loss of 1.3746424913406372\n",
            "1.1289852857589722\n",
            "Epoch #4. Batch Id 256/278  is having validation accuracy of 63.193093385214006\n",
            "Epoch #4. Batch Id 257/278  is having validation loss of 1.3738598823547363\n",
            "1.1727170944213867\n",
            "Epoch #4. Batch Id 257/278  is having validation accuracy of 63.17829457364341\n",
            "Epoch #4. Batch Id 258/278  is having validation loss of 1.3745976686477661\n",
            "1.5649384260177612\n",
            "Epoch #4. Batch Id 258/278  is having validation accuracy of 63.1515444015444\n",
            "Epoch #4. Batch Id 259/278  is having validation loss of 1.3732815980911255\n",
            "1.0324205160140991\n",
            "Epoch #4. Batch Id 259/278  is having validation accuracy of 63.16105769230769\n",
            "Epoch #4. Batch Id 260/278  is having validation loss of 1.3708350658416748\n",
            "0.7347326874732971\n",
            "Epoch #4. Batch Id 260/278  is having validation accuracy of 63.23036398467433\n",
            "Epoch #4. Batch Id 261/278  is having validation loss of 1.3697307109832764\n",
            "1.0815033912658691\n",
            "Epoch #4. Batch Id 261/278  is having validation accuracy of 63.22757633587786\n",
            "Epoch #4. Batch Id 262/278  is having validation loss of 1.371062159538269\n",
            "1.7198971509933472\n",
            "Epoch #4. Batch Id 262/278  is having validation accuracy of 63.18916349809886\n",
            "Epoch #4. Batch Id 263/278  is having validation loss of 1.3713799715042114\n",
            "1.4549634456634521\n",
            "Epoch #4. Batch Id 263/278  is having validation accuracy of 63.18655303030303\n",
            "Epoch #4. Batch Id 264/278  is having validation loss of 1.3698034286499023\n",
            "0.9535869359970093\n",
            "Epoch #4. Batch Id 264/278  is having validation accuracy of 63.25471698113208\n",
            "Epoch #4. Batch Id 265/278  is having validation loss of 1.3704882860183716\n",
            "1.5519769191741943\n",
            "Epoch #4. Batch Id 265/278  is having validation accuracy of 63.24013157894737\n",
            "Epoch #4. Batch Id 266/278  is having validation loss of 1.3699333667755127\n",
            "1.2223113775253296\n",
            "Epoch #4. Batch Id 266/278  is having validation accuracy of 63.27247191011236\n",
            "Epoch #4. Batch Id 267/278  is having validation loss of 1.368567943572998\n",
            "1.003987431526184\n",
            "Epoch #4. Batch Id 267/278  is having validation accuracy of 63.30457089552239\n",
            "Epoch #4. Batch Id 268/278  is having validation loss of 1.3666925430297852\n",
            "0.8640936613082886\n",
            "Epoch #4. Batch Id 268/278  is having validation accuracy of 63.34804832713755\n",
            "Epoch #4. Batch Id 269/278  is having validation loss of 1.3651666641235352\n",
            "0.9547026753425598\n",
            "Epoch #4. Batch Id 269/278  is having validation accuracy of 63.3912037037037\n",
            "Epoch #4. Batch Id 270/278  is having validation loss of 1.3652721643447876\n",
            "1.3937467336654663\n",
            "Epoch #4. Batch Id 270/278  is having validation accuracy of 63.4109778597786\n",
            "Epoch #4. Batch Id 271/278  is having validation loss of 1.3657640218734741\n",
            "1.4990569353103638\n",
            "Epoch #4. Batch Id 271/278  is having validation accuracy of 63.384650735294116\n",
            "Epoch #4. Batch Id 272/278  is having validation loss of 1.3671220541000366\n",
            "1.7364948987960815\n",
            "Epoch #4. Batch Id 272/278  is having validation accuracy of 63.35851648351648\n",
            "Epoch #4. Batch Id 273/278  is having validation loss of 1.3683602809906006\n",
            "1.706380009651184\n",
            "Epoch #4. Batch Id 273/278  is having validation accuracy of 63.309762773722625\n",
            "Epoch #4. Batch Id 274/278  is having validation loss of 1.3676053285598755\n",
            "1.1607401371002197\n",
            "Epoch #4. Batch Id 274/278  is having validation accuracy of 63.32954545454545\n",
            "Epoch #4. Batch Id 275/278  is having validation loss of 1.3688336610794067\n",
            "1.706616997718811\n",
            "Epoch #4. Batch Id 275/278  is having validation accuracy of 63.32653985507246\n",
            "Epoch #4. Batch Id 276/278  is having validation loss of 1.3684625625610352\n",
            "1.2660338878631592\n",
            "Epoch #4. Batch Id 276/278  is having validation accuracy of 63.34611913357401\n",
            "Epoch #4. Batch Id 277/278  is having validation loss of 1.3636431694030762\n",
            "0.02867608517408371\n",
            "Epoch #4. Batch Id 277/278  is having validation accuracy of 63.354387547935936\n",
            "Эпоха #4 train_loss: 1.5146248188102618e-05, val_loss: 0.00015380590048152953\n",
            "Потрачено 25.7 минут на 4 эпоху\n",
            "Batch Id 0/2438 is having training loss of 1.0386673212051392\n",
            "1.0386673212051392\n",
            "Epoch #5. Accuracy on batch 0/2438  on Training is 65.625\n",
            "Epoch #5. Accuracy on batch 1/2438  on Training is 73.4375\n",
            "Epoch #5. Accuracy on batch 2/2438  on Training is 70.83333333333333\n",
            "Epoch #5. Accuracy on batch 3/2438  on Training is 72.65625\n",
            "Epoch #5. Accuracy on batch 4/2438  on Training is 74.375\n",
            "Epoch #5. Accuracy on batch 5/2438  on Training is 73.4375\n",
            "Epoch #5. Accuracy on batch 6/2438  on Training is 71.875\n",
            "Epoch #5. Accuracy on batch 7/2438  on Training is 71.484375\n",
            "Epoch #5. Accuracy on batch 8/2438  on Training is 69.79166666666667\n",
            "Epoch #5. Accuracy on batch 9/2438  on Training is 70.3125\n",
            "Epoch #5. Accuracy on batch 10/2438  on Training is 70.17045454545455\n",
            "Epoch #5. Accuracy on batch 11/2438  on Training is 68.22916666666667\n",
            "Epoch #5. Accuracy on batch 12/2438  on Training is 66.82692307692308\n",
            "Epoch #5. Accuracy on batch 13/2438  on Training is 67.41071428571429\n",
            "Epoch #5. Accuracy on batch 14/2438  on Training is 66.66666666666667\n",
            "Epoch #5. Accuracy on batch 15/2438  on Training is 66.40625\n",
            "Epoch #5. Accuracy on batch 16/2438  on Training is 65.80882352941177\n",
            "Epoch #5. Accuracy on batch 17/2438  on Training is 65.97222222222223\n",
            "Epoch #5. Accuracy on batch 18/2438  on Training is 66.77631578947368\n",
            "Epoch #5. Accuracy on batch 19/2438  on Training is 66.71875\n",
            "Batch Id 20/2438 is having training loss of 1.2432962656021118\n",
            "1.4058798551559448\n",
            "Epoch #5. Accuracy on batch 20/2438  on Training is 66.51785714285714\n",
            "Epoch #5. Accuracy on batch 21/2438  on Training is 66.47727272727273\n",
            "Epoch #5. Accuracy on batch 22/2438  on Training is 65.76086956521739\n",
            "Epoch #5. Accuracy on batch 23/2438  on Training is 65.75520833333333\n",
            "Epoch #5. Accuracy on batch 24/2438  on Training is 66.0\n",
            "Epoch #5. Accuracy on batch 25/2438  on Training is 66.46634615384616\n",
            "Epoch #5. Accuracy on batch 26/2438  on Training is 66.43518518518519\n",
            "Epoch #5. Accuracy on batch 27/2438  on Training is 67.1875\n",
            "Epoch #5. Accuracy on batch 28/2438  on Training is 67.13362068965517\n",
            "Epoch #5. Accuracy on batch 29/2438  on Training is 67.29166666666667\n",
            "Epoch #5. Accuracy on batch 30/2438  on Training is 67.33870967741936\n",
            "Epoch #5. Accuracy on batch 31/2438  on Training is 67.28515625\n",
            "Epoch #5. Accuracy on batch 32/2438  on Training is 67.23484848484848\n",
            "Epoch #5. Accuracy on batch 33/2438  on Training is 67.00367647058823\n",
            "Epoch #5. Accuracy on batch 34/2438  on Training is 67.05357142857143\n",
            "Epoch #5. Accuracy on batch 35/2438  on Training is 66.75347222222223\n",
            "Epoch #5. Accuracy on batch 36/2438  on Training is 67.14527027027027\n",
            "Epoch #5. Accuracy on batch 37/2438  on Training is 67.4342105263158\n",
            "Epoch #5. Accuracy on batch 38/2438  on Training is 67.38782051282051\n",
            "Epoch #5. Accuracy on batch 39/2438  on Training is 67.34375\n",
            "Batch Id 40/2438 is having training loss of 1.1906485557556152\n",
            "1.0022720098495483\n",
            "Epoch #5. Accuracy on batch 40/2438  on Training is 67.45426829268293\n",
            "Epoch #5. Accuracy on batch 41/2438  on Training is 67.63392857142857\n",
            "Epoch #5. Accuracy on batch 42/2438  on Training is 67.44186046511628\n",
            "Epoch #5. Accuracy on batch 43/2438  on Training is 67.54261363636364\n",
            "Epoch #5. Accuracy on batch 44/2438  on Training is 67.63888888888889\n",
            "Epoch #5. Accuracy on batch 45/2438  on Training is 67.79891304347827\n",
            "Epoch #5. Accuracy on batch 46/2438  on Training is 67.75265957446808\n",
            "Epoch #5. Accuracy on batch 47/2438  on Training is 67.7734375\n",
            "Epoch #5. Accuracy on batch 48/2438  on Training is 67.60204081632654\n",
            "Epoch #5. Accuracy on batch 49/2438  on Training is 67.5625\n",
            "Epoch #5. Accuracy on batch 50/2438  on Training is 67.58578431372548\n",
            "Epoch #5. Accuracy on batch 51/2438  on Training is 67.78846153846153\n",
            "Epoch #5. Accuracy on batch 52/2438  on Training is 67.80660377358491\n",
            "Epoch #5. Accuracy on batch 53/2438  on Training is 67.53472222222223\n",
            "Epoch #5. Accuracy on batch 54/2438  on Training is 67.55681818181819\n",
            "Epoch #5. Accuracy on batch 55/2438  on Training is 67.578125\n",
            "Epoch #5. Accuracy on batch 56/2438  on Training is 67.59868421052632\n",
            "Epoch #5. Accuracy on batch 57/2438  on Training is 67.5646551724138\n",
            "Epoch #5. Accuracy on batch 58/2438  on Training is 67.47881355932203\n",
            "Epoch #5. Accuracy on batch 59/2438  on Training is 67.1875\n",
            "Batch Id 60/2438 is having training loss of 1.192295789718628\n",
            "1.4145644903182983\n",
            "Epoch #5. Accuracy on batch 60/2438  on Training is 67.11065573770492\n",
            "Epoch #5. Accuracy on batch 61/2438  on Training is 66.98588709677419\n",
            "Epoch #5. Accuracy on batch 62/2438  on Training is 67.01388888888889\n",
            "Epoch #5. Accuracy on batch 63/2438  on Training is 67.138671875\n",
            "Epoch #5. Accuracy on batch 64/2438  on Training is 67.16346153846153\n",
            "Epoch #5. Accuracy on batch 65/2438  on Training is 67.14015151515152\n",
            "Epoch #5. Accuracy on batch 66/2438  on Training is 67.07089552238806\n",
            "Epoch #5. Accuracy on batch 67/2438  on Training is 67.00367647058823\n",
            "Epoch #5. Accuracy on batch 68/2438  on Training is 67.07427536231884\n",
            "Epoch #5. Accuracy on batch 69/2438  on Training is 67.14285714285714\n",
            "Epoch #5. Accuracy on batch 70/2438  on Training is 67.16549295774648\n",
            "Epoch #5. Accuracy on batch 71/2438  on Training is 67.1875\n",
            "Epoch #5. Accuracy on batch 72/2438  on Training is 67.16609589041096\n",
            "Epoch #5. Accuracy on batch 73/2438  on Training is 67.01858108108108\n",
            "Epoch #5. Accuracy on batch 74/2438  on Training is 67.20833333333333\n",
            "Epoch #5. Accuracy on batch 75/2438  on Training is 67.31085526315789\n",
            "Epoch #5. Accuracy on batch 76/2438  on Training is 67.41071428571429\n",
            "Epoch #5. Accuracy on batch 77/2438  on Training is 67.2676282051282\n",
            "Epoch #5. Accuracy on batch 78/2438  on Training is 67.16772151898734\n",
            "Epoch #5. Accuracy on batch 79/2438  on Training is 67.109375\n",
            "Batch Id 80/2438 is having training loss of 1.2013061046600342\n",
            "1.4179227352142334\n",
            "Epoch #5. Accuracy on batch 80/2438  on Training is 67.12962962962963\n",
            "Epoch #5. Accuracy on batch 81/2438  on Training is 67.11128048780488\n",
            "Epoch #5. Accuracy on batch 82/2438  on Training is 67.16867469879519\n",
            "Epoch #5. Accuracy on batch 83/2438  on Training is 67.33630952380952\n",
            "Epoch #5. Accuracy on batch 84/2438  on Training is 67.46323529411765\n",
            "Epoch #5. Accuracy on batch 85/2438  on Training is 67.40552325581395\n",
            "Epoch #5. Accuracy on batch 86/2438  on Training is 67.38505747126437\n",
            "Epoch #5. Accuracy on batch 87/2438  on Training is 67.36505681818181\n",
            "Epoch #5. Accuracy on batch 88/2438  on Training is 67.41573033707866\n",
            "Epoch #5. Accuracy on batch 89/2438  on Training is 67.32638888888889\n",
            "Epoch #5. Accuracy on batch 90/2438  on Training is 67.3076923076923\n",
            "Epoch #5. Accuracy on batch 91/2438  on Training is 67.2554347826087\n",
            "Epoch #5. Accuracy on batch 92/2438  on Training is 67.43951612903226\n",
            "Epoch #5. Accuracy on batch 93/2438  on Training is 67.48670212765957\n",
            "Epoch #5. Accuracy on batch 94/2438  on Training is 67.40131578947368\n",
            "Epoch #5. Accuracy on batch 95/2438  on Training is 67.3828125\n",
            "Epoch #5. Accuracy on batch 96/2438  on Training is 67.42912371134021\n",
            "Epoch #5. Accuracy on batch 97/2438  on Training is 67.5063775510204\n",
            "Epoch #5. Accuracy on batch 98/2438  on Training is 67.58207070707071\n",
            "Epoch #5. Accuracy on batch 99/2438  on Training is 67.625\n",
            "Batch Id 100/2438 is having training loss of 1.178508996963501\n",
            "1.193235158920288\n",
            "Epoch #5. Accuracy on batch 100/2438  on Training is 67.6980198019802\n",
            "Epoch #5. Accuracy on batch 101/2438  on Training is 67.70833333333333\n",
            "Epoch #5. Accuracy on batch 102/2438  on Training is 67.71844660194175\n",
            "Epoch #5. Accuracy on batch 103/2438  on Training is 67.78846153846153\n",
            "Epoch #5. Accuracy on batch 104/2438  on Training is 67.64880952380952\n",
            "Epoch #5. Accuracy on batch 105/2438  on Training is 67.57075471698113\n",
            "Epoch #5. Accuracy on batch 106/2438  on Training is 67.64018691588785\n",
            "Epoch #5. Accuracy on batch 107/2438  on Training is 67.65046296296296\n",
            "Epoch #5. Accuracy on batch 108/2438  on Training is 67.63188073394495\n",
            "Epoch #5. Accuracy on batch 109/2438  on Training is 67.64204545454545\n",
            "Epoch #5. Accuracy on batch 110/2438  on Training is 67.59572072072072\n",
            "Epoch #5. Accuracy on batch 111/2438  on Training is 67.578125\n",
            "Epoch #5. Accuracy on batch 112/2438  on Training is 67.67146017699115\n",
            "Epoch #5. Accuracy on batch 113/2438  on Training is 67.59868421052632\n",
            "Epoch #5. Accuracy on batch 114/2438  on Training is 67.77173913043478\n",
            "Epoch #5. Accuracy on batch 115/2438  on Training is 67.78017241379311\n",
            "Epoch #5. Accuracy on batch 116/2438  on Training is 67.86858974358974\n",
            "Epoch #5. Accuracy on batch 117/2438  on Training is 67.84957627118644\n",
            "Epoch #5. Accuracy on batch 118/2438  on Training is 67.8046218487395\n",
            "Epoch #5. Accuracy on batch 119/2438  on Training is 67.76041666666667\n",
            "Batch Id 120/2438 is having training loss of 1.170145869255066\n",
            "0.9863009452819824\n",
            "Epoch #5. Accuracy on batch 120/2438  on Training is 67.7944214876033\n",
            "Epoch #5. Accuracy on batch 121/2438  on Training is 67.82786885245902\n",
            "Epoch #5. Accuracy on batch 122/2438  on Training is 67.83536585365853\n",
            "Epoch #5. Accuracy on batch 123/2438  on Training is 67.79233870967742\n",
            "Epoch #5. Accuracy on batch 124/2438  on Training is 67.875\n",
            "Epoch #5. Accuracy on batch 125/2438  on Training is 67.7579365079365\n",
            "Epoch #5. Accuracy on batch 126/2438  on Training is 67.79035433070867\n",
            "Epoch #5. Accuracy on batch 127/2438  on Training is 67.67578125\n",
            "Epoch #5. Accuracy on batch 128/2438  on Training is 67.56298449612403\n",
            "Epoch #5. Accuracy on batch 129/2438  on Training is 67.59615384615384\n",
            "Epoch #5. Accuracy on batch 130/2438  on Training is 67.55725190839695\n",
            "Epoch #5. Accuracy on batch 131/2438  on Training is 67.56628787878788\n",
            "Epoch #5. Accuracy on batch 132/2438  on Training is 67.55169172932331\n",
            "Epoch #5. Accuracy on batch 133/2438  on Training is 67.63059701492537\n",
            "Epoch #5. Accuracy on batch 134/2438  on Training is 67.5925925925926\n",
            "Epoch #5. Accuracy on batch 135/2438  on Training is 67.67003676470588\n",
            "Epoch #5. Accuracy on batch 136/2438  on Training is 67.63229927007299\n",
            "Epoch #5. Accuracy on batch 137/2438  on Training is 67.6177536231884\n",
            "Epoch #5. Accuracy on batch 138/2438  on Training is 67.73830935251799\n",
            "Epoch #5. Accuracy on batch 139/2438  on Training is 67.76785714285714\n",
            "Batch Id 140/2438 is having training loss of 1.1751495599746704\n",
            "1.3459298610687256\n",
            "Epoch #5. Accuracy on batch 140/2438  on Training is 67.73049645390071\n",
            "Epoch #5. Accuracy on batch 141/2438  on Training is 67.73767605633803\n",
            "Epoch #5. Accuracy on batch 142/2438  on Training is 67.81031468531468\n",
            "Epoch #5. Accuracy on batch 143/2438  on Training is 67.81684027777777\n",
            "Epoch #5. Accuracy on batch 144/2438  on Training is 67.73706896551724\n",
            "Epoch #5. Accuracy on batch 145/2438  on Training is 67.78681506849315\n",
            "Epoch #5. Accuracy on batch 146/2438  on Training is 67.85714285714286\n",
            "Epoch #5. Accuracy on batch 147/2438  on Training is 67.92652027027027\n",
            "Epoch #5. Accuracy on batch 148/2438  on Training is 68.03691275167785\n",
            "Epoch #5. Accuracy on batch 149/2438  on Training is 68.14583333333333\n",
            "Epoch #5. Accuracy on batch 150/2438  on Training is 68.1498344370861\n",
            "Epoch #5. Accuracy on batch 151/2438  on Training is 68.17434210526316\n",
            "Epoch #5. Accuracy on batch 152/2438  on Training is 68.11683006535948\n",
            "Epoch #5. Accuracy on batch 153/2438  on Training is 68.14123376623377\n",
            "Epoch #5. Accuracy on batch 154/2438  on Training is 68.125\n",
            "Epoch #5. Accuracy on batch 155/2438  on Training is 68.02884615384616\n",
            "Epoch #5. Accuracy on batch 156/2438  on Training is 68.01353503184713\n",
            "Epoch #5. Accuracy on batch 157/2438  on Training is 68.05775316455696\n",
            "Epoch #5. Accuracy on batch 158/2438  on Training is 68.10141509433963\n",
            "Epoch #5. Accuracy on batch 159/2438  on Training is 68.14453125\n",
            "Batch Id 160/2438 is having training loss of 1.157953143119812\n",
            "0.861117959022522\n",
            "Epoch #5. Accuracy on batch 160/2438  on Training is 68.24534161490683\n",
            "Epoch #5. Accuracy on batch 161/2438  on Training is 68.19058641975309\n",
            "Epoch #5. Accuracy on batch 162/2438  on Training is 68.23236196319019\n",
            "Epoch #5. Accuracy on batch 163/2438  on Training is 68.2736280487805\n",
            "Epoch #5. Accuracy on batch 164/2438  on Training is 68.27651515151516\n",
            "Epoch #5. Accuracy on batch 165/2438  on Training is 68.2605421686747\n",
            "Epoch #5. Accuracy on batch 166/2438  on Training is 68.26347305389221\n",
            "Epoch #5. Accuracy on batch 167/2438  on Training is 68.1547619047619\n",
            "Epoch #5. Accuracy on batch 168/2438  on Training is 68.15828402366864\n",
            "Epoch #5. Accuracy on batch 169/2438  on Training is 68.10661764705883\n",
            "Epoch #5. Accuracy on batch 170/2438  on Training is 68.09210526315789\n",
            "Epoch #5. Accuracy on batch 171/2438  on Training is 68.09593023255815\n",
            "Epoch #5. Accuracy on batch 172/2438  on Training is 68.17196531791907\n",
            "Epoch #5. Accuracy on batch 173/2438  on Training is 68.22916666666667\n",
            "Epoch #5. Accuracy on batch 174/2438  on Training is 68.26785714285714\n",
            "Epoch #5. Accuracy on batch 175/2438  on Training is 68.2528409090909\n",
            "Epoch #5. Accuracy on batch 176/2438  on Training is 68.23799435028249\n",
            "Epoch #5. Accuracy on batch 177/2438  on Training is 68.2935393258427\n",
            "Epoch #5. Accuracy on batch 178/2438  on Training is 68.2786312849162\n",
            "Epoch #5. Accuracy on batch 179/2438  on Training is 68.24652777777777\n",
            "Batch Id 180/2438 is having training loss of 1.1489112377166748\n",
            "0.9069005250930786\n",
            "Epoch #5. Accuracy on batch 180/2438  on Training is 68.23204419889503\n",
            "Epoch #5. Accuracy on batch 181/2438  on Training is 68.32074175824175\n",
            "Epoch #5. Accuracy on batch 182/2438  on Training is 68.3743169398907\n",
            "Epoch #5. Accuracy on batch 183/2438  on Training is 68.359375\n",
            "Epoch #5. Accuracy on batch 184/2438  on Training is 68.36148648648648\n",
            "Epoch #5. Accuracy on batch 185/2438  on Training is 68.39717741935483\n",
            "Epoch #5. Accuracy on batch 186/2438  on Training is 68.3322192513369\n",
            "Epoch #5. Accuracy on batch 187/2438  on Training is 68.30119680851064\n",
            "Epoch #5. Accuracy on batch 188/2438  on Training is 68.25396825396825\n",
            "Epoch #5. Accuracy on batch 189/2438  on Training is 68.27302631578948\n",
            "Epoch #5. Accuracy on batch 190/2438  on Training is 68.27552356020942\n",
            "Epoch #5. Accuracy on batch 191/2438  on Training is 68.24544270833333\n",
            "Epoch #5. Accuracy on batch 192/2438  on Training is 68.26424870466322\n",
            "Epoch #5. Accuracy on batch 193/2438  on Training is 68.23453608247422\n",
            "Epoch #5. Accuracy on batch 194/2438  on Training is 68.22115384615384\n",
            "Epoch #5. Accuracy on batch 195/2438  on Training is 68.25573979591837\n",
            "Epoch #5. Accuracy on batch 196/2438  on Training is 68.21065989847716\n",
            "Epoch #5. Accuracy on batch 197/2438  on Training is 68.16603535353535\n",
            "Epoch #5. Accuracy on batch 198/2438  on Training is 68.15326633165829\n",
            "Epoch #5. Accuracy on batch 199/2438  on Training is 68.140625\n",
            "Batch Id 200/2438 is having training loss of 1.1502026319503784\n",
            "0.9785877466201782\n",
            "Epoch #5. Accuracy on batch 200/2438  on Training is 68.20584577114428\n",
            "Epoch #5. Accuracy on batch 201/2438  on Training is 68.2549504950495\n",
            "Epoch #5. Accuracy on batch 202/2438  on Training is 68.30357142857143\n",
            "Epoch #5. Accuracy on batch 203/2438  on Training is 68.25980392156863\n",
            "Epoch #5. Accuracy on batch 204/2438  on Training is 68.27743902439025\n",
            "Epoch #5. Accuracy on batch 205/2438  on Training is 68.3252427184466\n",
            "Epoch #5. Accuracy on batch 206/2438  on Training is 68.32729468599034\n",
            "Epoch #5. Accuracy on batch 207/2438  on Training is 68.32932692307692\n",
            "Epoch #5. Accuracy on batch 208/2438  on Training is 68.34629186602871\n",
            "Epoch #5. Accuracy on batch 209/2438  on Training is 68.4077380952381\n",
            "Epoch #5. Accuracy on batch 210/2438  on Training is 68.42417061611374\n",
            "Epoch #5. Accuracy on batch 211/2438  on Training is 68.36674528301887\n",
            "Epoch #5. Accuracy on batch 212/2438  on Training is 68.33920187793427\n",
            "Epoch #5. Accuracy on batch 213/2438  on Training is 68.3411214953271\n",
            "Epoch #5. Accuracy on batch 214/2438  on Training is 68.35755813953489\n",
            "Epoch #5. Accuracy on batch 215/2438  on Training is 68.359375\n",
            "Epoch #5. Accuracy on batch 216/2438  on Training is 68.31797235023042\n",
            "Epoch #5. Accuracy on batch 217/2438  on Training is 68.36295871559633\n",
            "Epoch #5. Accuracy on batch 218/2438  on Training is 68.42180365296804\n",
            "Epoch #5. Accuracy on batch 219/2438  on Training is 68.45170454545455\n",
            "Batch Id 220/2438 is having training loss of 1.1422538757324219\n",
            "0.9709221720695496\n",
            "Epoch #5. Accuracy on batch 220/2438  on Training is 68.49547511312217\n",
            "Epoch #5. Accuracy on batch 221/2438  on Training is 68.44031531531532\n",
            "Epoch #5. Accuracy on batch 222/2438  on Training is 68.45571748878923\n",
            "Epoch #5. Accuracy on batch 223/2438  on Training is 68.45703125\n",
            "Epoch #5. Accuracy on batch 224/2438  on Training is 68.51388888888889\n",
            "Epoch #5. Accuracy on batch 225/2438  on Training is 68.50110619469027\n",
            "Epoch #5. Accuracy on batch 226/2438  on Training is 68.51596916299559\n",
            "Epoch #5. Accuracy on batch 227/2438  on Training is 68.46217105263158\n",
            "Epoch #5. Accuracy on batch 228/2438  on Training is 68.49072052401746\n",
            "Epoch #5. Accuracy on batch 229/2438  on Training is 68.45108695652173\n",
            "Epoch #5. Accuracy on batch 230/2438  on Training is 68.49296536796537\n",
            "Epoch #5. Accuracy on batch 231/2438  on Training is 68.48060344827586\n",
            "Epoch #5. Accuracy on batch 232/2438  on Training is 68.5219957081545\n",
            "Epoch #5. Accuracy on batch 233/2438  on Training is 68.5630341880342\n",
            "Epoch #5. Accuracy on batch 234/2438  on Training is 68.55053191489361\n",
            "Epoch #5. Accuracy on batch 235/2438  on Training is 68.53813559322033\n",
            "Epoch #5. Accuracy on batch 236/2438  on Training is 68.59177215189874\n",
            "Epoch #5. Accuracy on batch 237/2438  on Training is 68.63182773109244\n",
            "Epoch #5. Accuracy on batch 238/2438  on Training is 68.65847280334728\n",
            "Epoch #5. Accuracy on batch 239/2438  on Training is 68.64583333333333\n",
            "Batch Id 240/2438 is having training loss of 1.1410205364227295\n",
            "1.5462369918823242\n",
            "Epoch #5. Accuracy on batch 240/2438  on Training is 68.59439834024896\n",
            "Epoch #5. Accuracy on batch 241/2438  on Training is 68.64669421487604\n",
            "Epoch #5. Accuracy on batch 242/2438  on Training is 68.65997942386831\n",
            "Epoch #5. Accuracy on batch 243/2438  on Training is 68.69877049180327\n",
            "Epoch #5. Accuracy on batch 244/2438  on Training is 68.72448979591837\n",
            "Epoch #5. Accuracy on batch 245/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 246/2438  on Training is 68.6993927125506\n",
            "Epoch #5. Accuracy on batch 247/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 248/2438  on Training is 68.72489959839358\n",
            "Epoch #5. Accuracy on batch 249/2438  on Training is 68.675\n",
            "Epoch #5. Accuracy on batch 250/2438  on Training is 68.67529880478088\n",
            "Epoch #5. Accuracy on batch 251/2438  on Training is 68.67559523809524\n",
            "Epoch #5. Accuracy on batch 252/2438  on Training is 68.63883399209486\n",
            "Epoch #5. Accuracy on batch 253/2438  on Training is 68.61466535433071\n",
            "Epoch #5. Accuracy on batch 254/2438  on Training is 68.57843137254902\n",
            "Epoch #5. Accuracy on batch 255/2438  on Training is 68.61572265625\n",
            "Epoch #5. Accuracy on batch 256/2438  on Training is 68.60408560311284\n",
            "Epoch #5. Accuracy on batch 257/2438  on Training is 68.64098837209302\n",
            "Epoch #5. Accuracy on batch 258/2438  on Training is 68.62934362934362\n",
            "Epoch #5. Accuracy on batch 259/2438  on Training is 68.61778846153847\n",
            "Batch Id 260/2438 is having training loss of 1.138087511062622\n",
            "0.8882653117179871\n",
            "Epoch #5. Accuracy on batch 260/2438  on Training is 68.6661877394636\n",
            "Epoch #5. Accuracy on batch 261/2438  on Training is 68.70229007633588\n",
            "Epoch #5. Accuracy on batch 262/2438  on Training is 68.70247148288973\n",
            "Epoch #5. Accuracy on batch 263/2438  on Training is 68.69081439393939\n",
            "Epoch #5. Accuracy on batch 264/2438  on Training is 68.67924528301887\n",
            "Epoch #5. Accuracy on batch 265/2438  on Training is 68.7265037593985\n",
            "Epoch #5. Accuracy on batch 266/2438  on Training is 68.72659176029963\n",
            "Epoch #5. Accuracy on batch 267/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 268/2438  on Training is 68.76161710037175\n",
            "Epoch #5. Accuracy on batch 269/2438  on Training is 68.77314814814815\n",
            "Epoch #5. Accuracy on batch 270/2438  on Training is 68.73846863468634\n",
            "Epoch #5. Accuracy on batch 271/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 272/2438  on Training is 68.77289377289377\n",
            "Epoch #5. Accuracy on batch 273/2438  on Training is 68.7956204379562\n",
            "Epoch #5. Accuracy on batch 274/2438  on Training is 68.80681818181819\n",
            "Epoch #5. Accuracy on batch 275/2438  on Training is 68.86322463768116\n",
            "Epoch #5. Accuracy on batch 276/2438  on Training is 68.87409747292419\n",
            "Epoch #5. Accuracy on batch 277/2438  on Training is 68.88489208633094\n",
            "Epoch #5. Accuracy on batch 278/2438  on Training is 68.91801075268818\n",
            "Epoch #5. Accuracy on batch 279/2438  on Training is 68.89508928571429\n",
            "Batch Id 280/2438 is having training loss of 1.1320630311965942\n",
            "1.032475233078003\n",
            "Epoch #5. Accuracy on batch 280/2438  on Training is 68.93905693950178\n",
            "Epoch #5. Accuracy on batch 281/2438  on Training is 68.96054964539007\n",
            "Epoch #5. Accuracy on batch 282/2438  on Training is 69.01501766784452\n",
            "Epoch #5. Accuracy on batch 283/2438  on Training is 69.02508802816901\n",
            "Epoch #5. Accuracy on batch 284/2438  on Training is 69.04605263157895\n",
            "Epoch #5. Accuracy on batch 285/2438  on Training is 69.06687062937063\n",
            "Epoch #5. Accuracy on batch 286/2438  on Training is 69.06576655052265\n",
            "Epoch #5. Accuracy on batch 287/2438  on Training is 69.06467013888889\n",
            "Epoch #5. Accuracy on batch 288/2438  on Training is 69.09602076124567\n",
            "Epoch #5. Accuracy on batch 289/2438  on Training is 69.08405172413794\n",
            "Epoch #5. Accuracy on batch 290/2438  on Training is 69.08290378006873\n",
            "Epoch #5. Accuracy on batch 291/2438  on Training is 69.09246575342466\n",
            "Epoch #5. Accuracy on batch 292/2438  on Training is 69.08063139931741\n",
            "Epoch #5. Accuracy on batch 293/2438  on Training is 69.09013605442176\n",
            "Epoch #5. Accuracy on batch 294/2438  on Training is 69.09957627118644\n",
            "Epoch #5. Accuracy on batch 295/2438  on Training is 69.06672297297297\n",
            "Epoch #5. Accuracy on batch 296/2438  on Training is 69.05513468013469\n",
            "Epoch #5. Accuracy on batch 297/2438  on Training is 69.0121644295302\n",
            "Epoch #5. Accuracy on batch 298/2438  on Training is 68.99038461538461\n",
            "Epoch #5. Accuracy on batch 299/2438  on Training is 68.94791666666667\n",
            "Batch Id 300/2438 is having training loss of 1.1308934688568115\n",
            "1.2483989000320435\n",
            "Epoch #5. Accuracy on batch 300/2438  on Training is 68.93687707641196\n",
            "Epoch #5. Accuracy on batch 301/2438  on Training is 68.92591059602648\n",
            "Epoch #5. Accuracy on batch 302/2438  on Training is 68.90470297029702\n",
            "Epoch #5. Accuracy on batch 303/2438  on Training is 68.8939144736842\n",
            "Epoch #5. Accuracy on batch 304/2438  on Training is 68.95491803278688\n",
            "Epoch #5. Accuracy on batch 305/2438  on Training is 68.96446078431373\n",
            "Epoch #5. Accuracy on batch 306/2438  on Training is 68.93322475570032\n",
            "Epoch #5. Accuracy on batch 307/2438  on Training is 68.89204545454545\n",
            "Epoch #5. Accuracy on batch 308/2438  on Training is 68.93203883495146\n",
            "Epoch #5. Accuracy on batch 309/2438  on Training is 68.91129032258064\n",
            "Epoch #5. Accuracy on batch 310/2438  on Training is 68.85048231511254\n",
            "Epoch #5. Accuracy on batch 311/2438  on Training is 68.84014423076923\n",
            "Epoch #5. Accuracy on batch 312/2438  on Training is 68.82987220447285\n",
            "Epoch #5. Accuracy on batch 313/2438  on Training is 68.79976114649682\n",
            "Epoch #5. Accuracy on batch 314/2438  on Training is 68.78968253968254\n",
            "Epoch #5. Accuracy on batch 315/2438  on Training is 68.79944620253164\n",
            "Epoch #5. Accuracy on batch 316/2438  on Training is 68.77957413249212\n",
            "Epoch #5. Accuracy on batch 317/2438  on Training is 68.80896226415095\n",
            "Epoch #5. Accuracy on batch 318/2438  on Training is 68.83816614420063\n",
            "Epoch #5. Accuracy on batch 319/2438  on Training is 68.818359375\n",
            "Batch Id 320/2438 is having training loss of 1.1354334354400635\n",
            "1.2575668096542358\n",
            "Epoch #5. Accuracy on batch 320/2438  on Training is 68.77920560747664\n",
            "Epoch #5. Accuracy on batch 321/2438  on Training is 68.8373447204969\n",
            "Epoch #5. Accuracy on batch 322/2438  on Training is 68.86609907120743\n",
            "Epoch #5. Accuracy on batch 323/2438  on Training is 68.90432098765432\n",
            "Epoch #5. Accuracy on batch 324/2438  on Training is 68.90384615384616\n",
            "Epoch #5. Accuracy on batch 325/2438  on Training is 68.94171779141104\n",
            "Epoch #5. Accuracy on batch 326/2438  on Training is 68.96980122324159\n",
            "Epoch #5. Accuracy on batch 327/2438  on Training is 68.97865853658537\n",
            "Epoch #5. Accuracy on batch 328/2438  on Training is 68.98746200607903\n",
            "Epoch #5. Accuracy on batch 329/2438  on Training is 69.00568181818181\n",
            "Epoch #5. Accuracy on batch 330/2438  on Training is 69.00490936555892\n",
            "Epoch #5. Accuracy on batch 331/2438  on Training is 69.01355421686748\n",
            "Epoch #5. Accuracy on batch 332/2438  on Training is 68.97522522522523\n",
            "Epoch #5. Accuracy on batch 333/2438  on Training is 68.96519461077844\n",
            "Epoch #5. Accuracy on batch 334/2438  on Training is 68.98320895522389\n",
            "Epoch #5. Accuracy on batch 335/2438  on Training is 68.99181547619048\n",
            "Epoch #5. Accuracy on batch 336/2438  on Training is 69.0003709198813\n",
            "Epoch #5. Accuracy on batch 337/2438  on Training is 68.99038461538461\n",
            "Epoch #5. Accuracy on batch 338/2438  on Training is 68.99889380530973\n",
            "Epoch #5. Accuracy on batch 339/2438  on Training is 69.01654411764706\n",
            "Batch Id 340/2438 is having training loss of 1.1306630373001099\n",
            "1.0394601821899414\n",
            "Epoch #5. Accuracy on batch 340/2438  on Training is 69.01576246334311\n",
            "Epoch #5. Accuracy on batch 341/2438  on Training is 68.9967105263158\n",
            "Epoch #5. Accuracy on batch 342/2438  on Training is 68.9868804664723\n",
            "Epoch #5. Accuracy on batch 343/2438  on Training is 68.97710755813954\n",
            "Epoch #5. Accuracy on batch 344/2438  on Training is 68.91304347826087\n",
            "Epoch #5. Accuracy on batch 345/2438  on Training is 68.91257225433526\n",
            "Epoch #5. Accuracy on batch 346/2438  on Training is 68.93011527377521\n",
            "Epoch #5. Accuracy on batch 347/2438  on Training is 68.94755747126437\n",
            "Epoch #5. Accuracy on batch 348/2438  on Training is 68.97385386819484\n",
            "Epoch #5. Accuracy on batch 349/2438  on Training is 69.00892857142857\n",
            "Epoch #5. Accuracy on batch 350/2438  on Training is 69.00819088319088\n",
            "Epoch #5. Accuracy on batch 351/2438  on Training is 68.99857954545455\n",
            "Epoch #5. Accuracy on batch 352/2438  on Training is 68.98902266288952\n",
            "Epoch #5. Accuracy on batch 353/2438  on Training is 68.9795197740113\n",
            "Epoch #5. Accuracy on batch 354/2438  on Training is 68.97887323943662\n",
            "Epoch #5. Accuracy on batch 355/2438  on Training is 68.9255617977528\n",
            "Epoch #5. Accuracy on batch 356/2438  on Training is 68.94257703081233\n",
            "Epoch #5. Accuracy on batch 357/2438  on Training is 68.92458100558659\n",
            "Epoch #5. Accuracy on batch 358/2438  on Training is 68.9240947075209\n",
            "Epoch #5. Accuracy on batch 359/2438  on Training is 68.96701388888889\n",
            "Batch Id 360/2438 is having training loss of 1.1331157684326172\n",
            "1.0849409103393555\n",
            "Epoch #5. Accuracy on batch 360/2438  on Training is 68.96641274238227\n",
            "Epoch #5. Accuracy on batch 361/2438  on Training is 68.99171270718232\n",
            "Epoch #5. Accuracy on batch 362/2438  on Training is 68.98243801652893\n",
            "Epoch #5. Accuracy on batch 363/2438  on Training is 69.00755494505495\n",
            "Epoch #5. Accuracy on batch 364/2438  on Training is 68.98972602739725\n",
            "Epoch #5. Accuracy on batch 365/2438  on Training is 68.96345628415301\n",
            "Epoch #5. Accuracy on batch 366/2438  on Training is 68.9458446866485\n",
            "Epoch #5. Accuracy on batch 367/2438  on Training is 68.90285326086956\n",
            "Epoch #5. Accuracy on batch 368/2438  on Training is 68.8939701897019\n",
            "Epoch #5. Accuracy on batch 369/2438  on Training is 68.89358108108108\n",
            "Epoch #5. Accuracy on batch 370/2438  on Training is 68.89319407008087\n",
            "Epoch #5. Accuracy on batch 371/2438  on Training is 68.90961021505376\n",
            "Epoch #5. Accuracy on batch 372/2438  on Training is 68.91756032171581\n",
            "Epoch #5. Accuracy on batch 373/2438  on Training is 68.89204545454545\n",
            "Epoch #5. Accuracy on batch 374/2438  on Training is 68.88333333333334\n",
            "Epoch #5. Accuracy on batch 375/2438  on Training is 68.8497340425532\n",
            "Epoch #5. Accuracy on batch 376/2438  on Training is 68.88262599469496\n",
            "Epoch #5. Accuracy on batch 377/2438  on Training is 68.88227513227513\n",
            "Epoch #5. Accuracy on batch 378/2438  on Training is 68.88192612137203\n",
            "Epoch #5. Accuracy on batch 379/2438  on Training is 68.89802631578948\n",
            "Batch Id 380/2438 is having training loss of 1.1360880136489868\n",
            "1.2047673463821411\n",
            "Epoch #5. Accuracy on batch 380/2438  on Training is 68.88943569553805\n",
            "Epoch #5. Accuracy on batch 381/2438  on Training is 68.88907068062828\n",
            "Epoch #5. Accuracy on batch 382/2438  on Training is 68.85607049608355\n",
            "Epoch #5. Accuracy on batch 383/2438  on Training is 68.83138020833333\n",
            "Epoch #5. Accuracy on batch 384/2438  on Training is 68.83116883116882\n",
            "Epoch #5. Accuracy on batch 385/2438  on Training is 68.8309585492228\n",
            "Epoch #5. Accuracy on batch 386/2438  on Training is 68.83074935400516\n",
            "Epoch #5. Accuracy on batch 387/2438  on Training is 68.83859536082474\n",
            "Epoch #5. Accuracy on batch 388/2438  on Training is 68.81426735218508\n",
            "Epoch #5. Accuracy on batch 389/2438  on Training is 68.83814102564102\n",
            "Epoch #5. Accuracy on batch 390/2438  on Training is 68.85390025575448\n",
            "Epoch #5. Accuracy on batch 391/2438  on Training is 68.86160714285714\n",
            "Epoch #5. Accuracy on batch 392/2438  on Training is 68.83746819338423\n",
            "Epoch #5. Accuracy on batch 393/2438  on Training is 68.78172588832487\n",
            "Epoch #5. Accuracy on batch 394/2438  on Training is 68.77373417721519\n",
            "Epoch #5. Accuracy on batch 395/2438  on Training is 68.8052398989899\n",
            "Epoch #5. Accuracy on batch 396/2438  on Training is 68.79722921914357\n",
            "Epoch #5. Accuracy on batch 397/2438  on Training is 68.77355527638191\n",
            "Epoch #5. Accuracy on batch 398/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 399/2438  on Training is 68.75\n",
            "Batch Id 400/2438 is having training loss of 1.1370093822479248\n",
            "0.863330602645874\n",
            "Epoch #5. Accuracy on batch 400/2438  on Training is 68.76558603491272\n",
            "Epoch #5. Accuracy on batch 401/2438  on Training is 68.74222636815921\n",
            "Epoch #5. Accuracy on batch 402/2438  on Training is 68.74224565756823\n",
            "Epoch #5. Accuracy on batch 403/2438  on Training is 68.72679455445545\n",
            "Epoch #5. Accuracy on batch 404/2438  on Training is 68.68827160493827\n",
            "Epoch #5. Accuracy on batch 405/2438  on Training is 68.72690886699507\n",
            "Epoch #5. Accuracy on batch 406/2438  on Training is 68.69625307125307\n",
            "Epoch #5. Accuracy on batch 407/2438  on Training is 68.6810661764706\n",
            "Epoch #5. Accuracy on batch 408/2438  on Training is 68.6812347188264\n",
            "Epoch #5. Accuracy on batch 409/2438  on Training is 68.67378048780488\n",
            "Epoch #5. Accuracy on batch 410/2438  on Training is 68.68156934306569\n",
            "Epoch #5. Accuracy on batch 411/2438  on Training is 68.66656553398059\n",
            "Epoch #5. Accuracy on batch 412/2438  on Training is 68.68190072639226\n",
            "Epoch #5. Accuracy on batch 413/2438  on Training is 68.6820652173913\n",
            "Epoch #5. Accuracy on batch 414/2438  on Training is 68.71234939759036\n",
            "Epoch #5. Accuracy on batch 415/2438  on Training is 68.73497596153847\n",
            "Epoch #5. Accuracy on batch 416/2438  on Training is 68.73501199040767\n",
            "Epoch #5. Accuracy on batch 417/2438  on Training is 68.71261961722487\n",
            "Epoch #5. Accuracy on batch 418/2438  on Training is 68.72016706443914\n",
            "Epoch #5. Accuracy on batch 419/2438  on Training is 68.70535714285714\n",
            "Batch Id 420/2438 is having training loss of 1.1376149654388428\n",
            "0.6274635791778564\n",
            "Epoch #5. Accuracy on batch 420/2438  on Training is 68.73515439429929\n",
            "Epoch #5. Accuracy on batch 421/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 422/2438  on Training is 68.70567375886525\n",
            "Epoch #5. Accuracy on batch 423/2438  on Training is 68.68366745283019\n",
            "Epoch #5. Accuracy on batch 424/2438  on Training is 68.69117647058823\n",
            "Epoch #5. Accuracy on batch 425/2438  on Training is 68.71332159624413\n",
            "Epoch #5. Accuracy on batch 426/2438  on Training is 68.70608899297424\n",
            "Epoch #5. Accuracy on batch 427/2438  on Training is 68.72079439252336\n",
            "Epoch #5. Accuracy on batch 428/2438  on Training is 68.71357808857809\n",
            "Epoch #5. Accuracy on batch 429/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 430/2438  on Training is 68.7354988399072\n",
            "Epoch #5. Accuracy on batch 431/2438  on Training is 68.7355324074074\n",
            "Epoch #5. Accuracy on batch 432/2438  on Training is 68.72834872979215\n",
            "Epoch #5. Accuracy on batch 433/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 434/2438  on Training is 68.74281609195403\n",
            "Epoch #5. Accuracy on batch 435/2438  on Training is 68.72849770642202\n",
            "Epoch #5. Accuracy on batch 436/2438  on Training is 68.73569794050343\n",
            "Epoch #5. Accuracy on batch 437/2438  on Training is 68.72146118721462\n",
            "Epoch #5. Accuracy on batch 438/2438  on Training is 68.73576309794989\n",
            "Epoch #5. Accuracy on batch 439/2438  on Training is 68.76420454545455\n",
            "Batch Id 440/2438 is having training loss of 1.1367466449737549\n",
            "1.149226427078247\n",
            "Epoch #5. Accuracy on batch 440/2438  on Training is 68.75708616780045\n",
            "Epoch #5. Accuracy on batch 441/2438  on Training is 68.7570701357466\n",
            "Epoch #5. Accuracy on batch 442/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 443/2438  on Training is 68.72888513513513\n",
            "Epoch #5. Accuracy on batch 444/2438  on Training is 68.73595505617978\n",
            "Epoch #5. Accuracy on batch 445/2438  on Training is 68.7289798206278\n",
            "Epoch #5. Accuracy on batch 446/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 447/2438  on Training is 68.73604910714286\n",
            "Epoch #5. Accuracy on batch 448/2438  on Training is 68.72912026726058\n",
            "Epoch #5. Accuracy on batch 449/2438  on Training is 68.72916666666667\n",
            "Epoch #5. Accuracy on batch 450/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 451/2438  on Training is 68.70851769911505\n",
            "Epoch #5. Accuracy on batch 452/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 453/2438  on Training is 68.74311674008811\n",
            "Epoch #5. Accuracy on batch 454/2438  on Training is 68.71565934065934\n",
            "Epoch #5. Accuracy on batch 455/2438  on Training is 68.67461622807018\n",
            "Epoch #5. Accuracy on batch 456/2438  on Training is 68.667943107221\n",
            "Epoch #5. Accuracy on batch 457/2438  on Training is 68.64082969432314\n",
            "Epoch #5. Accuracy on batch 458/2438  on Training is 68.64106753812636\n",
            "Epoch #5. Accuracy on batch 459/2438  on Training is 68.62092391304348\n",
            "Batch Id 460/2438 is having training loss of 1.140859842300415\n",
            "0.9812510013580322\n",
            "Epoch #5. Accuracy on batch 460/2438  on Training is 68.62120390455532\n",
            "Epoch #5. Accuracy on batch 461/2438  on Training is 68.63501082251082\n",
            "Epoch #5. Accuracy on batch 462/2438  on Training is 68.62850971922246\n",
            "Epoch #5. Accuracy on batch 463/2438  on Training is 68.60183189655173\n",
            "Epoch #5. Accuracy on batch 464/2438  on Training is 68.60887096774194\n",
            "Epoch #5. Accuracy on batch 465/2438  on Training is 68.58905579399142\n",
            "Epoch #5. Accuracy on batch 466/2438  on Training is 68.56932548179871\n",
            "Epoch #5. Accuracy on batch 467/2438  on Training is 68.55635683760684\n",
            "Epoch #5. Accuracy on batch 468/2438  on Training is 68.58342217484008\n",
            "Epoch #5. Accuracy on batch 469/2438  on Training is 68.61037234042553\n",
            "Epoch #5. Accuracy on batch 470/2438  on Training is 68.62393842887474\n",
            "Epoch #5. Accuracy on batch 471/2438  on Training is 68.63082627118644\n",
            "Epoch #5. Accuracy on batch 472/2438  on Training is 68.64429175475686\n",
            "Epoch #5. Accuracy on batch 473/2438  on Training is 68.63132911392405\n",
            "Epoch #5. Accuracy on batch 474/2438  on Training is 68.61842105263158\n",
            "Epoch #5. Accuracy on batch 475/2438  on Training is 68.62526260504201\n",
            "Epoch #5. Accuracy on batch 476/2438  on Training is 68.63862683438155\n",
            "Epoch #5. Accuracy on batch 477/2438  on Training is 68.63232217573221\n",
            "Epoch #5. Accuracy on batch 478/2438  on Training is 68.65213987473904\n",
            "Epoch #5. Accuracy on batch 479/2438  on Training is 68.68489583333333\n",
            "Batch Id 480/2438 is having training loss of 1.141013264656067\n",
            "0.8393774032592773\n",
            "Epoch #5. Accuracy on batch 480/2438  on Training is 68.69152806652806\n",
            "Epoch #5. Accuracy on batch 481/2438  on Training is 68.7240663900415\n",
            "Epoch #5. Accuracy on batch 482/2438  on Training is 68.71765010351967\n",
            "Epoch #5. Accuracy on batch 483/2438  on Training is 68.70480371900827\n",
            "Epoch #5. Accuracy on batch 484/2438  on Training is 68.67268041237114\n",
            "Epoch #5. Accuracy on batch 485/2438  on Training is 68.67283950617283\n",
            "Epoch #5. Accuracy on batch 486/2438  on Training is 68.66016427104722\n",
            "Epoch #5. Accuracy on batch 487/2438  on Training is 68.6795594262295\n",
            "Epoch #5. Accuracy on batch 488/2438  on Training is 68.67970347648262\n",
            "Epoch #5. Accuracy on batch 489/2438  on Training is 68.69260204081633\n",
            "Epoch #5. Accuracy on batch 490/2438  on Training is 68.71181262729124\n",
            "Epoch #5. Accuracy on batch 491/2438  on Training is 68.70553861788618\n",
            "Epoch #5. Accuracy on batch 492/2438  on Training is 68.70562880324543\n",
            "Epoch #5. Accuracy on batch 493/2438  on Training is 68.67408906882591\n",
            "Epoch #5. Accuracy on batch 494/2438  on Training is 68.68055555555556\n",
            "Epoch #5. Accuracy on batch 495/2438  on Training is 68.66809475806451\n",
            "Epoch #5. Accuracy on batch 496/2438  on Training is 68.68712273641852\n",
            "Epoch #5. Accuracy on batch 497/2438  on Training is 68.68097389558233\n",
            "Epoch #5. Accuracy on batch 498/2438  on Training is 68.6685871743487\n",
            "Epoch #5. Accuracy on batch 499/2438  on Training is 68.66875\n",
            "Batch Id 500/2438 is having training loss of 1.1396251916885376\n",
            "1.249739408493042\n",
            "Epoch #5. Accuracy on batch 500/2438  on Training is 68.6626746506986\n",
            "Epoch #5. Accuracy on batch 501/2438  on Training is 68.6503984063745\n",
            "Epoch #5. Accuracy on batch 502/2438  on Training is 68.65059642147118\n",
            "Epoch #5. Accuracy on batch 503/2438  on Training is 68.66939484126983\n",
            "Epoch #5. Accuracy on batch 504/2438  on Training is 68.66955445544555\n",
            "Epoch #5. Accuracy on batch 505/2438  on Training is 68.66353754940711\n",
            "Epoch #5. Accuracy on batch 506/2438  on Training is 68.6698717948718\n",
            "Epoch #5. Accuracy on batch 507/2438  on Training is 68.65772637795276\n",
            "Epoch #5. Accuracy on batch 508/2438  on Training is 68.65176817288801\n",
            "Epoch #5. Accuracy on batch 509/2438  on Training is 68.68872549019608\n",
            "Epoch #5. Accuracy on batch 510/2438  on Training is 68.7133072407045\n",
            "Epoch #5. Accuracy on batch 511/2438  on Training is 68.701171875\n",
            "Epoch #5. Accuracy on batch 512/2438  on Training is 68.67690058479532\n",
            "Epoch #5. Accuracy on batch 513/2438  on Training is 68.67096303501945\n",
            "Epoch #5. Accuracy on batch 514/2438  on Training is 68.66504854368932\n",
            "Epoch #5. Accuracy on batch 515/2438  on Training is 68.67126937984496\n",
            "Epoch #5. Accuracy on batch 516/2438  on Training is 68.68351063829788\n",
            "Epoch #5. Accuracy on batch 517/2438  on Training is 68.68967181467181\n",
            "Epoch #5. Accuracy on batch 518/2438  on Training is 68.69580924855491\n",
            "Epoch #5. Accuracy on batch 519/2438  on Training is 68.68990384615384\n",
            "Batch Id 520/2438 is having training loss of 1.1389436721801758\n",
            "1.2807055711746216\n",
            "Epoch #5. Accuracy on batch 520/2438  on Training is 68.69601727447217\n",
            "Epoch #5. Accuracy on batch 521/2438  on Training is 68.67217432950191\n",
            "Epoch #5. Accuracy on batch 522/2438  on Training is 68.68427342256214\n",
            "Epoch #5. Accuracy on batch 523/2438  on Training is 68.69632633587786\n",
            "Epoch #5. Accuracy on batch 524/2438  on Training is 68.70238095238095\n",
            "Epoch #5. Accuracy on batch 525/2438  on Training is 68.70247148288973\n",
            "Epoch #5. Accuracy on batch 526/2438  on Training is 68.70849146110056\n",
            "Epoch #5. Accuracy on batch 527/2438  on Training is 68.72632575757575\n",
            "Epoch #5. Accuracy on batch 528/2438  on Training is 68.71455576559546\n",
            "Epoch #5. Accuracy on batch 529/2438  on Training is 68.70872641509433\n",
            "Epoch #5. Accuracy on batch 530/2438  on Training is 68.70291902071563\n",
            "Epoch #5. Accuracy on batch 531/2438  on Training is 68.7265037593985\n",
            "Epoch #5. Accuracy on batch 532/2438  on Training is 68.72068480300187\n",
            "Epoch #5. Accuracy on batch 533/2438  on Training is 68.73244382022472\n",
            "Epoch #5. Accuracy on batch 534/2438  on Training is 68.7266355140187\n",
            "Epoch #5. Accuracy on batch 535/2438  on Training is 68.7441697761194\n",
            "Epoch #5. Accuracy on batch 536/2438  on Training is 68.74418063314711\n",
            "Epoch #5. Accuracy on batch 537/2438  on Training is 68.79065985130111\n",
            "Epoch #5. Accuracy on batch 538/2438  on Training is 68.77898886827458\n",
            "Epoch #5. Accuracy on batch 539/2438  on Training is 68.77314814814815\n",
            "Batch Id 540/2438 is having training loss of 1.1384117603302002\n",
            "0.9831122159957886\n",
            "Epoch #5. Accuracy on batch 540/2438  on Training is 68.78465804066543\n",
            "Epoch #5. Accuracy on batch 541/2438  on Training is 68.76153136531366\n",
            "Epoch #5. Accuracy on batch 542/2438  on Training is 68.77302025782689\n",
            "Epoch #5. Accuracy on batch 543/2438  on Training is 68.76723345588235\n",
            "Epoch #5. Accuracy on batch 544/2438  on Training is 68.7729357798165\n",
            "Epoch #5. Accuracy on batch 545/2438  on Training is 68.76144688644689\n",
            "Epoch #5. Accuracy on batch 546/2438  on Training is 68.77856489945155\n",
            "Epoch #5. Accuracy on batch 547/2438  on Training is 68.78991788321167\n",
            "Epoch #5. Accuracy on batch 548/2438  on Training is 68.81830601092896\n",
            "Epoch #5. Accuracy on batch 549/2438  on Training is 68.77272727272727\n",
            "Epoch #5. Accuracy on batch 550/2438  on Training is 68.76134301270417\n",
            "Epoch #5. Accuracy on batch 551/2438  on Training is 68.76132246376811\n",
            "Epoch #5. Accuracy on batch 552/2438  on Training is 68.73304701627487\n",
            "Epoch #5. Accuracy on batch 553/2438  on Training is 68.73871841155234\n",
            "Epoch #5. Accuracy on batch 554/2438  on Training is 68.73310810810811\n",
            "Epoch #5. Accuracy on batch 555/2438  on Training is 68.73875899280576\n",
            "Epoch #5. Accuracy on batch 556/2438  on Training is 68.76683123877918\n",
            "Epoch #5. Accuracy on batch 557/2438  on Training is 68.7780017921147\n",
            "Epoch #5. Accuracy on batch 558/2438  on Training is 68.78354203935599\n",
            "Epoch #5. Accuracy on batch 559/2438  on Training is 68.80022321428571\n",
            "Batch Id 560/2438 is having training loss of 1.1388516426086426\n",
            "1.4137351512908936\n",
            "Epoch #5. Accuracy on batch 560/2438  on Training is 68.78899286987522\n",
            "Epoch #5. Accuracy on batch 561/2438  on Training is 68.81116548042705\n",
            "Epoch #5. Accuracy on batch 562/2438  on Training is 68.82770870337478\n",
            "Epoch #5. Accuracy on batch 563/2438  on Training is 68.84419326241135\n",
            "Epoch #5. Accuracy on batch 564/2438  on Training is 68.84402654867256\n",
            "Epoch #5. Accuracy on batch 565/2438  on Training is 68.8493816254417\n",
            "Epoch #5. Accuracy on batch 566/2438  on Training is 68.81613756613757\n",
            "Epoch #5. Accuracy on batch 567/2438  on Training is 68.79951584507042\n",
            "Epoch #5. Accuracy on batch 568/2438  on Training is 68.77746045694201\n",
            "Epoch #5. Accuracy on batch 569/2438  on Training is 68.7719298245614\n",
            "Epoch #5. Accuracy on batch 570/2438  on Training is 68.79378283712785\n",
            "Epoch #5. Accuracy on batch 571/2438  on Training is 68.78824300699301\n",
            "Epoch #5. Accuracy on batch 572/2438  on Training is 68.782722513089\n",
            "Epoch #5. Accuracy on batch 573/2438  on Training is 68.77177700348432\n",
            "Epoch #5. Accuracy on batch 574/2438  on Training is 68.77717391304348\n",
            "Epoch #5. Accuracy on batch 575/2438  on Training is 68.76627604166667\n",
            "Epoch #5. Accuracy on batch 576/2438  on Training is 68.73375216637781\n",
            "Epoch #5. Accuracy on batch 577/2438  on Training is 68.71756055363322\n",
            "Epoch #5. Accuracy on batch 578/2438  on Training is 68.71761658031087\n",
            "Epoch #5. Accuracy on batch 579/2438  on Training is 68.70150862068965\n",
            "Batch Id 580/2438 is having training loss of 1.1395416259765625\n",
            "1.1856876611709595\n",
            "Epoch #5. Accuracy on batch 580/2438  on Training is 68.71234939759036\n",
            "Epoch #5. Accuracy on batch 581/2438  on Training is 68.72315292096219\n",
            "Epoch #5. Accuracy on batch 582/2438  on Training is 68.73391938250428\n",
            "Epoch #5. Accuracy on batch 583/2438  on Training is 68.70184075342466\n",
            "Epoch #5. Accuracy on batch 584/2438  on Training is 68.70192307692308\n",
            "Epoch #5. Accuracy on batch 585/2438  on Training is 68.68600682593856\n",
            "Epoch #5. Accuracy on batch 586/2438  on Training is 68.67546848381602\n",
            "Epoch #5. Accuracy on batch 587/2438  on Training is 68.68090986394557\n",
            "Epoch #5. Accuracy on batch 588/2438  on Training is 68.70224957555179\n",
            "Epoch #5. Accuracy on batch 589/2438  on Training is 68.70762711864407\n",
            "Epoch #5. Accuracy on batch 590/2438  on Training is 68.6918358714044\n",
            "Epoch #5. Accuracy on batch 591/2438  on Training is 68.72360641891892\n",
            "Epoch #5. Accuracy on batch 592/2438  on Training is 68.71838111298483\n",
            "Epoch #5. Accuracy on batch 593/2438  on Training is 68.72895622895624\n",
            "Epoch #5. Accuracy on batch 594/2438  on Training is 68.70273109243698\n",
            "Epoch #5. Accuracy on batch 595/2438  on Training is 68.70281040268456\n",
            "Epoch #5. Accuracy on batch 596/2438  on Training is 68.70812395309883\n",
            "Epoch #5. Accuracy on batch 597/2438  on Training is 68.70819397993311\n",
            "Epoch #5. Accuracy on batch 598/2438  on Training is 68.71348080133556\n",
            "Epoch #5. Accuracy on batch 599/2438  on Training is 68.71875\n",
            "Batch Id 600/2438 is having training loss of 1.1409573554992676\n",
            "1.5781413316726685\n",
            "Epoch #5. Accuracy on batch 600/2438  on Training is 68.70320299500833\n",
            "Epoch #5. Accuracy on batch 601/2438  on Training is 68.703280730897\n",
            "Epoch #5. Accuracy on batch 602/2438  on Training is 68.70854063018243\n",
            "Epoch #5. Accuracy on batch 603/2438  on Training is 68.70860927152317\n",
            "Epoch #5. Accuracy on batch 604/2438  on Training is 68.70351239669421\n",
            "Epoch #5. Accuracy on batch 605/2438  on Training is 68.68296204620462\n",
            "Epoch #5. Accuracy on batch 606/2438  on Training is 68.67792421746293\n",
            "Epoch #5. Accuracy on batch 607/2438  on Training is 68.66776315789474\n",
            "Epoch #5. Accuracy on batch 608/2438  on Training is 68.67816091954023\n",
            "Epoch #5. Accuracy on batch 609/2438  on Training is 68.67315573770492\n",
            "Epoch #5. Accuracy on batch 610/2438  on Training is 68.67839607201309\n",
            "Epoch #5. Accuracy on batch 611/2438  on Training is 68.69893790849673\n",
            "Epoch #5. Accuracy on batch 612/2438  on Training is 68.69902120717781\n",
            "Epoch #5. Accuracy on batch 613/2438  on Training is 68.69910423452768\n",
            "Epoch #5. Accuracy on batch 614/2438  on Training is 68.67378048780488\n",
            "Epoch #5. Accuracy on batch 615/2438  on Training is 68.68405032467533\n",
            "Epoch #5. Accuracy on batch 616/2438  on Training is 68.68415721231767\n",
            "Epoch #5. Accuracy on batch 617/2438  on Training is 68.69943365695792\n",
            "Epoch #5. Accuracy on batch 618/2438  on Training is 68.71970920840064\n",
            "Epoch #5. Accuracy on batch 619/2438  on Training is 68.71471774193549\n",
            "Batch Id 620/2438 is having training loss of 1.1401245594024658\n",
            "0.7520557641983032\n",
            "Epoch #5. Accuracy on batch 620/2438  on Training is 68.73490338164251\n",
            "Epoch #5. Accuracy on batch 621/2438  on Training is 68.74497588424437\n",
            "Epoch #5. Accuracy on batch 622/2438  on Training is 68.74498394863564\n",
            "Epoch #5. Accuracy on batch 623/2438  on Training is 68.73497596153847\n",
            "Epoch #5. Accuracy on batch 624/2438  on Training is 68.735\n",
            "Epoch #5. Accuracy on batch 625/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 626/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 627/2438  on Training is 68.74004777070064\n",
            "Epoch #5. Accuracy on batch 628/2438  on Training is 68.73509538950715\n",
            "Epoch #5. Accuracy on batch 629/2438  on Training is 68.74007936507937\n",
            "Epoch #5. Accuracy on batch 630/2438  on Training is 68.72028526148969\n",
            "Epoch #5. Accuracy on batch 631/2438  on Training is 68.7351661392405\n",
            "Epoch #5. Accuracy on batch 632/2438  on Training is 68.72531595576619\n",
            "Epoch #5. Accuracy on batch 633/2438  on Training is 68.72535488958991\n",
            "Epoch #5. Accuracy on batch 634/2438  on Training is 68.72047244094489\n",
            "Epoch #5. Accuracy on batch 635/2438  on Training is 68.72543238993711\n",
            "Epoch #5. Accuracy on batch 636/2438  on Training is 68.72547095761381\n",
            "Epoch #5. Accuracy on batch 637/2438  on Training is 68.74020376175548\n",
            "Epoch #5. Accuracy on batch 638/2438  on Training is 68.75489045383412\n",
            "Epoch #5. Accuracy on batch 639/2438  on Training is 68.7548828125\n",
            "Batch Id 640/2438 is having training loss of 1.1398015022277832\n",
            "0.7672685384750366\n",
            "Epoch #5. Accuracy on batch 640/2438  on Training is 68.7792511700468\n",
            "Epoch #5. Accuracy on batch 641/2438  on Training is 68.79867601246106\n",
            "Epoch #5. Accuracy on batch 642/2438  on Training is 68.7937402799378\n",
            "Epoch #5. Accuracy on batch 643/2438  on Training is 68.77426242236025\n",
            "Epoch #5. Accuracy on batch 644/2438  on Training is 68.77422480620154\n",
            "Epoch #5. Accuracy on batch 645/2438  on Training is 68.78869969040248\n",
            "Epoch #5. Accuracy on batch 646/2438  on Training is 68.7789799072643\n",
            "Epoch #5. Accuracy on batch 647/2438  on Training is 68.7644675925926\n",
            "Epoch #5. Accuracy on batch 648/2438  on Training is 68.76444530046226\n",
            "Epoch #5. Accuracy on batch 649/2438  on Training is 68.76923076923077\n",
            "Epoch #5. Accuracy on batch 650/2438  on Training is 68.76440092165899\n",
            "Epoch #5. Accuracy on batch 651/2438  on Training is 68.76437883435582\n",
            "Epoch #5. Accuracy on batch 652/2438  on Training is 68.76914241960183\n",
            "Epoch #5. Accuracy on batch 653/2438  on Training is 68.78344801223241\n",
            "Epoch #5. Accuracy on batch 654/2438  on Training is 68.77862595419847\n",
            "Epoch #5. Accuracy on batch 655/2438  on Training is 68.78810975609755\n",
            "Epoch #5. Accuracy on batch 656/2438  on Training is 68.81183409436834\n",
            "Epoch #5. Accuracy on batch 657/2438  on Training is 68.79274316109422\n",
            "Epoch #5. Accuracy on batch 658/2438  on Training is 68.80216236722306\n",
            "Epoch #5. Accuracy on batch 659/2438  on Training is 68.79261363636364\n",
            "Batch Id 660/2438 is having training loss of 1.1393070220947266\n",
            "1.1194920539855957\n",
            "Epoch #5. Accuracy on batch 660/2438  on Training is 68.80200453857792\n",
            "Epoch #5. Accuracy on batch 661/2438  on Training is 68.81608761329305\n",
            "Epoch #5. Accuracy on batch 662/2438  on Training is 68.80656108597285\n",
            "Epoch #5. Accuracy on batch 663/2438  on Training is 68.79706325301204\n",
            "Epoch #5. Accuracy on batch 664/2438  on Training is 68.7922932330827\n",
            "Epoch #5. Accuracy on batch 665/2438  on Training is 68.75938438438439\n",
            "Epoch #5. Accuracy on batch 666/2438  on Training is 68.76405547226386\n",
            "Epoch #5. Accuracy on batch 667/2438  on Training is 68.75467814371258\n",
            "Epoch #5. Accuracy on batch 668/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 669/2438  on Training is 68.72201492537313\n",
            "Epoch #5. Accuracy on batch 670/2438  on Training is 68.72671385991057\n",
            "Epoch #5. Accuracy on batch 671/2438  on Training is 68.74534970238095\n",
            "Epoch #5. Accuracy on batch 672/2438  on Training is 68.7407132243685\n",
            "Epoch #5. Accuracy on batch 673/2438  on Training is 68.73609050445104\n",
            "Epoch #5. Accuracy on batch 674/2438  on Training is 68.73611111111111\n",
            "Epoch #5. Accuracy on batch 675/2438  on Training is 68.72226331360947\n",
            "Epoch #5. Accuracy on batch 676/2438  on Training is 68.72230428360413\n",
            "Epoch #5. Accuracy on batch 677/2438  on Training is 68.73617256637168\n",
            "Epoch #5. Accuracy on batch 678/2438  on Training is 68.74079528718704\n",
            "Epoch #5. Accuracy on batch 679/2438  on Training is 68.74540441176471\n",
            "Batch Id 680/2438 is having training loss of 1.1407252550125122\n",
            "1.5301786661148071\n",
            "Epoch #5. Accuracy on batch 680/2438  on Training is 68.73623348017621\n",
            "Epoch #5. Accuracy on batch 681/2438  on Training is 68.7408357771261\n",
            "Epoch #5. Accuracy on batch 682/2438  on Training is 68.72712298682283\n",
            "Epoch #5. Accuracy on batch 683/2438  on Training is 68.72715643274854\n",
            "Epoch #5. Accuracy on batch 684/2438  on Training is 68.71806569343066\n",
            "Epoch #5. Accuracy on batch 685/2438  on Training is 68.73633381924198\n",
            "Epoch #5. Accuracy on batch 686/2438  on Training is 68.73180494905385\n",
            "Epoch #5. Accuracy on batch 687/2438  on Training is 68.74091569767442\n",
            "Epoch #5. Accuracy on batch 688/2438  on Training is 68.73185776487664\n",
            "Epoch #5. Accuracy on batch 689/2438  on Training is 68.72282608695652\n",
            "Epoch #5. Accuracy on batch 690/2438  on Training is 68.73191027496382\n",
            "Epoch #5. Accuracy on batch 691/2438  on Training is 68.73193641618496\n",
            "Epoch #5. Accuracy on batch 692/2438  on Training is 68.74098124098124\n",
            "Epoch #5. Accuracy on batch 693/2438  on Training is 68.74099423631124\n",
            "Epoch #5. Accuracy on batch 694/2438  on Training is 68.73651079136691\n",
            "Epoch #5. Accuracy on batch 695/2438  on Training is 68.75448994252874\n",
            "Epoch #5. Accuracy on batch 696/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 697/2438  on Training is 68.7544770773639\n",
            "Epoch #5. Accuracy on batch 698/2438  on Training is 68.75894134477825\n",
            "Epoch #5. Accuracy on batch 699/2438  on Training is 68.76339285714286\n",
            "Batch Id 700/2438 is having training loss of 1.1400090456008911\n",
            "0.8760901093482971\n",
            "Epoch #5. Accuracy on batch 700/2438  on Training is 68.77228958630528\n",
            "Epoch #5. Accuracy on batch 701/2438  on Training is 68.78116096866097\n",
            "Epoch #5. Accuracy on batch 702/2438  on Training is 68.78556187766713\n",
            "Epoch #5. Accuracy on batch 703/2438  on Training is 68.7899502840909\n",
            "Epoch #5. Accuracy on batch 704/2438  on Training is 68.79875886524823\n",
            "Epoch #5. Accuracy on batch 705/2438  on Training is 68.78541076487252\n",
            "Epoch #5. Accuracy on batch 706/2438  on Training is 68.77652050919377\n",
            "Epoch #5. Accuracy on batch 707/2438  on Training is 68.78972457627118\n",
            "Epoch #5. Accuracy on batch 708/2438  on Training is 68.77644569816643\n",
            "Epoch #5. Accuracy on batch 709/2438  on Training is 68.76760563380282\n",
            "Epoch #5. Accuracy on batch 710/2438  on Training is 68.75439521800281\n",
            "Epoch #5. Accuracy on batch 711/2438  on Training is 68.75438904494382\n",
            "Epoch #5. Accuracy on batch 712/2438  on Training is 68.77191444600281\n",
            "Epoch #5. Accuracy on batch 713/2438  on Training is 68.76313025210084\n",
            "Epoch #5. Accuracy on batch 714/2438  on Training is 68.76748251748252\n",
            "Epoch #5. Accuracy on batch 715/2438  on Training is 68.75872905027933\n",
            "Epoch #5. Accuracy on batch 716/2438  on Training is 68.75871687587168\n",
            "Epoch #5. Accuracy on batch 717/2438  on Training is 68.73694289693593\n",
            "Epoch #5. Accuracy on batch 718/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 719/2438  on Training is 68.74131944444444\n",
            "Batch Id 720/2438 is having training loss of 1.1414612531661987\n",
            "0.991969108581543\n",
            "Epoch #5. Accuracy on batch 720/2438  on Training is 68.73266296809986\n",
            "Epoch #5. Accuracy on batch 721/2438  on Training is 68.74567174515235\n",
            "Epoch #5. Accuracy on batch 722/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 723/2438  on Training is 68.74136740331491\n",
            "Epoch #5. Accuracy on batch 724/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 725/2438  on Training is 68.741391184573\n",
            "Epoch #5. Accuracy on batch 726/2438  on Training is 68.7542984869326\n",
            "Epoch #5. Accuracy on batch 727/2438  on Training is 68.74141483516483\n",
            "Epoch #5. Accuracy on batch 728/2438  on Training is 68.73713991769547\n",
            "Epoch #5. Accuracy on batch 729/2438  on Training is 68.73287671232876\n",
            "Epoch #5. Accuracy on batch 730/2438  on Training is 68.74572503419972\n",
            "Epoch #5. Accuracy on batch 731/2438  on Training is 68.73719262295081\n",
            "Epoch #5. Accuracy on batch 732/2438  on Training is 68.73294679399727\n",
            "Epoch #5. Accuracy on batch 733/2438  on Training is 68.74148501362397\n",
            "Epoch #5. Accuracy on batch 734/2438  on Training is 68.74574829931973\n",
            "Epoch #5. Accuracy on batch 735/2438  on Training is 68.7584918478261\n",
            "Epoch #5. Accuracy on batch 736/2438  on Training is 68.76272048846675\n",
            "Epoch #5. Accuracy on batch 737/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 738/2438  on Training is 68.75422868741542\n",
            "Epoch #5. Accuracy on batch 739/2438  on Training is 68.7795608108108\n",
            "Batch Id 740/2438 is having training loss of 1.1409151554107666\n",
            "1.03299081325531\n",
            "Epoch #5. Accuracy on batch 740/2438  on Training is 68.7753036437247\n",
            "Epoch #5. Accuracy on batch 741/2438  on Training is 68.77948113207547\n",
            "Epoch #5. Accuracy on batch 742/2438  on Training is 68.77523553162854\n",
            "Epoch #5. Accuracy on batch 743/2438  on Training is 68.77940188172043\n",
            "Epoch #5. Accuracy on batch 744/2438  on Training is 68.77097315436242\n",
            "Epoch #5. Accuracy on batch 745/2438  on Training is 68.77932305630027\n",
            "Epoch #5. Accuracy on batch 746/2438  on Training is 68.7834672021419\n",
            "Epoch #5. Accuracy on batch 747/2438  on Training is 68.78342245989305\n",
            "Epoch #5. Accuracy on batch 748/2438  on Training is 68.78755006675567\n",
            "Epoch #5. Accuracy on batch 749/2438  on Training is 68.79583333333333\n",
            "Epoch #5. Accuracy on batch 750/2438  on Training is 68.7957723035952\n",
            "Epoch #5. Accuracy on batch 751/2438  on Training is 68.79155585106383\n",
            "Epoch #5. Accuracy on batch 752/2438  on Training is 68.78735059760956\n",
            "Epoch #5. Accuracy on batch 753/2438  on Training is 68.78315649867373\n",
            "Epoch #5. Accuracy on batch 754/2438  on Training is 68.7748344370861\n",
            "Epoch #5. Accuracy on batch 755/2438  on Training is 68.77066798941799\n",
            "Epoch #5. Accuracy on batch 756/2438  on Training is 68.76651254953765\n",
            "Epoch #5. Accuracy on batch 757/2438  on Training is 68.75824538258576\n",
            "Epoch #5. Accuracy on batch 758/2438  on Training is 68.76646903820817\n",
            "Epoch #5. Accuracy on batch 759/2438  on Training is 68.75411184210526\n",
            "Batch Id 760/2438 is having training loss of 1.1416014432907104\n",
            "1.3314800262451172\n",
            "Epoch #5. Accuracy on batch 760/2438  on Training is 68.75410643889619\n",
            "Epoch #5. Accuracy on batch 761/2438  on Training is 68.7623031496063\n",
            "Epoch #5. Accuracy on batch 762/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 763/2438  on Training is 68.74590968586388\n",
            "Epoch #5. Accuracy on batch 764/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 765/2438  on Training is 68.76631853785901\n",
            "Epoch #5. Accuracy on batch 766/2438  on Training is 68.76222294654498\n",
            "Epoch #5. Accuracy on batch 767/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 768/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 769/2438  on Training is 68.74188311688312\n",
            "Epoch #5. Accuracy on batch 770/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 771/2438  on Training is 68.74595207253886\n",
            "Epoch #5. Accuracy on batch 772/2438  on Training is 68.75404269081501\n",
            "Epoch #5. Accuracy on batch 773/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 774/2438  on Training is 68.74596774193549\n",
            "Epoch #5. Accuracy on batch 775/2438  on Training is 68.75805412371135\n",
            "Epoch #5. Accuracy on batch 776/2438  on Training is 68.75804375804375\n",
            "Epoch #5. Accuracy on batch 777/2438  on Training is 68.76606683804627\n",
            "Epoch #5. Accuracy on batch 778/2438  on Training is 68.76203465982029\n",
            "Epoch #5. Accuracy on batch 779/2438  on Training is 68.75801282051282\n",
            "Batch Id 780/2438 is having training loss of 1.1418997049331665\n",
            "0.8919041752815247\n",
            "Epoch #5. Accuracy on batch 780/2438  on Training is 68.77000640204865\n",
            "Epoch #5. Accuracy on batch 781/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 782/2438  on Training is 68.74201787994892\n",
            "Epoch #5. Accuracy on batch 783/2438  on Training is 68.75398596938776\n",
            "Epoch #5. Accuracy on batch 784/2438  on Training is 68.76194267515923\n",
            "Epoch #5. Accuracy on batch 785/2438  on Training is 68.76192748091603\n",
            "Epoch #5. Accuracy on batch 786/2438  on Training is 68.76588310038119\n",
            "Epoch #5. Accuracy on batch 787/2438  on Training is 68.74603426395939\n",
            "Epoch #5. Accuracy on batch 788/2438  on Training is 68.74603929024082\n",
            "Epoch #5. Accuracy on batch 789/2438  on Training is 68.75395569620254\n",
            "Epoch #5. Accuracy on batch 790/2438  on Training is 68.75790139064475\n",
            "Epoch #5. Accuracy on batch 791/2438  on Training is 68.75789141414141\n",
            "Epoch #5. Accuracy on batch 792/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 793/2438  on Training is 68.73819269521411\n",
            "Epoch #5. Accuracy on batch 794/2438  on Training is 68.73820754716981\n",
            "Epoch #5. Accuracy on batch 795/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 796/2438  on Training is 68.75392095357591\n",
            "Epoch #5. Accuracy on batch 797/2438  on Training is 68.73825187969925\n",
            "Epoch #5. Accuracy on batch 798/2438  on Training is 68.73044430538172\n",
            "Epoch #5. Accuracy on batch 799/2438  on Training is 68.73046875\n",
            "Batch Id 800/2438 is having training loss of 1.1434508562088013\n",
            "0.7268656492233276\n",
            "Epoch #5. Accuracy on batch 800/2438  on Training is 68.7460986267166\n",
            "Epoch #5. Accuracy on batch 801/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 802/2438  on Training is 68.74610834371109\n",
            "Epoch #5. Accuracy on batch 803/2438  on Training is 68.74222636815921\n",
            "Epoch #5. Accuracy on batch 804/2438  on Training is 68.74611801242236\n",
            "Epoch #5. Accuracy on batch 805/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 806/2438  on Training is 68.74612763320941\n",
            "Epoch #5. Accuracy on batch 807/2438  on Training is 68.74613242574257\n",
            "Epoch #5. Accuracy on batch 808/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 809/2438  on Training is 68.75771604938272\n",
            "Epoch #5. Accuracy on batch 810/2438  on Training is 68.7577065351418\n",
            "Epoch #5. Accuracy on batch 811/2438  on Training is 68.76154556650246\n",
            "Epoch #5. Accuracy on batch 812/2438  on Training is 68.75384378843789\n",
            "Epoch #5. Accuracy on batch 813/2438  on Training is 68.75383906633907\n",
            "Epoch #5. Accuracy on batch 814/2438  on Training is 68.76533742331289\n",
            "Epoch #5. Accuracy on batch 815/2438  on Training is 68.76148897058823\n",
            "Epoch #5. Accuracy on batch 816/2438  on Training is 68.76147490820074\n",
            "Epoch #5. Accuracy on batch 817/2438  on Training is 68.74617970660147\n",
            "Epoch #5. Accuracy on batch 818/2438  on Training is 68.73092185592185\n",
            "Epoch #5. Accuracy on batch 819/2438  on Training is 68.73475609756098\n",
            "Batch Id 820/2438 is having training loss of 1.1438137292861938\n",
            "1.4186393022537231\n",
            "Epoch #5. Accuracy on batch 820/2438  on Training is 68.71574299634592\n",
            "Epoch #5. Accuracy on batch 821/2438  on Training is 68.69677615571776\n",
            "Epoch #5. Accuracy on batch 822/2438  on Training is 68.70443499392466\n",
            "Epoch #5. Accuracy on batch 823/2438  on Training is 68.70069781553399\n",
            "Epoch #5. Accuracy on batch 824/2438  on Training is 68.6780303030303\n",
            "Epoch #5. Accuracy on batch 825/2438  on Training is 68.68190072639226\n",
            "Epoch #5. Accuracy on batch 826/2438  on Training is 68.6933192261185\n",
            "Epoch #5. Accuracy on batch 827/2438  on Training is 68.66696859903382\n",
            "Epoch #5. Accuracy on batch 828/2438  on Training is 68.65575995174909\n",
            "Epoch #5. Accuracy on batch 829/2438  on Training is 68.65210843373494\n",
            "Epoch #5. Accuracy on batch 830/2438  on Training is 68.63718411552347\n",
            "Epoch #5. Accuracy on batch 831/2438  on Training is 68.63731971153847\n",
            "Epoch #5. Accuracy on batch 832/2438  on Training is 68.6374549819928\n",
            "Epoch #5. Accuracy on batch 833/2438  on Training is 68.64508393285372\n",
            "Epoch #5. Accuracy on batch 834/2438  on Training is 68.64895209580838\n",
            "Epoch #5. Accuracy on batch 835/2438  on Training is 68.64907296650718\n",
            "Epoch #5. Accuracy on batch 836/2438  on Training is 68.65292712066906\n",
            "Epoch #5. Accuracy on batch 837/2438  on Training is 68.66050119331742\n",
            "Epoch #5. Accuracy on batch 838/2438  on Training is 68.66433253873659\n",
            "Epoch #5. Accuracy on batch 839/2438  on Training is 68.66815476190476\n",
            "Batch Id 840/2438 is having training loss of 1.1447113752365112\n",
            "1.3997581005096436\n",
            "Epoch #5. Accuracy on batch 840/2438  on Training is 68.65338882282997\n",
            "Epoch #5. Accuracy on batch 841/2438  on Training is 68.66092636579573\n",
            "Epoch #5. Accuracy on batch 842/2438  on Training is 68.64620403321472\n",
            "Epoch #5. Accuracy on batch 843/2438  on Training is 68.63151658767772\n",
            "Epoch #5. Accuracy on batch 844/2438  on Training is 68.6353550295858\n",
            "Epoch #5. Accuracy on batch 845/2438  on Training is 68.62071513002364\n",
            "Epoch #5. Accuracy on batch 846/2438  on Training is 68.61348878394332\n",
            "Epoch #5. Accuracy on batch 847/2438  on Training is 68.62102004716981\n",
            "Epoch #5. Accuracy on batch 848/2438  on Training is 68.64325677267374\n",
            "Epoch #5. Accuracy on batch 849/2438  on Training is 68.625\n",
            "Epoch #5. Accuracy on batch 850/2438  on Training is 68.60311398354877\n",
            "Epoch #5. Accuracy on batch 851/2438  on Training is 68.60328638497653\n",
            "Epoch #5. Accuracy on batch 852/2438  on Training is 68.59979484173505\n",
            "Epoch #5. Accuracy on batch 853/2438  on Training is 68.59631147540983\n",
            "Epoch #5. Accuracy on batch 854/2438  on Training is 68.57456140350877\n",
            "Epoch #5. Accuracy on batch 855/2438  on Training is 68.56746495327103\n",
            "Epoch #5. Accuracy on batch 856/2438  on Training is 68.56038506417737\n",
            "Epoch #5. Accuracy on batch 857/2438  on Training is 68.55696386946387\n",
            "Epoch #5. Accuracy on batch 858/2438  on Training is 68.54991268917345\n",
            "Epoch #5. Accuracy on batch 859/2438  on Training is 68.55377906976744\n",
            "Batch Id 860/2438 is having training loss of 1.1473298072814941\n",
            "1.107548475265503\n",
            "Epoch #5. Accuracy on batch 860/2438  on Training is 68.56489547038328\n",
            "Epoch #5. Accuracy on batch 861/2438  on Training is 68.56873549883991\n",
            "Epoch #5. Accuracy on batch 862/2438  on Training is 68.57256662804171\n",
            "Epoch #5. Accuracy on batch 863/2438  on Training is 68.59447337962963\n",
            "Epoch #5. Accuracy on batch 864/2438  on Training is 68.60187861271676\n",
            "Epoch #5. Accuracy on batch 865/2438  on Training is 68.59122401847576\n",
            "Epoch #5. Accuracy on batch 866/2438  on Training is 68.59140715109574\n",
            "Epoch #5. Accuracy on batch 867/2438  on Training is 68.59158986175115\n",
            "Epoch #5. Accuracy on batch 868/2438  on Training is 68.60256041426928\n",
            "Epoch #5. Accuracy on batch 869/2438  on Training is 68.61350574712644\n",
            "Epoch #5. Accuracy on batch 870/2438  on Training is 68.60289896670494\n",
            "Epoch #5. Accuracy on batch 871/2438  on Training is 68.58873279816514\n",
            "Epoch #5. Accuracy on batch 872/2438  on Training is 68.5745990836197\n",
            "Epoch #5. Accuracy on batch 873/2438  on Training is 68.58910183066362\n",
            "Epoch #5. Accuracy on batch 874/2438  on Training is 68.59285714285714\n",
            "Epoch #5. Accuracy on batch 875/2438  on Training is 68.58233447488584\n",
            "Epoch #5. Accuracy on batch 876/2438  on Training is 68.57539908779931\n",
            "Epoch #5. Accuracy on batch 877/2438  on Training is 68.56847949886105\n",
            "Epoch #5. Accuracy on batch 878/2438  on Training is 68.57579635949944\n",
            "Epoch #5. Accuracy on batch 879/2438  on Training is 68.57599431818181\n",
            "Batch Id 880/2438 is having training loss of 1.1472638845443726\n",
            "1.3150076866149902\n",
            "Epoch #5. Accuracy on batch 880/2438  on Training is 68.5832860385925\n",
            "Epoch #5. Accuracy on batch 881/2438  on Training is 68.56930272108843\n",
            "Epoch #5. Accuracy on batch 882/2438  on Training is 68.58366364665912\n",
            "Epoch #5. Accuracy on batch 883/2438  on Training is 68.58385180995475\n",
            "Epoch #5. Accuracy on batch 884/2438  on Training is 68.58050847457628\n",
            "Epoch #5. Accuracy on batch 885/2438  on Training is 68.59128103837472\n",
            "Epoch #5. Accuracy on batch 886/2438  on Training is 68.58793686583991\n",
            "Epoch #5. Accuracy on batch 887/2438  on Training is 68.58811936936937\n",
            "Epoch #5. Accuracy on batch 888/2438  on Training is 68.5883014623172\n",
            "Epoch #5. Accuracy on batch 889/2438  on Training is 68.6060393258427\n",
            "Epoch #5. Accuracy on batch 890/2438  on Training is 68.60970819304153\n",
            "Epoch #5. Accuracy on batch 891/2438  on Training is 68.63088565022422\n",
            "Epoch #5. Accuracy on batch 892/2438  on Training is 68.61352183650617\n",
            "Epoch #5. Accuracy on batch 893/2438  on Training is 68.60668344519016\n",
            "Epoch #5. Accuracy on batch 894/2438  on Training is 68.59986033519553\n",
            "Epoch #5. Accuracy on batch 895/2438  on Training is 68.60700334821429\n",
            "Epoch #5. Accuracy on batch 896/2438  on Training is 68.61761426978818\n",
            "Epoch #5. Accuracy on batch 897/2438  on Training is 68.6212416481069\n",
            "Epoch #5. Accuracy on batch 898/2438  on Training is 68.62486095661846\n",
            "Epoch #5. Accuracy on batch 899/2438  on Training is 68.62847222222223\n",
            "Batch Id 900/2438 is having training loss of 1.1455762386322021\n",
            "0.7542038559913635\n",
            "Epoch #5. Accuracy on batch 900/2438  on Training is 68.64594894561598\n",
            "Epoch #5. Accuracy on batch 901/2438  on Training is 68.64259977827051\n",
            "Epoch #5. Accuracy on batch 902/2438  on Training is 68.64964008859357\n",
            "Epoch #5. Accuracy on batch 903/2438  on Training is 68.63246681415929\n",
            "Epoch #5. Accuracy on batch 904/2438  on Training is 68.63950276243094\n",
            "Epoch #5. Accuracy on batch 905/2438  on Training is 68.64307395143487\n",
            "Epoch #5. Accuracy on batch 906/2438  on Training is 68.62596471885337\n",
            "Epoch #5. Accuracy on batch 907/2438  on Training is 68.6261013215859\n",
            "Epoch #5. Accuracy on batch 908/2438  on Training is 68.62967546754676\n",
            "Epoch #5. Accuracy on batch 909/2438  on Training is 68.60576923076923\n",
            "Epoch #5. Accuracy on batch 910/2438  on Training is 68.61278814489572\n",
            "Epoch #5. Accuracy on batch 911/2438  on Training is 68.61293859649123\n",
            "Epoch #5. Accuracy on batch 912/2438  on Training is 68.62335706462213\n",
            "Epoch #5. Accuracy on batch 913/2438  on Training is 68.62007658643326\n",
            "Epoch #5. Accuracy on batch 914/2438  on Training is 68.62021857923497\n",
            "Epoch #5. Accuracy on batch 915/2438  on Training is 68.62718340611353\n",
            "Epoch #5. Accuracy on batch 916/2438  on Training is 68.64776444929117\n",
            "Epoch #5. Accuracy on batch 917/2438  on Training is 68.6444716775599\n",
            "Epoch #5. Accuracy on batch 918/2438  on Training is 68.65818824809575\n",
            "Epoch #5. Accuracy on batch 919/2438  on Training is 68.67527173913044\n",
            "Batch Id 920/2438 is having training loss of 1.1452124118804932\n",
            "1.2829080820083618\n",
            "Epoch #5. Accuracy on batch 920/2438  on Training is 68.67535287730728\n",
            "Epoch #5. Accuracy on batch 921/2438  on Training is 68.69915943600867\n",
            "Epoch #5. Accuracy on batch 922/2438  on Training is 68.69921451787648\n",
            "Epoch #5. Accuracy on batch 923/2438  on Training is 68.6823593073593\n",
            "Epoch #5. Accuracy on batch 924/2438  on Training is 68.6858108108108\n",
            "Epoch #5. Accuracy on batch 925/2438  on Training is 68.67913066954644\n",
            "Epoch #5. Accuracy on batch 926/2438  on Training is 68.65223840345199\n",
            "Epoch #5. Accuracy on batch 927/2438  on Training is 68.6388739224138\n",
            "Epoch #5. Accuracy on batch 928/2438  on Training is 68.65244886975242\n",
            "Epoch #5. Accuracy on batch 929/2438  on Training is 68.65255376344086\n",
            "Epoch #5. Accuracy on batch 930/2438  on Training is 68.63923200859291\n",
            "Epoch #5. Accuracy on batch 931/2438  on Training is 68.6393508583691\n",
            "Epoch #5. Accuracy on batch 932/2438  on Training is 68.63946945337621\n",
            "Epoch #5. Accuracy on batch 933/2438  on Training is 68.65297109207708\n",
            "Epoch #5. Accuracy on batch 934/2438  on Training is 68.65641711229947\n",
            "Epoch #5. Accuracy on batch 935/2438  on Training is 68.65651709401709\n",
            "Epoch #5. Accuracy on batch 936/2438  on Training is 68.65661686232657\n",
            "Epoch #5. Accuracy on batch 937/2438  on Training is 68.66004797441364\n",
            "Epoch #5. Accuracy on batch 938/2438  on Training is 68.66014376996804\n",
            "Epoch #5. Accuracy on batch 939/2438  on Training is 68.66688829787235\n",
            "Batch Id 940/2438 is having training loss of 1.146088719367981\n",
            "1.2716538906097412\n",
            "Epoch #5. Accuracy on batch 940/2438  on Training is 68.66033475026568\n",
            "Epoch #5. Accuracy on batch 941/2438  on Training is 68.67038216560509\n",
            "Epoch #5. Accuracy on batch 942/2438  on Training is 68.67709437963944\n",
            "Epoch #5. Accuracy on batch 943/2438  on Training is 68.67386122881356\n",
            "Epoch #5. Accuracy on batch 944/2438  on Training is 68.67724867724868\n",
            "Epoch #5. Accuracy on batch 945/2438  on Training is 68.6872357293869\n",
            "Epoch #5. Accuracy on batch 946/2438  on Training is 68.69720168954593\n",
            "Epoch #5. Accuracy on batch 947/2438  on Training is 68.70055379746836\n",
            "Epoch #5. Accuracy on batch 948/2438  on Training is 68.67755532139094\n",
            "Epoch #5. Accuracy on batch 949/2438  on Training is 68.67434210526316\n",
            "Epoch #5. Accuracy on batch 950/2438  on Training is 68.65470557308096\n",
            "Epoch #5. Accuracy on batch 951/2438  on Training is 68.6548056722689\n",
            "Epoch #5. Accuracy on batch 952/2438  on Training is 68.66802203567681\n",
            "Epoch #5. Accuracy on batch 953/2438  on Training is 68.68448637316561\n",
            "Epoch #5. Accuracy on batch 954/2438  on Training is 68.70091623036649\n",
            "Epoch #5. Accuracy on batch 955/2438  on Training is 68.7140428870293\n",
            "Epoch #5. Accuracy on batch 956/2438  on Training is 68.71734587251828\n",
            "Epoch #5. Accuracy on batch 957/2438  on Training is 68.72390396659708\n",
            "Epoch #5. Accuracy on batch 958/2438  on Training is 68.72393117831074\n",
            "Epoch #5. Accuracy on batch 959/2438  on Training is 68.720703125\n",
            "Batch Id 960/2438 is having training loss of 1.1450541019439697\n",
            "0.8168990015983582\n",
            "Epoch #5. Accuracy on batch 960/2438  on Training is 68.7272372528616\n",
            "Epoch #5. Accuracy on batch 961/2438  on Training is 68.72726091476092\n",
            "Epoch #5. Accuracy on batch 962/2438  on Training is 68.7435098650052\n",
            "Epoch #5. Accuracy on batch 963/2438  on Training is 68.74027489626556\n",
            "Epoch #5. Accuracy on batch 964/2438  on Training is 68.74352331606218\n",
            "Epoch #5. Accuracy on batch 965/2438  on Training is 68.73706004140787\n",
            "Epoch #5. Accuracy on batch 966/2438  on Training is 68.733841778697\n",
            "Epoch #5. Accuracy on batch 967/2438  on Training is 68.73385847107438\n",
            "Epoch #5. Accuracy on batch 968/2438  on Training is 68.73387512899897\n",
            "Epoch #5. Accuracy on batch 969/2438  on Training is 68.74355670103093\n",
            "Epoch #5. Accuracy on batch 970/2438  on Training is 68.73390834191555\n",
            "Epoch #5. Accuracy on batch 971/2438  on Training is 68.73070987654322\n",
            "Epoch #5. Accuracy on batch 972/2438  on Training is 68.73072970195273\n",
            "Epoch #5. Accuracy on batch 973/2438  on Training is 68.71791581108829\n",
            "Epoch #5. Accuracy on batch 974/2438  on Training is 68.72435897435898\n",
            "Epoch #5. Accuracy on batch 975/2438  on Training is 68.72118340163935\n",
            "Epoch #5. Accuracy on batch 976/2438  on Training is 68.72761003070624\n",
            "Epoch #5. Accuracy on batch 977/2438  on Training is 68.7308282208589\n",
            "Epoch #5. Accuracy on batch 978/2438  on Training is 68.73723186925434\n",
            "Epoch #5. Accuracy on batch 979/2438  on Training is 68.74043367346938\n",
            "Batch Id 980/2438 is having training loss of 1.145088791847229\n",
            "1.007529377937317\n",
            "Epoch #5. Accuracy on batch 980/2438  on Training is 68.74362895005096\n",
            "Epoch #5. Accuracy on batch 981/2438  on Training is 68.75636456211812\n",
            "Epoch #5. Accuracy on batch 982/2438  on Training is 68.76271617497457\n",
            "Epoch #5. Accuracy on batch 983/2438  on Training is 68.76270325203252\n",
            "Epoch #5. Accuracy on batch 984/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 985/2438  on Training is 68.74683062880325\n",
            "Epoch #5. Accuracy on batch 986/2438  on Training is 68.73733535967578\n",
            "Epoch #5. Accuracy on batch 987/2438  on Training is 68.74051113360323\n",
            "Epoch #5. Accuracy on batch 988/2438  on Training is 68.75\n",
            "Epoch #5. Accuracy on batch 989/2438  on Training is 68.75315656565657\n",
            "Epoch #5. Accuracy on batch 990/2438  on Training is 68.75630676084762\n",
            "Epoch #5. Accuracy on batch 991/2438  on Training is 68.77520161290323\n",
            "Epoch #5. Accuracy on batch 992/2438  on Training is 68.77517623363545\n",
            "Epoch #5. Accuracy on batch 993/2438  on Training is 68.7751509054326\n",
            "Epoch #5. Accuracy on batch 994/2438  on Training is 68.77198492462311\n",
            "Epoch #5. Accuracy on batch 995/2438  on Training is 68.77196285140562\n",
            "Epoch #5. Accuracy on batch 996/2438  on Training is 68.77507522567703\n",
            "Epoch #5. Accuracy on batch 997/2438  on Training is 68.77818136272545\n",
            "Epoch #5. Accuracy on batch 998/2438  on Training is 68.76876876876877\n",
            "Epoch #5. Accuracy on batch 999/2438  on Training is 68.765625\n",
            "Batch Id 1000/2438 is having training loss of 1.1444774866104126\n",
            "1.1309431791305542\n",
            "Epoch #5. Accuracy on batch 1000/2438  on Training is 68.76560939060938\n",
            "Epoch #5. Accuracy on batch 1001/2438  on Training is 68.7562375249501\n",
            "Epoch #5. Accuracy on batch 1002/2438  on Training is 68.76557826520438\n",
            "Epoch #5. Accuracy on batch 1003/2438  on Training is 68.7562250996016\n",
            "Epoch #5. Accuracy on batch 1004/2438  on Training is 68.75932835820896\n",
            "Epoch #5. Accuracy on batch 1005/2438  on Training is 68.77174453280318\n",
            "Epoch #5. Accuracy on batch 1006/2438  on Training is 68.78413604766634\n",
            "Epoch #5. Accuracy on batch 1007/2438  on Training is 68.77480158730158\n",
            "Epoch #5. Accuracy on batch 1008/2438  on Training is 68.78097125867195\n",
            "Epoch #5. Accuracy on batch 1009/2438  on Training is 68.77475247524752\n",
            "Epoch #5. Accuracy on batch 1010/2438  on Training is 68.77781899109792\n",
            "Epoch #5. Accuracy on batch 1011/2438  on Training is 68.77161561264822\n",
            "Epoch #5. Accuracy on batch 1012/2438  on Training is 68.76233958538992\n",
            "Epoch #5. Accuracy on batch 1013/2438  on Training is 68.75616370808679\n",
            "Epoch #5. Accuracy on batch 1014/2438  on Training is 68.75615763546799\n",
            "Epoch #5. Accuracy on batch 1015/2438  on Training is 68.7623031496063\n",
            "Epoch #5. Accuracy on batch 1016/2438  on Training is 68.7715093411996\n",
            "Epoch #5. Accuracy on batch 1017/2438  on Training is 68.77762770137525\n",
            "Epoch #5. Accuracy on batch 1018/2438  on Training is 68.78373405299313\n",
            "Epoch #5. Accuracy on batch 1019/2438  on Training is 68.79595588235294\n",
            "Batch Id 1020/2438 is having training loss of 1.1428686380386353\n",
            "1.1298967599868774\n",
            "Epoch #5. Accuracy on batch 1020/2438  on Training is 68.80203232125368\n",
            "Epoch #5. Accuracy on batch 1021/2438  on Training is 68.79586594911937\n",
            "Epoch #5. Accuracy on batch 1022/2438  on Training is 68.79887585532747\n",
            "Epoch #5. Accuracy on batch 1023/2438  on Training is 68.804931640625\n",
            "Epoch #5. Accuracy on batch 1024/2438  on Training is 68.8048780487805\n",
            "Epoch #5. Accuracy on batch 1025/2438  on Training is 68.8048245614035\n",
            "Epoch #5. Accuracy on batch 1026/2438  on Training is 68.81389970788705\n",
            "Epoch #5. Accuracy on batch 1027/2438  on Training is 68.82295719844358\n",
            "Epoch #5. Accuracy on batch 1028/2438  on Training is 68.81073858114675\n",
            "Epoch #5. Accuracy on batch 1029/2438  on Training is 68.80461165048544\n",
            "Epoch #5. Accuracy on batch 1030/2438  on Training is 68.81062075654704\n",
            "Epoch #5. Accuracy on batch 1031/2438  on Training is 68.81056201550388\n",
            "Epoch #5. Accuracy on batch 1032/2438  on Training is 68.8195788964182\n",
            "Epoch #5. Accuracy on batch 1033/2438  on Training is 68.82555609284333\n",
            "Epoch #5. Accuracy on batch 1034/2438  on Training is 68.82850241545894\n",
            "Epoch #5. Accuracy on batch 1035/2438  on Training is 68.83445945945945\n",
            "Epoch #5. Accuracy on batch 1036/2438  on Training is 68.84341851494696\n",
            "Epoch #5. Accuracy on batch 1037/2438  on Training is 68.83429672447014\n",
            "Epoch #5. Accuracy on batch 1038/2438  on Training is 68.84323869104908\n",
            "Epoch #5. Accuracy on batch 1039/2438  on Training is 68.84915865384616\n",
            "Batch Id 1040/2438 is having training loss of 1.1407581567764282\n",
            "0.905292809009552\n",
            "Epoch #5. Accuracy on batch 1040/2438  on Training is 68.85506724303555\n",
            "Epoch #5. Accuracy on batch 1041/2438  on Training is 68.85196737044146\n",
            "Epoch #5. Accuracy on batch 1042/2438  on Training is 68.84288111217641\n",
            "Epoch #5. Accuracy on batch 1043/2438  on Training is 68.84578544061303\n",
            "Epoch #5. Accuracy on batch 1044/2438  on Training is 68.8427033492823\n",
            "Epoch #5. Accuracy on batch 1045/2438  on Training is 68.83066443594646\n",
            "Epoch #5. Accuracy on batch 1046/2438  on Training is 68.83058739255014\n",
            "Epoch #5. Accuracy on batch 1047/2438  on Training is 68.84243797709924\n",
            "Epoch #5. Accuracy on batch 1048/2438  on Training is 68.8512869399428\n",
            "Epoch #5. Accuracy on batch 1049/2438  on Training is 68.85416666666667\n",
            "Epoch #5. Accuracy on batch 1050/2438  on Training is 68.8570409134158\n",
            "Epoch #5. Accuracy on batch 1051/2438  on Training is 68.86882129277566\n",
            "Epoch #5. Accuracy on batch 1052/2438  on Training is 68.8627730294397\n",
            "Epoch #5. Accuracy on batch 1053/2438  on Training is 68.86859582542695\n",
            "Epoch #5. Accuracy on batch 1054/2438  on Training is 68.85959715639811\n",
            "Epoch #5. Accuracy on batch 1055/2438  on Training is 68.85061553030303\n",
            "Epoch #5. Accuracy on batch 1056/2438  on Training is 68.84756385998108\n",
            "Epoch #5. Accuracy on batch 1057/2438  on Training is 68.84747164461248\n",
            "Epoch #5. Accuracy on batch 1058/2438  on Training is 68.84442870632672\n",
            "Epoch #5. Accuracy on batch 1059/2438  on Training is 68.84139150943396\n",
            "Batch Id 1060/2438 is having training loss of 1.1411172151565552\n",
            "1.174422025680542\n",
            "Epoch #5. Accuracy on batch 1060/2438  on Training is 68.8442507068803\n",
            "Epoch #5. Accuracy on batch 1061/2438  on Training is 68.83533427495291\n",
            "Epoch #5. Accuracy on batch 1062/2438  on Training is 68.84407337723424\n",
            "Epoch #5. Accuracy on batch 1063/2438  on Training is 68.8469219924812\n",
            "Epoch #5. Accuracy on batch 1064/2438  on Training is 68.83802816901408\n",
            "Epoch #5. Accuracy on batch 1065/2438  on Training is 68.83794559099437\n",
            "Epoch #5. Accuracy on batch 1066/2438  on Training is 68.83786316776008\n",
            "Epoch #5. Accuracy on batch 1067/2438  on Training is 68.82607677902622\n",
            "Epoch #5. Accuracy on batch 1068/2438  on Training is 68.83185219831618\n",
            "Epoch #5. Accuracy on batch 1069/2438  on Training is 68.83177570093459\n",
            "Epoch #5. Accuracy on batch 1070/2438  on Training is 68.82878151260505\n",
            "Epoch #5. Accuracy on batch 1071/2438  on Training is 68.83453824626865\n",
            "Epoch #5. Accuracy on batch 1072/2438  on Training is 68.83445945945945\n",
            "Epoch #5. Accuracy on batch 1073/2438  on Training is 68.8372905027933\n",
            "Epoch #5. Accuracy on batch 1074/2438  on Training is 68.84011627906976\n",
            "Epoch #5. Accuracy on batch 1075/2438  on Training is 68.82551115241635\n",
            "Epoch #5. Accuracy on batch 1076/2438  on Training is 68.81093314763231\n",
            "Epoch #5. Accuracy on batch 1077/2438  on Training is 68.80797773654916\n",
            "Epoch #5. Accuracy on batch 1078/2438  on Training is 68.79923540315107\n",
            "Epoch #5. Accuracy on batch 1079/2438  on Training is 68.78182870370371\n",
            "Batch Id 1080/2438 is having training loss of 1.1427907943725586\n",
            "1.0962320566177368\n",
            "Epoch #5. Accuracy on batch 1080/2438  on Training is 68.78179925994449\n",
            "Epoch #5. Accuracy on batch 1081/2438  on Training is 68.77599353049908\n",
            "Epoch #5. Accuracy on batch 1082/2438  on Training is 68.76442751615882\n",
            "Epoch #5. Accuracy on batch 1083/2438  on Training is 68.77882841328413\n",
            "Epoch #5. Accuracy on batch 1084/2438  on Training is 68.77592165898618\n",
            "Epoch #5. Accuracy on batch 1085/2438  on Training is 68.75863259668509\n",
            "Epoch #5. Accuracy on batch 1086/2438  on Training is 68.764374425023\n",
            "Epoch #5. Accuracy on batch 1087/2438  on Training is 68.76436121323529\n",
            "Epoch #5. Accuracy on batch 1088/2438  on Training is 68.77582644628099\n",
            "Epoch #5. Accuracy on batch 1089/2438  on Training is 68.7815366972477\n",
            "Epoch #5. Accuracy on batch 1090/2438  on Training is 68.77577910174152\n",
            "Epoch #5. Accuracy on batch 1091/2438  on Training is 68.76717032967034\n",
            "Epoch #5. Accuracy on batch 1092/2438  on Training is 68.78145013723696\n",
            "Epoch #5. Accuracy on batch 1093/2438  on Training is 68.78999085923218\n",
            "Epoch #5. Accuracy on batch 1094/2438  on Training is 68.78995433789954\n",
            "Epoch #5. Accuracy on batch 1095/2438  on Training is 68.7813640510949\n",
            "Epoch #5. Accuracy on batch 1096/2438  on Training is 68.78988149498633\n",
            "Epoch #5. Accuracy on batch 1097/2438  on Training is 68.7898451730419\n",
            "Epoch #5. Accuracy on batch 1098/2438  on Training is 68.77843494085532\n",
            "Epoch #5. Accuracy on batch 1099/2438  on Training is 68.77556818181819\n",
            "Batch Id 1100/2438 is having training loss of 1.1433820724487305\n",
            "1.081207275390625\n",
            "Epoch #5. Accuracy on batch 1100/2438  on Training is 68.77838328792008\n",
            "Epoch #5. Accuracy on batch 1101/2438  on Training is 68.78970054446461\n",
            "Epoch #5. Accuracy on batch 1102/2438  on Training is 68.79816409791478\n",
            "Epoch #5. Accuracy on batch 1103/2438  on Training is 68.79528985507247\n",
            "Epoch #5. Accuracy on batch 1104/2438  on Training is 68.79242081447964\n",
            "Epoch #5. Accuracy on batch 1105/2438  on Training is 68.7867314647378\n",
            "Epoch #5. Accuracy on batch 1106/2438  on Training is 68.79234417344173\n",
            "Epoch #5. Accuracy on batch 1107/2438  on Training is 68.79794675090253\n",
            "Epoch #5. Accuracy on batch 1108/2438  on Training is 68.8091749323715\n",
            "Epoch #5. Accuracy on batch 1109/2438  on Training is 68.81193693693693\n",
            "Epoch #5. Accuracy on batch 1110/2438  on Training is 68.81188118811882\n",
            "Epoch #5. Accuracy on batch 1111/2438  on Training is 68.8005845323741\n",
            "Epoch #5. Accuracy on batch 1112/2438  on Training is 68.79211590296497\n",
            "Epoch #5. Accuracy on batch 1113/2438  on Training is 68.78646768402155\n",
            "Epoch #5. Accuracy on batch 1114/2438  on Training is 68.8060538116592\n",
            "Epoch #5. Accuracy on batch 1115/2438  on Training is 68.80600358422939\n",
            "Epoch #5. Accuracy on batch 1116/2438  on Training is 68.80595344673232\n",
            "Epoch #5. Accuracy on batch 1117/2438  on Training is 68.80869856887298\n",
            "Epoch #5. Accuracy on batch 1118/2438  on Training is 68.80864611260054\n",
            "Epoch #5. Accuracy on batch 1119/2438  on Training is 68.81975446428571\n",
            "Batch Id 1120/2438 is having training loss of 1.1422617435455322\n",
            "1.1943297386169434\n",
            "Epoch #5. Accuracy on batch 1120/2438  on Training is 68.81969223907225\n",
            "Epoch #5. Accuracy on batch 1121/2438  on Training is 68.82520053475936\n",
            "Epoch #5. Accuracy on batch 1122/2438  on Training is 68.80843722172752\n",
            "Epoch #5. Accuracy on batch 1123/2438  on Training is 68.82228647686833\n",
            "Epoch #5. Accuracy on batch 1124/2438  on Training is 68.81111111111112\n",
            "Epoch #5. Accuracy on batch 1125/2438  on Training is 68.8110568383659\n",
            "Epoch #5. Accuracy on batch 1126/2438  on Training is 68.81932120674357\n",
            "Epoch #5. Accuracy on batch 1127/2438  on Training is 68.81925975177305\n",
            "Epoch #5. Accuracy on batch 1128/2438  on Training is 68.81643046944198\n",
            "Epoch #5. Accuracy on batch 1129/2438  on Training is 68.81637168141593\n",
            "Epoch #5. Accuracy on batch 1130/2438  on Training is 68.8052608311229\n",
            "Epoch #5. Accuracy on batch 1131/2438  on Training is 68.79969081272085\n",
            "Epoch #5. Accuracy on batch 1132/2438  on Training is 68.80792144748456\n",
            "Epoch #5. Accuracy on batch 1133/2438  on Training is 68.81338183421516\n",
            "Epoch #5. Accuracy on batch 1134/2438  on Training is 68.81057268722466\n",
            "Epoch #5. Accuracy on batch 1135/2438  on Training is 68.81602112676056\n",
            "Epoch #5. Accuracy on batch 1136/2438  on Training is 68.81596306068602\n",
            "Epoch #5. Accuracy on batch 1137/2438  on Training is 68.8213971880492\n",
            "Epoch #5. Accuracy on batch 1138/2438  on Training is 68.82407813871818\n",
            "Epoch #5. Accuracy on batch 1139/2438  on Training is 68.81030701754386\n",
            "Batch Id 1140/2438 is having training loss of 1.142964482307434\n",
            "1.1458921432495117\n",
            "Epoch #5. Accuracy on batch 1140/2438  on Training is 68.80203768624014\n",
            "Epoch #5. Accuracy on batch 1141/2438  on Training is 68.81293782837128\n",
            "Epoch #5. Accuracy on batch 1142/2438  on Training is 68.8183508311461\n",
            "Epoch #5. Accuracy on batch 1143/2438  on Training is 68.82375437062937\n",
            "Epoch #5. Accuracy on batch 1144/2438  on Training is 68.82914847161572\n",
            "Epoch #5. Accuracy on batch 1145/2438  on Training is 68.83998691099477\n",
            "Epoch #5. Accuracy on batch 1146/2438  on Training is 68.83445945945945\n",
            "Epoch #5. Accuracy on batch 1147/2438  on Training is 68.83983013937282\n",
            "Epoch #5. Accuracy on batch 1148/2438  on Training is 68.83703220191471\n",
            "Epoch #5. Accuracy on batch 1149/2438  on Training is 68.83967391304348\n",
            "Epoch #5. Accuracy on batch 1150/2438  on Training is 68.84231103388358\n",
            "Epoch #5. Accuracy on batch 1151/2438  on Training is 68.85308159722223\n",
            "Epoch #5. Accuracy on batch 1152/2438  on Training is 68.8529921942758\n",
            "Epoch #5. Accuracy on batch 1153/2438  on Training is 68.8556109185442\n",
            "Epoch #5. Accuracy on batch 1154/2438  on Training is 68.86093073593074\n",
            "Epoch #5. Accuracy on batch 1155/2438  on Training is 68.85272491349481\n",
            "Epoch #5. Accuracy on batch 1156/2438  on Training is 68.86884183232497\n",
            "Epoch #5. Accuracy on batch 1157/2438  on Training is 68.87413644214162\n",
            "Epoch #5. Accuracy on batch 1158/2438  on Training is 68.88211820534944\n",
            "Epoch #5. Accuracy on batch 1159/2438  on Training is 68.87392241379311\n",
            "Batch Id 1160/2438 is having training loss of 1.1404380798339844\n",
            "1.0075082778930664\n",
            "Epoch #5. Accuracy on batch 1160/2438  on Training is 68.87381567614126\n",
            "Epoch #5. Accuracy on batch 1161/2438  on Training is 68.87101979345955\n",
            "Epoch #5. Accuracy on batch 1162/2438  on Training is 68.87628976784178\n",
            "Epoch #5. Accuracy on batch 1163/2438  on Training is 68.87618127147766\n",
            "Epoch #5. Accuracy on batch 1164/2438  on Training is 68.8760729613734\n",
            "Epoch #5. Accuracy on batch 1165/2438  on Training is 68.87060463121784\n",
            "Epoch #5. Accuracy on batch 1166/2438  on Training is 68.86782347900599\n",
            "Epoch #5. Accuracy on batch 1167/2438  on Training is 68.87307363013699\n",
            "Epoch #5. Accuracy on batch 1168/2438  on Training is 68.8809880239521\n",
            "Epoch #5. Accuracy on batch 1169/2438  on Training is 68.8755341880342\n",
            "Epoch #5. Accuracy on batch 1170/2438  on Training is 68.88076430401367\n",
            "Epoch #5. Accuracy on batch 1171/2438  on Training is 68.88598549488054\n",
            "Epoch #5. Accuracy on batch 1172/2438  on Training is 68.88054134697357\n",
            "Epoch #5. Accuracy on batch 1173/2438  on Training is 68.88309199318569\n",
            "Epoch #5. Accuracy on batch 1174/2438  on Training is 68.87234042553192\n",
            "Epoch #5. Accuracy on batch 1175/2438  on Training is 68.86957908163265\n",
            "Epoch #5. Accuracy on batch 1176/2438  on Training is 68.86682242990655\n",
            "Epoch #5. Accuracy on batch 1177/2438  on Training is 68.86937606112055\n",
            "Epoch #5. Accuracy on batch 1178/2438  on Training is 68.85337150127226\n",
            "Epoch #5. Accuracy on batch 1179/2438  on Training is 68.86122881355932\n",
            "Batch Id 1180/2438 is having training loss of 1.1405820846557617\n",
            "1.1886165142059326\n",
            "Epoch #5. Accuracy on batch 1180/2438  on Training is 68.86113463166808\n",
            "Epoch #5. Accuracy on batch 1181/2438  on Training is 68.87425972927242\n",
            "Epoch #5. Accuracy on batch 1182/2438  on Training is 68.88207945900254\n",
            "Epoch #5. Accuracy on batch 1183/2438  on Training is 68.88460726351352\n",
            "Epoch #5. Accuracy on batch 1184/2438  on Training is 68.88449367088607\n",
            "Epoch #5. Accuracy on batch 1185/2438  on Training is 68.88965008431703\n",
            "Epoch #5. Accuracy on batch 1186/2438  on Training is 68.8921651221567\n",
            "Epoch #5. Accuracy on batch 1187/2438  on Training is 68.89993686868686\n",
            "Epoch #5. Accuracy on batch 1188/2438  on Training is 68.91032380151388\n",
            "Epoch #5. Accuracy on batch 1189/2438  on Training is 68.9154411764706\n",
            "Epoch #5. Accuracy on batch 1190/2438  on Training is 68.92317380352645\n",
            "Epoch #5. Accuracy on batch 1191/2438  on Training is 68.93089345637584\n",
            "Epoch #5. Accuracy on batch 1192/2438  on Training is 68.9386001676446\n",
            "Epoch #5. Accuracy on batch 1193/2438  on Training is 68.93582495812396\n",
            "Epoch #5. Accuracy on batch 1194/2438  on Training is 68.92520920502092\n",
            "Epoch #5. Accuracy on batch 1195/2438  on Training is 68.93028846153847\n",
            "Epoch #5. Accuracy on batch 1196/2438  on Training is 68.9249164578112\n",
            "Epoch #5. Accuracy on batch 1197/2438  on Training is 68.93259599332221\n",
            "Epoch #5. Accuracy on batch 1198/2438  on Training is 68.93505004170142\n",
            "Epoch #5. Accuracy on batch 1199/2438  on Training is 68.94791666666667\n",
            "Batch Id 1200/2438 is having training loss of 1.1378666162490845\n",
            "1.0612341165542603\n",
            "Epoch #5. Accuracy on batch 1200/2438  on Training is 68.94514987510408\n",
            "Epoch #5. Accuracy on batch 1201/2438  on Training is 68.95278702163061\n",
            "Epoch #5. Accuracy on batch 1202/2438  on Training is 68.96300914380714\n",
            "Epoch #5. Accuracy on batch 1203/2438  on Training is 68.96283222591362\n",
            "Epoch #5. Accuracy on batch 1204/2438  on Training is 68.95746887966806\n",
            "Epoch #5. Accuracy on batch 1205/2438  on Training is 68.9547056384743\n",
            "Epoch #5. Accuracy on batch 1206/2438  on Training is 68.95712510356255\n",
            "Epoch #5. Accuracy on batch 1207/2438  on Training is 68.96730132450331\n",
            "Epoch #5. Accuracy on batch 1208/2438  on Training is 68.96970636889992\n",
            "Epoch #5. Accuracy on batch 1209/2438  on Training is 68.97469008264463\n",
            "Epoch #5. Accuracy on batch 1210/2438  on Training is 68.96676300578035\n",
            "Epoch #5. Accuracy on batch 1211/2438  on Training is 68.9743193069307\n",
            "Epoch #5. Accuracy on batch 1212/2438  on Training is 68.96640560593569\n",
            "Epoch #5. Accuracy on batch 1213/2438  on Training is 68.97909802306425\n",
            "Epoch #5. Accuracy on batch 1214/2438  on Training is 68.98148148148148\n",
            "Epoch #5. Accuracy on batch 1215/2438  on Training is 68.97872121710526\n",
            "Epoch #5. Accuracy on batch 1216/2438  on Training is 68.97596548890715\n",
            "Epoch #5. Accuracy on batch 1217/2438  on Training is 68.95525451559935\n",
            "Epoch #5. Accuracy on batch 1218/2438  on Training is 68.96277686628385\n",
            "Epoch #5. Accuracy on batch 1219/2438  on Training is 68.96516393442623\n",
            "Batch Id 1220/2438 is having training loss of 1.136864185333252\n",
            "1.2394517660140991\n",
            "Epoch #5. Accuracy on batch 1220/2438  on Training is 68.95986895986896\n",
            "Epoch #5. Accuracy on batch 1221/2438  on Training is 68.94946808510639\n",
            "Epoch #5. Accuracy on batch 1222/2438  on Training is 68.94674979558462\n",
            "Epoch #5. Accuracy on batch 1223/2438  on Training is 68.94914215686275\n",
            "Epoch #5. Accuracy on batch 1224/2438  on Training is 68.94642857142857\n",
            "Epoch #5. Accuracy on batch 1225/2438  on Training is 68.94626835236542\n",
            "Epoch #5. Accuracy on batch 1226/2438  on Training is 68.94610839445802\n",
            "Epoch #5. Accuracy on batch 1227/2438  on Training is 68.9459486970684\n",
            "Epoch #5. Accuracy on batch 1228/2438  on Training is 68.95850284784377\n",
            "Epoch #5. Accuracy on batch 1229/2438  on Training is 68.96341463414635\n",
            "Epoch #5. Accuracy on batch 1230/2438  on Training is 68.96324126726239\n",
            "Epoch #5. Accuracy on batch 1231/2438  on Training is 68.95292207792208\n",
            "Epoch #5. Accuracy on batch 1232/2438  on Training is 68.95529197080292\n",
            "Epoch #5. Accuracy on batch 1233/2438  on Training is 68.95512560777958\n",
            "Epoch #5. Accuracy on batch 1234/2438  on Training is 68.9423076923077\n",
            "Epoch #5. Accuracy on batch 1235/2438  on Training is 68.94215210355988\n",
            "Epoch #5. Accuracy on batch 1236/2438  on Training is 68.94957558609539\n",
            "Epoch #5. Accuracy on batch 1237/2438  on Training is 68.9468901453958\n",
            "Epoch #5. Accuracy on batch 1238/2438  on Training is 68.95429782082324\n",
            "Epoch #5. Accuracy on batch 1239/2438  on Training is 68.95413306451613\n",
            "Batch Id 1240/2438 is having training loss of 1.1379055976867676\n",
            "1.2593271732330322\n",
            "Epoch #5. Accuracy on batch 1240/2438  on Training is 68.95396857373086\n",
            "Epoch #5. Accuracy on batch 1241/2438  on Training is 68.94373993558776\n",
            "Epoch #5. Accuracy on batch 1242/2438  on Training is 68.93604183427192\n",
            "Epoch #5. Accuracy on batch 1243/2438  on Training is 68.93338022508038\n",
            "Epoch #5. Accuracy on batch 1244/2438  on Training is 68.93574297188755\n",
            "Epoch #5. Accuracy on batch 1245/2438  on Training is 68.93559390048154\n",
            "Epoch #5. Accuracy on batch 1246/2438  on Training is 68.94296311146752\n",
            "Epoch #5. Accuracy on batch 1247/2438  on Training is 68.9453125\n",
            "Epoch #5. Accuracy on batch 1248/2438  on Training is 68.93014411529224\n",
            "Epoch #5. Accuracy on batch 1249/2438  on Training is 68.9425\n",
            "Epoch #5. Accuracy on batch 1250/2438  on Training is 68.94234612310152\n",
            "Epoch #5. Accuracy on batch 1251/2438  on Training is 68.92721645367412\n",
            "Epoch #5. Accuracy on batch 1252/2438  on Training is 68.92208699122106\n",
            "Epoch #5. Accuracy on batch 1253/2438  on Training is 68.91447368421052\n",
            "Epoch #5. Accuracy on batch 1254/2438  on Training is 68.91932270916335\n",
            "Epoch #5. Accuracy on batch 1255/2438  on Training is 68.91669984076434\n",
            "Epoch #5. Accuracy on batch 1256/2438  on Training is 68.91408114558473\n",
            "Epoch #5. Accuracy on batch 1257/2438  on Training is 68.91643481717011\n",
            "Epoch #5. Accuracy on batch 1258/2438  on Training is 68.91133836378077\n",
            "Epoch #5. Accuracy on batch 1259/2438  on Training is 68.90625\n",
            "Batch Id 1260/2438 is having training loss of 1.138590931892395\n",
            "0.8485382795333862\n",
            "Epoch #5. Accuracy on batch 1260/2438  on Training is 68.9110824742268\n",
            "Epoch #5. Accuracy on batch 1261/2438  on Training is 68.91838351822504\n",
            "Epoch #5. Accuracy on batch 1262/2438  on Training is 68.91577593032463\n",
            "Epoch #5. Accuracy on batch 1263/2438  on Training is 68.9181170886076\n",
            "Epoch #5. Accuracy on batch 1264/2438  on Training is 68.92045454545455\n",
            "Epoch #5. Accuracy on batch 1265/2438  on Training is 68.92031990521328\n",
            "Epoch #5. Accuracy on batch 1266/2438  on Training is 68.92265193370166\n",
            "Epoch #5. Accuracy on batch 1267/2438  on Training is 68.92744479495268\n",
            "Epoch #5. Accuracy on batch 1268/2438  on Training is 68.92976753349093\n",
            "Epoch #5. Accuracy on batch 1269/2438  on Training is 68.93208661417323\n",
            "Epoch #5. Accuracy on batch 1270/2438  on Training is 68.93440204563336\n",
            "Epoch #5. Accuracy on batch 1271/2438  on Training is 68.92934355345912\n",
            "Epoch #5. Accuracy on batch 1272/2438  on Training is 68.93411233307148\n",
            "Epoch #5. Accuracy on batch 1273/2438  on Training is 68.93151491365776\n",
            "Epoch #5. Accuracy on batch 1274/2438  on Training is 68.93872549019608\n",
            "Epoch #5. Accuracy on batch 1275/2438  on Training is 68.92878134796238\n",
            "Epoch #5. Accuracy on batch 1276/2438  on Training is 68.91395849647611\n",
            "Epoch #5. Accuracy on batch 1277/2438  on Training is 68.91383020344288\n",
            "Epoch #5. Accuracy on batch 1278/2438  on Training is 68.91614542611416\n",
            "Epoch #5. Accuracy on batch 1279/2438  on Training is 68.90625\n",
            "Batch Id 1280/2438 is having training loss of 1.1382347345352173\n",
            "1.2441829442977905\n",
            "Epoch #5. Accuracy on batch 1280/2438  on Training is 68.90612802498049\n",
            "Epoch #5. Accuracy on batch 1281/2438  on Training is 68.91331903276131\n",
            "Epoch #5. Accuracy on batch 1282/2438  on Training is 68.90344894777864\n",
            "Epoch #5. Accuracy on batch 1283/2438  on Training is 68.90332943925233\n",
            "Epoch #5. Accuracy on batch 1284/2438  on Training is 68.90077821011673\n",
            "Epoch #5. Accuracy on batch 1285/2438  on Training is 68.89580093312597\n",
            "Epoch #5. Accuracy on batch 1286/2438  on Training is 68.8908313908314\n",
            "Epoch #5. Accuracy on batch 1287/2438  on Training is 68.88586956521739\n",
            "Epoch #5. Accuracy on batch 1288/2438  on Training is 68.89303723816913\n",
            "Epoch #5. Accuracy on batch 1289/2438  on Training is 68.90261627906976\n",
            "Epoch #5. Accuracy on batch 1290/2438  on Training is 68.90491866769946\n",
            "Epoch #5. Accuracy on batch 1291/2438  on Training is 68.90479876160991\n",
            "Epoch #5. Accuracy on batch 1292/2438  on Training is 68.89984532095902\n",
            "Epoch #5. Accuracy on batch 1293/2438  on Training is 68.89006955177743\n",
            "Epoch #5. Accuracy on batch 1294/2438  on Training is 68.88030888030887\n",
            "Epoch #5. Accuracy on batch 1295/2438  on Training is 68.88020833333333\n",
            "Epoch #5. Accuracy on batch 1296/2438  on Training is 68.89215497301466\n",
            "Epoch #5. Accuracy on batch 1297/2438  on Training is 68.90408320493066\n",
            "Epoch #5. Accuracy on batch 1298/2438  on Training is 68.90877598152424\n",
            "Epoch #5. Accuracy on batch 1299/2438  on Training is 68.91826923076923\n",
            "Batch Id 1300/2438 is having training loss of 1.1379092931747437\n",
            "1.285578966140747\n",
            "Epoch #5. Accuracy on batch 1300/2438  on Training is 68.92054189085319\n",
            "Epoch #5. Accuracy on batch 1301/2438  on Training is 68.920410906298\n",
            "Epoch #5. Accuracy on batch 1302/2438  on Training is 68.91788181120491\n",
            "Epoch #5. Accuracy on batch 1303/2438  on Training is 68.91775306748467\n",
            "Epoch #5. Accuracy on batch 1304/2438  on Training is 68.9272030651341\n",
            "Epoch #5. Accuracy on batch 1305/2438  on Training is 68.91988897396631\n",
            "Epoch #5. Accuracy on batch 1306/2438  on Training is 68.91736801836267\n",
            "Epoch #5. Accuracy on batch 1307/2438  on Training is 68.9124617737003\n",
            "Epoch #5. Accuracy on batch 1308/2438  on Training is 68.90995034377387\n",
            "Epoch #5. Accuracy on batch 1309/2438  on Training is 68.9098282442748\n",
            "Epoch #5. Accuracy on batch 1310/2438  on Training is 68.90732265446225\n",
            "Epoch #5. Accuracy on batch 1311/2438  on Training is 68.89529344512195\n",
            "Epoch #5. Accuracy on batch 1312/2438  on Training is 68.8975628332064\n",
            "Epoch #5. Accuracy on batch 1313/2438  on Training is 68.8855593607306\n",
            "Epoch #5. Accuracy on batch 1314/2438  on Training is 68.87832699619771\n",
            "Epoch #5. Accuracy on batch 1315/2438  on Training is 68.86873100303951\n",
            "Epoch #5. Accuracy on batch 1316/2438  on Training is 68.87101366742597\n",
            "Epoch #5. Accuracy on batch 1317/2438  on Training is 68.88040591805766\n",
            "Epoch #5. Accuracy on batch 1318/2438  on Training is 68.8874147081122\n",
            "Epoch #5. Accuracy on batch 1319/2438  on Training is 68.89441287878788\n",
            "Batch Id 1320/2438 is having training loss of 1.1385997533798218\n",
            "1.0034363269805908\n",
            "Epoch #5. Accuracy on batch 1320/2438  on Training is 68.89193792581378\n",
            "Epoch #5. Accuracy on batch 1321/2438  on Training is 68.88473903177004\n",
            "Epoch #5. Accuracy on batch 1322/2438  on Training is 68.88936130007559\n",
            "Epoch #5. Accuracy on batch 1323/2438  on Training is 68.88925604229607\n",
            "Epoch #5. Accuracy on batch 1324/2438  on Training is 68.89386792452831\n",
            "Epoch #5. Accuracy on batch 1325/2438  on Training is 68.8961161387632\n",
            "Epoch #5. Accuracy on batch 1326/2438  on Training is 68.90307083647325\n",
            "Epoch #5. Accuracy on batch 1327/2438  on Training is 68.90766189759036\n",
            "Epoch #5. Accuracy on batch 1328/2438  on Training is 68.9028404815651\n",
            "Epoch #5. Accuracy on batch 1329/2438  on Training is 68.90037593984962\n",
            "Epoch #5. Accuracy on batch 1330/2438  on Training is 68.89556724267469\n",
            "Epoch #5. Accuracy on batch 1331/2438  on Training is 68.89076576576576\n",
            "Epoch #5. Accuracy on batch 1332/2438  on Training is 68.89300450112528\n",
            "Epoch #5. Accuracy on batch 1333/2438  on Training is 68.89055472263868\n",
            "Epoch #5. Accuracy on batch 1334/2438  on Training is 68.8998127340824\n",
            "Epoch #5. Accuracy on batch 1335/2438  on Training is 68.90905688622755\n",
            "Epoch #5. Accuracy on batch 1336/2438  on Training is 68.91594988780852\n",
            "Epoch #5. Accuracy on batch 1337/2438  on Training is 68.91816143497758\n",
            "Epoch #5. Accuracy on batch 1338/2438  on Training is 68.9180358476475\n",
            "Epoch #5. Accuracy on batch 1339/2438  on Training is 68.92024253731343\n",
            "Batch Id 1340/2438 is having training loss of 1.138384461402893\n",
            "1.1161986589431763\n",
            "Epoch #5. Accuracy on batch 1340/2438  on Training is 68.92244593586875\n",
            "Epoch #5. Accuracy on batch 1341/2438  on Training is 68.92697466467958\n",
            "Epoch #5. Accuracy on batch 1342/2438  on Training is 68.92218912881609\n",
            "Epoch #5. Accuracy on batch 1343/2438  on Training is 68.91508556547619\n",
            "Epoch #5. Accuracy on batch 1344/2438  on Training is 68.91728624535315\n",
            "Epoch #5. Accuracy on batch 1345/2438  on Training is 68.91716196136701\n",
            "Epoch #5. Accuracy on batch 1346/2438  on Training is 68.91935783221975\n",
            "Epoch #5. Accuracy on batch 1347/2438  on Training is 68.92155044510386\n",
            "Epoch #5. Accuracy on batch 1348/2438  on Training is 68.91679021497406\n",
            "Epoch #5. Accuracy on batch 1349/2438  on Training is 68.9050925925926\n",
            "Epoch #5. Accuracy on batch 1350/2438  on Training is 68.9119170984456\n",
            "Epoch #5. Accuracy on batch 1351/2438  on Training is 68.9164201183432\n",
            "Epoch #5. Accuracy on batch 1352/2438  on Training is 68.91629711751663\n",
            "Epoch #5. Accuracy on batch 1353/2438  on Training is 68.91617429837518\n",
            "Epoch #5. Accuracy on batch 1354/2438  on Training is 68.91143911439114\n",
            "Epoch #5. Accuracy on batch 1355/2438  on Training is 68.9182337758112\n",
            "Epoch #5. Accuracy on batch 1356/2438  on Training is 68.92041267501843\n",
            "Epoch #5. Accuracy on batch 1357/2438  on Training is 68.92488954344624\n",
            "Epoch #5. Accuracy on batch 1358/2438  on Training is 68.9247608535688\n",
            "Epoch #5. Accuracy on batch 1359/2438  on Training is 68.93382352941177\n",
            "Batch Id 1360/2438 is having training loss of 1.137402892112732\n",
            "1.1481260061264038\n",
            "Epoch #5. Accuracy on batch 1360/2438  on Training is 68.93139235855988\n",
            "Epoch #5. Accuracy on batch 1361/2438  on Training is 68.94502569750367\n",
            "Epoch #5. Accuracy on batch 1362/2438  on Training is 68.94717534849596\n",
            "Epoch #5. Accuracy on batch 1363/2438  on Training is 68.94703079178886\n",
            "Epoch #5. Accuracy on batch 1364/2438  on Training is 68.9423076923077\n",
            "Epoch #5. Accuracy on batch 1365/2438  on Training is 68.94674231332357\n",
            "Epoch #5. Accuracy on batch 1366/2438  on Training is 68.95117044623262\n",
            "Epoch #5. Accuracy on batch 1367/2438  on Training is 68.95102339181287\n",
            "Epoch #5. Accuracy on batch 1368/2438  on Training is 68.9440284879474\n",
            "Epoch #5. Accuracy on batch 1369/2438  on Training is 68.94616788321167\n",
            "Epoch #5. Accuracy on batch 1370/2438  on Training is 68.95742159008023\n",
            "Epoch #5. Accuracy on batch 1371/2438  on Training is 68.95499271137027\n",
            "Epoch #5. Accuracy on batch 1372/2438  on Training is 68.96622359796066\n",
            "Epoch #5. Accuracy on batch 1373/2438  on Training is 68.97288937409024\n",
            "Epoch #5. Accuracy on batch 1374/2438  on Training is 68.98181818181818\n",
            "Epoch #5. Accuracy on batch 1375/2438  on Training is 68.97710755813954\n",
            "Epoch #5. Accuracy on batch 1376/2438  on Training is 68.98375090777051\n",
            "Epoch #5. Accuracy on batch 1377/2438  on Training is 68.97224238026125\n",
            "Epoch #5. Accuracy on batch 1378/2438  on Training is 68.97661348803481\n",
            "Epoch #5. Accuracy on batch 1379/2438  on Training is 68.97192028985508\n",
            "Batch Id 1380/2438 is having training loss of 1.1359602212905884\n",
            "1.008827567100525\n",
            "Epoch #5. Accuracy on batch 1380/2438  on Training is 68.97854815351195\n",
            "Epoch #5. Accuracy on batch 1381/2438  on Training is 68.97386034732273\n",
            "Epoch #5. Accuracy on batch 1382/2438  on Training is 68.97821764280549\n",
            "Epoch #5. Accuracy on batch 1383/2438  on Training is 68.97579479768787\n",
            "Epoch #5. Accuracy on batch 1384/2438  on Training is 68.98014440433214\n",
            "Epoch #5. Accuracy on batch 1385/2438  on Training is 68.97772366522366\n",
            "Epoch #5. Accuracy on batch 1386/2438  on Training is 68.97755948089402\n",
            "Epoch #5. Accuracy on batch 1387/2438  on Training is 68.98640129682997\n",
            "Epoch #5. Accuracy on batch 1388/2438  on Training is 68.99298056155507\n",
            "Epoch #5. Accuracy on batch 1389/2438  on Training is 69.00179856115108\n",
            "Epoch #5. Accuracy on batch 1390/2438  on Training is 68.99712437095614\n",
            "Epoch #5. Accuracy on batch 1391/2438  on Training is 69.0014367816092\n",
            "Epoch #5. Accuracy on batch 1392/2438  on Training is 69.00574300071787\n",
            "Epoch #5. Accuracy on batch 1393/2438  on Training is 69.00555954088952\n",
            "Epoch #5. Accuracy on batch 1394/2438  on Training is 69.00537634408602\n",
            "Epoch #5. Accuracy on batch 1395/2438  on Training is 68.99176217765043\n",
            "Epoch #5. Accuracy on batch 1396/2438  on Training is 68.99606299212599\n",
            "Epoch #5. Accuracy on batch 1397/2438  on Training is 69.00706366237482\n",
            "Epoch #5. Accuracy on batch 1398/2438  on Training is 69.00687991422444\n",
            "Epoch #5. Accuracy on batch 1399/2438  on Training is 69.00669642857143\n",
            "Batch Id 1400/2438 is having training loss of 1.1348586082458496\n",
            "1.1022745370864868\n",
            "Epoch #5. Accuracy on batch 1400/2438  on Training is 69.00651320485368\n",
            "Epoch #5. Accuracy on batch 1401/2438  on Training is 69.00410128388017\n",
            "Epoch #5. Accuracy on batch 1402/2438  on Training is 68.99278332145403\n",
            "Epoch #5. Accuracy on batch 1403/2438  on Training is 68.99928774928775\n",
            "Epoch #5. Accuracy on batch 1404/2438  on Training is 68.9991103202847\n",
            "Epoch #5. Accuracy on batch 1405/2438  on Training is 69.00337837837837\n",
            "Epoch #5. Accuracy on batch 1406/2438  on Training is 68.99431414356788\n",
            "Epoch #5. Accuracy on batch 1407/2438  on Training is 68.98748224431819\n",
            "Epoch #5. Accuracy on batch 1408/2438  on Training is 68.99396735273244\n",
            "Epoch #5. Accuracy on batch 1409/2438  on Training is 68.99601063829788\n",
            "Epoch #5. Accuracy on batch 1410/2438  on Training is 68.9869773210489\n",
            "Epoch #5. Accuracy on batch 1411/2438  on Training is 68.98902266288952\n",
            "Epoch #5. Accuracy on batch 1412/2438  on Training is 68.98000707714084\n",
            "Epoch #5. Accuracy on batch 1413/2438  on Training is 68.97984441301273\n",
            "Epoch #5. Accuracy on batch 1414/2438  on Training is 68.98189045936395\n",
            "Epoch #5. Accuracy on batch 1415/2438  on Training is 68.98614053672317\n",
            "Epoch #5. Accuracy on batch 1416/2438  on Training is 68.9925899788285\n",
            "Epoch #5. Accuracy on batch 1417/2438  on Training is 68.99241889985896\n",
            "Epoch #5. Accuracy on batch 1418/2438  on Training is 68.99445031712473\n",
            "Epoch #5. Accuracy on batch 1419/2438  on Training is 68.98987676056338\n",
            "Batch Id 1420/2438 is having training loss of 1.135890007019043\n",
            "1.4356073141098022\n",
            "Epoch #5. Accuracy on batch 1420/2438  on Training is 68.98311048557353\n",
            "Epoch #5. Accuracy on batch 1421/2438  on Training is 68.98294655414908\n",
            "Epoch #5. Accuracy on batch 1422/2438  on Training is 68.98058678847505\n",
            "Epoch #5. Accuracy on batch 1423/2438  on Training is 68.98042485955057\n",
            "Epoch #5. Accuracy on batch 1424/2438  on Training is 68.98026315789474\n",
            "Epoch #5. Accuracy on batch 1425/2438  on Training is 68.98229312762973\n",
            "Epoch #5. Accuracy on batch 1426/2438  on Training is 68.97556061667835\n",
            "Epoch #5. Accuracy on batch 1427/2438  on Training is 68.97321428571429\n",
            "Epoch #5. Accuracy on batch 1428/2438  on Training is 68.97961861441567\n",
            "Epoch #5. Accuracy on batch 1429/2438  on Training is 68.97071678321679\n",
            "Epoch #5. Accuracy on batch 1430/2438  on Training is 68.96182739343116\n",
            "Epoch #5. Accuracy on batch 1431/2438  on Training is 68.96167946927375\n",
            "Epoch #5. Accuracy on batch 1432/2438  on Training is 68.96589323098395\n",
            "Epoch #5. Accuracy on batch 1433/2438  on Training is 68.97010111576012\n",
            "Epoch #5. Accuracy on batch 1434/2438  on Training is 68.96341463414635\n",
            "Epoch #5. Accuracy on batch 1435/2438  on Training is 68.96108983286908\n",
            "Epoch #5. Accuracy on batch 1436/2438  on Training is 68.96094293667363\n",
            "Epoch #5. Accuracy on batch 1437/2438  on Training is 68.96079624478442\n",
            "Epoch #5. Accuracy on batch 1438/2438  on Training is 68.96933634468381\n",
            "Epoch #5. Accuracy on batch 1439/2438  on Training is 68.96918402777777\n",
            "Batch Id 1440/2438 is having training loss of 1.1353482007980347\n",
            "1.2030584812164307\n",
            "Epoch #5. Accuracy on batch 1440/2438  on Training is 68.9690319222762\n",
            "Epoch #5. Accuracy on batch 1441/2438  on Training is 68.97104715672677\n",
            "Epoch #5. Accuracy on batch 1442/2438  on Training is 68.96656271656272\n",
            "Epoch #5. Accuracy on batch 1443/2438  on Training is 68.96208448753463\n",
            "Epoch #5. Accuracy on batch 1444/2438  on Training is 68.96193771626298\n",
            "Epoch #5. Accuracy on batch 1445/2438  on Training is 68.96179114799446\n",
            "Epoch #5. Accuracy on batch 1446/2438  on Training is 68.95948514167243\n",
            "Epoch #5. Accuracy on batch 1447/2438  on Training is 68.95286602209944\n",
            "Epoch #5. Accuracy on batch 1448/2438  on Training is 68.94625603864735\n",
            "Epoch #5. Accuracy on batch 1449/2438  on Training is 68.9396551724138\n",
            "Epoch #5. Accuracy on batch 1450/2438  on Training is 68.93521709166092\n",
            "Epoch #5. Accuracy on batch 1451/2438  on Training is 68.94154614325069\n",
            "Epoch #5. Accuracy on batch 1452/2438  on Training is 68.95001720578114\n",
            "Epoch #5. Accuracy on batch 1453/2438  on Training is 68.93483493810179\n",
            "Epoch #5. Accuracy on batch 1454/2438  on Training is 68.9368556701031\n",
            "Epoch #5. Accuracy on batch 1455/2438  on Training is 68.93672733516483\n",
            "Epoch #5. Accuracy on batch 1456/2438  on Training is 68.93445435827041\n",
            "Epoch #5. Accuracy on batch 1457/2438  on Training is 68.9429012345679\n",
            "Epoch #5. Accuracy on batch 1458/2438  on Training is 68.94919465387251\n",
            "Epoch #5. Accuracy on batch 1459/2438  on Training is 68.94691780821918\n",
            "Batch Id 1460/2438 is having training loss of 1.1356985569000244\n",
            "1.0748844146728516\n",
            "Epoch #5. Accuracy on batch 1460/2438  on Training is 68.94892197125257\n",
            "Epoch #5. Accuracy on batch 1461/2438  on Training is 68.94878590971273\n",
            "Epoch #5. Accuracy on batch 1462/2438  on Training is 68.93796992481202\n",
            "Epoch #5. Accuracy on batch 1463/2438  on Training is 68.94424521857924\n",
            "Epoch #5. Accuracy on batch 1464/2438  on Training is 68.95691126279864\n",
            "Epoch #5. Accuracy on batch 1465/2438  on Training is 68.95463847203274\n",
            "Epoch #5. Accuracy on batch 1466/2438  on Training is 68.95236877982276\n",
            "Epoch #5. Accuracy on batch 1467/2438  on Training is 68.95861716621253\n",
            "Epoch #5. Accuracy on batch 1468/2438  on Training is 68.9606024506467\n",
            "Epoch #5. Accuracy on batch 1469/2438  on Training is 68.96896258503402\n",
            "Epoch #5. Accuracy on batch 1470/2438  on Training is 68.96456492182189\n",
            "Epoch #5. Accuracy on batch 1471/2438  on Training is 68.97078804347827\n",
            "Epoch #5. Accuracy on batch 1472/2438  on Training is 68.97488119484046\n",
            "Epoch #5. Accuracy on batch 1473/2438  on Training is 68.97896879240163\n",
            "Epoch #5. Accuracy on batch 1474/2438  on Training is 68.97669491525424\n",
            "Epoch #5. Accuracy on batch 1475/2438  on Training is 68.97442411924119\n",
            "Epoch #5. Accuracy on batch 1476/2438  on Training is 68.95946174678402\n",
            "Epoch #5. Accuracy on batch 1477/2438  on Training is 68.94663396481732\n",
            "Epoch #5. Accuracy on batch 1478/2438  on Training is 68.95072684246112\n",
            "Epoch #5. Accuracy on batch 1479/2438  on Training is 68.94636824324324\n",
            "Batch Id 1480/2438 is having training loss of 1.1357303857803345\n",
            "1.4976928234100342\n",
            "Epoch #5. Accuracy on batch 1480/2438  on Training is 68.93990546927752\n",
            "Epoch #5. Accuracy on batch 1481/2438  on Training is 68.92501686909581\n",
            "Epoch #5. Accuracy on batch 1482/2438  on Training is 68.93754214430209\n",
            "Epoch #5. Accuracy on batch 1483/2438  on Training is 68.94162735849056\n",
            "Epoch #5. Accuracy on batch 1484/2438  on Training is 68.93518518518519\n",
            "Epoch #5. Accuracy on batch 1485/2438  on Training is 68.92875168236877\n",
            "Epoch #5. Accuracy on batch 1486/2438  on Training is 68.92863147276395\n",
            "Epoch #5. Accuracy on batch 1487/2438  on Training is 68.92431115591398\n",
            "Epoch #5. Accuracy on batch 1488/2438  on Training is 68.92209536601746\n",
            "Epoch #5. Accuracy on batch 1489/2438  on Training is 68.92827181208054\n",
            "Epoch #5. Accuracy on batch 1490/2438  on Training is 68.92186452045607\n",
            "Epoch #5. Accuracy on batch 1491/2438  on Training is 68.92174932975871\n",
            "Epoch #5. Accuracy on batch 1492/2438  on Training is 68.92163429336905\n",
            "Epoch #5. Accuracy on batch 1493/2438  on Training is 68.91942771084338\n",
            "Epoch #5. Accuracy on batch 1494/2438  on Training is 68.92349498327759\n",
            "Epoch #5. Accuracy on batch 1495/2438  on Training is 68.93173462566845\n",
            "Epoch #5. Accuracy on batch 1496/2438  on Training is 68.92117568470275\n",
            "Epoch #5. Accuracy on batch 1497/2438  on Training is 68.9210614152203\n",
            "Epoch #5. Accuracy on batch 1498/2438  on Training is 68.92928619079386\n",
            "Epoch #5. Accuracy on batch 1499/2438  on Training is 68.92708333333333\n",
            "Batch Id 1500/2438 is having training loss of 1.1372897624969482\n",
            "1.3470215797424316\n",
            "Epoch #5. Accuracy on batch 1500/2438  on Training is 68.92280146568955\n",
            "Epoch #5. Accuracy on batch 1501/2438  on Training is 68.9226864181092\n",
            "Epoch #5. Accuracy on batch 1502/2438  on Training is 68.91633399866933\n",
            "Epoch #5. Accuracy on batch 1503/2438  on Training is 68.91830119680851\n",
            "Epoch #5. Accuracy on batch 1504/2438  on Training is 68.9264950166113\n",
            "Epoch #5. Accuracy on batch 1505/2438  on Training is 68.91807768924303\n",
            "Epoch #5. Accuracy on batch 1506/2438  on Training is 68.92211347047113\n",
            "Epoch #5. Accuracy on batch 1507/2438  on Training is 68.92821618037135\n",
            "Epoch #5. Accuracy on batch 1508/2438  on Training is 68.93431080185553\n",
            "Epoch #5. Accuracy on batch 1509/2438  on Training is 68.9362582781457\n",
            "Epoch #5. Accuracy on batch 1510/2438  on Training is 68.93406684315023\n",
            "Epoch #5. Accuracy on batch 1511/2438  on Training is 68.9339451058201\n",
            "Epoch #5. Accuracy on batch 1512/2438  on Training is 68.94208526107072\n",
            "Epoch #5. Accuracy on batch 1513/2438  on Training is 68.9522787318362\n",
            "Epoch #5. Accuracy on batch 1514/2438  on Training is 68.9480198019802\n",
            "Epoch #5. Accuracy on batch 1515/2438  on Training is 68.94582783641161\n",
            "Epoch #5. Accuracy on batch 1516/2438  on Training is 68.93745880026368\n",
            "Epoch #5. Accuracy on batch 1517/2438  on Training is 68.945569828722\n",
            "Epoch #5. Accuracy on batch 1518/2438  on Training is 68.94749835418038\n",
            "Epoch #5. Accuracy on batch 1519/2438  on Training is 68.94325657894737\n",
            "Batch Id 1520/2438 is having training loss of 1.136470913887024\n",
            "0.8062587976455688\n",
            "Epoch #5. Accuracy on batch 1520/2438  on Training is 68.94107495069034\n",
            "Epoch #5. Accuracy on batch 1521/2438  on Training is 68.9388961892247\n",
            "Epoch #5. Accuracy on batch 1522/2438  on Training is 68.93672028890347\n",
            "Epoch #5. Accuracy on batch 1523/2438  on Training is 68.9324967191601\n",
            "Epoch #5. Accuracy on batch 1524/2438  on Training is 68.93442622950819\n",
            "Epoch #5. Accuracy on batch 1525/2438  on Training is 68.93430537352556\n",
            "Epoch #5. Accuracy on batch 1526/2438  on Training is 68.9198592010478\n",
            "Epoch #5. Accuracy on batch 1527/2438  on Training is 68.91770287958116\n",
            "Epoch #5. Accuracy on batch 1528/2438  on Training is 68.91759319816873\n",
            "Epoch #5. Accuracy on batch 1529/2438  on Training is 68.9154411764706\n",
            "Epoch #5. Accuracy on batch 1530/2438  on Training is 68.91737426518615\n",
            "Epoch #5. Accuracy on batch 1531/2438  on Training is 68.90910574412533\n",
            "Epoch #5. Accuracy on batch 1532/2438  on Training is 68.91511741682974\n",
            "Epoch #5. Accuracy on batch 1533/2438  on Training is 68.91908409387223\n",
            "Epoch #5. Accuracy on batch 1534/2438  on Training is 68.92508143322476\n",
            "Epoch #5. Accuracy on batch 1535/2438  on Training is 68.927001953125\n",
            "Epoch #5. Accuracy on batch 1536/2438  on Training is 68.92688679245283\n",
            "Epoch #5. Accuracy on batch 1537/2438  on Training is 68.93286736020806\n",
            "Epoch #5. Accuracy on batch 1538/2438  on Training is 68.92868745938921\n",
            "Epoch #5. Accuracy on batch 1539/2438  on Training is 68.92248376623377\n",
            "Batch Id 1540/2438 is having training loss of 1.1360969543457031\n",
            "1.3238734006881714\n",
            "Epoch #5. Accuracy on batch 1540/2438  on Training is 68.91426022063595\n",
            "Epoch #5. Accuracy on batch 1541/2438  on Training is 68.91820687418937\n",
            "Epoch #5. Accuracy on batch 1542/2438  on Training is 68.91607258587167\n",
            "Epoch #5. Accuracy on batch 1543/2438  on Training is 68.91798898963731\n",
            "Epoch #5. Accuracy on batch 1544/2438  on Training is 68.91990291262135\n",
            "Epoch #5. Accuracy on batch 1545/2438  on Training is 68.91575032341527\n",
            "Epoch #5. Accuracy on batch 1546/2438  on Training is 68.9217032967033\n",
            "Epoch #5. Accuracy on batch 1547/2438  on Training is 68.92159237726098\n",
            "Epoch #5. Accuracy on batch 1548/2438  on Training is 68.91946417043253\n",
            "Epoch #5. Accuracy on batch 1549/2438  on Training is 68.91935483870968\n",
            "Epoch #5. Accuracy on batch 1550/2438  on Training is 68.91723081882657\n",
            "Epoch #5. Accuracy on batch 1551/2438  on Training is 68.91309600515464\n",
            "Epoch #5. Accuracy on batch 1552/2438  on Training is 68.91902768834514\n",
            "Epoch #5. Accuracy on batch 1553/2438  on Training is 68.9229407979408\n",
            "Epoch #5. Accuracy on batch 1554/2438  on Training is 68.92081993569131\n",
            "Epoch #5. Accuracy on batch 1555/2438  on Training is 68.92271850899743\n",
            "Epoch #5. Accuracy on batch 1556/2438  on Training is 68.92060051380861\n",
            "Epoch #5. Accuracy on batch 1557/2438  on Training is 68.91848523748395\n",
            "Epoch #5. Accuracy on batch 1558/2438  on Training is 68.92639512508018\n",
            "Epoch #5. Accuracy on batch 1559/2438  on Training is 68.93028846153847\n",
            "Batch Id 1560/2438 is having training loss of 1.1352888345718384\n",
            "1.1351287364959717\n",
            "Epoch #5. Accuracy on batch 1560/2438  on Training is 68.93217488789237\n",
            "Epoch #5. Accuracy on batch 1561/2438  on Training is 68.9240556978233\n",
            "Epoch #5. Accuracy on batch 1562/2438  on Training is 68.92194497760717\n",
            "Epoch #5. Accuracy on batch 1563/2438  on Training is 68.92782928388746\n",
            "Epoch #5. Accuracy on batch 1564/2438  on Training is 68.93370607028754\n",
            "Epoch #5. Accuracy on batch 1565/2438  on Training is 68.92361111111111\n",
            "Epoch #5. Accuracy on batch 1566/2438  on Training is 68.92748883216336\n",
            "Epoch #5. Accuracy on batch 1567/2438  on Training is 68.9273756377551\n",
            "Epoch #5. Accuracy on batch 1568/2438  on Training is 68.921287444232\n",
            "Epoch #5. Accuracy on batch 1569/2438  on Training is 68.92316878980891\n",
            "Epoch #5. Accuracy on batch 1570/2438  on Training is 68.92703691915978\n",
            "Epoch #5. Accuracy on batch 1571/2438  on Training is 68.92493638676845\n",
            "Epoch #5. Accuracy on batch 1572/2438  on Training is 68.92482517482517\n",
            "Epoch #5. Accuracy on batch 1573/2438  on Training is 68.93265565438374\n",
            "Epoch #5. Accuracy on batch 1574/2438  on Training is 68.9265873015873\n",
            "Epoch #5. Accuracy on batch 1575/2438  on Training is 68.9284581218274\n",
            "Epoch #5. Accuracy on batch 1576/2438  on Training is 68.92636334812936\n",
            "Epoch #5. Accuracy on batch 1577/2438  on Training is 68.92427122940431\n",
            "Epoch #5. Accuracy on batch 1578/2438  on Training is 68.92416086130463\n",
            "Epoch #5. Accuracy on batch 1579/2438  on Training is 68.92998417721519\n",
            "Batch Id 1580/2438 is having training loss of 1.1353893280029297\n",
            "1.0639479160308838\n",
            "Epoch #5. Accuracy on batch 1580/2438  on Training is 68.93382352941177\n",
            "Epoch #5. Accuracy on batch 1581/2438  on Training is 68.93173198482933\n",
            "Epoch #5. Accuracy on batch 1582/2438  on Training is 68.93161718256475\n",
            "Epoch #5. Accuracy on batch 1583/2438  on Training is 68.92952967171718\n",
            "Epoch #5. Accuracy on batch 1584/2438  on Training is 68.9294164037855\n",
            "Epoch #5. Accuracy on batch 1585/2438  on Training is 68.92142181588903\n",
            "Epoch #5. Accuracy on batch 1586/2438  on Training is 68.91934467548835\n",
            "Epoch #5. Accuracy on batch 1587/2438  on Training is 68.92317380352645\n",
            "Epoch #5. Accuracy on batch 1588/2438  on Training is 68.9210981749528\n",
            "Epoch #5. Accuracy on batch 1589/2438  on Training is 68.91509433962264\n",
            "Epoch #5. Accuracy on batch 1590/2438  on Training is 68.9051697045883\n",
            "Epoch #5. Accuracy on batch 1591/2438  on Training is 68.90310929648241\n",
            "Epoch #5. Accuracy on batch 1592/2438  on Training is 68.90889830508475\n",
            "Epoch #5. Accuracy on batch 1593/2438  on Training is 68.90291718946048\n",
            "Epoch #5. Accuracy on batch 1594/2438  on Training is 68.8891065830721\n",
            "Epoch #5. Accuracy on batch 1595/2438  on Training is 68.89880952380952\n",
            "Epoch #5. Accuracy on batch 1596/2438  on Training is 68.89871634314339\n",
            "Epoch #5. Accuracy on batch 1597/2438  on Training is 68.90253441802253\n",
            "Epoch #5. Accuracy on batch 1598/2438  on Training is 68.90243902439025\n",
            "Epoch #5. Accuracy on batch 1599/2438  on Training is 68.900390625\n",
            "Batch Id 1600/2438 is having training loss of 1.1358237266540527\n",
            "1.141617774963379\n",
            "Epoch #5. Accuracy on batch 1600/2438  on Training is 68.90420049968769\n",
            "Epoch #5. Accuracy on batch 1601/2438  on Training is 68.89435081148564\n",
            "Epoch #5. Accuracy on batch 1602/2438  on Training is 68.89815970056145\n",
            "Epoch #5. Accuracy on batch 1603/2438  on Training is 68.89611907730674\n",
            "Epoch #5. Accuracy on batch 1604/2438  on Training is 68.88629283489097\n",
            "Epoch #5. Accuracy on batch 1605/2438  on Training is 68.88426214196762\n",
            "Epoch #5. Accuracy on batch 1606/2438  on Training is 68.89001244555071\n",
            "Epoch #5. Accuracy on batch 1607/2438  on Training is 68.89381218905473\n",
            "Epoch #5. Accuracy on batch 1608/2438  on Training is 68.88789620882535\n",
            "Epoch #5. Accuracy on batch 1609/2438  on Training is 68.88975155279503\n",
            "Epoch #5. Accuracy on batch 1610/2438  on Training is 68.89160459342024\n",
            "Epoch #5. Accuracy on batch 1611/2438  on Training is 68.90120967741936\n",
            "Epoch #5. Accuracy on batch 1612/2438  on Training is 68.90886546807191\n",
            "Epoch #5. Accuracy on batch 1613/2438  on Training is 68.90683085501858\n",
            "Epoch #5. Accuracy on batch 1614/2438  on Training is 68.90866873065015\n",
            "Epoch #5. Accuracy on batch 1615/2438  on Training is 68.9163056930693\n",
            "Epoch #5. Accuracy on batch 1616/2438  on Training is 68.91427025355597\n",
            "Epoch #5. Accuracy on batch 1617/2438  on Training is 68.91416872682323\n",
            "Epoch #5. Accuracy on batch 1618/2438  on Training is 68.92178814082767\n",
            "Epoch #5. Accuracy on batch 1619/2438  on Training is 68.92554012345678\n",
            "Batch Id 1620/2438 is having training loss of 1.1347072124481201\n",
            "0.9744746088981628\n",
            "Epoch #5. Accuracy on batch 1620/2438  on Training is 68.92928747686614\n",
            "Epoch #5. Accuracy on batch 1621/2438  on Training is 68.93303020961775\n",
            "Epoch #5. Accuracy on batch 1622/2438  on Training is 68.93484288354898\n",
            "Epoch #5. Accuracy on batch 1623/2438  on Training is 68.93665332512315\n",
            "Epoch #5. Accuracy on batch 1624/2438  on Training is 68.93461538461538\n",
            "Epoch #5. Accuracy on batch 1625/2438  on Training is 68.93065805658057\n",
            "Epoch #5. Accuracy on batch 1626/2438  on Training is 68.93054701905348\n",
            "Epoch #5. Accuracy on batch 1627/2438  on Training is 68.92851658476658\n",
            "Epoch #5. Accuracy on batch 1628/2438  on Training is 68.9341620626151\n",
            "Epoch #5. Accuracy on batch 1629/2438  on Training is 68.93021472392638\n",
            "Epoch #5. Accuracy on batch 1630/2438  on Training is 68.93010423053342\n",
            "Epoch #5. Accuracy on batch 1631/2438  on Training is 68.92807904411765\n",
            "Epoch #5. Accuracy on batch 1632/2438  on Training is 68.92414268218003\n",
            "Epoch #5. Accuracy on batch 1633/2438  on Training is 68.92021113831089\n",
            "Epoch #5. Accuracy on batch 1634/2438  on Training is 68.92392966360856\n",
            "Epoch #5. Accuracy on batch 1635/2438  on Training is 68.91809290953545\n",
            "Epoch #5. Accuracy on batch 1636/2438  on Training is 68.9122632864997\n",
            "Epoch #5. Accuracy on batch 1637/2438  on Training is 68.91025641025641\n",
            "Epoch #5. Accuracy on batch 1638/2438  on Training is 68.90062538133007\n",
            "Epoch #5. Accuracy on batch 1639/2438  on Training is 68.90053353658537\n",
            "Batch Id 1640/2438 is having training loss of 1.1355165243148804\n",
            "1.2443087100982666\n",
            "Epoch #5. Accuracy on batch 1640/2438  on Training is 68.89663315051797\n",
            "Epoch #5. Accuracy on batch 1641/2438  on Training is 68.894640682095\n",
            "Epoch #5. Accuracy on batch 1642/2438  on Training is 68.89265063907486\n",
            "Epoch #5. Accuracy on batch 1643/2438  on Training is 68.89446472019465\n",
            "Epoch #5. Accuracy on batch 1644/2438  on Training is 68.89627659574468\n",
            "Epoch #5. Accuracy on batch 1645/2438  on Training is 68.89618772782504\n",
            "Epoch #5. Accuracy on batch 1646/2438  on Training is 68.89420157862781\n",
            "Epoch #5. Accuracy on batch 1647/2438  on Training is 68.89221783980582\n",
            "Epoch #5. Accuracy on batch 1648/2438  on Training is 68.892131594906\n",
            "Epoch #5. Accuracy on batch 1649/2438  on Training is 68.89962121212122\n",
            "Epoch #5. Accuracy on batch 1650/2438  on Training is 68.90331617201696\n",
            "Epoch #5. Accuracy on batch 1651/2438  on Training is 68.89376513317191\n",
            "Epoch #5. Accuracy on batch 1652/2438  on Training is 68.89934966727162\n",
            "Epoch #5. Accuracy on batch 1653/2438  on Training is 68.89548065296252\n",
            "Epoch #5. Accuracy on batch 1654/2438  on Training is 68.89350453172206\n",
            "Epoch #5. Accuracy on batch 1655/2438  on Training is 68.89530495169082\n",
            "Epoch #5. Accuracy on batch 1656/2438  on Training is 68.88390162945082\n",
            "Epoch #5. Accuracy on batch 1657/2438  on Training is 68.88005126658625\n",
            "Epoch #5. Accuracy on batch 1658/2438  on Training is 68.874321880651\n",
            "Epoch #5. Accuracy on batch 1659/2438  on Training is 68.87801204819277\n",
            "Batch Id 1660/2438 is having training loss of 1.1355050802230835\n",
            "0.9754206538200378\n",
            "Epoch #5. Accuracy on batch 1660/2438  on Training is 68.87981637567731\n",
            "Epoch #5. Accuracy on batch 1661/2438  on Training is 68.87973826714801\n",
            "Epoch #5. Accuracy on batch 1662/2438  on Training is 68.87966025255562\n",
            "Epoch #5. Accuracy on batch 1663/2438  on Training is 68.87770432692308\n",
            "Epoch #5. Accuracy on batch 1664/2438  on Training is 68.87762762762763\n",
            "Epoch #5. Accuracy on batch 1665/2438  on Training is 68.87942677070828\n",
            "Epoch #5. Accuracy on batch 1666/2438  on Training is 68.88497300539892\n",
            "Epoch #5. Accuracy on batch 1667/2438  on Training is 68.88863908872902\n",
            "Epoch #5. Accuracy on batch 1668/2438  on Training is 68.8885560215698\n",
            "Epoch #5. Accuracy on batch 1669/2438  on Training is 68.88285928143712\n",
            "Epoch #5. Accuracy on batch 1670/2438  on Training is 68.89026032315978\n",
            "Epoch #5. Accuracy on batch 1671/2438  on Training is 68.88830741626795\n",
            "Epoch #5. Accuracy on batch 1672/2438  on Training is 68.88822474596533\n",
            "Epoch #5. Accuracy on batch 1673/2438  on Training is 68.8694743130227\n",
            "Epoch #5. Accuracy on batch 1674/2438  on Training is 68.87126865671642\n",
            "Epoch #5. Accuracy on batch 1675/2438  on Training is 68.87306085918854\n",
            "Epoch #5. Accuracy on batch 1676/2438  on Training is 68.85994335122243\n",
            "Epoch #5. Accuracy on batch 1677/2438  on Training is 68.86732717520859\n",
            "Epoch #5. Accuracy on batch 1678/2438  on Training is 68.8709797498511\n",
            "Epoch #5. Accuracy on batch 1679/2438  on Training is 68.87276785714286\n",
            "Batch Id 1680/2438 is having training loss of 1.13571298122406\n",
            "0.8474496603012085\n",
            "Epoch #5. Accuracy on batch 1680/2438  on Training is 68.87641284949434\n",
            "Epoch #5. Accuracy on batch 1681/2438  on Training is 68.88005350772889\n",
            "Epoch #5. Accuracy on batch 1682/2438  on Training is 68.87254901960785\n",
            "Epoch #5. Accuracy on batch 1683/2438  on Training is 68.87247624703087\n",
            "Epoch #5. Accuracy on batch 1684/2438  on Training is 68.87054896142433\n",
            "Epoch #5. Accuracy on batch 1685/2438  on Training is 68.87233096085409\n",
            "Epoch #5. Accuracy on batch 1686/2438  on Training is 68.8685536455246\n",
            "Epoch #5. Accuracy on batch 1687/2438  on Training is 68.86848341232228\n",
            "Epoch #5. Accuracy on batch 1688/2438  on Training is 68.8721136767318\n",
            "Epoch #5. Accuracy on batch 1689/2438  on Training is 68.87204142011835\n",
            "Epoch #5. Accuracy on batch 1690/2438  on Training is 68.86457717327025\n",
            "Epoch #5. Accuracy on batch 1691/2438  on Training is 68.86635638297872\n",
            "Epoch #5. Accuracy on batch 1692/2438  on Training is 68.86813349084466\n",
            "Epoch #5. Accuracy on batch 1693/2438  on Training is 68.8680637544274\n",
            "Epoch #5. Accuracy on batch 1694/2438  on Training is 68.86615044247787\n",
            "Epoch #5. Accuracy on batch 1695/2438  on Training is 68.8697670990566\n",
            "Epoch #5. Accuracy on batch 1696/2438  on Training is 68.8770624631703\n",
            "Epoch #5. Accuracy on batch 1697/2438  on Training is 68.87882803297998\n",
            "Epoch #5. Accuracy on batch 1698/2438  on Training is 68.88243084167158\n",
            "Epoch #5. Accuracy on batch 1699/2438  on Training is 68.8841911764706\n",
            "Batch Id 1700/2438 is having training loss of 1.1352555751800537\n",
            "1.5935816764831543\n",
            "Epoch #5. Accuracy on batch 1700/2438  on Training is 68.87676366843033\n",
            "Epoch #5. Accuracy on batch 1701/2438  on Training is 68.87852526439482\n",
            "Epoch #5. Accuracy on batch 1702/2438  on Training is 68.87477980035231\n",
            "Epoch #5. Accuracy on batch 1703/2438  on Training is 68.86737089201878\n",
            "Epoch #5. Accuracy on batch 1704/2438  on Training is 68.86363636363636\n",
            "Epoch #5. Accuracy on batch 1705/2438  on Training is 68.86173798358733\n",
            "Epoch #5. Accuracy on batch 1706/2438  on Training is 68.85618043350908\n",
            "Epoch #5. Accuracy on batch 1707/2438  on Training is 68.85245901639344\n",
            "Epoch #5. Accuracy on batch 1708/2438  on Training is 68.85057050906963\n",
            "Epoch #5. Accuracy on batch 1709/2438  on Training is 68.85416666666667\n",
            "Epoch #5. Accuracy on batch 1710/2438  on Training is 68.84862653419053\n",
            "Epoch #5. Accuracy on batch 1711/2438  on Training is 68.84126752336448\n",
            "Epoch #5. Accuracy on batch 1712/2438  on Training is 68.83574138937537\n",
            "Epoch #5. Accuracy on batch 1713/2438  on Training is 68.84116102683781\n",
            "Epoch #5. Accuracy on batch 1714/2438  on Training is 68.83746355685132\n",
            "Epoch #5. Accuracy on batch 1715/2438  on Training is 68.83741258741259\n",
            "Epoch #5. Accuracy on batch 1716/2438  on Training is 68.84464181712289\n",
            "Epoch #5. Accuracy on batch 1717/2438  on Training is 68.84458672875436\n",
            "Epoch #5. Accuracy on batch 1718/2438  on Training is 68.84634962187319\n",
            "Epoch #5. Accuracy on batch 1719/2438  on Training is 68.84629360465117\n",
            "Batch Id 1720/2438 is having training loss of 1.1360142230987549\n",
            "1.0683470964431763\n",
            "Epoch #5. Accuracy on batch 1720/2438  on Training is 68.84805345729227\n",
            "Epoch #5. Accuracy on batch 1721/2438  on Training is 68.85162601626017\n",
            "Epoch #5. Accuracy on batch 1722/2438  on Training is 68.8515670342426\n",
            "Epoch #5. Accuracy on batch 1723/2438  on Training is 68.86057134570765\n",
            "Epoch #5. Accuracy on batch 1724/2438  on Training is 68.8659420289855\n",
            "Epoch #5. Accuracy on batch 1725/2438  on Training is 68.86587485515643\n",
            "Epoch #5. Accuracy on batch 1726/2438  on Training is 68.86218876664736\n",
            "Epoch #5. Accuracy on batch 1727/2438  on Training is 68.86031539351852\n",
            "Epoch #5. Accuracy on batch 1728/2438  on Training is 68.85844418739156\n",
            "Epoch #5. Accuracy on batch 1729/2438  on Training is 68.86380057803468\n",
            "Epoch #5. Accuracy on batch 1730/2438  on Training is 68.86373483535529\n",
            "Epoch #5. Accuracy on batch 1731/2438  on Training is 68.86366916859123\n",
            "Epoch #5. Accuracy on batch 1732/2438  on Training is 68.85819388343913\n",
            "Epoch #5. Accuracy on batch 1733/2438  on Training is 68.8599336793541\n",
            "Epoch #5. Accuracy on batch 1734/2438  on Training is 68.85626801152738\n",
            "Epoch #5. Accuracy on batch 1735/2438  on Training is 68.85980702764977\n",
            "Epoch #5. Accuracy on batch 1736/2438  on Training is 68.85434657455383\n",
            "Epoch #5. Accuracy on batch 1737/2438  on Training is 68.85608457997698\n",
            "Epoch #5. Accuracy on batch 1738/2438  on Training is 68.85063254744105\n",
            "Epoch #5. Accuracy on batch 1739/2438  on Training is 68.85237068965517\n",
            "Batch Id 1740/2438 is having training loss of 1.1361281871795654\n",
            "1.7093135118484497\n",
            "Epoch #5. Accuracy on batch 1740/2438  on Training is 68.84692705341757\n",
            "Epoch #5. Accuracy on batch 1741/2438  on Training is 68.85225315729048\n",
            "Epoch #5. Accuracy on batch 1742/2438  on Training is 68.85219449225474\n",
            "Epoch #5. Accuracy on batch 1743/2438  on Training is 68.85034403669725\n",
            "Epoch #5. Accuracy on batch 1744/2438  on Training is 68.85028653295129\n",
            "Epoch #5. Accuracy on batch 1745/2438  on Training is 68.85201890034364\n",
            "Epoch #5. Accuracy on batch 1746/2438  on Training is 68.84659416141957\n",
            "Epoch #5. Accuracy on batch 1747/2438  on Training is 68.85190217391305\n",
            "Epoch #5. Accuracy on batch 1748/2438  on Training is 68.85541738136078\n",
            "Epoch #5. Accuracy on batch 1749/2438  on Training is 68.85892857142858\n",
            "Epoch #5. Accuracy on batch 1750/2438  on Training is 68.86778983438036\n",
            "Epoch #5. Accuracy on batch 1751/2438  on Training is 68.85880422374429\n",
            "Epoch #5. Accuracy on batch 1752/2438  on Training is 68.85517683970336\n",
            "Epoch #5. Accuracy on batch 1753/2438  on Training is 68.85511687571265\n",
            "Epoch #5. Accuracy on batch 1754/2438  on Training is 68.86039886039886\n",
            "Epoch #5. Accuracy on batch 1755/2438  on Training is 68.8692340546697\n",
            "Epoch #5. Accuracy on batch 1756/2438  on Training is 68.86916619237337\n",
            "Epoch #5. Accuracy on batch 1757/2438  on Training is 68.85843287827076\n",
            "Epoch #5. Accuracy on batch 1758/2438  on Training is 68.8601478112564\n",
            "Epoch #5. Accuracy on batch 1759/2438  on Training is 68.8583096590909\n",
            "Batch Id 1760/2438 is having training loss of 1.1354776620864868\n",
            "0.8146471381187439\n",
            "Epoch #5. Accuracy on batch 1760/2438  on Training is 68.86357183418512\n",
            "Epoch #5. Accuracy on batch 1761/2438  on Training is 68.85286606129398\n",
            "Epoch #5. Accuracy on batch 1762/2438  on Training is 68.85103516732842\n",
            "Epoch #5. Accuracy on batch 1763/2438  on Training is 68.8562925170068\n",
            "Epoch #5. Accuracy on batch 1764/2438  on Training is 68.85977337110482\n",
            "Epoch #5. Accuracy on batch 1765/2438  on Training is 68.86325028312571\n",
            "Epoch #5. Accuracy on batch 1766/2438  on Training is 68.86318619128467\n",
            "Epoch #5. Accuracy on batch 1767/2438  on Training is 68.8631221719457\n",
            "Epoch #5. Accuracy on batch 1768/2438  on Training is 68.86305822498586\n",
            "Epoch #5. Accuracy on batch 1769/2438  on Training is 68.86652542372882\n",
            "Epoch #5. Accuracy on batch 1770/2438  on Training is 68.86645962732919\n",
            "Epoch #5. Accuracy on batch 1771/2438  on Training is 68.86463036117381\n",
            "Epoch #5. Accuracy on batch 1772/2438  on Training is 68.86985335589397\n",
            "Epoch #5. Accuracy on batch 1773/2438  on Training is 68.86450112739571\n",
            "Epoch #5. Accuracy on batch 1774/2438  on Training is 68.86267605633803\n",
            "Epoch #5. Accuracy on batch 1775/2438  on Training is 68.86965090090091\n",
            "Epoch #5. Accuracy on batch 1776/2438  on Training is 68.86958356781092\n",
            "Epoch #5. Accuracy on batch 1777/2438  on Training is 68.87303149606299\n",
            "Epoch #5. Accuracy on batch 1778/2438  on Training is 68.869449128724\n",
            "Epoch #5. Accuracy on batch 1779/2438  on Training is 68.86762640449439\n",
            "Batch Id 1780/2438 is having training loss of 1.1353306770324707\n",
            "1.0954749584197998\n",
            "Epoch #5. Accuracy on batch 1780/2438  on Training is 68.86756035934869\n",
            "Epoch #5. Accuracy on batch 1781/2438  on Training is 68.86749438832773\n",
            "Epoch #5. Accuracy on batch 1782/2438  on Training is 68.8709338194055\n",
            "Epoch #5. Accuracy on batch 1783/2438  on Training is 68.86561098654708\n",
            "Epoch #5. Accuracy on batch 1784/2438  on Training is 68.87079831932773\n",
            "Epoch #5. Accuracy on batch 1785/2438  on Training is 68.87597984322508\n",
            "Epoch #5. Accuracy on batch 1786/2438  on Training is 68.87765808617795\n",
            "Epoch #5. Accuracy on batch 1787/2438  on Training is 68.8810822147651\n",
            "Epoch #5. Accuracy on batch 1788/2438  on Training is 68.88450251537172\n",
            "Epoch #5. Accuracy on batch 1789/2438  on Training is 68.88966480446928\n",
            "Epoch #5. Accuracy on batch 1790/2438  on Training is 68.89133165829146\n",
            "Epoch #5. Accuracy on batch 1791/2438  on Training is 68.89299665178571\n",
            "Epoch #5. Accuracy on batch 1792/2438  on Training is 68.89640267707752\n",
            "Epoch #5. Accuracy on batch 1793/2438  on Training is 68.8980629877369\n",
            "Epoch #5. Accuracy on batch 1794/2438  on Training is 68.90320334261838\n",
            "Epoch #5. Accuracy on batch 1795/2438  on Training is 68.9013780623608\n",
            "Epoch #5. Accuracy on batch 1796/2438  on Training is 68.89607679465776\n",
            "Epoch #5. Accuracy on batch 1797/2438  on Training is 68.89947163515016\n",
            "Epoch #5. Accuracy on batch 1798/2438  on Training is 68.90112562534742\n",
            "Epoch #5. Accuracy on batch 1799/2438  on Training is 68.90104166666667\n",
            "Batch Id 1800/2438 is having training loss of 1.1338698863983154\n",
            "1.101548433303833\n",
            "Epoch #5. Accuracy on batch 1800/2438  on Training is 68.89922265408107\n",
            "Epoch #5. Accuracy on batch 1801/2438  on Training is 68.90087402885682\n",
            "Epoch #5. Accuracy on batch 1802/2438  on Training is 68.90945646145313\n",
            "Epoch #5. Accuracy on batch 1803/2438  on Training is 68.91976164079823\n",
            "Epoch #5. Accuracy on batch 1804/2438  on Training is 68.93005540166205\n",
            "Epoch #5. Accuracy on batch 1805/2438  on Training is 68.92822535991141\n",
            "Epoch #5. Accuracy on batch 1806/2438  on Training is 68.92466795794134\n",
            "Epoch #5. Accuracy on batch 1807/2438  on Training is 68.92284292035399\n",
            "Epoch #5. Accuracy on batch 1808/2438  on Training is 68.9313847429519\n",
            "Epoch #5. Accuracy on batch 1809/2438  on Training is 68.93646408839778\n",
            "Epoch #5. Accuracy on batch 1810/2438  on Training is 68.93808669243512\n",
            "Epoch #5. Accuracy on batch 1811/2438  on Training is 68.93970750551877\n",
            "Epoch #5. Accuracy on batch 1812/2438  on Training is 68.9430501930502\n",
            "Epoch #5. Accuracy on batch 1813/2438  on Training is 68.94466648291069\n",
            "Epoch #5. Accuracy on batch 1814/2438  on Training is 68.94455922865014\n",
            "Epoch #5. Accuracy on batch 1815/2438  on Training is 68.94617290748899\n",
            "Epoch #5. Accuracy on batch 1816/2438  on Training is 68.9443450742983\n",
            "Epoch #5. Accuracy on batch 1817/2438  on Training is 68.93908140814081\n",
            "Epoch #5. Accuracy on batch 1818/2438  on Training is 68.94069543705332\n",
            "Epoch #5. Accuracy on batch 1819/2438  on Training is 68.93887362637362\n",
            "Batch Id 1820/2438 is having training loss of 1.1326758861541748\n",
            "1.1194899082183838\n",
            "Epoch #5. Accuracy on batch 1820/2438  on Training is 68.9387699066447\n",
            "Epoch #5. Accuracy on batch 1821/2438  on Training is 68.93866630076839\n",
            "Epoch #5. Accuracy on batch 1822/2438  on Training is 68.94370543060889\n",
            "Epoch #5. Accuracy on batch 1823/2438  on Training is 68.95045230263158\n",
            "Epoch #5. Accuracy on batch 1824/2438  on Training is 68.94349315068493\n",
            "Epoch #5. Accuracy on batch 1825/2438  on Training is 68.95023274917854\n",
            "Epoch #5. Accuracy on batch 1826/2438  on Training is 68.95012315270937\n",
            "Epoch #5. Accuracy on batch 1827/2438  on Training is 68.94317560175055\n",
            "Epoch #5. Accuracy on batch 1828/2438  on Training is 68.94648715144888\n",
            "Epoch #5. Accuracy on batch 1829/2438  on Training is 68.94637978142076\n",
            "Epoch #5. Accuracy on batch 1830/2438  on Training is 68.95139268159475\n",
            "Epoch #5. Accuracy on batch 1831/2438  on Training is 68.9564001091703\n",
            "Epoch #5. Accuracy on batch 1832/2438  on Training is 68.96822149481724\n",
            "Epoch #5. Accuracy on batch 1833/2438  on Training is 68.96810250817884\n",
            "Epoch #5. Accuracy on batch 1834/2438  on Training is 68.97138964577657\n",
            "Epoch #5. Accuracy on batch 1835/2438  on Training is 68.96956699346406\n",
            "Epoch #5. Accuracy on batch 1836/2438  on Training is 68.96944746869896\n",
            "Epoch #5. Accuracy on batch 1837/2438  on Training is 68.9761289445049\n",
            "Epoch #5. Accuracy on batch 1838/2438  on Training is 68.97940456769983\n",
            "Epoch #5. Accuracy on batch 1839/2438  on Training is 68.98267663043478\n",
            "Batch Id 1840/2438 is having training loss of 1.1317111253738403\n",
            "1.1307395696640015\n",
            "Epoch #5. Accuracy on batch 1840/2438  on Training is 68.98255024443237\n",
            "Epoch #5. Accuracy on batch 1841/2438  on Training is 68.98412052117264\n",
            "Epoch #5. Accuracy on batch 1842/2438  on Training is 68.98229788388497\n",
            "Epoch #5. Accuracy on batch 1843/2438  on Training is 68.97708785249458\n",
            "Epoch #5. Accuracy on batch 1844/2438  on Training is 68.97527100271003\n",
            "Epoch #5. Accuracy on batch 1845/2438  on Training is 68.97007042253522\n",
            "Epoch #5. Accuracy on batch 1846/2438  on Training is 68.95810774228478\n",
            "Epoch #5. Accuracy on batch 1847/2438  on Training is 68.95968614718615\n",
            "Epoch #5. Accuracy on batch 1848/2438  on Training is 68.95957274202271\n",
            "Epoch #5. Accuracy on batch 1849/2438  on Training is 68.94763513513513\n",
            "Epoch #5. Accuracy on batch 1850/2438  on Training is 68.94921663965424\n",
            "Epoch #5. Accuracy on batch 1851/2438  on Training is 68.9507964362851\n",
            "Epoch #5. Accuracy on batch 1852/2438  on Training is 68.94731516459795\n",
            "Epoch #5. Accuracy on batch 1853/2438  on Training is 68.94552319309601\n",
            "Epoch #5. Accuracy on batch 1854/2438  on Training is 68.94541778975741\n",
            "Epoch #5. Accuracy on batch 1855/2438  on Training is 68.94194504310344\n",
            "Epoch #5. Accuracy on batch 1856/2438  on Training is 68.94352450188477\n",
            "Epoch #5. Accuracy on batch 1857/2438  on Training is 68.9400565123789\n",
            "Epoch #5. Accuracy on batch 1858/2438  on Training is 68.93995427649274\n",
            "Epoch #5. Accuracy on batch 1859/2438  on Training is 68.93649193548387\n",
            "Batch Id 1860/2438 is having training loss of 1.1327531337738037\n",
            "0.859653651714325\n",
            "Epoch #5. Accuracy on batch 1860/2438  on Training is 68.93975013433638\n",
            "Epoch #5. Accuracy on batch 1861/2438  on Training is 68.94636143931257\n",
            "Epoch #5. Accuracy on batch 1862/2438  on Training is 68.94457863660762\n",
            "Epoch #5. Accuracy on batch 1863/2438  on Training is 68.9344152360515\n",
            "Epoch #5. Accuracy on batch 1864/2438  on Training is 68.93599195710456\n",
            "Epoch #5. Accuracy on batch 1865/2438  on Training is 68.93924169346195\n",
            "Epoch #5. Accuracy on batch 1866/2438  on Training is 68.94081414033208\n",
            "Epoch #5. Accuracy on batch 1867/2438  on Training is 68.93903907922912\n",
            "Epoch #5. Accuracy on batch 1868/2438  on Training is 68.94228196896736\n",
            "Epoch #5. Accuracy on batch 1869/2438  on Training is 68.94385026737967\n",
            "Epoch #5. Accuracy on batch 1870/2438  on Training is 68.94541688936398\n",
            "Epoch #5. Accuracy on batch 1871/2438  on Training is 68.94197382478633\n",
            "Epoch #5. Accuracy on batch 1872/2438  on Training is 68.9535504538174\n",
            "Epoch #5. Accuracy on batch 1873/2438  on Training is 68.95344183564568\n",
            "Epoch #5. Accuracy on batch 1874/2438  on Training is 68.95166666666667\n",
            "Epoch #5. Accuracy on batch 1875/2438  on Training is 68.9598880597015\n",
            "Epoch #5. Accuracy on batch 1876/2438  on Training is 68.96310602024508\n",
            "Epoch #5. Accuracy on batch 1877/2438  on Training is 68.96465654952077\n",
            "Epoch #5. Accuracy on batch 1878/2438  on Training is 68.96454230973923\n",
            "Epoch #5. Accuracy on batch 1879/2438  on Training is 68.95777925531915\n",
            "Batch Id 1880/2438 is having training loss of 1.132467269897461\n",
            "0.7283281087875366\n",
            "Epoch #5. Accuracy on batch 1880/2438  on Training is 68.9626528442318\n",
            "Epoch #5. Accuracy on batch 1881/2438  on Training is 68.95423751328374\n",
            "Epoch #5. Accuracy on batch 1882/2438  on Training is 68.95412904938927\n",
            "Epoch #5. Accuracy on batch 1883/2438  on Training is 68.95899681528662\n",
            "Epoch #5. Accuracy on batch 1884/2438  on Training is 68.95557029177719\n",
            "Epoch #5. Accuracy on batch 1885/2438  on Training is 68.9538043478261\n",
            "Epoch #5. Accuracy on batch 1886/2438  on Training is 68.95535241123477\n",
            "Epoch #5. Accuracy on batch 1887/2438  on Training is 68.9502780720339\n",
            "Epoch #5. Accuracy on batch 1888/2438  on Training is 68.95844362096348\n",
            "Epoch #5. Accuracy on batch 1889/2438  on Training is 68.96164021164022\n",
            "Epoch #5. Accuracy on batch 1890/2438  on Training is 68.9681385510312\n",
            "Epoch #5. Accuracy on batch 1891/2438  on Training is 68.96967494714588\n",
            "Epoch #5. Accuracy on batch 1892/2438  on Training is 68.97120972002114\n",
            "Epoch #5. Accuracy on batch 1893/2438  on Training is 68.97439281942978\n",
            "Epoch #5. Accuracy on batch 1894/2438  on Training is 68.97427440633246\n",
            "Epoch #5. Accuracy on batch 1895/2438  on Training is 68.96591508438819\n",
            "Epoch #5. Accuracy on batch 1896/2438  on Training is 68.9690959409594\n",
            "Epoch #5. Accuracy on batch 1897/2438  on Training is 68.96898050579557\n",
            "Epoch #5. Accuracy on batch 1898/2438  on Training is 68.97544760400211\n",
            "Epoch #5. Accuracy on batch 1899/2438  on Training is 68.97368421052632\n",
            "Batch Id 1900/2438 is having training loss of 1.1327306032180786\n",
            "1.6868482828140259\n",
            "Epoch #5. Accuracy on batch 1900/2438  on Training is 68.96699105733825\n",
            "Epoch #5. Accuracy on batch 1901/2438  on Training is 68.96523396424816\n",
            "Epoch #5. Accuracy on batch 1902/2438  on Training is 68.9618365738308\n",
            "Epoch #5. Accuracy on batch 1903/2438  on Training is 68.96500787815125\n",
            "Epoch #5. Accuracy on batch 1904/2438  on Training is 68.96325459317585\n",
            "Epoch #5. Accuracy on batch 1905/2438  on Training is 68.96478226652675\n",
            "Epoch #5. Accuracy on batch 1906/2438  on Training is 68.9630309386471\n",
            "Epoch #5. Accuracy on batch 1907/2438  on Training is 68.96619496855345\n",
            "Epoch #5. Accuracy on batch 1908/2438  on Training is 68.96117077003667\n",
            "Epoch #5. Accuracy on batch 1909/2438  on Training is 68.95942408376963\n",
            "Epoch #5. Accuracy on batch 1910/2438  on Training is 68.96094976452119\n",
            "Epoch #5. Accuracy on batch 1911/2438  on Training is 68.96410826359832\n",
            "Epoch #5. Accuracy on batch 1912/2438  on Training is 68.96399634082593\n",
            "Epoch #5. Accuracy on batch 1913/2438  on Training is 68.97368077324974\n",
            "Epoch #5. Accuracy on batch 1914/2438  on Training is 68.97030026109661\n",
            "Epoch #5. Accuracy on batch 1915/2438  on Training is 68.97018528183716\n",
            "Epoch #5. Accuracy on batch 1916/2438  on Training is 68.97496087636932\n",
            "Epoch #5. Accuracy on batch 1917/2438  on Training is 68.97810218978103\n",
            "Epoch #5. Accuracy on batch 1918/2438  on Training is 68.98124022928609\n",
            "Epoch #5. Accuracy on batch 1919/2438  on Training is 68.984375\n",
            "Batch Id 1920/2438 is having training loss of 1.1322596073150635\n",
            "0.7617495059967041\n",
            "Epoch #5. Accuracy on batch 1920/2438  on Training is 68.99076002082249\n",
            "Epoch #5. Accuracy on batch 1921/2438  on Training is 68.99226066597295\n",
            "Epoch #5. Accuracy on batch 1922/2438  on Training is 68.99538481539261\n",
            "Epoch #5. Accuracy on batch 1923/2438  on Training is 68.98713617463618\n",
            "Epoch #5. Accuracy on batch 1924/2438  on Training is 68.98863636363636\n",
            "Epoch #5. Accuracy on batch 1925/2438  on Training is 68.99013499480789\n",
            "Epoch #5. Accuracy on batch 1926/2438  on Training is 68.98676699532953\n",
            "Epoch #5. Accuracy on batch 1927/2438  on Training is 68.98664419087137\n",
            "Epoch #5. Accuracy on batch 1928/2438  on Training is 68.98490150336963\n",
            "Epoch #5. Accuracy on batch 1929/2438  on Training is 68.98801813471502\n",
            "Epoch #5. Accuracy on batch 1930/2438  on Training is 68.98789487312274\n",
            "Epoch #5. Accuracy on batch 1931/2438  on Training is 68.98777173913044\n",
            "Epoch #5. Accuracy on batch 1932/2438  on Training is 68.98926539058458\n",
            "Epoch #5. Accuracy on batch 1933/2438  on Training is 68.99075749741469\n",
            "Epoch #5. Accuracy on batch 1934/2438  on Training is 68.9890180878553\n",
            "Epoch #5. Accuracy on batch 1935/2438  on Training is 68.99373708677686\n",
            "Epoch #5. Accuracy on batch 1936/2438  on Training is 69.00329117191534\n",
            "Epoch #5. Accuracy on batch 1937/2438  on Training is 69.0031604747162\n",
            "Epoch #5. Accuracy on batch 1938/2438  on Training is 69.00302991232594\n",
            "Epoch #5. Accuracy on batch 1939/2438  on Training is 68.99484536082474\n",
            "Batch Id 1940/2438 is having training loss of 1.132237195968628\n",
            "1.748002290725708\n",
            "Epoch #5. Accuracy on batch 1940/2438  on Training is 68.98344925296239\n",
            "Epoch #5. Accuracy on batch 1941/2438  on Training is 68.98332904222451\n",
            "Epoch #5. Accuracy on batch 1942/2438  on Training is 68.99285898095728\n",
            "Epoch #5. Accuracy on batch 1943/2438  on Training is 68.99273405349794\n",
            "Epoch #5. Accuracy on batch 1944/2438  on Training is 68.99582262210797\n",
            "Epoch #5. Accuracy on batch 1945/2438  on Training is 68.99409044193217\n",
            "Epoch #5. Accuracy on batch 1946/2438  on Training is 69.00038520801233\n",
            "Epoch #5. Accuracy on batch 1947/2438  on Training is 68.99704825462013\n",
            "Epoch #5. Accuracy on batch 1948/2438  on Training is 68.99852488455618\n",
            "Epoch #5. Accuracy on batch 1949/2438  on Training is 68.99358974358974\n",
            "Epoch #5. Accuracy on batch 1950/2438  on Training is 68.99346488980011\n",
            "Epoch #5. Accuracy on batch 1951/2438  on Training is 68.99173924180327\n",
            "Epoch #5. Accuracy on batch 1952/2438  on Training is 68.9932155657962\n",
            "Epoch #5. Accuracy on batch 1953/2438  on Training is 68.99628966223132\n",
            "Epoch #5. Accuracy on batch 1954/2438  on Training is 68.99936061381074\n",
            "Epoch #5. Accuracy on batch 1955/2438  on Training is 69.00402607361963\n",
            "Epoch #5. Accuracy on batch 1956/2438  on Training is 69.00229943791517\n",
            "Epoch #5. Accuracy on batch 1957/2438  on Training is 69.00695863125638\n",
            "Epoch #5. Accuracy on batch 1958/2438  on Training is 69.0084226646248\n",
            "Epoch #5. Accuracy on batch 1959/2438  on Training is 69.01307397959184\n",
            "Batch Id 1960/2438 is having training loss of 1.1311721801757812\n",
            "1.3099966049194336\n",
            "Epoch #5. Accuracy on batch 1960/2438  on Training is 69.00656552779195\n",
            "Epoch #5. Accuracy on batch 1961/2438  on Training is 69.00802752293578\n",
            "Epoch #5. Accuracy on batch 1962/2438  on Training is 69.00630412633724\n",
            "Epoch #5. Accuracy on batch 1963/2438  on Training is 69.01572046843177\n",
            "Epoch #5. Accuracy on batch 1964/2438  on Training is 69.00922391857506\n",
            "Epoch #5. Accuracy on batch 1965/2438  on Training is 69.01068158697863\n",
            "Epoch #5. Accuracy on batch 1966/2438  on Training is 69.01054905948145\n",
            "Epoch #5. Accuracy on batch 1967/2438  on Training is 69.0135924796748\n",
            "Epoch #5. Accuracy on batch 1968/2438  on Training is 69.01345860843068\n",
            "Epoch #5. Accuracy on batch 1969/2438  on Training is 69.01332487309645\n",
            "Epoch #5. Accuracy on batch 1970/2438  on Training is 69.00843480466769\n",
            "Epoch #5. Accuracy on batch 1971/2438  on Training is 69.00988843813387\n",
            "Epoch #5. Accuracy on batch 1972/2438  on Training is 69.00817283324886\n",
            "Epoch #5. Accuracy on batch 1973/2438  on Training is 69.00487588652483\n",
            "Epoch #5. Accuracy on batch 1974/2438  on Training is 69.00316455696202\n",
            "Epoch #5. Accuracy on batch 1975/2438  on Training is 69.00936234817814\n",
            "Epoch #5. Accuracy on batch 1976/2438  on Training is 69.0013277693475\n",
            "Epoch #5. Accuracy on batch 1977/2438  on Training is 69.00752022244691\n",
            "Epoch #5. Accuracy on batch 1978/2438  on Training is 69.00739009600808\n",
            "Epoch #5. Accuracy on batch 1979/2438  on Training is 69.00883838383838\n",
            "Batch Id 1980/2438 is having training loss of 1.1312509775161743\n",
            "1.1770472526550293\n",
            "Epoch #5. Accuracy on batch 1980/2438  on Training is 69.01028520949016\n",
            "Epoch #5. Accuracy on batch 1981/2438  on Training is 69.00857719475277\n",
            "Epoch #5. Accuracy on batch 1982/2438  on Training is 69.01475037821483\n",
            "Epoch #5. Accuracy on batch 1983/2438  on Training is 69.00674143145162\n",
            "Epoch #5. Accuracy on batch 1984/2438  on Training is 69.00031486146096\n",
            "Epoch #5. Accuracy on batch 1985/2438  on Training is 68.99861530715005\n",
            "Epoch #5. Accuracy on batch 1986/2438  on Training is 68.9906265727227\n",
            "Epoch #5. Accuracy on batch 1987/2438  on Training is 68.98578973843058\n",
            "Epoch #5. Accuracy on batch 1988/2438  on Training is 68.97467320261438\n",
            "Epoch #5. Accuracy on batch 1989/2438  on Training is 68.98241206030151\n",
            "Epoch #5. Accuracy on batch 1990/2438  on Training is 68.98072576594676\n",
            "Epoch #5. Accuracy on batch 1991/2438  on Training is 68.97904116465864\n",
            "Epoch #5. Accuracy on batch 1992/2438  on Training is 68.98049422980432\n",
            "Epoch #5. Accuracy on batch 1993/2438  on Training is 68.97881143430291\n",
            "Epoch #5. Accuracy on batch 1994/2438  on Training is 68.98652882205513\n",
            "Epoch #5. Accuracy on batch 1995/2438  on Training is 68.9879759519038\n",
            "Epoch #5. Accuracy on batch 1996/2438  on Training is 68.98942163244867\n",
            "Epoch #5. Accuracy on batch 1997/2438  on Training is 68.98304554554555\n",
            "Epoch #5. Accuracy on batch 1998/2438  on Training is 68.98136568284141\n",
            "Epoch #5. Accuracy on batch 1999/2438  on Training is 68.9859375\n",
            "Batch Id 2000/2438 is having training loss of 1.132142186164856\n",
            "1.1856153011322021\n",
            "Epoch #5. Accuracy on batch 2000/2438  on Training is 68.98269615192403\n",
            "Epoch #5. Accuracy on batch 2001/2438  on Training is 68.98726273726274\n",
            "Epoch #5. Accuracy on batch 2002/2438  on Training is 68.988704443335\n",
            "Epoch #5. Accuracy on batch 2003/2438  on Training is 68.99326347305389\n",
            "Epoch #5. Accuracy on batch 2004/2438  on Training is 69.00249376558604\n",
            "Epoch #5. Accuracy on batch 2005/2438  on Training is 69.00548354935195\n",
            "Epoch #5. Accuracy on batch 2006/2438  on Training is 69.00691330343797\n",
            "Epoch #5. Accuracy on batch 2007/2438  on Training is 69.01301045816733\n",
            "Epoch #5. Accuracy on batch 2008/2438  on Training is 69.01132404181185\n",
            "Epoch #5. Accuracy on batch 2009/2438  on Training is 69.0205223880597\n",
            "Epoch #5. Accuracy on batch 2010/2438  on Training is 69.02349577324713\n",
            "Epoch #5. Accuracy on batch 2011/2438  on Training is 69.02335984095427\n",
            "Epoch #5. Accuracy on batch 2012/2438  on Training is 69.02477645305514\n",
            "Epoch #5. Accuracy on batch 2013/2438  on Training is 69.02308838133068\n",
            "Epoch #5. Accuracy on batch 2014/2438  on Training is 69.02295285359801\n",
            "Epoch #5. Accuracy on batch 2015/2438  on Training is 69.02591765873017\n",
            "Epoch #5. Accuracy on batch 2016/2438  on Training is 69.02423153197819\n",
            "Epoch #5. Accuracy on batch 2017/2438  on Training is 69.01635282457879\n",
            "Epoch #5. Accuracy on batch 2018/2438  on Training is 69.0208642892521\n",
            "Epoch #5. Accuracy on batch 2019/2438  on Training is 69.01454207920793\n",
            "Batch Id 2020/2438 is having training loss of 1.131401777267456\n",
            "1.185347557067871\n",
            "Epoch #5. Accuracy on batch 2020/2438  on Training is 69.01286491835725\n",
            "Epoch #5. Accuracy on batch 2021/2438  on Training is 69.0158259149357\n",
            "Epoch #5. Accuracy on batch 2022/2438  on Training is 69.01723924864064\n",
            "Epoch #5. Accuracy on batch 2023/2438  on Training is 69.01556324110672\n",
            "Epoch #5. Accuracy on batch 2024/2438  on Training is 69.01851851851852\n",
            "Epoch #5. Accuracy on batch 2025/2438  on Training is 69.01530108588351\n",
            "Epoch #5. Accuracy on batch 2026/2438  on Training is 69.01979526393686\n",
            "Epoch #5. Accuracy on batch 2027/2438  on Training is 69.02120315581854\n",
            "Epoch #5. Accuracy on batch 2028/2438  on Training is 69.02568999507146\n",
            "Epoch #5. Accuracy on batch 2029/2438  on Training is 69.0286330049261\n",
            "Epoch #5. Accuracy on batch 2030/2438  on Training is 69.03157311669129\n",
            "Epoch #5. Accuracy on batch 2031/2438  on Training is 69.0298966535433\n",
            "Epoch #5. Accuracy on batch 2032/2438  on Training is 69.023610427939\n",
            "Epoch #5. Accuracy on batch 2033/2438  on Training is 69.02347590953785\n",
            "Epoch #5. Accuracy on batch 2034/2438  on Training is 69.02487714987716\n",
            "Epoch #5. Accuracy on batch 2035/2438  on Training is 69.02627701375246\n",
            "Epoch #5. Accuracy on batch 2036/2438  on Training is 69.02000490918017\n",
            "Epoch #5. Accuracy on batch 2037/2438  on Training is 69.02293915603533\n",
            "Epoch #5. Accuracy on batch 2038/2438  on Training is 69.02587052476704\n",
            "Epoch #5. Accuracy on batch 2039/2438  on Training is 69.01501225490196\n",
            "Batch Id 2040/2438 is having training loss of 1.1321179866790771\n",
            "1.2892500162124634\n",
            "Epoch #5. Accuracy on batch 2040/2438  on Training is 69.01028907398334\n",
            "Epoch #5. Accuracy on batch 2041/2438  on Training is 69.00863124387855\n",
            "Epoch #5. Accuracy on batch 2042/2438  on Training is 69.01309348996574\n",
            "Epoch #5. Accuracy on batch 2043/2438  on Training is 69.00837818003914\n",
            "Epoch #5. Accuracy on batch 2044/2438  on Training is 69.00977995110024\n",
            "Epoch #5. Accuracy on batch 2045/2438  on Training is 69.00354349951124\n",
            "Epoch #5. Accuracy on batch 2046/2438  on Training is 68.99578651685393\n",
            "Epoch #5. Accuracy on batch 2047/2438  on Training is 68.99566650390625\n",
            "Epoch #5. Accuracy on batch 2048/2438  on Training is 68.9955466081015\n",
            "Epoch #5. Accuracy on batch 2049/2438  on Training is 68.9954268292683\n",
            "Epoch #5. Accuracy on batch 2050/2438  on Training is 68.98921257922964\n",
            "Epoch #5. Accuracy on batch 2051/2438  on Training is 68.99061890838206\n",
            "Epoch #5. Accuracy on batch 2052/2438  on Training is 68.98745737944472\n",
            "Epoch #5. Accuracy on batch 2053/2438  on Training is 68.98886319376825\n",
            "Epoch #5. Accuracy on batch 2054/2438  on Training is 68.9933090024331\n",
            "Epoch #5. Accuracy on batch 2055/2438  on Training is 68.99623054474708\n",
            "Epoch #5. Accuracy on batch 2056/2438  on Training is 68.99763004375303\n",
            "Epoch #5. Accuracy on batch 2057/2438  on Training is 68.99750971817298\n",
            "Epoch #5. Accuracy on batch 2058/2438  on Training is 68.99587178241865\n",
            "Epoch #5. Accuracy on batch 2059/2438  on Training is 68.9942354368932\n",
            "Batch Id 2060/2438 is having training loss of 1.1322858333587646\n",
            "0.6458296179771423\n",
            "Epoch #5. Accuracy on batch 2060/2438  on Training is 68.99866569626396\n",
            "Epoch #5. Accuracy on batch 2061/2438  on Training is 68.99096750727449\n",
            "Epoch #5. Accuracy on batch 2062/2438  on Training is 68.99388027144934\n",
            "Epoch #5. Accuracy on batch 2063/2438  on Training is 68.9937621124031\n",
            "Epoch #5. Accuracy on batch 2064/2438  on Training is 68.98910411622276\n",
            "Epoch #5. Accuracy on batch 2065/2438  on Training is 68.98898838334947\n",
            "Epoch #5. Accuracy on batch 2066/2438  on Training is 68.9934083212385\n",
            "Epoch #5. Accuracy on batch 2067/2438  on Training is 68.99026837524178\n",
            "Epoch #5. Accuracy on batch 2068/2438  on Training is 68.99015224746255\n",
            "Epoch #5. Accuracy on batch 2069/2438  on Training is 68.98701690821257\n",
            "Epoch #5. Accuracy on batch 2070/2438  on Training is 68.98690246257847\n",
            "Epoch #5. Accuracy on batch 2071/2438  on Training is 68.99583735521236\n",
            "Epoch #5. Accuracy on batch 2072/2438  on Training is 68.99571876507477\n",
            "Epoch #5. Accuracy on batch 2073/2438  on Training is 68.99560028929605\n",
            "Epoch #5. Accuracy on batch 2074/2438  on Training is 68.99096385542168\n",
            "Epoch #5. Accuracy on batch 2075/2438  on Training is 68.99536368015414\n",
            "Epoch #5. Accuracy on batch 2076/2438  on Training is 68.99524554646125\n",
            "Epoch #5. Accuracy on batch 2077/2438  on Training is 68.9921198267565\n",
            "Epoch #5. Accuracy on batch 2078/2438  on Training is 68.99050024050024\n",
            "Epoch #5. Accuracy on batch 2079/2438  on Training is 68.98587740384616\n",
            "Batch Id 2080/2438 is having training loss of 1.1326618194580078\n",
            "1.2081639766693115\n",
            "Epoch #5. Accuracy on batch 2080/2438  on Training is 68.98276069197502\n",
            "Epoch #5. Accuracy on batch 2081/2438  on Training is 68.98414985590779\n",
            "Epoch #5. Accuracy on batch 2082/2438  on Training is 68.98403744599136\n",
            "Epoch #5. Accuracy on batch 2083/2438  on Training is 68.98842370441459\n",
            "Epoch #5. Accuracy on batch 2084/2438  on Training is 68.98830935251799\n",
            "Epoch #5. Accuracy on batch 2085/2438  on Training is 68.98669702780441\n",
            "Epoch #5. Accuracy on batch 2086/2438  on Training is 68.97759942501197\n",
            "Epoch #5. Accuracy on batch 2087/2438  on Training is 68.98048371647509\n",
            "Epoch #5. Accuracy on batch 2088/2438  on Training is 68.98037338439445\n",
            "Epoch #5. Accuracy on batch 2089/2438  on Training is 68.98325358851675\n",
            "Epoch #5. Accuracy on batch 2090/2438  on Training is 68.98613103778096\n",
            "Epoch #5. Accuracy on batch 2091/2438  on Training is 68.9919933078394\n",
            "Epoch #5. Accuracy on batch 2092/2438  on Training is 68.99038461538461\n",
            "Epoch #5. Accuracy on batch 2093/2438  on Training is 68.99176217765043\n",
            "Epoch #5. Accuracy on batch 2094/2438  on Training is 68.98418854415274\n",
            "Epoch #5. Accuracy on batch 2095/2438  on Training is 68.98258587786259\n",
            "Epoch #5. Accuracy on batch 2096/2438  on Training is 68.98396518836434\n",
            "Epoch #5. Accuracy on batch 2097/2438  on Training is 68.98087464251668\n",
            "Epoch #5. Accuracy on batch 2098/2438  on Training is 68.97927584564079\n",
            "Epoch #5. Accuracy on batch 2099/2438  on Training is 68.98214285714286\n",
            "Batch Id 2100/2438 is having training loss of 1.1323044300079346\n",
            "0.933173418045044\n",
            "Epoch #5. Accuracy on batch 2100/2438  on Training is 68.98203236554022\n",
            "Epoch #5. Accuracy on batch 2101/2438  on Training is 68.98192197906755\n",
            "Epoch #5. Accuracy on batch 2102/2438  on Training is 68.9877555872563\n",
            "Epoch #5. Accuracy on batch 2103/2438  on Training is 68.98615731939164\n",
            "Epoch #5. Accuracy on batch 2104/2438  on Training is 68.98901425178147\n",
            "Epoch #5. Accuracy on batch 2105/2438  on Training is 68.99483618233619\n",
            "Epoch #5. Accuracy on batch 2106/2438  on Training is 68.99768628381585\n",
            "Epoch #5. Accuracy on batch 2107/2438  on Training is 69.00053368121442\n",
            "Epoch #5. Accuracy on batch 2108/2438  on Training is 68.99448790896159\n",
            "Epoch #5. Accuracy on batch 2109/2438  on Training is 68.99585308056872\n",
            "Epoch #5. Accuracy on batch 2110/2438  on Training is 68.9972169587873\n",
            "Epoch #5. Accuracy on batch 2111/2438  on Training is 68.99709990530303\n",
            "Epoch #5. Accuracy on batch 2112/2438  on Training is 68.99550402271652\n",
            "Epoch #5. Accuracy on batch 2113/2438  on Training is 69.00130085146641\n",
            "Epoch #5. Accuracy on batch 2114/2438  on Training is 69.00265957446808\n",
            "Epoch #5. Accuracy on batch 2115/2438  on Training is 69.00844754253308\n",
            "Epoch #5. Accuracy on batch 2116/2438  on Training is 69.00832546055739\n",
            "Epoch #5. Accuracy on batch 2117/2438  on Training is 69.00377714825306\n",
            "Epoch #5. Accuracy on batch 2118/2438  on Training is 69.00365738555922\n",
            "Epoch #5. Accuracy on batch 2119/2438  on Training is 69.00501179245283\n",
            "Batch Id 2120/2438 is having training loss of 1.1311558485031128\n",
            "0.877729594707489\n",
            "Epoch #5. Accuracy on batch 2120/2438  on Training is 69.01078500707213\n",
            "Epoch #5. Accuracy on batch 2121/2438  on Training is 69.00771677662583\n",
            "Epoch #5. Accuracy on batch 2122/2438  on Training is 69.00317946302403\n",
            "Epoch #5. Accuracy on batch 2123/2438  on Training is 69.00453154425612\n",
            "Epoch #5. Accuracy on batch 2124/2438  on Training is 69.00147058823529\n",
            "Epoch #5. Accuracy on batch 2125/2438  on Training is 68.99694261523989\n",
            "Epoch #5. Accuracy on batch 2126/2438  on Training is 68.98948048895157\n",
            "Epoch #5. Accuracy on batch 2127/2438  on Training is 68.98789943609023\n",
            "Epoch #5. Accuracy on batch 2128/2438  on Training is 68.98925551902302\n",
            "Epoch #5. Accuracy on batch 2129/2438  on Training is 68.9906103286385\n",
            "Epoch #5. Accuracy on batch 2130/2438  on Training is 68.99196386672924\n",
            "Epoch #5. Accuracy on batch 2131/2438  on Training is 68.99331613508443\n",
            "Epoch #5. Accuracy on batch 2132/2438  on Training is 68.99613220815752\n",
            "Epoch #5. Accuracy on batch 2133/2438  on Training is 68.99162371134021\n",
            "Epoch #5. Accuracy on batch 2134/2438  on Training is 68.9900468384075\n",
            "Epoch #5. Accuracy on batch 2135/2438  on Training is 68.9870084269663\n",
            "Epoch #5. Accuracy on batch 2136/2438  on Training is 68.98689751988769\n",
            "Epoch #5. Accuracy on batch 2137/2438  on Training is 68.98678671655753\n",
            "Epoch #5. Accuracy on batch 2138/2438  on Training is 68.98813697989715\n",
            "Epoch #5. Accuracy on batch 2139/2438  on Training is 68.99386682242991\n",
            "Batch Id 2140/2438 is having training loss of 1.1316180229187012\n",
            "0.7002752423286438\n",
            "Epoch #5. Accuracy on batch 2140/2438  on Training is 68.99667211583372\n",
            "Epoch #5. Accuracy on batch 2141/2438  on Training is 68.99947478991596\n",
            "Epoch #5. Accuracy on batch 2142/2438  on Training is 69.00227484834345\n",
            "Epoch #5. Accuracy on batch 2143/2438  on Training is 69.00361473880596\n",
            "Epoch #5. Accuracy on batch 2144/2438  on Training is 69.00495337995338\n",
            "Epoch #5. Accuracy on batch 2145/2438  on Training is 69.00337837837837\n",
            "Epoch #5. Accuracy on batch 2146/2438  on Training is 69.00617140195622\n",
            "Epoch #5. Accuracy on batch 2147/2438  on Training is 69.00750698324022\n",
            "Epoch #5. Accuracy on batch 2148/2438  on Training is 69.00738715681713\n",
            "Epoch #5. Accuracy on batch 2149/2438  on Training is 69.00726744186046\n",
            "Epoch #5. Accuracy on batch 2150/2438  on Training is 69.00714783821478\n",
            "Epoch #5. Accuracy on batch 2151/2438  on Training is 69.00267193308551\n",
            "Epoch #5. Accuracy on batch 2152/2438  on Training is 69.00400603808639\n",
            "Epoch #5. Accuracy on batch 2153/2438  on Training is 69.00678969359332\n",
            "Epoch #5. Accuracy on batch 2154/2438  on Training is 69.00087006960557\n",
            "Epoch #5. Accuracy on batch 2155/2438  on Training is 69.00220315398887\n",
            "Epoch #5. Accuracy on batch 2156/2438  on Training is 69.00208623087622\n",
            "Epoch #5. Accuracy on batch 2157/2438  on Training is 68.99472891566265\n",
            "Epoch #5. Accuracy on batch 2158/2438  on Training is 68.99027327466419\n",
            "Epoch #5. Accuracy on batch 2159/2438  on Training is 68.98871527777777\n",
            "Batch Id 2160/2438 is having training loss of 1.1321969032287598\n",
            "1.3930219411849976\n",
            "Epoch #5. Accuracy on batch 2160/2438  on Training is 68.98426654326701\n",
            "Epoch #5. Accuracy on batch 2161/2438  on Training is 68.97982192414432\n",
            "Epoch #5. Accuracy on batch 2162/2438  on Training is 68.97971567267683\n",
            "Epoch #5. Accuracy on batch 2163/2438  on Training is 68.97527726432533\n",
            "Epoch #5. Accuracy on batch 2164/2438  on Training is 68.98527713625866\n",
            "Epoch #5. Accuracy on batch 2165/2438  on Training is 68.9808402585411\n",
            "Epoch #5. Accuracy on batch 2166/2438  on Training is 68.97929164743886\n",
            "Epoch #5. Accuracy on batch 2167/2438  on Training is 68.97630304428044\n",
            "Epoch #5. Accuracy on batch 2168/2438  on Training is 68.97475795297372\n",
            "Epoch #5. Accuracy on batch 2169/2438  on Training is 68.97321428571429\n",
            "Epoch #5. Accuracy on batch 2170/2438  on Training is 68.97742975587288\n",
            "Epoch #5. Accuracy on batch 2171/2438  on Training is 68.97732504604052\n",
            "Epoch #5. Accuracy on batch 2172/2438  on Training is 68.98153474459274\n",
            "Epoch #5. Accuracy on batch 2173/2438  on Training is 68.97424103035878\n",
            "Epoch #5. Accuracy on batch 2174/2438  on Training is 68.97557471264368\n",
            "Epoch #5. Accuracy on batch 2175/2438  on Training is 68.97259880514706\n",
            "Epoch #5. Accuracy on batch 2176/2438  on Training is 68.96962563160312\n",
            "Epoch #5. Accuracy on batch 2177/2438  on Training is 68.97382920110194\n",
            "Epoch #5. Accuracy on batch 2178/2438  on Training is 68.97372648003672\n",
            "Epoch #5. Accuracy on batch 2179/2438  on Training is 68.97505733944953\n",
            "Batch Id 2180/2438 is having training loss of 1.132330060005188\n",
            "1.154637336730957\n",
            "Epoch #5. Accuracy on batch 2180/2438  on Training is 68.97065566254012\n",
            "Epoch #5. Accuracy on batch 2181/2438  on Training is 68.97055453712191\n",
            "Epoch #5. Accuracy on batch 2182/2438  on Training is 68.97474805313789\n",
            "Epoch #5. Accuracy on batch 2183/2438  on Training is 68.97321428571429\n",
            "Epoch #5. Accuracy on batch 2184/2438  on Training is 68.97740274599542\n",
            "Epoch #5. Accuracy on batch 2185/2438  on Training is 68.97301006404392\n",
            "Epoch #5. Accuracy on batch 2186/2438  on Training is 68.97005029721079\n",
            "Epoch #5. Accuracy on batch 2187/2438  on Training is 68.96280850091408\n",
            "Epoch #5. Accuracy on batch 2188/2438  on Training is 68.95129054362722\n",
            "Epoch #5. Accuracy on batch 2189/2438  on Training is 68.95690639269407\n",
            "Epoch #5. Accuracy on batch 2190/2438  on Training is 68.95823824737563\n",
            "Epoch #5. Accuracy on batch 2191/2438  on Training is 68.96099452554745\n",
            "Epoch #5. Accuracy on batch 2192/2438  on Training is 68.95804833561331\n",
            "Epoch #5. Accuracy on batch 2193/2438  on Training is 68.95225615314494\n",
            "Epoch #5. Accuracy on batch 2194/2438  on Training is 68.95785876993166\n",
            "Epoch #5. Accuracy on batch 2195/2438  on Training is 68.95491803278688\n",
            "Epoch #5. Accuracy on batch 2196/2438  on Training is 68.95197997269003\n",
            "Epoch #5. Accuracy on batch 2197/2438  on Training is 68.95188808007279\n",
            "Epoch #5. Accuracy on batch 2198/2438  on Training is 68.96032287403365\n",
            "Epoch #5. Accuracy on batch 2199/2438  on Training is 68.95738636363636\n",
            "Batch Id 2200/2438 is having training loss of 1.1325078010559082\n",
            "1.2316787242889404\n",
            "Epoch #5. Accuracy on batch 2200/2438  on Training is 68.95303271240346\n",
            "Epoch #5. Accuracy on batch 2201/2438  on Training is 68.9501021798365\n",
            "Epoch #5. Accuracy on batch 2202/2438  on Training is 68.95426690876079\n",
            "Epoch #5. Accuracy on batch 2203/2438  on Training is 68.95700998185119\n",
            "Epoch #5. Accuracy on batch 2204/2438  on Training is 68.95124716553288\n",
            "Epoch #5. Accuracy on batch 2205/2438  on Training is 68.94690616500453\n",
            "Epoch #5. Accuracy on batch 2206/2438  on Training is 68.9439850475759\n",
            "Epoch #5. Accuracy on batch 2207/2438  on Training is 68.94248188405797\n",
            "Epoch #5. Accuracy on batch 2208/2438  on Training is 68.94380941602535\n",
            "Epoch #5. Accuracy on batch 2209/2438  on Training is 68.9423076923077\n",
            "Epoch #5. Accuracy on batch 2210/2438  on Training is 68.94080732700135\n",
            "Epoch #5. Accuracy on batch 2211/2438  on Training is 68.94637206148282\n",
            "Epoch #5. Accuracy on batch 2212/2438  on Training is 68.94487121554451\n",
            "Epoch #5. Accuracy on batch 2213/2438  on Training is 68.94619467028004\n",
            "Epoch #5. Accuracy on batch 2214/2438  on Training is 68.94751693002257\n",
            "Epoch #5. Accuracy on batch 2215/2438  on Training is 68.94601759927798\n",
            "Epoch #5. Accuracy on batch 2216/2438  on Training is 68.95015787099685\n",
            "Epoch #5. Accuracy on batch 2217/2438  on Training is 68.95288548241659\n",
            "Epoch #5. Accuracy on batch 2218/2438  on Training is 68.95420234339792\n",
            "Epoch #5. Accuracy on batch 2219/2438  on Training is 68.95411036036036\n",
            "Batch Id 2220/2438 is having training loss of 1.1322298049926758\n",
            "0.5882554054260254\n",
            "Epoch #5. Accuracy on batch 2220/2438  on Training is 68.96246060333183\n",
            "Epoch #5. Accuracy on batch 2221/2438  on Training is 68.96095859585958\n",
            "Epoch #5. Accuracy on batch 2222/2438  on Training is 68.9622694556905\n",
            "Epoch #5. Accuracy on batch 2223/2438  on Training is 68.96498426258992\n",
            "Epoch #5. Accuracy on batch 2224/2438  on Training is 68.97331460674157\n",
            "Epoch #5. Accuracy on batch 2225/2438  on Training is 68.97040655884996\n",
            "Epoch #5. Accuracy on batch 2226/2438  on Training is 68.96890435563539\n",
            "Epoch #5. Accuracy on batch 2227/2438  on Training is 68.96740350089766\n",
            "Epoch #5. Accuracy on batch 2228/2438  on Training is 68.9659039928219\n",
            "Epoch #5. Accuracy on batch 2229/2438  on Training is 68.97281390134529\n",
            "Epoch #5. Accuracy on batch 2230/2438  on Training is 68.97691618108472\n",
            "Epoch #5. Accuracy on batch 2231/2438  on Training is 68.9796146953405\n",
            "Epoch #5. Accuracy on batch 2232/2438  on Training is 68.97811240483654\n",
            "Epoch #5. Accuracy on batch 2233/2438  on Training is 68.98080796777082\n",
            "Epoch #5. Accuracy on batch 2234/2438  on Training is 68.98350111856823\n",
            "Epoch #5. Accuracy on batch 2235/2438  on Training is 68.98479427549195\n",
            "Epoch #5. Accuracy on batch 2236/2438  on Training is 68.98468931604828\n",
            "Epoch #5. Accuracy on batch 2237/2438  on Training is 68.98179177837355\n",
            "Epoch #5. Accuracy on batch 2238/2438  on Training is 68.97610540419831\n",
            "Epoch #5. Accuracy on batch 2239/2438  on Training is 68.974609375\n",
            "Batch Id 2240/2438 is having training loss of 1.1319373846054077\n",
            "0.6492951512336731\n",
            "Epoch #5. Accuracy on batch 2240/2438  on Training is 68.98148148148148\n",
            "Epoch #5. Accuracy on batch 2241/2438  on Training is 68.98834745762711\n",
            "Epoch #5. Accuracy on batch 2242/2438  on Training is 68.98684797146679\n",
            "Epoch #5. Accuracy on batch 2243/2438  on Training is 68.98534982174688\n",
            "Epoch #5. Accuracy on batch 2244/2438  on Training is 68.9880289532294\n",
            "Epoch #5. Accuracy on batch 2245/2438  on Training is 68.98653161175423\n",
            "Epoch #5. Accuracy on batch 2246/2438  on Training is 68.99198931909213\n",
            "Epoch #5. Accuracy on batch 2247/2438  on Training is 68.99605204626334\n",
            "Epoch #5. Accuracy on batch 2248/2438  on Training is 68.99316362827923\n",
            "Epoch #5. Accuracy on batch 2249/2438  on Training is 68.99583333333334\n",
            "Epoch #5. Accuracy on batch 2250/2438  on Training is 68.99711239449134\n",
            "Epoch #5. Accuracy on batch 2251/2438  on Training is 69.00394094138544\n",
            "Epoch #5. Accuracy on batch 2252/2438  on Training is 68.99966711051931\n",
            "Epoch #5. Accuracy on batch 2253/2438  on Training is 68.99401064773735\n",
            "Epoch #5. Accuracy on batch 2254/2438  on Training is 68.99251662971176\n",
            "Epoch #5. Accuracy on batch 2255/2438  on Training is 68.99102393617021\n",
            "Epoch #5. Accuracy on batch 2256/2438  on Training is 68.98953256535223\n",
            "Epoch #5. Accuracy on batch 2257/2438  on Training is 68.99219441984057\n",
            "Epoch #5. Accuracy on batch 2258/2438  on Training is 68.99347056219567\n",
            "Epoch #5. Accuracy on batch 2259/2438  on Training is 68.99612831858407\n",
            "Batch Id 2260/2438 is having training loss of 1.131558895111084\n",
            "1.4555847644805908\n",
            "Epoch #5. Accuracy on batch 2260/2438  on Training is 68.99187306501548\n",
            "Epoch #5. Accuracy on batch 2261/2438  on Training is 68.99452917771883\n",
            "Epoch #5. Accuracy on batch 2262/2438  on Training is 68.99442112240389\n",
            "Epoch #5. Accuracy on batch 2263/2438  on Training is 68.99569346289752\n",
            "Epoch #5. Accuracy on batch 2264/2438  on Training is 68.99972406181016\n",
            "Epoch #5. Accuracy on batch 2265/2438  on Training is 69.00375110326567\n",
            "Epoch #5. Accuracy on batch 2266/2438  on Training is 69.00501764446405\n",
            "Epoch #5. Accuracy on batch 2267/2438  on Training is 69.00214947089947\n",
            "Epoch #5. Accuracy on batch 2268/2438  on Training is 68.99515204936095\n",
            "Epoch #5. Accuracy on batch 2269/2438  on Training is 68.98953744493392\n",
            "Epoch #5. Accuracy on batch 2270/2438  on Training is 68.97979964773228\n",
            "Epoch #5. Accuracy on batch 2271/2438  on Training is 68.98107394366197\n",
            "Epoch #5. Accuracy on batch 2272/2438  on Training is 68.980972283326\n",
            "Epoch #5. Accuracy on batch 2273/2438  on Training is 68.98361917326297\n",
            "Epoch #5. Accuracy on batch 2274/2438  on Training is 68.9793956043956\n",
            "Epoch #5. Accuracy on batch 2275/2438  on Training is 68.97929481546574\n",
            "Epoch #5. Accuracy on batch 2276/2438  on Training is 68.97507685551165\n",
            "Epoch #5. Accuracy on batch 2277/2438  on Training is 68.9777216856892\n",
            "Epoch #5. Accuracy on batch 2278/2438  on Training is 68.97899297937693\n",
            "Epoch #5. Accuracy on batch 2279/2438  on Training is 68.98026315789474\n",
            "Batch Id 2280/2438 is having training loss of 1.132495403289795\n",
            "1.3984743356704712\n",
            "Epoch #5. Accuracy on batch 2280/2438  on Training is 68.98290223586146\n",
            "Epoch #5. Accuracy on batch 2281/2438  on Training is 68.98690841367221\n",
            "Epoch #5. Accuracy on batch 2282/2438  on Training is 68.98406701708278\n",
            "Epoch #5. Accuracy on batch 2283/2438  on Training is 68.98806917688266\n",
            "Epoch #5. Accuracy on batch 2284/2438  on Training is 68.99617067833698\n",
            "Epoch #5. Accuracy on batch 2285/2438  on Training is 68.99606299212599\n",
            "Epoch #5. Accuracy on batch 2286/2438  on Training is 68.9986882378662\n",
            "Epoch #5. Accuracy on batch 2287/2438  on Training is 68.99311625874125\n",
            "Epoch #5. Accuracy on batch 2288/2438  on Training is 68.99164482306684\n",
            "Epoch #5. Accuracy on batch 2289/2438  on Training is 68.99426855895196\n",
            "Epoch #5. Accuracy on batch 2290/2438  on Training is 68.99143387167176\n",
            "Epoch #5. Accuracy on batch 2291/2438  on Training is 68.99269197207678\n",
            "Epoch #5. Accuracy on batch 2292/2438  on Training is 68.99803750545138\n",
            "Epoch #5. Accuracy on batch 2293/2438  on Training is 68.99656713164778\n",
            "Epoch #5. Accuracy on batch 2294/2438  on Training is 68.99918300653594\n",
            "Epoch #5. Accuracy on batch 2295/2438  on Training is 69.00043554006969\n",
            "Epoch #5. Accuracy on batch 2296/2438  on Training is 69.00168698302133\n",
            "Epoch #5. Accuracy on batch 2297/2438  on Training is 69.00837684943428\n",
            "Epoch #5. Accuracy on batch 2298/2438  on Training is 69.00962374945628\n",
            "Epoch #5. Accuracy on batch 2299/2438  on Training is 69.01358695652173\n",
            "Batch Id 2300/2438 is having training loss of 1.1316776275634766\n",
            "1.1319630146026611\n",
            "Epoch #5. Accuracy on batch 2300/2438  on Training is 69.01075619295958\n",
            "Epoch #5. Accuracy on batch 2301/2438  on Training is 69.00928540399653\n",
            "Epoch #5. Accuracy on batch 2302/2438  on Training is 69.00645896656535\n",
            "Epoch #5. Accuracy on batch 2303/2438  on Training is 69.01041666666667\n",
            "Epoch #5. Accuracy on batch 2304/2438  on Training is 69.00623644251627\n",
            "Epoch #5. Accuracy on batch 2305/2438  on Training is 69.0074804856895\n",
            "Epoch #5. Accuracy on batch 2306/2438  on Training is 69.00465973125272\n",
            "Epoch #5. Accuracy on batch 2307/2438  on Training is 69.00454939341421\n",
            "Epoch #5. Accuracy on batch 2308/2438  on Training is 69.00714595062797\n",
            "Epoch #5. Accuracy on batch 2309/2438  on Training is 69.00974025974025\n",
            "Epoch #5. Accuracy on batch 2310/2438  on Training is 69.01233232366941\n",
            "Epoch #5. Accuracy on batch 2311/2438  on Training is 69.0135705017301\n",
            "Epoch #5. Accuracy on batch 2312/2438  on Training is 69.01210549070471\n",
            "Epoch #5. Accuracy on batch 2313/2438  on Training is 69.01334269662921\n",
            "Epoch #5. Accuracy on batch 2314/2438  on Training is 69.01187904967603\n",
            "Epoch #5. Accuracy on batch 2315/2438  on Training is 69.01311528497409\n",
            "Epoch #5. Accuracy on batch 2316/2438  on Training is 69.01839663357791\n",
            "Epoch #5. Accuracy on batch 2317/2438  on Training is 69.01558455565143\n",
            "Epoch #5. Accuracy on batch 2318/2438  on Training is 69.01412246658042\n",
            "Epoch #5. Accuracy on batch 2319/2438  on Training is 69.01670258620689\n",
            "Batch Id 2320/2438 is having training loss of 1.1317623853683472\n",
            "1.1021573543548584\n",
            "Epoch #5. Accuracy on batch 2320/2438  on Training is 69.01793408013788\n",
            "Epoch #5. Accuracy on batch 2321/2438  on Training is 69.0124354005168\n",
            "Epoch #5. Accuracy on batch 2322/2438  on Training is 69.01232242789496\n",
            "Epoch #5. Accuracy on batch 2323/2438  on Training is 69.01086488812392\n",
            "Epoch #5. Accuracy on batch 2324/2438  on Training is 69.01209677419355\n",
            "Epoch #5. Accuracy on batch 2325/2438  on Training is 69.01332760103182\n",
            "Epoch #5. Accuracy on batch 2326/2438  on Training is 69.0159003008165\n",
            "Epoch #5. Accuracy on batch 2327/2438  on Training is 69.01444372852234\n",
            "Epoch #5. Accuracy on batch 2328/2438  on Training is 69.0170137398025\n",
            "Epoch #5. Accuracy on batch 2329/2438  on Training is 69.01958154506438\n",
            "Epoch #5. Accuracy on batch 2330/2438  on Training is 69.01812526812527\n",
            "Epoch #5. Accuracy on batch 2331/2438  on Training is 69.01399013722127\n",
            "Epoch #5. Accuracy on batch 2332/2438  on Training is 69.01521645949421\n",
            "Epoch #5. Accuracy on batch 2333/2438  on Training is 69.01644173093402\n",
            "Epoch #5. Accuracy on batch 2334/2438  on Training is 69.01231263383298\n",
            "Epoch #5. Accuracy on batch 2335/2438  on Training is 69.01353809931507\n",
            "Epoch #5. Accuracy on batch 2336/2438  on Training is 69.00540222507489\n",
            "Epoch #5. Accuracy on batch 2337/2438  on Training is 69.00930282292558\n",
            "Epoch #5. Accuracy on batch 2338/2438  on Training is 69.01186404446345\n",
            "Epoch #5. Accuracy on batch 2339/2438  on Training is 69.00774572649573\n",
            "Batch Id 2340/2438 is having training loss of 1.1319303512573242\n",
            "1.062827229499817\n",
            "Epoch #5. Accuracy on batch 2340/2438  on Training is 69.00363092695429\n",
            "Epoch #5. Accuracy on batch 2341/2438  on Training is 69.00619128949616\n",
            "Epoch #5. Accuracy on batch 2342/2438  on Training is 69.00608194622279\n",
            "Epoch #5. Accuracy on batch 2343/2438  on Training is 69.00330631399318\n",
            "Epoch #5. Accuracy on batch 2344/2438  on Training is 69.00852878464819\n",
            "Epoch #5. Accuracy on batch 2345/2438  on Training is 69.01108269394715\n",
            "Epoch #5. Accuracy on batch 2346/2438  on Training is 69.00697699190457\n",
            "Epoch #5. Accuracy on batch 2347/2438  on Training is 69.01086030664395\n",
            "Epoch #5. Accuracy on batch 2348/2438  on Training is 69.01207960834398\n",
            "Epoch #5. Accuracy on batch 2349/2438  on Training is 69.0186170212766\n",
            "Epoch #5. Accuracy on batch 2350/2438  on Training is 69.0211612079966\n",
            "Epoch #5. Accuracy on batch 2351/2438  on Training is 69.015731292517\n",
            "Epoch #5. Accuracy on batch 2352/2438  on Training is 69.01694645133871\n",
            "Epoch #5. Accuracy on batch 2353/2438  on Training is 69.0194881053526\n",
            "Epoch #5. Accuracy on batch 2354/2438  on Training is 69.01804670912951\n",
            "Epoch #5. Accuracy on batch 2355/2438  on Training is 69.01660653650255\n",
            "Epoch #5. Accuracy on batch 2356/2438  on Training is 69.01649342384387\n",
            "Epoch #5. Accuracy on batch 2357/2438  on Training is 69.01638040712469\n",
            "Epoch #5. Accuracy on batch 2358/2438  on Training is 69.01626748622297\n",
            "Epoch #5. Accuracy on batch 2359/2438  on Training is 69.01483050847457\n",
            "Batch Id 2360/2438 is having training loss of 1.1314349174499512\n",
            "1.2389527559280396\n",
            "Epoch #5. Accuracy on batch 2360/2438  on Training is 69.01074756459127\n",
            "Epoch #5. Accuracy on batch 2361/2438  on Training is 69.01460626587638\n",
            "Epoch #5. Accuracy on batch 2362/2438  on Training is 69.01449428692341\n",
            "Epoch #5. Accuracy on batch 2363/2438  on Training is 69.01438240270727\n",
            "Epoch #5. Accuracy on batch 2364/2438  on Training is 69.01427061310783\n",
            "Epoch #5. Accuracy on batch 2365/2438  on Training is 69.01151732882502\n",
            "Epoch #5. Accuracy on batch 2366/2438  on Training is 69.01272708069285\n",
            "Epoch #5. Accuracy on batch 2367/2438  on Training is 69.0086570945946\n",
            "Epoch #5. Accuracy on batch 2368/2438  on Training is 69.00459054453356\n",
            "Epoch #5. Accuracy on batch 2369/2438  on Training is 69.00448312236287\n",
            "Epoch #5. Accuracy on batch 2370/2438  on Training is 69.00701180936314\n",
            "Epoch #5. Accuracy on batch 2371/2438  on Training is 69.00822091062395\n",
            "Epoch #5. Accuracy on batch 2372/2438  on Training is 69.01074589127687\n",
            "Epoch #5. Accuracy on batch 2373/2438  on Training is 69.01195240101096\n",
            "Epoch #5. Accuracy on batch 2374/2438  on Training is 69.01447368421053\n",
            "Epoch #5. Accuracy on batch 2375/2438  on Training is 69.01436237373737\n",
            "Epoch #5. Accuracy on batch 2376/2438  on Training is 69.01556583929323\n",
            "Epoch #5. Accuracy on batch 2377/2438  on Training is 69.02071068124474\n",
            "Epoch #5. Accuracy on batch 2378/2438  on Training is 69.02059688944935\n",
            "Epoch #5. Accuracy on batch 2379/2438  on Training is 69.01917016806723\n",
            "Batch Id 2380/2438 is having training loss of 1.13103449344635\n",
            "0.8307055830955505\n",
            "Epoch #5. Accuracy on batch 2380/2438  on Training is 69.02168206635868\n",
            "Epoch #5. Accuracy on batch 2381/2438  on Training is 69.02156801007557\n",
            "Epoch #5. Accuracy on batch 2382/2438  on Training is 69.0227654217373\n",
            "Epoch #5. Accuracy on batch 2383/2438  on Training is 69.02527265100672\n",
            "Epoch #5. Accuracy on batch 2384/2438  on Training is 69.02646750524109\n",
            "Epoch #5. Accuracy on batch 2385/2438  on Training is 69.01980301760268\n",
            "Epoch #5. Accuracy on batch 2386/2438  on Training is 69.01968998743192\n",
            "Epoch #5. Accuracy on batch 2387/2438  on Training is 69.02219430485762\n",
            "Epoch #5. Accuracy on batch 2388/2438  on Training is 69.02469652574298\n",
            "Epoch #5. Accuracy on batch 2389/2438  on Training is 69.02458158995816\n",
            "Epoch #5. Accuracy on batch 2390/2438  on Training is 69.02969468841489\n",
            "Epoch #5. Accuracy on batch 2391/2438  on Training is 69.02827132107024\n",
            "Epoch #5. Accuracy on batch 2392/2438  on Training is 69.02815503552027\n",
            "Epoch #5. Accuracy on batch 2393/2438  on Training is 69.03064954051796\n",
            "Epoch #5. Accuracy on batch 2394/2438  on Training is 69.03183716075156\n",
            "Epoch #5. Accuracy on batch 2395/2438  on Training is 69.03563230383973\n",
            "Epoch #5. Accuracy on batch 2396/2438  on Training is 69.03420942845223\n",
            "Epoch #5. Accuracy on batch 2397/2438  on Training is 69.03930358632194\n",
            "Epoch #5. Accuracy on batch 2398/2438  on Training is 69.03918299291371\n",
            "Epoch #5. Accuracy on batch 2399/2438  on Training is 69.04296875\n",
            "Batch Id 2400/2438 is having training loss of 1.13068425655365\n",
            "1.3110204935073853\n",
            "Epoch #5. Accuracy on batch 2400/2438  on Training is 69.04414827155352\n",
            "Epoch #5. Accuracy on batch 2401/2438  on Training is 69.04142381348876\n",
            "Epoch #5. Accuracy on batch 2402/2438  on Training is 69.03870162297129\n",
            "Epoch #5. Accuracy on batch 2403/2438  on Training is 69.03988144758735\n",
            "Epoch #5. Accuracy on batch 2404/2438  on Training is 69.04625779625779\n",
            "Epoch #5. Accuracy on batch 2405/2438  on Training is 69.0435369908562\n",
            "Epoch #5. Accuracy on batch 2406/2438  on Training is 69.03822185292896\n",
            "Epoch #5. Accuracy on batch 2407/2438  on Training is 69.03939991694352\n",
            "Epoch #5. Accuracy on batch 2408/2438  on Training is 69.04317144043172\n",
            "Epoch #5. Accuracy on batch 2409/2438  on Training is 69.05082987551867\n",
            "Epoch #5. Accuracy on batch 2410/2438  on Training is 69.05459352965575\n",
            "Epoch #5. Accuracy on batch 2411/2438  on Training is 69.05317164179104\n",
            "Epoch #5. Accuracy on batch 2412/2438  on Training is 69.04916079569001\n",
            "Epoch #5. Accuracy on batch 2413/2438  on Training is 69.04903686826843\n",
            "Epoch #5. Accuracy on batch 2414/2438  on Training is 69.04891304347827\n",
            "Epoch #5. Accuracy on batch 2415/2438  on Training is 69.05266970198676\n",
            "Epoch #5. Accuracy on batch 2416/2438  on Training is 69.05513032685147\n",
            "Epoch #5. Accuracy on batch 2417/2438  on Training is 69.053711745244\n",
            "Epoch #5. Accuracy on batch 2418/2438  on Training is 69.0548780487805\n",
            "Epoch #5. Accuracy on batch 2419/2438  on Training is 69.04829545454545\n",
            "Batch Id 2420/2438 is having training loss of 1.1300997734069824\n",
            "1.238234281539917\n",
            "Epoch #5. Accuracy on batch 2420/2438  on Training is 69.04559066501446\n",
            "Epoch #5. Accuracy on batch 2421/2438  on Training is 69.03772708505367\n",
            "Epoch #5. Accuracy on batch 2422/2438  on Training is 69.04147750722245\n",
            "Epoch #5. Accuracy on batch 2423/2438  on Training is 69.04264645214522\n",
            "Epoch #5. Accuracy on batch 2424/2438  on Training is 69.03994845360825\n",
            "Epoch #5. Accuracy on batch 2425/2438  on Training is 69.03854080791426\n",
            "Epoch #5. Accuracy on batch 2426/2438  on Training is 69.03584672435105\n",
            "Epoch #5. Accuracy on batch 2427/2438  on Training is 69.03186779242175\n",
            "Epoch #5. Accuracy on batch 2428/2438  on Training is 69.03432482503088\n",
            "Epoch #5. Accuracy on batch 2429/2438  on Training is 69.02777777777777\n",
            "Epoch #5. Accuracy on batch 2430/2438  on Training is 69.03023447141094\n",
            "Epoch #5. Accuracy on batch 2431/2438  on Training is 69.03525904605263\n",
            "Epoch #5. Accuracy on batch 2432/2438  on Training is 69.03899506781751\n",
            "Epoch #5. Accuracy on batch 2433/2438  on Training is 69.04144412489728\n",
            "Epoch #5. Accuracy on batch 2434/2438  on Training is 69.04517453798768\n",
            "Epoch #5. Accuracy on batch 2435/2438  on Training is 69.03992200328408\n",
            "Epoch #5. Accuracy on batch 2436/2438  on Training is 69.03852072219942\n",
            "Epoch #5. Accuracy on batch 2437/2438  on Training is 69.0397435897436\n",
            "Epoch #5. Batch Id 0/278  is having validation loss of 1.2308237552642822\n",
            "1.2308237552642822\n",
            "Epoch #5. Batch Id 0/278  is having validation accuracy of 56.25\n",
            "Epoch #5. Batch Id 1/278  is having validation loss of 1.2111420631408691\n",
            "1.1914602518081665\n",
            "Epoch #5. Batch Id 1/278  is having validation accuracy of 60.9375\n",
            "Epoch #5. Batch Id 2/278  is having validation loss of 1.1975587606430054\n",
            "1.1703922748565674\n",
            "Epoch #5. Batch Id 2/278  is having validation accuracy of 61.458333333333336\n",
            "Epoch #5. Batch Id 3/278  is having validation loss of 1.0910364389419556\n",
            "0.7714695930480957\n",
            "Epoch #5. Batch Id 3/278  is having validation accuracy of 67.1875\n",
            "Epoch #5. Batch Id 4/278  is having validation loss of 1.285349726676941\n",
            "2.0626027584075928\n",
            "Epoch #5. Batch Id 4/278  is having validation accuracy of 63.75\n",
            "Epoch #5. Batch Id 5/278  is having validation loss of 1.3221547603607178\n",
            "1.506179928779602\n",
            "Epoch #5. Batch Id 5/278  is having validation accuracy of 63.020833333333336\n",
            "Epoch #5. Batch Id 6/278  is having validation loss of 1.3629924058914185\n",
            "1.6080185174942017\n",
            "Epoch #5. Batch Id 6/278  is having validation accuracy of 62.94642857142857\n",
            "Epoch #5. Batch Id 7/278  is having validation loss of 1.3683744668960571\n",
            "1.406049132347107\n",
            "Epoch #5. Batch Id 7/278  is having validation accuracy of 60.9375\n",
            "Epoch #5. Batch Id 8/278  is having validation loss of 1.3699650764465332\n",
            "1.382690191268921\n",
            "Epoch #5. Batch Id 8/278  is having validation accuracy of 60.416666666666664\n",
            "Epoch #5. Batch Id 9/278  is having validation loss of 1.3201754093170166\n",
            "0.872067928314209\n",
            "Epoch #5. Batch Id 9/278  is having validation accuracy of 60.625\n",
            "Epoch #5. Batch Id 10/278  is having validation loss of 1.3124148845672607\n",
            "1.2348095178604126\n",
            "Epoch #5. Batch Id 10/278  is having validation accuracy of 60.51136363636363\n",
            "Epoch #5. Batch Id 11/278  is having validation loss of 1.3093181848526\n",
            "1.2752548456192017\n",
            "Epoch #5. Batch Id 11/278  is having validation accuracy of 61.197916666666664\n",
            "Epoch #5. Batch Id 12/278  is having validation loss of 1.3201370239257812\n",
            "1.4499623775482178\n",
            "Epoch #5. Batch Id 12/278  is having validation accuracy of 61.77884615384615\n",
            "Epoch #5. Batch Id 13/278  is having validation loss of 1.332271695137024\n",
            "1.490023136138916\n",
            "Epoch #5. Batch Id 13/278  is having validation accuracy of 61.607142857142854\n",
            "Epoch #5. Batch Id 14/278  is having validation loss of 1.3217799663543701\n",
            "1.1748955249786377\n",
            "Epoch #5. Batch Id 14/278  is having validation accuracy of 62.083333333333336\n",
            "Epoch #5. Batch Id 15/278  is having validation loss of 1.3164020776748657\n",
            "1.2357332706451416\n",
            "Epoch #5. Batch Id 15/278  is having validation accuracy of 62.5\n",
            "Epoch #5. Batch Id 16/278  is having validation loss of 1.3282079696655273\n",
            "1.5171020030975342\n",
            "Epoch #5. Batch Id 16/278  is having validation accuracy of 62.13235294117647\n",
            "Epoch #5. Batch Id 17/278  is having validation loss of 1.3426138162612915\n",
            "1.5875139236450195\n",
            "Epoch #5. Batch Id 17/278  is having validation accuracy of 61.28472222222222\n",
            "Epoch #5. Batch Id 18/278  is having validation loss of 1.346182107925415\n",
            "1.4104114770889282\n",
            "Epoch #5. Batch Id 18/278  is having validation accuracy of 61.01973684210526\n",
            "Epoch #5. Batch Id 19/278  is having validation loss of 1.347872018814087\n",
            "1.3799808025360107\n",
            "Epoch #5. Batch Id 19/278  is having validation accuracy of 61.25\n",
            "Epoch #5. Batch Id 20/278  is having validation loss of 1.338904857635498\n",
            "1.1595628261566162\n",
            "Epoch #5. Batch Id 20/278  is having validation accuracy of 61.458333333333336\n",
            "Epoch #5. Batch Id 21/278  is having validation loss of 1.3388251066207886\n",
            "1.337149739265442\n",
            "Epoch #5. Batch Id 21/278  is having validation accuracy of 61.93181818181818\n",
            "Epoch #5. Batch Id 22/278  is having validation loss of 1.3040560483932495\n",
            "0.5391365885734558\n",
            "Epoch #5. Batch Id 22/278  is having validation accuracy of 63.04347826086956\n",
            "Epoch #5. Batch Id 23/278  is having validation loss of 1.3189054727554321\n",
            "1.6604423522949219\n",
            "Epoch #5. Batch Id 23/278  is having validation accuracy of 62.890625\n",
            "Epoch #5. Batch Id 24/278  is having validation loss of 1.305181622505188\n",
            "0.9758086204528809\n",
            "Epoch #5. Batch Id 24/278  is having validation accuracy of 63.0\n",
            "Epoch #5. Batch Id 25/278  is having validation loss of 1.305487036705017\n",
            "1.3131232261657715\n",
            "Epoch #5. Batch Id 25/278  is having validation accuracy of 62.86057692307692\n",
            "Epoch #5. Batch Id 26/278  is having validation loss of 1.3275203704833984\n",
            "1.9003875255584717\n",
            "Epoch #5. Batch Id 26/278  is having validation accuracy of 62.26851851851852\n",
            "Epoch #5. Batch Id 27/278  is having validation loss of 1.3313218355178833\n",
            "1.4339622259140015\n",
            "Epoch #5. Batch Id 27/278  is having validation accuracy of 62.276785714285715\n",
            "Epoch #5. Batch Id 28/278  is having validation loss of 1.3528311252593994\n",
            "1.9550925493240356\n",
            "Epoch #5. Batch Id 28/278  is having validation accuracy of 61.85344827586207\n",
            "Epoch #5. Batch Id 29/278  is having validation loss of 1.3456834554672241\n",
            "1.1384004354476929\n",
            "Epoch #5. Batch Id 29/278  is having validation accuracy of 61.979166666666664\n",
            "Epoch #5. Batch Id 30/278  is having validation loss of 1.3342387676239014\n",
            "0.9908975958824158\n",
            "Epoch #5. Batch Id 30/278  is having validation accuracy of 62.600806451612904\n",
            "Epoch #5. Batch Id 31/278  is having validation loss of 1.3324530124664307\n",
            "1.2770943641662598\n",
            "Epoch #5. Batch Id 31/278  is having validation accuracy of 62.59765625\n",
            "Epoch #5. Batch Id 32/278  is having validation loss of 1.3383179903030396\n",
            "1.5259990692138672\n",
            "Epoch #5. Batch Id 32/278  is having validation accuracy of 62.5\n",
            "Epoch #5. Batch Id 33/278  is having validation loss of 1.3343199491500854\n",
            "1.202385425567627\n",
            "Epoch #5. Batch Id 33/278  is having validation accuracy of 62.68382352941177\n",
            "Epoch #5. Batch Id 34/278  is having validation loss of 1.3454532623291016\n",
            "1.7239850759506226\n",
            "Epoch #5. Batch Id 34/278  is having validation accuracy of 62.232142857142854\n",
            "Epoch #5. Batch Id 35/278  is having validation loss of 1.3417335748672485\n",
            "1.2115437984466553\n",
            "Epoch #5. Batch Id 35/278  is having validation accuracy of 62.326388888888886\n",
            "Epoch #5. Batch Id 36/278  is having validation loss of 1.3386573791503906\n",
            "1.227915644645691\n",
            "Epoch #5. Batch Id 36/278  is having validation accuracy of 62.41554054054054\n",
            "Epoch #5. Batch Id 37/278  is having validation loss of 1.3345404863357544\n",
            "1.1822134256362915\n",
            "Epoch #5. Batch Id 37/278  is having validation accuracy of 62.5\n",
            "Epoch #5. Batch Id 38/278  is having validation loss of 1.3356199264526367\n",
            "1.3766393661499023\n",
            "Epoch #5. Batch Id 38/278  is having validation accuracy of 62.33974358974359\n",
            "Epoch #5. Batch Id 39/278  is having validation loss of 1.3304013013839722\n",
            "1.126874327659607\n",
            "Epoch #5. Batch Id 39/278  is having validation accuracy of 62.5\n",
            "Epoch #5. Batch Id 40/278  is having validation loss of 1.3339025974273682\n",
            "1.4739550352096558\n",
            "Epoch #5. Batch Id 40/278  is having validation accuracy of 62.576219512195124\n",
            "Epoch #5. Batch Id 41/278  is having validation loss of 1.335559368133545\n",
            "1.4034873247146606\n",
            "Epoch #5. Batch Id 41/278  is having validation accuracy of 62.57440476190476\n",
            "Epoch #5. Batch Id 42/278  is having validation loss of 1.3241639137268066\n",
            "0.8455549478530884\n",
            "Epoch #5. Batch Id 42/278  is having validation accuracy of 63.08139534883721\n",
            "Epoch #5. Batch Id 43/278  is having validation loss of 1.3219562768936157\n",
            "1.2270257472991943\n",
            "Epoch #5. Batch Id 43/278  is having validation accuracy of 63.06818181818182\n",
            "Epoch #5. Batch Id 44/278  is having validation loss of 1.3205361366271973\n",
            "1.2580479383468628\n",
            "Epoch #5. Batch Id 44/278  is having validation accuracy of 63.263888888888886\n",
            "Epoch #5. Batch Id 45/278  is having validation loss of 1.3220690488815308\n",
            "1.3910505771636963\n",
            "Epoch #5. Batch Id 45/278  is having validation accuracy of 63.17934782608695\n",
            "Epoch #5. Batch Id 46/278  is having validation loss of 1.3103615045547485\n",
            "0.7718124985694885\n",
            "Epoch #5. Batch Id 46/278  is having validation accuracy of 63.49734042553192\n",
            "Epoch #5. Batch Id 47/278  is having validation loss of 1.3084343671798706\n",
            "1.2178572416305542\n",
            "Epoch #5. Batch Id 47/278  is having validation accuracy of 63.736979166666664\n",
            "Epoch #5. Batch Id 48/278  is having validation loss of 1.3052622079849243\n",
            "1.1529990434646606\n",
            "Epoch #5. Batch Id 48/278  is having validation accuracy of 63.9030612244898\n",
            "Epoch #5. Batch Id 49/278  is having validation loss of 1.3070504665374756\n",
            "1.394676685333252\n",
            "Epoch #5. Batch Id 49/278  is having validation accuracy of 64.0625\n",
            "Epoch #5. Batch Id 50/278  is having validation loss of 1.3015680313110352\n",
            "1.027443528175354\n",
            "Epoch #5. Batch Id 50/278  is having validation accuracy of 64.09313725490196\n",
            "Epoch #5. Batch Id 51/278  is having validation loss of 1.2965466976165771\n",
            "1.0404576063156128\n",
            "Epoch #5. Batch Id 51/278  is having validation accuracy of 64.1826923076923\n",
            "Epoch #5. Batch Id 52/278  is having validation loss of 1.2951304912567139\n",
            "1.2214864492416382\n",
            "Epoch #5. Batch Id 52/278  is having validation accuracy of 64.20990566037736\n",
            "Epoch #5. Batch Id 53/278  is having validation loss of 1.2972116470336914\n",
            "1.4075130224227905\n",
            "Epoch #5. Batch Id 53/278  is having validation accuracy of 64.12037037037037\n",
            "Epoch #5. Batch Id 54/278  is having validation loss of 1.2937711477279663\n",
            "1.1079814434051514\n",
            "Epoch #5. Batch Id 54/278  is having validation accuracy of 64.20454545454545\n",
            "Epoch #5. Batch Id 55/278  is having validation loss of 1.293687105178833\n",
            "1.2890650033950806\n",
            "Epoch #5. Batch Id 55/278  is having validation accuracy of 64.17410714285714\n",
            "Epoch #5. Batch Id 56/278  is having validation loss of 1.2963950634002686\n",
            "1.4480403661727905\n",
            "Epoch #5. Batch Id 56/278  is having validation accuracy of 64.03508771929825\n",
            "Epoch #5. Batch Id 57/278  is having validation loss of 1.2930364608764648\n",
            "1.1015976667404175\n",
            "Epoch #5. Batch Id 57/278  is having validation accuracy of 64.17025862068965\n",
            "Epoch #5. Batch Id 58/278  is having validation loss of 1.2919349670410156\n",
            "1.2280465364456177\n",
            "Epoch #5. Batch Id 58/278  is having validation accuracy of 64.19491525423729\n",
            "Epoch #5. Batch Id 59/278  is having validation loss of 1.2896255254745483\n",
            "1.1533663272857666\n",
            "Epoch #5. Batch Id 59/278  is having validation accuracy of 64.32291666666667\n",
            "Epoch #5. Batch Id 60/278  is having validation loss of 1.284563422203064\n",
            "0.9808404445648193\n",
            "Epoch #5. Batch Id 60/278  is having validation accuracy of 64.39549180327869\n",
            "Epoch #5. Batch Id 61/278  is having validation loss of 1.2867588996887207\n",
            "1.4206801652908325\n",
            "Epoch #5. Batch Id 61/278  is having validation accuracy of 64.41532258064517\n",
            "Epoch #5. Batch Id 62/278  is having validation loss of 1.2794841527938843\n",
            "0.8284528255462646\n",
            "Epoch #5. Batch Id 62/278  is having validation accuracy of 64.6329365079365\n",
            "Epoch #5. Batch Id 63/278  is having validation loss of 1.2837687730789185\n",
            "1.5536978244781494\n",
            "Epoch #5. Batch Id 63/278  is having validation accuracy of 64.55078125\n",
            "Epoch #5. Batch Id 64/278  is having validation loss of 1.2906111478805542\n",
            "1.7285233736038208\n",
            "Epoch #5. Batch Id 64/278  is having validation accuracy of 64.32692307692308\n",
            "Epoch #5. Batch Id 65/278  is having validation loss of 1.286436915397644\n",
            "1.0151139497756958\n",
            "Epoch #5. Batch Id 65/278  is having validation accuracy of 64.53598484848484\n",
            "Epoch #5. Batch Id 66/278  is having validation loss of 1.2868461608886719\n",
            "1.3138582706451416\n",
            "Epoch #5. Batch Id 66/278  is having validation accuracy of 64.59888059701493\n",
            "Epoch #5. Batch Id 67/278  is having validation loss of 1.2928688526153564\n",
            "1.6963860988616943\n",
            "Epoch #5. Batch Id 67/278  is having validation accuracy of 64.43014705882354\n",
            "Epoch #5. Batch Id 68/278  is having validation loss of 1.2872416973114014\n",
            "0.9045975208282471\n",
            "Epoch #5. Batch Id 68/278  is having validation accuracy of 64.58333333333333\n",
            "Epoch #5. Batch Id 69/278  is having validation loss of 1.28555166721344\n",
            "1.1689387559890747\n",
            "Epoch #5. Batch Id 69/278  is having validation accuracy of 64.6875\n",
            "Epoch #5. Batch Id 70/278  is having validation loss of 1.291388750076294\n",
            "1.6999861001968384\n",
            "Epoch #5. Batch Id 70/278  is having validation accuracy of 64.43661971830986\n",
            "Epoch #5. Batch Id 71/278  is having validation loss of 1.2861381769180298\n",
            "0.9133480191230774\n",
            "Epoch #5. Batch Id 71/278  is having validation accuracy of 64.49652777777777\n",
            "Epoch #5. Batch Id 72/278  is having validation loss of 1.2918336391448975\n",
            "1.7019057273864746\n",
            "Epoch #5. Batch Id 72/278  is having validation accuracy of 64.25513698630137\n",
            "Epoch #5. Batch Id 73/278  is having validation loss of 1.2934616804122925\n",
            "1.4123051166534424\n",
            "Epoch #5. Batch Id 73/278  is having validation accuracy of 64.23141891891892\n",
            "Epoch #5. Batch Id 74/278  is having validation loss of 1.3003230094909668\n",
            "1.8080633878707886\n",
            "Epoch #5. Batch Id 74/278  is having validation accuracy of 64.08333333333333\n",
            "Epoch #5. Batch Id 75/278  is having validation loss of 1.299351453781128\n",
            "1.2264885902404785\n",
            "Epoch #5. Batch Id 75/278  is having validation accuracy of 64.14473684210526\n",
            "Epoch #5. Batch Id 76/278  is having validation loss of 1.2991702556610107\n",
            "1.2854018211364746\n",
            "Epoch #5. Batch Id 76/278  is having validation accuracy of 64.16396103896103\n",
            "Epoch #5. Batch Id 77/278  is having validation loss of 1.2956689596176147\n",
            "1.0260651111602783\n",
            "Epoch #5. Batch Id 77/278  is having validation accuracy of 64.30288461538461\n",
            "Epoch #5. Batch Id 78/278  is having validation loss of 1.2929136753082275\n",
            "1.0780048370361328\n",
            "Epoch #5. Batch Id 78/278  is having validation accuracy of 64.35917721518987\n",
            "Epoch #5. Batch Id 79/278  is having validation loss of 1.290643334388733\n",
            "1.11128568649292\n",
            "Epoch #5. Batch Id 79/278  is having validation accuracy of 64.3359375\n",
            "Epoch #5. Batch Id 80/278  is having validation loss of 1.2993072271347046\n",
            "1.9924143552780151\n",
            "Epoch #5. Batch Id 80/278  is having validation accuracy of 64.19753086419753\n",
            "Epoch #5. Batch Id 81/278  is having validation loss of 1.300660490989685\n",
            "1.4102766513824463\n",
            "Epoch #5. Batch Id 81/278  is having validation accuracy of 64.13871951219512\n",
            "Epoch #5. Batch Id 82/278  is having validation loss of 1.3034723997116089\n",
            "1.534045934677124\n",
            "Epoch #5. Batch Id 82/278  is having validation accuracy of 64.1566265060241\n",
            "Epoch #5. Batch Id 83/278  is having validation loss of 1.30281400680542\n",
            "1.248165249824524\n",
            "Epoch #5. Batch Id 83/278  is having validation accuracy of 64.17410714285714\n",
            "Epoch #5. Batch Id 84/278  is having validation loss of 1.3009434938430786\n",
            "1.143817663192749\n",
            "Epoch #5. Batch Id 84/278  is having validation accuracy of 64.15441176470588\n",
            "Epoch #5. Batch Id 85/278  is having validation loss of 1.2971681356430054\n",
            "0.9762611985206604\n",
            "Epoch #5. Batch Id 85/278  is having validation accuracy of 64.35319767441861\n",
            "Epoch #5. Batch Id 86/278  is having validation loss of 1.302638053894043\n",
            "1.7730461359024048\n",
            "Epoch #5. Batch Id 86/278  is having validation accuracy of 64.1882183908046\n",
            "Epoch #5. Batch Id 87/278  is having validation loss of 1.3007699251174927\n",
            "1.1382478475570679\n",
            "Epoch #5. Batch Id 87/278  is having validation accuracy of 64.1690340909091\n",
            "Epoch #5. Batch Id 88/278  is having validation loss of 1.3029247522354126\n",
            "1.4925475120544434\n",
            "Epoch #5. Batch Id 88/278  is having validation accuracy of 64.11516853932584\n",
            "Epoch #5. Batch Id 89/278  is having validation loss of 1.298857569694519\n",
            "0.936876654624939\n",
            "Epoch #5. Batch Id 89/278  is having validation accuracy of 64.20138888888889\n",
            "Epoch #5. Batch Id 90/278  is having validation loss of 1.2927021980285645\n",
            "0.7387185096740723\n",
            "Epoch #5. Batch Id 90/278  is having validation accuracy of 64.32005494505495\n",
            "Epoch #5. Batch Id 91/278  is having validation loss of 1.2917219400405884\n",
            "1.2025130987167358\n",
            "Epoch #5. Batch Id 91/278  is having validation accuracy of 64.43614130434783\n",
            "Epoch #5. Batch Id 92/278  is having validation loss of 1.2921243906021118\n",
            "1.3291457891464233\n",
            "Epoch #5. Batch Id 92/278  is having validation accuracy of 64.41532258064517\n",
            "Epoch #5. Batch Id 93/278  is having validation loss of 1.2895458936691284\n",
            "1.0497443675994873\n",
            "Epoch #5. Batch Id 93/278  is having validation accuracy of 64.49468085106383\n",
            "Epoch #5. Batch Id 94/278  is having validation loss of 1.2874795198440552\n",
            "1.093239188194275\n",
            "Epoch #5. Batch Id 94/278  is having validation accuracy of 64.47368421052632\n",
            "Epoch #5. Batch Id 95/278  is having validation loss of 1.2864514589309692\n",
            "1.188791275024414\n",
            "Epoch #5. Batch Id 95/278  is having validation accuracy of 64.55078125\n",
            "Epoch #5. Batch Id 96/278  is having validation loss of 1.2892788648605347\n",
            "1.5607045888900757\n",
            "Epoch #5. Batch Id 96/278  is having validation accuracy of 64.49742268041237\n",
            "Epoch #5. Batch Id 97/278  is having validation loss of 1.2879548072814941\n",
            "1.1595163345336914\n",
            "Epoch #5. Batch Id 97/278  is having validation accuracy of 64.50892857142857\n",
            "Epoch #5. Batch Id 98/278  is having validation loss of 1.289856195449829\n",
            "1.4761961698532104\n",
            "Epoch #5. Batch Id 98/278  is having validation accuracy of 64.52020202020202\n",
            "Epoch #5. Batch Id 99/278  is having validation loss of 1.2877895832061768\n",
            "1.083191990852356\n",
            "Epoch #5. Batch Id 99/278  is having validation accuracy of 64.53125\n",
            "Epoch #5. Batch Id 100/278  is having validation loss of 1.2898948192596436\n",
            "1.500413179397583\n",
            "Epoch #5. Batch Id 100/278  is having validation accuracy of 64.44925742574257\n",
            "Epoch #5. Batch Id 101/278  is having validation loss of 1.2887893915176392\n",
            "1.1771420240402222\n",
            "Epoch #5. Batch Id 101/278  is having validation accuracy of 64.43014705882354\n",
            "Epoch #5. Batch Id 102/278  is having validation loss of 1.2854211330413818\n",
            "0.9418621063232422\n",
            "Epoch #5. Batch Id 102/278  is having validation accuracy of 64.59344660194175\n",
            "Epoch #5. Batch Id 103/278  is having validation loss of 1.289591670036316\n",
            "1.7191587686538696\n",
            "Epoch #5. Batch Id 103/278  is having validation accuracy of 64.453125\n",
            "Epoch #5. Batch Id 104/278  is having validation loss of 1.2886853218078613\n",
            "1.1944204568862915\n",
            "Epoch #5. Batch Id 104/278  is having validation accuracy of 64.4047619047619\n",
            "Epoch #5. Batch Id 105/278  is having validation loss of 1.2872350215911865\n",
            "1.1349583864212036\n",
            "Epoch #5. Batch Id 105/278  is having validation accuracy of 64.41627358490567\n",
            "Epoch #5. Batch Id 106/278  is having validation loss of 1.284119963645935\n",
            "0.9539238810539246\n",
            "Epoch #5. Batch Id 106/278  is having validation accuracy of 64.51518691588785\n",
            "Epoch #5. Batch Id 107/278  is having validation loss of 1.2806313037872314\n",
            "0.9073501825332642\n",
            "Epoch #5. Batch Id 107/278  is having validation accuracy of 64.61226851851852\n",
            "Epoch #5. Batch Id 108/278  is having validation loss of 1.2824465036392212\n",
            "1.478490948677063\n",
            "Epoch #5. Batch Id 108/278  is having validation accuracy of 64.53555045871559\n",
            "Epoch #5. Batch Id 109/278  is having validation loss of 1.2816106081008911\n",
            "1.1904964447021484\n",
            "Epoch #5. Batch Id 109/278  is having validation accuracy of 64.48863636363636\n",
            "Epoch #5. Batch Id 110/278  is having validation loss of 1.2777374982833862\n",
            "0.8516941070556641\n",
            "Epoch #5. Batch Id 110/278  is having validation accuracy of 64.52702702702703\n",
            "Epoch #5. Batch Id 111/278  is having validation loss of 1.2752113342285156\n",
            "0.9948097467422485\n",
            "Epoch #5. Batch Id 111/278  is having validation accuracy of 64.62053571428571\n",
            "Epoch #5. Batch Id 112/278  is having validation loss of 1.277807354927063\n",
            "1.5685557126998901\n",
            "Epoch #5. Batch Id 112/278  is having validation accuracy of 64.49115044247787\n",
            "Epoch #5. Batch Id 113/278  is having validation loss of 1.2782498598098755\n",
            "1.3282568454742432\n",
            "Epoch #5. Batch Id 113/278  is having validation accuracy of 64.41885964912281\n",
            "Epoch #5. Batch Id 114/278  is having validation loss of 1.2823153734207153\n",
            "1.7457890510559082\n",
            "Epoch #5. Batch Id 114/278  is having validation accuracy of 64.2663043478261\n",
            "Epoch #5. Batch Id 115/278  is having validation loss of 1.285797119140625\n",
            "1.6861940622329712\n",
            "Epoch #5. Batch Id 115/278  is having validation accuracy of 64.22413793103448\n",
            "Epoch #5. Batch Id 116/278  is having validation loss of 1.2897648811340332\n",
            "1.7500232458114624\n",
            "Epoch #5. Batch Id 116/278  is having validation accuracy of 64.2094017094017\n",
            "Epoch #5. Batch Id 117/278  is having validation loss of 1.2923558950424194\n",
            "1.5955066680908203\n",
            "Epoch #5. Batch Id 117/278  is having validation accuracy of 64.22139830508475\n",
            "Epoch #5. Batch Id 118/278  is having validation loss of 1.2903034687042236\n",
            "1.0481157302856445\n",
            "Epoch #5. Batch Id 118/278  is having validation accuracy of 64.28571428571429\n",
            "Epoch #5. Batch Id 119/278  is having validation loss of 1.2902295589447021\n",
            "1.2814382314682007\n",
            "Epoch #5. Batch Id 119/278  is having validation accuracy of 64.27083333333333\n",
            "Epoch #5. Batch Id 120/278  is having validation loss of 1.2890881299972534\n",
            "1.1521167755126953\n",
            "Epoch #5. Batch Id 120/278  is having validation accuracy of 64.30785123966942\n",
            "Epoch #5. Batch Id 121/278  is having validation loss of 1.2918715476989746\n",
            "1.6286659240722656\n",
            "Epoch #5. Batch Id 121/278  is having validation accuracy of 64.21618852459017\n",
            "Epoch #5. Batch Id 122/278  is having validation loss of 1.2950741052627563\n",
            "1.6857845783233643\n",
            "Epoch #5. Batch Id 122/278  is having validation accuracy of 64.10060975609755\n",
            "Epoch #5. Batch Id 123/278  is having validation loss of 1.2988675832748413\n",
            "1.765468716621399\n",
            "Epoch #5. Batch Id 123/278  is having validation accuracy of 63.98689516129032\n",
            "Epoch #5. Batch Id 124/278  is having validation loss of 1.297546625137329\n",
            "1.1337518692016602\n",
            "Epoch #5. Batch Id 124/278  is having validation accuracy of 64.025\n",
            "Epoch #5. Batch Id 125/278  is having validation loss of 1.2955900430679321\n",
            "1.051023244857788\n",
            "Epoch #5. Batch Id 125/278  is having validation accuracy of 64.11210317460318\n",
            "Epoch #5. Batch Id 126/278  is having validation loss of 1.2937324047088623\n",
            "1.0596634149551392\n",
            "Epoch #5. Batch Id 126/278  is having validation accuracy of 64.14862204724409\n",
            "Epoch #5. Batch Id 127/278  is having validation loss of 1.2945667505264282\n",
            "1.400529384613037\n",
            "Epoch #5. Batch Id 127/278  is having validation accuracy of 64.111328125\n",
            "Epoch #5. Batch Id 128/278  is having validation loss of 1.292097806930542\n",
            "0.9760662317276001\n",
            "Epoch #5. Batch Id 128/278  is having validation accuracy of 64.14728682170542\n",
            "Epoch #5. Batch Id 129/278  is having validation loss of 1.2917556762695312\n",
            "1.2476141452789307\n",
            "Epoch #5. Batch Id 129/278  is having validation accuracy of 64.15865384615384\n",
            "Epoch #5. Batch Id 130/278  is having validation loss of 1.286119818687439\n",
            "0.5534511804580688\n",
            "Epoch #5. Batch Id 130/278  is having validation accuracy of 64.3368320610687\n",
            "Epoch #5. Batch Id 131/278  is having validation loss of 1.2877813577651978\n",
            "1.5054469108581543\n",
            "Epoch #5. Batch Id 131/278  is having validation accuracy of 64.32291666666667\n",
            "Epoch #5. Batch Id 132/278  is having validation loss of 1.2882169485092163\n",
            "1.3457170724868774\n",
            "Epoch #5. Batch Id 132/278  is having validation accuracy of 64.3562030075188\n",
            "Epoch #5. Batch Id 133/278  is having validation loss of 1.290615439414978\n",
            "1.609614610671997\n",
            "Epoch #5. Batch Id 133/278  is having validation accuracy of 64.31902985074628\n",
            "Epoch #5. Batch Id 134/278  is having validation loss of 1.295929193496704\n",
            "2.007967710494995\n",
            "Epoch #5. Batch Id 134/278  is having validation accuracy of 64.25925925925925\n",
            "Epoch #5. Batch Id 135/278  is having validation loss of 1.2970609664916992\n",
            "1.4498474597930908\n",
            "Epoch #5. Batch Id 135/278  is having validation accuracy of 64.17738970588235\n",
            "Epoch #5. Batch Id 136/278  is having validation loss of 1.297055959701538\n",
            "1.2963800430297852\n",
            "Epoch #5. Batch Id 136/278  is having validation accuracy of 64.21076642335767\n",
            "Epoch #5. Batch Id 137/278  is having validation loss of 1.2986055612564087\n",
            "1.510898232460022\n",
            "Epoch #5. Batch Id 137/278  is having validation accuracy of 64.1304347826087\n",
            "Epoch #5. Batch Id 138/278  is having validation loss of 1.2948668003082275\n",
            "0.7789250016212463\n",
            "Epoch #5. Batch Id 138/278  is having validation accuracy of 64.18615107913669\n",
            "Epoch #5. Batch Id 139/278  is having validation loss of 1.2941805124282837\n",
            "1.1987924575805664\n",
            "Epoch #5. Batch Id 139/278  is having validation accuracy of 64.19642857142857\n",
            "Epoch #5. Batch Id 140/278  is having validation loss of 1.2946135997772217\n",
            "1.3552517890930176\n",
            "Epoch #5. Batch Id 140/278  is having validation accuracy of 64.11790780141844\n",
            "Epoch #5. Batch Id 141/278  is having validation loss of 1.2931777238845825\n",
            "1.090725302696228\n",
            "Epoch #5. Batch Id 141/278  is having validation accuracy of 64.12852112676056\n",
            "Epoch #5. Batch Id 142/278  is having validation loss of 1.2913222312927246\n",
            "1.0278464555740356\n",
            "Epoch #5. Batch Id 142/278  is having validation accuracy of 64.13898601398601\n",
            "Epoch #5. Batch Id 143/278  is having validation loss of 1.294636845588684\n",
            "1.7686216831207275\n",
            "Epoch #5. Batch Id 143/278  is having validation accuracy of 64.10590277777777\n",
            "Epoch #5. Batch Id 144/278  is having validation loss of 1.2972487211227417\n",
            "1.673364520072937\n",
            "Epoch #5. Batch Id 144/278  is having validation accuracy of 64.07327586206897\n",
            "Epoch #5. Batch Id 145/278  is having validation loss of 1.2994755506515503\n",
            "1.62236487865448\n",
            "Epoch #5. Batch Id 145/278  is having validation accuracy of 63.99828767123287\n",
            "Epoch #5. Batch Id 146/278  is having validation loss of 1.2986129522323608\n",
            "1.1726781129837036\n",
            "Epoch #5. Batch Id 146/278  is having validation accuracy of 64.0093537414966\n",
            "Epoch #5. Batch Id 147/278  is having validation loss of 1.2984530925750732\n",
            "1.274961233139038\n",
            "Epoch #5. Batch Id 147/278  is having validation accuracy of 64.04138513513513\n",
            "Epoch #5. Batch Id 148/278  is having validation loss of 1.3001772165298462\n",
            "1.5553488731384277\n",
            "Epoch #5. Batch Id 148/278  is having validation accuracy of 63.94714765100671\n",
            "Epoch #5. Batch Id 149/278  is having validation loss of 1.3001030683517456\n",
            "1.289049506187439\n",
            "Epoch #5. Batch Id 149/278  is having validation accuracy of 63.916666666666664\n",
            "Epoch #5. Batch Id 150/278  is having validation loss of 1.2994794845581055\n",
            "1.205950379371643\n",
            "Epoch #5. Batch Id 150/278  is having validation accuracy of 63.96937086092715\n",
            "Epoch #5. Batch Id 151/278  is having validation loss of 1.300544261932373\n",
            "1.4613327980041504\n",
            "Epoch #5. Batch Id 151/278  is having validation accuracy of 63.95970394736842\n",
            "Epoch #5. Batch Id 152/278  is having validation loss of 1.299547791481018\n",
            "1.1480804681777954\n",
            "Epoch #5. Batch Id 152/278  is having validation accuracy of 63.970588235294116\n",
            "Epoch #5. Batch Id 153/278  is having validation loss of 1.297910451889038\n",
            "1.0473947525024414\n",
            "Epoch #5. Batch Id 153/278  is having validation accuracy of 63.98133116883117\n",
            "Epoch #5. Batch Id 154/278  is having validation loss of 1.3011949062347412\n",
            "1.8070091009140015\n",
            "Epoch #5. Batch Id 154/278  is having validation accuracy of 63.931451612903224\n",
            "Epoch #5. Batch Id 155/278  is having validation loss of 1.2999144792556763\n",
            "1.1014515161514282\n",
            "Epoch #5. Batch Id 155/278  is having validation accuracy of 63.982371794871796\n",
            "Epoch #5. Batch Id 156/278  is having validation loss of 1.301544189453125\n",
            "1.5557827949523926\n",
            "Epoch #5. Batch Id 156/278  is having validation accuracy of 63.89331210191083\n",
            "Epoch #5. Batch Id 157/278  is having validation loss of 1.3019002676010132\n",
            "1.3578124046325684\n",
            "Epoch #5. Batch Id 157/278  is having validation accuracy of 63.90427215189873\n",
            "Epoch #5. Batch Id 158/278  is having validation loss of 1.3022112846374512\n",
            "1.3513462543487549\n",
            "Epoch #5. Batch Id 158/278  is having validation accuracy of 63.895440251572325\n",
            "Epoch #5. Batch Id 159/278  is having validation loss of 1.301966667175293\n",
            "1.2630820274353027\n",
            "Epoch #5. Batch Id 159/278  is having validation accuracy of 63.90625\n",
            "Epoch #5. Batch Id 160/278  is having validation loss of 1.303978681564331\n",
            "1.625892996788025\n",
            "Epoch #5. Batch Id 160/278  is having validation accuracy of 63.89751552795031\n",
            "Epoch #5. Batch Id 161/278  is having validation loss of 1.3063621520996094\n",
            "1.6900988817214966\n",
            "Epoch #5. Batch Id 161/278  is having validation accuracy of 63.85030864197531\n",
            "Epoch #5. Batch Id 162/278  is having validation loss of 1.3047276735305786\n",
            "1.0399473905563354\n",
            "Epoch #5. Batch Id 162/278  is having validation accuracy of 63.918711656441715\n",
            "Epoch #5. Batch Id 163/278  is having validation loss of 1.3035024404525757\n",
            "1.1037935018539429\n",
            "Epoch #5. Batch Id 163/278  is having validation accuracy of 63.986280487804876\n",
            "Epoch #5. Batch Id 164/278  is having validation loss of 1.306800127029419\n",
            "1.84762442111969\n",
            "Epoch #5. Batch Id 164/278  is having validation accuracy of 63.90151515151515\n",
            "Epoch #5. Batch Id 165/278  is having validation loss of 1.304802417755127\n",
            "0.9751778244972229\n",
            "Epoch #5. Batch Id 165/278  is having validation accuracy of 64.00602409638554\n",
            "Epoch #5. Batch Id 166/278  is having validation loss of 1.3023244142532349\n",
            "0.8909833431243896\n",
            "Epoch #5. Batch Id 166/278  is having validation accuracy of 64.05314371257485\n",
            "Epoch #5. Batch Id 167/278  is having validation loss of 1.3015788793563843\n",
            "1.177074670791626\n",
            "Epoch #5. Batch Id 167/278  is having validation accuracy of 64.08110119047619\n",
            "Epoch #5. Batch Id 168/278  is having validation loss of 1.2987947463989258\n",
            "0.8310563564300537\n",
            "Epoch #5. Batch Id 168/278  is having validation accuracy of 64.12721893491124\n",
            "Epoch #5. Batch Id 169/278  is having validation loss of 1.297371745109558\n",
            "1.0568886995315552\n",
            "Epoch #5. Batch Id 169/278  is having validation accuracy of 64.2279411764706\n",
            "Epoch #5. Batch Id 170/278  is having validation loss of 1.2997273206710815\n",
            "1.70017409324646\n",
            "Epoch #5. Batch Id 170/278  is having validation accuracy of 64.21783625730994\n",
            "Epoch #5. Batch Id 171/278  is having validation loss of 1.301371693611145\n",
            "1.5825624465942383\n",
            "Epoch #5. Batch Id 171/278  is having validation accuracy of 64.2078488372093\n",
            "Epoch #5. Batch Id 172/278  is having validation loss of 1.2975515127182007\n",
            "0.6404768824577332\n",
            "Epoch #5. Batch Id 172/278  is having validation accuracy of 64.34248554913295\n",
            "Epoch #5. Batch Id 173/278  is having validation loss of 1.2957792282104492\n",
            "0.9891647100448608\n",
            "Epoch #5. Batch Id 173/278  is having validation accuracy of 64.38577586206897\n",
            "Epoch #5. Batch Id 174/278  is having validation loss of 1.2977631092071533\n",
            "1.642953634262085\n",
            "Epoch #5. Batch Id 174/278  is having validation accuracy of 64.32142857142857\n",
            "Epoch #5. Batch Id 175/278  is having validation loss of 1.2977650165557861\n",
            "1.298095703125\n",
            "Epoch #5. Batch Id 175/278  is having validation accuracy of 64.2578125\n",
            "Epoch #5. Batch Id 176/278  is having validation loss of 1.2978534698486328\n",
            "1.3134180307388306\n",
            "Epoch #5. Batch Id 176/278  is having validation accuracy of 64.28319209039547\n",
            "Epoch #5. Batch Id 177/278  is having validation loss of 1.2978094816207886\n",
            "1.2900309562683105\n",
            "Epoch #5. Batch Id 177/278  is having validation accuracy of 64.34339887640449\n",
            "Epoch #5. Batch Id 178/278  is having validation loss of 1.3015869855880737\n",
            "1.973978877067566\n",
            "Epoch #5. Batch Id 178/278  is having validation accuracy of 64.2108938547486\n",
            "Epoch #5. Batch Id 179/278  is having validation loss of 1.303781509399414\n",
            "1.6965922117233276\n",
            "Epoch #5. Batch Id 179/278  is having validation accuracy of 64.16666666666667\n",
            "Epoch #5. Batch Id 180/278  is having validation loss of 1.3045275211334229\n",
            "1.4388066530227661\n",
            "Epoch #5. Batch Id 180/278  is having validation accuracy of 64.12292817679558\n",
            "Epoch #5. Batch Id 181/278  is having validation loss of 1.3035228252410889\n",
            "1.1216788291931152\n",
            "Epoch #5. Batch Id 181/278  is having validation accuracy of 64.13118131868131\n",
            "Epoch #5. Batch Id 182/278  is having validation loss of 1.3043162822723389\n",
            "1.4487357139587402\n",
            "Epoch #5. Batch Id 182/278  is having validation accuracy of 64.08811475409836\n",
            "Epoch #5. Batch Id 183/278  is having validation loss of 1.3065396547317505\n",
            "1.7134222984313965\n",
            "Epoch #5. Batch Id 183/278  is having validation accuracy of 64.07948369565217\n",
            "Epoch #5. Batch Id 184/278  is having validation loss of 1.3050507307052612\n",
            "1.031079888343811\n",
            "Epoch #5. Batch Id 184/278  is having validation accuracy of 64.13851351351352\n",
            "Epoch #5. Batch Id 185/278  is having validation loss of 1.3023185729980469\n",
            "0.7968762516975403\n",
            "Epoch #5. Batch Id 185/278  is having validation accuracy of 64.21370967741936\n",
            "Epoch #5. Batch Id 186/278  is having validation loss of 1.302345871925354\n",
            "1.307433843612671\n",
            "Epoch #5. Batch Id 186/278  is having validation accuracy of 64.18783422459893\n",
            "Epoch #5. Batch Id 187/278  is having validation loss of 1.3005882501602173\n",
            "0.9719147682189941\n",
            "Epoch #5. Batch Id 187/278  is having validation accuracy of 64.21210106382979\n",
            "Epoch #5. Batch Id 188/278  is having validation loss of 1.3019658327102661\n",
            "1.5609619617462158\n",
            "Epoch #5. Batch Id 188/278  is having validation accuracy of 64.2526455026455\n",
            "Epoch #5. Batch Id 189/278  is having validation loss of 1.2997969388961792\n",
            "0.8898715972900391\n",
            "Epoch #5. Batch Id 189/278  is having validation accuracy of 64.29276315789474\n",
            "Epoch #5. Batch Id 190/278  is having validation loss of 1.2991231679916382\n",
            "1.1711041927337646\n",
            "Epoch #5. Batch Id 190/278  is having validation accuracy of 64.31609947643979\n",
            "Epoch #5. Batch Id 191/278  is having validation loss of 1.3018766641616821\n",
            "1.8277950286865234\n",
            "Epoch #5. Batch Id 191/278  is having validation accuracy of 64.29036458333333\n",
            "Epoch #5. Batch Id 192/278  is having validation loss of 1.3021070957183838\n",
            "1.3463536500930786\n",
            "Epoch #5. Batch Id 192/278  is having validation accuracy of 64.24870466321244\n",
            "Epoch #5. Batch Id 193/278  is having validation loss of 1.302348256111145\n",
            "1.348889708518982\n",
            "Epoch #5. Batch Id 193/278  is having validation accuracy of 64.23969072164948\n",
            "Epoch #5. Batch Id 194/278  is having validation loss of 1.3032491207122803\n",
            "1.478013277053833\n",
            "Epoch #5. Batch Id 194/278  is having validation accuracy of 64.16666666666667\n",
            "Epoch #5. Batch Id 195/278  is having validation loss of 1.3028067350387573\n",
            "1.216546654701233\n",
            "Epoch #5. Batch Id 195/278  is having validation accuracy of 64.17410714285714\n",
            "Epoch #5. Batch Id 196/278  is having validation loss of 1.3025670051574707\n",
            "1.2555738687515259\n",
            "Epoch #5. Batch Id 196/278  is having validation accuracy of 64.16560913705584\n",
            "Epoch #5. Batch Id 197/278  is having validation loss of 1.3029340505599976\n",
            "1.3752344846725464\n",
            "Epoch #5. Batch Id 197/278  is having validation accuracy of 64.15719696969697\n",
            "Epoch #5. Batch Id 198/278  is having validation loss of 1.3036572933197021\n",
            "1.4468700885772705\n",
            "Epoch #5. Batch Id 198/278  is having validation accuracy of 64.14886934673366\n",
            "Epoch #5. Batch Id 199/278  is having validation loss of 1.3021602630615234\n",
            "1.0042403936386108\n",
            "Epoch #5. Batch Id 199/278  is having validation accuracy of 64.234375\n",
            "Epoch #5. Batch Id 200/278  is having validation loss of 1.3047077655792236\n",
            "1.814217209815979\n",
            "Epoch #5. Batch Id 200/278  is having validation accuracy of 64.16355721393035\n",
            "Epoch #5. Batch Id 201/278  is having validation loss of 1.3042256832122803\n",
            "1.2073314189910889\n",
            "Epoch #5. Batch Id 201/278  is having validation accuracy of 64.15532178217822\n",
            "Epoch #5. Batch Id 202/278  is having validation loss of 1.3012596368789673\n",
            "0.7021108269691467\n",
            "Epoch #5. Batch Id 202/278  is having validation accuracy of 64.20874384236453\n",
            "Epoch #5. Batch Id 203/278  is having validation loss of 1.3008445501327515\n",
            "1.2165776491165161\n",
            "Epoch #5. Batch Id 203/278  is having validation accuracy of 64.18504901960785\n",
            "Epoch #5. Batch Id 204/278  is having validation loss of 1.3028976917266846\n",
            "1.7217458486557007\n",
            "Epoch #5. Batch Id 204/278  is having validation accuracy of 64.10060975609755\n",
            "Epoch #5. Batch Id 205/278  is having validation loss of 1.3035491704940796\n",
            "1.4370975494384766\n",
            "Epoch #5. Batch Id 205/278  is having validation accuracy of 64.07766990291262\n",
            "Epoch #5. Batch Id 206/278  is having validation loss of 1.3025579452514648\n",
            "1.0983675718307495\n",
            "Epoch #5. Batch Id 206/278  is having validation accuracy of 64.08514492753623\n",
            "Epoch #5. Batch Id 207/278  is having validation loss of 1.3027845621109009\n",
            "1.3496819734573364\n",
            "Epoch #5. Batch Id 207/278  is having validation accuracy of 64.09254807692308\n",
            "Epoch #5. Batch Id 208/278  is having validation loss of 1.3025158643722534\n",
            "1.2466188669204712\n",
            "Epoch #5. Batch Id 208/278  is having validation accuracy of 64.11483253588517\n",
            "Epoch #5. Batch Id 209/278  is having validation loss of 1.3017210960388184\n",
            "1.135608434677124\n",
            "Epoch #5. Batch Id 209/278  is having validation accuracy of 64.0625\n",
            "Epoch #5. Batch Id 210/278  is having validation loss of 1.3023600578308105\n",
            "1.4365304708480835\n",
            "Epoch #5. Batch Id 210/278  is having validation accuracy of 64.06990521327015\n",
            "Epoch #5. Batch Id 211/278  is having validation loss of 1.3015697002410889\n",
            "1.1347938776016235\n",
            "Epoch #5. Batch Id 211/278  is having validation accuracy of 64.1067216981132\n",
            "Epoch #5. Batch Id 212/278  is having validation loss of 1.3009554147720337\n",
            "1.1707146167755127\n",
            "Epoch #5. Batch Id 212/278  is having validation accuracy of 64.11384976525821\n",
            "Epoch #5. Batch Id 213/278  is having validation loss of 1.3012975454330444\n",
            "1.374167561531067\n",
            "Epoch #5. Batch Id 213/278  is having validation accuracy of 64.0625\n",
            "Epoch #5. Batch Id 214/278  is having validation loss of 1.3003170490264893\n",
            "1.090501308441162\n",
            "Epoch #5. Batch Id 214/278  is having validation accuracy of 64.08430232558139\n",
            "Epoch #5. Batch Id 215/278  is having validation loss of 1.3029807806015015\n",
            "1.8756855726242065\n",
            "Epoch #5. Batch Id 215/278  is having validation accuracy of 64.01909722222223\n",
            "Epoch #5. Batch Id 216/278  is having validation loss of 1.3038437366485596\n",
            "1.4902414083480835\n",
            "Epoch #5. Batch Id 216/278  is having validation accuracy of 63.96889400921659\n",
            "Epoch #5. Batch Id 217/278  is having validation loss of 1.3029145002365112\n",
            "1.1012626886367798\n",
            "Epoch #5. Batch Id 217/278  is having validation accuracy of 64.03383027522936\n",
            "Epoch #5. Batch Id 218/278  is having validation loss of 1.302043080329895\n",
            "1.1120834350585938\n",
            "Epoch #5. Batch Id 218/278  is having validation accuracy of 64.05536529680366\n",
            "Epoch #5. Batch Id 219/278  is having validation loss of 1.3020662069320679\n",
            "1.3071305751800537\n",
            "Epoch #5. Batch Id 219/278  is having validation accuracy of 64.0625\n",
            "Epoch #5. Batch Id 220/278  is having validation loss of 1.302884817123413\n",
            "1.482988953590393\n",
            "Epoch #5. Batch Id 220/278  is having validation accuracy of 64.02714932126698\n",
            "Epoch #5. Batch Id 221/278  is having validation loss of 1.3029277324676514\n",
            "1.3124189376831055\n",
            "Epoch #5. Batch Id 221/278  is having validation accuracy of 63.99211711711712\n",
            "Epoch #5. Batch Id 222/278  is having validation loss of 1.3029786348342896\n",
            "1.3142683506011963\n",
            "Epoch #5. Batch Id 222/278  is having validation accuracy of 63.98542600896861\n",
            "Epoch #5. Batch Id 223/278  is having validation loss of 1.3038020133972168\n",
            "1.487414836883545\n",
            "Epoch #5. Batch Id 223/278  is having validation accuracy of 63.92299107142857\n",
            "Epoch #5. Batch Id 224/278  is having validation loss of 1.3046891689300537\n",
            "1.5034047365188599\n",
            "Epoch #5. Batch Id 224/278  is having validation accuracy of 63.93055555555556\n",
            "Epoch #5. Batch Id 225/278  is having validation loss of 1.3046636581420898\n",
            "1.2989140748977661\n",
            "Epoch #5. Batch Id 225/278  is having validation accuracy of 63.92422566371681\n",
            "Epoch #5. Batch Id 226/278  is having validation loss of 1.3042329549789429\n",
            "1.2069021463394165\n",
            "Epoch #5. Batch Id 226/278  is having validation accuracy of 63.945484581497794\n",
            "Epoch #5. Batch Id 227/278  is having validation loss of 1.306274175643921\n",
            "1.7696352005004883\n",
            "Epoch #5. Batch Id 227/278  is having validation accuracy of 63.95285087719298\n",
            "Epoch #5. Batch Id 228/278  is having validation loss of 1.3089877367019653\n",
            "1.9276825189590454\n",
            "Epoch #5. Batch Id 228/278  is having validation accuracy of 63.8782751091703\n",
            "Epoch #5. Batch Id 229/278  is having validation loss of 1.308253288269043\n",
            "1.1400535106658936\n",
            "Epoch #5. Batch Id 229/278  is having validation accuracy of 63.88586956521739\n",
            "Epoch #5. Batch Id 230/278  is having validation loss of 1.3077205419540405\n",
            "1.1851999759674072\n",
            "Epoch #5. Batch Id 230/278  is having validation accuracy of 63.92045454545455\n",
            "Epoch #5. Batch Id 231/278  is having validation loss of 1.310073971748352\n",
            "1.8537157773971558\n",
            "Epoch #5. Batch Id 231/278  is having validation accuracy of 63.8739224137931\n",
            "Epoch #5. Batch Id 232/278  is having validation loss of 1.3112562894821167\n",
            "1.5855637788772583\n",
            "Epoch #5. Batch Id 232/278  is having validation accuracy of 63.81437768240343\n",
            "Epoch #5. Batch Id 233/278  is having validation loss of 1.310457706451416\n",
            "1.1243948936462402\n",
            "Epoch #5. Batch Id 233/278  is having validation accuracy of 63.82211538461539\n",
            "Epoch #5. Batch Id 234/278  is having validation loss of 1.3087140321731567\n",
            "0.9006891250610352\n",
            "Epoch #5. Batch Id 234/278  is having validation accuracy of 63.869680851063826\n",
            "Epoch #5. Batch Id 235/278  is having validation loss of 1.3098604679107666\n",
            "1.5792760848999023\n",
            "Epoch #5. Batch Id 235/278  is having validation accuracy of 63.82415254237288\n",
            "Epoch #5. Batch Id 236/278  is having validation loss of 1.3094944953918457\n",
            "1.2231377363204956\n",
            "Epoch #5. Batch Id 236/278  is having validation accuracy of 63.81856540084388\n",
            "Epoch #5. Batch Id 237/278  is having validation loss of 1.3093349933624268\n",
            "1.2715346813201904\n",
            "Epoch #5. Batch Id 237/278  is having validation accuracy of 63.85241596638655\n",
            "Epoch #5. Batch Id 238/278  is having validation loss of 1.3072837591171265\n",
            "0.8190979957580566\n",
            "Epoch #5. Batch Id 238/278  is having validation accuracy of 63.92520920502092\n",
            "Epoch #5. Batch Id 239/278  is having validation loss of 1.3095598220825195\n",
            "1.8535431623458862\n",
            "Epoch #5. Batch Id 239/278  is having validation accuracy of 63.841145833333336\n",
            "Epoch #5. Batch Id 240/278  is having validation loss of 1.3076139688491821\n",
            "0.8405972719192505\n",
            "Epoch #5. Batch Id 240/278  is having validation accuracy of 63.90041493775934\n",
            "Epoch #5. Batch Id 241/278  is having validation loss of 1.3079122304916382\n",
            "1.3797976970672607\n",
            "Epoch #5. Batch Id 241/278  is having validation accuracy of 63.90754132231405\n",
            "Epoch #5. Batch Id 242/278  is having validation loss of 1.3080250024795532\n",
            "1.335301399230957\n",
            "Epoch #5. Batch Id 242/278  is having validation accuracy of 63.92746913580247\n",
            "Epoch #5. Batch Id 243/278  is having validation loss of 1.3065601587295532\n",
            "0.9505999684333801\n",
            "Epoch #5. Batch Id 243/278  is having validation accuracy of 63.98565573770492\n",
            "Epoch #5. Batch Id 244/278  is having validation loss of 1.3076415061950684\n",
            "1.571492314338684\n",
            "Epoch #5. Batch Id 244/278  is having validation accuracy of 63.954081632653065\n",
            "Epoch #5. Batch Id 245/278  is having validation loss of 1.3095251321792603\n",
            "1.7710163593292236\n",
            "Epoch #5. Batch Id 245/278  is having validation accuracy of 63.884654471544714\n",
            "Epoch #5. Batch Id 246/278  is having validation loss of 1.3104134798049927\n",
            "1.5289382934570312\n",
            "Epoch #5. Batch Id 246/278  is having validation accuracy of 63.8917004048583\n",
            "Epoch #5. Batch Id 247/278  is having validation loss of 1.3118131160736084\n",
            "1.6575210094451904\n",
            "Epoch #5. Batch Id 247/278  is having validation accuracy of 63.810483870967744\n",
            "Epoch #5. Batch Id 248/278  is having validation loss of 1.3123711347579956\n",
            "1.4507695436477661\n",
            "Epoch #5. Batch Id 248/278  is having validation accuracy of 63.7675702811245\n",
            "Epoch #5. Batch Id 249/278  is having validation loss of 1.3125264644622803\n",
            "1.3512043952941895\n",
            "Epoch #5. Batch Id 249/278  is having validation accuracy of 63.775\n",
            "Epoch #5. Batch Id 250/278  is having validation loss of 1.3122624158859253\n",
            "1.2462540864944458\n",
            "Epoch #5. Batch Id 250/278  is having validation accuracy of 63.80727091633466\n",
            "Epoch #5. Batch Id 251/278  is having validation loss of 1.3143433332443237\n",
            "1.8366540670394897\n",
            "Epoch #5. Batch Id 251/278  is having validation accuracy of 63.802083333333336\n",
            "Epoch #5. Batch Id 252/278  is having validation loss of 1.3141270875930786\n",
            "1.2596426010131836\n",
            "Epoch #5. Batch Id 252/278  is having validation accuracy of 63.77223320158103\n",
            "Epoch #5. Batch Id 253/278  is having validation loss of 1.3142569065093994\n",
            "1.347092628479004\n",
            "Epoch #5. Batch Id 253/278  is having validation accuracy of 63.76722440944882\n",
            "Epoch #5. Batch Id 254/278  is having validation loss of 1.3130205869674683\n",
            "0.998993456363678\n",
            "Epoch #5. Batch Id 254/278  is having validation accuracy of 63.81127450980392\n",
            "Epoch #5. Batch Id 255/278  is having validation loss of 1.3118778467178345\n",
            "1.020493507385254\n",
            "Epoch #5. Batch Id 255/278  is having validation accuracy of 63.818359375\n",
            "Epoch #5. Batch Id 256/278  is having validation loss of 1.3110017776489258\n",
            "1.0867245197296143\n",
            "Epoch #5. Batch Id 256/278  is having validation accuracy of 63.8375486381323\n",
            "Epoch #5. Batch Id 257/278  is having validation loss of 1.3101584911346436\n",
            "1.0934195518493652\n",
            "Epoch #5. Batch Id 257/278  is having validation accuracy of 63.832364341085274\n",
            "Epoch #5. Batch Id 258/278  is having validation loss of 1.3109239339828491\n",
            "1.5084028244018555\n",
            "Epoch #5. Batch Id 258/278  is having validation accuracy of 63.81515444015444\n",
            "Epoch #5. Batch Id 259/278  is having validation loss of 1.3097119331359863\n",
            "0.9958005547523499\n",
            "Epoch #5. Batch Id 259/278  is having validation accuracy of 63.84615384615385\n",
            "Epoch #5. Batch Id 260/278  is having validation loss of 1.3074356317520142\n",
            "0.7156065702438354\n",
            "Epoch #5. Batch Id 260/278  is having validation accuracy of 63.900862068965516\n",
            "Epoch #5. Batch Id 261/278  is having validation loss of 1.3063733577728271\n",
            "1.029125690460205\n",
            "Epoch #5. Batch Id 261/278  is having validation accuracy of 63.93129770992366\n",
            "Epoch #5. Batch Id 262/278  is having validation loss of 1.307870864868164\n",
            "1.7002202272415161\n",
            "Epoch #5. Batch Id 262/278  is having validation accuracy of 63.89020912547529\n",
            "Epoch #5. Batch Id 263/278  is having validation loss of 1.3079274892807007\n",
            "1.3228129148483276\n",
            "Epoch #5. Batch Id 263/278  is having validation accuracy of 63.896780303030305\n",
            "Epoch #5. Batch Id 264/278  is having validation loss of 1.3060919046401978\n",
            "0.8214831352233887\n",
            "Epoch #5. Batch Id 264/278  is having validation accuracy of 63.9622641509434\n",
            "Epoch #5. Batch Id 265/278  is having validation loss of 1.3073288202285767\n",
            "1.6351205110549927\n",
            "Epoch #5. Batch Id 265/278  is having validation accuracy of 63.95676691729323\n",
            "Epoch #5. Batch Id 266/278  is having validation loss of 1.3071008920669556\n",
            "1.2464838027954102\n",
            "Epoch #5. Batch Id 266/278  is having validation accuracy of 63.9747191011236\n",
            "Epoch #5. Batch Id 267/278  is having validation loss of 1.3060474395751953\n",
            "1.0247894525527954\n",
            "Epoch #5. Batch Id 267/278  is having validation accuracy of 64.00419776119404\n",
            "Epoch #5. Batch Id 268/278  is having validation loss of 1.3041208982467651\n",
            "0.7878075838088989\n",
            "Epoch #5. Batch Id 268/278  is having validation accuracy of 64.06830855018588\n",
            "Epoch #5. Batch Id 269/278  is having validation loss of 1.302652359008789\n",
            "0.9076244235038757\n",
            "Epoch #5. Batch Id 269/278  is having validation accuracy of 64.10879629629629\n",
            "Epoch #5. Batch Id 270/278  is having validation loss of 1.303527593612671\n",
            "1.5398271083831787\n",
            "Epoch #5. Batch Id 270/278  is having validation accuracy of 64.10285977859779\n",
            "Epoch #5. Batch Id 271/278  is having validation loss of 1.3044836521148682\n",
            "1.5635877847671509\n",
            "Epoch #5. Batch Id 271/278  is having validation accuracy of 64.09696691176471\n",
            "Epoch #5. Batch Id 272/278  is having validation loss of 1.306309700012207\n",
            "1.8029834032058716\n",
            "Epoch #5. Batch Id 272/278  is having validation accuracy of 64.06822344322345\n",
            "Epoch #5. Batch Id 273/278  is having validation loss of 1.308144450187683\n",
            "1.8090381622314453\n",
            "Epoch #5. Batch Id 273/278  is having validation accuracy of 63.994069343065696\n",
            "Epoch #5. Batch Id 274/278  is having validation loss of 1.3073513507843018\n",
            "1.0900285243988037\n",
            "Epoch #5. Batch Id 274/278  is having validation accuracy of 64.02272727272727\n",
            "Epoch #5. Batch Id 275/278  is having validation loss of 1.308290719985962\n",
            "1.5666323900222778\n",
            "Epoch #5. Batch Id 275/278  is having validation accuracy of 64.00588768115942\n",
            "Epoch #5. Batch Id 276/278  is having validation loss of 1.308448076248169\n",
            "1.3518904447555542\n",
            "Epoch #5. Batch Id 276/278  is having validation accuracy of 64.00045126353791\n",
            "Epoch #5. Batch Id 277/278  is having validation loss of 1.3038352727890015\n",
            "0.026077959686517715\n",
            "Epoch #5. Batch Id 277/278  is having validation accuracy of 64.0085720730882\n",
            "Эпоха #5 train_loss: 1.4489615750790108e-05, val_loss: 0.00014706014189869165\n",
            "Потрачено 26.7 минут на 5 эпоху\n",
            "Batch Id 0/2438 is having training loss of 1.0576756000518799\n",
            "1.0576756000518799\n",
            "Epoch #6. Accuracy on batch 0/2438  on Training is 75.0\n",
            "Epoch #6. Accuracy on batch 1/2438  on Training is 64.0625\n",
            "Epoch #6. Accuracy on batch 2/2438  on Training is 62.5\n",
            "Epoch #6. Accuracy on batch 3/2438  on Training is 65.625\n",
            "Epoch #6. Accuracy on batch 4/2438  on Training is 63.125\n",
            "Epoch #6. Accuracy on batch 5/2438  on Training is 64.58333333333333\n",
            "Epoch #6. Accuracy on batch 6/2438  on Training is 66.51785714285714\n",
            "Epoch #6. Accuracy on batch 7/2438  on Training is 66.40625\n",
            "Epoch #6. Accuracy on batch 8/2438  on Training is 68.05555555555556\n",
            "Epoch #6. Accuracy on batch 9/2438  on Training is 69.0625\n",
            "Epoch #6. Accuracy on batch 10/2438  on Training is 68.75\n",
            "Epoch #6. Accuracy on batch 11/2438  on Training is 69.79166666666667\n",
            "Epoch #6. Accuracy on batch 12/2438  on Training is 70.4326923076923\n",
            "Epoch #6. Accuracy on batch 13/2438  on Training is 70.75892857142857\n",
            "Epoch #6. Accuracy on batch 14/2438  on Training is 70.0\n",
            "Epoch #6. Accuracy on batch 15/2438  on Training is 69.53125\n",
            "Epoch #6. Accuracy on batch 16/2438  on Training is 69.8529411764706\n",
            "Epoch #6. Accuracy on batch 17/2438  on Training is 69.96527777777777\n",
            "Epoch #6. Accuracy on batch 18/2438  on Training is 70.39473684210526\n",
            "Epoch #6. Accuracy on batch 19/2438  on Training is 70.15625\n",
            "Batch Id 20/2438 is having training loss of 1.0474611520767212\n",
            "1.1499186754226685\n",
            "Epoch #6. Accuracy on batch 20/2438  on Training is 70.23809523809524\n",
            "Epoch #6. Accuracy on batch 21/2438  on Training is 70.17045454545455\n",
            "Epoch #6. Accuracy on batch 22/2438  on Training is 69.56521739130434\n",
            "Epoch #6. Accuracy on batch 23/2438  on Training is 69.40104166666667\n",
            "Epoch #6. Accuracy on batch 24/2438  on Training is 69.875\n",
            "Epoch #6. Accuracy on batch 25/2438  on Training is 70.1923076923077\n",
            "Epoch #6. Accuracy on batch 26/2438  on Training is 70.25462962962963\n",
            "Epoch #6. Accuracy on batch 27/2438  on Training is 70.75892857142857\n",
            "Epoch #6. Accuracy on batch 28/2438  on Training is 70.47413793103448\n",
            "Epoch #6. Accuracy on batch 29/2438  on Training is 70.72916666666667\n",
            "Epoch #6. Accuracy on batch 30/2438  on Training is 70.66532258064517\n",
            "Epoch #6. Accuracy on batch 31/2438  on Training is 70.80078125\n",
            "Epoch #6. Accuracy on batch 32/2438  on Training is 70.9280303030303\n",
            "Epoch #6. Accuracy on batch 33/2438  on Training is 71.04779411764706\n",
            "Epoch #6. Accuracy on batch 34/2438  on Training is 70.98214285714286\n",
            "Epoch #6. Accuracy on batch 35/2438  on Training is 70.65972222222223\n",
            "Epoch #6. Accuracy on batch 36/2438  on Training is 71.11486486486487\n",
            "Epoch #6. Accuracy on batch 37/2438  on Training is 70.80592105263158\n",
            "Epoch #6. Accuracy on batch 38/2438  on Training is 70.75320512820512\n",
            "Epoch #6. Accuracy on batch 39/2438  on Training is 70.9375\n",
            "Batch Id 40/2438 is having training loss of 1.0614218711853027\n",
            "0.8892533779144287\n",
            "Epoch #6. Accuracy on batch 40/2438  on Training is 71.03658536585365\n",
            "Epoch #6. Accuracy on batch 41/2438  on Training is 71.2797619047619\n",
            "Epoch #6. Accuracy on batch 42/2438  on Training is 70.63953488372093\n",
            "Epoch #6. Accuracy on batch 43/2438  on Training is 70.88068181818181\n",
            "Epoch #6. Accuracy on batch 44/2438  on Training is 70.76388888888889\n",
            "Epoch #6. Accuracy on batch 45/2438  on Training is 70.72010869565217\n",
            "Epoch #6. Accuracy on batch 46/2438  on Training is 70.67819148936171\n",
            "Epoch #6. Accuracy on batch 47/2438  on Training is 70.96354166666667\n",
            "Epoch #6. Accuracy on batch 48/2438  on Training is 70.8545918367347\n",
            "Epoch #6. Accuracy on batch 49/2438  on Training is 70.9375\n",
            "Epoch #6. Accuracy on batch 50/2438  on Training is 71.07843137254902\n",
            "Epoch #6. Accuracy on batch 51/2438  on Training is 70.91346153846153\n",
            "Epoch #6. Accuracy on batch 52/2438  on Training is 71.0495283018868\n",
            "Epoch #6. Accuracy on batch 53/2438  on Training is 71.12268518518519\n",
            "Epoch #6. Accuracy on batch 54/2438  on Training is 71.13636363636364\n",
            "Epoch #6. Accuracy on batch 55/2438  on Training is 71.03794642857143\n",
            "Epoch #6. Accuracy on batch 56/2438  on Training is 70.83333333333333\n",
            "Epoch #6. Accuracy on batch 57/2438  on Training is 70.63577586206897\n",
            "Epoch #6. Accuracy on batch 58/2438  on Training is 70.81567796610169\n",
            "Epoch #6. Accuracy on batch 59/2438  on Training is 70.88541666666667\n",
            "Batch Id 60/2438 is having training loss of 1.0774697065353394\n",
            "0.8749392628669739\n",
            "Epoch #6. Accuracy on batch 60/2438  on Training is 70.85040983606558\n",
            "Epoch #6. Accuracy on batch 61/2438  on Training is 70.71572580645162\n",
            "Epoch #6. Accuracy on batch 62/2438  on Training is 70.8829365079365\n",
            "Epoch #6. Accuracy on batch 63/2438  on Training is 70.947265625\n",
            "Epoch #6. Accuracy on batch 64/2438  on Training is 70.96153846153847\n",
            "Epoch #6. Accuracy on batch 65/2438  on Training is 71.02272727272727\n",
            "Epoch #6. Accuracy on batch 66/2438  on Training is 70.8955223880597\n",
            "Epoch #6. Accuracy on batch 67/2438  on Training is 70.7720588235294\n",
            "Epoch #6. Accuracy on batch 68/2438  on Training is 70.8786231884058\n",
            "Epoch #6. Accuracy on batch 69/2438  on Training is 70.66964285714286\n",
            "Epoch #6. Accuracy on batch 70/2438  on Training is 70.68661971830986\n",
            "Epoch #6. Accuracy on batch 71/2438  on Training is 70.57291666666667\n",
            "Epoch #6. Accuracy on batch 72/2438  on Training is 70.6763698630137\n",
            "Epoch #6. Accuracy on batch 73/2438  on Training is 70.73479729729729\n",
            "Epoch #6. Accuracy on batch 74/2438  on Training is 70.58333333333333\n",
            "Epoch #6. Accuracy on batch 75/2438  on Training is 70.51809210526316\n",
            "Epoch #6. Accuracy on batch 76/2438  on Training is 70.53571428571429\n",
            "Epoch #6. Accuracy on batch 77/2438  on Training is 70.3926282051282\n",
            "Epoch #6. Accuracy on batch 78/2438  on Training is 70.53006329113924\n",
            "Epoch #6. Accuracy on batch 79/2438  on Training is 70.390625\n",
            "Batch Id 80/2438 is having training loss of 1.07408607006073\n",
            "1.277374267578125\n",
            "Epoch #6. Accuracy on batch 80/2438  on Training is 70.25462962962963\n",
            "Epoch #6. Accuracy on batch 81/2438  on Training is 70.38871951219512\n",
            "Epoch #6. Accuracy on batch 82/2438  on Training is 70.519578313253\n",
            "Epoch #6. Accuracy on batch 83/2438  on Training is 70.53571428571429\n",
            "Epoch #6. Accuracy on batch 84/2438  on Training is 70.51470588235294\n",
            "Epoch #6. Accuracy on batch 85/2438  on Training is 70.4578488372093\n",
            "Epoch #6. Accuracy on batch 86/2438  on Training is 70.4382183908046\n",
            "Epoch #6. Accuracy on batch 87/2438  on Training is 70.49005681818181\n",
            "Epoch #6. Accuracy on batch 88/2438  on Training is 70.47050561797752\n",
            "Epoch #6. Accuracy on batch 89/2438  on Training is 70.48611111111111\n",
            "Epoch #6. Accuracy on batch 90/2438  on Training is 70.50137362637362\n",
            "Epoch #6. Accuracy on batch 91/2438  on Training is 70.48233695652173\n",
            "Epoch #6. Accuracy on batch 92/2438  on Training is 70.36290322580645\n",
            "Epoch #6. Accuracy on batch 93/2438  on Training is 70.34574468085107\n",
            "Epoch #6. Accuracy on batch 94/2438  on Training is 70.49342105263158\n",
            "Epoch #6. Accuracy on batch 95/2438  on Training is 70.57291666666667\n",
            "Epoch #6. Accuracy on batch 96/2438  on Training is 70.61855670103093\n",
            "Epoch #6. Accuracy on batch 97/2438  on Training is 70.56760204081633\n",
            "Epoch #6. Accuracy on batch 98/2438  on Training is 70.70707070707071\n",
            "Epoch #6. Accuracy on batch 99/2438  on Training is 70.65625\n",
            "Batch Id 100/2438 is having training loss of 1.0627959966659546\n",
            "0.9850239157676697\n",
            "Epoch #6. Accuracy on batch 100/2438  on Training is 70.66831683168317\n",
            "Epoch #6. Accuracy on batch 101/2438  on Training is 70.4656862745098\n",
            "Epoch #6. Accuracy on batch 102/2438  on Training is 70.29733009708738\n",
            "Epoch #6. Accuracy on batch 103/2438  on Training is 70.3125\n",
            "Epoch #6. Accuracy on batch 104/2438  on Training is 70.32738095238095\n",
            "Epoch #6. Accuracy on batch 105/2438  on Training is 70.3125\n",
            "Epoch #6. Accuracy on batch 106/2438  on Training is 70.21028037383178\n",
            "Epoch #6. Accuracy on batch 107/2438  on Training is 70.3125\n",
            "Epoch #6. Accuracy on batch 108/2438  on Training is 70.32683486238533\n",
            "Epoch #6. Accuracy on batch 109/2438  on Training is 70.25568181818181\n",
            "Epoch #6. Accuracy on batch 110/2438  on Training is 70.27027027027027\n",
            "Epoch #6. Accuracy on batch 111/2438  on Training is 70.22879464285714\n",
            "Epoch #6. Accuracy on batch 112/2438  on Training is 70.2433628318584\n",
            "Epoch #6. Accuracy on batch 113/2438  on Training is 70.3673245614035\n",
            "Epoch #6. Accuracy on batch 114/2438  on Training is 70.29891304347827\n",
            "Epoch #6. Accuracy on batch 115/2438  on Training is 70.3125\n",
            "Epoch #6. Accuracy on batch 116/2438  on Training is 70.2457264957265\n",
            "Epoch #6. Accuracy on batch 117/2438  on Training is 70.20656779661017\n",
            "Epoch #6. Accuracy on batch 118/2438  on Training is 70.22058823529412\n",
            "Epoch #6. Accuracy on batch 119/2438  on Training is 70.33854166666667\n",
            "Batch Id 120/2438 is having training loss of 1.0682402849197388\n",
            "0.9057284593582153\n",
            "Epoch #6. Accuracy on batch 120/2438  on Training is 70.3254132231405\n",
            "Epoch #6. Accuracy on batch 121/2438  on Training is 70.28688524590164\n",
            "Epoch #6. Accuracy on batch 122/2438  on Training is 70.2489837398374\n",
            "Epoch #6. Accuracy on batch 123/2438  on Training is 70.33770161290323\n",
            "Epoch #6. Accuracy on batch 124/2438  on Training is 70.35\n",
            "Epoch #6. Accuracy on batch 125/2438  on Training is 70.36210317460318\n",
            "Epoch #6. Accuracy on batch 126/2438  on Training is 70.44783464566929\n",
            "Epoch #6. Accuracy on batch 127/2438  on Training is 70.4345703125\n",
            "Epoch #6. Accuracy on batch 128/2438  on Training is 70.39728682170542\n",
            "Epoch #6. Accuracy on batch 129/2438  on Training is 70.48076923076923\n",
            "Epoch #6. Accuracy on batch 130/2438  on Training is 70.44370229007633\n",
            "Epoch #6. Accuracy on batch 131/2438  on Training is 70.45454545454545\n",
            "Epoch #6. Accuracy on batch 132/2438  on Training is 70.34774436090225\n",
            "Epoch #6. Accuracy on batch 133/2438  on Training is 70.40578358208955\n",
            "Epoch #6. Accuracy on batch 134/2438  on Training is 70.34722222222223\n",
            "Epoch #6. Accuracy on batch 135/2438  on Training is 70.35845588235294\n",
            "Epoch #6. Accuracy on batch 136/2438  on Training is 70.32390510948905\n",
            "Epoch #6. Accuracy on batch 137/2438  on Training is 70.35778985507247\n",
            "Epoch #6. Accuracy on batch 138/2438  on Training is 70.43615107913669\n",
            "Epoch #6. Accuracy on batch 139/2438  on Training is 70.37946428571429\n",
            "Batch Id 140/2438 is having training loss of 1.0714627504348755\n",
            "1.170096516609192\n",
            "Epoch #6. Accuracy on batch 140/2438  on Training is 70.36790780141844\n",
            "Epoch #6. Accuracy on batch 141/2438  on Training is 70.40052816901408\n",
            "Epoch #6. Accuracy on batch 142/2438  on Training is 70.38898601398601\n",
            "Epoch #6. Accuracy on batch 143/2438  on Training is 70.37760416666667\n",
            "Epoch #6. Accuracy on batch 144/2438  on Training is 70.34482758620689\n",
            "Epoch #6. Accuracy on batch 145/2438  on Training is 70.29109589041096\n",
            "Epoch #6. Accuracy on batch 146/2438  on Training is 70.28061224489795\n",
            "Epoch #6. Accuracy on batch 147/2438  on Training is 70.39695945945945\n",
            "Epoch #6. Accuracy on batch 148/2438  on Training is 70.49077181208054\n",
            "Epoch #6. Accuracy on batch 149/2438  on Training is 70.39583333333333\n",
            "Epoch #6. Accuracy on batch 150/2438  on Training is 70.28145695364239\n",
            "Epoch #6. Accuracy on batch 151/2438  on Training is 70.27138157894737\n",
            "Epoch #6. Accuracy on batch 152/2438  on Training is 70.1797385620915\n",
            "Epoch #6. Accuracy on batch 153/2438  on Training is 70.17045454545455\n",
            "Epoch #6. Accuracy on batch 154/2438  on Training is 70.24193548387096\n",
            "Epoch #6. Accuracy on batch 155/2438  on Training is 70.3125\n",
            "Epoch #6. Accuracy on batch 156/2438  on Training is 70.32245222929936\n",
            "Epoch #6. Accuracy on batch 157/2438  on Training is 70.3125\n",
            "Epoch #6. Accuracy on batch 158/2438  on Training is 70.26336477987421\n",
            "Epoch #6. Accuracy on batch 159/2438  on Training is 70.25390625\n",
            "Batch Id 160/2438 is having training loss of 1.0815529823303223\n",
            "1.3162717819213867\n",
            "Epoch #6. Accuracy on batch 160/2438  on Training is 70.1863354037267\n",
            "Epoch #6. Accuracy on batch 161/2438  on Training is 70.23533950617283\n",
            "Epoch #6. Accuracy on batch 162/2438  on Training is 70.24539877300613\n",
            "Epoch #6. Accuracy on batch 163/2438  on Training is 70.16006097560975\n",
            "Epoch #6. Accuracy on batch 164/2438  on Training is 70.18939393939394\n",
            "Epoch #6. Accuracy on batch 165/2438  on Training is 70.18072289156626\n",
            "Epoch #6. Accuracy on batch 166/2438  on Training is 70.19086826347305\n",
            "Epoch #6. Accuracy on batch 167/2438  on Training is 70.23809523809524\n",
            "Epoch #6. Accuracy on batch 168/2438  on Training is 70.17381656804734\n",
            "Epoch #6. Accuracy on batch 169/2438  on Training is 70.20220588235294\n",
            "Epoch #6. Accuracy on batch 170/2438  on Training is 70.15716374269006\n",
            "Epoch #6. Accuracy on batch 171/2438  on Training is 70.14898255813954\n",
            "Epoch #6. Accuracy on batch 172/2438  on Training is 70.15895953757226\n",
            "Epoch #6. Accuracy on batch 173/2438  on Training is 70.13290229885058\n",
            "Epoch #6. Accuracy on batch 174/2438  on Training is 70.21428571428571\n",
            "Epoch #6. Accuracy on batch 175/2438  on Training is 70.29474431818181\n",
            "Epoch #6. Accuracy on batch 176/2438  on Training is 70.2683615819209\n",
            "Epoch #6. Accuracy on batch 177/2438  on Training is 70.27738764044943\n",
            "Epoch #6. Accuracy on batch 178/2438  on Training is 70.26885474860335\n",
            "Epoch #6. Accuracy on batch 179/2438  on Training is 70.13888888888889\n",
            "Batch Id 180/2438 is having training loss of 1.0801128149032593\n",
            "1.3195449113845825\n",
            "Epoch #6. Accuracy on batch 180/2438  on Training is 70.09668508287292\n",
            "Epoch #6. Accuracy on batch 181/2438  on Training is 70.1407967032967\n",
            "Epoch #6. Accuracy on batch 182/2438  on Training is 70.09904371584699\n",
            "Epoch #6. Accuracy on batch 183/2438  on Training is 70.05774456521739\n",
            "Epoch #6. Accuracy on batch 184/2438  on Training is 70.0\n",
            "Epoch #6. Accuracy on batch 185/2438  on Training is 70.06048387096774\n",
            "Epoch #6. Accuracy on batch 186/2438  on Training is 70.08689839572193\n",
            "Epoch #6. Accuracy on batch 187/2438  on Training is 70.07978723404256\n",
            "Epoch #6. Accuracy on batch 188/2438  on Training is 70.07275132275132\n",
            "Epoch #6. Accuracy on batch 189/2438  on Training is 70.13157894736842\n",
            "Epoch #6. Accuracy on batch 190/2438  on Training is 70.14070680628272\n",
            "Epoch #6. Accuracy on batch 191/2438  on Training is 70.13346354166667\n",
            "Epoch #6. Accuracy on batch 192/2438  on Training is 70.14248704663213\n",
            "Epoch #6. Accuracy on batch 193/2438  on Training is 70.1514175257732\n",
            "Epoch #6. Accuracy on batch 194/2438  on Training is 70.14423076923077\n",
            "Epoch #6. Accuracy on batch 195/2438  on Training is 70.16900510204081\n",
            "Epoch #6. Accuracy on batch 196/2438  on Training is 70.14593908629442\n",
            "Epoch #6. Accuracy on batch 197/2438  on Training is 70.17045454545455\n",
            "Epoch #6. Accuracy on batch 198/2438  on Training is 70.16331658291458\n",
            "Epoch #6. Accuracy on batch 199/2438  on Training is 70.15625\n",
            "Batch Id 200/2438 is having training loss of 1.0807149410247803\n",
            "1.2928483486175537\n",
            "Epoch #6. Accuracy on batch 200/2438  on Training is 70.1337064676617\n",
            "Epoch #6. Accuracy on batch 201/2438  on Training is 70.18873762376238\n",
            "Epoch #6. Accuracy on batch 202/2438  on Training is 70.12007389162562\n",
            "Epoch #6. Accuracy on batch 203/2438  on Training is 70.12867647058823\n",
            "Epoch #6. Accuracy on batch 204/2438  on Training is 70.1219512195122\n",
            "Epoch #6. Accuracy on batch 205/2438  on Training is 70.14563106796116\n",
            "Epoch #6. Accuracy on batch 206/2438  on Training is 70.13888888888889\n",
            "Epoch #6. Accuracy on batch 207/2438  on Training is 70.1923076923077\n",
            "Epoch #6. Accuracy on batch 208/2438  on Training is 70.14055023923444\n",
            "Epoch #6. Accuracy on batch 209/2438  on Training is 70.13392857142857\n",
            "Epoch #6. Accuracy on batch 210/2438  on Training is 70.15699052132702\n",
            "Epoch #6. Accuracy on batch 211/2438  on Training is 70.22405660377359\n",
            "Epoch #6. Accuracy on batch 212/2438  on Training is 70.21713615023474\n",
            "Epoch #6. Accuracy on batch 213/2438  on Training is 70.19567757009345\n",
            "Epoch #6. Accuracy on batch 214/2438  on Training is 70.17441860465117\n",
            "Epoch #6. Accuracy on batch 215/2438  on Training is 70.22569444444444\n",
            "Epoch #6. Accuracy on batch 216/2438  on Training is 70.21889400921658\n",
            "Epoch #6. Accuracy on batch 217/2438  on Training is 70.26949541284404\n",
            "Epoch #6. Accuracy on batch 218/2438  on Training is 70.27682648401826\n",
            "Epoch #6. Accuracy on batch 219/2438  on Training is 70.29829545454545\n",
            "Batch Id 220/2438 is having training loss of 1.0777301788330078\n",
            "0.6619012355804443\n",
            "Epoch #6. Accuracy on batch 220/2438  on Training is 70.34785067873302\n",
            "Epoch #6. Accuracy on batch 221/2438  on Training is 70.32657657657657\n",
            "Epoch #6. Accuracy on batch 222/2438  on Training is 70.2914798206278\n",
            "Epoch #6. Accuracy on batch 223/2438  on Training is 70.27064732142857\n",
            "Epoch #6. Accuracy on batch 224/2438  on Training is 70.23611111111111\n",
            "Epoch #6. Accuracy on batch 225/2438  on Training is 70.2433628318584\n",
            "Epoch #6. Accuracy on batch 226/2438  on Training is 70.16795154185021\n",
            "Epoch #6. Accuracy on batch 227/2438  on Training is 70.12061403508773\n",
            "Epoch #6. Accuracy on batch 228/2438  on Training is 70.14192139737992\n",
            "Epoch #6. Accuracy on batch 229/2438  on Training is 70.14945652173913\n",
            "Epoch #6. Accuracy on batch 230/2438  on Training is 70.12987012987013\n",
            "Epoch #6. Accuracy on batch 231/2438  on Training is 70.12392241379311\n",
            "Epoch #6. Accuracy on batch 232/2438  on Training is 70.10461373390558\n",
            "Epoch #6. Accuracy on batch 233/2438  on Training is 70.07211538461539\n",
            "Epoch #6. Accuracy on batch 234/2438  on Training is 70.06648936170212\n",
            "Epoch #6. Accuracy on batch 235/2438  on Training is 70.07415254237289\n",
            "Epoch #6. Accuracy on batch 236/2438  on Training is 70.06856540084388\n",
            "Epoch #6. Accuracy on batch 237/2438  on Training is 70.06302521008404\n",
            "Epoch #6. Accuracy on batch 238/2438  on Training is 70.03138075313808\n",
            "Epoch #6. Accuracy on batch 239/2438  on Training is 70.0390625\n",
            "Batch Id 240/2438 is having training loss of 1.0877331495285034\n",
            "0.9928126335144043\n",
            "Epoch #6. Accuracy on batch 240/2438  on Training is 70.04668049792531\n",
            "Epoch #6. Accuracy on batch 241/2438  on Training is 70.01549586776859\n",
            "Epoch #6. Accuracy on batch 242/2438  on Training is 70.06172839506173\n",
            "Epoch #6. Accuracy on batch 243/2438  on Training is 70.09477459016394\n",
            "Epoch #6. Accuracy on batch 244/2438  on Training is 70.03826530612245\n",
            "Epoch #6. Accuracy on batch 245/2438  on Training is 69.96951219512195\n",
            "Epoch #6. Accuracy on batch 246/2438  on Training is 69.98987854251013\n",
            "Epoch #6. Accuracy on batch 247/2438  on Training is 69.97227822580645\n",
            "Epoch #6. Accuracy on batch 248/2438  on Training is 69.96736947791165\n",
            "Epoch #6. Accuracy on batch 249/2438  on Training is 69.925\n",
            "Epoch #6. Accuracy on batch 250/2438  on Training is 69.89541832669323\n",
            "Epoch #6. Accuracy on batch 251/2438  on Training is 69.92807539682539\n",
            "Epoch #6. Accuracy on batch 252/2438  on Training is 69.93577075098814\n",
            "Epoch #6. Accuracy on batch 253/2438  on Training is 69.94340551181102\n",
            "Epoch #6. Accuracy on batch 254/2438  on Training is 69.92647058823529\n",
            "Epoch #6. Accuracy on batch 255/2438  on Training is 69.98291015625\n",
            "Epoch #6. Accuracy on batch 256/2438  on Training is 70.01459143968872\n",
            "Epoch #6. Accuracy on batch 257/2438  on Training is 69.98546511627907\n",
            "Epoch #6. Accuracy on batch 258/2438  on Training is 69.95656370656371\n",
            "Epoch #6. Accuracy on batch 259/2438  on Training is 69.93990384615384\n",
            "Batch Id 260/2438 is having training loss of 1.0865020751953125\n",
            "1.0256839990615845\n",
            "Epoch #6. Accuracy on batch 260/2438  on Training is 69.9353448275862\n",
            "Epoch #6. Accuracy on batch 261/2438  on Training is 69.95467557251908\n",
            "Epoch #6. Accuracy on batch 262/2438  on Training is 69.95009505703422\n",
            "Epoch #6. Accuracy on batch 263/2438  on Training is 69.94554924242425\n",
            "Epoch #6. Accuracy on batch 264/2438  on Training is 69.95283018867924\n",
            "Epoch #6. Accuracy on batch 265/2438  on Training is 69.91306390977444\n",
            "Epoch #6. Accuracy on batch 266/2438  on Training is 69.88529962546816\n",
            "Epoch #6. Accuracy on batch 267/2438  on Training is 69.86940298507463\n",
            "Epoch #6. Accuracy on batch 268/2438  on Training is 69.85362453531599\n",
            "Epoch #6. Accuracy on batch 269/2438  on Training is 69.88425925925925\n",
            "Epoch #6. Accuracy on batch 270/2438  on Training is 69.880073800738\n",
            "Epoch #6. Accuracy on batch 271/2438  on Training is 69.8529411764706\n",
            "Epoch #6. Accuracy on batch 272/2438  on Training is 69.8489010989011\n",
            "Epoch #6. Accuracy on batch 273/2438  on Training is 69.7764598540146\n",
            "Epoch #6. Accuracy on batch 274/2438  on Training is 69.76136363636364\n",
            "Epoch #6. Accuracy on batch 275/2438  on Training is 69.7463768115942\n",
            "Epoch #6. Accuracy on batch 276/2438  on Training is 69.7653429602888\n",
            "Epoch #6. Accuracy on batch 277/2438  on Training is 69.75044964028777\n",
            "Epoch #6. Accuracy on batch 278/2438  on Training is 69.75806451612904\n",
            "Epoch #6. Accuracy on batch 279/2438  on Training is 69.765625\n",
            "Batch Id 280/2438 is having training loss of 1.0944428443908691\n",
            "0.9990591406822205\n",
            "Epoch #6. Accuracy on batch 280/2438  on Training is 69.78425266903915\n",
            "Epoch #6. Accuracy on batch 281/2438  on Training is 69.73625886524823\n",
            "Epoch #6. Accuracy on batch 282/2438  on Training is 69.73277385159011\n",
            "Epoch #6. Accuracy on batch 283/2438  on Training is 69.77332746478874\n",
            "Epoch #6. Accuracy on batch 284/2438  on Training is 69.75877192982456\n",
            "Epoch #6. Accuracy on batch 285/2438  on Training is 69.75524475524476\n",
            "Epoch #6. Accuracy on batch 286/2438  on Training is 69.77351916376307\n",
            "Epoch #6. Accuracy on batch 287/2438  on Training is 69.79166666666667\n",
            "Epoch #6. Accuracy on batch 288/2438  on Training is 69.79887543252595\n",
            "Epoch #6. Accuracy on batch 289/2438  on Training is 69.82758620689656\n",
            "Epoch #6. Accuracy on batch 290/2438  on Training is 69.8131443298969\n",
            "Epoch #6. Accuracy on batch 291/2438  on Training is 69.83090753424658\n",
            "Epoch #6. Accuracy on batch 292/2438  on Training is 69.8485494880546\n",
            "Epoch #6. Accuracy on batch 293/2438  on Training is 69.79166666666667\n",
            "Epoch #6. Accuracy on batch 294/2438  on Training is 69.81991525423729\n",
            "Epoch #6. Accuracy on batch 295/2438  on Training is 69.82685810810811\n",
            "Epoch #6. Accuracy on batch 296/2438  on Training is 69.86531986531986\n",
            "Epoch #6. Accuracy on batch 297/2438  on Training is 69.84060402684564\n",
            "Epoch #6. Accuracy on batch 298/2438  on Training is 69.87876254180603\n",
            "Epoch #6. Accuracy on batch 299/2438  on Training is 69.90625\n",
            "Batch Id 300/2438 is having training loss of 1.091847538948059\n",
            "1.4402529001235962\n",
            "Epoch #6. Accuracy on batch 300/2438  on Training is 69.89202657807309\n",
            "Epoch #6. Accuracy on batch 301/2438  on Training is 69.89859271523179\n",
            "Epoch #6. Accuracy on batch 302/2438  on Training is 69.87417491749174\n",
            "Epoch #6. Accuracy on batch 303/2438  on Training is 69.88075657894737\n",
            "Epoch #6. Accuracy on batch 304/2438  on Training is 69.88729508196721\n",
            "Epoch #6. Accuracy on batch 305/2438  on Training is 69.88357843137256\n",
            "Epoch #6. Accuracy on batch 306/2438  on Training is 69.9206026058632\n",
            "Epoch #6. Accuracy on batch 307/2438  on Training is 69.90665584415585\n",
            "Epoch #6. Accuracy on batch 308/2438  on Training is 69.93325242718447\n",
            "Epoch #6. Accuracy on batch 309/2438  on Training is 69.92943548387096\n",
            "Epoch #6. Accuracy on batch 310/2438  on Training is 69.90554662379421\n",
            "Epoch #6. Accuracy on batch 311/2438  on Training is 69.921875\n",
            "Epoch #6. Accuracy on batch 312/2438  on Training is 69.88817891373802\n",
            "Epoch #6. Accuracy on batch 313/2438  on Training is 69.90445859872611\n",
            "Epoch #6. Accuracy on batch 314/2438  on Training is 69.87103174603175\n",
            "Epoch #6. Accuracy on batch 315/2438  on Training is 69.85759493670886\n",
            "Epoch #6. Accuracy on batch 316/2438  on Training is 69.88367507886436\n",
            "Epoch #6. Accuracy on batch 317/2438  on Training is 69.88011006289308\n",
            "Epoch #6. Accuracy on batch 318/2438  on Training is 69.84717868338558\n",
            "Epoch #6. Accuracy on batch 319/2438  on Training is 69.833984375\n",
            "Batch Id 320/2438 is having training loss of 1.097329020500183\n",
            "1.452510118484497\n",
            "Epoch #6. Accuracy on batch 320/2438  on Training is 69.81113707165109\n",
            "Epoch #6. Accuracy on batch 321/2438  on Training is 69.81754658385093\n",
            "Epoch #6. Accuracy on batch 322/2438  on Training is 69.78521671826626\n",
            "Epoch #6. Accuracy on batch 323/2438  on Training is 69.79166666666667\n",
            "Epoch #6. Accuracy on batch 324/2438  on Training is 69.78846153846153\n",
            "Epoch #6. Accuracy on batch 325/2438  on Training is 69.82361963190183\n",
            "Epoch #6. Accuracy on batch 326/2438  on Training is 69.81077981651376\n",
            "Epoch #6. Accuracy on batch 327/2438  on Training is 69.80754573170732\n",
            "Epoch #6. Accuracy on batch 328/2438  on Training is 69.81382978723404\n",
            "Epoch #6. Accuracy on batch 329/2438  on Training is 69.76325757575758\n",
            "Epoch #6. Accuracy on batch 330/2438  on Training is 69.75075528700906\n",
            "Epoch #6. Accuracy on batch 331/2438  on Training is 69.75715361445783\n",
            "Epoch #6. Accuracy on batch 332/2438  on Training is 69.74474474474475\n",
            "Epoch #6. Accuracy on batch 333/2438  on Training is 69.74176646706587\n",
            "Epoch #6. Accuracy on batch 334/2438  on Training is 69.72014925373135\n",
            "Epoch #6. Accuracy on batch 335/2438  on Training is 69.7265625\n",
            "Epoch #6. Accuracy on batch 336/2438  on Training is 69.69584569732937\n",
            "Epoch #6. Accuracy on batch 337/2438  on Training is 69.71153846153847\n",
            "Epoch #6. Accuracy on batch 338/2438  on Training is 69.70870206489676\n",
            "Epoch #6. Accuracy on batch 339/2438  on Training is 69.73345588235294\n",
            "Batch Id 340/2438 is having training loss of 1.1027369499206543\n",
            "1.2083836793899536\n",
            "Epoch #6. Accuracy on batch 340/2438  on Training is 69.73057184750733\n",
            "Epoch #6. Accuracy on batch 341/2438  on Training is 69.69115497076024\n",
            "Epoch #6. Accuracy on batch 342/2438  on Training is 69.6884110787172\n",
            "Epoch #6. Accuracy on batch 343/2438  on Training is 69.7311046511628\n",
            "Epoch #6. Accuracy on batch 344/2438  on Training is 69.71920289855072\n",
            "Epoch #6. Accuracy on batch 345/2438  on Training is 69.72543352601156\n",
            "Epoch #6. Accuracy on batch 346/2438  on Training is 69.70461095100865\n",
            "Epoch #6. Accuracy on batch 347/2438  on Training is 69.66594827586206\n",
            "Epoch #6. Accuracy on batch 348/2438  on Training is 69.70809455587393\n",
            "Epoch #6. Accuracy on batch 349/2438  on Training is 69.70535714285714\n",
            "Epoch #6. Accuracy on batch 350/2438  on Training is 69.7204415954416\n",
            "Epoch #6. Accuracy on batch 351/2438  on Training is 69.7176846590909\n",
            "Epoch #6. Accuracy on batch 352/2438  on Training is 69.7415014164306\n",
            "Epoch #6. Accuracy on batch 353/2438  on Training is 69.73870056497175\n",
            "Epoch #6. Accuracy on batch 354/2438  on Training is 69.73591549295774\n",
            "Epoch #6. Accuracy on batch 355/2438  on Training is 69.7682584269663\n",
            "Epoch #6. Accuracy on batch 356/2438  on Training is 69.76540616246498\n",
            "Epoch #6. Accuracy on batch 357/2438  on Training is 69.71892458100558\n",
            "Epoch #6. Accuracy on batch 358/2438  on Training is 69.75104456824512\n",
            "Epoch #6. Accuracy on batch 359/2438  on Training is 69.73958333333333\n",
            "Batch Id 360/2438 is having training loss of 1.1049320697784424\n",
            "1.0379568338394165\n",
            "Epoch #6. Accuracy on batch 360/2438  on Training is 69.74549861495845\n",
            "Epoch #6. Accuracy on batch 361/2438  on Training is 69.7082182320442\n",
            "Epoch #6. Accuracy on batch 362/2438  on Training is 69.6711432506887\n",
            "Epoch #6. Accuracy on batch 363/2438  on Training is 69.6514423076923\n",
            "Epoch #6. Accuracy on batch 364/2438  on Training is 69.6318493150685\n",
            "Epoch #6. Accuracy on batch 365/2438  on Training is 69.6806693989071\n",
            "Epoch #6. Accuracy on batch 366/2438  on Training is 69.70367847411444\n",
            "Epoch #6. Accuracy on batch 367/2438  on Training is 69.7265625\n",
            "Epoch #6. Accuracy on batch 368/2438  on Training is 69.68157181571816\n",
            "Epoch #6. Accuracy on batch 369/2438  on Training is 69.72128378378379\n",
            "Epoch #6. Accuracy on batch 370/2438  on Training is 69.74393530997304\n",
            "Epoch #6. Accuracy on batch 371/2438  on Training is 69.73286290322581\n",
            "Epoch #6. Accuracy on batch 372/2438  on Training is 69.75536193029491\n",
            "Epoch #6. Accuracy on batch 373/2438  on Training is 69.76938502673796\n",
            "Epoch #6. Accuracy on batch 374/2438  on Training is 69.775\n",
            "Epoch #6. Accuracy on batch 375/2438  on Training is 69.80551861702128\n",
            "Epoch #6. Accuracy on batch 376/2438  on Training is 69.82758620689656\n",
            "Epoch #6. Accuracy on batch 377/2438  on Training is 69.83300264550265\n",
            "Epoch #6. Accuracy on batch 378/2438  on Training is 69.83014511873351\n",
            "Epoch #6. Accuracy on batch 379/2438  on Training is 69.82730263157895\n",
            "Batch Id 380/2438 is having training loss of 1.1038156747817993\n",
            "1.0765836238861084\n",
            "Epoch #6. Accuracy on batch 380/2438  on Training is 69.81627296587926\n",
            "Epoch #6. Accuracy on batch 381/2438  on Training is 69.83802356020942\n",
            "Epoch #6. Accuracy on batch 382/2438  on Training is 69.85966057441253\n",
            "Epoch #6. Accuracy on batch 383/2438  on Training is 69.8486328125\n",
            "Epoch #6. Accuracy on batch 384/2438  on Training is 69.82142857142857\n",
            "Epoch #6. Accuracy on batch 385/2438  on Training is 69.81055699481865\n",
            "Epoch #6. Accuracy on batch 386/2438  on Training is 69.81589147286822\n",
            "Epoch #6. Accuracy on batch 387/2438  on Training is 69.83730670103093\n",
            "Epoch #6. Accuracy on batch 388/2438  on Training is 69.8586118251928\n",
            "Epoch #6. Accuracy on batch 389/2438  on Training is 69.83974358974359\n",
            "Epoch #6. Accuracy on batch 390/2438  on Training is 69.8529411764706\n",
            "Epoch #6. Accuracy on batch 391/2438  on Training is 69.82621173469387\n",
            "Epoch #6. Accuracy on batch 392/2438  on Training is 69.82347328244275\n",
            "Epoch #6. Accuracy on batch 393/2438  on Training is 69.86833756345177\n",
            "Epoch #6. Accuracy on batch 394/2438  on Training is 69.87341772151899\n",
            "Epoch #6. Accuracy on batch 395/2438  on Training is 69.8705808080808\n",
            "Epoch #6. Accuracy on batch 396/2438  on Training is 69.89137279596977\n",
            "Epoch #6. Accuracy on batch 397/2438  on Training is 69.88065326633166\n",
            "Epoch #6. Accuracy on batch 398/2438  on Training is 69.86998746867168\n",
            "Epoch #6. Accuracy on batch 399/2438  on Training is 69.859375\n",
            "Batch Id 400/2438 is having training loss of 1.1014084815979004\n",
            "1.1140490770339966\n",
            "Epoch #6. Accuracy on batch 400/2438  on Training is 69.856608478803\n",
            "Epoch #6. Accuracy on batch 401/2438  on Training is 69.86162935323384\n",
            "Epoch #6. Accuracy on batch 402/2438  on Training is 69.88988833746899\n",
            "Epoch #6. Accuracy on batch 403/2438  on Training is 69.88706683168317\n",
            "Epoch #6. Accuracy on batch 404/2438  on Training is 69.9074074074074\n",
            "Epoch #6. Accuracy on batch 405/2438  on Training is 69.95073891625616\n",
            "Epoch #6. Accuracy on batch 406/2438  on Training is 69.9477886977887\n",
            "Epoch #6. Accuracy on batch 407/2438  on Training is 69.91421568627452\n",
            "Epoch #6. Accuracy on batch 408/2438  on Training is 69.8960880195599\n",
            "Epoch #6. Accuracy on batch 409/2438  on Training is 69.90853658536585\n",
            "Epoch #6. Accuracy on batch 410/2438  on Training is 69.8905109489051\n",
            "Epoch #6. Accuracy on batch 411/2438  on Training is 69.91808252427184\n",
            "Epoch #6. Accuracy on batch 412/2438  on Training is 69.90768765133171\n",
            "Epoch #6. Accuracy on batch 413/2438  on Training is 69.9350845410628\n",
            "Epoch #6. Accuracy on batch 414/2438  on Training is 69.93222891566265\n",
            "Epoch #6. Accuracy on batch 415/2438  on Training is 69.92938701923077\n",
            "Epoch #6. Accuracy on batch 416/2438  on Training is 69.92655875299761\n",
            "Epoch #6. Accuracy on batch 417/2438  on Training is 69.93122009569377\n",
            "Epoch #6. Accuracy on batch 418/2438  on Training is 69.94331742243436\n",
            "Epoch #6. Accuracy on batch 419/2438  on Training is 69.94791666666667\n",
            "Batch Id 420/2438 is having training loss of 1.1026256084442139\n",
            "1.143122911453247\n",
            "Epoch #6. Accuracy on batch 420/2438  on Training is 69.937648456057\n",
            "Epoch #6. Accuracy on batch 421/2438  on Training is 69.97186018957346\n",
            "Epoch #6. Accuracy on batch 422/2438  on Training is 69.96897163120568\n",
            "Epoch #6. Accuracy on batch 423/2438  on Training is 69.9660966981132\n",
            "Epoch #6. Accuracy on batch 424/2438  on Training is 69.99264705882354\n",
            "Epoch #6. Accuracy on batch 425/2438  on Training is 70.01173708920187\n",
            "Epoch #6. Accuracy on batch 426/2438  on Training is 70.00878220140515\n",
            "Epoch #6. Accuracy on batch 427/2438  on Training is 69.9766355140187\n",
            "Epoch #6. Accuracy on batch 428/2438  on Training is 69.97377622377623\n",
            "Epoch #6. Accuracy on batch 429/2438  on Training is 69.99273255813954\n",
            "Epoch #6. Accuracy on batch 430/2438  on Training is 69.99709976798144\n",
            "Epoch #6. Accuracy on batch 431/2438  on Training is 70.03038194444444\n",
            "Epoch #6. Accuracy on batch 432/2438  on Training is 70.00577367205543\n",
            "Epoch #6. Accuracy on batch 433/2438  on Training is 70.02448156682027\n",
            "Epoch #6. Accuracy on batch 434/2438  on Training is 70.04310344827586\n",
            "Epoch #6. Accuracy on batch 435/2438  on Training is 70.01146788990826\n",
            "Epoch #6. Accuracy on batch 436/2438  on Training is 70.00143020594966\n",
            "Epoch #6. Accuracy on batch 437/2438  on Training is 70.02711187214612\n",
            "Epoch #6. Accuracy on batch 438/2438  on Training is 70.04555808656036\n",
            "Epoch #6. Accuracy on batch 439/2438  on Training is 70.04261363636364\n",
            "Batch Id 440/2438 is having training loss of 1.0989409685134888\n",
            "1.227195382118225\n",
            "Epoch #6. Accuracy on batch 440/2438  on Training is 70.046768707483\n",
            "Epoch #6. Accuracy on batch 441/2438  on Training is 70.04383484162896\n",
            "Epoch #6. Accuracy on batch 442/2438  on Training is 70.03386004514672\n",
            "Epoch #6. Accuracy on batch 443/2438  on Training is 70.02393018018019\n",
            "Epoch #6. Accuracy on batch 444/2438  on Training is 70.00702247191012\n",
            "Epoch #6. Accuracy on batch 445/2438  on Training is 69.99719730941705\n",
            "Epoch #6. Accuracy on batch 446/2438  on Training is 70.0153803131991\n",
            "Epoch #6. Accuracy on batch 447/2438  on Training is 70.04045758928571\n",
            "Epoch #6. Accuracy on batch 448/2438  on Training is 70.06542316258351\n",
            "Epoch #6. Accuracy on batch 449/2438  on Training is 70.09027777777777\n",
            "Epoch #6. Accuracy on batch 450/2438  on Training is 70.10116407982261\n",
            "Epoch #6. Accuracy on batch 451/2438  on Training is 70.11891592920354\n",
            "Epoch #6. Accuracy on batch 452/2438  on Training is 70.08830022075055\n",
            "Epoch #6. Accuracy on batch 453/2438  on Training is 70.07846916299559\n",
            "Epoch #6. Accuracy on batch 454/2438  on Training is 70.06868131868131\n",
            "Epoch #6. Accuracy on batch 455/2438  on Training is 70.1000548245614\n",
            "Epoch #6. Accuracy on batch 456/2438  on Training is 70.10393873085339\n",
            "Epoch #6. Accuracy on batch 457/2438  on Training is 70.10098253275109\n",
            "Epoch #6. Accuracy on batch 458/2438  on Training is 70.09123093681917\n",
            "Epoch #6. Accuracy on batch 459/2438  on Training is 70.08152173913044\n",
            "Batch Id 460/2438 is having training loss of 1.0987510681152344\n",
            "1.036659598350525\n",
            "Epoch #6. Accuracy on batch 460/2438  on Training is 70.0718546637744\n",
            "Epoch #6. Accuracy on batch 461/2438  on Training is 70.0284090909091\n",
            "Epoch #6. Accuracy on batch 462/2438  on Training is 70.00539956803456\n",
            "Epoch #6. Accuracy on batch 463/2438  on Training is 70.01616379310344\n",
            "Epoch #6. Accuracy on batch 464/2438  on Training is 70.02016129032258\n",
            "Epoch #6. Accuracy on batch 465/2438  on Training is 69.99061158798283\n",
            "Epoch #6. Accuracy on batch 466/2438  on Training is 69.9478051391863\n",
            "Epoch #6. Accuracy on batch 467/2438  on Training is 69.93856837606837\n",
            "Epoch #6. Accuracy on batch 468/2438  on Training is 69.9360341151386\n",
            "Epoch #6. Accuracy on batch 469/2438  on Training is 69.96010638297872\n",
            "Epoch #6. Accuracy on batch 470/2438  on Training is 69.95753715498938\n",
            "Epoch #6. Accuracy on batch 471/2438  on Training is 69.94835805084746\n",
            "Epoch #6. Accuracy on batch 472/2438  on Training is 69.9392177589852\n",
            "Epoch #6. Accuracy on batch 473/2438  on Training is 69.95648734177215\n",
            "Epoch #6. Accuracy on batch 474/2438  on Training is 69.94736842105263\n",
            "Epoch #6. Accuracy on batch 475/2438  on Training is 69.93172268907563\n",
            "Epoch #6. Accuracy on batch 476/2438  on Training is 69.92924528301887\n",
            "Epoch #6. Accuracy on batch 477/2438  on Training is 69.92024058577405\n",
            "Epoch #6. Accuracy on batch 478/2438  on Training is 69.89170146137788\n",
            "Epoch #6. Accuracy on batch 479/2438  on Training is 69.90885416666667\n",
            "Batch Id 480/2438 is having training loss of 1.1032954454421997\n",
            "1.218050241470337\n",
            "Epoch #6. Accuracy on batch 480/2438  on Training is 69.9064449064449\n",
            "Epoch #6. Accuracy on batch 481/2438  on Training is 69.89107883817428\n",
            "Epoch #6. Accuracy on batch 482/2438  on Training is 69.92106625258799\n",
            "Epoch #6. Accuracy on batch 483/2438  on Training is 69.93801652892562\n",
            "Epoch #6. Accuracy on batch 484/2438  on Training is 69.96778350515464\n",
            "Epoch #6. Accuracy on batch 485/2438  on Training is 69.9266975308642\n",
            "Epoch #6. Accuracy on batch 486/2438  on Training is 69.91144763860369\n",
            "Epoch #6. Accuracy on batch 487/2438  on Training is 69.89626024590164\n",
            "Epoch #6. Accuracy on batch 488/2438  on Training is 69.9066973415133\n",
            "Epoch #6. Accuracy on batch 489/2438  on Training is 69.90433673469387\n",
            "Epoch #6. Accuracy on batch 490/2438  on Training is 69.95290224032587\n",
            "Epoch #6. Accuracy on batch 491/2438  on Training is 69.95045731707317\n",
            "Epoch #6. Accuracy on batch 492/2438  on Training is 69.97337728194726\n",
            "Epoch #6. Accuracy on batch 493/2438  on Training is 69.9709008097166\n",
            "Epoch #6. Accuracy on batch 494/2438  on Training is 70.0\n",
            "Epoch #6. Accuracy on batch 495/2438  on Training is 70.0163810483871\n",
            "Epoch #6. Accuracy on batch 496/2438  on Training is 70.03269617706238\n",
            "Epoch #6. Accuracy on batch 497/2438  on Training is 70.00502008032129\n",
            "Epoch #6. Accuracy on batch 498/2438  on Training is 70.00876753507013\n",
            "Epoch #6. Accuracy on batch 499/2438  on Training is 70.00625\n",
            "Batch Id 500/2438 is having training loss of 1.1019443273544312\n",
            "1.548354148864746\n",
            "Epoch #6. Accuracy on batch 500/2438  on Training is 69.97255489021956\n",
            "Epoch #6. Accuracy on batch 501/2438  on Training is 69.97634462151395\n",
            "Epoch #6. Accuracy on batch 502/2438  on Training is 69.96148111332008\n",
            "Epoch #6. Accuracy on batch 503/2438  on Training is 69.9342757936508\n",
            "Epoch #6. Accuracy on batch 504/2438  on Training is 69.93811881188118\n",
            "Epoch #6. Accuracy on batch 505/2438  on Training is 69.95429841897233\n",
            "Epoch #6. Accuracy on batch 506/2438  on Training is 69.93343195266272\n",
            "Epoch #6. Accuracy on batch 507/2438  on Training is 69.95570866141732\n",
            "Epoch #6. Accuracy on batch 508/2438  on Training is 69.95333988212181\n",
            "Epoch #6. Accuracy on batch 509/2438  on Training is 69.97549019607843\n",
            "Epoch #6. Accuracy on batch 510/2438  on Training is 69.96086105675147\n",
            "Epoch #6. Accuracy on batch 511/2438  on Training is 69.964599609375\n",
            "Epoch #6. Accuracy on batch 512/2438  on Training is 69.95614035087719\n",
            "Epoch #6. Accuracy on batch 513/2438  on Training is 69.9477140077821\n",
            "Epoch #6. Accuracy on batch 514/2438  on Training is 69.92718446601941\n",
            "Epoch #6. Accuracy on batch 515/2438  on Training is 69.90067829457364\n",
            "Epoch #6. Accuracy on batch 516/2438  on Training is 69.90449709864603\n",
            "Epoch #6. Accuracy on batch 517/2438  on Training is 69.87813706563706\n",
            "Epoch #6. Accuracy on batch 518/2438  on Training is 69.88800578034682\n",
            "Epoch #6. Accuracy on batch 519/2438  on Training is 69.8858173076923\n",
            "Batch Id 520/2438 is having training loss of 1.1026206016540527\n",
            "0.6440792083740234\n",
            "Epoch #6. Accuracy on batch 520/2438  on Training is 69.91362763915546\n",
            "Epoch #6. Accuracy on batch 521/2438  on Training is 69.92935823754789\n",
            "Epoch #6. Accuracy on batch 522/2438  on Training is 69.92710325047801\n",
            "Epoch #6. Accuracy on batch 523/2438  on Training is 69.91292938931298\n",
            "Epoch #6. Accuracy on batch 524/2438  on Training is 69.9047619047619\n",
            "Epoch #6. Accuracy on batch 525/2438  on Training is 69.91444866920152\n",
            "Epoch #6. Accuracy on batch 526/2438  on Training is 69.93002846299811\n",
            "Epoch #6. Accuracy on batch 527/2438  on Training is 69.92779356060606\n",
            "Epoch #6. Accuracy on batch 528/2438  on Training is 69.89012287334593\n",
            "Epoch #6. Accuracy on batch 529/2438  on Training is 69.91155660377359\n",
            "Epoch #6. Accuracy on batch 530/2438  on Training is 69.89171374764595\n",
            "Epoch #6. Accuracy on batch 531/2438  on Training is 69.88369360902256\n",
            "Epoch #6. Accuracy on batch 532/2438  on Training is 69.86984052532833\n",
            "Epoch #6. Accuracy on batch 533/2438  on Training is 69.8501872659176\n",
            "Epoch #6. Accuracy on batch 534/2438  on Training is 69.85397196261682\n",
            "Epoch #6. Accuracy on batch 535/2438  on Training is 69.82859141791045\n",
            "Epoch #6. Accuracy on batch 536/2438  on Training is 69.85567970204842\n",
            "Epoch #6. Accuracy on batch 537/2438  on Training is 69.85943308550186\n",
            "Epoch #6. Accuracy on batch 538/2438  on Training is 69.84577922077922\n",
            "Epoch #6. Accuracy on batch 539/2438  on Training is 69.84953703703704\n",
            "Batch Id 540/2438 is having training loss of 1.1042637825012207\n",
            "1.1995575428009033\n",
            "Epoch #6. Accuracy on batch 540/2438  on Training is 69.83017560073937\n",
            "Epoch #6. Accuracy on batch 541/2438  on Training is 69.78782287822878\n",
            "Epoch #6. Accuracy on batch 542/2438  on Training is 69.78591160220995\n",
            "Epoch #6. Accuracy on batch 543/2438  on Training is 69.7954963235294\n",
            "Epoch #6. Accuracy on batch 544/2438  on Training is 69.81651376146789\n",
            "Epoch #6. Accuracy on batch 545/2438  on Training is 69.80883699633699\n",
            "Epoch #6. Accuracy on batch 546/2438  on Training is 69.81832723948811\n",
            "Epoch #6. Accuracy on batch 547/2438  on Training is 69.81637773722628\n",
            "Epoch #6. Accuracy on batch 548/2438  on Training is 69.79735883424408\n",
            "Epoch #6. Accuracy on batch 549/2438  on Training is 69.7784090909091\n",
            "Epoch #6. Accuracy on batch 550/2438  on Training is 69.77087114337569\n",
            "Epoch #6. Accuracy on batch 551/2438  on Training is 69.76336050724638\n",
            "Epoch #6. Accuracy on batch 552/2438  on Training is 69.75587703435805\n",
            "Epoch #6. Accuracy on batch 553/2438  on Training is 69.75970216606498\n",
            "Epoch #6. Accuracy on batch 554/2438  on Training is 69.75788288288288\n",
            "Epoch #6. Accuracy on batch 555/2438  on Training is 69.7560701438849\n",
            "Epoch #6. Accuracy on batch 556/2438  on Training is 69.74865350089766\n",
            "Epoch #6. Accuracy on batch 557/2438  on Training is 69.75246415770609\n",
            "Epoch #6. Accuracy on batch 558/2438  on Training is 69.73949016100178\n",
            "Epoch #6. Accuracy on batch 559/2438  on Training is 69.74330357142857\n",
            "Batch Id 560/2438 is having training loss of 1.1062138080596924\n",
            "0.7770701050758362\n",
            "Epoch #6. Accuracy on batch 560/2438  on Training is 69.75824420677363\n",
            "Epoch #6. Accuracy on batch 561/2438  on Training is 69.7786921708185\n",
            "Epoch #6. Accuracy on batch 562/2438  on Training is 69.76576376554173\n",
            "Epoch #6. Accuracy on batch 563/2438  on Training is 69.76396276595744\n",
            "Epoch #6. Accuracy on batch 564/2438  on Training is 69.78429203539822\n",
            "Epoch #6. Accuracy on batch 565/2438  on Training is 69.79350706713781\n",
            "Epoch #6. Accuracy on batch 566/2438  on Training is 69.75859788359789\n",
            "Epoch #6. Accuracy on batch 567/2438  on Training is 69.75132042253522\n",
            "Epoch #6. Accuracy on batch 568/2438  on Training is 69.72210017574693\n",
            "Epoch #6. Accuracy on batch 569/2438  on Training is 69.73684210526316\n",
            "Epoch #6. Accuracy on batch 570/2438  on Training is 69.7460595446585\n",
            "Epoch #6. Accuracy on batch 571/2438  on Training is 69.73339160839161\n",
            "Epoch #6. Accuracy on batch 572/2438  on Training is 69.74258289703316\n",
            "Epoch #6. Accuracy on batch 573/2438  on Training is 69.76263066202091\n",
            "Epoch #6. Accuracy on batch 574/2438  on Training is 69.7554347826087\n",
            "Epoch #6. Accuracy on batch 575/2438  on Training is 69.76453993055556\n",
            "Epoch #6. Accuracy on batch 576/2438  on Training is 69.76278162911612\n",
            "Epoch #6. Accuracy on batch 577/2438  on Training is 69.78806228373702\n",
            "Epoch #6. Accuracy on batch 578/2438  on Training is 69.80785837651122\n",
            "Epoch #6. Accuracy on batch 579/2438  on Training is 69.80064655172414\n",
            "Batch Id 580/2438 is having training loss of 1.1050511598587036\n",
            "1.1952179670333862\n",
            "Epoch #6. Accuracy on batch 580/2438  on Training is 69.7880808950086\n",
            "Epoch #6. Accuracy on batch 581/2438  on Training is 69.79166666666667\n",
            "Epoch #6. Accuracy on batch 582/2438  on Training is 69.77915951972555\n",
            "Epoch #6. Accuracy on batch 583/2438  on Training is 69.78274828767124\n",
            "Epoch #6. Accuracy on batch 584/2438  on Training is 69.78098290598291\n",
            "Epoch #6. Accuracy on batch 585/2438  on Training is 69.77922354948805\n",
            "Epoch #6. Accuracy on batch 586/2438  on Training is 69.76682282793867\n",
            "Epoch #6. Accuracy on batch 587/2438  on Training is 69.75446428571429\n",
            "Epoch #6. Accuracy on batch 588/2438  on Training is 69.7633701188455\n",
            "Epoch #6. Accuracy on batch 589/2438  on Training is 69.76694915254237\n",
            "Epoch #6. Accuracy on batch 590/2438  on Training is 69.77051607445009\n",
            "Epoch #6. Accuracy on batch 591/2438  on Training is 69.77407094594595\n",
            "Epoch #6. Accuracy on batch 592/2438  on Training is 69.77234401349072\n",
            "Epoch #6. Accuracy on batch 593/2438  on Training is 69.78114478114477\n",
            "Epoch #6. Accuracy on batch 594/2438  on Training is 69.77941176470588\n",
            "Epoch #6. Accuracy on batch 595/2438  on Training is 69.79865771812081\n",
            "Epoch #6. Accuracy on batch 596/2438  on Training is 69.80737018425461\n",
            "Epoch #6. Accuracy on batch 597/2438  on Training is 69.82127926421404\n",
            "Epoch #6. Accuracy on batch 598/2438  on Training is 69.84035893155259\n",
            "Epoch #6. Accuracy on batch 599/2438  on Training is 69.83854166666667\n",
            "Batch Id 600/2438 is having training loss of 1.1037888526916504\n",
            "0.8434566259384155\n",
            "Epoch #6. Accuracy on batch 600/2438  on Training is 69.84712978369384\n",
            "Epoch #6. Accuracy on batch 601/2438  on Training is 69.8608803986711\n",
            "Epoch #6. Accuracy on batch 602/2438  on Training is 69.86422056384743\n",
            "Epoch #6. Accuracy on batch 603/2438  on Training is 69.84685430463576\n",
            "Epoch #6. Accuracy on batch 604/2438  on Training is 69.86053719008264\n",
            "Epoch #6. Accuracy on batch 605/2438  on Training is 69.86901815181518\n",
            "Epoch #6. Accuracy on batch 606/2438  on Training is 69.86202635914333\n",
            "Epoch #6. Accuracy on batch 607/2438  on Training is 69.8756167763158\n",
            "Epoch #6. Accuracy on batch 608/2438  on Training is 69.86863711001642\n",
            "Epoch #6. Accuracy on batch 609/2438  on Training is 69.84631147540983\n",
            "Epoch #6. Accuracy on batch 610/2438  on Training is 69.82917348608838\n",
            "Epoch #6. Accuracy on batch 611/2438  on Training is 69.83251633986929\n",
            "Epoch #6. Accuracy on batch 612/2438  on Training is 69.84094616639479\n",
            "Epoch #6. Accuracy on batch 613/2438  on Training is 69.8391693811075\n",
            "Epoch #6. Accuracy on batch 614/2438  on Training is 69.82215447154472\n",
            "Epoch #6. Accuracy on batch 615/2438  on Training is 69.82041396103897\n",
            "Epoch #6. Accuracy on batch 616/2438  on Training is 69.83387358184766\n",
            "Epoch #6. Accuracy on batch 617/2438  on Training is 69.8169498381877\n",
            "Epoch #6. Accuracy on batch 618/2438  on Training is 69.82532310177706\n",
            "Epoch #6. Accuracy on batch 619/2438  on Training is 69.8336693548387\n",
            "Batch Id 620/2438 is having training loss of 1.1055591106414795\n",
            "0.7371737957000732\n",
            "Epoch #6. Accuracy on batch 620/2438  on Training is 69.8419887278583\n",
            "Epoch #6. Accuracy on batch 621/2438  on Training is 69.85028135048232\n",
            "Epoch #6. Accuracy on batch 622/2438  on Training is 69.84349919743178\n",
            "Epoch #6. Accuracy on batch 623/2438  on Training is 69.8467548076923\n",
            "Epoch #6. Accuracy on batch 624/2438  on Training is 69.85\n",
            "Epoch #6. Accuracy on batch 625/2438  on Training is 69.8582268370607\n",
            "Epoch #6. Accuracy on batch 626/2438  on Training is 69.84649122807018\n",
            "Epoch #6. Accuracy on batch 627/2438  on Training is 69.82981687898089\n",
            "Epoch #6. Accuracy on batch 628/2438  on Training is 69.84797297297297\n",
            "Epoch #6. Accuracy on batch 629/2438  on Training is 69.84126984126983\n",
            "Epoch #6. Accuracy on batch 630/2438  on Training is 69.82963549920761\n",
            "Epoch #6. Accuracy on batch 631/2438  on Training is 69.8229825949367\n",
            "Epoch #6. Accuracy on batch 632/2438  on Training is 69.83116113744076\n",
            "Epoch #6. Accuracy on batch 633/2438  on Training is 69.84917192429022\n",
            "Epoch #6. Accuracy on batch 634/2438  on Training is 69.82775590551181\n",
            "Epoch #6. Accuracy on batch 635/2438  on Training is 69.82606132075472\n",
            "Epoch #6. Accuracy on batch 636/2438  on Training is 69.82927786499215\n",
            "Epoch #6. Accuracy on batch 637/2438  on Training is 69.83738244514106\n",
            "Epoch #6. Accuracy on batch 638/2438  on Training is 69.83568075117371\n",
            "Epoch #6. Accuracy on batch 639/2438  on Training is 69.84375\n",
            "Batch Id 640/2438 is having training loss of 1.1071693897247314\n",
            "1.492959976196289\n",
            "Epoch #6. Accuracy on batch 640/2438  on Training is 69.83716848673947\n",
            "Epoch #6. Accuracy on batch 641/2438  on Training is 69.8257398753894\n",
            "Epoch #6. Accuracy on batch 642/2438  on Training is 69.8094867807154\n",
            "Epoch #6. Accuracy on batch 643/2438  on Training is 69.81269409937889\n",
            "Epoch #6. Accuracy on batch 644/2438  on Training is 69.81589147286822\n",
            "Epoch #6. Accuracy on batch 645/2438  on Training is 69.80456656346749\n",
            "Epoch #6. Accuracy on batch 646/2438  on Training is 69.80293663060279\n",
            "Epoch #6. Accuracy on batch 647/2438  on Training is 69.78202160493827\n",
            "Epoch #6. Accuracy on batch 648/2438  on Training is 69.7804314329738\n",
            "Epoch #6. Accuracy on batch 649/2438  on Training is 69.77884615384616\n",
            "Epoch #6. Accuracy on batch 650/2438  on Training is 69.78206605222734\n",
            "Epoch #6. Accuracy on batch 651/2438  on Training is 69.77569018404908\n",
            "Epoch #6. Accuracy on batch 652/2438  on Training is 69.77890505359878\n",
            "Epoch #6. Accuracy on batch 653/2438  on Training is 69.80600152905198\n",
            "Epoch #6. Accuracy on batch 654/2438  on Training is 69.81393129770993\n",
            "Epoch #6. Accuracy on batch 655/2438  on Training is 69.79325457317073\n",
            "Epoch #6. Accuracy on batch 656/2438  on Training is 69.78215372907154\n",
            "Epoch #6. Accuracy on batch 657/2438  on Training is 69.79483282674772\n",
            "Epoch #6. Accuracy on batch 658/2438  on Training is 69.78850531107739\n",
            "Epoch #6. Accuracy on batch 659/2438  on Training is 69.76325757575758\n",
            "Batch Id 660/2438 is having training loss of 1.1084928512573242\n",
            "1.1525989770889282\n",
            "Epoch #6. Accuracy on batch 660/2438  on Training is 69.76172465960666\n",
            "Epoch #6. Accuracy on batch 661/2438  on Training is 69.76019637462235\n",
            "Epoch #6. Accuracy on batch 662/2438  on Training is 69.77281297134239\n",
            "Epoch #6. Accuracy on batch 663/2438  on Training is 69.76185993975903\n",
            "Epoch #6. Accuracy on batch 664/2438  on Training is 69.76973684210526\n",
            "Epoch #6. Accuracy on batch 665/2438  on Training is 69.77289789789789\n",
            "Epoch #6. Accuracy on batch 666/2438  on Training is 69.78073463268366\n",
            "Epoch #6. Accuracy on batch 667/2438  on Training is 69.77919161676647\n",
            "Epoch #6. Accuracy on batch 668/2438  on Training is 69.77765321375186\n",
            "Epoch #6. Accuracy on batch 669/2438  on Training is 69.78078358208955\n",
            "Epoch #6. Accuracy on batch 670/2438  on Training is 69.77924739195231\n",
            "Epoch #6. Accuracy on batch 671/2438  on Training is 69.77306547619048\n",
            "Epoch #6. Accuracy on batch 672/2438  on Training is 69.76225854383358\n",
            "Epoch #6. Accuracy on batch 673/2438  on Training is 69.74221068249258\n",
            "Epoch #6. Accuracy on batch 674/2438  on Training is 69.73611111111111\n",
            "Epoch #6. Accuracy on batch 675/2438  on Training is 69.74389792899409\n",
            "Epoch #6. Accuracy on batch 676/2438  on Training is 69.75166174298376\n",
            "Epoch #6. Accuracy on batch 677/2438  on Training is 69.74557522123894\n",
            "Epoch #6. Accuracy on batch 678/2438  on Training is 69.7441089837997\n",
            "Epoch #6. Accuracy on batch 679/2438  on Training is 69.73345588235294\n",
            "Batch Id 680/2438 is having training loss of 1.1099417209625244\n",
            "0.7775095105171204\n",
            "Epoch #6. Accuracy on batch 680/2438  on Training is 69.7503671071953\n",
            "Epoch #6. Accuracy on batch 681/2438  on Training is 69.75806451612904\n",
            "Epoch #6. Accuracy on batch 682/2438  on Training is 69.75658857979502\n",
            "Epoch #6. Accuracy on batch 683/2438  on Training is 69.73684210526316\n",
            "Epoch #6. Accuracy on batch 684/2438  on Training is 69.73540145985402\n",
            "Epoch #6. Accuracy on batch 685/2438  on Training is 69.73852040816327\n",
            "Epoch #6. Accuracy on batch 686/2438  on Training is 69.74163027656478\n",
            "Epoch #6. Accuracy on batch 687/2438  on Training is 69.74473110465117\n",
            "Epoch #6. Accuracy on batch 688/2438  on Training is 69.75235849056604\n",
            "Epoch #6. Accuracy on batch 689/2438  on Training is 69.75090579710145\n",
            "Epoch #6. Accuracy on batch 690/2438  on Training is 69.75397973950795\n",
            "Epoch #6. Accuracy on batch 691/2438  on Training is 69.72994942196532\n",
            "Epoch #6. Accuracy on batch 692/2438  on Training is 69.72853535353535\n",
            "Epoch #6. Accuracy on batch 693/2438  on Training is 69.71811959654178\n",
            "Epoch #6. Accuracy on batch 694/2438  on Training is 69.73021582733813\n",
            "Epoch #6. Accuracy on batch 695/2438  on Training is 69.73778735632185\n",
            "Epoch #6. Accuracy on batch 696/2438  on Training is 69.73188665710187\n",
            "Epoch #6. Accuracy on batch 697/2438  on Training is 69.73943409742121\n",
            "Epoch #6. Accuracy on batch 698/2438  on Training is 69.72907725321889\n",
            "Epoch #6. Accuracy on batch 699/2438  on Training is 69.74553571428571\n",
            "Batch Id 700/2438 is having training loss of 1.1102434396743774\n",
            "0.9369633793830872\n",
            "Epoch #6. Accuracy on batch 700/2438  on Training is 69.74411554921541\n",
            "Epoch #6. Accuracy on batch 701/2438  on Training is 69.74269943019944\n",
            "Epoch #6. Accuracy on batch 702/2438  on Training is 69.75462304409673\n",
            "Epoch #6. Accuracy on batch 703/2438  on Training is 69.75763494318181\n",
            "Epoch #6. Accuracy on batch 704/2438  on Training is 69.74734042553192\n",
            "Epoch #6. Accuracy on batch 705/2438  on Training is 69.75920679886686\n",
            "Epoch #6. Accuracy on batch 706/2438  on Training is 69.77103960396039\n",
            "Epoch #6. Accuracy on batch 707/2438  on Training is 69.77842514124293\n",
            "Epoch #6. Accuracy on batch 708/2438  on Training is 69.79019746121297\n",
            "Epoch #6. Accuracy on batch 709/2438  on Training is 69.7931338028169\n",
            "Epoch #6. Accuracy on batch 710/2438  on Training is 69.78727144866386\n",
            "Epoch #6. Accuracy on batch 711/2438  on Training is 69.78142556179775\n",
            "Epoch #6. Accuracy on batch 712/2438  on Training is 69.78436185133239\n",
            "Epoch #6. Accuracy on batch 713/2438  on Training is 69.76102941176471\n",
            "Epoch #6. Accuracy on batch 714/2438  on Training is 69.75524475524476\n",
            "Epoch #6. Accuracy on batch 715/2438  on Training is 69.75820530726257\n",
            "Epoch #6. Accuracy on batch 716/2438  on Training is 69.7655160390516\n",
            "Epoch #6. Accuracy on batch 717/2438  on Training is 69.76410167130919\n",
            "Epoch #6. Accuracy on batch 718/2438  on Training is 69.78007649513212\n",
            "Epoch #6. Accuracy on batch 719/2438  on Training is 69.78732638888889\n",
            "Batch Id 720/2438 is having training loss of 1.1092989444732666\n",
            "0.8900493383407593\n",
            "Epoch #6. Accuracy on batch 720/2438  on Training is 69.79022191400833\n",
            "Epoch #6. Accuracy on batch 721/2438  on Training is 69.7887811634349\n",
            "Epoch #6. Accuracy on batch 722/2438  on Training is 69.774377593361\n",
            "Epoch #6. Accuracy on batch 723/2438  on Training is 69.75569751381215\n",
            "Epoch #6. Accuracy on batch 724/2438  on Training is 69.77586206896552\n",
            "Epoch #6. Accuracy on batch 725/2438  on Training is 69.80027548209367\n",
            "Epoch #6. Accuracy on batch 726/2438  on Training is 69.79023383768913\n",
            "Epoch #6. Accuracy on batch 727/2438  on Training is 69.79309752747253\n",
            "Epoch #6. Accuracy on batch 728/2438  on Training is 69.82167352537724\n",
            "Epoch #6. Accuracy on batch 729/2438  on Training is 69.81592465753425\n",
            "Epoch #6. Accuracy on batch 730/2438  on Training is 69.84011627906976\n",
            "Epoch #6. Accuracy on batch 731/2438  on Training is 69.83435792349727\n",
            "Epoch #6. Accuracy on batch 732/2438  on Training is 69.81582537517053\n",
            "Epoch #6. Accuracy on batch 733/2438  on Training is 69.81437329700273\n",
            "Epoch #6. Accuracy on batch 734/2438  on Training is 69.81292517006803\n",
            "Epoch #6. Accuracy on batch 735/2438  on Training is 69.81148097826087\n",
            "Epoch #6. Accuracy on batch 736/2438  on Training is 69.81428086838535\n",
            "Epoch #6. Accuracy on batch 737/2438  on Training is 69.80860433604336\n",
            "Epoch #6. Accuracy on batch 738/2438  on Training is 69.7987144790257\n",
            "Epoch #6. Accuracy on batch 739/2438  on Training is 69.80574324324324\n",
            "Batch Id 740/2438 is having training loss of 1.1077226400375366\n",
            "0.665026068687439\n",
            "Epoch #6. Accuracy on batch 740/2438  on Training is 69.81697031039137\n",
            "Epoch #6. Accuracy on batch 741/2438  on Training is 69.83237870619946\n",
            "Epoch #6. Accuracy on batch 742/2438  on Training is 69.83092193808884\n",
            "Epoch #6. Accuracy on batch 743/2438  on Training is 69.8252688172043\n",
            "Epoch #6. Accuracy on batch 744/2438  on Training is 69.81963087248322\n",
            "Epoch #6. Accuracy on batch 745/2438  on Training is 69.82657506702412\n",
            "Epoch #6. Accuracy on batch 746/2438  on Training is 69.83350066934405\n",
            "Epoch #6. Accuracy on batch 747/2438  on Training is 69.81116310160428\n",
            "Epoch #6. Accuracy on batch 748/2438  on Training is 69.80974632843791\n",
            "Epoch #6. Accuracy on batch 749/2438  on Training is 69.81666666666666\n",
            "Epoch #6. Accuracy on batch 750/2438  on Training is 69.84021304926765\n",
            "Epoch #6. Accuracy on batch 751/2438  on Training is 69.86369680851064\n",
            "Epoch #6. Accuracy on batch 752/2438  on Training is 69.86636786188579\n",
            "Epoch #6. Accuracy on batch 753/2438  on Training is 69.86903183023873\n",
            "Epoch #6. Accuracy on batch 754/2438  on Training is 69.86341059602648\n",
            "Epoch #6. Accuracy on batch 755/2438  on Training is 69.88260582010582\n",
            "Epoch #6. Accuracy on batch 756/2438  on Training is 69.88523778071334\n",
            "Epoch #6. Accuracy on batch 757/2438  on Training is 69.8837401055409\n",
            "Epoch #6. Accuracy on batch 758/2438  on Training is 69.8822463768116\n",
            "Epoch #6. Accuracy on batch 759/2438  on Training is 69.88075657894737\n",
            "Batch Id 760/2438 is having training loss of 1.1049869060516357\n",
            "1.0727200508117676\n",
            "Epoch #6. Accuracy on batch 760/2438  on Training is 69.88337713534823\n",
            "Epoch #6. Accuracy on batch 761/2438  on Training is 69.89009186351706\n",
            "Epoch #6. Accuracy on batch 762/2438  on Training is 69.88040629095676\n",
            "Epoch #6. Accuracy on batch 763/2438  on Training is 69.88710732984293\n",
            "Epoch #6. Accuracy on batch 764/2438  on Training is 69.90196078431373\n",
            "Epoch #6. Accuracy on batch 765/2438  on Training is 69.91677545691905\n",
            "Epoch #6. Accuracy on batch 766/2438  on Training is 69.91932855280312\n",
            "Epoch #6. Accuracy on batch 767/2438  on Training is 69.8974609375\n",
            "Epoch #6. Accuracy on batch 768/2438  on Training is 69.90003250975293\n",
            "Epoch #6. Accuracy on batch 769/2438  on Training is 69.89448051948052\n",
            "Epoch #6. Accuracy on batch 770/2438  on Training is 69.8889429312581\n",
            "Epoch #6. Accuracy on batch 771/2438  on Training is 69.89556347150258\n",
            "Epoch #6. Accuracy on batch 772/2438  on Training is 69.90216688227684\n",
            "Epoch #6. Accuracy on batch 773/2438  on Training is 69.91279069767442\n",
            "Epoch #6. Accuracy on batch 774/2438  on Training is 69.90725806451613\n",
            "Epoch #6. Accuracy on batch 775/2438  on Training is 69.91382087628865\n",
            "Epoch #6. Accuracy on batch 776/2438  on Training is 69.89623552123552\n",
            "Epoch #6. Accuracy on batch 777/2438  on Training is 69.90279562982005\n",
            "Epoch #6. Accuracy on batch 778/2438  on Training is 69.89730423620026\n",
            "Epoch #6. Accuracy on batch 779/2438  on Training is 69.89583333333333\n",
            "Batch Id 780/2438 is having training loss of 1.1045081615447998\n",
            "1.5759347677230835\n",
            "Epoch #6. Accuracy on batch 780/2438  on Training is 69.88636363636364\n",
            "Epoch #6. Accuracy on batch 781/2438  on Training is 69.86892583120205\n",
            "Epoch #6. Accuracy on batch 782/2438  on Training is 69.84355044699872\n",
            "Epoch #6. Accuracy on batch 783/2438  on Training is 69.86208545918367\n",
            "Epoch #6. Accuracy on batch 784/2438  on Training is 69.8765923566879\n",
            "Epoch #6. Accuracy on batch 785/2438  on Training is 69.86323155216284\n",
            "Epoch #6. Accuracy on batch 786/2438  on Training is 69.85387547649302\n",
            "Epoch #6. Accuracy on batch 787/2438  on Training is 69.86040609137056\n",
            "Epoch #6. Accuracy on batch 788/2438  on Training is 69.8510773130545\n",
            "Epoch #6. Accuracy on batch 789/2438  on Training is 69.8496835443038\n",
            "Epoch #6. Accuracy on batch 790/2438  on Training is 69.84039190897597\n",
            "Epoch #6. Accuracy on batch 791/2438  on Training is 69.84296085858585\n",
            "Epoch #6. Accuracy on batch 792/2438  on Training is 69.85340479192938\n",
            "Epoch #6. Accuracy on batch 793/2438  on Training is 69.87562972292191\n",
            "Epoch #6. Accuracy on batch 794/2438  on Training is 69.87421383647799\n",
            "Epoch #6. Accuracy on batch 795/2438  on Training is 69.85709798994975\n",
            "Epoch #6. Accuracy on batch 796/2438  on Training is 69.85962986198244\n",
            "Epoch #6. Accuracy on batch 797/2438  on Training is 69.86607142857143\n",
            "Epoch #6. Accuracy on batch 798/2438  on Training is 69.8685857321652\n",
            "Epoch #6. Accuracy on batch 799/2438  on Training is 69.8671875\n",
            "Batch Id 800/2438 is having training loss of 1.1042060852050781\n",
            "0.653435230255127\n",
            "Epoch #6. Accuracy on batch 800/2438  on Training is 69.88139825218477\n",
            "Epoch #6. Accuracy on batch 801/2438  on Training is 69.86050498753117\n",
            "Epoch #6. Accuracy on batch 802/2438  on Training is 69.8785803237858\n",
            "Epoch #6. Accuracy on batch 803/2438  on Training is 69.88106343283582\n",
            "Epoch #6. Accuracy on batch 804/2438  on Training is 69.88354037267081\n",
            "Epoch #6. Accuracy on batch 805/2438  on Training is 69.8860111662531\n",
            "Epoch #6. Accuracy on batch 806/2438  on Training is 69.88847583643123\n",
            "Epoch #6. Accuracy on batch 807/2438  on Training is 69.87933168316832\n",
            "Epoch #6. Accuracy on batch 808/2438  on Training is 69.87407292954265\n",
            "Epoch #6. Accuracy on batch 809/2438  on Training is 69.88811728395062\n",
            "Epoch #6. Accuracy on batch 810/2438  on Training is 69.87515413070284\n",
            "Epoch #6. Accuracy on batch 811/2438  on Training is 69.88531403940887\n",
            "Epoch #6. Accuracy on batch 812/2438  on Training is 69.91082410824109\n",
            "Epoch #6. Accuracy on batch 813/2438  on Training is 69.90939803439804\n",
            "Epoch #6. Accuracy on batch 814/2438  on Training is 69.89647239263803\n",
            "Epoch #6. Accuracy on batch 815/2438  on Training is 69.91038602941177\n",
            "Epoch #6. Accuracy on batch 816/2438  on Training is 69.91279069767442\n",
            "Epoch #6. Accuracy on batch 817/2438  on Training is 69.90372860635696\n",
            "Epoch #6. Accuracy on batch 818/2438  on Training is 69.9137667887668\n",
            "Epoch #6. Accuracy on batch 819/2438  on Training is 69.9123475609756\n",
            "Batch Id 820/2438 is having training loss of 1.1018568277359009\n",
            "0.88914555311203\n",
            "Epoch #6. Accuracy on batch 820/2438  on Training is 69.91093179049939\n",
            "Epoch #6. Accuracy on batch 821/2438  on Training is 69.92472627737226\n",
            "Epoch #6. Accuracy on batch 822/2438  on Training is 69.93469015795868\n",
            "Epoch #6. Accuracy on batch 823/2438  on Training is 69.94842233009709\n",
            "Epoch #6. Accuracy on batch 824/2438  on Training is 69.9469696969697\n",
            "Epoch #6. Accuracy on batch 825/2438  on Training is 69.93417070217917\n",
            "Epoch #6. Accuracy on batch 826/2438  on Training is 69.94407496977026\n",
            "Epoch #6. Accuracy on batch 827/2438  on Training is 69.9615036231884\n",
            "Epoch #6. Accuracy on batch 828/2438  on Training is 69.95250301568154\n",
            "Epoch #6. Accuracy on batch 829/2438  on Training is 69.96611445783132\n",
            "Epoch #6. Accuracy on batch 830/2438  on Training is 69.97217208182911\n",
            "Epoch #6. Accuracy on batch 831/2438  on Training is 69.96319110576923\n",
            "Epoch #6. Accuracy on batch 832/2438  on Training is 69.97298919567827\n",
            "Epoch #6. Accuracy on batch 833/2438  on Training is 69.95653477218225\n",
            "Epoch #6. Accuracy on batch 834/2438  on Training is 69.97380239520957\n",
            "Epoch #6. Accuracy on batch 835/2438  on Training is 69.97607655502392\n",
            "Epoch #6. Accuracy on batch 836/2438  on Training is 69.97461170848267\n",
            "Epoch #6. Accuracy on batch 837/2438  on Training is 69.97687947494033\n",
            "Epoch #6. Accuracy on batch 838/2438  on Training is 69.96796781883194\n",
            "Epoch #6. Accuracy on batch 839/2438  on Training is 69.96279761904762\n",
            "Batch Id 840/2438 is having training loss of 1.1005849838256836\n",
            "1.0279643535614014\n",
            "Epoch #6. Accuracy on batch 840/2438  on Training is 69.96878715814506\n",
            "Epoch #6. Accuracy on batch 841/2438  on Training is 69.96362826603325\n",
            "Epoch #6. Accuracy on batch 842/2438  on Training is 69.95477461447213\n",
            "Epoch #6. Accuracy on batch 843/2438  on Training is 69.93483412322274\n",
            "Epoch #6. Accuracy on batch 844/2438  on Training is 69.92603550295858\n",
            "Epoch #6. Accuracy on batch 845/2438  on Training is 69.92464539007092\n",
            "Epoch #6. Accuracy on batch 846/2438  on Training is 69.92694805194805\n",
            "Epoch #6. Accuracy on batch 847/2438  on Training is 69.90344929245283\n",
            "Epoch #6. Accuracy on batch 848/2438  on Training is 69.9057714958775\n",
            "Epoch #6. Accuracy on batch 849/2438  on Training is 69.90808823529412\n",
            "Epoch #6. Accuracy on batch 850/2438  on Training is 69.91407168037603\n",
            "Epoch #6. Accuracy on batch 851/2438  on Training is 69.92004107981221\n",
            "Epoch #6. Accuracy on batch 852/2438  on Training is 69.91500586166471\n",
            "Epoch #6. Accuracy on batch 853/2438  on Training is 69.92096018735363\n",
            "Epoch #6. Accuracy on batch 854/2438  on Training is 69.91228070175438\n",
            "Epoch #6. Accuracy on batch 855/2438  on Training is 69.921875\n",
            "Epoch #6. Accuracy on batch 856/2438  on Training is 69.92050758459743\n",
            "Epoch #6. Accuracy on batch 857/2438  on Training is 69.91185897435898\n",
            "Epoch #6. Accuracy on batch 858/2438  on Training is 69.8959545983702\n",
            "Epoch #6. Accuracy on batch 859/2438  on Training is 69.89825581395348\n",
            "Batch Id 860/2438 is having training loss of 1.1027462482452393\n",
            "1.5513584613800049\n",
            "Epoch #6. Accuracy on batch 860/2438  on Training is 69.88240418118467\n",
            "Epoch #6. Accuracy on batch 861/2438  on Training is 69.88471577726219\n",
            "Epoch #6. Accuracy on batch 862/2438  on Training is 69.87253765932793\n",
            "Epoch #6. Accuracy on batch 863/2438  on Training is 69.86038773148148\n",
            "Epoch #6. Accuracy on batch 864/2438  on Training is 69.8699421965318\n",
            "Epoch #6. Accuracy on batch 865/2438  on Training is 69.85782332563511\n",
            "Epoch #6. Accuracy on batch 866/2438  on Training is 69.86014994232987\n",
            "Epoch #6. Accuracy on batch 867/2438  on Training is 69.8480702764977\n",
            "Epoch #6. Accuracy on batch 868/2438  on Training is 69.85759493670886\n",
            "Epoch #6. Accuracy on batch 869/2438  on Training is 69.83477011494253\n",
            "Epoch #6. Accuracy on batch 870/2438  on Training is 69.82993685419059\n",
            "Epoch #6. Accuracy on batch 871/2438  on Training is 69.81077981651376\n",
            "Epoch #6. Accuracy on batch 872/2438  on Training is 69.79882588774342\n",
            "Epoch #6. Accuracy on batch 873/2438  on Training is 69.81550343249428\n",
            "Epoch #6. Accuracy on batch 874/2438  on Training is 69.81785714285714\n",
            "Epoch #6. Accuracy on batch 875/2438  on Training is 69.82020547945206\n",
            "Epoch #6. Accuracy on batch 876/2438  on Training is 69.82254846066135\n",
            "Epoch #6. Accuracy on batch 877/2438  on Training is 69.82132687927107\n",
            "Epoch #6. Accuracy on batch 878/2438  on Training is 69.82366325369739\n",
            "Epoch #6. Accuracy on batch 879/2438  on Training is 69.82244318181819\n",
            "Batch Id 880/2438 is having training loss of 1.1038442850112915\n",
            "1.237534999847412\n",
            "Epoch #6. Accuracy on batch 880/2438  on Training is 69.82477298524404\n",
            "Epoch #6. Accuracy on batch 881/2438  on Training is 69.82001133786848\n",
            "Epoch #6. Accuracy on batch 882/2438  on Training is 69.81526047565119\n",
            "Epoch #6. Accuracy on batch 883/2438  on Training is 69.81759049773756\n",
            "Epoch #6. Accuracy on batch 884/2438  on Training is 69.81285310734464\n",
            "Epoch #6. Accuracy on batch 885/2438  on Training is 69.80459932279909\n",
            "Epoch #6. Accuracy on batch 886/2438  on Training is 69.80341037204059\n",
            "Epoch #6. Accuracy on batch 887/2438  on Training is 69.79166666666667\n",
            "Epoch #6. Accuracy on batch 888/2438  on Training is 69.78346456692914\n",
            "Epoch #6. Accuracy on batch 889/2438  on Training is 69.79634831460675\n",
            "Epoch #6. Accuracy on batch 890/2438  on Training is 69.7986812570146\n",
            "Epoch #6. Accuracy on batch 891/2438  on Training is 69.78699551569507\n",
            "Epoch #6. Accuracy on batch 892/2438  on Training is 69.79283314669652\n",
            "Epoch #6. Accuracy on batch 893/2438  on Training is 69.79166666666667\n",
            "Epoch #6. Accuracy on batch 894/2438  on Training is 69.77653631284916\n",
            "Epoch #6. Accuracy on batch 895/2438  on Training is 69.77887834821429\n",
            "Epoch #6. Accuracy on batch 896/2438  on Training is 69.77424749163879\n",
            "Epoch #6. Accuracy on batch 897/2438  on Training is 69.74874721603564\n",
            "Epoch #6. Accuracy on batch 898/2438  on Training is 69.75111234705228\n",
            "Epoch #6. Accuracy on batch 899/2438  on Training is 69.76041666666667\n",
            "Batch Id 900/2438 is having training loss of 1.1047532558441162\n",
            "0.9104779362678528\n",
            "Epoch #6. Accuracy on batch 900/2438  on Training is 69.76623196448391\n",
            "Epoch #6. Accuracy on batch 901/2438  on Training is 69.76164079822617\n",
            "Epoch #6. Accuracy on batch 902/2438  on Training is 69.76052048726467\n",
            "Epoch #6. Accuracy on batch 903/2438  on Training is 69.75940265486726\n",
            "Epoch #6. Accuracy on batch 904/2438  on Training is 69.76174033149171\n",
            "Epoch #6. Accuracy on batch 905/2438  on Training is 69.75717439293598\n",
            "Epoch #6. Accuracy on batch 906/2438  on Training is 69.76984564498346\n",
            "Epoch #6. Accuracy on batch 907/2438  on Training is 69.77560572687224\n",
            "Epoch #6. Accuracy on batch 908/2438  on Training is 69.77103960396039\n",
            "Epoch #6. Accuracy on batch 909/2438  on Training is 69.75961538461539\n",
            "Epoch #6. Accuracy on batch 910/2438  on Training is 69.76193743139407\n",
            "Epoch #6. Accuracy on batch 911/2438  on Training is 69.76425438596492\n",
            "Epoch #6. Accuracy on batch 912/2438  on Training is 69.76656626506023\n",
            "Epoch #6. Accuracy on batch 913/2438  on Training is 69.77571115973741\n",
            "Epoch #6. Accuracy on batch 914/2438  on Training is 69.78142076502732\n",
            "Epoch #6. Accuracy on batch 915/2438  on Training is 69.78711790393012\n",
            "Epoch #6. Accuracy on batch 916/2438  on Training is 69.78257906215921\n",
            "Epoch #6. Accuracy on batch 917/2438  on Training is 69.78145424836602\n",
            "Epoch #6. Accuracy on batch 918/2438  on Training is 69.76673014145811\n",
            "Epoch #6. Accuracy on batch 919/2438  on Training is 69.78260869565217\n",
            "Batch Id 920/2438 is having training loss of 1.102925419807434\n",
            "0.7334185838699341\n",
            "Epoch #6. Accuracy on batch 920/2438  on Training is 69.79505971769815\n",
            "Epoch #6. Accuracy on batch 921/2438  on Training is 69.79053687635574\n",
            "Epoch #6. Accuracy on batch 922/2438  on Training is 69.80295232936078\n",
            "Epoch #6. Accuracy on batch 923/2438  on Training is 69.79166666666667\n",
            "Epoch #6. Accuracy on batch 924/2438  on Training is 69.79391891891892\n",
            "Epoch #6. Accuracy on batch 925/2438  on Training is 69.80629049676025\n",
            "Epoch #6. Accuracy on batch 926/2438  on Training is 69.80852211434735\n",
            "Epoch #6. Accuracy on batch 927/2438  on Training is 69.81411637931035\n",
            "Epoch #6. Accuracy on batch 928/2438  on Training is 69.81297093649086\n",
            "Epoch #6. Accuracy on batch 929/2438  on Training is 69.80846774193549\n",
            "Epoch #6. Accuracy on batch 930/2438  on Training is 69.81068743286788\n",
            "Epoch #6. Accuracy on batch 931/2438  on Training is 69.81625536480686\n",
            "Epoch #6. Accuracy on batch 932/2438  on Training is 69.81176312968917\n",
            "Epoch #6. Accuracy on batch 933/2438  on Training is 69.80058886509636\n",
            "Epoch #6. Accuracy on batch 934/2438  on Training is 69.78609625668449\n",
            "Epoch #6. Accuracy on batch 935/2438  on Training is 69.78832799145299\n",
            "Epoch #6. Accuracy on batch 936/2438  on Training is 69.79389007470651\n",
            "Epoch #6. Accuracy on batch 937/2438  on Training is 69.80277185501066\n",
            "Epoch #6. Accuracy on batch 938/2438  on Training is 69.80165069222578\n",
            "Epoch #6. Accuracy on batch 939/2438  on Training is 69.80385638297872\n",
            "Batch Id 940/2438 is having training loss of 1.1023494005203247\n",
            "1.5495967864990234\n",
            "Epoch #6. Accuracy on batch 940/2438  on Training is 69.78945270988311\n",
            "Epoch #6. Accuracy on batch 941/2438  on Training is 69.80161889596603\n",
            "Epoch #6. Accuracy on batch 942/2438  on Training is 69.80713149522799\n",
            "Epoch #6. Accuracy on batch 943/2438  on Training is 69.80601165254237\n",
            "Epoch #6. Accuracy on batch 944/2438  on Training is 69.79166666666667\n",
            "Epoch #6. Accuracy on batch 945/2438  on Training is 69.79717230443974\n",
            "Epoch #6. Accuracy on batch 946/2438  on Training is 69.79606652587117\n",
            "Epoch #6. Accuracy on batch 947/2438  on Training is 69.79825949367088\n",
            "Epoch #6. Accuracy on batch 948/2438  on Training is 69.8004478398314\n",
            "Epoch #6. Accuracy on batch 949/2438  on Training is 69.8125\n",
            "Epoch #6. Accuracy on batch 950/2438  on Training is 69.81795478443743\n",
            "Epoch #6. Accuracy on batch 951/2438  on Training is 69.81355042016807\n",
            "Epoch #6. Accuracy on batch 952/2438  on Training is 69.79931794333683\n",
            "Epoch #6. Accuracy on batch 953/2438  on Training is 69.79494234800839\n",
            "Epoch #6. Accuracy on batch 954/2438  on Training is 69.80039267015707\n",
            "Epoch #6. Accuracy on batch 955/2438  on Training is 69.80256276150628\n",
            "Epoch #6. Accuracy on batch 956/2438  on Training is 69.80146290491118\n",
            "Epoch #6. Accuracy on batch 957/2438  on Training is 69.78731732776617\n",
            "Epoch #6. Accuracy on batch 958/2438  on Training is 69.78623566214807\n",
            "Epoch #6. Accuracy on batch 959/2438  on Training is 69.76236979166667\n",
            "Batch Id 960/2438 is having training loss of 1.1036401987075806\n",
            "1.379595160484314\n",
            "Epoch #6. Accuracy on batch 960/2438  on Training is 69.75481269510927\n",
            "Epoch #6. Accuracy on batch 961/2438  on Training is 69.74402286902287\n",
            "Epoch #6. Accuracy on batch 962/2438  on Training is 69.73001038421599\n",
            "Epoch #6. Accuracy on batch 963/2438  on Training is 69.73223547717842\n",
            "Epoch #6. Accuracy on batch 964/2438  on Training is 69.73121761658031\n",
            "Epoch #6. Accuracy on batch 965/2438  on Training is 69.72373188405797\n",
            "Epoch #6. Accuracy on batch 966/2438  on Training is 69.71626163391934\n",
            "Epoch #6. Accuracy on batch 967/2438  on Training is 69.7055785123967\n",
            "Epoch #6. Accuracy on batch 968/2438  on Training is 69.70781733746131\n",
            "Epoch #6. Accuracy on batch 969/2438  on Training is 69.71971649484536\n",
            "Epoch #6. Accuracy on batch 970/2438  on Training is 69.71549948506694\n",
            "Epoch #6. Accuracy on batch 971/2438  on Training is 69.71772119341564\n",
            "Epoch #6. Accuracy on batch 972/2438  on Training is 69.71351490236383\n",
            "Epoch #6. Accuracy on batch 973/2438  on Training is 69.72215092402465\n",
            "Epoch #6. Accuracy on batch 974/2438  on Training is 69.73397435897436\n",
            "Epoch #6. Accuracy on batch 975/2438  on Training is 69.72976434426229\n",
            "Epoch #6. Accuracy on batch 976/2438  on Training is 69.73835721596724\n",
            "Epoch #6. Accuracy on batch 977/2438  on Training is 69.73734662576688\n",
            "Epoch #6. Accuracy on batch 978/2438  on Training is 69.73953013278856\n",
            "Epoch #6. Accuracy on batch 979/2438  on Training is 69.74489795918367\n",
            "Batch Id 980/2438 is having training loss of 1.104258418083191\n",
            "1.1026747226715088\n",
            "Epoch #6. Accuracy on batch 980/2438  on Training is 69.74388379204893\n",
            "Epoch #6. Accuracy on batch 981/2438  on Training is 69.73968940936864\n",
            "Epoch #6. Accuracy on batch 982/2438  on Training is 69.73868260427264\n",
            "Epoch #6. Accuracy on batch 983/2438  on Training is 69.7313262195122\n",
            "Epoch #6. Accuracy on batch 984/2438  on Training is 69.73032994923858\n",
            "Epoch #6. Accuracy on batch 985/2438  on Training is 69.73250507099391\n",
            "Epoch #6. Accuracy on batch 986/2438  on Training is 69.72201114488348\n",
            "Epoch #6. Accuracy on batch 987/2438  on Training is 69.72102732793522\n",
            "Epoch #6. Accuracy on batch 988/2438  on Training is 69.707406471183\n",
            "Epoch #6. Accuracy on batch 989/2438  on Training is 69.70643939393939\n",
            "Epoch #6. Accuracy on batch 990/2438  on Training is 69.70862764883955\n",
            "Epoch #6. Accuracy on batch 991/2438  on Training is 69.71396169354838\n",
            "Epoch #6. Accuracy on batch 992/2438  on Training is 69.72872608257805\n",
            "Epoch #6. Accuracy on batch 993/2438  on Training is 69.74346076458752\n",
            "Epoch #6. Accuracy on batch 994/2438  on Training is 69.73304020100502\n",
            "Epoch #6. Accuracy on batch 995/2438  on Training is 69.73205321285141\n",
            "Epoch #6. Accuracy on batch 996/2438  on Training is 69.74360581745236\n",
            "Epoch #6. Accuracy on batch 997/2438  on Training is 69.75513527054109\n",
            "Epoch #6. Accuracy on batch 998/2438  on Training is 69.76351351351352\n",
            "Epoch #6. Accuracy on batch 999/2438  on Training is 69.76875\n",
            "Batch Id 1000/2438 is having training loss of 1.1035091876983643\n",
            "0.9522485733032227\n",
            "Epoch #6. Accuracy on batch 1000/2438  on Training is 69.7770979020979\n",
            "Epoch #6. Accuracy on batch 1001/2438  on Training is 69.77295409181637\n",
            "Epoch #6. Accuracy on batch 1002/2438  on Training is 69.76570289132601\n",
            "Epoch #6. Accuracy on batch 1003/2438  on Training is 69.76157868525897\n",
            "Epoch #6. Accuracy on batch 1004/2438  on Training is 69.76679104477611\n",
            "Epoch #6. Accuracy on batch 1005/2438  on Training is 69.77509940357852\n",
            "Epoch #6. Accuracy on batch 1006/2438  on Training is 69.7833912611718\n",
            "Epoch #6. Accuracy on batch 1007/2438  on Training is 69.78856646825396\n",
            "Epoch #6. Accuracy on batch 1008/2438  on Training is 69.78444003964321\n",
            "Epoch #6. Accuracy on batch 1009/2438  on Training is 69.78341584158416\n",
            "Epoch #6. Accuracy on batch 1010/2438  on Training is 69.78239366963403\n",
            "Epoch #6. Accuracy on batch 1011/2438  on Training is 69.7844614624506\n",
            "Epoch #6. Accuracy on batch 1012/2438  on Training is 69.78035538005923\n",
            "Epoch #6. Accuracy on batch 1013/2438  on Training is 69.78550295857988\n",
            "Epoch #6. Accuracy on batch 1014/2438  on Training is 69.77832512315271\n",
            "Epoch #6. Accuracy on batch 1015/2438  on Training is 69.78654035433071\n",
            "Epoch #6. Accuracy on batch 1016/2438  on Training is 69.7793756145526\n",
            "Epoch #6. Accuracy on batch 1017/2438  on Training is 69.78757367387034\n",
            "Epoch #6. Accuracy on batch 1018/2438  on Training is 69.78348871442591\n",
            "Epoch #6. Accuracy on batch 1019/2438  on Training is 69.79473039215686\n",
            "Batch Id 1020/2438 is having training loss of 1.1033414602279663\n",
            "1.3883895874023438\n",
            "Epoch #6. Accuracy on batch 1020/2438  on Training is 69.79370714985309\n",
            "Epoch #6. Accuracy on batch 1021/2438  on Training is 69.8018590998043\n",
            "Epoch #6. Accuracy on batch 1022/2438  on Training is 69.7977761485826\n",
            "Epoch #6. Accuracy on batch 1023/2438  on Training is 69.805908203125\n",
            "Epoch #6. Accuracy on batch 1024/2438  on Training is 69.8079268292683\n",
            "Epoch #6. Accuracy on batch 1025/2438  on Training is 69.81907894736842\n",
            "Epoch #6. Accuracy on batch 1026/2438  on Training is 69.83020934761441\n",
            "Epoch #6. Accuracy on batch 1027/2438  on Training is 69.81395914396887\n",
            "Epoch #6. Accuracy on batch 1028/2438  on Training is 69.82203595724003\n",
            "Epoch #6. Accuracy on batch 1029/2438  on Training is 69.83009708737865\n",
            "Epoch #6. Accuracy on batch 1030/2438  on Training is 69.81995635305529\n",
            "Epoch #6. Accuracy on batch 1031/2438  on Training is 69.81891957364341\n",
            "Epoch #6. Accuracy on batch 1032/2438  on Training is 69.8148596321394\n",
            "Epoch #6. Accuracy on batch 1033/2438  on Training is 69.81987427466152\n",
            "Epoch #6. Accuracy on batch 1034/2438  on Training is 69.81884057971014\n",
            "Epoch #6. Accuracy on batch 1035/2438  on Training is 69.80272683397683\n",
            "Epoch #6. Accuracy on batch 1036/2438  on Training is 69.80472516875602\n",
            "Epoch #6. Accuracy on batch 1037/2438  on Training is 69.80671965317919\n",
            "Epoch #6. Accuracy on batch 1038/2438  on Training is 69.80570259865254\n",
            "Epoch #6. Accuracy on batch 1039/2438  on Training is 69.79567307692308\n",
            "Batch Id 1040/2438 is having training loss of 1.1036932468414307\n",
            "1.287195086479187\n",
            "Epoch #6. Accuracy on batch 1040/2438  on Training is 69.79166666666667\n",
            "Epoch #6. Accuracy on batch 1041/2438  on Training is 69.7936660268714\n",
            "Epoch #6. Accuracy on batch 1042/2438  on Training is 69.78667305848514\n",
            "Epoch #6. Accuracy on batch 1043/2438  on Training is 69.79765325670498\n",
            "Epoch #6. Accuracy on batch 1044/2438  on Training is 69.79964114832536\n",
            "Epoch #6. Accuracy on batch 1045/2438  on Training is 69.81357552581262\n",
            "Epoch #6. Accuracy on batch 1046/2438  on Training is 69.80062082139446\n",
            "Epoch #6. Accuracy on batch 1047/2438  on Training is 69.8055820610687\n",
            "Epoch #6. Accuracy on batch 1048/2438  on Training is 69.8164918970448\n",
            "Epoch #6. Accuracy on batch 1049/2438  on Training is 69.8125\n",
            "Epoch #6. Accuracy on batch 1050/2438  on Training is 69.80554234062798\n",
            "Epoch #6. Accuracy on batch 1051/2438  on Training is 69.81345057034221\n",
            "Epoch #6. Accuracy on batch 1052/2438  on Training is 69.81244064577398\n",
            "Epoch #6. Accuracy on batch 1053/2438  on Training is 69.81143263757116\n",
            "Epoch #6. Accuracy on batch 1054/2438  on Training is 69.82227488151659\n",
            "Epoch #6. Accuracy on batch 1055/2438  on Training is 69.81830018939394\n",
            "Epoch #6. Accuracy on batch 1056/2438  on Training is 69.8350283822138\n",
            "Epoch #6. Accuracy on batch 1057/2438  on Training is 69.82218809073724\n",
            "Epoch #6. Accuracy on batch 1058/2438  on Training is 69.8034702549575\n",
            "Epoch #6. Accuracy on batch 1059/2438  on Training is 69.79363207547169\n",
            "Batch Id 1060/2438 is having training loss of 1.103508472442627\n",
            "0.8684129118919373\n",
            "Epoch #6. Accuracy on batch 1060/2438  on Training is 69.79853911404335\n",
            "Epoch #6. Accuracy on batch 1061/2438  on Training is 69.78283898305085\n",
            "Epoch #6. Accuracy on batch 1062/2438  on Training is 69.79068673565381\n",
            "Epoch #6. Accuracy on batch 1063/2438  on Training is 69.79264567669173\n",
            "Epoch #6. Accuracy on batch 1064/2438  on Training is 69.80340375586854\n",
            "Epoch #6. Accuracy on batch 1065/2438  on Training is 69.80241557223265\n",
            "Epoch #6. Accuracy on batch 1066/2438  on Training is 69.80728678537957\n",
            "Epoch #6. Accuracy on batch 1067/2438  on Training is 69.80922284644194\n",
            "Epoch #6. Accuracy on batch 1068/2438  on Training is 69.80823199251637\n",
            "Epoch #6. Accuracy on batch 1069/2438  on Training is 69.79556074766356\n",
            "Epoch #6. Accuracy on batch 1070/2438  on Training is 69.80042016806723\n",
            "Epoch #6. Accuracy on batch 1071/2438  on Training is 69.79652518656717\n",
            "Epoch #6. Accuracy on batch 1072/2438  on Training is 69.80719944082013\n",
            "Epoch #6. Accuracy on batch 1073/2438  on Training is 69.81785381750466\n",
            "Epoch #6. Accuracy on batch 1074/2438  on Training is 69.83720930232558\n",
            "Epoch #6. Accuracy on batch 1075/2438  on Training is 69.83329460966543\n",
            "Epoch #6. Accuracy on batch 1076/2438  on Training is 69.83228876508821\n",
            "Epoch #6. Accuracy on batch 1077/2438  on Training is 69.83418367346938\n",
            "Epoch #6. Accuracy on batch 1078/2438  on Training is 69.83897126969416\n",
            "Epoch #6. Accuracy on batch 1079/2438  on Training is 69.84375\n",
            "Batch Id 1080/2438 is having training loss of 1.103049635887146\n",
            "1.6432075500488281\n",
            "Epoch #6. Accuracy on batch 1080/2438  on Training is 69.81672062904718\n",
            "Epoch #6. Accuracy on batch 1081/2438  on Training is 69.82151109057301\n",
            "Epoch #6. Accuracy on batch 1082/2438  on Training is 69.81763619575254\n",
            "Epoch #6. Accuracy on batch 1083/2438  on Training is 69.82818265682657\n",
            "Epoch #6. Accuracy on batch 1084/2438  on Training is 69.82430875576037\n",
            "Epoch #6. Accuracy on batch 1085/2438  on Training is 69.82044198895028\n",
            "Epoch #6. Accuracy on batch 1086/2438  on Training is 69.81658233670653\n",
            "Epoch #6. Accuracy on batch 1087/2438  on Training is 69.83283547794117\n",
            "Epoch #6. Accuracy on batch 1088/2438  on Training is 69.83471074380165\n",
            "Epoch #6. Accuracy on batch 1089/2438  on Training is 69.83371559633028\n",
            "Epoch #6. Accuracy on batch 1090/2438  on Training is 69.81840054995418\n",
            "Epoch #6. Accuracy on batch 1091/2438  on Training is 69.81169871794872\n",
            "Epoch #6. Accuracy on batch 1092/2438  on Training is 69.80215004574565\n",
            "Epoch #6. Accuracy on batch 1093/2438  on Training is 69.79833180987202\n",
            "Epoch #6. Accuracy on batch 1094/2438  on Training is 69.80022831050228\n",
            "Epoch #6. Accuracy on batch 1095/2438  on Training is 69.7992700729927\n",
            "Epoch #6. Accuracy on batch 1096/2438  on Training is 69.79831358249773\n",
            "Epoch #6. Accuracy on batch 1097/2438  on Training is 69.79166666666667\n",
            "Epoch #6. Accuracy on batch 1098/2438  on Training is 69.79356232939035\n",
            "Epoch #6. Accuracy on batch 1099/2438  on Training is 69.79545454545455\n",
            "Batch Id 1100/2438 is having training loss of 1.1047509908676147\n",
            "1.228384256362915\n",
            "Epoch #6. Accuracy on batch 1100/2438  on Training is 69.79450499545868\n",
            "Epoch #6. Accuracy on batch 1101/2438  on Training is 69.79072141560799\n",
            "Epoch #6. Accuracy on batch 1102/2438  on Training is 69.78977787851315\n",
            "Epoch #6. Accuracy on batch 1103/2438  on Training is 69.79166666666667\n",
            "Epoch #6. Accuracy on batch 1104/2438  on Training is 69.78223981900453\n",
            "Epoch #6. Accuracy on batch 1105/2438  on Training is 69.77848101265823\n",
            "Epoch #6. Accuracy on batch 1106/2438  on Training is 69.7775519421861\n",
            "Epoch #6. Accuracy on batch 1107/2438  on Training is 69.78226534296029\n",
            "Epoch #6. Accuracy on batch 1108/2438  on Training is 69.78133453561767\n",
            "Epoch #6. Accuracy on batch 1109/2438  on Training is 69.78603603603604\n",
            "Epoch #6. Accuracy on batch 1110/2438  on Training is 69.79354185418542\n",
            "Epoch #6. Accuracy on batch 1111/2438  on Training is 69.7841726618705\n",
            "Epoch #6. Accuracy on batch 1112/2438  on Training is 69.78324348607367\n",
            "Epoch #6. Accuracy on batch 1113/2438  on Training is 69.796342010772\n",
            "Epoch #6. Accuracy on batch 1114/2438  on Training is 69.79260089686099\n",
            "Epoch #6. Accuracy on batch 1115/2438  on Training is 69.80566756272401\n",
            "Epoch #6. Accuracy on batch 1116/2438  on Training is 69.81591316025067\n",
            "Epoch #6. Accuracy on batch 1117/2438  on Training is 69.82055008944543\n",
            "Epoch #6. Accuracy on batch 1118/2438  on Training is 69.82517873100983\n",
            "Epoch #6. Accuracy on batch 1119/2438  on Training is 69.83816964285714\n",
            "Batch Id 1120/2438 is having training loss of 1.1041944026947021\n",
            "1.362993836402893\n",
            "Epoch #6. Accuracy on batch 1120/2438  on Training is 69.81489741302408\n",
            "Epoch #6. Accuracy on batch 1121/2438  on Training is 69.81116310160428\n",
            "Epoch #6. Accuracy on batch 1122/2438  on Training is 69.81300089047195\n",
            "Epoch #6. Accuracy on batch 1123/2438  on Training is 69.80927491103203\n",
            "Epoch #6. Accuracy on batch 1124/2438  on Training is 69.81944444444444\n",
            "Epoch #6. Accuracy on batch 1125/2438  on Training is 69.82682060390763\n",
            "Epoch #6. Accuracy on batch 1126/2438  on Training is 69.8286379769299\n",
            "Epoch #6. Accuracy on batch 1127/2438  on Training is 69.83045212765957\n",
            "Epoch #6. Accuracy on batch 1128/2438  on Training is 69.81842338352524\n",
            "Epoch #6. Accuracy on batch 1129/2438  on Training is 69.8174778761062\n",
            "Epoch #6. Accuracy on batch 1130/2438  on Training is 69.81929708222812\n",
            "Epoch #6. Accuracy on batch 1131/2438  on Training is 69.81559187279152\n",
            "Epoch #6. Accuracy on batch 1132/2438  on Training is 69.81465136804943\n",
            "Epoch #6. Accuracy on batch 1133/2438  on Training is 69.81095679012346\n",
            "Epoch #6. Accuracy on batch 1134/2438  on Training is 69.79074889867842\n",
            "Epoch #6. Accuracy on batch 1135/2438  on Training is 69.78983274647888\n",
            "Epoch #6. Accuracy on batch 1136/2438  on Training is 69.78067282321899\n",
            "Epoch #6. Accuracy on batch 1137/2438  on Training is 69.79075131810194\n",
            "Epoch #6. Accuracy on batch 1138/2438  on Training is 69.79258121158911\n",
            "Epoch #6. Accuracy on batch 1139/2438  on Training is 69.79989035087719\n",
            "Batch Id 1140/2438 is having training loss of 1.1051958799362183\n",
            "1.3067800998687744\n",
            "Epoch #6. Accuracy on batch 1140/2438  on Training is 69.79349255039439\n",
            "Epoch #6. Accuracy on batch 1141/2438  on Training is 69.77616024518389\n",
            "Epoch #6. Accuracy on batch 1142/2438  on Training is 69.79166666666667\n",
            "Epoch #6. Accuracy on batch 1143/2438  on Training is 69.78256118881119\n",
            "Epoch #6. Accuracy on batch 1144/2438  on Training is 69.78711790393012\n",
            "Epoch #6. Accuracy on batch 1145/2438  on Training is 69.77257853403141\n",
            "Epoch #6. Accuracy on batch 1146/2438  on Training is 69.76351351351352\n",
            "Epoch #6. Accuracy on batch 1147/2438  on Training is 69.75718641114983\n",
            "Epoch #6. Accuracy on batch 1148/2438  on Training is 69.76446910356832\n",
            "Epoch #6. Accuracy on batch 1149/2438  on Training is 69.76358695652173\n",
            "Epoch #6. Accuracy on batch 1150/2438  on Training is 69.75727628149436\n",
            "Epoch #6. Accuracy on batch 1151/2438  on Training is 69.74826388888889\n",
            "Epoch #6. Accuracy on batch 1152/2438  on Training is 69.75823937554206\n",
            "Epoch #6. Accuracy on batch 1153/2438  on Training is 69.75194974003466\n",
            "Epoch #6. Accuracy on batch 1154/2438  on Training is 69.74296536796537\n",
            "Epoch #6. Accuracy on batch 1155/2438  on Training is 69.75021626297578\n",
            "Epoch #6. Accuracy on batch 1156/2438  on Training is 69.75205272255835\n",
            "Epoch #6. Accuracy on batch 1157/2438  on Training is 69.75928324697755\n",
            "Epoch #6. Accuracy on batch 1158/2438  on Training is 69.75571613459879\n",
            "Epoch #6. Accuracy on batch 1159/2438  on Training is 69.74946120689656\n",
            "Batch Id 1160/2438 is having training loss of 1.1073540449142456\n",
            "1.098932147026062\n",
            "Epoch #6. Accuracy on batch 1160/2438  on Training is 69.74590869939708\n",
            "Epoch #6. Accuracy on batch 1161/2438  on Training is 69.74774096385542\n",
            "Epoch #6. Accuracy on batch 1162/2438  on Training is 69.75225709372313\n",
            "Epoch #6. Accuracy on batch 1163/2438  on Training is 69.76750429553265\n",
            "Epoch #6. Accuracy on batch 1164/2438  on Training is 69.76931330472102\n",
            "Epoch #6. Accuracy on batch 1165/2438  on Training is 69.76307890222985\n",
            "Epoch #6. Accuracy on batch 1166/2438  on Training is 69.75685518423307\n",
            "Epoch #6. Accuracy on batch 1167/2438  on Training is 69.7533176369863\n",
            "Epoch #6. Accuracy on batch 1168/2438  on Training is 69.74443969204448\n",
            "Epoch #6. Accuracy on batch 1169/2438  on Training is 69.73824786324786\n",
            "Epoch #6. Accuracy on batch 1170/2438  on Training is 69.7267292912041\n",
            "Epoch #6. Accuracy on batch 1171/2438  on Training is 69.7232295221843\n",
            "Epoch #6. Accuracy on batch 1172/2438  on Training is 69.71973572037511\n",
            "Epoch #6. Accuracy on batch 1173/2438  on Training is 69.72157155025553\n",
            "Epoch #6. Accuracy on batch 1174/2438  on Training is 69.72872340425532\n",
            "Epoch #6. Accuracy on batch 1175/2438  on Training is 69.72523384353741\n",
            "Epoch #6. Accuracy on batch 1176/2438  on Training is 69.72706032285471\n",
            "Epoch #6. Accuracy on batch 1177/2438  on Training is 69.71561969439729\n",
            "Epoch #6. Accuracy on batch 1178/2438  on Training is 69.70949957591179\n",
            "Epoch #6. Accuracy on batch 1179/2438  on Training is 69.70074152542372\n",
            "Batch Id 1180/2438 is having training loss of 1.1090370416641235\n",
            "1.206092357635498\n",
            "Epoch #6. Accuracy on batch 1180/2438  on Training is 69.70258255715495\n",
            "Epoch #6. Accuracy on batch 1181/2438  on Training is 69.7097081218274\n",
            "Epoch #6. Accuracy on batch 1182/2438  on Training is 69.7036136939983\n",
            "Epoch #6. Accuracy on batch 1183/2438  on Training is 69.70544763513513\n",
            "Epoch #6. Accuracy on batch 1184/2438  on Training is 69.70991561181435\n",
            "Epoch #6. Accuracy on batch 1185/2438  on Training is 69.71174114671163\n",
            "Epoch #6. Accuracy on batch 1186/2438  on Training is 69.69250210614996\n",
            "Epoch #6. Accuracy on batch 1187/2438  on Training is 69.69433922558923\n",
            "Epoch #6. Accuracy on batch 1188/2438  on Training is 69.69880151387721\n",
            "Epoch #6. Accuracy on batch 1189/2438  on Training is 69.69275210084034\n",
            "Epoch #6. Accuracy on batch 1190/2438  on Training is 69.69458438287154\n",
            "Epoch #6. Accuracy on batch 1191/2438  on Training is 69.68854865771812\n",
            "Epoch #6. Accuracy on batch 1192/2438  on Training is 69.68776194467729\n",
            "Epoch #6. Accuracy on batch 1193/2438  on Training is 69.68697654941373\n",
            "Epoch #6. Accuracy on batch 1194/2438  on Training is 69.69403765690376\n",
            "Epoch #6. Accuracy on batch 1195/2438  on Training is 69.69063545150502\n",
            "Epoch #6. Accuracy on batch 1196/2438  on Training is 69.68462823725982\n",
            "Epoch #6. Accuracy on batch 1197/2438  on Training is 69.68906510851419\n",
            "Epoch #6. Accuracy on batch 1198/2438  on Training is 69.70131359466222\n",
            "Epoch #6. Accuracy on batch 1199/2438  on Training is 69.6953125\n",
            "Batch Id 1200/2438 is having training loss of 1.1093469858169556\n",
            "1.5894896984100342\n",
            "Epoch #6. Accuracy on batch 1200/2438  on Training is 69.68671940049958\n",
            "Epoch #6. Accuracy on batch 1201/2438  on Training is 69.68334026622296\n",
            "Epoch #6. Accuracy on batch 1202/2438  on Training is 69.67996674979219\n",
            "Epoch #6. Accuracy on batch 1203/2438  on Training is 69.69736295681064\n",
            "Epoch #6. Accuracy on batch 1204/2438  on Training is 69.68879668049793\n",
            "Epoch #6. Accuracy on batch 1205/2438  on Training is 69.68542703150912\n",
            "Epoch #6. Accuracy on batch 1206/2438  on Training is 69.6924192212096\n",
            "Epoch #6. Accuracy on batch 1207/2438  on Training is 69.69681291390728\n",
            "Epoch #6. Accuracy on batch 1208/2438  on Training is 69.69861455748553\n",
            "Epoch #6. Accuracy on batch 1209/2438  on Training is 69.7004132231405\n",
            "Epoch #6. Accuracy on batch 1210/2438  on Training is 69.70478943022296\n",
            "Epoch #6. Accuracy on batch 1211/2438  on Training is 69.70142326732673\n",
            "Epoch #6. Accuracy on batch 1212/2438  on Training is 69.6929101401484\n",
            "Epoch #6. Accuracy on batch 1213/2438  on Training is 69.69728171334431\n",
            "Epoch #6. Accuracy on batch 1214/2438  on Training is 69.69650205761317\n",
            "Epoch #6. Accuracy on batch 1215/2438  on Training is 69.69572368421052\n",
            "Epoch #6. Accuracy on batch 1216/2438  on Training is 69.69751437962202\n",
            "Epoch #6. Accuracy on batch 1217/2438  on Training is 69.69160509031198\n",
            "Epoch #6. Accuracy on batch 1218/2438  on Training is 69.69852337981952\n",
            "Epoch #6. Accuracy on batch 1219/2438  on Training is 69.70030737704919\n",
            "Batch Id 1220/2438 is having training loss of 1.1087263822555542\n",
            "0.9897377490997314\n",
            "Epoch #6. Accuracy on batch 1220/2438  on Training is 69.70464782964783\n",
            "Epoch #6. Accuracy on batch 1221/2438  on Training is 69.7038666121113\n",
            "Epoch #6. Accuracy on batch 1222/2438  on Training is 69.7005314799673\n",
            "Epoch #6. Accuracy on batch 1223/2438  on Training is 69.69975490196079\n",
            "Epoch #6. Accuracy on batch 1224/2438  on Training is 69.69897959183673\n",
            "Epoch #6. Accuracy on batch 1225/2438  on Training is 69.7084013050571\n",
            "Epoch #6. Accuracy on batch 1226/2438  on Training is 69.69997962510188\n",
            "Epoch #6. Accuracy on batch 1227/2438  on Training is 69.71447475570032\n",
            "Epoch #6. Accuracy on batch 1228/2438  on Training is 69.71623270951993\n",
            "Epoch #6. Accuracy on batch 1229/2438  on Training is 69.72052845528455\n",
            "Epoch #6. Accuracy on batch 1230/2438  on Training is 69.72735580828595\n",
            "Epoch #6. Accuracy on batch 1231/2438  on Training is 69.71895292207792\n",
            "Epoch #6. Accuracy on batch 1232/2438  on Training is 69.71563260340632\n",
            "Epoch #6. Accuracy on batch 1233/2438  on Training is 69.73004457050243\n",
            "Epoch #6. Accuracy on batch 1234/2438  on Training is 69.72672064777328\n",
            "Epoch #6. Accuracy on batch 1235/2438  on Training is 69.72845873786407\n",
            "Epoch #6. Accuracy on batch 1236/2438  on Training is 69.73272029102668\n",
            "Epoch #6. Accuracy on batch 1237/2438  on Training is 69.72435379644588\n",
            "Epoch #6. Accuracy on batch 1238/2438  on Training is 69.7185230024213\n",
            "Epoch #6. Accuracy on batch 1239/2438  on Training is 69.72026209677419\n",
            "Batch Id 1240/2438 is having training loss of 1.1077619791030884\n",
            "0.8439911007881165\n",
            "Epoch #6. Accuracy on batch 1240/2438  on Training is 69.72199838839646\n",
            "Epoch #6. Accuracy on batch 1241/2438  on Training is 69.72121578099839\n",
            "Epoch #6. Accuracy on batch 1242/2438  on Training is 69.73049074818987\n",
            "Epoch #6. Accuracy on batch 1243/2438  on Training is 69.74477491961414\n",
            "Epoch #6. Accuracy on batch 1244/2438  on Training is 69.73895582329317\n",
            "Epoch #6. Accuracy on batch 1245/2438  on Training is 69.7381621187801\n",
            "Epoch #6. Accuracy on batch 1246/2438  on Training is 69.74488773055333\n",
            "Epoch #6. Accuracy on batch 1247/2438  on Training is 69.7440905448718\n",
            "Epoch #6. Accuracy on batch 1248/2438  on Training is 69.74579663730985\n",
            "Epoch #6. Accuracy on batch 1249/2438  on Training is 69.7425\n",
            "Epoch #6. Accuracy on batch 1250/2438  on Training is 69.74670263788968\n",
            "Epoch #6. Accuracy on batch 1251/2438  on Training is 69.74341054313099\n",
            "Epoch #6. Accuracy on batch 1252/2438  on Training is 69.74012370311253\n",
            "Epoch #6. Accuracy on batch 1253/2438  on Training is 69.74431818181819\n",
            "Epoch #6. Accuracy on batch 1254/2438  on Training is 69.73605577689243\n",
            "Epoch #6. Accuracy on batch 1255/2438  on Training is 69.74273487261146\n",
            "Epoch #6. Accuracy on batch 1256/2438  on Training is 69.73697295147176\n",
            "Epoch #6. Accuracy on batch 1257/2438  on Training is 69.74364069952306\n",
            "Epoch #6. Accuracy on batch 1258/2438  on Training is 69.74036934074662\n",
            "Epoch #6. Accuracy on batch 1259/2438  on Training is 69.74702380952381\n",
            "Batch Id 1260/2438 is having training loss of 1.1076899766921997\n",
            "0.8816089034080505\n",
            "Epoch #6. Accuracy on batch 1260/2438  on Training is 69.74871134020619\n",
            "Epoch #6. Accuracy on batch 1261/2438  on Training is 69.74791996830427\n",
            "Epoch #6. Accuracy on batch 1262/2438  on Training is 69.75455265241489\n",
            "Epoch #6. Accuracy on batch 1263/2438  on Training is 69.75870253164557\n",
            "Epoch #6. Accuracy on batch 1264/2438  on Training is 69.75790513833992\n",
            "Epoch #6. Accuracy on batch 1265/2438  on Training is 69.75464060031595\n",
            "Epoch #6. Accuracy on batch 1266/2438  on Training is 69.7637134964483\n",
            "Epoch #6. Accuracy on batch 1267/2438  on Training is 69.76044952681389\n",
            "Epoch #6. Accuracy on batch 1268/2438  on Training is 69.75226556343577\n",
            "Epoch #6. Accuracy on batch 1269/2438  on Training is 69.7490157480315\n",
            "Epoch #6. Accuracy on batch 1270/2438  on Training is 69.74577104642015\n",
            "Epoch #6. Accuracy on batch 1271/2438  on Training is 69.7400746855346\n",
            "Epoch #6. Accuracy on batch 1272/2438  on Training is 69.73684210526316\n",
            "Epoch #6. Accuracy on batch 1273/2438  on Training is 69.73606750392464\n",
            "Epoch #6. Accuracy on batch 1274/2438  on Training is 69.75\n",
            "Epoch #6. Accuracy on batch 1275/2438  on Training is 69.75166536050156\n",
            "Epoch #6. Accuracy on batch 1276/2438  on Training is 69.76556382145654\n",
            "Epoch #6. Accuracy on batch 1277/2438  on Training is 69.77699530516432\n",
            "Epoch #6. Accuracy on batch 1278/2438  on Training is 69.78352228303362\n",
            "Epoch #6. Accuracy on batch 1279/2438  on Training is 69.77783203125\n",
            "Batch Id 1280/2438 is having training loss of 1.1070839166641235\n",
            "1.657437801361084\n",
            "Epoch #6. Accuracy on batch 1280/2438  on Training is 69.76483216237314\n",
            "Epoch #6. Accuracy on batch 1281/2438  on Training is 69.75429017160687\n",
            "Epoch #6. Accuracy on batch 1282/2438  on Training is 69.75594310210444\n",
            "Epoch #6. Accuracy on batch 1283/2438  on Training is 69.75515965732087\n",
            "Epoch #6. Accuracy on batch 1284/2438  on Training is 69.75924124513618\n",
            "Epoch #6. Accuracy on batch 1285/2438  on Training is 69.7584564541213\n",
            "Epoch #6. Accuracy on batch 1286/2438  on Training is 69.76252913752914\n",
            "Epoch #6. Accuracy on batch 1287/2438  on Training is 69.75931677018633\n",
            "Epoch #6. Accuracy on batch 1288/2438  on Training is 69.75368502715283\n",
            "Epoch #6. Accuracy on batch 1289/2438  on Training is 69.7625968992248\n",
            "Epoch #6. Accuracy on batch 1290/2438  on Training is 69.76181254841208\n",
            "Epoch #6. Accuracy on batch 1291/2438  on Training is 69.76344814241486\n",
            "Epoch #6. Accuracy on batch 1292/2438  on Training is 69.76024748646559\n",
            "Epoch #6. Accuracy on batch 1293/2438  on Training is 69.76188176197836\n",
            "Epoch #6. Accuracy on batch 1294/2438  on Training is 69.75144787644787\n",
            "Epoch #6. Accuracy on batch 1295/2438  on Training is 69.74826388888889\n",
            "Epoch #6. Accuracy on batch 1296/2438  on Training is 69.75713184271396\n",
            "Epoch #6. Accuracy on batch 1297/2438  on Training is 69.7515408320493\n",
            "Epoch #6. Accuracy on batch 1298/2438  on Training is 69.73874133949192\n",
            "Epoch #6. Accuracy on batch 1299/2438  on Training is 69.74038461538461\n",
            "Batch Id 1300/2438 is having training loss of 1.1070894002914429\n",
            "1.0177967548370361\n",
            "Epoch #6. Accuracy on batch 1300/2438  on Training is 69.73722136817833\n",
            "Epoch #6. Accuracy on batch 1301/2438  on Training is 69.72206221198157\n",
            "Epoch #6. Accuracy on batch 1302/2438  on Training is 69.71891788181121\n",
            "Epoch #6. Accuracy on batch 1303/2438  on Training is 69.71817484662577\n",
            "Epoch #6. Accuracy on batch 1304/2438  on Training is 69.71503831417624\n",
            "Epoch #6. Accuracy on batch 1305/2438  on Training is 69.6999425727412\n",
            "Epoch #6. Accuracy on batch 1306/2438  on Training is 69.68486993114001\n",
            "Epoch #6. Accuracy on batch 1307/2438  on Training is 69.67459862385321\n",
            "Epoch #6. Accuracy on batch 1308/2438  on Training is 69.67389228418641\n",
            "Epoch #6. Accuracy on batch 1309/2438  on Training is 69.68272900763358\n",
            "Epoch #6. Accuracy on batch 1310/2438  on Training is 69.68201754385964\n",
            "Epoch #6. Accuracy on batch 1311/2438  on Training is 69.67654344512195\n",
            "Epoch #6. Accuracy on batch 1312/2438  on Training is 69.66869763899467\n",
            "Epoch #6. Accuracy on batch 1313/2438  on Training is 69.65848554033485\n",
            "Epoch #6. Accuracy on batch 1314/2438  on Training is 69.6601711026616\n",
            "Epoch #6. Accuracy on batch 1315/2438  on Training is 69.6523556231003\n",
            "Epoch #6. Accuracy on batch 1316/2438  on Training is 69.64455201214882\n",
            "Epoch #6. Accuracy on batch 1317/2438  on Training is 69.63913125948406\n",
            "Epoch #6. Accuracy on batch 1318/2438  on Training is 69.6337187263078\n",
            "Epoch #6. Accuracy on batch 1319/2438  on Training is 69.64251893939394\n",
            "Batch Id 1320/2438 is having training loss of 1.1086466312408447\n",
            "1.5244736671447754\n",
            "Epoch #6. Accuracy on batch 1320/2438  on Training is 69.6371120363361\n",
            "Epoch #6. Accuracy on batch 1321/2438  on Training is 69.63644099848715\n",
            "Epoch #6. Accuracy on batch 1322/2438  on Training is 69.64049508692366\n",
            "Epoch #6. Accuracy on batch 1323/2438  on Training is 69.6327416918429\n",
            "Epoch #6. Accuracy on batch 1324/2438  on Training is 69.63679245283019\n",
            "Epoch #6. Accuracy on batch 1325/2438  on Training is 69.62905354449472\n",
            "Epoch #6. Accuracy on batch 1326/2438  on Training is 69.63310097965335\n",
            "Epoch #6. Accuracy on batch 1327/2438  on Training is 69.6300828313253\n",
            "Epoch #6. Accuracy on batch 1328/2438  on Training is 69.62236644093304\n",
            "Epoch #6. Accuracy on batch 1329/2438  on Training is 69.63110902255639\n",
            "Epoch #6. Accuracy on batch 1330/2438  on Training is 69.62809917355372\n",
            "Epoch #6. Accuracy on batch 1331/2438  on Training is 69.63682432432432\n",
            "Epoch #6. Accuracy on batch 1332/2438  on Training is 69.63850337584397\n",
            "Epoch #6. Accuracy on batch 1333/2438  on Training is 69.6518928035982\n",
            "Epoch #6. Accuracy on batch 1334/2438  on Training is 69.65589887640449\n",
            "Epoch #6. Accuracy on batch 1335/2438  on Training is 69.64586452095809\n",
            "Epoch #6. Accuracy on batch 1336/2438  on Training is 69.64519446522064\n",
            "Epoch #6. Accuracy on batch 1337/2438  on Training is 69.64452541106128\n",
            "Epoch #6. Accuracy on batch 1338/2438  on Training is 69.64619118745333\n",
            "Epoch #6. Accuracy on batch 1339/2438  on Training is 69.65251865671642\n",
            "Batch Id 1340/2438 is having training loss of 1.1083250045776367\n",
            "1.4697611331939697\n",
            "Epoch #6. Accuracy on batch 1340/2438  on Training is 69.65184563758389\n",
            "Epoch #6. Accuracy on batch 1341/2438  on Training is 69.65815946348734\n",
            "Epoch #6. Accuracy on batch 1342/2438  on Training is 69.65050260610573\n",
            "Epoch #6. Accuracy on batch 1343/2438  on Training is 69.64518229166667\n",
            "Epoch #6. Accuracy on batch 1344/2438  on Training is 69.63986988847584\n",
            "Epoch #6. Accuracy on batch 1345/2438  on Training is 69.6484955423477\n",
            "Epoch #6. Accuracy on batch 1346/2438  on Training is 69.64086859688196\n",
            "Epoch #6. Accuracy on batch 1347/2438  on Training is 69.63557121661721\n",
            "Epoch #6. Accuracy on batch 1348/2438  on Training is 69.6349147516679\n",
            "Epoch #6. Accuracy on batch 1349/2438  on Training is 69.63657407407408\n",
            "Epoch #6. Accuracy on batch 1350/2438  on Training is 69.62666543301259\n",
            "Epoch #6. Accuracy on batch 1351/2438  on Training is 69.62370562130178\n",
            "Epoch #6. Accuracy on batch 1352/2438  on Training is 69.6299889135255\n",
            "Epoch #6. Accuracy on batch 1353/2438  on Training is 69.62933899556869\n",
            "Epoch #6. Accuracy on batch 1354/2438  on Training is 69.62869003690037\n",
            "Epoch #6. Accuracy on batch 1355/2438  on Training is 69.62343289085545\n",
            "Epoch #6. Accuracy on batch 1356/2438  on Training is 69.63200073691968\n",
            "Epoch #6. Accuracy on batch 1357/2438  on Training is 69.63365243004418\n",
            "Epoch #6. Accuracy on batch 1358/2438  on Training is 69.6353016924209\n",
            "Epoch #6. Accuracy on batch 1359/2438  on Training is 69.64154411764706\n",
            "Batch Id 1360/2438 is having training loss of 1.1089377403259277\n",
            "0.9005385637283325\n",
            "Epoch #6. Accuracy on batch 1360/2438  on Training is 69.64318515797208\n",
            "Epoch #6. Accuracy on batch 1361/2438  on Training is 69.64482378854626\n",
            "Epoch #6. Accuracy on batch 1362/2438  on Training is 69.63041085840058\n",
            "Epoch #6. Accuracy on batch 1363/2438  on Training is 69.62518328445748\n",
            "Epoch #6. Accuracy on batch 1364/2438  on Training is 69.63141025641026\n",
            "Epoch #6. Accuracy on batch 1365/2438  on Training is 69.63991581259151\n",
            "Epoch #6. Accuracy on batch 1366/2438  on Training is 69.64612289685442\n",
            "Epoch #6. Accuracy on batch 1367/2438  on Training is 69.64089912280701\n",
            "Epoch #6. Accuracy on batch 1368/2438  on Training is 69.64481373265157\n",
            "Epoch #6. Accuracy on batch 1369/2438  on Training is 69.64872262773723\n",
            "Epoch #6. Accuracy on batch 1370/2438  on Training is 69.64350838803793\n",
            "Epoch #6. Accuracy on batch 1371/2438  on Training is 69.63374635568513\n",
            "Epoch #6. Accuracy on batch 1372/2438  on Training is 69.63082665695558\n",
            "Epoch #6. Accuracy on batch 1373/2438  on Training is 69.62336244541484\n",
            "Epoch #6. Accuracy on batch 1374/2438  on Training is 69.625\n",
            "Epoch #6. Accuracy on batch 1375/2438  on Training is 69.62890625\n",
            "Epoch #6. Accuracy on batch 1376/2438  on Training is 69.63280682643428\n",
            "Epoch #6. Accuracy on batch 1377/2438  on Training is 69.62989840348331\n",
            "Epoch #6. Accuracy on batch 1378/2438  on Training is 69.63379260333575\n",
            "Epoch #6. Accuracy on batch 1379/2438  on Training is 69.6376811594203\n",
            "Batch Id 1380/2438 is having training loss of 1.109248399734497\n",
            "0.8954624533653259\n",
            "Epoch #6. Accuracy on batch 1380/2438  on Training is 69.63930123099203\n",
            "Epoch #6. Accuracy on batch 1381/2438  on Training is 69.64996382054993\n",
            "Epoch #6. Accuracy on batch 1382/2438  on Training is 69.65835140997831\n",
            "Epoch #6. Accuracy on batch 1383/2438  on Training is 69.66446893063583\n",
            "Epoch #6. Accuracy on batch 1384/2438  on Training is 69.65929602888086\n",
            "Epoch #6. Accuracy on batch 1385/2438  on Training is 69.66314935064935\n",
            "Epoch #6. Accuracy on batch 1386/2438  on Training is 69.66699711607787\n",
            "Epoch #6. Accuracy on batch 1387/2438  on Training is 69.67984510086455\n",
            "Epoch #6. Accuracy on batch 1388/2438  on Training is 69.67467602591793\n",
            "Epoch #6. Accuracy on batch 1389/2438  on Training is 69.67176258992805\n",
            "Epoch #6. Accuracy on batch 1390/2438  on Training is 69.67109992810927\n",
            "Epoch #6. Accuracy on batch 1391/2438  on Training is 69.66145833333333\n",
            "Epoch #6. Accuracy on batch 1392/2438  on Training is 69.66753409906676\n",
            "Epoch #6. Accuracy on batch 1393/2438  on Training is 69.6601506456241\n",
            "Epoch #6. Accuracy on batch 1394/2438  on Training is 69.64829749103943\n",
            "Epoch #6. Accuracy on batch 1395/2438  on Training is 69.64541547277938\n",
            "Epoch #6. Accuracy on batch 1396/2438  on Training is 69.63806370794559\n",
            "Epoch #6. Accuracy on batch 1397/2438  on Training is 69.64636981402003\n",
            "Epoch #6. Accuracy on batch 1398/2438  on Training is 69.65243030736241\n",
            "Epoch #6. Accuracy on batch 1399/2438  on Training is 69.65625\n",
            "Batch Id 1400/2438 is having training loss of 1.108680009841919\n",
            "1.2107313871383667\n",
            "Epoch #6. Accuracy on batch 1400/2438  on Training is 69.65783369022127\n",
            "Epoch #6. Accuracy on batch 1401/2438  on Training is 69.6549572039943\n",
            "Epoch #6. Accuracy on batch 1402/2438  on Training is 69.6565395580898\n",
            "Epoch #6. Accuracy on batch 1403/2438  on Training is 69.64921652421653\n",
            "Epoch #6. Accuracy on batch 1404/2438  on Training is 69.64857651245552\n",
            "Epoch #6. Accuracy on batch 1405/2438  on Training is 69.6523826458037\n",
            "Epoch #6. Accuracy on batch 1406/2438  on Training is 69.65396233120114\n",
            "Epoch #6. Accuracy on batch 1407/2438  on Training is 69.65110085227273\n",
            "Epoch #6. Accuracy on batch 1408/2438  on Training is 69.64824343506032\n",
            "Epoch #6. Accuracy on batch 1409/2438  on Training is 69.64539007092199\n",
            "Epoch #6. Accuracy on batch 1410/2438  on Training is 69.66025868178596\n",
            "Epoch #6. Accuracy on batch 1411/2438  on Training is 69.65518767705383\n",
            "Epoch #6. Accuracy on batch 1412/2438  on Training is 69.65012384996461\n",
            "Epoch #6. Accuracy on batch 1413/2438  on Training is 69.64948727015559\n",
            "Epoch #6. Accuracy on batch 1414/2438  on Training is 69.63339222614842\n",
            "Epoch #6. Accuracy on batch 1415/2438  on Training is 69.63497528248588\n",
            "Epoch #6. Accuracy on batch 1416/2438  on Training is 69.63435074100212\n",
            "Epoch #6. Accuracy on batch 1417/2438  on Training is 69.63152327221438\n",
            "Epoch #6. Accuracy on batch 1418/2438  on Training is 69.6353065539112\n",
            "Epoch #6. Accuracy on batch 1419/2438  on Training is 69.64348591549296\n",
            "Batch Id 1420/2438 is having training loss of 1.1096954345703125\n",
            "1.0913121700286865\n",
            "Epoch #6. Accuracy on batch 1420/2438  on Training is 69.6472554539057\n",
            "Epoch #6. Accuracy on batch 1421/2438  on Training is 69.64882208157525\n",
            "Epoch #6. Accuracy on batch 1422/2438  on Training is 69.64379831342235\n",
            "Epoch #6. Accuracy on batch 1423/2438  on Training is 69.6387816011236\n",
            "Epoch #6. Accuracy on batch 1424/2438  on Training is 69.6469298245614\n",
            "Epoch #6. Accuracy on batch 1425/2438  on Training is 69.64410939691444\n",
            "Epoch #6. Accuracy on batch 1426/2438  on Training is 69.65443237561317\n",
            "Epoch #6. Accuracy on batch 1427/2438  on Training is 69.66036414565826\n",
            "Epoch #6. Accuracy on batch 1428/2438  on Training is 69.65754023792861\n",
            "Epoch #6. Accuracy on batch 1429/2438  on Training is 69.66783216783217\n",
            "Epoch #6. Accuracy on batch 1430/2438  on Training is 69.67155835080364\n",
            "Epoch #6. Accuracy on batch 1431/2438  on Training is 69.6796438547486\n",
            "Epoch #6. Accuracy on batch 1432/2438  on Training is 69.67899511514305\n",
            "Epoch #6. Accuracy on batch 1433/2438  on Training is 69.6848849372385\n",
            "Epoch #6. Accuracy on batch 1434/2438  on Training is 69.68858885017421\n",
            "Epoch #6. Accuracy on batch 1435/2438  on Training is 69.69881615598885\n",
            "Epoch #6. Accuracy on batch 1436/2438  on Training is 69.70250521920669\n",
            "Epoch #6. Accuracy on batch 1437/2438  on Training is 69.70618915159945\n",
            "Epoch #6. Accuracy on batch 1438/2438  on Training is 69.69900972897845\n",
            "Epoch #6. Accuracy on batch 1439/2438  on Training is 69.69835069444444\n",
            "Batch Id 1440/2438 is having training loss of 1.108193278312683\n",
            "1.4389368295669556\n",
            "Epoch #6. Accuracy on batch 1440/2438  on Training is 69.69769257460098\n",
            "Epoch #6. Accuracy on batch 1441/2438  on Training is 69.69486823855756\n",
            "Epoch #6. Accuracy on batch 1442/2438  on Training is 69.69637907137907\n",
            "Epoch #6. Accuracy on batch 1443/2438  on Training is 69.69788781163435\n",
            "Epoch #6. Accuracy on batch 1444/2438  on Training is 69.70588235294117\n",
            "Epoch #6. Accuracy on batch 1445/2438  on Training is 69.70954356846472\n",
            "Epoch #6. Accuracy on batch 1446/2438  on Training is 69.7110400829302\n",
            "Epoch #6. Accuracy on batch 1447/2438  on Training is 69.71469267955801\n",
            "Epoch #6. Accuracy on batch 1448/2438  on Training is 69.72049689440993\n",
            "Epoch #6. Accuracy on batch 1449/2438  on Training is 69.71767241379311\n",
            "Epoch #6. Accuracy on batch 1450/2438  on Training is 69.71915920055135\n",
            "Epoch #6. Accuracy on batch 1451/2438  on Training is 69.71203512396694\n",
            "Epoch #6. Accuracy on batch 1452/2438  on Training is 69.71782518926359\n",
            "Epoch #6. Accuracy on batch 1453/2438  on Training is 69.71286107290234\n",
            "Epoch #6. Accuracy on batch 1454/2438  on Training is 69.71434707903781\n",
            "Epoch #6. Accuracy on batch 1455/2438  on Training is 69.70724587912088\n",
            "Epoch #6. Accuracy on batch 1456/2438  on Training is 69.70229924502402\n",
            "Epoch #6. Accuracy on batch 1457/2438  on Training is 69.69521604938272\n",
            "Epoch #6. Accuracy on batch 1458/2438  on Training is 69.70099383139136\n",
            "Epoch #6. Accuracy on batch 1459/2438  on Training is 69.6917808219178\n",
            "Batch Id 1460/2438 is having training loss of 1.106942892074585\n",
            "1.064162015914917\n",
            "Epoch #6. Accuracy on batch 1460/2438  on Training is 69.69113620807666\n",
            "Epoch #6. Accuracy on batch 1461/2438  on Training is 69.69049247606019\n",
            "Epoch #6. Accuracy on batch 1462/2438  on Training is 69.68557758031442\n",
            "Epoch #6. Accuracy on batch 1463/2438  on Training is 69.6870730874317\n",
            "Epoch #6. Accuracy on batch 1464/2438  on Training is 69.68856655290102\n",
            "Epoch #6. Accuracy on batch 1465/2438  on Training is 69.69432128240109\n",
            "Epoch #6. Accuracy on batch 1466/2438  on Training is 69.70006816632583\n",
            "Epoch #6. Accuracy on batch 1467/2438  on Training is 69.69942098092643\n",
            "Epoch #6. Accuracy on batch 1468/2438  on Training is 69.69452008168822\n",
            "Epoch #6. Accuracy on batch 1469/2438  on Training is 69.69175170068027\n",
            "Epoch #6. Accuracy on batch 1470/2438  on Training is 69.69536029911625\n",
            "Epoch #6. Accuracy on batch 1471/2438  on Training is 69.70533288043478\n",
            "Epoch #6. Accuracy on batch 1472/2438  on Training is 69.70468431771894\n",
            "Epoch #6. Accuracy on batch 1473/2438  on Training is 69.70403663500679\n",
            "Epoch #6. Accuracy on batch 1474/2438  on Training is 69.70338983050847\n",
            "Epoch #6. Accuracy on batch 1475/2438  on Training is 69.70274390243902\n",
            "Epoch #6. Accuracy on batch 1476/2438  on Training is 69.69151997291807\n",
            "Epoch #6. Accuracy on batch 1477/2438  on Training is 69.69511163734776\n",
            "Epoch #6. Accuracy on batch 1478/2438  on Training is 69.68602096010818\n",
            "Epoch #6. Accuracy on batch 1479/2438  on Training is 69.69172297297297\n",
            "Batch Id 1480/2438 is having training loss of 1.106785774230957\n",
            "0.9483151435852051\n",
            "Epoch #6. Accuracy on batch 1480/2438  on Training is 69.69530722484808\n",
            "Epoch #6. Accuracy on batch 1481/2438  on Training is 69.69677800269906\n",
            "Epoch #6. Accuracy on batch 1482/2438  on Training is 69.70878287255563\n",
            "Epoch #6. Accuracy on batch 1483/2438  on Training is 69.71024258760107\n",
            "Epoch #6. Accuracy on batch 1484/2438  on Training is 69.72222222222223\n",
            "Epoch #6. Accuracy on batch 1485/2438  on Training is 69.72156796769852\n",
            "Epoch #6. Accuracy on batch 1486/2438  on Training is 69.71460995292536\n",
            "Epoch #6. Accuracy on batch 1487/2438  on Training is 69.70766129032258\n",
            "Epoch #6. Accuracy on batch 1488/2438  on Training is 69.70701813297515\n",
            "Epoch #6. Accuracy on batch 1489/2438  on Training is 69.70637583892618\n",
            "Epoch #6. Accuracy on batch 1490/2438  on Training is 69.70573440643864\n",
            "Epoch #6. Accuracy on batch 1491/2438  on Training is 69.7155663538874\n",
            "Epoch #6. Accuracy on batch 1492/2438  on Training is 69.70654722036168\n",
            "Epoch #6. Accuracy on batch 1493/2438  on Training is 69.71218206157965\n",
            "Epoch #6. Accuracy on batch 1494/2438  on Training is 69.72198996655518\n",
            "Epoch #6. Accuracy on batch 1495/2438  on Training is 69.7067179144385\n",
            "Epoch #6. Accuracy on batch 1496/2438  on Training is 69.70190380761522\n",
            "Epoch #6. Accuracy on batch 1497/2438  on Training is 69.69918224299066\n",
            "Epoch #6. Accuracy on batch 1498/2438  on Training is 69.69437958639092\n",
            "Epoch #6. Accuracy on batch 1499/2438  on Training is 69.68541666666667\n",
            "Batch Id 1500/2438 is having training loss of 1.107434630393982\n",
            "1.0781763792037964\n",
            "Epoch #6. Accuracy on batch 1500/2438  on Training is 69.68479347101932\n",
            "Epoch #6. Accuracy on batch 1501/2438  on Training is 69.68209054593875\n",
            "Epoch #6. Accuracy on batch 1502/2438  on Training is 69.67523286759814\n",
            "Epoch #6. Accuracy on batch 1503/2438  on Training is 69.67046210106383\n",
            "Epoch #6. Accuracy on batch 1504/2438  on Training is 69.67607973421927\n",
            "Epoch #6. Accuracy on batch 1505/2438  on Training is 69.67753984063745\n",
            "Epoch #6. Accuracy on batch 1506/2438  on Training is 69.68729263437292\n",
            "Epoch #6. Accuracy on batch 1507/2438  on Training is 69.68252652519894\n",
            "Epoch #6. Accuracy on batch 1508/2438  on Training is 69.68397945659378\n",
            "Epoch #6. Accuracy on batch 1509/2438  on Training is 69.67922185430463\n",
            "Epoch #6. Accuracy on batch 1510/2438  on Training is 69.6744705493051\n",
            "Epoch #6. Accuracy on batch 1511/2438  on Training is 69.67385912698413\n",
            "Epoch #6. Accuracy on batch 1512/2438  on Training is 69.6732485128883\n",
            "Epoch #6. Accuracy on batch 1513/2438  on Training is 69.67057463672391\n",
            "Epoch #6. Accuracy on batch 1514/2438  on Training is 69.6637788778878\n",
            "Epoch #6. Accuracy on batch 1515/2438  on Training is 69.6611147757256\n",
            "Epoch #6. Accuracy on batch 1516/2438  on Training is 69.65639419907713\n",
            "Epoch #6. Accuracy on batch 1517/2438  on Training is 69.6578557312253\n",
            "Epoch #6. Accuracy on batch 1518/2438  on Training is 69.66754443712969\n",
            "Epoch #6. Accuracy on batch 1519/2438  on Training is 69.66488486842105\n",
            "Batch Id 1520/2438 is having training loss of 1.1083197593688965\n",
            "1.064154028892517\n",
            "Epoch #6. Accuracy on batch 1520/2438  on Training is 69.65811965811966\n",
            "Epoch #6. Accuracy on batch 1521/2438  on Training is 69.64725689881735\n",
            "Epoch #6. Accuracy on batch 1522/2438  on Training is 69.65487524622456\n",
            "Epoch #6. Accuracy on batch 1523/2438  on Training is 69.6522309711286\n",
            "Epoch #6. Accuracy on batch 1524/2438  on Training is 69.65573770491804\n",
            "Epoch #6. Accuracy on batch 1525/2438  on Training is 69.65923984272608\n",
            "Epoch #6. Accuracy on batch 1526/2438  on Training is 69.66683038637852\n",
            "Epoch #6. Accuracy on batch 1527/2438  on Training is 69.67236583769633\n",
            "Epoch #6. Accuracy on batch 1528/2438  on Training is 69.66767495094834\n",
            "Epoch #6. Accuracy on batch 1529/2438  on Training is 69.67116013071896\n",
            "Epoch #6. Accuracy on batch 1530/2438  on Training is 69.67055845852384\n",
            "Epoch #6. Accuracy on batch 1531/2438  on Training is 69.66587793733682\n",
            "Epoch #6. Accuracy on batch 1532/2438  on Training is 69.66324200913242\n",
            "Epoch #6. Accuracy on batch 1533/2438  on Training is 69.66672099087353\n",
            "Epoch #6. Accuracy on batch 1534/2438  on Training is 69.66815960912052\n",
            "Epoch #6. Accuracy on batch 1535/2438  on Training is 69.671630859375\n",
            "Epoch #6. Accuracy on batch 1536/2438  on Training is 69.67103122966819\n",
            "Epoch #6. Accuracy on batch 1537/2438  on Training is 69.66636866059818\n",
            "Epoch #6. Accuracy on batch 1538/2438  on Training is 69.66577322936972\n",
            "Epoch #6. Accuracy on batch 1539/2438  on Training is 69.66112012987013\n",
            "Batch Id 1540/2438 is having training loss of 1.1083930730819702\n",
            "1.3456616401672363\n",
            "Epoch #6. Accuracy on batch 1540/2438  on Training is 69.6585009733939\n",
            "Epoch #6. Accuracy on batch 1541/2438  on Training is 69.65385862516213\n",
            "Epoch #6. Accuracy on batch 1542/2438  on Training is 69.65327284510694\n",
            "Epoch #6. Accuracy on batch 1543/2438  on Training is 69.64256800518135\n",
            "Epoch #6. Accuracy on batch 1544/2438  on Training is 69.64199029126213\n",
            "Epoch #6. Accuracy on batch 1545/2438  on Training is 69.64545601552393\n",
            "Epoch #6. Accuracy on batch 1546/2438  on Training is 69.64689722042664\n",
            "Epoch #6. Accuracy on batch 1547/2438  on Training is 69.65237403100775\n",
            "Epoch #6. Accuracy on batch 1548/2438  on Training is 69.65784377017431\n",
            "Epoch #6. Accuracy on batch 1549/2438  on Training is 69.65322580645162\n",
            "Epoch #6. Accuracy on batch 1550/2438  on Training is 69.65062862669245\n",
            "Epoch #6. Accuracy on batch 1551/2438  on Training is 69.6520618556701\n",
            "Epoch #6. Accuracy on batch 1552/2438  on Training is 69.65952994204766\n",
            "Epoch #6. Accuracy on batch 1553/2438  on Training is 69.66296653796654\n",
            "Epoch #6. Accuracy on batch 1554/2438  on Training is 69.65635048231512\n"
          ]
        }
      ],
      "source": [
        "# Загрузка словарей с лоссами\n",
        "if last_epoch is not None:\n",
        "    train_losses = checkpoint['losses_train']\n",
        "    val_losses = checkpoint['losses_val']\n",
        "    train_accuracies = checkpoint['accuracies_train']\n",
        "    val_accuracies = checkpoint['accuracies_val']\n",
        "    train_f1_micros = checkpoint['train_f1_micro']\n",
        "    val_f1_micros = checkpoint['val_f1_micro']\n",
        "    train_f1_macros = checkpoint['train_f1_macro']\n",
        "    val_f1_macros = checkpoint['val_f1_macro']\n",
        "    train_f1_weighteds = checkpoint['train_f1_weighted']\n",
        "    val_f1_weighteds = checkpoint['val_f1_weighted']\n",
        "else:\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    train_f1_micros = []\n",
        "    val_f1_micros = []\n",
        "    train_f1_macros = []\n",
        "    val_f1_macros = []\n",
        "    train_f1_weighteds = []\n",
        "    val_f1_weighteds = []\n",
        "\n",
        "if last_epoch is None:\n",
        "    start_epoch = 0\n",
        "else:\n",
        "    start_epoch = last_epoch +1\n",
        "\n",
        "try:\n",
        "    for epoch in range(start_epoch, n_epochs):\n",
        "        start = time.time()\n",
        "        train_loss, train_accuracy, train_f1_micro, train_f1_macro, train_f1_weighted = train(train_data_loader, epoch)\n",
        "        #val_loss = 0\n",
        "        val_loss, val_accuracy, val_f1_micro, val_f1_macro, val_f1_weighted = val(val_data_loader, epoch)\n",
        "        #lr_scheduler.step()\n",
        "        print(f\"Эпоха #{epoch} train_loss: {train_loss}, val_loss: {val_loss}\")  \n",
        "        end = time.time()\n",
        "        print(f\"Потрачено {round((end - start) / 60, 1)} минут на {epoch} эпоху\")\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "        train_f1_micros.append(train_f1_micro)\n",
        "        val_f1_micros.append(val_f1_micro)\n",
        "        train_f1_macros.append(train_f1_macro)\n",
        "        val_f1_macros.append(val_f1_macro)\n",
        "        train_f1_weighteds.append(train_f1_weighted)\n",
        "        val_f1_weighteds.append(val_f1_weighted)\n",
        "        \n",
        "\n",
        "        torch.save({'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    #'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "                    'losses_train': train_losses,\n",
        "                    'losses_val': val_losses,\n",
        "                    'accuracies_train': train_accuracies,\n",
        "                    'accuracies_val': val_accuracies,\n",
        "                    'f1_micros_train': train_f1_micros,\n",
        "                    'f1_micros_val': val_f1_micros,\n",
        "                    'f1_macros_train': train_f1_macros,\n",
        "                    'f1_macros_val': val_f1_macros,\n",
        "                    'f1_weighteds_train': train_f1_weighteds,\n",
        "                    'f1_weighteds_val': val_f1_weighteds,\n",
        "                    }, os.path.join(checkpoints_path, f'chkpt_classifier_{model_name}_{epoch}.pth'))\n",
        "    \n",
        "        torch.save(model, os.path.join(checkpoints_path, f'model_classifier_{model_name}_{epoch}.pth'))\n",
        "    \n",
        "except KeyboardInterrupt:\n",
        "    print('Прервано пользователем')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(train_f1_micros, label='F1_micro_train')\n",
        "ax.plot(val_f1_micros, label='F1_micro_val')\n",
        "ax.plot(train_f1_macros, label='F1_macro_train')\n",
        "ax.plot(val_f1_macros, label='F1_micro_val')\n",
        "ax.set_title(model_name)\n",
        "ax.set(xlabel='Epoch', ylabel='Loss')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(71, 72)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "item = 13\n",
        "model.eval()\n",
        "pred = model(val_dataset.__getitem__(item)['images'].unsqueeze(0).to(device)).data.max(1,keepdim=True)[1], \n",
        "int(pred[0][0][0]), int(val_dataset.__getitem__(item)['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "r4ln2ar7t_dK"
      },
      "outputs": [],
      "source": [
        "last_epoch = 3\n",
        "model_name = 'detector_resnet50_augmented'\n",
        "\n",
        "\n",
        "if last_epoch == None:\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "else:\n",
        "    # Загрузка весов модели\n",
        "    checkpoint = torch.load(os.path.join(checkpoints_path, f'chkpt_{model_name}_{last_epoch}.pth'), map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
        "    #epoch = checkpoint['epoch']\n",
        "    train_losses = checkpoint['losses_train']\n",
        "    val_losses = checkpoint['losses_val']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 403,
      "metadata": {
        "id": "JYImJAxe8HWu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'step_size': 1,\n",
              " 'gamma': 0.9,\n",
              " 'base_lrs': [0.001],\n",
              " 'last_epoch': 30,\n",
              " 'verbose': False,\n",
              " '_step_count': 31,\n",
              " '_get_lr_called_within_step': False,\n",
              " '_last_lr': [4.239115827521624e-05]}"
            ]
          },
          "execution_count": 403,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_scheduler.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 406,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "RLL0C1078HWu",
        "outputId": "d92014cd-dea2-4e7e-ee4f-d54968066738"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(train_accuracies, label='Train')\n",
        "ax.plot(val_accuracies, label='Val')\n",
        "ax.set_title(model_name)\n",
        "ax.set(xlabel='Epoch', ylabel='Accuracy')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pVD7IpU8HWu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "242586dd62d544a39c122c7b1ed6efc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78cb1778f71b45b88ffdb20bfe0cd66e",
              "IPY_MODEL_6d83c78727204f529982e56c3bfe32c1",
              "IPY_MODEL_55191ea6a8eb4574aff8a9bc21fdd55a"
            ],
            "layout": "IPY_MODEL_ae7f4e349b634abd8b36184774421f7a"
          }
        },
        "4146164713eb4c2db70cf52335398a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55191ea6a8eb4574aff8a9bc21fdd55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b17d80f4da05457781be26c19a1dca17",
            "placeholder": "​",
            "style": "IPY_MODEL_8e403bce502349d28da4553899f80c33",
            "value": " 160M/160M [00:00&lt;00:00, 331MB/s]"
          }
        },
        "6d83c78727204f529982e56c3bfe32c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4146164713eb4c2db70cf52335398a3e",
            "max": 167502836,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e66226838c994913b2d58fd0db3f4282",
            "value": 167502836
          }
        },
        "78cb1778f71b45b88ffdb20bfe0cd66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e012c54a3a9f48b38c500c17227f67b8",
            "placeholder": "​",
            "style": "IPY_MODEL_91eb94ac4f6347c6b7d860b73e3742da",
            "value": "100%"
          }
        },
        "8e403bce502349d28da4553899f80c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91eb94ac4f6347c6b7d860b73e3742da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae7f4e349b634abd8b36184774421f7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b17d80f4da05457781be26c19a1dca17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e012c54a3a9f48b38c500c17227f67b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e66226838c994913b2d58fd0db3f4282": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
