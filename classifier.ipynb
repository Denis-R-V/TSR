{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Denis-R-V/TSR/blob/main/sign_detector_augmentated_v1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ8-zW_yJ279"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis-R-V/TSR/blob/main/sign_detector.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xtJ8o7tJ27-"
      },
      "source": [
        "# Система распознавания дорожных знаков на датасете RTSD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "colab = False\n",
        "\n",
        "if colab == True:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    !pip install kaggle\n",
        "    !mkdir ~/.kaggle\n",
        "    !cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "    !kaggle datasets download watchman/rtsd-dataset\n",
        "    !unzip rtsd-dataset.zip\n",
        "    !rm rtsd-dataset.zip\n",
        "    !cp -r rtsd-frames/rtsd-frames/ .\n",
        "    !rm -r rtsd-frames/rtsd-frames/\n",
        "    !pip install fiftyone\n",
        "if colab == True:\n",
        "    dataset_path = '.'\n",
        "    checkpoints_path = '../content/drive/MyDrive/TSR/checkpoints'\n",
        "else:\n",
        "    dataset_path = 'data'\n",
        "    checkpoints_path = 'checkpoints'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "#import matplotlib.patches as patches\n",
        "#%matplotlib inline\n",
        "\n",
        "#from pycocotools.coco import COCO\n",
        "#import fiftyone as fo\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "#from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "#from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models import resnet152\n",
        "#import cv2\n",
        "#PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k69EoY9zJ28Y"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRRoJ7Q4J28Z"
      },
      "source": [
        "### Загрузчик данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RTSD_dataset_classifier(Dataset):\n",
        "    def __init__(self, json_path, img_path, transforms):\n",
        "        self.json_path = json_path\n",
        "        self.img_path = img_path\n",
        "        self.transforms = transforms\n",
        "        \n",
        "        with open(json_path, 'r') as read_file:\n",
        "            self.anno = json.load(read_file)\n",
        "        read_file.close()\n",
        "\n",
        "        self.df_anno = pd.DataFrame(self.anno.get('annotations'))[['image_id','bbox','category_id']]\n",
        "        self.df_images = pd.DataFrame(self.anno.get('images'))[['id','file_name']]\n",
        "        self.df_dataset = self.df_anno.merge(self.df_images, left_on='image_id', right_on='id',)[['file_name','bbox','category_id']]\n",
        "        self.labels = torch.eye(156)[self.df_dataset['category_id']]\n",
        "    def __len__(self):\n",
        "        return self.df_dataset.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.df_dataset.loc[index,'file_name']\n",
        "        bbox = self.df_dataset.loc[index,'bbox']\n",
        "        bbox = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]\n",
        "        img = Image.open(os.path.join(self.img_path, img_name))\n",
        "        img = img.crop(bbox)\n",
        "        img = self.transforms(img)\n",
        "        label = torch.tensor(self.df_dataset.loc[index,'category_id'] - 1)\n",
        "        \n",
        "        return {'images':img, 'labels':label}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_transform(train):\n",
        "    if train == True:\n",
        "        return transforms.Compose([transforms.Resize((224,224)),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   #transforms.Normalize([0.496, 0.456, 0.406],\n",
        "                                   #                     [0.229, 0.224, 0.225])\n",
        "                                   ])\n",
        "    else:\n",
        "        return transforms.Compose([transforms.Resize((224,224)),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   #transforms.Normalize([0.496, 0.456, 0.406],\n",
        "                                   #                     [0.229, 0.224, 0.225])\n",
        "                                   ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {},
      "outputs": [],
      "source": [
        "test = RTSD_dataset_classifier(json_path = os.path.join(dataset_path, 'train_anno_reduced.json'),\n",
        "                               img_path = dataset_path,\n",
        "                               transforms = get_transform(train=True)\n",
        "                               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'images': tensor([[[0.2627, 0.2627, 0.2627,  ..., 0.4745, 0.4745, 0.4745],\n",
              "          [0.2627, 0.2627, 0.2627,  ..., 0.4745, 0.4745, 0.4745],\n",
              "          [0.2627, 0.2627, 0.2627,  ..., 0.4745, 0.4745, 0.4745],\n",
              "          ...,\n",
              "          [0.1608, 0.1608, 0.1608,  ..., 0.3843, 0.3843, 0.3843],\n",
              "          [0.1608, 0.1608, 0.1608,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          [0.1608, 0.1608, 0.1608,  ..., 0.3804, 0.3804, 0.3804]],\n",
              " \n",
              "         [[0.2627, 0.2627, 0.2627,  ..., 0.5098, 0.5098, 0.5098],\n",
              "          [0.2627, 0.2627, 0.2627,  ..., 0.5098, 0.5098, 0.5098],\n",
              "          [0.2627, 0.2627, 0.2627,  ..., 0.5098, 0.5098, 0.5098],\n",
              "          ...,\n",
              "          [0.1608, 0.1608, 0.1608,  ..., 0.3843, 0.3843, 0.3843],\n",
              "          [0.1608, 0.1608, 0.1608,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          [0.1608, 0.1608, 0.1608,  ..., 0.3804, 0.3804, 0.3804]],\n",
              " \n",
              "         [[0.2627, 0.2627, 0.2627,  ..., 0.4980, 0.4980, 0.4980],\n",
              "          [0.2627, 0.2627, 0.2627,  ..., 0.4980, 0.4980, 0.4980],\n",
              "          [0.2627, 0.2627, 0.2627,  ..., 0.4980, 0.4980, 0.4980],\n",
              "          ...,\n",
              "          [0.1608, 0.1608, 0.1608,  ..., 0.3843, 0.3843, 0.3843],\n",
              "          [0.1608, 0.1608, 0.1608,  ..., 0.3804, 0.3804, 0.3804],\n",
              "          [0.1608, 0.1608, 0.1608,  ..., 0.3804, 0.3804, 0.3804]]]),\n",
              " 'labels': tensor(154)}"
            ]
          },
          "execution_count": 297,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.__getitem__(2324)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.]])"
            ]
          },
          "execution_count": 298,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_sign(index):\n",
        "    item = test.__getitem__(index)\n",
        "    img = item['images']\n",
        "    target = item['labels']\n",
        "    #img, target = test.__getitem__(index)\n",
        "    img = img.permute(1, 2, 0).detach().numpy()\n",
        "    img = img*255\n",
        "    img = img.astype(np.uint8)\n",
        "    fig, a = plt.subplots(1,1)\n",
        "    #fig.set_size_inches(10,10)\n",
        "    display(int(target.cpu().detach().numpy()))\n",
        "    a.imshow(img)\n",
        "    return None\n",
        "plot_sign(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TnfiyYUJ28Z"
      },
      "source": [
        "### Формирование батча"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn_conv(data: list):\n",
        "  # data = [(pic, target)...]\n",
        "  pics = []\n",
        "  target = []\n",
        "  for item in data:\n",
        "    pics.append(np.array(item[0]))\n",
        "    target.append(item[1])\n",
        "  pics = torch.from_numpy(np.array(pics)).float() #/ 255 # B x W x H\n",
        "  target = torch.from_numpy(np.array(target))\n",
        "\n",
        "  return {\n",
        "      # метод unsqueeze добавляет метод измерения в тензоре\n",
        "      # сверточный слой ждет число каналов (изображения подаются поканально)\n",
        "      'data': pics, # B x 1 x W x H\n",
        "      'target': target.long(),\n",
        "      }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_list = []\n",
        "for i in range(8):\n",
        "    data_list.append(test.__getitem__(i))\n",
        "data_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8, 3, 224, 224])"
            ]
          },
          "execution_count": 186,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "collate_fn_conv(data_list).get('data').shape, collate_fn_conv(data_list).get('target').shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "ltY8LK2BJ28Z"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J90qxR2RJ28Z"
      },
      "source": [
        "### Гиперпараметры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {
        "id": "CI7vlkQPJ28Z"
      },
      "outputs": [],
      "source": [
        "device_id = 0\n",
        "if torch.cuda.is_available() == True:\n",
        "    device = f'cuda:{device_id}'\n",
        "elif torch.backends.mps.is_available() == True:\n",
        "    device = 'mps'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "n_epochs = 10\n",
        "batch_size = 8\n",
        "num_classes = 155"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HsbUmnfKyhlr",
        "outputId": "96e3d4b4-b23b-4653-972d-828936361e5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "execution_count": 318,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo40ASBXJ28Z"
      },
      "source": [
        "### Инициализация модели, задание оптимизатора и функции потерь"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {
        "id": "TNQ4zYcHtHId"
      },
      "outputs": [],
      "source": [
        "def create_model(num_classes):\n",
        "    model = resnet152(weights='ResNet152_Weights.IMAGENET1K_V1')\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    model.fc = nn.Sequential(nn.Linear(2048, 1024), nn.Linear(1024, num_classes))\n",
        "    for param in model.fc.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    #torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='FasterRCNN_ResNet50_FPN_Weights.COCO_V1')\n",
        "    #in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    #model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "242586dd62d544a39c122c7b1ed6efc9",
            "78cb1778f71b45b88ffdb20bfe0cd66e",
            "6d83c78727204f529982e56c3bfe32c1",
            "55191ea6a8eb4574aff8a9bc21fdd55a",
            "ae7f4e349b634abd8b36184774421f7a",
            "e012c54a3a9f48b38c500c17227f67b8",
            "91eb94ac4f6347c6b7d860b73e3742da",
            "4146164713eb4c2db70cf52335398a3e",
            "e66226838c994913b2d58fd0db3f4282",
            "b17d80f4da05457781be26c19a1dca17",
            "8e403bce502349d28da4553899f80c33"
          ]
        },
        "id": "ZdWxX5-PJ28Z",
        "outputId": "d572c5f8-341f-46c4-adb3-14866216da69"
      },
      "outputs": [],
      "source": [
        "model = create_model(num_classes).to(device)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# parameters\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "#params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.0005)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "\n",
        "\n",
        "\n",
        "#optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "    # and a learning rate scheduler\n",
        "#lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "#lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "train_dataset = RTSD_dataset_classifier(json_path = os.path.join(dataset_path, 'train_anno_reduced.json'),\n",
        "                                        img_path = dataset_path,\n",
        "                                        transforms = get_transform(train=True)\n",
        "                                        )\n",
        "val_dataset = RTSD_dataset_classifier(os.path.join(dataset_path, 'val_anno.json'),\n",
        "                                        dataset_path,\n",
        "                                          transforms = get_transform(train=False)\n",
        "                                          )\n",
        "\n",
        "train_data_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    #sampler=SubsetRandomSampler(),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    #num_workers=4,\n",
        "    #collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_data_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    #sampler=SubsetRandomSampler(),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    #num_workers=4,\n",
        "    #collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YimGoL3J28Z"
      },
      "source": [
        "### Трейн луп"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {},
      "outputs": [],
      "source": [
        "for batch_idx, data in enumerate(train_data_loader):\n",
        "    a = data\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 55],\n",
              "        [  3],\n",
              "        [115],\n",
              "        [ 46],\n",
              "        [124],\n",
              "        [ 49],\n",
              "        [ 35],\n",
              "        [111],\n",
              "        [147],\n",
              "        [ 57],\n",
              "        [138],\n",
              "        [109],\n",
              "        [ 99],\n",
              "        [ 79],\n",
              "        [146],\n",
              "        [ 71]])"
            ]
          },
          "execution_count": 239,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(train_dataloader, epoch): \n",
        "    len_dataloader = len(train_dataloader)\n",
        "\n",
        "    training_loss=0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0        # training_loss\n",
        "    for batch_idx, data in enumerate(train_dataloader):\n",
        "        \n",
        "        \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        #images, targets = data[0], data[1]\n",
        "        #images = images.to(device)\n",
        "        #targets = targets.to(device)\n",
        "        images = data['images'].to(device)\n",
        "        targets = data['labels'].to(device)\n",
        "        output = model(images)\n",
        "        loss = loss_function(output, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        training_loss =  + ((1/(batch_idx+1))*(loss.data-training_loss))\n",
        "        if batch_idx%50 == 0:\n",
        "            print(f\"Training loss {training_loss}\")\n",
        "            print(loss.item())\n",
        "\n",
        "        pred = output.data.max(1,keepdim=True)[1]\n",
        "        correct += np.sum(np.squeeze(pred.eq(targets.data.view_as(pred))).cpu().numpy())\n",
        "        print(f\"Accuracy on batch {batch_idx} on Training id {(100*correct/total)}\")\n",
        "\n",
        "\n",
        "        #images = list(image.to(device) for image in images)\n",
        "        #targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        #loss_dict = model(images, targets)\n",
        "        #loss = sum(loss for loss in loss_dict.values())\n",
        "        #running_loss += loss.item()\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "        #if batch_idx % 50 == 0:\n",
        "        #    print(f\"\\tЭпоха {epoch}. Итерация {batch_idx}/{len_dataloader}. Loss: {loss}\")\n",
        "    train_loss = running_loss/len(train_dataloader.dataset)\n",
        "    return train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss 5.0490946769714355\n",
            "5.0490946769714355\n",
            "Accuracy on batch 0 on Training id nan\n",
            "Accuracy on batch 1 on Training id nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15992\\3059405845.py:32: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  print(f\"Accuracy on batch {batch_idx} on Training id {(100*correct/total)}\")\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15992\\3059405845.py:32: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  print(f\"Accuracy on batch {batch_idx} on Training id {(100*correct/total)}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on batch 2 on Training id inf\n",
            "Accuracy on batch 3 on Training id inf\n",
            "Accuracy on batch 4 on Training id inf\n",
            "Accuracy on batch 5 on Training id inf\n",
            "Accuracy on batch 6 on Training id inf\n",
            "Accuracy on batch 7 on Training id inf\n",
            "Accuracy on batch 8 on Training id inf\n",
            "Accuracy on batch 9 on Training id inf\n",
            "Accuracy on batch 10 on Training id inf\n",
            "Accuracy on batch 11 on Training id inf\n",
            "Accuracy on batch 12 on Training id inf\n",
            "Accuracy on batch 13 on Training id inf\n",
            "Accuracy on batch 14 on Training id inf\n",
            "Accuracy on batch 15 on Training id inf\n",
            "Accuracy on batch 16 on Training id inf\n",
            "Accuracy on batch 17 on Training id inf\n",
            "Accuracy on batch 18 on Training id inf\n",
            "Accuracy on batch 19 on Training id inf\n",
            "Accuracy on batch 20 on Training id inf\n",
            "Accuracy on batch 21 on Training id inf\n",
            "Accuracy on batch 22 on Training id inf\n",
            "Accuracy on batch 23 on Training id inf\n",
            "Accuracy on batch 24 on Training id inf\n",
            "Accuracy on batch 25 on Training id inf\n",
            "Accuracy on batch 26 on Training id inf\n",
            "Accuracy on batch 27 on Training id inf\n",
            "Accuracy on batch 28 on Training id inf\n",
            "Accuracy on batch 29 on Training id inf\n",
            "Accuracy on batch 30 on Training id inf\n",
            "Accuracy on batch 31 on Training id inf\n",
            "Accuracy on batch 32 on Training id inf\n",
            "Accuracy on batch 33 on Training id inf\n",
            "Accuracy on batch 34 on Training id inf\n",
            "Accuracy on batch 35 on Training id inf\n",
            "Accuracy on batch 36 on Training id inf\n",
            "Accuracy on batch 37 on Training id inf\n",
            "Accuracy on batch 38 on Training id inf\n",
            "Accuracy on batch 39 on Training id inf\n",
            "Accuracy on batch 40 on Training id inf\n",
            "Accuracy on batch 41 on Training id inf\n",
            "Accuracy on batch 42 on Training id inf\n",
            "Accuracy on batch 43 on Training id inf\n",
            "Accuracy on batch 44 on Training id inf\n",
            "Accuracy on batch 45 on Training id inf\n",
            "Accuracy on batch 46 on Training id inf\n",
            "Accuracy on batch 47 on Training id inf\n",
            "Accuracy on batch 48 on Training id inf\n",
            "Accuracy on batch 49 on Training id inf\n",
            "Training loss 0.08853742480278015\n",
            "4.622588157653809\n",
            "Accuracy on batch 50 on Training id inf\n",
            "Accuracy on batch 51 on Training id inf\n",
            "Accuracy on batch 52 on Training id inf\n",
            "Accuracy on batch 53 on Training id inf\n",
            "Accuracy on batch 54 on Training id inf\n",
            "Accuracy on batch 55 on Training id inf\n",
            "Accuracy on batch 56 on Training id inf\n",
            "Accuracy on batch 57 on Training id inf\n",
            "Accuracy on batch 58 on Training id inf\n",
            "Accuracy on batch 59 on Training id inf\n",
            "Accuracy on batch 60 on Training id inf\n",
            "Accuracy on batch 61 on Training id inf\n",
            "Accuracy on batch 62 on Training id inf\n",
            "Accuracy on batch 63 on Training id inf\n",
            "Accuracy on batch 64 on Training id inf\n",
            "Accuracy on batch 65 on Training id inf\n",
            "Accuracy on batch 66 on Training id inf\n",
            "Accuracy on batch 67 on Training id inf\n",
            "Accuracy on batch 68 on Training id inf\n",
            "Accuracy on batch 69 on Training id inf\n",
            "Accuracy on batch 70 on Training id inf\n",
            "Accuracy on batch 71 on Training id inf\n",
            "Accuracy on batch 72 on Training id inf\n",
            "Accuracy on batch 73 on Training id inf\n",
            "Accuracy on batch 74 on Training id inf\n",
            "Accuracy on batch 75 on Training id inf\n",
            "Accuracy on batch 76 on Training id inf\n",
            "Accuracy on batch 77 on Training id inf\n",
            "Accuracy on batch 78 on Training id inf\n",
            "Accuracy on batch 79 on Training id inf\n",
            "Accuracy on batch 80 on Training id inf\n",
            "Accuracy on batch 81 on Training id inf\n",
            "Accuracy on batch 82 on Training id inf\n",
            "Accuracy on batch 83 on Training id inf\n",
            "Accuracy on batch 84 on Training id inf\n",
            "Accuracy on batch 85 on Training id inf\n",
            "Accuracy on batch 86 on Training id inf\n",
            "Accuracy on batch 87 on Training id inf\n",
            "Accuracy on batch 88 on Training id inf\n",
            "Accuracy on batch 89 on Training id inf\n",
            "Accuracy on batch 90 on Training id inf\n",
            "Accuracy on batch 91 on Training id inf\n",
            "Accuracy on batch 92 on Training id inf\n",
            "Accuracy on batch 93 on Training id inf\n",
            "Accuracy on batch 94 on Training id inf\n",
            "Accuracy on batch 95 on Training id inf\n",
            "Accuracy on batch 96 on Training id inf\n",
            "Accuracy on batch 97 on Training id inf\n",
            "Accuracy on batch 98 on Training id inf\n",
            "Accuracy on batch 99 on Training id inf\n",
            "Training loss 0.04439159855246544\n",
            "4.530399322509766\n",
            "Accuracy on batch 100 on Training id inf\n",
            "Accuracy on batch 101 on Training id inf\n",
            "Accuracy on batch 102 on Training id inf\n",
            "Accuracy on batch 103 on Training id inf\n",
            "Accuracy on batch 104 on Training id inf\n",
            "Accuracy on batch 105 on Training id inf\n",
            "Accuracy on batch 106 on Training id inf\n",
            "Accuracy on batch 107 on Training id inf\n",
            "Accuracy on batch 108 on Training id inf\n",
            "Accuracy on batch 109 on Training id inf\n",
            "Accuracy on batch 110 on Training id inf\n",
            "Accuracy on batch 111 on Training id inf\n",
            "Accuracy on batch 112 on Training id inf\n",
            "Accuracy on batch 113 on Training id inf\n",
            "Accuracy on batch 114 on Training id inf\n",
            "Accuracy on batch 115 on Training id inf\n",
            "Accuracy on batch 116 on Training id inf\n",
            "Accuracy on batch 117 on Training id inf\n",
            "Accuracy on batch 118 on Training id inf\n",
            "Accuracy on batch 119 on Training id inf\n",
            "Accuracy on batch 120 on Training id inf\n",
            "Accuracy on batch 121 on Training id inf\n",
            "Accuracy on batch 122 on Training id inf\n",
            "Accuracy on batch 123 on Training id inf\n",
            "Accuracy on batch 124 on Training id inf\n",
            "Accuracy on batch 125 on Training id inf\n",
            "Accuracy on batch 126 on Training id inf\n",
            "Accuracy on batch 127 on Training id inf\n",
            "Accuracy on batch 128 on Training id inf\n",
            "Accuracy on batch 129 on Training id inf\n",
            "Accuracy on batch 130 on Training id inf\n",
            "Accuracy on batch 131 on Training id inf\n",
            "Accuracy on batch 132 on Training id inf\n",
            "Accuracy on batch 133 on Training id inf\n",
            "Accuracy on batch 134 on Training id inf\n",
            "Accuracy on batch 135 on Training id inf\n",
            "Accuracy on batch 136 on Training id inf\n",
            "Accuracy on batch 137 on Training id inf\n",
            "Accuracy on batch 138 on Training id inf\n",
            "Accuracy on batch 139 on Training id inf\n",
            "Accuracy on batch 140 on Training id inf\n",
            "Accuracy on batch 141 on Training id inf\n",
            "Accuracy on batch 142 on Training id inf\n",
            "Accuracy on batch 143 on Training id inf\n",
            "Accuracy on batch 144 on Training id inf\n",
            "Accuracy on batch 145 on Training id inf\n",
            "Accuracy on batch 146 on Training id inf\n",
            "Accuracy on batch 147 on Training id inf\n",
            "Accuracy on batch 148 on Training id inf\n",
            "Accuracy on batch 149 on Training id inf\n",
            "Training loss 0.026045214384794235\n",
            "3.960392951965332\n",
            "Accuracy on batch 150 on Training id inf\n",
            "Accuracy on batch 151 on Training id inf\n",
            "Accuracy on batch 152 on Training id inf\n",
            "Accuracy on batch 153 on Training id inf\n",
            "Accuracy on batch 154 on Training id inf\n",
            "Accuracy on batch 155 on Training id inf\n",
            "Accuracy on batch 156 on Training id inf\n",
            "Accuracy on batch 157 on Training id inf\n",
            "Accuracy on batch 158 on Training id inf\n",
            "Accuracy on batch 159 on Training id inf\n",
            "Accuracy on batch 160 on Training id inf\n",
            "Accuracy on batch 161 on Training id inf\n",
            "Accuracy on batch 162 on Training id inf\n",
            "Accuracy on batch 163 on Training id inf\n",
            "Accuracy on batch 164 on Training id inf\n",
            "Accuracy on batch 165 on Training id inf\n",
            "Accuracy on batch 166 on Training id inf\n",
            "Accuracy on batch 167 on Training id inf\n",
            "Accuracy on batch 168 on Training id inf\n",
            "Accuracy on batch 169 on Training id inf\n",
            "Accuracy on batch 170 on Training id inf\n",
            "Accuracy on batch 171 on Training id inf\n",
            "Accuracy on batch 172 on Training id inf\n",
            "Accuracy on batch 173 on Training id inf\n",
            "Accuracy on batch 174 on Training id inf\n",
            "Accuracy on batch 175 on Training id inf\n",
            "Accuracy on batch 176 on Training id inf\n",
            "Accuracy on batch 177 on Training id inf\n",
            "Accuracy on batch 178 on Training id inf\n",
            "Accuracy on batch 179 on Training id inf\n",
            "Accuracy on batch 180 on Training id inf\n",
            "Accuracy on batch 181 on Training id inf\n",
            "Accuracy on batch 182 on Training id inf\n",
            "Accuracy on batch 183 on Training id inf\n",
            "Accuracy on batch 184 on Training id inf\n",
            "Accuracy on batch 185 on Training id inf\n",
            "Accuracy on batch 186 on Training id inf\n",
            "Accuracy on batch 187 on Training id inf\n",
            "Accuracy on batch 188 on Training id inf\n",
            "Accuracy on batch 189 on Training id inf\n",
            "Accuracy on batch 190 on Training id inf\n",
            "Accuracy on batch 191 on Training id inf\n",
            "Accuracy on batch 192 on Training id inf\n",
            "Accuracy on batch 193 on Training id inf\n",
            "Accuracy on batch 194 on Training id inf\n",
            "Accuracy on batch 195 on Training id inf\n",
            "Accuracy on batch 196 on Training id inf\n",
            "Accuracy on batch 197 on Training id inf\n",
            "Accuracy on batch 198 on Training id inf\n",
            "Accuracy on batch 199 on Training id inf\n",
            "Training loss 0.019852347671985626\n",
            "4.011867523193359\n",
            "Accuracy on batch 200 on Training id inf\n",
            "Accuracy on batch 201 on Training id inf\n",
            "Accuracy on batch 202 on Training id inf\n",
            "Accuracy on batch 203 on Training id inf\n",
            "Accuracy on batch 204 on Training id inf\n",
            "Accuracy on batch 205 on Training id inf\n",
            "Accuracy on batch 206 on Training id inf\n",
            "Accuracy on batch 207 on Training id inf\n",
            "Accuracy on batch 208 on Training id inf\n",
            "Accuracy on batch 209 on Training id inf\n",
            "Accuracy on batch 210 on Training id inf\n",
            "Accuracy on batch 211 on Training id inf\n",
            "Accuracy on batch 212 on Training id inf\n",
            "Accuracy on batch 213 on Training id inf\n",
            "Accuracy on batch 214 on Training id inf\n",
            "Accuracy on batch 215 on Training id inf\n",
            "Accuracy on batch 216 on Training id inf\n",
            "Accuracy on batch 217 on Training id inf\n",
            "Accuracy on batch 218 on Training id inf\n",
            "Accuracy on batch 219 on Training id inf\n",
            "Accuracy on batch 220 on Training id inf\n",
            "Accuracy on batch 221 on Training id inf\n",
            "Accuracy on batch 222 on Training id inf\n",
            "Accuracy on batch 223 on Training id inf\n",
            "Accuracy on batch 224 on Training id inf\n",
            "Accuracy on batch 225 on Training id inf\n",
            "Accuracy on batch 226 on Training id inf\n",
            "Accuracy on batch 227 on Training id inf\n",
            "Accuracy on batch 228 on Training id inf\n",
            "Accuracy on batch 229 on Training id inf\n",
            "Accuracy on batch 230 on Training id inf\n",
            "Accuracy on batch 231 on Training id inf\n",
            "Accuracy on batch 232 on Training id inf\n",
            "Accuracy on batch 233 on Training id inf\n",
            "Accuracy on batch 234 on Training id inf\n",
            "Accuracy on batch 235 on Training id inf\n",
            "Accuracy on batch 236 on Training id inf\n",
            "Accuracy on batch 237 on Training id inf\n",
            "Accuracy on batch 238 on Training id inf\n",
            "Accuracy on batch 239 on Training id inf\n",
            "Accuracy on batch 240 on Training id inf\n",
            "Accuracy on batch 241 on Training id inf\n",
            "Accuracy on batch 242 on Training id inf\n",
            "Accuracy on batch 243 on Training id inf\n",
            "Accuracy on batch 244 on Training id inf\n",
            "Accuracy on batch 245 on Training id inf\n",
            "Accuracy on batch 246 on Training id inf\n",
            "Accuracy on batch 247 on Training id inf\n",
            "Accuracy on batch 248 on Training id inf\n",
            "Accuracy on batch 249 on Training id inf\n",
            "Training loss 0.014253501780331135\n",
            "3.594939708709717\n",
            "Accuracy on batch 250 on Training id inf\n",
            "Accuracy on batch 251 on Training id inf\n",
            "Accuracy on batch 252 on Training id inf\n",
            "Accuracy on batch 253 on Training id inf\n",
            "Accuracy on batch 254 on Training id inf\n",
            "Accuracy on batch 255 on Training id inf\n",
            "Accuracy on batch 256 on Training id inf\n",
            "Accuracy on batch 257 on Training id inf\n",
            "Accuracy on batch 258 on Training id inf\n",
            "Accuracy on batch 259 on Training id inf\n",
            "Accuracy on batch 260 on Training id inf\n",
            "Accuracy on batch 261 on Training id inf\n",
            "Accuracy on batch 262 on Training id inf\n",
            "Accuracy on batch 263 on Training id inf\n",
            "Accuracy on batch 264 on Training id inf\n",
            "Accuracy on batch 265 on Training id inf\n",
            "Accuracy on batch 266 on Training id inf\n",
            "Accuracy on batch 267 on Training id inf\n",
            "Accuracy on batch 268 on Training id inf\n",
            "Accuracy on batch 269 on Training id inf\n",
            "Accuracy on batch 270 on Training id inf\n",
            "Accuracy on batch 271 on Training id inf\n",
            "Accuracy on batch 272 on Training id inf\n",
            "Accuracy on batch 273 on Training id inf\n",
            "Accuracy on batch 274 on Training id inf\n",
            "Accuracy on batch 275 on Training id inf\n",
            "Accuracy on batch 276 on Training id inf\n",
            "Accuracy on batch 277 on Training id inf\n",
            "Accuracy on batch 278 on Training id inf\n",
            "Accuracy on batch 279 on Training id inf\n",
            "Accuracy on batch 280 on Training id inf\n",
            "Accuracy on batch 281 on Training id inf\n",
            "Accuracy on batch 282 on Training id inf\n",
            "Accuracy on batch 283 on Training id inf\n",
            "Accuracy on batch 284 on Training id inf\n",
            "Accuracy on batch 285 on Training id inf\n",
            "Accuracy on batch 286 on Training id inf\n",
            "Accuracy on batch 287 on Training id inf\n",
            "Accuracy on batch 288 on Training id inf\n",
            "Accuracy on batch 289 on Training id inf\n",
            "Accuracy on batch 290 on Training id inf\n",
            "Эпоха #0 train_loss: 0.0, val_loss: 0\n",
            "Потрачено 0.4 минут на 0 эпоху\n",
            "Training loss 2.987983226776123\n",
            "2.987983226776123\n",
            "Accuracy on batch 0 on Training id inf\n",
            "Accuracy on batch 1 on Training id inf\n",
            "Accuracy on batch 2 on Training id inf\n",
            "Accuracy on batch 3 on Training id inf\n",
            "Accuracy on batch 4 on Training id inf\n",
            "Accuracy on batch 5 on Training id inf\n",
            "Accuracy on batch 6 on Training id inf\n",
            "Accuracy on batch 7 on Training id inf\n",
            "Accuracy on batch 8 on Training id inf\n",
            "Accuracy on batch 9 on Training id inf\n",
            "Accuracy on batch 10 on Training id inf\n",
            "Accuracy on batch 11 on Training id inf\n",
            "Accuracy on batch 12 on Training id inf\n",
            "Accuracy on batch 13 on Training id inf\n",
            "Accuracy on batch 14 on Training id inf\n",
            "Accuracy on batch 15 on Training id inf\n",
            "Accuracy on batch 16 on Training id inf\n",
            "Accuracy on batch 17 on Training id inf\n",
            "Accuracy on batch 18 on Training id inf\n",
            "Accuracy on batch 19 on Training id inf\n",
            "Accuracy on batch 20 on Training id inf\n",
            "Accuracy on batch 21 on Training id inf\n",
            "Accuracy on batch 22 on Training id inf\n",
            "Accuracy on batch 23 on Training id inf\n",
            "Accuracy on batch 24 on Training id inf\n",
            "Accuracy on batch 25 on Training id inf\n",
            "Accuracy on batch 26 on Training id inf\n",
            "Accuracy on batch 27 on Training id inf\n",
            "Accuracy on batch 28 on Training id inf\n",
            "Accuracy on batch 29 on Training id inf\n",
            "Accuracy on batch 30 on Training id inf\n",
            "Accuracy on batch 31 on Training id inf\n",
            "Accuracy on batch 32 on Training id inf\n",
            "Accuracy on batch 33 on Training id inf\n",
            "Accuracy on batch 34 on Training id inf\n",
            "Accuracy on batch 35 on Training id inf\n",
            "Accuracy on batch 36 on Training id inf\n",
            "Accuracy on batch 37 on Training id inf\n",
            "Accuracy on batch 38 on Training id inf\n",
            "Accuracy on batch 39 on Training id inf\n",
            "Accuracy on batch 40 on Training id inf\n",
            "Accuracy on batch 41 on Training id inf\n",
            "Accuracy on batch 42 on Training id inf\n",
            "Accuracy on batch 43 on Training id inf\n",
            "Accuracy on batch 44 on Training id inf\n",
            "Accuracy on batch 45 on Training id inf\n",
            "Accuracy on batch 46 on Training id inf\n",
            "Accuracy on batch 47 on Training id inf\n",
            "Accuracy on batch 48 on Training id inf\n",
            "Accuracy on batch 49 on Training id inf\n",
            "Training loss 0.06991387903690338\n",
            "3.6315085887908936\n",
            "Accuracy on batch 50 on Training id inf\n",
            "Accuracy on batch 51 on Training id inf\n",
            "Accuracy on batch 52 on Training id inf\n",
            "Accuracy on batch 53 on Training id inf\n",
            "Accuracy on batch 54 on Training id inf\n",
            "Accuracy on batch 55 on Training id inf\n",
            "Accuracy on batch 56 on Training id inf\n",
            "Accuracy on batch 57 on Training id inf\n",
            "Accuracy on batch 58 on Training id inf\n",
            "Accuracy on batch 59 on Training id inf\n",
            "Accuracy on batch 60 on Training id inf\n",
            "Accuracy on batch 61 on Training id inf\n",
            "Accuracy on batch 62 on Training id inf\n",
            "Accuracy on batch 63 on Training id inf\n",
            "Accuracy on batch 64 on Training id inf\n",
            "Accuracy on batch 65 on Training id inf\n",
            "Accuracy on batch 66 on Training id inf\n",
            "Accuracy on batch 67 on Training id inf\n",
            "Accuracy on batch 68 on Training id inf\n",
            "Accuracy on batch 69 on Training id inf\n",
            "Accuracy on batch 70 on Training id inf\n",
            "Accuracy on batch 71 on Training id inf\n",
            "Accuracy on batch 72 on Training id inf\n",
            "Accuracy on batch 73 on Training id inf\n",
            "Accuracy on batch 74 on Training id inf\n",
            "Accuracy on batch 75 on Training id inf\n",
            "Accuracy on batch 76 on Training id inf\n",
            "Accuracy on batch 77 on Training id inf\n",
            "Accuracy on batch 78 on Training id inf\n",
            "Accuracy on batch 79 on Training id inf\n",
            "Accuracy on batch 80 on Training id inf\n",
            "Accuracy on batch 81 on Training id inf\n",
            "Accuracy on batch 82 on Training id inf\n",
            "Accuracy on batch 83 on Training id inf\n",
            "Accuracy on batch 84 on Training id inf\n",
            "Accuracy on batch 85 on Training id inf\n",
            "Accuracy on batch 86 on Training id inf\n",
            "Accuracy on batch 87 on Training id inf\n",
            "Accuracy on batch 88 on Training id inf\n",
            "Accuracy on batch 89 on Training id inf\n",
            "Accuracy on batch 90 on Training id inf\n",
            "Accuracy on batch 91 on Training id inf\n",
            "Accuracy on batch 92 on Training id inf\n",
            "Accuracy on batch 93 on Training id inf\n",
            "Accuracy on batch 94 on Training id inf\n",
            "Accuracy on batch 95 on Training id inf\n",
            "Accuracy on batch 96 on Training id inf\n",
            "Accuracy on batch 97 on Training id inf\n",
            "Accuracy on batch 98 on Training id inf\n",
            "Accuracy on batch 99 on Training id inf\n",
            "Training loss 0.033634889870882034\n",
            "3.4200704097747803\n",
            "Accuracy on batch 100 on Training id inf\n",
            "Accuracy on batch 101 on Training id inf\n",
            "Accuracy on batch 102 on Training id inf\n",
            "Accuracy on batch 103 on Training id inf\n",
            "Accuracy on batch 104 on Training id inf\n",
            "Accuracy on batch 105 on Training id inf\n",
            "Accuracy on batch 106 on Training id inf\n",
            "Accuracy on batch 107 on Training id inf\n",
            "Accuracy on batch 108 on Training id inf\n",
            "Accuracy on batch 109 on Training id inf\n",
            "Accuracy on batch 110 on Training id inf\n",
            "Accuracy on batch 111 on Training id inf\n",
            "Accuracy on batch 112 on Training id inf\n",
            "Accuracy on batch 113 on Training id inf\n",
            "Accuracy on batch 114 on Training id inf\n",
            "Accuracy on batch 115 on Training id inf\n",
            "Accuracy on batch 116 on Training id inf\n",
            "Accuracy on batch 117 on Training id inf\n",
            "Accuracy on batch 118 on Training id inf\n",
            "Accuracy on batch 119 on Training id inf\n",
            "Accuracy on batch 120 on Training id inf\n",
            "Accuracy on batch 121 on Training id inf\n",
            "Accuracy on batch 122 on Training id inf\n",
            "Accuracy on batch 123 on Training id inf\n",
            "Accuracy on batch 124 on Training id inf\n",
            "Accuracy on batch 125 on Training id inf\n",
            "Accuracy on batch 126 on Training id inf\n",
            "Accuracy on batch 127 on Training id inf\n",
            "Accuracy on batch 128 on Training id inf\n",
            "Accuracy on batch 129 on Training id inf\n",
            "Accuracy on batch 130 on Training id inf\n",
            "Accuracy on batch 131 on Training id inf\n",
            "Accuracy on batch 132 on Training id inf\n",
            "Accuracy on batch 133 on Training id inf\n",
            "Accuracy on batch 134 on Training id inf\n",
            "Accuracy on batch 135 on Training id inf\n",
            "Accuracy on batch 136 on Training id inf\n",
            "Accuracy on batch 137 on Training id inf\n",
            "Accuracy on batch 138 on Training id inf\n",
            "Accuracy on batch 139 on Training id inf\n",
            "Accuracy on batch 140 on Training id inf\n",
            "Accuracy on batch 141 on Training id inf\n",
            "Accuracy on batch 142 on Training id inf\n",
            "Accuracy on batch 143 on Training id inf\n",
            "Accuracy on batch 144 on Training id inf\n",
            "Accuracy on batch 145 on Training id inf\n",
            "Accuracy on batch 146 on Training id inf\n",
            "Accuracy on batch 147 on Training id inf\n",
            "Accuracy on batch 148 on Training id inf\n",
            "Accuracy on batch 149 on Training id inf\n",
            "Training loss 0.01493742410093546\n",
            "2.269376516342163\n",
            "Accuracy on batch 150 on Training id inf\n",
            "Accuracy on batch 151 on Training id inf\n",
            "Accuracy on batch 152 on Training id inf\n",
            "Accuracy on batch 153 on Training id inf\n",
            "Accuracy on batch 154 on Training id inf\n",
            "Accuracy on batch 155 on Training id inf\n",
            "Accuracy on batch 156 on Training id inf\n",
            "Accuracy on batch 157 on Training id inf\n",
            "Accuracy on batch 158 on Training id inf\n",
            "Accuracy on batch 159 on Training id inf\n",
            "Accuracy on batch 160 on Training id inf\n",
            "Accuracy on batch 161 on Training id inf\n",
            "Accuracy on batch 162 on Training id inf\n",
            "Accuracy on batch 163 on Training id inf\n",
            "Accuracy on batch 164 on Training id inf\n",
            "Accuracy on batch 165 on Training id inf\n",
            "Accuracy on batch 166 on Training id inf\n",
            "Accuracy on batch 167 on Training id inf\n",
            "Accuracy on batch 168 on Training id inf\n",
            "Accuracy on batch 169 on Training id inf\n",
            "Accuracy on batch 170 on Training id inf\n",
            "Accuracy on batch 171 on Training id inf\n",
            "Accuracy on batch 172 on Training id inf\n",
            "Accuracy on batch 173 on Training id inf\n",
            "Accuracy on batch 174 on Training id inf\n",
            "Accuracy on batch 175 on Training id inf\n",
            "Accuracy on batch 176 on Training id inf\n",
            "Accuracy on batch 177 on Training id inf\n",
            "Accuracy on batch 178 on Training id inf\n",
            "Accuracy on batch 179 on Training id inf\n",
            "Accuracy on batch 180 on Training id inf\n",
            "Accuracy on batch 181 on Training id inf\n",
            "Accuracy on batch 182 on Training id inf\n",
            "Accuracy on batch 183 on Training id inf\n",
            "Accuracy on batch 184 on Training id inf\n",
            "Accuracy on batch 185 on Training id inf\n",
            "Accuracy on batch 186 on Training id inf\n",
            "Accuracy on batch 187 on Training id inf\n",
            "Accuracy on batch 188 on Training id inf\n",
            "Accuracy on batch 189 on Training id inf\n",
            "Accuracy on batch 190 on Training id inf\n",
            "Accuracy on batch 191 on Training id inf\n",
            "Accuracy on batch 192 on Training id inf\n",
            "Accuracy on batch 193 on Training id inf\n",
            "Accuracy on batch 194 on Training id inf\n",
            "Accuracy on batch 195 on Training id inf\n",
            "Accuracy on batch 196 on Training id inf\n",
            "Accuracy on batch 197 on Training id inf\n",
            "Accuracy on batch 198 on Training id inf\n",
            "Accuracy on batch 199 on Training id inf\n",
            "Training loss 0.01385666336864233\n",
            "2.7972919940948486\n",
            "Accuracy on batch 200 on Training id inf\n",
            "Accuracy on batch 201 on Training id inf\n",
            "Accuracy on batch 202 on Training id inf\n",
            "Accuracy on batch 203 on Training id inf\n",
            "Accuracy on batch 204 on Training id inf\n",
            "Accuracy on batch 205 on Training id inf\n",
            "Accuracy on batch 206 on Training id inf\n",
            "Accuracy on batch 207 on Training id inf\n",
            "Accuracy on batch 208 on Training id inf\n",
            "Accuracy on batch 209 on Training id inf\n",
            "Accuracy on batch 210 on Training id inf\n",
            "Accuracy on batch 211 on Training id inf\n",
            "Accuracy on batch 212 on Training id inf\n",
            "Accuracy on batch 213 on Training id inf\n",
            "Accuracy on batch 214 on Training id inf\n",
            "Accuracy on batch 215 on Training id inf\n",
            "Accuracy on batch 216 on Training id inf\n",
            "Accuracy on batch 217 on Training id inf\n",
            "Accuracy on batch 218 on Training id inf\n",
            "Accuracy on batch 219 on Training id inf\n",
            "Accuracy on batch 220 on Training id inf\n",
            "Accuracy on batch 221 on Training id inf\n",
            "Accuracy on batch 222 on Training id inf\n",
            "Accuracy on batch 223 on Training id inf\n",
            "Accuracy on batch 224 on Training id inf\n",
            "Accuracy on batch 225 on Training id inf\n",
            "Accuracy on batch 226 on Training id inf\n",
            "Accuracy on batch 227 on Training id inf\n",
            "Accuracy on batch 228 on Training id inf\n",
            "Accuracy on batch 229 on Training id inf\n",
            "Accuracy on batch 230 on Training id inf\n",
            "Accuracy on batch 231 on Training id inf\n",
            "Accuracy on batch 232 on Training id inf\n",
            "Accuracy on batch 233 on Training id inf\n",
            "Accuracy on batch 234 on Training id inf\n",
            "Accuracy on batch 235 on Training id inf\n",
            "Accuracy on batch 236 on Training id inf\n",
            "Accuracy on batch 237 on Training id inf\n",
            "Accuracy on batch 238 on Training id inf\n",
            "Accuracy on batch 239 on Training id inf\n",
            "Accuracy on batch 240 on Training id inf\n",
            "Accuracy on batch 241 on Training id inf\n",
            "Accuracy on batch 242 on Training id inf\n",
            "Accuracy on batch 243 on Training id inf\n",
            "Accuracy on batch 244 on Training id inf\n",
            "Accuracy on batch 245 on Training id inf\n",
            "Accuracy on batch 246 on Training id inf\n",
            "Accuracy on batch 247 on Training id inf\n",
            "Accuracy on batch 248 on Training id inf\n",
            "Accuracy on batch 249 on Training id inf\n",
            "Training loss 0.008113556541502476\n",
            "2.046098232269287\n",
            "Accuracy on batch 250 on Training id inf\n",
            "Accuracy on batch 251 on Training id inf\n",
            "Accuracy on batch 252 on Training id inf\n",
            "Accuracy on batch 253 on Training id inf\n",
            "Accuracy on batch 254 on Training id inf\n",
            "Accuracy on batch 255 on Training id inf\n",
            "Accuracy on batch 256 on Training id inf\n",
            "Accuracy on batch 257 on Training id inf\n",
            "Accuracy on batch 258 on Training id inf\n",
            "Accuracy on batch 259 on Training id inf\n",
            "Accuracy on batch 260 on Training id inf\n",
            "Accuracy on batch 261 on Training id inf\n",
            "Accuracy on batch 262 on Training id inf\n",
            "Accuracy on batch 263 on Training id inf\n",
            "Accuracy on batch 264 on Training id inf\n",
            "Accuracy on batch 265 on Training id inf\n",
            "Accuracy on batch 266 on Training id inf\n",
            "Accuracy on batch 267 on Training id inf\n",
            "Accuracy on batch 268 on Training id inf\n",
            "Accuracy on batch 269 on Training id inf\n",
            "Accuracy on batch 270 on Training id inf\n",
            "Accuracy on batch 271 on Training id inf\n",
            "Accuracy on batch 272 on Training id inf\n",
            "Accuracy on batch 273 on Training id inf\n",
            "Accuracy on batch 274 on Training id inf\n",
            "Accuracy on batch 275 on Training id inf\n",
            "Accuracy on batch 276 on Training id inf\n",
            "Accuracy on batch 277 on Training id inf\n",
            "Accuracy on batch 278 on Training id inf\n",
            "Accuracy on batch 279 on Training id inf\n",
            "Accuracy on batch 280 on Training id inf\n",
            "Accuracy on batch 281 on Training id inf\n",
            "Accuracy on batch 282 on Training id inf\n",
            "Accuracy on batch 283 on Training id inf\n",
            "Accuracy on batch 284 on Training id inf\n",
            "Accuracy on batch 285 on Training id inf\n",
            "Accuracy on batch 286 on Training id inf\n",
            "Accuracy on batch 287 on Training id inf\n",
            "Accuracy on batch 288 on Training id inf\n",
            "Accuracy on batch 289 on Training id inf\n",
            "Accuracy on batch 290 on Training id inf\n",
            "Эпоха #1 train_loss: 0.0, val_loss: 0\n",
            "Потрачено 0.4 минут на 1 эпоху\n",
            "Training loss 2.037050247192383\n",
            "2.037050247192383\n",
            "Accuracy on batch 0 on Training id inf\n",
            "Accuracy on batch 1 on Training id inf\n",
            "Accuracy on batch 2 on Training id inf\n",
            "Accuracy on batch 3 on Training id inf\n",
            "Accuracy on batch 4 on Training id inf\n",
            "Accuracy on batch 5 on Training id inf\n",
            "Accuracy on batch 6 on Training id inf\n",
            "Accuracy on batch 7 on Training id inf\n",
            "Accuracy on batch 8 on Training id inf\n",
            "Accuracy on batch 9 on Training id inf\n",
            "Accuracy on batch 10 on Training id inf\n",
            "Accuracy on batch 11 on Training id inf\n",
            "Accuracy on batch 12 on Training id inf\n",
            "Accuracy on batch 13 on Training id inf\n",
            "Accuracy on batch 14 on Training id inf\n",
            "Accuracy on batch 15 on Training id inf\n",
            "Accuracy on batch 16 on Training id inf\n",
            "Accuracy on batch 17 on Training id inf\n",
            "Accuracy on batch 18 on Training id inf\n",
            "Accuracy on batch 19 on Training id inf\n",
            "Accuracy on batch 20 on Training id inf\n",
            "Accuracy on batch 21 on Training id inf\n",
            "Accuracy on batch 22 on Training id inf\n",
            "Accuracy on batch 23 on Training id inf\n",
            "Accuracy on batch 24 on Training id inf\n",
            "Accuracy on batch 25 on Training id inf\n",
            "Accuracy on batch 26 on Training id inf\n",
            "Accuracy on batch 27 on Training id inf\n",
            "Accuracy on batch 28 on Training id inf\n",
            "Accuracy on batch 29 on Training id inf\n",
            "Accuracy on batch 30 on Training id inf\n",
            "Accuracy on batch 31 on Training id inf\n",
            "Accuracy on batch 32 on Training id inf\n",
            "Accuracy on batch 33 on Training id inf\n",
            "Accuracy on batch 34 on Training id inf\n",
            "Accuracy on batch 35 on Training id inf\n",
            "Accuracy on batch 36 on Training id inf\n",
            "Accuracy on batch 37 on Training id inf\n",
            "Accuracy on batch 38 on Training id inf\n",
            "Accuracy on batch 39 on Training id inf\n",
            "Accuracy on batch 40 on Training id inf\n",
            "Accuracy on batch 41 on Training id inf\n",
            "Accuracy on batch 42 on Training id inf\n",
            "Accuracy on batch 43 on Training id inf\n",
            "Accuracy on batch 44 on Training id inf\n",
            "Accuracy on batch 45 on Training id inf\n",
            "Accuracy on batch 46 on Training id inf\n",
            "Accuracy on batch 47 on Training id inf\n",
            "Accuracy on batch 48 on Training id inf\n",
            "Accuracy on batch 49 on Training id inf\n",
            "Training loss 0.0302109494805336\n",
            "1.5869865417480469\n",
            "Accuracy on batch 50 on Training id inf\n",
            "Accuracy on batch 51 on Training id inf\n",
            "Accuracy on batch 52 on Training id inf\n",
            "Accuracy on batch 53 on Training id inf\n",
            "Accuracy on batch 54 on Training id inf\n",
            "Accuracy on batch 55 on Training id inf\n",
            "Accuracy on batch 56 on Training id inf\n",
            "Accuracy on batch 57 on Training id inf\n",
            "Accuracy on batch 58 on Training id inf\n",
            "Accuracy on batch 59 on Training id inf\n",
            "Accuracy on batch 60 on Training id inf\n",
            "Accuracy on batch 61 on Training id inf\n",
            "Accuracy on batch 62 on Training id inf\n",
            "Accuracy on batch 63 on Training id inf\n",
            "Accuracy on batch 64 on Training id inf\n",
            "Accuracy on batch 65 on Training id inf\n",
            "Accuracy on batch 66 on Training id inf\n",
            "Accuracy on batch 67 on Training id inf\n",
            "Accuracy on batch 68 on Training id inf\n",
            "Accuracy on batch 69 on Training id inf\n",
            "Accuracy on batch 70 on Training id inf\n",
            "Accuracy on batch 71 on Training id inf\n",
            "Accuracy on batch 72 on Training id inf\n",
            "Accuracy on batch 73 on Training id inf\n",
            "Accuracy on batch 74 on Training id inf\n",
            "Accuracy on batch 75 on Training id inf\n",
            "Accuracy on batch 76 on Training id inf\n",
            "Accuracy on batch 77 on Training id inf\n",
            "Accuracy on batch 78 on Training id inf\n",
            "Accuracy on batch 79 on Training id inf\n",
            "Accuracy on batch 80 on Training id inf\n",
            "Accuracy on batch 81 on Training id inf\n",
            "Accuracy on batch 82 on Training id inf\n",
            "Accuracy on batch 83 on Training id inf\n",
            "Accuracy on batch 84 on Training id inf\n",
            "Accuracy on batch 85 on Training id inf\n",
            "Accuracy on batch 86 on Training id inf\n",
            "Accuracy on batch 87 on Training id inf\n",
            "Accuracy on batch 88 on Training id inf\n",
            "Accuracy on batch 89 on Training id inf\n",
            "Accuracy on batch 90 on Training id inf\n",
            "Accuracy on batch 91 on Training id inf\n",
            "Accuracy on batch 92 on Training id inf\n",
            "Accuracy on batch 93 on Training id inf\n",
            "Accuracy on batch 94 on Training id inf\n",
            "Accuracy on batch 95 on Training id inf\n",
            "Accuracy on batch 96 on Training id inf\n",
            "Accuracy on batch 97 on Training id inf\n",
            "Accuracy on batch 98 on Training id inf\n",
            "Accuracy on batch 99 on Training id inf\n",
            "Training loss 0.023248011246323586\n",
            "2.3679840564727783\n",
            "Accuracy on batch 100 on Training id inf\n",
            "Accuracy on batch 101 on Training id inf\n",
            "Accuracy on batch 102 on Training id inf\n",
            "Accuracy on batch 103 on Training id inf\n",
            "Accuracy on batch 104 on Training id inf\n",
            "Accuracy on batch 105 on Training id inf\n",
            "Accuracy on batch 106 on Training id inf\n",
            "Accuracy on batch 107 on Training id inf\n",
            "Accuracy on batch 108 on Training id inf\n",
            "Accuracy on batch 109 on Training id inf\n",
            "Accuracy on batch 110 on Training id inf\n",
            "Accuracy on batch 111 on Training id inf\n",
            "Accuracy on batch 112 on Training id inf\n",
            "Accuracy on batch 113 on Training id inf\n",
            "Accuracy on batch 114 on Training id inf\n",
            "Accuracy on batch 115 on Training id inf\n",
            "Accuracy on batch 116 on Training id inf\n",
            "Accuracy on batch 117 on Training id inf\n",
            "Accuracy on batch 118 on Training id inf\n",
            "Accuracy on batch 119 on Training id inf\n",
            "Accuracy on batch 120 on Training id inf\n",
            "Accuracy on batch 121 on Training id inf\n",
            "Accuracy on batch 122 on Training id inf\n",
            "Accuracy on batch 123 on Training id inf\n",
            "Accuracy on batch 124 on Training id inf\n",
            "Accuracy on batch 125 on Training id inf\n",
            "Accuracy on batch 126 on Training id inf\n",
            "Accuracy on batch 127 on Training id inf\n",
            "Accuracy on batch 128 on Training id inf\n",
            "Accuracy on batch 129 on Training id inf\n",
            "Accuracy on batch 130 on Training id inf\n",
            "Accuracy on batch 131 on Training id inf\n",
            "Accuracy on batch 132 on Training id inf\n",
            "Accuracy on batch 133 on Training id inf\n",
            "Accuracy on batch 134 on Training id inf\n",
            "Accuracy on batch 135 on Training id inf\n",
            "Accuracy on batch 136 on Training id inf\n",
            "Accuracy on batch 137 on Training id inf\n",
            "Accuracy on batch 138 on Training id inf\n",
            "Accuracy on batch 139 on Training id inf\n",
            "Accuracy on batch 140 on Training id inf\n",
            "Accuracy on batch 141 on Training id inf\n",
            "Accuracy on batch 142 on Training id inf\n",
            "Accuracy on batch 143 on Training id inf\n",
            "Accuracy on batch 144 on Training id inf\n",
            "Accuracy on batch 145 on Training id inf\n",
            "Accuracy on batch 146 on Training id inf\n",
            "Accuracy on batch 147 on Training id inf\n",
            "Accuracy on batch 148 on Training id inf\n",
            "Accuracy on batch 149 on Training id inf\n",
            "Training loss 0.0144697530195117\n",
            "2.193770408630371\n",
            "Accuracy on batch 150 on Training id inf\n",
            "Accuracy on batch 151 on Training id inf\n",
            "Accuracy on batch 152 on Training id inf\n",
            "Accuracy on batch 153 on Training id inf\n",
            "Accuracy on batch 154 on Training id inf\n",
            "Accuracy on batch 155 on Training id inf\n",
            "Accuracy on batch 156 on Training id inf\n",
            "Accuracy on batch 157 on Training id inf\n",
            "Accuracy on batch 158 on Training id inf\n",
            "Accuracy on batch 159 on Training id inf\n",
            "Accuracy on batch 160 on Training id inf\n",
            "Accuracy on batch 161 on Training id inf\n",
            "Accuracy on batch 162 on Training id inf\n",
            "Accuracy on batch 163 on Training id inf\n",
            "Accuracy on batch 164 on Training id inf\n",
            "Accuracy on batch 165 on Training id inf\n",
            "Accuracy on batch 166 on Training id inf\n",
            "Accuracy on batch 167 on Training id inf\n",
            "Accuracy on batch 168 on Training id inf\n",
            "Accuracy on batch 169 on Training id inf\n",
            "Accuracy on batch 170 on Training id inf\n",
            "Accuracy on batch 171 on Training id inf\n",
            "Accuracy on batch 172 on Training id inf\n",
            "Accuracy on batch 173 on Training id inf\n",
            "Accuracy on batch 174 on Training id inf\n",
            "Accuracy on batch 175 on Training id inf\n",
            "Accuracy on batch 176 on Training id inf\n",
            "Accuracy on batch 177 on Training id inf\n",
            "Accuracy on batch 178 on Training id inf\n",
            "Accuracy on batch 179 on Training id inf\n",
            "Accuracy on batch 180 on Training id inf\n",
            "Accuracy on batch 181 on Training id inf\n",
            "Accuracy on batch 182 on Training id inf\n",
            "Accuracy on batch 183 on Training id inf\n",
            "Accuracy on batch 184 on Training id inf\n",
            "Accuracy on batch 185 on Training id inf\n",
            "Accuracy on batch 186 on Training id inf\n",
            "Accuracy on batch 187 on Training id inf\n",
            "Accuracy on batch 188 on Training id inf\n",
            "Accuracy on batch 189 on Training id inf\n",
            "Accuracy on batch 190 on Training id inf\n",
            "Accuracy on batch 191 on Training id inf\n",
            "Accuracy on batch 192 on Training id inf\n",
            "Accuracy on batch 193 on Training id inf\n",
            "Accuracy on batch 194 on Training id inf\n",
            "Accuracy on batch 195 on Training id inf\n",
            "Accuracy on batch 196 on Training id inf\n",
            "Accuracy on batch 197 on Training id inf\n",
            "Accuracy on batch 198 on Training id inf\n",
            "Accuracy on batch 199 on Training id inf\n",
            "Training loss 0.006978544406592846\n",
            "1.4130922555923462\n",
            "Accuracy on batch 200 on Training id inf\n",
            "Accuracy on batch 201 on Training id inf\n",
            "Accuracy on batch 202 on Training id inf\n",
            "Accuracy on batch 203 on Training id inf\n",
            "Accuracy on batch 204 on Training id inf\n",
            "Accuracy on batch 205 on Training id inf\n",
            "Accuracy on batch 206 on Training id inf\n",
            "Accuracy on batch 207 on Training id inf\n",
            "Accuracy on batch 208 on Training id inf\n",
            "Accuracy on batch 209 on Training id inf\n",
            "Accuracy on batch 210 on Training id inf\n",
            "Accuracy on batch 211 on Training id inf\n",
            "Accuracy on batch 212 on Training id inf\n",
            "Accuracy on batch 213 on Training id inf\n",
            "Accuracy on batch 214 on Training id inf\n",
            "Accuracy on batch 215 on Training id inf\n",
            "Accuracy on batch 216 on Training id inf\n",
            "Accuracy on batch 217 on Training id inf\n",
            "Accuracy on batch 218 on Training id inf\n",
            "Accuracy on batch 219 on Training id inf\n",
            "Accuracy on batch 220 on Training id inf\n",
            "Accuracy on batch 221 on Training id inf\n",
            "Accuracy on batch 222 on Training id inf\n",
            "Accuracy on batch 223 on Training id inf\n",
            "Accuracy on batch 224 on Training id inf\n",
            "Accuracy on batch 225 on Training id inf\n",
            "Accuracy on batch 226 on Training id inf\n",
            "Accuracy on batch 227 on Training id inf\n",
            "Accuracy on batch 228 on Training id inf\n",
            "Accuracy on batch 229 on Training id inf\n",
            "Accuracy on batch 230 on Training id inf\n",
            "Accuracy on batch 231 on Training id inf\n",
            "Accuracy on batch 232 on Training id inf\n",
            "Accuracy on batch 233 on Training id inf\n",
            "Accuracy on batch 234 on Training id inf\n",
            "Accuracy on batch 235 on Training id inf\n",
            "Accuracy on batch 236 on Training id inf\n",
            "Accuracy on batch 237 on Training id inf\n",
            "Accuracy on batch 238 on Training id inf\n",
            "Accuracy on batch 239 on Training id inf\n",
            "Accuracy on batch 240 on Training id inf\n",
            "Accuracy on batch 241 on Training id inf\n",
            "Accuracy on batch 242 on Training id inf\n",
            "Accuracy on batch 243 on Training id inf\n",
            "Accuracy on batch 244 on Training id inf\n",
            "Accuracy on batch 245 on Training id inf\n",
            "Accuracy on batch 246 on Training id inf\n",
            "Accuracy on batch 247 on Training id inf\n",
            "Accuracy on batch 248 on Training id inf\n",
            "Accuracy on batch 249 on Training id inf\n",
            "Training loss 0.006105633452534676\n",
            "1.5428427457809448\n",
            "Accuracy on batch 250 on Training id inf\n",
            "Accuracy on batch 251 on Training id inf\n",
            "Accuracy on batch 252 on Training id inf\n",
            "Accuracy on batch 253 on Training id inf\n",
            "Accuracy on batch 254 on Training id inf\n",
            "Accuracy on batch 255 on Training id inf\n",
            "Accuracy on batch 256 on Training id inf\n",
            "Accuracy on batch 257 on Training id inf\n",
            "Accuracy on batch 258 on Training id inf\n",
            "Accuracy on batch 259 on Training id inf\n",
            "Accuracy on batch 260 on Training id inf\n",
            "Accuracy on batch 261 on Training id inf\n",
            "Accuracy on batch 262 on Training id inf\n",
            "Accuracy on batch 263 on Training id inf\n",
            "Accuracy on batch 264 on Training id inf\n",
            "Accuracy on batch 265 on Training id inf\n",
            "Accuracy on batch 266 on Training id inf\n",
            "Accuracy on batch 267 on Training id inf\n",
            "Accuracy on batch 268 on Training id inf\n",
            "Accuracy on batch 269 on Training id inf\n",
            "Accuracy on batch 270 on Training id inf\n",
            "Accuracy on batch 271 on Training id inf\n",
            "Accuracy on batch 272 on Training id inf\n",
            "Accuracy on batch 273 on Training id inf\n",
            "Accuracy on batch 274 on Training id inf\n",
            "Accuracy on batch 275 on Training id inf\n",
            "Accuracy on batch 276 on Training id inf\n",
            "Accuracy on batch 277 on Training id inf\n",
            "Accuracy on batch 278 on Training id inf\n",
            "Accuracy on batch 279 on Training id inf\n",
            "Accuracy on batch 280 on Training id inf\n",
            "Accuracy on batch 281 on Training id inf\n",
            "Accuracy on batch 282 on Training id inf\n",
            "Accuracy on batch 283 on Training id inf\n",
            "Accuracy on batch 284 on Training id inf\n",
            "Accuracy on batch 285 on Training id inf\n",
            "Accuracy on batch 286 on Training id inf\n",
            "Accuracy on batch 287 on Training id inf\n",
            "Accuracy on batch 288 on Training id inf\n",
            "Accuracy on batch 289 on Training id inf\n",
            "Accuracy on batch 290 on Training id inf\n",
            "Эпоха #2 train_loss: 0.0, val_loss: 0\n",
            "Потрачено 0.4 минут на 2 эпоху\n",
            "Training loss 1.5354214906692505\n",
            "1.5354214906692505\n",
            "Accuracy on batch 0 on Training id inf\n",
            "Accuracy on batch 1 on Training id inf\n",
            "Accuracy on batch 2 on Training id inf\n",
            "Accuracy on batch 3 on Training id inf\n",
            "Accuracy on batch 4 on Training id inf\n",
            "Accuracy on batch 5 on Training id inf\n",
            "Accuracy on batch 6 on Training id inf\n",
            "Accuracy on batch 7 on Training id inf\n",
            "Accuracy on batch 8 on Training id inf\n",
            "Accuracy on batch 9 on Training id inf\n",
            "Accuracy on batch 10 on Training id inf\n",
            "Accuracy on batch 11 on Training id inf\n",
            "Accuracy on batch 12 on Training id inf\n",
            "Accuracy on batch 13 on Training id inf\n",
            "Accuracy on batch 14 on Training id inf\n",
            "Accuracy on batch 15 on Training id inf\n",
            "Accuracy on batch 16 on Training id inf\n",
            "Accuracy on batch 17 on Training id inf\n",
            "Accuracy on batch 18 on Training id inf\n",
            "Accuracy on batch 19 on Training id inf\n",
            "Accuracy on batch 20 on Training id inf\n",
            "Accuracy on batch 21 on Training id inf\n",
            "Accuracy on batch 22 on Training id inf\n",
            "Accuracy on batch 23 on Training id inf\n",
            "Accuracy on batch 24 on Training id inf\n",
            "Accuracy on batch 25 on Training id inf\n",
            "Accuracy on batch 26 on Training id inf\n",
            "Accuracy on batch 27 on Training id inf\n",
            "Accuracy on batch 28 on Training id inf\n",
            "Accuracy on batch 29 on Training id inf\n",
            "Accuracy on batch 30 on Training id inf\n",
            "Accuracy on batch 31 on Training id inf\n",
            "Accuracy on batch 32 on Training id inf\n",
            "Accuracy on batch 33 on Training id inf\n",
            "Accuracy on batch 34 on Training id inf\n",
            "Accuracy on batch 35 on Training id inf\n",
            "Accuracy on batch 36 on Training id inf\n",
            "Accuracy on batch 37 on Training id inf\n",
            "Accuracy on batch 38 on Training id inf\n",
            "Accuracy on batch 39 on Training id inf\n",
            "Accuracy on batch 40 on Training id inf\n",
            "Accuracy on batch 41 on Training id inf\n",
            "Accuracy on batch 42 on Training id inf\n",
            "Accuracy on batch 43 on Training id inf\n",
            "Accuracy on batch 44 on Training id inf\n",
            "Accuracy on batch 45 on Training id inf\n",
            "Accuracy on batch 46 on Training id inf\n",
            "Accuracy on batch 47 on Training id inf\n",
            "Accuracy on batch 48 on Training id inf\n",
            "Accuracy on batch 49 on Training id inf\n",
            "Training loss 0.033801883459091187\n",
            "1.754501223564148\n",
            "Accuracy on batch 50 on Training id inf\n",
            "Accuracy on batch 51 on Training id inf\n",
            "Accuracy on batch 52 on Training id inf\n",
            "Accuracy on batch 53 on Training id inf\n",
            "Accuracy on batch 54 on Training id inf\n",
            "Accuracy on batch 55 on Training id inf\n",
            "Accuracy on batch 56 on Training id inf\n",
            "Accuracy on batch 57 on Training id inf\n",
            "Accuracy on batch 58 on Training id inf\n",
            "Accuracy on batch 59 on Training id inf\n",
            "Accuracy on batch 60 on Training id inf\n",
            "Accuracy on batch 61 on Training id inf\n",
            "Accuracy on batch 62 on Training id inf\n",
            "Accuracy on batch 63 on Training id inf\n",
            "Accuracy on batch 64 on Training id inf\n",
            "Accuracy on batch 65 on Training id inf\n",
            "Accuracy on batch 66 on Training id inf\n",
            "Accuracy on batch 67 on Training id inf\n",
            "Accuracy on batch 68 on Training id inf\n",
            "Accuracy on batch 69 on Training id inf\n",
            "Accuracy on batch 70 on Training id inf\n",
            "Accuracy on batch 71 on Training id inf\n",
            "Accuracy on batch 72 on Training id inf\n",
            "Accuracy on batch 73 on Training id inf\n",
            "Accuracy on batch 74 on Training id inf\n",
            "Accuracy on batch 75 on Training id inf\n",
            "Accuracy on batch 76 on Training id inf\n",
            "Accuracy on batch 77 on Training id inf\n",
            "Accuracy on batch 78 on Training id inf\n",
            "Accuracy on batch 79 on Training id inf\n",
            "Accuracy on batch 80 on Training id inf\n",
            "Accuracy on batch 81 on Training id inf\n",
            "Accuracy on batch 82 on Training id inf\n",
            "Accuracy on batch 83 on Training id inf\n",
            "Accuracy on batch 84 on Training id inf\n",
            "Accuracy on batch 85 on Training id inf\n",
            "Accuracy on batch 86 on Training id inf\n",
            "Accuracy on batch 87 on Training id inf\n",
            "Accuracy on batch 88 on Training id inf\n",
            "Accuracy on batch 89 on Training id inf\n",
            "Accuracy on batch 90 on Training id inf\n",
            "Accuracy on batch 91 on Training id inf\n",
            "Accuracy on batch 92 on Training id inf\n",
            "Accuracy on batch 93 on Training id inf\n",
            "Accuracy on batch 94 on Training id inf\n",
            "Accuracy on batch 95 on Training id inf\n",
            "Accuracy on batch 96 on Training id inf\n",
            "Accuracy on batch 97 on Training id inf\n",
            "Accuracy on batch 98 on Training id inf\n",
            "Accuracy on batch 99 on Training id inf\n",
            "Training loss 0.010396894998848438\n",
            "1.0610350370407104\n",
            "Accuracy on batch 100 on Training id inf\n",
            "Accuracy on batch 101 on Training id inf\n",
            "Accuracy on batch 102 on Training id inf\n",
            "Accuracy on batch 103 on Training id inf\n",
            "Accuracy on batch 104 on Training id inf\n",
            "Accuracy on batch 105 on Training id inf\n",
            "Accuracy on batch 106 on Training id inf\n",
            "Accuracy on batch 107 on Training id inf\n",
            "Accuracy on batch 108 on Training id inf\n",
            "Accuracy on batch 109 on Training id inf\n",
            "Accuracy on batch 110 on Training id inf\n",
            "Accuracy on batch 111 on Training id inf\n",
            "Accuracy on batch 112 on Training id inf\n",
            "Accuracy on batch 113 on Training id inf\n",
            "Accuracy on batch 114 on Training id inf\n",
            "Accuracy on batch 115 on Training id inf\n",
            "Accuracy on batch 116 on Training id inf\n",
            "Accuracy on batch 117 on Training id inf\n",
            "Accuracy on batch 118 on Training id inf\n",
            "Accuracy on batch 119 on Training id inf\n",
            "Accuracy on batch 120 on Training id inf\n",
            "Accuracy on batch 121 on Training id inf\n",
            "Accuracy on batch 122 on Training id inf\n",
            "Accuracy on batch 123 on Training id inf\n",
            "Accuracy on batch 124 on Training id inf\n",
            "Accuracy on batch 125 on Training id inf\n",
            "Accuracy on batch 126 on Training id inf\n",
            "Accuracy on batch 127 on Training id inf\n",
            "Accuracy on batch 128 on Training id inf\n",
            "Accuracy on batch 129 on Training id inf\n",
            "Accuracy on batch 130 on Training id inf\n",
            "Accuracy on batch 131 on Training id inf\n",
            "Accuracy on batch 132 on Training id inf\n",
            "Accuracy on batch 133 on Training id inf\n",
            "Accuracy on batch 134 on Training id inf\n",
            "Accuracy on batch 135 on Training id inf\n",
            "Accuracy on batch 136 on Training id inf\n",
            "Accuracy on batch 137 on Training id inf\n",
            "Accuracy on batch 138 on Training id inf\n",
            "Accuracy on batch 139 on Training id inf\n",
            "Accuracy on batch 140 on Training id inf\n",
            "Accuracy on batch 141 on Training id inf\n",
            "Accuracy on batch 142 on Training id inf\n",
            "Accuracy on batch 143 on Training id inf\n",
            "Accuracy on batch 144 on Training id inf\n",
            "Accuracy on batch 145 on Training id inf\n",
            "Accuracy on batch 146 on Training id inf\n",
            "Accuracy on batch 147 on Training id inf\n",
            "Accuracy on batch 148 on Training id inf\n",
            "Accuracy on batch 149 on Training id inf\n",
            "Training loss 0.012462214566767216\n",
            "1.8931087255477905\n",
            "Accuracy on batch 150 on Training id inf\n",
            "Accuracy on batch 151 on Training id inf\n",
            "Accuracy on batch 152 on Training id inf\n",
            "Accuracy on batch 153 on Training id inf\n",
            "Accuracy on batch 154 on Training id inf\n",
            "Accuracy on batch 155 on Training id inf\n",
            "Accuracy on batch 156 on Training id inf\n",
            "Accuracy on batch 157 on Training id inf\n",
            "Accuracy on batch 158 on Training id inf\n",
            "Accuracy on batch 159 on Training id inf\n",
            "Accuracy on batch 160 on Training id inf\n",
            "Accuracy on batch 161 on Training id inf\n",
            "Accuracy on batch 162 on Training id inf\n",
            "Accuracy on batch 163 on Training id inf\n",
            "Accuracy on batch 164 on Training id inf\n",
            "Accuracy on batch 165 on Training id inf\n",
            "Accuracy on batch 166 on Training id inf\n",
            "Accuracy on batch 167 on Training id inf\n",
            "Accuracy on batch 168 on Training id inf\n",
            "Accuracy on batch 169 on Training id inf\n",
            "Accuracy on batch 170 on Training id inf\n",
            "Accuracy on batch 171 on Training id inf\n",
            "Accuracy on batch 172 on Training id inf\n",
            "Accuracy on batch 173 on Training id inf\n",
            "Accuracy on batch 174 on Training id inf\n",
            "Accuracy on batch 175 on Training id inf\n",
            "Accuracy on batch 176 on Training id inf\n",
            "Accuracy on batch 177 on Training id inf\n",
            "Accuracy on batch 178 on Training id inf\n",
            "Accuracy on batch 179 on Training id inf\n",
            "Accuracy on batch 180 on Training id inf\n",
            "Accuracy on batch 181 on Training id inf\n",
            "Accuracy on batch 182 on Training id inf\n",
            "Accuracy on batch 183 on Training id inf\n",
            "Accuracy on batch 184 on Training id inf\n",
            "Accuracy on batch 185 on Training id inf\n",
            "Accuracy on batch 186 on Training id inf\n",
            "Accuracy on batch 187 on Training id inf\n",
            "Accuracy on batch 188 on Training id inf\n",
            "Accuracy on batch 189 on Training id inf\n",
            "Accuracy on batch 190 on Training id inf\n",
            "Accuracy on batch 191 on Training id inf\n",
            "Accuracy on batch 192 on Training id inf\n",
            "Accuracy on batch 193 on Training id inf\n",
            "Accuracy on batch 194 on Training id inf\n",
            "Accuracy on batch 195 on Training id inf\n",
            "Accuracy on batch 196 on Training id inf\n",
            "Accuracy on batch 197 on Training id inf\n",
            "Accuracy on batch 198 on Training id inf\n",
            "Accuracy on batch 199 on Training id inf\n",
            "Training loss 0.004899634048342705\n",
            "0.9933983683586121\n",
            "Accuracy on batch 200 on Training id inf\n",
            "Accuracy on batch 201 on Training id inf\n",
            "Accuracy on batch 202 on Training id inf\n",
            "Accuracy on batch 203 on Training id inf\n",
            "Accuracy on batch 204 on Training id inf\n",
            "Accuracy on batch 205 on Training id inf\n",
            "Accuracy on batch 206 on Training id inf\n",
            "Accuracy on batch 207 on Training id inf\n",
            "Accuracy on batch 208 on Training id inf\n",
            "Accuracy on batch 209 on Training id inf\n",
            "Accuracy on batch 210 on Training id inf\n",
            "Accuracy on batch 211 on Training id inf\n",
            "Accuracy on batch 212 on Training id inf\n",
            "Accuracy on batch 213 on Training id inf\n",
            "Accuracy on batch 214 on Training id inf\n",
            "Accuracy on batch 215 on Training id inf\n",
            "Accuracy on batch 216 on Training id inf\n",
            "Accuracy on batch 217 on Training id inf\n",
            "Accuracy on batch 218 on Training id inf\n",
            "Accuracy on batch 219 on Training id inf\n",
            "Accuracy on batch 220 on Training id inf\n",
            "Accuracy on batch 221 on Training id inf\n",
            "Accuracy on batch 222 on Training id inf\n",
            "Accuracy on batch 223 on Training id inf\n",
            "Accuracy on batch 224 on Training id inf\n",
            "Accuracy on batch 225 on Training id inf\n",
            "Accuracy on batch 226 on Training id inf\n",
            "Accuracy on batch 227 on Training id inf\n",
            "Accuracy on batch 228 on Training id inf\n",
            "Accuracy on batch 229 on Training id inf\n",
            "Accuracy on batch 230 on Training id inf\n",
            "Accuracy on batch 231 on Training id inf\n",
            "Accuracy on batch 232 on Training id inf\n",
            "Accuracy on batch 233 on Training id inf\n",
            "Accuracy on batch 234 on Training id inf\n",
            "Accuracy on batch 235 on Training id inf\n",
            "Accuracy on batch 236 on Training id inf\n",
            "Accuracy on batch 237 on Training id inf\n",
            "Accuracy on batch 238 on Training id inf\n",
            "Accuracy on batch 239 on Training id inf\n",
            "Accuracy on batch 240 on Training id inf\n",
            "Accuracy on batch 241 on Training id inf\n",
            "Accuracy on batch 242 on Training id inf\n",
            "Accuracy on batch 243 on Training id inf\n",
            "Accuracy on batch 244 on Training id inf\n",
            "Accuracy on batch 245 on Training id inf\n",
            "Accuracy on batch 246 on Training id inf\n",
            "Accuracy on batch 247 on Training id inf\n",
            "Accuracy on batch 248 on Training id inf\n",
            "Accuracy on batch 249 on Training id inf\n",
            "Training loss 0.01275431364774704\n",
            "3.207627534866333\n",
            "Accuracy on batch 250 on Training id inf\n",
            "Accuracy on batch 251 on Training id inf\n",
            "Accuracy on batch 252 on Training id inf\n",
            "Accuracy on batch 253 on Training id inf\n",
            "Accuracy on batch 254 on Training id inf\n",
            "Accuracy on batch 255 on Training id inf\n",
            "Accuracy on batch 256 on Training id inf\n",
            "Accuracy on batch 257 on Training id inf\n",
            "Accuracy on batch 258 on Training id inf\n",
            "Accuracy on batch 259 on Training id inf\n",
            "Accuracy on batch 260 on Training id inf\n",
            "Accuracy on batch 261 on Training id inf\n",
            "Accuracy on batch 262 on Training id inf\n",
            "Accuracy on batch 263 on Training id inf\n",
            "Accuracy on batch 264 on Training id inf\n",
            "Accuracy on batch 265 on Training id inf\n",
            "Accuracy on batch 266 on Training id inf\n",
            "Accuracy on batch 267 on Training id inf\n",
            "Accuracy on batch 268 on Training id inf\n",
            "Accuracy on batch 269 on Training id inf\n",
            "Accuracy on batch 270 on Training id inf\n",
            "Accuracy on batch 271 on Training id inf\n",
            "Accuracy on batch 272 on Training id inf\n",
            "Accuracy on batch 273 on Training id inf\n",
            "Accuracy on batch 274 on Training id inf\n",
            "Accuracy on batch 275 on Training id inf\n",
            "Accuracy on batch 276 on Training id inf\n",
            "Accuracy on batch 277 on Training id inf\n",
            "Accuracy on batch 278 on Training id inf\n",
            "Accuracy on batch 279 on Training id inf\n",
            "Accuracy on batch 280 on Training id inf\n",
            "Accuracy on batch 281 on Training id inf\n",
            "Accuracy on batch 282 on Training id inf\n",
            "Accuracy on batch 283 on Training id inf\n",
            "Accuracy on batch 284 on Training id inf\n",
            "Accuracy on batch 285 on Training id inf\n",
            "Accuracy on batch 286 on Training id inf\n",
            "Accuracy on batch 287 on Training id inf\n",
            "Accuracy on batch 288 on Training id inf\n",
            "Accuracy on batch 289 on Training id inf\n",
            "Accuracy on batch 290 on Training id inf\n",
            "Эпоха #3 train_loss: 0.0, val_loss: 0\n",
            "Потрачено 0.4 минут на 3 эпоху\n",
            "Training loss 2.395634412765503\n",
            "2.395634412765503\n",
            "Accuracy on batch 0 on Training id inf\n",
            "Accuracy on batch 1 on Training id inf\n",
            "Accuracy on batch 2 on Training id inf\n",
            "Accuracy on batch 3 on Training id inf\n",
            "Accuracy on batch 4 on Training id inf\n",
            "Accuracy on batch 5 on Training id inf\n",
            "Accuracy on batch 6 on Training id inf\n",
            "Accuracy on batch 7 on Training id inf\n",
            "Accuracy on batch 8 on Training id inf\n",
            "Accuracy on batch 9 on Training id inf\n",
            "Accuracy on batch 10 on Training id inf\n",
            "Accuracy on batch 11 on Training id inf\n",
            "Accuracy on batch 12 on Training id inf\n",
            "Accuracy on batch 13 on Training id inf\n",
            "Accuracy on batch 14 on Training id inf\n",
            "Accuracy on batch 15 on Training id inf\n",
            "Accuracy on batch 16 on Training id inf\n",
            "Accuracy on batch 17 on Training id inf\n",
            "Accuracy on batch 18 on Training id inf\n",
            "Accuracy on batch 19 on Training id inf\n",
            "Accuracy on batch 20 on Training id inf\n",
            "Accuracy on batch 21 on Training id inf\n",
            "Accuracy on batch 22 on Training id inf\n",
            "Accuracy on batch 23 on Training id inf\n",
            "Accuracy on batch 24 on Training id inf\n",
            "Accuracy on batch 25 on Training id inf\n",
            "Accuracy on batch 26 on Training id inf\n",
            "Accuracy on batch 27 on Training id inf\n",
            "Accuracy on batch 28 on Training id inf\n",
            "Accuracy on batch 29 on Training id inf\n",
            "Accuracy on batch 30 on Training id inf\n",
            "Accuracy on batch 31 on Training id inf\n",
            "Accuracy on batch 32 on Training id inf\n",
            "Accuracy on batch 33 on Training id inf\n",
            "Accuracy on batch 34 on Training id inf\n",
            "Accuracy on batch 35 on Training id inf\n",
            "Accuracy on batch 36 on Training id inf\n",
            "Accuracy on batch 37 on Training id inf\n",
            "Accuracy on batch 38 on Training id inf\n",
            "Accuracy on batch 39 on Training id inf\n",
            "Accuracy on batch 40 on Training id inf\n",
            "Accuracy on batch 41 on Training id inf\n",
            "Accuracy on batch 42 on Training id inf\n",
            "Accuracy on batch 43 on Training id inf\n",
            "Accuracy on batch 44 on Training id inf\n",
            "Accuracy on batch 45 on Training id inf\n",
            "Accuracy on batch 46 on Training id inf\n",
            "Accuracy on batch 47 on Training id inf\n",
            "Accuracy on batch 48 on Training id inf\n",
            "Accuracy on batch 49 on Training id inf\n",
            "Training loss 0.026881853118538857\n",
            "1.3900587558746338\n",
            "Accuracy on batch 50 on Training id inf\n",
            "Accuracy on batch 51 on Training id inf\n",
            "Accuracy on batch 52 on Training id inf\n",
            "Accuracy on batch 53 on Training id inf\n",
            "Accuracy on batch 54 on Training id inf\n",
            "Accuracy on batch 55 on Training id inf\n",
            "Accuracy on batch 56 on Training id inf\n",
            "Accuracy on batch 57 on Training id inf\n",
            "Accuracy on batch 58 on Training id inf\n",
            "Accuracy on batch 59 on Training id inf\n",
            "Accuracy on batch 60 on Training id inf\n",
            "Accuracy on batch 61 on Training id inf\n",
            "Accuracy on batch 62 on Training id inf\n",
            "Accuracy on batch 63 on Training id inf\n",
            "Accuracy on batch 64 on Training id inf\n",
            "Accuracy on batch 65 on Training id inf\n",
            "Accuracy on batch 66 on Training id inf\n",
            "Accuracy on batch 67 on Training id inf\n",
            "Accuracy on batch 68 on Training id inf\n",
            "Accuracy on batch 69 on Training id inf\n",
            "Accuracy on batch 70 on Training id inf\n",
            "Accuracy on batch 71 on Training id inf\n",
            "Accuracy on batch 72 on Training id inf\n",
            "Accuracy on batch 73 on Training id inf\n",
            "Accuracy on batch 74 on Training id inf\n",
            "Accuracy on batch 75 on Training id inf\n",
            "Accuracy on batch 76 on Training id inf\n",
            "Accuracy on batch 77 on Training id inf\n",
            "Accuracy on batch 78 on Training id inf\n",
            "Accuracy on batch 79 on Training id inf\n",
            "Accuracy on batch 80 on Training id inf\n",
            "Accuracy on batch 81 on Training id inf\n",
            "Accuracy on batch 82 on Training id inf\n",
            "Accuracy on batch 83 on Training id inf\n",
            "Accuracy on batch 84 on Training id inf\n",
            "Accuracy on batch 85 on Training id inf\n",
            "Accuracy on batch 86 on Training id inf\n",
            "Accuracy on batch 87 on Training id inf\n",
            "Accuracy on batch 88 on Training id inf\n",
            "Accuracy on batch 89 on Training id inf\n",
            "Accuracy on batch 90 on Training id inf\n",
            "Accuracy on batch 91 on Training id inf\n",
            "Accuracy on batch 92 on Training id inf\n",
            "Accuracy on batch 93 on Training id inf\n",
            "Accuracy on batch 94 on Training id inf\n",
            "Accuracy on batch 95 on Training id inf\n",
            "Accuracy on batch 96 on Training id inf\n",
            "Accuracy on batch 97 on Training id inf\n",
            "Accuracy on batch 98 on Training id inf\n",
            "Accuracy on batch 99 on Training id inf\n",
            "Training loss 0.013139880262315273\n",
            "1.346618413925171\n",
            "Accuracy on batch 100 on Training id inf\n",
            "Accuracy on batch 101 on Training id inf\n",
            "Accuracy on batch 102 on Training id inf\n",
            "Accuracy on batch 103 on Training id inf\n",
            "Accuracy on batch 104 on Training id inf\n",
            "Accuracy on batch 105 on Training id inf\n",
            "Accuracy on batch 106 on Training id inf\n",
            "Accuracy on batch 107 on Training id inf\n",
            "Accuracy on batch 108 on Training id inf\n",
            "Accuracy on batch 109 on Training id inf\n",
            "Accuracy on batch 110 on Training id inf\n",
            "Accuracy on batch 111 on Training id inf\n",
            "Accuracy on batch 112 on Training id inf\n",
            "Accuracy on batch 113 on Training id inf\n",
            "Accuracy on batch 114 on Training id inf\n",
            "Accuracy on batch 115 on Training id inf\n",
            "Accuracy on batch 116 on Training id inf\n",
            "Accuracy on batch 117 on Training id inf\n",
            "Accuracy on batch 118 on Training id inf\n",
            "Accuracy on batch 119 on Training id inf\n",
            "Accuracy on batch 120 on Training id inf\n",
            "Accuracy on batch 121 on Training id inf\n",
            "Accuracy on batch 122 on Training id inf\n",
            "Accuracy on batch 123 on Training id inf\n",
            "Accuracy on batch 124 on Training id inf\n",
            "Accuracy on batch 125 on Training id inf\n",
            "Accuracy on batch 126 on Training id inf\n",
            "Accuracy on batch 127 on Training id inf\n",
            "Accuracy on batch 128 on Training id inf\n",
            "Accuracy on batch 129 on Training id inf\n",
            "Accuracy on batch 130 on Training id inf\n",
            "Accuracy on batch 131 on Training id inf\n",
            "Accuracy on batch 132 on Training id inf\n",
            "Accuracy on batch 133 on Training id inf\n",
            "Accuracy on batch 134 on Training id inf\n",
            "Accuracy on batch 135 on Training id inf\n",
            "Accuracy on batch 136 on Training id inf\n",
            "Accuracy on batch 137 on Training id inf\n",
            "Accuracy on batch 138 on Training id inf\n",
            "Accuracy on batch 139 on Training id inf\n",
            "Accuracy on batch 140 on Training id inf\n",
            "Accuracy on batch 141 on Training id inf\n",
            "Accuracy on batch 142 on Training id inf\n",
            "Accuracy on batch 143 on Training id inf\n",
            "Accuracy on batch 144 on Training id inf\n",
            "Accuracy on batch 145 on Training id inf\n",
            "Accuracy on batch 146 on Training id inf\n",
            "Accuracy on batch 147 on Training id inf\n",
            "Accuracy on batch 148 on Training id inf\n",
            "Accuracy on batch 149 on Training id inf\n",
            "Training loss 0.006737533025443554\n",
            "1.025451898574829\n",
            "Accuracy on batch 150 on Training id inf\n",
            "Accuracy on batch 151 on Training id inf\n",
            "Accuracy on batch 152 on Training id inf\n",
            "Accuracy on batch 153 on Training id inf\n",
            "Accuracy on batch 154 on Training id inf\n",
            "Accuracy on batch 155 on Training id inf\n",
            "Accuracy on batch 156 on Training id inf\n",
            "Accuracy on batch 157 on Training id inf\n",
            "Accuracy on batch 158 on Training id inf\n",
            "Accuracy on batch 159 on Training id inf\n",
            "Accuracy on batch 160 on Training id inf\n",
            "Accuracy on batch 161 on Training id inf\n",
            "Accuracy on batch 162 on Training id inf\n",
            "Accuracy on batch 163 on Training id inf\n",
            "Accuracy on batch 164 on Training id inf\n",
            "Accuracy on batch 165 on Training id inf\n",
            "Accuracy on batch 166 on Training id inf\n",
            "Accuracy on batch 167 on Training id inf\n",
            "Accuracy on batch 168 on Training id inf\n",
            "Accuracy on batch 169 on Training id inf\n",
            "Accuracy on batch 170 on Training id inf\n",
            "Accuracy on batch 171 on Training id inf\n",
            "Accuracy on batch 172 on Training id inf\n",
            "Accuracy on batch 173 on Training id inf\n",
            "Accuracy on batch 174 on Training id inf\n",
            "Accuracy on batch 175 on Training id inf\n",
            "Accuracy on batch 176 on Training id inf\n",
            "Accuracy on batch 177 on Training id inf\n",
            "Accuracy on batch 178 on Training id inf\n",
            "Accuracy on batch 179 on Training id inf\n",
            "Accuracy on batch 180 on Training id inf\n",
            "Accuracy on batch 181 on Training id inf\n",
            "Accuracy on batch 182 on Training id inf\n",
            "Accuracy on batch 183 on Training id inf\n",
            "Accuracy on batch 184 on Training id inf\n",
            "Accuracy on batch 185 on Training id inf\n",
            "Accuracy on batch 186 on Training id inf\n",
            "Accuracy on batch 187 on Training id inf\n",
            "Accuracy on batch 188 on Training id inf\n",
            "Accuracy on batch 189 on Training id inf\n",
            "Accuracy on batch 190 on Training id inf\n",
            "Accuracy on batch 191 on Training id inf\n",
            "Accuracy on batch 192 on Training id inf\n",
            "Accuracy on batch 193 on Training id inf\n",
            "Accuracy on batch 194 on Training id inf\n",
            "Accuracy on batch 195 on Training id inf\n",
            "Accuracy on batch 196 on Training id inf\n",
            "Accuracy on batch 197 on Training id inf\n",
            "Accuracy on batch 198 on Training id inf\n",
            "Accuracy on batch 199 on Training id inf\n",
            "Training loss 0.0078043946996331215\n",
            "1.5761486291885376\n",
            "Accuracy on batch 200 on Training id inf\n",
            "Accuracy on batch 201 on Training id inf\n",
            "Accuracy on batch 202 on Training id inf\n",
            "Accuracy on batch 203 on Training id inf\n",
            "Accuracy on batch 204 on Training id inf\n",
            "Accuracy on batch 205 on Training id inf\n",
            "Accuracy on batch 206 on Training id inf\n",
            "Accuracy on batch 207 on Training id inf\n",
            "Accuracy on batch 208 on Training id inf\n",
            "Accuracy on batch 209 on Training id inf\n",
            "Accuracy on batch 210 on Training id inf\n",
            "Accuracy on batch 211 on Training id inf\n",
            "Accuracy on batch 212 on Training id inf\n",
            "Accuracy on batch 213 on Training id inf\n",
            "Accuracy on batch 214 on Training id inf\n",
            "Accuracy on batch 215 on Training id inf\n",
            "Accuracy on batch 216 on Training id inf\n",
            "Accuracy on batch 217 on Training id inf\n",
            "Accuracy on batch 218 on Training id inf\n",
            "Accuracy on batch 219 on Training id inf\n",
            "Accuracy on batch 220 on Training id inf\n",
            "Accuracy on batch 221 on Training id inf\n",
            "Accuracy on batch 222 on Training id inf\n",
            "Accuracy on batch 223 on Training id inf\n",
            "Accuracy on batch 224 on Training id inf\n",
            "Accuracy on batch 225 on Training id inf\n",
            "Accuracy on batch 226 on Training id inf\n",
            "Accuracy on batch 227 on Training id inf\n",
            "Accuracy on batch 228 on Training id inf\n",
            "Accuracy on batch 229 on Training id inf\n",
            "Accuracy on batch 230 on Training id inf\n",
            "Accuracy on batch 231 on Training id inf\n",
            "Accuracy on batch 232 on Training id inf\n",
            "Accuracy on batch 233 on Training id inf\n",
            "Accuracy on batch 234 on Training id inf\n",
            "Accuracy on batch 235 on Training id inf\n",
            "Accuracy on batch 236 on Training id inf\n",
            "Accuracy on batch 237 on Training id inf\n",
            "Accuracy on batch 238 on Training id inf\n",
            "Accuracy on batch 239 on Training id inf\n",
            "Accuracy on batch 240 on Training id inf\n",
            "Accuracy on batch 241 on Training id inf\n",
            "Accuracy on batch 242 on Training id inf\n",
            "Accuracy on batch 243 on Training id inf\n",
            "Accuracy on batch 244 on Training id inf\n",
            "Accuracy on batch 245 on Training id inf\n",
            "Accuracy on batch 246 on Training id inf\n",
            "Accuracy on batch 247 on Training id inf\n",
            "Accuracy on batch 248 on Training id inf\n",
            "Accuracy on batch 249 on Training id inf\n",
            "Training loss 0.00236021401360631\n",
            "0.5964184999465942\n",
            "Accuracy on batch 250 on Training id inf\n",
            "Accuracy on batch 251 on Training id inf\n",
            "Accuracy on batch 252 on Training id inf\n",
            "Accuracy on batch 253 on Training id inf\n",
            "Accuracy on batch 254 on Training id inf\n",
            "Accuracy on batch 255 on Training id inf\n",
            "Accuracy on batch 256 on Training id inf\n",
            "Accuracy on batch 257 on Training id inf\n",
            "Accuracy on batch 258 on Training id inf\n",
            "Accuracy on batch 259 on Training id inf\n",
            "Accuracy on batch 260 on Training id inf\n",
            "Accuracy on batch 261 on Training id inf\n",
            "Accuracy on batch 262 on Training id inf\n",
            "Accuracy on batch 263 on Training id inf\n",
            "Accuracy on batch 264 on Training id inf\n",
            "Accuracy on batch 265 on Training id inf\n",
            "Accuracy on batch 266 on Training id inf\n",
            "Accuracy on batch 267 on Training id inf\n",
            "Accuracy on batch 268 on Training id inf\n",
            "Accuracy on batch 269 on Training id inf\n",
            "Accuracy on batch 270 on Training id inf\n",
            "Accuracy on batch 271 on Training id inf\n",
            "Accuracy on batch 272 on Training id inf\n",
            "Accuracy on batch 273 on Training id inf\n",
            "Accuracy on batch 274 on Training id inf\n",
            "Accuracy on batch 275 on Training id inf\n",
            "Accuracy on batch 276 on Training id inf\n",
            "Accuracy on batch 277 on Training id inf\n",
            "Accuracy on batch 278 on Training id inf\n",
            "Accuracy on batch 279 on Training id inf\n",
            "Accuracy on batch 280 on Training id inf\n",
            "Accuracy on batch 281 on Training id inf\n",
            "Accuracy on batch 282 on Training id inf\n",
            "Accuracy on batch 283 on Training id inf\n",
            "Accuracy on batch 284 on Training id inf\n",
            "Accuracy on batch 285 on Training id inf\n",
            "Accuracy on batch 286 on Training id inf\n",
            "Accuracy on batch 287 on Training id inf\n",
            "Accuracy on batch 288 on Training id inf\n",
            "Accuracy on batch 289 on Training id inf\n",
            "Accuracy on batch 290 on Training id inf\n",
            "Эпоха #4 train_loss: 0.0, val_loss: 0\n",
            "Потрачено 0.4 минут на 4 эпоху\n",
            "Training loss 1.7221190929412842\n",
            "1.7221190929412842\n",
            "Accuracy on batch 0 on Training id inf\n",
            "Accuracy on batch 1 on Training id inf\n",
            "Accuracy on batch 2 on Training id inf\n",
            "Accuracy on batch 3 on Training id inf\n",
            "Accuracy on batch 4 on Training id inf\n",
            "Accuracy on batch 5 on Training id inf\n",
            "Accuracy on batch 6 on Training id inf\n",
            "Accuracy on batch 7 on Training id inf\n",
            "Accuracy on batch 8 on Training id inf\n",
            "Accuracy on batch 9 on Training id inf\n",
            "Accuracy on batch 10 on Training id inf\n",
            "Accuracy on batch 11 on Training id inf\n",
            "Accuracy on batch 12 on Training id inf\n",
            "Accuracy on batch 13 on Training id inf\n",
            "Accuracy on batch 14 on Training id inf\n",
            "Accuracy on batch 15 on Training id inf\n",
            "Accuracy on batch 16 on Training id inf\n",
            "Accuracy on batch 17 on Training id inf\n",
            "Accuracy on batch 18 on Training id inf\n",
            "Accuracy on batch 19 on Training id inf\n",
            "Accuracy on batch 20 on Training id inf\n",
            "Accuracy on batch 21 on Training id inf\n",
            "Accuracy on batch 22 on Training id inf\n",
            "Accuracy on batch 23 on Training id inf\n",
            "Accuracy on batch 24 on Training id inf\n",
            "Accuracy on batch 25 on Training id inf\n",
            "Accuracy on batch 26 on Training id inf\n",
            "Accuracy on batch 27 on Training id inf\n",
            "Accuracy on batch 28 on Training id inf\n",
            "Accuracy on batch 29 on Training id inf\n",
            "Accuracy on batch 30 on Training id inf\n",
            "Accuracy on batch 31 on Training id inf\n",
            "Accuracy on batch 32 on Training id inf\n",
            "Accuracy on batch 33 on Training id inf\n",
            "Accuracy on batch 34 on Training id inf\n",
            "Accuracy on batch 35 on Training id inf\n",
            "Accuracy on batch 36 on Training id inf\n",
            "Accuracy on batch 37 on Training id inf\n",
            "Accuracy on batch 38 on Training id inf\n",
            "Accuracy on batch 39 on Training id inf\n",
            "Accuracy on batch 40 on Training id inf\n",
            "Accuracy on batch 41 on Training id inf\n",
            "Accuracy on batch 42 on Training id inf\n",
            "Accuracy on batch 43 on Training id inf\n",
            "Accuracy on batch 44 on Training id inf\n",
            "Accuracy on batch 45 on Training id inf\n",
            "Accuracy on batch 46 on Training id inf\n",
            "Accuracy on batch 47 on Training id inf\n",
            "Accuracy on batch 48 on Training id inf\n",
            "Accuracy on batch 49 on Training id inf\n",
            "Training loss 0.02396177127957344\n",
            "1.2401814460754395\n",
            "Accuracy on batch 50 on Training id inf\n",
            "Accuracy on batch 51 on Training id inf\n",
            "Accuracy on batch 52 on Training id inf\n",
            "Accuracy on batch 53 on Training id inf\n",
            "Accuracy on batch 54 on Training id inf\n",
            "Accuracy on batch 55 on Training id inf\n",
            "Accuracy on batch 56 on Training id inf\n",
            "Accuracy on batch 57 on Training id inf\n",
            "Accuracy on batch 58 on Training id inf\n",
            "Accuracy on batch 59 on Training id inf\n",
            "Accuracy on batch 60 on Training id inf\n",
            "Accuracy on batch 61 on Training id inf\n",
            "Accuracy on batch 62 on Training id inf\n",
            "Accuracy on batch 63 on Training id inf\n",
            "Accuracy on batch 64 on Training id inf\n",
            "Accuracy on batch 65 on Training id inf\n",
            "Accuracy on batch 66 on Training id inf\n",
            "Accuracy on batch 67 on Training id inf\n",
            "Accuracy on batch 68 on Training id inf\n",
            "Accuracy on batch 69 on Training id inf\n",
            "Accuracy on batch 70 on Training id inf\n",
            "Accuracy on batch 71 on Training id inf\n",
            "Accuracy on batch 72 on Training id inf\n",
            "Accuracy on batch 73 on Training id inf\n",
            "Accuracy on batch 74 on Training id inf\n",
            "Accuracy on batch 75 on Training id inf\n",
            "Accuracy on batch 76 on Training id inf\n",
            "Accuracy on batch 77 on Training id inf\n",
            "Accuracy on batch 78 on Training id inf\n",
            "Accuracy on batch 79 on Training id inf\n",
            "Accuracy on batch 80 on Training id inf\n",
            "Accuracy on batch 81 on Training id inf\n",
            "Accuracy on batch 82 on Training id inf\n",
            "Accuracy on batch 83 on Training id inf\n",
            "Accuracy on batch 84 on Training id inf\n",
            "Accuracy on batch 85 on Training id inf\n",
            "Accuracy on batch 86 on Training id inf\n",
            "Accuracy on batch 87 on Training id inf\n",
            "Accuracy on batch 88 on Training id inf\n",
            "Accuracy on batch 89 on Training id inf\n",
            "Accuracy on batch 90 on Training id inf\n",
            "Accuracy on batch 91 on Training id inf\n",
            "Accuracy on batch 92 on Training id inf\n",
            "Accuracy on batch 93 on Training id inf\n",
            "Accuracy on batch 94 on Training id inf\n",
            "Accuracy on batch 95 on Training id inf\n",
            "Accuracy on batch 96 on Training id inf\n",
            "Accuracy on batch 97 on Training id inf\n",
            "Accuracy on batch 98 on Training id inf\n",
            "Accuracy on batch 99 on Training id inf\n",
            "Training loss 0.005285575985908508\n",
            "0.5372387766838074\n",
            "Accuracy on batch 100 on Training id inf\n",
            "Accuracy on batch 101 on Training id inf\n",
            "Accuracy on batch 102 on Training id inf\n",
            "Accuracy on batch 103 on Training id inf\n",
            "Accuracy on batch 104 on Training id inf\n",
            "Accuracy on batch 105 on Training id inf\n",
            "Accuracy on batch 106 on Training id inf\n",
            "Accuracy on batch 107 on Training id inf\n",
            "Accuracy on batch 108 on Training id inf\n",
            "Accuracy on batch 109 on Training id inf\n",
            "Accuracy on batch 110 on Training id inf\n",
            "Accuracy on batch 111 on Training id inf\n",
            "Accuracy on batch 112 on Training id inf\n",
            "Accuracy on batch 113 on Training id inf\n",
            "Accuracy on batch 114 on Training id inf\n",
            "Accuracy on batch 115 on Training id inf\n",
            "Accuracy on batch 116 on Training id inf\n",
            "Accuracy on batch 117 on Training id inf\n",
            "Accuracy on batch 118 on Training id inf\n",
            "Accuracy on batch 119 on Training id inf\n",
            "Accuracy on batch 120 on Training id inf\n",
            "Accuracy on batch 121 on Training id inf\n",
            "Accuracy on batch 122 on Training id inf\n",
            "Accuracy on batch 123 on Training id inf\n",
            "Accuracy on batch 124 on Training id inf\n",
            "Accuracy on batch 125 on Training id inf\n",
            "Accuracy on batch 126 on Training id inf\n",
            "Accuracy on batch 127 on Training id inf\n",
            "Accuracy on batch 128 on Training id inf\n",
            "Accuracy on batch 129 on Training id inf\n",
            "Accuracy on batch 130 on Training id inf\n",
            "Accuracy on batch 131 on Training id inf\n",
            "Accuracy on batch 132 on Training id inf\n",
            "Accuracy on batch 133 on Training id inf\n",
            "Accuracy on batch 134 on Training id inf\n",
            "Accuracy on batch 135 on Training id inf\n",
            "Accuracy on batch 136 on Training id inf\n",
            "Accuracy on batch 137 on Training id inf\n",
            "Accuracy on batch 138 on Training id inf\n",
            "Accuracy on batch 139 on Training id inf\n",
            "Accuracy on batch 140 on Training id inf\n",
            "Accuracy on batch 141 on Training id inf\n",
            "Accuracy on batch 142 on Training id inf\n",
            "Accuracy on batch 143 on Training id inf\n",
            "Accuracy on batch 144 on Training id inf\n",
            "Accuracy on batch 145 on Training id inf\n",
            "Accuracy on batch 146 on Training id inf\n",
            "Accuracy on batch 147 on Training id inf\n",
            "Accuracy on batch 148 on Training id inf\n",
            "Accuracy on batch 149 on Training id inf\n",
            "Training loss 0.008105711080133915\n",
            "1.2280173301696777\n",
            "Accuracy on batch 150 on Training id inf\n",
            "Accuracy on batch 151 on Training id inf\n",
            "Accuracy on batch 152 on Training id inf\n",
            "Accuracy on batch 153 on Training id inf\n",
            "Accuracy on batch 154 on Training id inf\n",
            "Accuracy on batch 155 on Training id inf\n",
            "Accuracy on batch 156 on Training id inf\n",
            "Accuracy on batch 157 on Training id inf\n",
            "Accuracy on batch 158 on Training id inf\n",
            "Accuracy on batch 159 on Training id inf\n",
            "Accuracy on batch 160 on Training id inf\n",
            "Accuracy on batch 161 on Training id inf\n",
            "Accuracy on batch 162 on Training id inf\n",
            "Accuracy on batch 163 on Training id inf\n",
            "Accuracy on batch 164 on Training id inf\n",
            "Accuracy on batch 165 on Training id inf\n",
            "Accuracy on batch 166 on Training id inf\n",
            "Accuracy on batch 167 on Training id inf\n",
            "Accuracy on batch 168 on Training id inf\n",
            "Accuracy on batch 169 on Training id inf\n",
            "Accuracy on batch 170 on Training id inf\n",
            "Accuracy on batch 171 on Training id inf\n",
            "Accuracy on batch 172 on Training id inf\n",
            "Accuracy on batch 173 on Training id inf\n",
            "Accuracy on batch 174 on Training id inf\n",
            "Accuracy on batch 175 on Training id inf\n",
            "Accuracy on batch 176 on Training id inf\n",
            "Accuracy on batch 177 on Training id inf\n",
            "Accuracy on batch 178 on Training id inf\n",
            "Accuracy on batch 179 on Training id inf\n",
            "Accuracy on batch 180 on Training id inf\n",
            "Accuracy on batch 181 on Training id inf\n",
            "Accuracy on batch 182 on Training id inf\n",
            "Accuracy on batch 183 on Training id inf\n",
            "Accuracy on batch 184 on Training id inf\n",
            "Accuracy on batch 185 on Training id inf\n",
            "Accuracy on batch 186 on Training id inf\n",
            "Accuracy on batch 187 on Training id inf\n",
            "Accuracy on batch 188 on Training id inf\n",
            "Accuracy on batch 189 on Training id inf\n",
            "Accuracy on batch 190 on Training id inf\n",
            "Accuracy on batch 191 on Training id inf\n",
            "Accuracy on batch 192 on Training id inf\n",
            "Accuracy on batch 193 on Training id inf\n",
            "Accuracy on batch 194 on Training id inf\n",
            "Accuracy on batch 195 on Training id inf\n",
            "Accuracy on batch 196 on Training id inf\n",
            "Accuracy on batch 197 on Training id inf\n",
            "Accuracy on batch 198 on Training id inf\n",
            "Accuracy on batch 199 on Training id inf\n",
            "Training loss 0.005986381322145462\n",
            "1.211243748664856\n",
            "Accuracy on batch 200 on Training id inf\n",
            "Accuracy on batch 201 on Training id inf\n",
            "Accuracy on batch 202 on Training id inf\n",
            "Accuracy on batch 203 on Training id inf\n",
            "Accuracy on batch 204 on Training id inf\n",
            "Accuracy on batch 205 on Training id inf\n",
            "Accuracy on batch 206 on Training id inf\n",
            "Accuracy on batch 207 on Training id inf\n",
            "Accuracy on batch 208 on Training id inf\n",
            "Accuracy on batch 209 on Training id inf\n",
            "Accuracy on batch 210 on Training id inf\n",
            "Accuracy on batch 211 on Training id inf\n",
            "Accuracy on batch 212 on Training id inf\n",
            "Accuracy on batch 213 on Training id inf\n",
            "Accuracy on batch 214 on Training id inf\n",
            "Accuracy on batch 215 on Training id inf\n",
            "Accuracy on batch 216 on Training id inf\n",
            "Accuracy on batch 217 on Training id inf\n",
            "Accuracy on batch 218 on Training id inf\n",
            "Accuracy on batch 219 on Training id inf\n",
            "Accuracy on batch 220 on Training id inf\n",
            "Accuracy on batch 221 on Training id inf\n",
            "Accuracy on batch 222 on Training id inf\n",
            "Accuracy on batch 223 on Training id inf\n",
            "Accuracy on batch 224 on Training id inf\n",
            "Accuracy on batch 225 on Training id inf\n",
            "Accuracy on batch 226 on Training id inf\n",
            "Accuracy on batch 227 on Training id inf\n",
            "Accuracy on batch 228 on Training id inf\n",
            "Accuracy on batch 229 on Training id inf\n",
            "Accuracy on batch 230 on Training id inf\n",
            "Accuracy on batch 231 on Training id inf\n",
            "Accuracy on batch 232 on Training id inf\n",
            "Accuracy on batch 233 on Training id inf\n",
            "Accuracy on batch 234 on Training id inf\n",
            "Accuracy on batch 235 on Training id inf\n",
            "Accuracy on batch 236 on Training id inf\n",
            "Accuracy on batch 237 on Training id inf\n",
            "Accuracy on batch 238 on Training id inf\n",
            "Accuracy on batch 239 on Training id inf\n",
            "Accuracy on batch 240 on Training id inf\n",
            "Accuracy on batch 241 on Training id inf\n",
            "Accuracy on batch 242 on Training id inf\n",
            "Accuracy on batch 243 on Training id inf\n",
            "Accuracy on batch 244 on Training id inf\n",
            "Accuracy on batch 245 on Training id inf\n",
            "Accuracy on batch 246 on Training id inf\n",
            "Accuracy on batch 247 on Training id inf\n",
            "Accuracy on batch 248 on Training id inf\n",
            "Accuracy on batch 249 on Training id inf\n",
            "Training loss 0.005559055600315332\n",
            "1.4089895486831665\n",
            "Accuracy on batch 250 on Training id inf\n",
            "Accuracy on batch 251 on Training id inf\n",
            "Accuracy on batch 252 on Training id inf\n",
            "Accuracy on batch 253 on Training id inf\n",
            "Accuracy on batch 254 on Training id inf\n",
            "Accuracy on batch 255 on Training id inf\n",
            "Accuracy on batch 256 on Training id inf\n",
            "Accuracy on batch 257 on Training id inf\n",
            "Accuracy on batch 258 on Training id inf\n",
            "Accuracy on batch 259 on Training id inf\n",
            "Accuracy on batch 260 on Training id inf\n",
            "Accuracy on batch 261 on Training id inf\n",
            "Accuracy on batch 262 on Training id inf\n",
            "Accuracy on batch 263 on Training id inf\n",
            "Accuracy on batch 264 on Training id inf\n",
            "Accuracy on batch 265 on Training id inf\n",
            "Accuracy on batch 266 on Training id inf\n",
            "Accuracy on batch 267 on Training id inf\n",
            "Accuracy on batch 268 on Training id inf\n",
            "Accuracy on batch 269 on Training id inf\n",
            "Accuracy on batch 270 on Training id inf\n",
            "Accuracy on batch 271 on Training id inf\n",
            "Accuracy on batch 272 on Training id inf\n",
            "Accuracy on batch 273 on Training id inf\n",
            "Accuracy on batch 274 on Training id inf\n",
            "Accuracy on batch 275 on Training id inf\n",
            "Accuracy on batch 276 on Training id inf\n",
            "Accuracy on batch 277 on Training id inf\n",
            "Accuracy on batch 278 on Training id inf\n",
            "Accuracy on batch 279 on Training id inf\n",
            "Accuracy on batch 280 on Training id inf\n",
            "Accuracy on batch 281 on Training id inf\n",
            "Accuracy on batch 282 on Training id inf\n",
            "Accuracy on batch 283 on Training id inf\n",
            "Accuracy on batch 284 on Training id inf\n",
            "Accuracy on batch 285 on Training id inf\n",
            "Accuracy on batch 286 on Training id inf\n",
            "Accuracy on batch 287 on Training id inf\n",
            "Accuracy on batch 288 on Training id inf\n",
            "Accuracy on batch 289 on Training id inf\n",
            "Accuracy on batch 290 on Training id inf\n",
            "Эпоха #5 train_loss: 0.0, val_loss: 0\n",
            "Потрачено 0.4 минут на 5 эпоху\n",
            "Training loss 0.7450957894325256\n",
            "0.7450957894325256\n",
            "Accuracy on batch 0 on Training id inf\n",
            "Accuracy on batch 1 on Training id inf\n",
            "Accuracy on batch 2 on Training id inf\n",
            "Accuracy on batch 3 on Training id inf\n",
            "Accuracy on batch 4 on Training id inf\n",
            "Accuracy on batch 5 on Training id inf\n",
            "Accuracy on batch 6 on Training id inf\n",
            "Accuracy on batch 7 on Training id inf\n",
            "Accuracy on batch 8 on Training id inf\n",
            "Accuracy on batch 9 on Training id inf\n",
            "Accuracy on batch 10 on Training id inf\n",
            "Accuracy on batch 11 on Training id inf\n",
            "Accuracy on batch 12 on Training id inf\n",
            "Accuracy on batch 13 on Training id inf\n",
            "Accuracy on batch 14 on Training id inf\n",
            "Accuracy on batch 15 on Training id inf\n",
            "Accuracy on batch 16 on Training id inf\n",
            "Accuracy on batch 17 on Training id inf\n",
            "Accuracy on batch 18 on Training id inf\n",
            "Accuracy on batch 19 on Training id inf\n",
            "Accuracy on batch 20 on Training id inf\n",
            "Accuracy on batch 21 on Training id inf\n",
            "Accuracy on batch 22 on Training id inf\n",
            "Accuracy on batch 23 on Training id inf\n",
            "Accuracy on batch 24 on Training id inf\n",
            "Accuracy on batch 25 on Training id inf\n",
            "Accuracy on batch 26 on Training id inf\n",
            "Accuracy on batch 27 on Training id inf\n",
            "Accuracy on batch 28 on Training id inf\n",
            "Accuracy on batch 29 on Training id inf\n",
            "Accuracy on batch 30 on Training id inf\n",
            "Accuracy on batch 31 on Training id inf\n",
            "Accuracy on batch 32 on Training id inf\n",
            "Accuracy on batch 33 on Training id inf\n",
            "Accuracy on batch 34 on Training id inf\n",
            "Accuracy on batch 35 on Training id inf\n",
            "Accuracy on batch 36 on Training id inf\n",
            "Accuracy on batch 37 on Training id inf\n",
            "Accuracy on batch 38 on Training id inf\n",
            "Accuracy on batch 39 on Training id inf\n",
            "Accuracy on batch 40 on Training id inf\n",
            "Accuracy on batch 41 on Training id inf\n",
            "Accuracy on batch 42 on Training id inf\n",
            "Accuracy on batch 43 on Training id inf\n",
            "Accuracy on batch 44 on Training id inf\n",
            "Accuracy on batch 45 on Training id inf\n",
            "Accuracy on batch 46 on Training id inf\n",
            "Accuracy on batch 47 on Training id inf\n",
            "Accuracy on batch 48 on Training id inf\n",
            "Accuracy on batch 49 on Training id inf\n",
            "Training loss 0.013904083520174026\n",
            "0.7491321563720703\n",
            "Accuracy on batch 50 on Training id inf\n",
            "Accuracy on batch 51 on Training id inf\n",
            "Accuracy on batch 52 on Training id inf\n",
            "Accuracy on batch 53 on Training id inf\n",
            "Accuracy on batch 54 on Training id inf\n",
            "Accuracy on batch 55 on Training id inf\n",
            "Accuracy on batch 56 on Training id inf\n",
            "Accuracy on batch 57 on Training id inf\n",
            "Accuracy on batch 58 on Training id inf\n",
            "Accuracy on batch 59 on Training id inf\n",
            "Accuracy on batch 60 on Training id inf\n",
            "Accuracy on batch 61 on Training id inf\n",
            "Accuracy on batch 62 on Training id inf\n",
            "Accuracy on batch 63 on Training id inf\n",
            "Accuracy on batch 64 on Training id inf\n",
            "Accuracy on batch 65 on Training id inf\n",
            "Accuracy on batch 66 on Training id inf\n",
            "Accuracy on batch 67 on Training id inf\n",
            "Accuracy on batch 68 on Training id inf\n",
            "Accuracy on batch 69 on Training id inf\n",
            "Accuracy on batch 70 on Training id inf\n",
            "Accuracy on batch 71 on Training id inf\n",
            "Accuracy on batch 72 on Training id inf\n",
            "Accuracy on batch 73 on Training id inf\n",
            "Accuracy on batch 74 on Training id inf\n",
            "Accuracy on batch 75 on Training id inf\n",
            "Accuracy on batch 76 on Training id inf\n",
            "Accuracy on batch 77 on Training id inf\n",
            "Accuracy on batch 78 on Training id inf\n",
            "Accuracy on batch 79 on Training id inf\n",
            "Accuracy on batch 80 on Training id inf\n",
            "Accuracy on batch 81 on Training id inf\n",
            "Accuracy on batch 82 on Training id inf\n",
            "Accuracy on batch 83 on Training id inf\n",
            "Accuracy on batch 84 on Training id inf\n",
            "Accuracy on batch 85 on Training id inf\n",
            "Accuracy on batch 86 on Training id inf\n",
            "Accuracy on batch 87 on Training id inf\n",
            "Accuracy on batch 88 on Training id inf\n",
            "Accuracy on batch 89 on Training id inf\n",
            "Accuracy on batch 90 on Training id inf\n",
            "Accuracy on batch 91 on Training id inf\n",
            "Accuracy on batch 92 on Training id inf\n",
            "Accuracy on batch 93 on Training id inf\n",
            "Accuracy on batch 94 on Training id inf\n",
            "Accuracy on batch 95 on Training id inf\n",
            "Accuracy on batch 96 on Training id inf\n",
            "Accuracy on batch 97 on Training id inf\n",
            "Accuracy on batch 98 on Training id inf\n",
            "Accuracy on batch 99 on Training id inf\n",
            "Training loss 0.01459830068051815\n",
            "1.4813759326934814\n",
            "Accuracy on batch 100 on Training id inf\n",
            "Accuracy on batch 101 on Training id inf\n",
            "Accuracy on batch 102 on Training id inf\n",
            "Accuracy on batch 103 on Training id inf\n",
            "Accuracy on batch 104 on Training id inf\n",
            "Accuracy on batch 105 on Training id inf\n",
            "Accuracy on batch 106 on Training id inf\n",
            "Accuracy on batch 107 on Training id inf\n",
            "Accuracy on batch 108 on Training id inf\n",
            "Accuracy on batch 109 on Training id inf\n",
            "Accuracy on batch 110 on Training id inf\n",
            "Accuracy on batch 111 on Training id inf\n",
            "Accuracy on batch 112 on Training id inf\n",
            "Accuracy on batch 113 on Training id inf\n",
            "Accuracy on batch 114 on Training id inf\n",
            "Accuracy on batch 115 on Training id inf\n",
            "Accuracy on batch 116 on Training id inf\n",
            "Accuracy on batch 117 on Training id inf\n",
            "Accuracy on batch 118 on Training id inf\n",
            "Accuracy on batch 119 on Training id inf\n",
            "Accuracy on batch 120 on Training id inf\n",
            "Accuracy on batch 121 on Training id inf\n",
            "Accuracy on batch 122 on Training id inf\n",
            "Accuracy on batch 123 on Training id inf\n",
            "Accuracy on batch 124 on Training id inf\n",
            "Accuracy on batch 125 on Training id inf\n",
            "Accuracy on batch 126 on Training id inf\n",
            "Accuracy on batch 127 on Training id inf\n",
            "Accuracy on batch 128 on Training id inf\n",
            "Accuracy on batch 129 on Training id inf\n",
            "Accuracy on batch 130 on Training id inf\n",
            "Accuracy on batch 131 on Training id inf\n",
            "Accuracy on batch 132 on Training id inf\n",
            "Accuracy on batch 133 on Training id inf\n",
            "Accuracy on batch 134 on Training id inf\n",
            "Accuracy on batch 135 on Training id inf\n",
            "Accuracy on batch 136 on Training id inf\n",
            "Accuracy on batch 137 on Training id inf\n",
            "Accuracy on batch 138 on Training id inf\n",
            "Accuracy on batch 139 on Training id inf\n",
            "Accuracy on batch 140 on Training id inf\n",
            "Accuracy on batch 141 on Training id inf\n",
            "Accuracy on batch 142 on Training id inf\n",
            "Accuracy on batch 143 on Training id inf\n",
            "Accuracy on batch 144 on Training id inf\n",
            "Accuracy on batch 145 on Training id inf\n",
            "Accuracy on batch 146 on Training id inf\n",
            "Accuracy on batch 147 on Training id inf\n",
            "Accuracy on batch 148 on Training id inf\n",
            "Accuracy on batch 149 on Training id inf\n",
            "Training loss 0.01300155371427536\n",
            "1.971164584159851\n",
            "Accuracy on batch 150 on Training id inf\n",
            "Accuracy on batch 151 on Training id inf\n",
            "Accuracy on batch 152 on Training id inf\n",
            "Accuracy on batch 153 on Training id inf\n",
            "Accuracy on batch 154 on Training id inf\n",
            "Accuracy on batch 155 on Training id inf\n",
            "Accuracy on batch 156 on Training id inf\n",
            "Accuracy on batch 157 on Training id inf\n",
            "Accuracy on batch 158 on Training id inf\n",
            "Accuracy on batch 159 on Training id inf\n",
            "Accuracy on batch 160 on Training id inf\n",
            "Accuracy on batch 161 on Training id inf\n",
            "Accuracy on batch 162 on Training id inf\n",
            "Accuracy on batch 163 on Training id inf\n",
            "Accuracy on batch 164 on Training id inf\n",
            "Accuracy on batch 165 on Training id inf\n",
            "Accuracy on batch 166 on Training id inf\n",
            "Accuracy on batch 167 on Training id inf\n",
            "Accuracy on batch 168 on Training id inf\n",
            "Accuracy on batch 169 on Training id inf\n",
            "Accuracy on batch 170 on Training id inf\n",
            "Accuracy on batch 171 on Training id inf\n",
            "Accuracy on batch 172 on Training id inf\n",
            "Accuracy on batch 173 on Training id inf\n",
            "Accuracy on batch 174 on Training id inf\n",
            "Accuracy on batch 175 on Training id inf\n",
            "Accuracy on batch 176 on Training id inf\n",
            "Accuracy on batch 177 on Training id inf\n",
            "Accuracy on batch 178 on Training id inf\n",
            "Accuracy on batch 179 on Training id inf\n",
            "Accuracy on batch 180 on Training id inf\n",
            "Accuracy on batch 181 on Training id inf\n",
            "Accuracy on batch 182 on Training id inf\n",
            "Accuracy on batch 183 on Training id inf\n",
            "Accuracy on batch 184 on Training id inf\n",
            "Accuracy on batch 185 on Training id inf\n",
            "Accuracy on batch 186 on Training id inf\n",
            "Accuracy on batch 187 on Training id inf\n",
            "Accuracy on batch 188 on Training id inf\n",
            "Accuracy on batch 189 on Training id inf\n",
            "Accuracy on batch 190 on Training id inf\n",
            "Accuracy on batch 191 on Training id inf\n",
            "Accuracy on batch 192 on Training id inf\n",
            "Accuracy on batch 193 on Training id inf\n",
            "Accuracy on batch 194 on Training id inf\n",
            "Accuracy on batch 195 on Training id inf\n",
            "Accuracy on batch 196 on Training id inf\n",
            "Accuracy on batch 197 on Training id inf\n",
            "Accuracy on batch 198 on Training id inf\n",
            "Accuracy on batch 199 on Training id inf\n",
            "Training loss 0.007523423992097378\n",
            "1.519634485244751\n",
            "Accuracy on batch 200 on Training id inf\n",
            "Accuracy on batch 201 on Training id inf\n",
            "Accuracy on batch 202 on Training id inf\n",
            "Accuracy on batch 203 on Training id inf\n",
            "Accuracy on batch 204 on Training id inf\n",
            "Accuracy on batch 205 on Training id inf\n",
            "Accuracy on batch 206 on Training id inf\n",
            "Accuracy on batch 207 on Training id inf\n",
            "Accuracy on batch 208 on Training id inf\n",
            "Accuracy on batch 209 on Training id inf\n",
            "Accuracy on batch 210 on Training id inf\n",
            "Accuracy on batch 211 on Training id inf\n",
            "Accuracy on batch 212 on Training id inf\n",
            "Accuracy on batch 213 on Training id inf\n",
            "Accuracy on batch 214 on Training id inf\n",
            "Accuracy on batch 215 on Training id inf\n",
            "Accuracy on batch 216 on Training id inf\n",
            "Accuracy on batch 217 on Training id inf\n",
            "Accuracy on batch 218 on Training id inf\n",
            "Accuracy on batch 219 on Training id inf\n",
            "Accuracy on batch 220 on Training id inf\n",
            "Accuracy on batch 221 on Training id inf\n",
            "Accuracy on batch 222 on Training id inf\n",
            "Accuracy on batch 223 on Training id inf\n",
            "Accuracy on batch 224 on Training id inf\n",
            "Accuracy on batch 225 on Training id inf\n",
            "Accuracy on batch 226 on Training id inf\n",
            "Accuracy on batch 227 on Training id inf\n",
            "Accuracy on batch 228 on Training id inf\n",
            "Accuracy on batch 229 on Training id inf\n",
            "Accuracy on batch 230 on Training id inf\n",
            "Accuracy on batch 231 on Training id inf\n",
            "Accuracy on batch 232 on Training id inf\n",
            "Accuracy on batch 233 on Training id inf\n",
            "Accuracy on batch 234 on Training id inf\n",
            "Accuracy on batch 235 on Training id inf\n",
            "Accuracy on batch 236 on Training id inf\n",
            "Accuracy on batch 237 on Training id inf\n",
            "Accuracy on batch 238 on Training id inf\n",
            "Accuracy on batch 239 on Training id inf\n",
            "Accuracy on batch 240 on Training id inf\n",
            "Accuracy on batch 241 on Training id inf\n",
            "Accuracy on batch 242 on Training id inf\n",
            "Accuracy on batch 243 on Training id inf\n",
            "Accuracy on batch 244 on Training id inf\n",
            "Accuracy on batch 245 on Training id inf\n",
            "Accuracy on batch 246 on Training id inf\n",
            "Accuracy on batch 247 on Training id inf\n",
            "Accuracy on batch 248 on Training id inf\n",
            "Accuracy on batch 249 on Training id inf\n",
            "Training loss 0.011358378455042839\n",
            "2.8542087078094482\n",
            "Accuracy on batch 250 on Training id inf\n",
            "Accuracy on batch 251 on Training id inf\n",
            "Accuracy on batch 252 on Training id inf\n",
            "Accuracy on batch 253 on Training id inf\n",
            "Accuracy on batch 254 on Training id inf\n",
            "Accuracy on batch 255 on Training id inf\n",
            "Accuracy on batch 256 on Training id inf\n",
            "Accuracy on batch 257 on Training id inf\n",
            "Accuracy on batch 258 on Training id inf\n",
            "Accuracy on batch 259 on Training id inf\n",
            "Accuracy on batch 260 on Training id inf\n",
            "Accuracy on batch 261 on Training id inf\n",
            "Accuracy on batch 262 on Training id inf\n",
            "Accuracy on batch 263 on Training id inf\n",
            "Accuracy on batch 264 on Training id inf\n",
            "Accuracy on batch 265 on Training id inf\n",
            "Accuracy on batch 266 on Training id inf\n",
            "Accuracy on batch 267 on Training id inf\n",
            "Accuracy on batch 268 on Training id inf\n",
            "Accuracy on batch 269 on Training id inf\n",
            "Accuracy on batch 270 on Training id inf\n",
            "Accuracy on batch 271 on Training id inf\n",
            "Accuracy on batch 272 on Training id inf\n",
            "Accuracy on batch 273 on Training id inf\n",
            "Accuracy on batch 274 on Training id inf\n",
            "Accuracy on batch 275 on Training id inf\n",
            "Accuracy on batch 276 on Training id inf\n",
            "Accuracy on batch 277 on Training id inf\n",
            "Accuracy on batch 278 on Training id inf\n",
            "Accuracy on batch 279 on Training id inf\n",
            "Accuracy on batch 280 on Training id inf\n",
            "Accuracy on batch 281 on Training id inf\n",
            "Accuracy on batch 282 on Training id inf\n",
            "Accuracy on batch 283 on Training id inf\n",
            "Accuracy on batch 284 on Training id inf\n",
            "Accuracy on batch 285 on Training id inf\n",
            "Accuracy on batch 286 on Training id inf\n",
            "Accuracy on batch 287 on Training id inf\n",
            "Accuracy on batch 288 on Training id inf\n",
            "Accuracy on batch 289 on Training id inf\n",
            "Accuracy on batch 290 on Training id inf\n",
            "Эпоха #6 train_loss: 0.0, val_loss: 0\n",
            "Потрачено 0.4 минут на 6 эпоху\n",
            "Training loss 1.7106964588165283\n",
            "1.7106964588165283\n",
            "Accuracy on batch 0 on Training id inf\n",
            "Accuracy on batch 1 on Training id inf\n",
            "Accuracy on batch 2 on Training id inf\n",
            "Accuracy on batch 3 on Training id inf\n",
            "Accuracy on batch 4 on Training id inf\n",
            "Accuracy on batch 5 on Training id inf\n",
            "Accuracy on batch 6 on Training id inf\n",
            "Accuracy on batch 7 on Training id inf\n",
            "Accuracy on batch 8 on Training id inf\n",
            "Accuracy on batch 9 on Training id inf\n",
            "Accuracy on batch 10 on Training id inf\n",
            "Accuracy on batch 11 on Training id inf\n",
            "Accuracy on batch 12 on Training id inf\n",
            "Accuracy on batch 13 on Training id inf\n",
            "Accuracy on batch 14 on Training id inf\n",
            "Accuracy on batch 15 on Training id inf\n",
            "Accuracy on batch 16 on Training id inf\n",
            "Accuracy on batch 17 on Training id inf\n",
            "Accuracy on batch 18 on Training id inf\n",
            "Accuracy on batch 19 on Training id inf\n",
            "Accuracy on batch 20 on Training id inf\n",
            "Accuracy on batch 21 on Training id inf\n",
            "Accuracy on batch 22 on Training id inf\n",
            "Accuracy on batch 23 on Training id inf\n",
            "Accuracy on batch 24 on Training id inf\n",
            "Accuracy on batch 25 on Training id inf\n",
            "Accuracy on batch 26 on Training id inf\n",
            "Accuracy on batch 27 on Training id inf\n",
            "Accuracy on batch 28 on Training id inf\n",
            "Accuracy on batch 29 on Training id inf\n",
            "Accuracy on batch 30 on Training id inf\n",
            "Accuracy on batch 31 on Training id inf\n",
            "Accuracy on batch 32 on Training id inf\n",
            "Accuracy on batch 33 on Training id inf\n",
            "Accuracy on batch 34 on Training id inf\n",
            "Accuracy on batch 35 on Training id inf\n",
            "Accuracy on batch 36 on Training id inf\n",
            "Accuracy on batch 37 on Training id inf\n",
            "Accuracy on batch 38 on Training id inf\n",
            "Accuracy on batch 39 on Training id inf\n",
            "Accuracy on batch 40 on Training id inf\n",
            "Accuracy on batch 41 on Training id inf\n",
            "Accuracy on batch 42 on Training id inf\n",
            "Accuracy on batch 43 on Training id inf\n",
            "Accuracy on batch 44 on Training id inf\n",
            "Accuracy on batch 45 on Training id inf\n",
            "Accuracy on batch 46 on Training id inf\n",
            "Accuracy on batch 47 on Training id inf\n",
            "Accuracy on batch 48 on Training id inf\n",
            "Accuracy on batch 49 on Training id inf\n",
            "Training loss 0.04028371348977089\n",
            "2.0933358669281006\n",
            "Accuracy on batch 50 on Training id inf\n",
            "Accuracy on batch 51 on Training id inf\n",
            "Accuracy on batch 52 on Training id inf\n",
            "Accuracy on batch 53 on Training id inf\n",
            "Accuracy on batch 54 on Training id inf\n",
            "Accuracy on batch 55 on Training id inf\n",
            "Accuracy on batch 56 on Training id inf\n",
            "Accuracy on batch 57 on Training id inf\n",
            "Accuracy on batch 58 on Training id inf\n",
            "Accuracy on batch 59 on Training id inf\n",
            "Accuracy on batch 60 on Training id inf\n",
            "Accuracy on batch 61 on Training id inf\n",
            "Accuracy on batch 62 on Training id inf\n",
            "Accuracy on batch 63 on Training id inf\n",
            "Accuracy on batch 64 on Training id inf\n",
            "Accuracy on batch 65 on Training id inf\n",
            "Accuracy on batch 66 on Training id inf\n",
            "Accuracy on batch 67 on Training id inf\n",
            "Accuracy on batch 68 on Training id inf\n",
            "Accuracy on batch 69 on Training id inf\n",
            "Accuracy on batch 70 on Training id inf\n",
            "Accuracy on batch 71 on Training id inf\n",
            "Accuracy on batch 72 on Training id inf\n",
            "Accuracy on batch 73 on Training id inf\n",
            "Accuracy on batch 74 on Training id inf\n",
            "Accuracy on batch 75 on Training id inf\n",
            "Accuracy on batch 76 on Training id inf\n",
            "Accuracy on batch 77 on Training id inf\n",
            "Accuracy on batch 78 on Training id inf\n",
            "Accuracy on batch 79 on Training id inf\n",
            "Accuracy on batch 80 on Training id inf\n",
            "Accuracy on batch 81 on Training id inf\n",
            "Accuracy on batch 82 on Training id inf\n",
            "Accuracy on batch 83 on Training id inf\n",
            "Accuracy on batch 84 on Training id inf\n",
            "Accuracy on batch 85 on Training id inf\n",
            "Accuracy on batch 86 on Training id inf\n",
            "Accuracy on batch 87 on Training id inf\n",
            "Accuracy on batch 88 on Training id inf\n",
            "Accuracy on batch 89 on Training id inf\n",
            "Accuracy on batch 90 on Training id inf\n",
            "Accuracy on batch 91 on Training id inf\n",
            "Accuracy on batch 92 on Training id inf\n",
            "Accuracy on batch 93 on Training id inf\n",
            "Accuracy on batch 94 on Training id inf\n",
            "Accuracy on batch 95 on Training id inf\n",
            "Accuracy on batch 96 on Training id inf\n",
            "Accuracy on batch 97 on Training id inf\n",
            "Accuracy on batch 98 on Training id inf\n",
            "Accuracy on batch 99 on Training id inf\n",
            "Training loss 0.006588309537619352\n",
            "0.6765345931053162\n",
            "Accuracy on batch 100 on Training id inf\n",
            "Accuracy on batch 101 on Training id inf\n",
            "Accuracy on batch 102 on Training id inf\n",
            "Accuracy on batch 103 on Training id inf\n",
            "Accuracy on batch 104 on Training id inf\n",
            "Accuracy on batch 105 on Training id inf\n",
            "Accuracy on batch 106 on Training id inf\n",
            "Accuracy on batch 107 on Training id inf\n",
            "Accuracy on batch 108 on Training id inf\n",
            "Accuracy on batch 109 on Training id inf\n",
            "Accuracy on batch 110 on Training id inf\n",
            "Accuracy on batch 111 on Training id inf\n",
            "Accuracy on batch 112 on Training id inf\n",
            "Accuracy on batch 113 on Training id inf\n",
            "Accuracy on batch 114 on Training id inf\n",
            "Accuracy on batch 115 on Training id inf\n",
            "Accuracy on batch 116 on Training id inf\n",
            "Accuracy on batch 117 on Training id inf\n",
            "Accuracy on batch 118 on Training id inf\n",
            "Accuracy on batch 119 on Training id inf\n",
            "Accuracy on batch 120 on Training id inf\n",
            "Accuracy on batch 121 on Training id inf\n",
            "Accuracy on batch 122 on Training id inf\n",
            "Accuracy on batch 123 on Training id inf\n",
            "Accuracy on batch 124 on Training id inf\n",
            "Accuracy on batch 125 on Training id inf\n",
            "Accuracy on batch 126 on Training id inf\n",
            "Accuracy on batch 127 on Training id inf\n",
            "Accuracy on batch 128 on Training id inf\n",
            "Accuracy on batch 129 on Training id inf\n",
            "Accuracy on batch 130 on Training id inf\n",
            "Accuracy on batch 131 on Training id inf\n",
            "Accuracy on batch 132 on Training id inf\n",
            "Accuracy on batch 133 on Training id inf\n",
            "Accuracy on batch 134 on Training id inf\n",
            "Accuracy on batch 135 on Training id inf\n",
            "Accuracy on batch 136 on Training id inf\n",
            "Accuracy on batch 137 on Training id inf\n",
            "Accuracy on batch 138 on Training id inf\n",
            "Accuracy on batch 139 on Training id inf\n",
            "Accuracy on batch 140 on Training id inf\n",
            "Accuracy on batch 141 on Training id inf\n",
            "Accuracy on batch 142 on Training id inf\n",
            "Accuracy on batch 143 on Training id inf\n",
            "Accuracy on batch 144 on Training id inf\n",
            "Accuracy on batch 145 on Training id inf\n",
            "Accuracy on batch 146 on Training id inf\n",
            "Accuracy on batch 147 on Training id inf\n",
            "Accuracy on batch 148 on Training id inf\n",
            "Accuracy on batch 149 on Training id inf\n",
            "Training loss 0.00569140026345849\n",
            "0.8738690614700317\n",
            "Accuracy on batch 150 on Training id inf\n",
            "Accuracy on batch 151 on Training id inf\n",
            "Accuracy on batch 152 on Training id inf\n",
            "Accuracy on batch 153 on Training id inf\n",
            "Accuracy on batch 154 on Training id inf\n",
            "Accuracy on batch 155 on Training id inf\n",
            "Accuracy on batch 156 on Training id inf\n",
            "Accuracy on batch 157 on Training id inf\n",
            "Accuracy on batch 158 on Training id inf\n",
            "Accuracy on batch 159 on Training id inf\n",
            "Accuracy on batch 160 on Training id inf\n",
            "Accuracy on batch 161 on Training id inf\n",
            "Accuracy on batch 162 on Training id inf\n",
            "Accuracy on batch 163 on Training id inf\n",
            "Accuracy on batch 164 on Training id inf\n",
            "Accuracy on batch 165 on Training id inf\n",
            "Accuracy on batch 166 on Training id inf\n",
            "Accuracy on batch 167 on Training id inf\n",
            "Accuracy on batch 168 on Training id inf\n",
            "Accuracy on batch 169 on Training id inf\n",
            "Accuracy on batch 170 on Training id inf\n",
            "Accuracy on batch 171 on Training id inf\n",
            "Accuracy on batch 172 on Training id inf\n",
            "Accuracy on batch 173 on Training id inf\n",
            "Accuracy on batch 174 on Training id inf\n",
            "Accuracy on batch 175 on Training id inf\n",
            "Accuracy on batch 176 on Training id inf\n",
            "Accuracy on batch 177 on Training id inf\n",
            "Accuracy on batch 178 on Training id inf\n",
            "Accuracy on batch 179 on Training id inf\n",
            "Accuracy on batch 180 on Training id inf\n",
            "Accuracy on batch 181 on Training id inf\n",
            "Accuracy on batch 182 on Training id inf\n",
            "Accuracy on batch 183 on Training id inf\n",
            "Accuracy on batch 184 on Training id inf\n",
            "Accuracy on batch 185 on Training id inf\n",
            "Accuracy on batch 186 on Training id inf\n",
            "Accuracy on batch 187 on Training id inf\n",
            "Accuracy on batch 188 on Training id inf\n",
            "Accuracy on batch 189 on Training id inf\n",
            "Accuracy on batch 190 on Training id inf\n",
            "Accuracy on batch 191 on Training id inf\n",
            "Accuracy on batch 192 on Training id inf\n",
            "Accuracy on batch 193 on Training id inf\n",
            "Accuracy on batch 194 on Training id inf\n",
            "Accuracy on batch 195 on Training id inf\n",
            "Accuracy on batch 196 on Training id inf\n",
            "Accuracy on batch 197 on Training id inf\n",
            "Accuracy on batch 198 on Training id inf\n",
            "Accuracy on batch 199 on Training id inf\n",
            "Training loss 0.012630118057131767\n",
            "2.543773889541626\n",
            "Accuracy on batch 200 on Training id inf\n",
            "Accuracy on batch 201 on Training id inf\n",
            "Accuracy on batch 202 on Training id inf\n",
            "Accuracy on batch 203 on Training id inf\n",
            "Accuracy on batch 204 on Training id inf\n",
            "Accuracy on batch 205 on Training id inf\n",
            "Accuracy on batch 206 on Training id inf\n",
            "Accuracy on batch 207 on Training id inf\n",
            "Accuracy on batch 208 on Training id inf\n",
            "Accuracy on batch 209 on Training id inf\n",
            "Accuracy on batch 210 on Training id inf\n",
            "Accuracy on batch 211 on Training id inf\n",
            "Accuracy on batch 212 on Training id inf\n",
            "Accuracy on batch 213 on Training id inf\n",
            "Accuracy on batch 214 on Training id inf\n",
            "Accuracy on batch 215 on Training id inf\n",
            "Accuracy on batch 216 on Training id inf\n",
            "Accuracy on batch 217 on Training id inf\n",
            "Accuracy on batch 218 on Training id inf\n",
            "Accuracy on batch 219 on Training id inf\n",
            "Accuracy on batch 220 on Training id inf\n",
            "Accuracy on batch 221 on Training id inf\n",
            "Accuracy on batch 222 on Training id inf\n",
            "Accuracy on batch 223 on Training id inf\n",
            "Accuracy on batch 224 on Training id inf\n",
            "Accuracy on batch 225 on Training id inf\n",
            "Accuracy on batch 226 on Training id inf\n",
            "Accuracy on batch 227 on Training id inf\n",
            "Accuracy on batch 228 on Training id inf\n",
            "Accuracy on batch 229 on Training id inf\n",
            "Accuracy on batch 230 on Training id inf\n",
            "Accuracy on batch 231 on Training id inf\n",
            "Accuracy on batch 232 on Training id inf\n",
            "Accuracy on batch 233 on Training id inf\n",
            "Accuracy on batch 234 on Training id inf\n",
            "Accuracy on batch 235 on Training id inf\n",
            "Accuracy on batch 236 on Training id inf\n",
            "Accuracy on batch 237 on Training id inf\n",
            "Accuracy on batch 238 on Training id inf\n",
            "Accuracy on batch 239 on Training id inf\n",
            "Accuracy on batch 240 on Training id inf\n",
            "Accuracy on batch 241 on Training id inf\n",
            "Accuracy on batch 242 on Training id inf\n",
            "Accuracy on batch 243 on Training id inf\n",
            "Accuracy on batch 244 on Training id inf\n",
            "Accuracy on batch 245 on Training id inf\n",
            "Accuracy on batch 246 on Training id inf\n",
            "Accuracy on batch 247 on Training id inf\n",
            "Accuracy on batch 248 on Training id inf\n",
            "Accuracy on batch 249 on Training id inf\n",
            "Training loss 0.004709659144282341\n",
            "1.193122148513794\n",
            "Accuracy on batch 250 on Training id inf\n",
            "Accuracy on batch 251 on Training id inf\n",
            "Accuracy on batch 252 on Training id inf\n",
            "Accuracy on batch 253 on Training id inf\n",
            "Accuracy on batch 254 on Training id inf\n",
            "Accuracy on batch 255 on Training id inf\n",
            "Accuracy on batch 256 on Training id inf\n",
            "Accuracy on batch 257 on Training id inf\n",
            "Accuracy on batch 258 on Training id inf\n",
            "Accuracy on batch 259 on Training id inf\n",
            "Accuracy on batch 260 on Training id inf\n",
            "Accuracy on batch 261 on Training id inf\n",
            "Accuracy on batch 262 on Training id inf\n",
            "Accuracy on batch 263 on Training id inf\n",
            "Accuracy on batch 264 on Training id inf\n",
            "Accuracy on batch 265 on Training id inf\n",
            "Accuracy on batch 266 on Training id inf\n",
            "Accuracy on batch 267 on Training id inf\n",
            "Accuracy on batch 268 on Training id inf\n",
            "Accuracy on batch 269 on Training id inf\n",
            "Accuracy on batch 270 on Training id inf\n",
            "Accuracy on batch 271 on Training id inf\n",
            "Accuracy on batch 272 on Training id inf\n",
            "Accuracy on batch 273 on Training id inf\n",
            "Accuracy on batch 274 on Training id inf\n",
            "Accuracy on batch 275 on Training id inf\n",
            "Accuracy on batch 276 on Training id inf\n",
            "Accuracy on batch 277 on Training id inf\n",
            "Accuracy on batch 278 on Training id inf\n",
            "Accuracy on batch 279 on Training id inf\n",
            "Accuracy on batch 280 on Training id inf\n",
            "Accuracy on batch 281 on Training id inf\n",
            "Accuracy on batch 282 on Training id inf\n",
            "Accuracy on batch 283 on Training id inf\n",
            "Accuracy on batch 284 on Training id inf\n",
            "Accuracy on batch 285 on Training id inf\n",
            "Accuracy on batch 286 on Training id inf\n",
            "Accuracy on batch 287 on Training id inf\n",
            "Accuracy on batch 288 on Training id inf\n",
            "Accuracy on batch 289 on Training id inf\n",
            "Accuracy on batch 290 on Training id inf\n",
            "Эпоха #7 train_loss: 0.0, val_loss: 0\n",
            "Потрачено 0.4 минут на 7 эпоху\n",
            "Training loss 1.8586715459823608\n",
            "1.8586715459823608\n",
            "Accuracy on batch 0 on Training id inf\n",
            "Accuracy on batch 1 on Training id inf\n",
            "Accuracy on batch 2 on Training id inf\n",
            "Accuracy on batch 3 on Training id inf\n",
            "Accuracy on batch 4 on Training id inf\n",
            "Accuracy on batch 5 on Training id inf\n",
            "Accuracy on batch 6 on Training id inf\n",
            "Accuracy on batch 7 on Training id inf\n",
            "Accuracy on batch 8 on Training id inf\n",
            "Accuracy on batch 9 on Training id inf\n",
            "Accuracy on batch 10 on Training id inf\n",
            "Accuracy on batch 11 on Training id inf\n",
            "Accuracy on batch 12 on Training id inf\n",
            "Accuracy on batch 13 on Training id inf\n",
            "Accuracy on batch 14 on Training id inf\n",
            "Accuracy on batch 15 on Training id inf\n",
            "Accuracy on batch 16 on Training id inf\n",
            "Accuracy on batch 17 on Training id inf\n",
            "Accuracy on batch 18 on Training id inf\n",
            "Accuracy on batch 19 on Training id inf\n",
            "Accuracy on batch 20 on Training id inf\n",
            "Accuracy on batch 21 on Training id inf\n",
            "Accuracy on batch 22 on Training id inf\n",
            "Accuracy on batch 23 on Training id inf\n",
            "Accuracy on batch 24 on Training id inf\n",
            "Accuracy on batch 25 on Training id inf\n",
            "Accuracy on batch 26 on Training id inf\n",
            "Accuracy on batch 27 on Training id inf\n",
            "Accuracy on batch 28 on Training id inf\n",
            "Accuracy on batch 29 on Training id inf\n",
            "Accuracy on batch 30 on Training id inf\n",
            "Accuracy on batch 31 on Training id inf\n",
            "Accuracy on batch 32 on Training id inf\n",
            "Accuracy on batch 33 on Training id inf\n",
            "Accuracy on batch 34 on Training id inf\n",
            "Accuracy on batch 35 on Training id inf\n",
            "Accuracy on batch 36 on Training id inf\n",
            "Accuracy on batch 37 on Training id inf\n",
            "Accuracy on batch 38 on Training id inf\n",
            "Accuracy on batch 39 on Training id inf\n",
            "Accuracy on batch 40 on Training id inf\n",
            "Accuracy on batch 41 on Training id inf\n",
            "Accuracy on batch 42 on Training id inf\n",
            "Accuracy on batch 43 on Training id inf\n",
            "Accuracy on batch 44 on Training id inf\n",
            "Accuracy on batch 45 on Training id inf\n",
            "Accuracy on batch 46 on Training id inf\n",
            "Accuracy on batch 47 on Training id inf\n",
            "Accuracy on batch 48 on Training id inf\n",
            "Accuracy on batch 49 on Training id inf\n",
            "Training loss 0.04444100335240364\n",
            "2.2848970890045166\n",
            "Accuracy on batch 50 on Training id inf\n",
            "Accuracy on batch 51 on Training id inf\n",
            "Accuracy on batch 52 on Training id inf\n",
            "Accuracy on batch 53 on Training id inf\n",
            "Accuracy on batch 54 on Training id inf\n",
            "Accuracy on batch 55 on Training id inf\n",
            "Accuracy on batch 56 on Training id inf\n",
            "Accuracy on batch 57 on Training id inf\n",
            "Accuracy on batch 58 on Training id inf\n",
            "Accuracy on batch 59 on Training id inf\n",
            "Accuracy on batch 60 on Training id inf\n",
            "Accuracy on batch 61 on Training id inf\n",
            "Accuracy on batch 62 on Training id inf\n",
            "Accuracy on batch 63 on Training id inf\n",
            "Accuracy on batch 64 on Training id inf\n",
            "Accuracy on batch 65 on Training id inf\n",
            "Accuracy on batch 66 on Training id inf\n",
            "Accuracy on batch 67 on Training id inf\n",
            "Accuracy on batch 68 on Training id inf\n",
            "Accuracy on batch 69 on Training id inf\n",
            "Accuracy on batch 70 on Training id inf\n",
            "Accuracy on batch 71 on Training id inf\n",
            "Accuracy on batch 72 on Training id inf\n",
            "Accuracy on batch 73 on Training id inf\n",
            "Accuracy on batch 74 on Training id inf\n",
            "Accuracy on batch 75 on Training id inf\n",
            "Accuracy on batch 76 on Training id inf\n",
            "Accuracy on batch 77 on Training id inf\n",
            "Accuracy on batch 78 on Training id inf\n",
            "Accuracy on batch 79 on Training id inf\n",
            "Accuracy on batch 80 on Training id inf\n",
            "Accuracy on batch 81 on Training id inf\n",
            "Accuracy on batch 82 on Training id inf\n",
            "Accuracy on batch 83 on Training id inf\n",
            "Accuracy on batch 84 on Training id inf\n",
            "Accuracy on batch 85 on Training id inf\n",
            "Accuracy on batch 86 on Training id inf\n",
            "Accuracy on batch 87 on Training id inf\n",
            "Accuracy on batch 88 on Training id inf\n",
            "Accuracy on batch 89 on Training id inf\n",
            "Accuracy on batch 90 on Training id inf\n",
            "Accuracy on batch 91 on Training id inf\n",
            "Accuracy on batch 92 on Training id inf\n",
            "Accuracy on batch 93 on Training id inf\n",
            "Accuracy on batch 94 on Training id inf\n",
            "Accuracy on batch 95 on Training id inf\n",
            "Accuracy on batch 96 on Training id inf\n",
            "Accuracy on batch 97 on Training id inf\n",
            "Accuracy on batch 98 on Training id inf\n",
            "Accuracy on batch 99 on Training id inf\n",
            "Training loss 0.006456939969211817\n",
            "0.6653383374214172\n",
            "Accuracy on batch 100 on Training id inf\n",
            "Accuracy on batch 101 on Training id inf\n",
            "Accuracy on batch 102 on Training id inf\n",
            "Accuracy on batch 103 on Training id inf\n",
            "Accuracy on batch 104 on Training id inf\n",
            "Accuracy on batch 105 on Training id inf\n",
            "Accuracy on batch 106 on Training id inf\n",
            "Accuracy on batch 107 on Training id inf\n",
            "Accuracy on batch 108 on Training id inf\n",
            "Accuracy on batch 109 on Training id inf\n",
            "Accuracy on batch 110 on Training id inf\n",
            "Accuracy on batch 111 on Training id inf\n",
            "Accuracy on batch 112 on Training id inf\n",
            "Accuracy on batch 113 on Training id inf\n",
            "Accuracy on batch 114 on Training id inf\n",
            "Accuracy on batch 115 on Training id inf\n",
            "Accuracy on batch 116 on Training id inf\n",
            "Accuracy on batch 117 on Training id inf\n",
            "Accuracy on batch 118 on Training id inf\n",
            "Accuracy on batch 119 on Training id inf\n",
            "Accuracy on batch 120 on Training id inf\n",
            "Accuracy on batch 121 on Training id inf\n",
            "Accuracy on batch 122 on Training id inf\n",
            "Accuracy on batch 123 on Training id inf\n",
            "Accuracy on batch 124 on Training id inf\n",
            "Accuracy on batch 125 on Training id inf\n",
            "Accuracy on batch 126 on Training id inf\n",
            "Accuracy on batch 127 on Training id inf\n",
            "Accuracy on batch 128 on Training id inf\n",
            "Accuracy on batch 129 on Training id inf\n",
            "Accuracy on batch 130 on Training id inf\n",
            "Accuracy on batch 131 on Training id inf\n",
            "Accuracy on batch 132 on Training id inf\n",
            "Accuracy on batch 133 on Training id inf\n",
            "Accuracy on batch 134 on Training id inf\n",
            "Accuracy on batch 135 on Training id inf\n",
            "Accuracy on batch 136 on Training id inf\n",
            "Accuracy on batch 137 on Training id inf\n",
            "Accuracy on batch 138 on Training id inf\n",
            "Accuracy on batch 139 on Training id inf\n",
            "Accuracy on batch 140 on Training id inf\n",
            "Accuracy on batch 141 on Training id inf\n",
            "Accuracy on batch 142 on Training id inf\n",
            "Accuracy on batch 143 on Training id inf\n",
            "Accuracy on batch 144 on Training id inf\n",
            "Accuracy on batch 145 on Training id inf\n",
            "Accuracy on batch 146 on Training id inf\n",
            "Accuracy on batch 147 on Training id inf\n",
            "Accuracy on batch 148 on Training id inf\n",
            "Accuracy on batch 149 on Training id inf\n",
            "Training loss 0.012409873306751251\n",
            "1.880048155784607\n",
            "Accuracy on batch 150 on Training id inf\n",
            "Accuracy on batch 151 on Training id inf\n",
            "Accuracy on batch 152 on Training id inf\n",
            "Accuracy on batch 153 on Training id inf\n",
            "Accuracy on batch 154 on Training id inf\n",
            "Accuracy on batch 155 on Training id inf\n",
            "Accuracy on batch 156 on Training id inf\n",
            "Accuracy on batch 157 on Training id inf\n",
            "Accuracy on batch 158 on Training id inf\n",
            "Accuracy on batch 159 on Training id inf\n",
            "Accuracy on batch 160 on Training id inf\n",
            "Accuracy on batch 161 on Training id inf\n",
            "Accuracy on batch 162 on Training id inf\n",
            "Accuracy on batch 163 on Training id inf\n",
            "Accuracy on batch 164 on Training id inf\n",
            "Accuracy on batch 165 on Training id inf\n",
            "Accuracy on batch 166 on Training id inf\n",
            "Accuracy on batch 167 on Training id inf\n",
            "Accuracy on batch 168 on Training id inf\n",
            "Accuracy on batch 169 on Training id inf\n",
            "Accuracy on batch 170 on Training id inf\n",
            "Accuracy on batch 171 on Training id inf\n",
            "Accuracy on batch 172 on Training id inf\n",
            "Accuracy on batch 173 on Training id inf\n",
            "Accuracy on batch 174 on Training id inf\n",
            "Accuracy on batch 175 on Training id inf\n",
            "Accuracy on batch 176 on Training id inf\n",
            "Accuracy on batch 177 on Training id inf\n",
            "Accuracy on batch 178 on Training id inf\n",
            "Accuracy on batch 179 on Training id inf\n",
            "Accuracy on batch 180 on Training id inf\n",
            "Accuracy on batch 181 on Training id inf\n",
            "Accuracy on batch 182 on Training id inf\n",
            "Accuracy on batch 183 on Training id inf\n",
            "Accuracy on batch 184 on Training id inf\n",
            "Accuracy on batch 185 on Training id inf\n",
            "Accuracy on batch 186 on Training id inf\n",
            "Accuracy on batch 187 on Training id inf\n",
            "Accuracy on batch 188 on Training id inf\n",
            "Accuracy on batch 189 on Training id inf\n",
            "Accuracy on batch 190 on Training id inf\n",
            "Accuracy on batch 191 on Training id inf\n",
            "Accuracy on batch 192 on Training id inf\n",
            "Accuracy on batch 193 on Training id inf\n",
            "Accuracy on batch 194 on Training id inf\n",
            "Accuracy on batch 195 on Training id inf\n",
            "Accuracy on batch 196 on Training id inf\n",
            "Accuracy on batch 197 on Training id inf\n",
            "Accuracy on batch 198 on Training id inf\n",
            "Accuracy on batch 199 on Training id inf\n",
            "Training loss 0.006237288936972618\n",
            "1.2583240270614624\n",
            "Accuracy on batch 200 on Training id inf\n",
            "Accuracy on batch 201 on Training id inf\n",
            "Accuracy on batch 202 on Training id inf\n",
            "Accuracy on batch 203 on Training id inf\n",
            "Accuracy on batch 204 on Training id inf\n",
            "Accuracy on batch 205 on Training id inf\n",
            "Accuracy on batch 206 on Training id inf\n",
            "Accuracy on batch 207 on Training id inf\n",
            "Accuracy on batch 208 on Training id inf\n",
            "Accuracy on batch 209 on Training id inf\n",
            "Accuracy on batch 210 on Training id inf\n",
            "Accuracy on batch 211 on Training id inf\n",
            "Accuracy on batch 212 on Training id inf\n",
            "Accuracy on batch 213 on Training id inf\n",
            "Accuracy on batch 214 on Training id inf\n",
            "Accuracy on batch 215 on Training id inf\n",
            "Accuracy on batch 216 on Training id inf\n",
            "Accuracy on batch 217 on Training id inf\n",
            "Accuracy on batch 218 on Training id inf\n",
            "Accuracy on batch 219 on Training id inf\n",
            "Accuracy on batch 220 on Training id inf\n",
            "Accuracy on batch 221 on Training id inf\n",
            "Accuracy on batch 222 on Training id inf\n",
            "Accuracy on batch 223 on Training id inf\n",
            "Accuracy on batch 224 on Training id inf\n",
            "Accuracy on batch 225 on Training id inf\n",
            "Accuracy on batch 226 on Training id inf\n",
            "Accuracy on batch 227 on Training id inf\n",
            "Accuracy on batch 228 on Training id inf\n",
            "Accuracy on batch 229 on Training id inf\n",
            "Accuracy on batch 230 on Training id inf\n",
            "Accuracy on batch 231 on Training id inf\n",
            "Accuracy on batch 232 on Training id inf\n",
            "Accuracy on batch 233 on Training id inf\n",
            "Accuracy on batch 234 on Training id inf\n",
            "Accuracy on batch 235 on Training id inf\n",
            "Accuracy on batch 236 on Training id inf\n",
            "Accuracy on batch 237 on Training id inf\n",
            "Accuracy on batch 238 on Training id inf\n",
            "Accuracy on batch 239 on Training id inf\n",
            "Accuracy on batch 240 on Training id inf\n",
            "Accuracy on batch 241 on Training id inf\n",
            "Accuracy on batch 242 on Training id inf\n",
            "Accuracy on batch 243 on Training id inf\n",
            "Accuracy on batch 244 on Training id inf\n",
            "Accuracy on batch 245 on Training id inf\n",
            "Accuracy on batch 246 on Training id inf\n",
            "Accuracy on batch 247 on Training id inf\n",
            "Accuracy on batch 248 on Training id inf\n",
            "Accuracy on batch 249 on Training id inf\n",
            "Training loss 0.006289708893746138\n",
            "1.5825294256210327\n",
            "Accuracy on batch 250 on Training id inf\n",
            "Accuracy on batch 251 on Training id inf\n",
            "Accuracy on batch 252 on Training id inf\n",
            "Accuracy on batch 253 on Training id inf\n",
            "Accuracy on batch 254 on Training id inf\n",
            "Accuracy on batch 255 on Training id inf\n",
            "Accuracy on batch 256 on Training id inf\n",
            "Accuracy on batch 257 on Training id inf\n",
            "Accuracy on batch 258 on Training id inf\n",
            "Accuracy on batch 259 on Training id inf\n",
            "Accuracy on batch 260 on Training id inf\n",
            "Accuracy on batch 261 on Training id inf\n",
            "Accuracy on batch 262 on Training id inf\n",
            "Accuracy on batch 263 on Training id inf\n",
            "Accuracy on batch 264 on Training id inf\n",
            "Accuracy on batch 265 on Training id inf\n",
            "Accuracy on batch 266 on Training id inf\n",
            "Accuracy on batch 267 on Training id inf\n",
            "Accuracy on batch 268 on Training id inf\n",
            "Accuracy on batch 269 on Training id inf\n",
            "Accuracy on batch 270 on Training id inf\n",
            "Accuracy on batch 271 on Training id inf\n",
            "Accuracy on batch 272 on Training id inf\n",
            "Accuracy on batch 273 on Training id inf\n",
            "Accuracy on batch 274 on Training id inf\n",
            "Accuracy on batch 275 on Training id inf\n",
            "Accuracy on batch 276 on Training id inf\n",
            "Accuracy on batch 277 on Training id inf\n",
            "Accuracy on batch 278 on Training id inf\n",
            "Accuracy on batch 279 on Training id inf\n",
            "Accuracy on batch 280 on Training id inf\n",
            "Accuracy on batch 281 on Training id inf\n",
            "Accuracy on batch 282 on Training id inf\n",
            "Accuracy on batch 283 on Training id inf\n",
            "Accuracy on batch 284 on Training id inf\n",
            "Accuracy on batch 285 on Training id inf\n",
            "Accuracy on batch 286 on Training id inf\n",
            "Accuracy on batch 287 on Training id inf\n",
            "Accuracy on batch 288 on Training id inf\n",
            "Accuracy on batch 289 on Training id inf\n",
            "Accuracy on batch 290 on Training id inf\n",
            "Эпоха #8 train_loss: 0.0, val_loss: 0\n",
            "Потрачено 0.4 минут на 8 эпоху\n",
            "Training loss 1.1018872261047363\n",
            "1.1018872261047363\n",
            "Accuracy on batch 0 on Training id inf\n",
            "Accuracy on batch 1 on Training id inf\n",
            "Accuracy on batch 2 on Training id inf\n",
            "Accuracy on batch 3 on Training id inf\n",
            "Accuracy on batch 4 on Training id inf\n",
            "Accuracy on batch 5 on Training id inf\n",
            "Accuracy on batch 6 on Training id inf\n",
            "Accuracy on batch 7 on Training id inf\n",
            "Accuracy on batch 8 on Training id inf\n",
            "Accuracy on batch 9 on Training id inf\n",
            "Accuracy on batch 10 on Training id inf\n",
            "Accuracy on batch 11 on Training id inf\n",
            "Accuracy on batch 12 on Training id inf\n",
            "Accuracy on batch 13 on Training id inf\n",
            "Accuracy on batch 14 on Training id inf\n",
            "Accuracy on batch 15 on Training id inf\n",
            "Accuracy on batch 16 on Training id inf\n",
            "Accuracy on batch 17 on Training id inf\n",
            "Accuracy on batch 18 on Training id inf\n",
            "Accuracy on batch 19 on Training id inf\n",
            "Accuracy on batch 20 on Training id inf\n",
            "Accuracy on batch 21 on Training id inf\n",
            "Accuracy on batch 22 on Training id inf\n",
            "Accuracy on batch 23 on Training id inf\n",
            "Accuracy on batch 24 on Training id inf\n",
            "Accuracy on batch 25 on Training id inf\n",
            "Accuracy on batch 26 on Training id inf\n",
            "Accuracy on batch 27 on Training id inf\n",
            "Accuracy on batch 28 on Training id inf\n",
            "Accuracy on batch 29 on Training id inf\n",
            "Accuracy on batch 30 on Training id inf\n",
            "Accuracy on batch 31 on Training id inf\n",
            "Accuracy on batch 32 on Training id inf\n",
            "Accuracy on batch 33 on Training id inf\n",
            "Accuracy on batch 34 on Training id inf\n",
            "Accuracy on batch 35 on Training id inf\n",
            "Accuracy on batch 36 on Training id inf\n",
            "Accuracy on batch 37 on Training id inf\n",
            "Accuracy on batch 38 on Training id inf\n",
            "Accuracy on batch 39 on Training id inf\n",
            "Accuracy on batch 40 on Training id inf\n",
            "Accuracy on batch 41 on Training id inf\n",
            "Accuracy on batch 42 on Training id inf\n",
            "Accuracy on batch 43 on Training id inf\n",
            "Accuracy on batch 44 on Training id inf\n",
            "Accuracy on batch 45 on Training id inf\n",
            "Accuracy on batch 46 on Training id inf\n",
            "Accuracy on batch 47 on Training id inf\n",
            "Accuracy on batch 48 on Training id inf\n",
            "Accuracy on batch 49 on Training id inf\n",
            "Training loss 0.03145866096019745\n",
            "1.6163883209228516\n",
            "Accuracy on batch 50 on Training id inf\n",
            "Accuracy on batch 51 on Training id inf\n",
            "Accuracy on batch 52 on Training id inf\n",
            "Accuracy on batch 53 on Training id inf\n",
            "Accuracy on batch 54 on Training id inf\n",
            "Accuracy on batch 55 on Training id inf\n",
            "Accuracy on batch 56 on Training id inf\n",
            "Accuracy on batch 57 on Training id inf\n",
            "Accuracy on batch 58 on Training id inf\n",
            "Accuracy on batch 59 on Training id inf\n",
            "Accuracy on batch 60 on Training id inf\n",
            "Accuracy on batch 61 on Training id inf\n",
            "Accuracy on batch 62 on Training id inf\n",
            "Accuracy on batch 63 on Training id inf\n",
            "Accuracy on batch 64 on Training id inf\n",
            "Accuracy on batch 65 on Training id inf\n",
            "Accuracy on batch 66 on Training id inf\n",
            "Accuracy on batch 67 on Training id inf\n",
            "Accuracy on batch 68 on Training id inf\n",
            "Accuracy on batch 69 on Training id inf\n",
            "Accuracy on batch 70 on Training id inf\n",
            "Accuracy on batch 71 on Training id inf\n",
            "Accuracy on batch 72 on Training id inf\n",
            "Accuracy on batch 73 on Training id inf\n",
            "Accuracy on batch 74 on Training id inf\n",
            "Accuracy on batch 75 on Training id inf\n",
            "Accuracy on batch 76 on Training id inf\n",
            "Accuracy on batch 77 on Training id inf\n",
            "Accuracy on batch 78 on Training id inf\n",
            "Accuracy on batch 79 on Training id inf\n",
            "Accuracy on batch 80 on Training id inf\n",
            "Accuracy on batch 81 on Training id inf\n",
            "Accuracy on batch 82 on Training id inf\n",
            "Accuracy on batch 83 on Training id inf\n",
            "Accuracy on batch 84 on Training id inf\n",
            "Accuracy on batch 85 on Training id inf\n",
            "Accuracy on batch 86 on Training id inf\n",
            "Accuracy on batch 87 on Training id inf\n",
            "Accuracy on batch 88 on Training id inf\n",
            "Accuracy on batch 89 on Training id inf\n",
            "Accuracy on batch 90 on Training id inf\n",
            "Accuracy on batch 91 on Training id inf\n",
            "Accuracy on batch 92 on Training id inf\n",
            "Accuracy on batch 93 on Training id inf\n",
            "Accuracy on batch 94 on Training id inf\n",
            "Accuracy on batch 95 on Training id inf\n",
            "Accuracy on batch 96 on Training id inf\n",
            "Accuracy on batch 97 on Training id inf\n",
            "Accuracy on batch 98 on Training id inf\n",
            "Accuracy on batch 99 on Training id inf\n",
            "Training loss 0.0020270184613764286\n",
            "0.22064688801765442\n",
            "Accuracy on batch 100 on Training id inf\n",
            "Accuracy on batch 101 on Training id inf\n",
            "Accuracy on batch 102 on Training id inf\n",
            "Accuracy on batch 103 on Training id inf\n",
            "Accuracy on batch 104 on Training id inf\n",
            "Accuracy on batch 105 on Training id inf\n",
            "Accuracy on batch 106 on Training id inf\n",
            "Accuracy on batch 107 on Training id inf\n",
            "Accuracy on batch 108 on Training id inf\n",
            "Accuracy on batch 109 on Training id inf\n",
            "Accuracy on batch 110 on Training id inf\n",
            "Accuracy on batch 111 on Training id inf\n",
            "Accuracy on batch 112 on Training id inf\n",
            "Accuracy on batch 113 on Training id inf\n",
            "Accuracy on batch 114 on Training id inf\n",
            "Accuracy on batch 115 on Training id inf\n",
            "Accuracy on batch 116 on Training id inf\n",
            "Accuracy on batch 117 on Training id inf\n",
            "Accuracy on batch 118 on Training id inf\n",
            "Accuracy on batch 119 on Training id inf\n",
            "Accuracy on batch 120 on Training id inf\n",
            "Accuracy on batch 121 on Training id inf\n",
            "Accuracy on batch 122 on Training id inf\n",
            "Accuracy on batch 123 on Training id inf\n",
            "Accuracy on batch 124 on Training id inf\n",
            "Accuracy on batch 125 on Training id inf\n",
            "Accuracy on batch 126 on Training id inf\n",
            "Accuracy on batch 127 on Training id inf\n",
            "Accuracy on batch 128 on Training id inf\n",
            "Accuracy on batch 129 on Training id inf\n",
            "Accuracy on batch 130 on Training id inf\n",
            "Accuracy on batch 131 on Training id inf\n",
            "Accuracy on batch 132 on Training id inf\n",
            "Accuracy on batch 133 on Training id inf\n",
            "Accuracy on batch 134 on Training id inf\n",
            "Accuracy on batch 135 on Training id inf\n",
            "Accuracy on batch 136 on Training id inf\n",
            "Accuracy on batch 137 on Training id inf\n",
            "Accuracy on batch 138 on Training id inf\n",
            "Accuracy on batch 139 on Training id inf\n",
            "Accuracy on batch 140 on Training id inf\n",
            "Accuracy on batch 141 on Training id inf\n",
            "Accuracy on batch 142 on Training id inf\n",
            "Accuracy on batch 143 on Training id inf\n",
            "Accuracy on batch 144 on Training id inf\n",
            "Accuracy on batch 145 on Training id inf\n",
            "Accuracy on batch 146 on Training id inf\n",
            "Accuracy on batch 147 on Training id inf\n",
            "Accuracy on batch 148 on Training id inf\n",
            "Accuracy on batch 149 on Training id inf\n",
            "Training loss 0.00931810587644577\n",
            "1.4131956100463867\n",
            "Accuracy on batch 150 on Training id inf\n",
            "Accuracy on batch 151 on Training id inf\n",
            "Accuracy on batch 152 on Training id inf\n",
            "Accuracy on batch 153 on Training id inf\n",
            "Accuracy on batch 154 on Training id inf\n",
            "Accuracy on batch 155 on Training id inf\n",
            "Accuracy on batch 156 on Training id inf\n",
            "Accuracy on batch 157 on Training id inf\n",
            "Accuracy on batch 158 on Training id inf\n",
            "Accuracy on batch 159 on Training id inf\n",
            "Accuracy on batch 160 on Training id inf\n",
            "Accuracy on batch 161 on Training id inf\n",
            "Accuracy on batch 162 on Training id inf\n",
            "Accuracy on batch 163 on Training id inf\n",
            "Accuracy on batch 164 on Training id inf\n",
            "Accuracy on batch 165 on Training id inf\n",
            "Accuracy on batch 166 on Training id inf\n",
            "Accuracy on batch 167 on Training id inf\n",
            "Accuracy on batch 168 on Training id inf\n",
            "Accuracy on batch 169 on Training id inf\n",
            "Accuracy on batch 170 on Training id inf\n",
            "Accuracy on batch 171 on Training id inf\n",
            "Accuracy on batch 172 on Training id inf\n",
            "Accuracy on batch 173 on Training id inf\n",
            "Accuracy on batch 174 on Training id inf\n",
            "Accuracy on batch 175 on Training id inf\n",
            "Accuracy on batch 176 on Training id inf\n",
            "Accuracy on batch 177 on Training id inf\n",
            "Accuracy on batch 178 on Training id inf\n",
            "Accuracy on batch 179 on Training id inf\n",
            "Accuracy on batch 180 on Training id inf\n",
            "Accuracy on batch 181 on Training id inf\n",
            "Accuracy on batch 182 on Training id inf\n",
            "Accuracy on batch 183 on Training id inf\n",
            "Accuracy on batch 184 on Training id inf\n",
            "Accuracy on batch 185 on Training id inf\n",
            "Accuracy on batch 186 on Training id inf\n",
            "Accuracy on batch 187 on Training id inf\n",
            "Accuracy on batch 188 on Training id inf\n",
            "Accuracy on batch 189 on Training id inf\n",
            "Accuracy on batch 190 on Training id inf\n",
            "Accuracy on batch 191 on Training id inf\n",
            "Accuracy on batch 192 on Training id inf\n",
            "Accuracy on batch 193 on Training id inf\n",
            "Accuracy on batch 194 on Training id inf\n",
            "Accuracy on batch 195 on Training id inf\n",
            "Accuracy on batch 196 on Training id inf\n",
            "Accuracy on batch 197 on Training id inf\n",
            "Accuracy on batch 198 on Training id inf\n",
            "Accuracy on batch 199 on Training id inf\n",
            "Training loss 0.01791982725262642\n",
            "3.6073110103607178\n",
            "Accuracy on batch 200 on Training id inf\n",
            "Accuracy on batch 201 on Training id inf\n",
            "Accuracy on batch 202 on Training id inf\n",
            "Accuracy on batch 203 on Training id inf\n",
            "Accuracy on batch 204 on Training id inf\n",
            "Accuracy on batch 205 on Training id inf\n",
            "Accuracy on batch 206 on Training id inf\n",
            "Accuracy on batch 207 on Training id inf\n",
            "Accuracy on batch 208 on Training id inf\n",
            "Accuracy on batch 209 on Training id inf\n",
            "Accuracy on batch 210 on Training id inf\n",
            "Accuracy on batch 211 on Training id inf\n",
            "Accuracy on batch 212 on Training id inf\n",
            "Accuracy on batch 213 on Training id inf\n",
            "Accuracy on batch 214 on Training id inf\n",
            "Accuracy on batch 215 on Training id inf\n",
            "Accuracy on batch 216 on Training id inf\n",
            "Accuracy on batch 217 on Training id inf\n",
            "Accuracy on batch 218 on Training id inf\n",
            "Accuracy on batch 219 on Training id inf\n",
            "Accuracy on batch 220 on Training id inf\n",
            "Accuracy on batch 221 on Training id inf\n",
            "Accuracy on batch 222 on Training id inf\n",
            "Accuracy on batch 223 on Training id inf\n",
            "Accuracy on batch 224 on Training id inf\n",
            "Accuracy on batch 225 on Training id inf\n",
            "Accuracy on batch 226 on Training id inf\n",
            "Accuracy on batch 227 on Training id inf\n",
            "Accuracy on batch 228 on Training id inf\n",
            "Accuracy on batch 229 on Training id inf\n",
            "Accuracy on batch 230 on Training id inf\n",
            "Accuracy on batch 231 on Training id inf\n",
            "Accuracy on batch 232 on Training id inf\n",
            "Accuracy on batch 233 on Training id inf\n",
            "Accuracy on batch 234 on Training id inf\n",
            "Accuracy on batch 235 on Training id inf\n",
            "Accuracy on batch 236 on Training id inf\n",
            "Accuracy on batch 237 on Training id inf\n",
            "Accuracy on batch 238 on Training id inf\n",
            "Accuracy on batch 239 on Training id inf\n",
            "Accuracy on batch 240 on Training id inf\n",
            "Accuracy on batch 241 on Training id inf\n",
            "Accuracy on batch 242 on Training id inf\n",
            "Accuracy on batch 243 on Training id inf\n",
            "Accuracy on batch 244 on Training id inf\n",
            "Accuracy on batch 245 on Training id inf\n",
            "Accuracy on batch 246 on Training id inf\n",
            "Accuracy on batch 247 on Training id inf\n",
            "Accuracy on batch 248 on Training id inf\n",
            "Accuracy on batch 249 on Training id inf\n",
            "Training loss 0.0060570333153009415\n",
            "1.5228670835494995\n",
            "Accuracy on batch 250 on Training id inf\n",
            "Accuracy on batch 251 on Training id inf\n",
            "Accuracy on batch 252 on Training id inf\n",
            "Accuracy on batch 253 on Training id inf\n",
            "Accuracy on batch 254 on Training id inf\n",
            "Accuracy on batch 255 on Training id inf\n",
            "Accuracy on batch 256 on Training id inf\n",
            "Accuracy on batch 257 on Training id inf\n",
            "Accuracy on batch 258 on Training id inf\n",
            "Accuracy on batch 259 on Training id inf\n",
            "Accuracy on batch 260 on Training id inf\n",
            "Accuracy on batch 261 on Training id inf\n",
            "Accuracy on batch 262 on Training id inf\n",
            "Accuracy on batch 263 on Training id inf\n",
            "Accuracy on batch 264 on Training id inf\n",
            "Accuracy on batch 265 on Training id inf\n",
            "Accuracy on batch 266 on Training id inf\n",
            "Accuracy on batch 267 on Training id inf\n",
            "Accuracy on batch 268 on Training id inf\n",
            "Accuracy on batch 269 on Training id inf\n",
            "Accuracy on batch 270 on Training id inf\n",
            "Accuracy on batch 271 on Training id inf\n",
            "Accuracy on batch 272 on Training id inf\n",
            "Accuracy on batch 273 on Training id inf\n",
            "Accuracy on batch 274 on Training id inf\n",
            "Accuracy on batch 275 on Training id inf\n",
            "Accuracy on batch 276 on Training id inf\n",
            "Accuracy on batch 277 on Training id inf\n",
            "Accuracy on batch 278 on Training id inf\n",
            "Accuracy on batch 279 on Training id inf\n",
            "Accuracy on batch 280 on Training id inf\n",
            "Accuracy on batch 281 on Training id inf\n",
            "Accuracy on batch 282 on Training id inf\n",
            "Accuracy on batch 283 on Training id inf\n",
            "Accuracy on batch 284 on Training id inf\n",
            "Accuracy on batch 285 on Training id inf\n",
            "Accuracy on batch 286 on Training id inf\n",
            "Accuracy on batch 287 on Training id inf\n",
            "Accuracy on batch 288 on Training id inf\n",
            "Accuracy on batch 289 on Training id inf\n",
            "Accuracy on batch 290 on Training id inf\n",
            "Эпоха #9 train_loss: 0.0, val_loss: 0\n",
            "Потрачено 0.4 минут на 9 эпоху\n"
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "try:\n",
        "    for epoch in range(n_epochs):\n",
        "        start = time.time()\n",
        "        train_loss = train(train_data_loader, epoch)\n",
        "        #val_loss = val(val_data_loader, epoch)\n",
        "        val_loss = 0 # удалить потом\n",
        "        #lr_scheduler.step()\n",
        "        print(f\"Эпоха #{epoch} train_loss: {train_loss}, val_loss: {val_loss}\")  \n",
        "        end = time.time()\n",
        "        print(f\"Потрачено {round((end - start) / 60, 1)} минут на {epoch} эпоху\")\n",
        "        train_losses.append(train_loss)\n",
        "        #val_losses.append(val_loss)\n",
        "        '''torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "            'losses_train': train_losses,\n",
        "            'losses_val': val_losses\n",
        "            }, os.path.join(checkpoints_path, f'chkpt_{model_name}_{epoch}.pth'))\n",
        "    \n",
        "        torch.save(model, os.path.join(checkpoints_path, f'model_{model_name}_{epoch}.pth'))'''\n",
        "    \n",
        "except KeyboardInterrupt:\n",
        "    print('Прервано пользователем')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "A7iQ-nA4J28Z"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, epoch): \n",
        "    len_dataloader = len(train_dataloader)\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for i, data in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        images, targets = data[0], data[1]\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        loss_dict = model(images, targets)\n",
        "        loss = sum(loss for loss in loss_dict.values())\n",
        "        running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if i % 50 == 0:\n",
        "            print(f\"\\tЭпоха {epoch}. Итерация {i}/{len_dataloader}. Loss: {loss}\")\n",
        "    train_loss = running_loss/len(train_dataloader.dataset)\n",
        "    return train_loss\n",
        "\n",
        "def val(val_dataloader, epoch):\n",
        "    running_loss = 0\n",
        "    for data in val_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        images, targets = data[0], data[1]\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        with torch.no_grad():\n",
        "            loss_dict = model(images, targets)\n",
        "        loss_dict = model(images, targets)\n",
        "        loss = sum(loss for loss in loss_dict.values())\n",
        "        running_loss += loss.item()\n",
        "    val_loss = running_loss/len(val_dataloader.dataset)\n",
        "    return val_loss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uEkHoBJQtHIe"
      },
      "outputs": [],
      "source": [
        "last_epoch = 2\n",
        "# Загрузка весов модели\n",
        "checkpoint = torch.load(os.path.join(checkpoints_path, f'model_detector_resnet50_augmented_{last_epoch}.pth'), map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
        "#epoch = checkpoint['epoch']\n",
        "train_losses = checkpoint['losses_train']\n",
        "val_losses = checkpoint['losses_val']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c31bzq-4ykFc",
        "outputId": "182712f7-5273-41ae-9214-4311fde9f61b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([0.006822872471820277,\n",
              "  0.00596496530648258,\n",
              "  0.005799468892012618,\n",
              "  0.005696767864120071],\n",
              " [0.0056146160304546356,\n",
              "  0.005224747147411108,\n",
              "  0.005272344498336315,\n",
              "  0.005582686723768711])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint['losses_train'], checkpoint['losses_val']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK7V4WjRtHIe"
      },
      "outputs": [],
      "source": [
        "if last_epoch == None:\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "else:\n",
        "    # Загрузка весов модели\n",
        "    checkpoint = torch.load(os.path.join(checkpoints_path, f'chkpt_{model_name}_{last_epoch}.pth'), map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
        "    #epoch = checkpoint['epoch']\n",
        "    train_losses = checkpoint['losses_train']\n",
        "    val_losses = checkpoint['losses_val']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "r4ln2ar7t_dK"
      },
      "outputs": [],
      "source": [
        "last_epoch = 3\n",
        "model_name = 'detector_resnet50_augmented'\n",
        "\n",
        "\n",
        "if last_epoch == None:\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "else:\n",
        "    # Загрузка весов модели\n",
        "    checkpoint = torch.load(os.path.join(checkpoints_path, f'chkpt_{model_name}_{last_epoch}.pth'), map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
        "    #epoch = checkpoint['epoch']\n",
        "    train_losses = checkpoint['losses_train']\n",
        "    val_losses = checkpoint['losses_val']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KZUIkmvXGEGm"
      },
      "outputs": [],
      "source": [
        "model_name = 'detector_resnet50_augmented'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPWlmt4_J28a",
        "outputId": "cc17a6f9-1d38-4f4c-da5e-72d95b81de97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tЭпоха 4. Итерация 0/3387. Loss: 0.11603625863790512\n",
            "\tЭпоха 4. Итерация 50/3387. Loss: 0.09132763743400574\n",
            "\tЭпоха 4. Итерация 100/3387. Loss: 0.09525351226329803\n",
            "\tЭпоха 4. Итерация 150/3387. Loss: 0.08201088011264801\n",
            "\tЭпоха 4. Итерация 200/3387. Loss: 0.11788337677717209\n",
            "\tЭпоха 4. Итерация 250/3387. Loss: 0.09946923702955246\n",
            "\tЭпоха 4. Итерация 300/3387. Loss: 0.09350793063640594\n",
            "\tЭпоха 4. Итерация 350/3387. Loss: 0.09657343477010727\n",
            "\tЭпоха 4. Итерация 400/3387. Loss: 0.08998836576938629\n",
            "\tЭпоха 4. Итерация 450/3387. Loss: 0.08942896872758865\n",
            "\tЭпоха 4. Итерация 500/3387. Loss: 0.0664619505405426\n",
            "\tЭпоха 4. Итерация 550/3387. Loss: 0.08274924755096436\n",
            "\tЭпоха 4. Итерация 600/3387. Loss: 0.06323593109846115\n",
            "\tЭпоха 4. Итерация 650/3387. Loss: 0.07226131856441498\n",
            "\tЭпоха 4. Итерация 700/3387. Loss: 0.07295990735292435\n",
            "\tЭпоха 4. Итерация 750/3387. Loss: 0.06773833930492401\n",
            "\tЭпоха 4. Итерация 800/3387. Loss: 0.11777892708778381\n",
            "\tЭпоха 4. Итерация 850/3387. Loss: 0.09019037336111069\n",
            "\tЭпоха 4. Итерация 900/3387. Loss: 0.07822129130363464\n",
            "\tЭпоха 4. Итерация 950/3387. Loss: 0.06052594259381294\n",
            "\tЭпоха 4. Итерация 1000/3387. Loss: 0.07345942407846451\n",
            "\tЭпоха 4. Итерация 1050/3387. Loss: 0.07717742770910263\n",
            "\tЭпоха 4. Итерация 1100/3387. Loss: 0.06409034878015518\n",
            "\tЭпоха 4. Итерация 1150/3387. Loss: 0.09143809229135513\n",
            "\tЭпоха 4. Итерация 1200/3387. Loss: 0.07615028321743011\n",
            "\tЭпоха 4. Итерация 1250/3387. Loss: 0.09745550155639648\n",
            "\tЭпоха 4. Итерация 1300/3387. Loss: 0.09170036762952805\n",
            "\tЭпоха 4. Итерация 1350/3387. Loss: 0.06408890336751938\n",
            "\tЭпоха 4. Итерация 1400/3387. Loss: 0.10413724184036255\n",
            "\tЭпоха 4. Итерация 1450/3387. Loss: 0.08004828542470932\n",
            "\tЭпоха 4. Итерация 1500/3387. Loss: 0.08290593326091766\n",
            "\tЭпоха 4. Итерация 1550/3387. Loss: 0.07502719014883041\n",
            "\tЭпоха 4. Итерация 1600/3387. Loss: 0.08438242971897125\n",
            "\tЭпоха 4. Итерация 1650/3387. Loss: 0.05449351295828819\n",
            "\tЭпоха 4. Итерация 1700/3387. Loss: 0.14444123208522797\n",
            "\tЭпоха 4. Итерация 1750/3387. Loss: 0.08392274379730225\n",
            "\tЭпоха 4. Итерация 1800/3387. Loss: 0.11227336525917053\n",
            "\tЭпоха 4. Итерация 1850/3387. Loss: 0.06348342448472977\n",
            "\tЭпоха 4. Итерация 1900/3387. Loss: 0.09295957535505295\n",
            "\tЭпоха 4. Итерация 1950/3387. Loss: 0.07618264853954315\n",
            "\tЭпоха 4. Итерация 2000/3387. Loss: 0.06287781894207001\n",
            "\tЭпоха 4. Итерация 2050/3387. Loss: 0.10074707120656967\n",
            "\tЭпоха 4. Итерация 2100/3387. Loss: 0.09345182776451111\n",
            "\tЭпоха 4. Итерация 2150/3387. Loss: 0.09661507606506348\n",
            "\tЭпоха 4. Итерация 2200/3387. Loss: 0.07314032316207886\n",
            "\tЭпоха 4. Итерация 2250/3387. Loss: 0.07773245871067047\n",
            "\tЭпоха 4. Итерация 2300/3387. Loss: 0.07221110910177231\n",
            "\tЭпоха 4. Итерация 2350/3387. Loss: 0.09711426496505737\n",
            "\tЭпоха 4. Итерация 2400/3387. Loss: 0.07089707255363464\n",
            "\tЭпоха 4. Итерация 2450/3387. Loss: 0.10149577260017395\n",
            "\tЭпоха 4. Итерация 2500/3387. Loss: 0.09024722874164581\n",
            "\tЭпоха 4. Итерация 2550/3387. Loss: 0.08304310590028763\n",
            "\tЭпоха 4. Итерация 2600/3387. Loss: 0.13452155888080597\n",
            "\tЭпоха 4. Итерация 2650/3387. Loss: 0.06688462197780609\n",
            "\tЭпоха 4. Итерация 2700/3387. Loss: 0.0783919245004654\n",
            "\tЭпоха 4. Итерация 2750/3387. Loss: 0.09943044185638428\n",
            "\tЭпоха 4. Итерация 2800/3387. Loss: 0.09517356753349304\n",
            "\tЭпоха 4. Итерация 2850/3387. Loss: 0.08536633849143982\n",
            "\tЭпоха 4. Итерация 2900/3387. Loss: 0.056873586028814316\n",
            "\tЭпоха 4. Итерация 2950/3387. Loss: 0.07926899939775467\n",
            "\tЭпоха 4. Итерация 3000/3387. Loss: 0.10848496854305267\n",
            "\tЭпоха 4. Итерация 3050/3387. Loss: 0.0754411518573761\n",
            "\tЭпоха 4. Итерация 3100/3387. Loss: 0.08374585211277008\n",
            "\tЭпоха 4. Итерация 3150/3387. Loss: 0.09555276483297348\n",
            "\tЭпоха 4. Итерация 3200/3387. Loss: 0.07873371988534927\n",
            "\tЭпоха 4. Итерация 3250/3387. Loss: 0.14205558598041534\n",
            "\tЭпоха 4. Итерация 3300/3387. Loss: 0.07441110908985138\n",
            "\tЭпоха 4. Итерация 3350/3387. Loss: 0.07840423285961151\n",
            "Эпоха #4 train_loss: 0.005604889409316438, val_loss: 0.005126563803851605\n",
            "Потрачено 77.4 минут на 4 эпоху\n",
            "\tЭпоха 5. Итерация 0/3387. Loss: 0.11043357849121094\n",
            "\tЭпоха 5. Итерация 50/3387. Loss: 0.10003184527158737\n",
            "\tЭпоха 5. Итерация 100/3387. Loss: 0.08751209080219269\n",
            "\tЭпоха 5. Итерация 150/3387. Loss: 0.07736430317163467\n",
            "\tЭпоха 5. Итерация 200/3387. Loss: 0.10406886786222458\n",
            "\tЭпоха 5. Итерация 250/3387. Loss: 0.07873156666755676\n",
            "\tЭпоха 5. Итерация 300/3387. Loss: 0.09615469723939896\n",
            "\tЭпоха 5. Итерация 350/3387. Loss: 0.12829256057739258\n",
            "\tЭпоха 5. Итерация 400/3387. Loss: 0.0928274542093277\n",
            "\tЭпоха 5. Итерация 450/3387. Loss: 0.07026734948158264\n",
            "\tЭпоха 5. Итерация 500/3387. Loss: 0.0896499902009964\n",
            "\tЭпоха 5. Итерация 550/3387. Loss: 0.13303382694721222\n",
            "\tЭпоха 5. Итерация 600/3387. Loss: 0.07851165533065796\n",
            "\tЭпоха 5. Итерация 650/3387. Loss: 0.11531458050012589\n",
            "\tЭпоха 5. Итерация 700/3387. Loss: 0.07176968455314636\n",
            "\tЭпоха 5. Итерация 750/3387. Loss: 0.08690912276506424\n",
            "\tЭпоха 5. Итерация 800/3387. Loss: 0.07366175204515457\n",
            "\tЭпоха 5. Итерация 850/3387. Loss: 0.08483704924583435\n",
            "\tЭпоха 5. Итерация 900/3387. Loss: 0.0893249586224556\n",
            "\tЭпоха 5. Итерация 950/3387. Loss: 0.10252492874860764\n",
            "\tЭпоха 5. Итерация 1000/3387. Loss: 0.09391957521438599\n",
            "\tЭпоха 5. Итерация 1050/3387. Loss: 0.09872449934482574\n",
            "\tЭпоха 5. Итерация 1100/3387. Loss: 0.09894886612892151\n",
            "\tЭпоха 5. Итерация 1150/3387. Loss: 0.09085991978645325\n",
            "\tЭпоха 5. Итерация 1200/3387. Loss: 0.09614866226911545\n",
            "\tЭпоха 5. Итерация 1250/3387. Loss: 0.10549784451723099\n",
            "\tЭпоха 5. Итерация 1300/3387. Loss: 0.08832625299692154\n",
            "\tЭпоха 5. Итерация 1350/3387. Loss: 0.10099366307258606\n",
            "\tЭпоха 5. Итерация 1400/3387. Loss: 0.12304644286632538\n",
            "\tЭпоха 5. Итерация 1450/3387. Loss: 0.0771268755197525\n",
            "\tЭпоха 5. Итерация 1500/3387. Loss: 0.07430917769670486\n",
            "\tЭпоха 5. Итерация 1550/3387. Loss: 0.10674313455820084\n",
            "\tЭпоха 5. Итерация 1600/3387. Loss: 0.12111136317253113\n",
            "\tЭпоха 5. Итерация 1650/3387. Loss: 0.10397383570671082\n",
            "\tЭпоха 5. Итерация 1700/3387. Loss: 0.08170681446790695\n",
            "\tЭпоха 5. Итерация 1750/3387. Loss: 0.08216825872659683\n",
            "\tЭпоха 5. Итерация 1800/3387. Loss: 0.11820347607135773\n",
            "\tЭпоха 5. Итерация 1850/3387. Loss: 0.09545254707336426\n",
            "\tЭпоха 5. Итерация 1900/3387. Loss: 0.05972716957330704\n",
            "\tЭпоха 5. Итерация 1950/3387. Loss: 0.10126010328531265\n",
            "\tЭпоха 5. Итерация 2000/3387. Loss: 0.10328716039657593\n",
            "\tЭпоха 5. Итерация 2050/3387. Loss: 0.08272730559110641\n",
            "\tЭпоха 5. Итерация 2100/3387. Loss: 0.128114253282547\n",
            "\tЭпоха 5. Итерация 2150/3387. Loss: 0.08932490646839142\n",
            "\tЭпоха 5. Итерация 2200/3387. Loss: 0.10122840851545334\n",
            "\tЭпоха 5. Итерация 2250/3387. Loss: 0.11302843689918518\n",
            "\tЭпоха 5. Итерация 2300/3387. Loss: 0.06740493327379227\n",
            "\tЭпоха 5. Итерация 2350/3387. Loss: 0.0722433403134346\n",
            "\tЭпоха 5. Итерация 2400/3387. Loss: 0.08407176285982132\n",
            "\tЭпоха 5. Итерация 2450/3387. Loss: 0.07897794991731644\n",
            "\tЭпоха 5. Итерация 2500/3387. Loss: 0.07725340873003006\n",
            "\tЭпоха 5. Итерация 2550/3387. Loss: 0.0881546139717102\n",
            "\tЭпоха 5. Итерация 2600/3387. Loss: 0.06882338225841522\n",
            "\tЭпоха 5. Итерация 2650/3387. Loss: 0.07352511584758759\n",
            "\tЭпоха 5. Итерация 2700/3387. Loss: 0.08827140182256699\n",
            "\tЭпоха 5. Итерация 2750/3387. Loss: 0.06403612345457077\n",
            "\tЭпоха 5. Итерация 2800/3387. Loss: 0.07848846167325974\n",
            "\tЭпоха 5. Итерация 2850/3387. Loss: 0.07722825556993484\n",
            "\tЭпоха 5. Итерация 2900/3387. Loss: 0.0716768130660057\n",
            "\tЭпоха 5. Итерация 2950/3387. Loss: 0.0660458654165268\n",
            "\tЭпоха 5. Итерация 3000/3387. Loss: 0.0856732577085495\n",
            "\tЭпоха 5. Итерация 3050/3387. Loss: 0.08191581815481186\n",
            "\tЭпоха 5. Итерация 3100/3387. Loss: 0.08604485541582108\n",
            "\tЭпоха 5. Итерация 3150/3387. Loss: 0.08111005276441574\n",
            "\tЭпоха 5. Итерация 3200/3387. Loss: 0.08734871447086334\n",
            "\tЭпоха 5. Итерация 3250/3387. Loss: 0.0663626492023468\n",
            "\tЭпоха 5. Итерация 3300/3387. Loss: 0.08402350544929504\n",
            "\tЭпоха 5. Итерация 3350/3387. Loss: 0.07374858856201172\n",
            "Эпоха #5 train_loss: 0.0055833846000517134, val_loss: 0.005666033986210823\n",
            "Потрачено 77.7 минут на 5 эпоху\n",
            "\tЭпоха 6. Итерация 0/3387. Loss: 0.08567621558904648\n",
            "\tЭпоха 6. Итерация 50/3387. Loss: 0.12389116734266281\n",
            "\tЭпоха 6. Итерация 100/3387. Loss: 0.07015643268823624\n",
            "\tЭпоха 6. Итерация 150/3387. Loss: 0.0683545395731926\n",
            "\tЭпоха 6. Итерация 200/3387. Loss: 0.11463218927383423\n",
            "\tЭпоха 6. Итерация 250/3387. Loss: 0.09415289014577866\n",
            "\tЭпоха 6. Итерация 300/3387. Loss: 0.061202846467494965\n",
            "\tЭпоха 6. Итерация 350/3387. Loss: 0.11042959243059158\n",
            "\tЭпоха 6. Итерация 400/3387. Loss: 0.06912131607532501\n",
            "\tЭпоха 6. Итерация 450/3387. Loss: 0.09164624661207199\n",
            "\tЭпоха 6. Итерация 500/3387. Loss: 0.06414133310317993\n",
            "\tЭпоха 6. Итерация 550/3387. Loss: 0.08593379706144333\n",
            "\tЭпоха 6. Итерация 600/3387. Loss: 0.07069854438304901\n",
            "\tЭпоха 6. Итерация 650/3387. Loss: 0.07146618515253067\n",
            "\tЭпоха 6. Итерация 700/3387. Loss: 0.10772620141506195\n",
            "\tЭпоха 6. Итерация 750/3387. Loss: 0.07442203909158707\n",
            "\tЭпоха 6. Итерация 800/3387. Loss: 0.08928506076335907\n",
            "\tЭпоха 6. Итерация 850/3387. Loss: 0.08464695513248444\n",
            "\tЭпоха 6. Итерация 900/3387. Loss: 0.061752546578645706\n",
            "\tЭпоха 6. Итерация 950/3387. Loss: 0.06144189089536667\n",
            "\tЭпоха 6. Итерация 1000/3387. Loss: 0.07742565870285034\n",
            "\tЭпоха 6. Итерация 1050/3387. Loss: 0.10106947273015976\n",
            "\tЭпоха 6. Итерация 1100/3387. Loss: 0.09120506048202515\n",
            "\tЭпоха 6. Итерация 1150/3387. Loss: 0.08107585459947586\n",
            "\tЭпоха 6. Итерация 1200/3387. Loss: 0.09573089331388474\n",
            "\tЭпоха 6. Итерация 1250/3387. Loss: 0.0713609978556633\n",
            "\tЭпоха 6. Итерация 1300/3387. Loss: 0.09443525969982147\n",
            "\tЭпоха 6. Итерация 1350/3387. Loss: 0.0969569981098175\n",
            "\tЭпоха 6. Итерация 1400/3387. Loss: 0.08642382174730301\n",
            "\tЭпоха 6. Итерация 1450/3387. Loss: 0.06360834836959839\n",
            "\tЭпоха 6. Итерация 1500/3387. Loss: 0.08332508057355881\n",
            "\tЭпоха 6. Итерация 1550/3387. Loss: 0.09656171500682831\n",
            "\tЭпоха 6. Итерация 1600/3387. Loss: 0.06956389546394348\n",
            "\tЭпоха 6. Итерация 1650/3387. Loss: 0.08240890502929688\n",
            "\tЭпоха 6. Итерация 1700/3387. Loss: 0.07319962978363037\n",
            "\tЭпоха 6. Итерация 1750/3387. Loss: 0.0882166177034378\n",
            "\tЭпоха 6. Итерация 1800/3387. Loss: 0.0839359387755394\n",
            "\tЭпоха 6. Итерация 1850/3387. Loss: 0.07940192520618439\n",
            "\tЭпоха 6. Итерация 1900/3387. Loss: 0.10986340045928955\n",
            "\tЭпоха 6. Итерация 1950/3387. Loss: 0.08961669355630875\n",
            "\tЭпоха 6. Итерация 2000/3387. Loss: 0.09901341050863266\n",
            "\tЭпоха 6. Итерация 2050/3387. Loss: 0.08634732663631439\n",
            "\tЭпоха 6. Итерация 2100/3387. Loss: 0.07752593606710434\n",
            "\tЭпоха 6. Итерация 2150/3387. Loss: 0.08293741196393967\n",
            "\tЭпоха 6. Итерация 2200/3387. Loss: 0.0791519358754158\n",
            "\tЭпоха 6. Итерация 2250/3387. Loss: 0.08414807915687561\n",
            "\tЭпоха 6. Итерация 2300/3387. Loss: 0.08542382717132568\n",
            "\tЭпоха 6. Итерация 2350/3387. Loss: 0.13067369163036346\n",
            "\tЭпоха 6. Итерация 2400/3387. Loss: 0.0845036655664444\n",
            "\tЭпоха 6. Итерация 2450/3387. Loss: 0.09531064331531525\n",
            "\tЭпоха 6. Итерация 2500/3387. Loss: 0.08111739158630371\n",
            "\tЭпоха 6. Итерация 2550/3387. Loss: 0.10571761429309845\n",
            "\tЭпоха 6. Итерация 2600/3387. Loss: 0.07819857448339462\n",
            "\tЭпоха 6. Итерация 2650/3387. Loss: 0.09982295334339142\n",
            "\tЭпоха 6. Итерация 2700/3387. Loss: 0.06797226518392563\n",
            "\tЭпоха 6. Итерация 2750/3387. Loss: 0.08710420876741409\n",
            "\tЭпоха 6. Итерация 2800/3387. Loss: 0.07239101082086563\n",
            "\tЭпоха 6. Итерация 2850/3387. Loss: 0.07607673108577728\n",
            "\tЭпоха 6. Итерация 2900/3387. Loss: 0.06917265057563782\n",
            "\tЭпоха 6. Итерация 2950/3387. Loss: 0.09236875176429749\n",
            "\tЭпоха 6. Итерация 3000/3387. Loss: 0.0727715715765953\n",
            "\tЭпоха 6. Итерация 3050/3387. Loss: 0.1012926772236824\n",
            "\tЭпоха 6. Итерация 3100/3387. Loss: 0.09609273821115494\n",
            "\tЭпоха 6. Итерация 3150/3387. Loss: 0.0865151584148407\n",
            "\tЭпоха 6. Итерация 3200/3387. Loss: 0.06690851598978043\n",
            "\tЭпоха 6. Итерация 3250/3387. Loss: 0.12324976176023483\n",
            "\tЭпоха 6. Итерация 3300/3387. Loss: 0.06474371999502182\n",
            "\tЭпоха 6. Итерация 3350/3387. Loss: 0.0651879757642746\n",
            "Эпоха #6 train_loss: 0.005629228140847806, val_loss: 0.0051099161364138125\n",
            "Потрачено 76.5 минут на 6 эпоху\n",
            "\tЭпоха 7. Итерация 0/3387. Loss: 0.09844015538692474\n",
            "\tЭпоха 7. Итерация 50/3387. Loss: 0.07925985753536224\n",
            "\tЭпоха 7. Итерация 100/3387. Loss: 0.09219378232955933\n",
            "\tЭпоха 7. Итерация 150/3387. Loss: 0.1259264349937439\n",
            "\tЭпоха 7. Итерация 200/3387. Loss: 0.06174000725150108\n",
            "\tЭпоха 7. Итерация 250/3387. Loss: 0.09852565824985504\n",
            "\tЭпоха 7. Итерация 300/3387. Loss: 0.06544654816389084\n",
            "\tЭпоха 7. Итерация 350/3387. Loss: 0.09530916064977646\n",
            "\tЭпоха 7. Итерация 400/3387. Loss: 0.09381235390901566\n",
            "\tЭпоха 7. Итерация 450/3387. Loss: 0.081890769302845\n",
            "\tЭпоха 7. Итерация 500/3387. Loss: 0.10705902427434921\n",
            "\tЭпоха 7. Итерация 550/3387. Loss: 0.07691280543804169\n",
            "\tЭпоха 7. Итерация 600/3387. Loss: 0.060635048896074295\n",
            "\tЭпоха 7. Итерация 650/3387. Loss: 0.0852212905883789\n",
            "\tЭпоха 7. Итерация 700/3387. Loss: 0.08801119774580002\n",
            "\tЭпоха 7. Итерация 750/3387. Loss: 0.07398276031017303\n",
            "\tЭпоха 7. Итерация 800/3387. Loss: 0.10727456212043762\n",
            "\tЭпоха 7. Итерация 850/3387. Loss: 0.1101236641407013\n",
            "\tЭпоха 7. Итерация 900/3387. Loss: 0.1207384243607521\n",
            "\tЭпоха 7. Итерация 950/3387. Loss: 0.07752969115972519\n",
            "\tЭпоха 7. Итерация 1000/3387. Loss: 0.06361829489469528\n",
            "\tЭпоха 7. Итерация 1050/3387. Loss: 0.17871977388858795\n",
            "\tЭпоха 7. Итерация 1100/3387. Loss: 0.07063279300928116\n",
            "\tЭпоха 7. Итерация 1150/3387. Loss: 0.07743637263774872\n",
            "\tЭпоха 7. Итерация 1200/3387. Loss: 0.09267380833625793\n",
            "\tЭпоха 7. Итерация 1250/3387. Loss: 0.06952805072069168\n",
            "\tЭпоха 7. Итерация 1300/3387. Loss: 0.13022983074188232\n",
            "\tЭпоха 7. Итерация 1350/3387. Loss: 0.09407052397727966\n",
            "\tЭпоха 7. Итерация 1400/3387. Loss: 0.07649007439613342\n",
            "\tЭпоха 7. Итерация 1450/3387. Loss: 0.09874098747968674\n",
            "\tЭпоха 7. Итерация 1500/3387. Loss: 0.08737053722143173\n",
            "\tЭпоха 7. Итерация 1550/3387. Loss: 0.07311443239450455\n",
            "\tЭпоха 7. Итерация 1600/3387. Loss: 0.09881963580846786\n",
            "\tЭпоха 7. Итерация 1650/3387. Loss: 0.07810791581869125\n",
            "\tЭпоха 7. Итерация 1700/3387. Loss: 0.06885582953691483\n",
            "\tЭпоха 7. Итерация 1750/3387. Loss: 0.05761090666055679\n",
            "\tЭпоха 7. Итерация 1800/3387. Loss: 0.08999812602996826\n",
            "\tЭпоха 7. Итерация 1850/3387. Loss: 0.07258766889572144\n",
            "\tЭпоха 7. Итерация 1900/3387. Loss: 0.061876434832811356\n",
            "\tЭпоха 7. Итерация 1950/3387. Loss: 0.09285856783390045\n",
            "\tЭпоха 7. Итерация 2000/3387. Loss: 0.09522926807403564\n",
            "\tЭпоха 7. Итерация 2050/3387. Loss: 0.07785583287477493\n",
            "\tЭпоха 7. Итерация 2100/3387. Loss: 0.08957423269748688\n",
            "\tЭпоха 7. Итерация 2150/3387. Loss: 0.08262187242507935\n",
            "\tЭпоха 7. Итерация 2200/3387. Loss: 0.09134503453969955\n",
            "\tЭпоха 7. Итерация 2250/3387. Loss: 0.11807257682085037\n",
            "\tЭпоха 7. Итерация 2300/3387. Loss: 0.1337023675441742\n",
            "\tЭпоха 7. Итерация 2350/3387. Loss: 0.10483106970787048\n",
            "\tЭпоха 7. Итерация 2400/3387. Loss: 0.10585936903953552\n",
            "\tЭпоха 7. Итерация 2450/3387. Loss: 0.09723924845457077\n",
            "\tЭпоха 7. Итерация 2500/3387. Loss: 0.1218569278717041\n",
            "\tЭпоха 7. Итерация 2550/3387. Loss: 0.11955182999372482\n",
            "\tЭпоха 7. Итерация 2600/3387. Loss: 0.08451776951551437\n",
            "\tЭпоха 7. Итерация 2650/3387. Loss: 0.10231174528598785\n",
            "\tЭпоха 7. Итерация 2700/3387. Loss: 0.07867006957530975\n",
            "\tЭпоха 7. Итерация 2750/3387. Loss: 0.09719308465719223\n",
            "\tЭпоха 7. Итерация 2800/3387. Loss: 0.08802147209644318\n",
            "\tЭпоха 7. Итерация 2850/3387. Loss: 0.09597960859537125\n",
            "\tЭпоха 7. Итерация 2900/3387. Loss: 0.08316827565431595\n",
            "\tЭпоха 7. Итерация 2950/3387. Loss: 0.08619822561740875\n",
            "\tЭпоха 7. Итерация 3000/3387. Loss: 0.08860936760902405\n",
            "\tЭпоха 7. Итерация 3050/3387. Loss: 0.09869617968797684\n",
            "\tЭпоха 7. Итерация 3100/3387. Loss: 0.07909087836742401\n",
            "\tЭпоха 7. Итерация 3150/3387. Loss: 0.1348314732313156\n",
            "\tЭпоха 7. Итерация 3200/3387. Loss: 0.11446673423051834\n",
            "\tЭпоха 7. Итерация 3250/3387. Loss: 0.11177729070186615\n",
            "\tЭпоха 7. Итерация 3300/3387. Loss: 0.08022172749042511\n",
            "\tЭпоха 7. Итерация 3350/3387. Loss: 0.08702471852302551\n",
            "Эпоха #7 train_loss: 0.005547962800513081, val_loss: 0.005101670296490193\n",
            "Потрачено 78.3 минут на 7 эпоху\n",
            "\tЭпоха 8. Итерация 0/3387. Loss: 0.08133617788553238\n",
            "\tЭпоха 8. Итерация 50/3387. Loss: 0.0848928764462471\n",
            "\tЭпоха 8. Итерация 100/3387. Loss: 0.08345523476600647\n",
            "\tЭпоха 8. Итерация 150/3387. Loss: 0.09754069149494171\n",
            "\tЭпоха 8. Итерация 200/3387. Loss: 0.06776534020900726\n",
            "\tЭпоха 8. Итерация 250/3387. Loss: 0.07472396641969681\n",
            "\tЭпоха 8. Итерация 300/3387. Loss: 0.1090570017695427\n",
            "\tЭпоха 8. Итерация 350/3387. Loss: 0.11200587451457977\n",
            "\tЭпоха 8. Итерация 400/3387. Loss: 0.1005387231707573\n",
            "\tЭпоха 8. Итерация 450/3387. Loss: 0.07031060010194778\n",
            "\tЭпоха 8. Итерация 500/3387. Loss: 0.0901143029332161\n",
            "\tЭпоха 8. Итерация 550/3387. Loss: 0.09763544052839279\n",
            "\tЭпоха 8. Итерация 600/3387. Loss: 0.09191284328699112\n",
            "\tЭпоха 8. Итерация 650/3387. Loss: 0.10593290627002716\n",
            "\tЭпоха 8. Итерация 700/3387. Loss: 0.08102810382843018\n",
            "\tЭпоха 8. Итерация 750/3387. Loss: 0.1016358882188797\n",
            "\tЭпоха 8. Итерация 800/3387. Loss: 0.06611912697553635\n",
            "\tЭпоха 8. Итерация 850/3387. Loss: 0.07267773896455765\n",
            "\tЭпоха 8. Итерация 900/3387. Loss: 0.10687766224145889\n",
            "\tЭпоха 8. Итерация 950/3387. Loss: 0.09033676981925964\n",
            "\tЭпоха 8. Итерация 1000/3387. Loss: 0.0833202600479126\n",
            "\tЭпоха 8. Итерация 1050/3387. Loss: 0.12519477307796478\n",
            "\tЭпоха 8. Итерация 1100/3387. Loss: 0.08760024607181549\n",
            "\tЭпоха 8. Итерация 1150/3387. Loss: 0.08643431216478348\n",
            "\tЭпоха 8. Итерация 1200/3387. Loss: 0.07703791558742523\n",
            "\tЭпоха 8. Итерация 1250/3387. Loss: 0.08265695720911026\n",
            "\tЭпоха 8. Итерация 1300/3387. Loss: 0.09290611743927002\n",
            "\tЭпоха 8. Итерация 1350/3387. Loss: 0.09654511511325836\n",
            "\tЭпоха 8. Итерация 1400/3387. Loss: 0.11182679235935211\n",
            "\tЭпоха 8. Итерация 1450/3387. Loss: 0.10720915347337723\n",
            "\tЭпоха 8. Итерация 1500/3387. Loss: 0.07609868049621582\n",
            "\tЭпоха 8. Итерация 1550/3387. Loss: 0.11074618250131607\n",
            "\tЭпоха 8. Итерация 1600/3387. Loss: 0.07533090561628342\n",
            "\tЭпоха 8. Итерация 1650/3387. Loss: 0.0773683413863182\n",
            "\tЭпоха 8. Итерация 1700/3387. Loss: 0.07260306179523468\n",
            "\tЭпоха 8. Итерация 1750/3387. Loss: 0.10098008811473846\n",
            "\tЭпоха 8. Итерация 1800/3387. Loss: 0.07652341574430466\n",
            "\tЭпоха 8. Итерация 1850/3387. Loss: 0.10016510635614395\n",
            "\tЭпоха 8. Итерация 1900/3387. Loss: 0.09071463346481323\n",
            "\tЭпоха 8. Итерация 1950/3387. Loss: 0.12720254063606262\n",
            "\tЭпоха 8. Итерация 2000/3387. Loss: 0.07432261854410172\n",
            "\tЭпоха 8. Итерация 2050/3387. Loss: 0.0850788950920105\n",
            "\tЭпоха 8. Итерация 2100/3387. Loss: 0.07818034291267395\n",
            "\tЭпоха 8. Итерация 2150/3387. Loss: 0.1019202470779419\n",
            "\tЭпоха 8. Итерация 2200/3387. Loss: 0.07337435334920883\n",
            "\tЭпоха 8. Итерация 2250/3387. Loss: 0.11742212623357773\n",
            "\tЭпоха 8. Итерация 2300/3387. Loss: 0.10914626717567444\n",
            "\tЭпоха 8. Итерация 2350/3387. Loss: 0.09379075467586517\n",
            "\tЭпоха 8. Итерация 2400/3387. Loss: 0.11938084661960602\n",
            "\tЭпоха 8. Итерация 2450/3387. Loss: 0.09062882512807846\n",
            "\tЭпоха 8. Итерация 2500/3387. Loss: 0.07095489650964737\n",
            "\tЭпоха 8. Итерация 2550/3387. Loss: 0.0949590653181076\n",
            "\tЭпоха 8. Итерация 2600/3387. Loss: 0.11318124830722809\n",
            "\tЭпоха 8. Итерация 2650/3387. Loss: 0.08657974749803543\n",
            "\tЭпоха 8. Итерация 2700/3387. Loss: 0.11092869937419891\n",
            "\tЭпоха 8. Итерация 2750/3387. Loss: 0.10387169569730759\n",
            "\tЭпоха 8. Итерация 2800/3387. Loss: 0.11119237542152405\n",
            "\tЭпоха 8. Итерация 2850/3387. Loss: 0.11230441927909851\n",
            "\tЭпоха 8. Итерация 2900/3387. Loss: 0.09819179773330688\n",
            "\tЭпоха 8. Итерация 2950/3387. Loss: 0.07364877313375473\n",
            "\tЭпоха 8. Итерация 3000/3387. Loss: 0.10385376214981079\n",
            "\tЭпоха 8. Итерация 3050/3387. Loss: 0.06920980662107468\n",
            "\tЭпоха 8. Итерация 3100/3387. Loss: 0.09277177602052689\n",
            "\tЭпоха 8. Итерация 3150/3387. Loss: 0.10240308940410614\n",
            "\tЭпоха 8. Итерация 3200/3387. Loss: 0.0835493728518486\n",
            "\tЭпоха 8. Итерация 3250/3387. Loss: 0.07426190376281738\n",
            "\tЭпоха 8. Итерация 3300/3387. Loss: 0.06854217499494553\n",
            "\tЭпоха 8. Итерация 3350/3387. Loss: 0.08464068919420242\n",
            "Эпоха #8 train_loss: 0.00553514801933476, val_loss: 0.0051783937379717825\n",
            "Потрачено 77.5 минут на 8 эпоху\n",
            "\tЭпоха 9. Итерация 0/3387. Loss: 0.09199930727481842\n",
            "\tЭпоха 9. Итерация 50/3387. Loss: 0.09228729456663132\n",
            "\tЭпоха 9. Итерация 100/3387. Loss: 0.08712314069271088\n",
            "\tЭпоха 9. Итерация 150/3387. Loss: 0.08155935257673264\n",
            "\tЭпоха 9. Итерация 200/3387. Loss: 0.0642663761973381\n",
            "\tЭпоха 9. Итерация 250/3387. Loss: 0.09663046896457672\n",
            "\tЭпоха 9. Итерация 300/3387. Loss: 0.08410938084125519\n",
            "\tЭпоха 9. Итерация 350/3387. Loss: 0.07877297699451447\n",
            "\tЭпоха 9. Итерация 400/3387. Loss: 0.09594756364822388\n",
            "\tЭпоха 9. Итерация 450/3387. Loss: 0.06797294318675995\n",
            "\tЭпоха 9. Итерация 500/3387. Loss: 0.09131429344415665\n",
            "\tЭпоха 9. Итерация 550/3387. Loss: 0.06810283660888672\n",
            "\tЭпоха 9. Итерация 600/3387. Loss: 0.10819736868143082\n",
            "\tЭпоха 9. Итерация 650/3387. Loss: 0.07501061260700226\n",
            "\tЭпоха 9. Итерация 700/3387. Loss: 0.09427408874034882\n",
            "\tЭпоха 9. Итерация 750/3387. Loss: 0.06825724244117737\n",
            "\tЭпоха 9. Итерация 800/3387. Loss: 0.07218876481056213\n",
            "\tЭпоха 9. Итерация 850/3387. Loss: 0.08757037669420242\n",
            "\tЭпоха 9. Итерация 900/3387. Loss: 0.0704374611377716\n",
            "\tЭпоха 9. Итерация 950/3387. Loss: 0.06908915191888809\n",
            "\tЭпоха 9. Итерация 1000/3387. Loss: 0.06965930759906769\n",
            "\tЭпоха 9. Итерация 1050/3387. Loss: 0.06940215080976486\n",
            "\tЭпоха 9. Итерация 1100/3387. Loss: 0.08450539410114288\n",
            "\tЭпоха 9. Итерация 1150/3387. Loss: 0.09549173712730408\n",
            "\tЭпоха 9. Итерация 1200/3387. Loss: 0.07224994897842407\n",
            "\tЭпоха 9. Итерация 1250/3387. Loss: 0.055508315563201904\n",
            "\tЭпоха 9. Итерация 1300/3387. Loss: 0.08898742496967316\n",
            "\tЭпоха 9. Итерация 1350/3387. Loss: 0.05618787929415703\n",
            "\tЭпоха 9. Итерация 1400/3387. Loss: 0.068338543176651\n",
            "\tЭпоха 9. Итерация 1450/3387. Loss: 0.09358765929937363\n",
            "\tЭпоха 9. Итерация 1500/3387. Loss: 0.06952404230833054\n",
            "\tЭпоха 9. Итерация 1550/3387. Loss: 0.09347213804721832\n",
            "\tЭпоха 9. Итерация 1600/3387. Loss: 0.07136834412813187\n",
            "\tЭпоха 9. Итерация 1650/3387. Loss: 0.07647575438022614\n",
            "\tЭпоха 9. Итерация 1700/3387. Loss: 0.07017739117145538\n",
            "\tЭпоха 9. Итерация 1750/3387. Loss: 0.07162094861268997\n",
            "\tЭпоха 9. Итерация 1800/3387. Loss: 0.06462513655424118\n",
            "\tЭпоха 9. Итерация 1850/3387. Loss: 0.07077568769454956\n",
            "\tЭпоха 9. Итерация 1900/3387. Loss: 0.11966125667095184\n",
            "\tЭпоха 9. Итерация 1950/3387. Loss: 0.07059696316719055\n",
            "\tЭпоха 9. Итерация 2000/3387. Loss: 0.06352775543928146\n",
            "\tЭпоха 9. Итерация 2050/3387. Loss: 0.12054029107093811\n",
            "\tЭпоха 9. Итерация 2100/3387. Loss: 0.09983394294977188\n",
            "\tЭпоха 9. Итерация 2150/3387. Loss: 0.0814257562160492\n",
            "\tЭпоха 9. Итерация 2200/3387. Loss: 0.08067748695611954\n",
            "\tЭпоха 9. Итерация 2250/3387. Loss: 0.08222812414169312\n",
            "\tЭпоха 9. Итерация 2300/3387. Loss: 0.09961771965026855\n",
            "\tЭпоха 9. Итерация 2350/3387. Loss: 0.06904834508895874\n",
            "\tЭпоха 9. Итерация 2400/3387. Loss: 0.0685984268784523\n",
            "\tЭпоха 9. Итерация 2450/3387. Loss: 0.0958177000284195\n",
            "\tЭпоха 9. Итерация 2500/3387. Loss: 0.08879096060991287\n",
            "\tЭпоха 9. Итерация 2550/3387. Loss: 0.08143143355846405\n",
            "\tЭпоха 9. Итерация 2600/3387. Loss: 0.08976373821496964\n",
            "\tЭпоха 9. Итерация 2650/3387. Loss: 0.08961936086416245\n",
            "\tЭпоха 9. Итерация 2700/3387. Loss: 0.08130911737680435\n",
            "\tЭпоха 9. Итерация 2750/3387. Loss: 0.06520004570484161\n",
            "\tЭпоха 9. Итерация 2800/3387. Loss: 0.11921392381191254\n",
            "\tЭпоха 9. Итерация 2850/3387. Loss: 0.08132841438055038\n",
            "\tЭпоха 9. Итерация 2900/3387. Loss: 0.06266257911920547\n",
            "\tЭпоха 9. Итерация 2950/3387. Loss: 0.0874943733215332\n",
            "\tЭпоха 9. Итерация 3000/3387. Loss: 0.07738900184631348\n",
            "\tЭпоха 9. Итерация 3050/3387. Loss: 0.06370855867862701\n",
            "\tЭпоха 9. Итерация 3100/3387. Loss: 0.06914035230875015\n",
            "\tЭпоха 9. Итерация 3150/3387. Loss: 0.09203172475099564\n",
            "\tЭпоха 9. Итерация 3200/3387. Loss: 0.08349590748548508\n",
            "\tЭпоха 9. Итерация 3250/3387. Loss: 0.09178123623132706\n",
            "\tЭпоха 9. Итерация 3300/3387. Loss: 0.08104987442493439\n",
            "\tЭпоха 9. Итерация 3350/3387. Loss: 0.11209098249673843\n",
            "Эпоха #9 train_loss: 0.005502277377899647, val_loss: 0.005250982386618853\n",
            "Потрачено 77.2 минут на 9 эпоху\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    for epoch in range(last_epoch + 1, n_epochs):\n",
        "        start = time.time()\n",
        "        train_loss = train(train_data_loader, epoch)\n",
        "        val_loss = val(val_data_loader, epoch)\n",
        "        #lr_scheduler.step()\n",
        "        print(f\"Эпоха #{epoch} train_loss: {train_loss}, val_loss: {val_loss}\")  \n",
        "        end = time.time()\n",
        "        print(f\"Потрачено {round((end - start) / 60, 1)} минут на {epoch} эпоху\")\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "            'losses_train': train_losses,\n",
        "            'losses_val': val_losses\n",
        "            }, os.path.join(checkpoints_path, f'chkpt_{model_name}_{epoch}.pth'))\n",
        "    \n",
        "        torch.save(model, os.path.join(checkpoints_path, f'model_{model_name}_{epoch}.pth'))\n",
        "    \n",
        "except KeyboardInterrupt:\n",
        "    print('Прервано пользователем')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "M584PZv6tHIe"
      },
      "outputs": [],
      "source": [
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "            'losses_train': train_losses,\n",
        "            'losses_val': val_losses\n",
        "            }, os.path.join(checkpoints_path, f'chkpt_{model_name}_{epoch}.pth'))\n",
        "    \n",
        "torch.save(model, os.path.join(checkpoints_path, f'model_{model_name}_{epoch}.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5cjIjiCtHIe",
        "outputId": "d53ebc6c-5b52-4f52-d764-5a971c93f463"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'../checkpoints'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoints_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tORE5beOtHIe"
      },
      "outputs": [],
      "source": [
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "            'losses_train': train_losses,\n",
        "            'losses_val': val_losses\n",
        "            }, os.path.join(checkpoints_path, f'model_detector_resnet50_augmented_{epoch}.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cBAujDitHIf"
      },
      "outputs": [],
      "source": [
        "checkpoint2 = torch.load(os.path.join('checkpoints', f'model_detector_resnet50_augmented_2.pth'), map_location=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8aDrH5KtHIf"
      },
      "outputs": [],
      "source": [
        "checkpoint3 = torch.load(os.path.join('checkpoints', f'model_detector_resnet50_augmented_3.pth'), map_location=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEN2BXnStHIf",
        "outputId": "c266908e-04d3-492f-ad1a-ecd1639f5686"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.006822872471820277, 0.00596496530648258, 0.005799468892012618]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint2['losses_train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ISihzJ_tHIf",
        "outputId": "b9ec9ea7-7482-40b0-81a1-fb85d4997a10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.006822872471820277,\n",
              " 0.00596496530648258,\n",
              " 0.005799468892012618,\n",
              " 0.011846726517383244]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint3['losses_train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJDKIgmPtHIf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8cjVoDX8HWt",
        "outputId": "87932dc9-f2a3-4376-c369-fc1397a65293"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([0.014400107387186303], [0.010745501028001309])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_losses, val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24EVi0gp8HWt"
      },
      "outputs": [],
      "source": [
        "'''torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "    'losses_train': train_losses,\n",
        "    'losses_val': val_losses\n",
        "    }, os.path.join(dataset_path, f'../checkpoints/model_detector_resnet50_augmented_{epoch}.pth'))'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmcJUIyy8HWt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1pW07TQ8HWt"
      },
      "outputs": [],
      "source": [
        "def create_model(num_classes, pretrained=True):\n",
        "    model =torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(weights='FasterRCNN_MobileNet_V3_Large_FPN_Weights.DEFAULT')\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "be07765f19b946589dd0ed7cc58b5ce8"
          ]
        },
        "id": "2uGdiZ6O8HWu",
        "outputId": "7e3127c3-f904-4cbc-9bde-94c97ed84b62"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth\" to C:\\Users\\User/.cache\\torch\\hub\\checkpoints\\fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be07765f19b946589dd0ed7cc58b5ce8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/74.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = create_model(num_classes=2, pretrained=True).to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# parameters\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "#params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.0005)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "\n",
        "\n",
        "\n",
        "#optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "    # and a learning rate scheduler\n",
        "#lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "train_dataset = RTSD_dataset(os.path.join(dataset_path, 'train_anno_bin_class.json'),\n",
        "                                          dataset_path)\n",
        "val_dataset = RTSD_dataset(os.path.join(dataset_path, 'val_anno_bin_class.json'), dataset_path)\n",
        "\n",
        "train_data_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    #num_workers=4,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_data_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    #num_workers=4,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIr8FnYO8HWu"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, epoch): \n",
        "    len_dataloader = len(train_dataloader)\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for i, data in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        images, targets = data[0], data[1]\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        loss_dict = model(images, targets)\n",
        "        loss = sum(loss for loss in loss_dict.values())\n",
        "        running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if i % 50 == 0:\n",
        "            print(f\"\\tЭпоха {epoch}. Итерация {i}/{len_dataloader}. Loss: {loss}\")\n",
        "    train_loss = running_loss/len(train_dataloader.dataset)\n",
        "    return train_loss\n",
        "\n",
        "def val(val_dataloader, epoch):\n",
        "    running_loss = 0\n",
        "    for data in val_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        images, targets = data[0], data[1]\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        with torch.no_grad():\n",
        "            loss_dict = model(images, targets)\n",
        "        loss_dict = model(images, targets)\n",
        "        loss = sum(loss for loss in loss_dict.values())\n",
        "        running_loss += loss.item()\n",
        "    val_loss = running_loss/len(val_dataloader.dataset)\n",
        "    return val_loss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2cNTn4Z8HWu",
        "outputId": "253e1ef9-5822-46f3-cf17-9a5eaea597e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tЭпоха 0. Итерация 0/6774. Loss: 0.8358988165855408\n",
            "\tЭпоха 0. Итерация 50/6774. Loss: 0.09858530014753342\n",
            "\tЭпоха 0. Итерация 100/6774. Loss: 0.2172754555940628\n",
            "\tЭпоха 0. Итерация 150/6774. Loss: 0.40015822649002075\n",
            "\tЭпоха 0. Итерация 200/6774. Loss: 0.13395972549915314\n",
            "\tЭпоха 0. Итерация 250/6774. Loss: 0.28839361667633057\n",
            "\tЭпоха 0. Итерация 300/6774. Loss: 0.2116183489561081\n",
            "\tЭпоха 0. Итерация 350/6774. Loss: 0.2833598256111145\n",
            "\tЭпоха 0. Итерация 400/6774. Loss: 0.2793215811252594\n",
            "\tЭпоха 0. Итерация 450/6774. Loss: 0.309714674949646\n",
            "\tЭпоха 0. Итерация 500/6774. Loss: 0.20718857645988464\n",
            "\tЭпоха 0. Итерация 550/6774. Loss: 0.26163995265960693\n",
            "\tЭпоха 0. Итерация 600/6774. Loss: 0.35022008419036865\n",
            "\tЭпоха 0. Итерация 650/6774. Loss: 0.25102320313453674\n",
            "\tЭпоха 0. Итерация 700/6774. Loss: 0.36677470803260803\n",
            "\tЭпоха 0. Итерация 750/6774. Loss: 0.34893864393234253\n",
            "\tЭпоха 0. Итерация 800/6774. Loss: 0.32514622807502747\n",
            "\tЭпоха 0. Итерация 850/6774. Loss: 0.2878253161907196\n",
            "\tЭпоха 0. Итерация 900/6774. Loss: 0.3401532471179962\n",
            "\tЭпоха 0. Итерация 950/6774. Loss: 0.38222745060920715\n",
            "\tЭпоха 0. Итерация 1000/6774. Loss: 0.18317118287086487\n",
            "\tЭпоха 0. Итерация 1050/6774. Loss: 0.3864421844482422\n",
            "\tЭпоха 0. Итерация 1100/6774. Loss: 0.38182953000068665\n",
            "\tЭпоха 0. Итерация 1150/6774. Loss: 0.32848238945007324\n",
            "\tЭпоха 0. Итерация 1200/6774. Loss: 0.2292160838842392\n",
            "\tЭпоха 0. Итерация 1250/6774. Loss: 0.357188880443573\n",
            "\tЭпоха 0. Итерация 1300/6774. Loss: 0.30188116431236267\n",
            "\tЭпоха 0. Итерация 1350/6774. Loss: 0.2532297372817993\n",
            "\tЭпоха 0. Итерация 1400/6774. Loss: 0.29030346870422363\n",
            "\tЭпоха 0. Итерация 1450/6774. Loss: 0.35013389587402344\n",
            "\tЭпоха 0. Итерация 1500/6774. Loss: 0.36888572573661804\n",
            "\tЭпоха 0. Итерация 1550/6774. Loss: 0.2636238634586334\n",
            "\tЭпоха 0. Итерация 1600/6774. Loss: 0.4155515730381012\n",
            "\tЭпоха 0. Итерация 1650/6774. Loss: 0.4899461269378662\n",
            "\tЭпоха 0. Итерация 1700/6774. Loss: 0.3157951235771179\n",
            "\tЭпоха 0. Итерация 1750/6774. Loss: 0.3650500774383545\n",
            "\tЭпоха 0. Итерация 1800/6774. Loss: 0.27937963604927063\n",
            "\tЭпоха 0. Итерация 1850/6774. Loss: 0.30610644817352295\n",
            "\tЭпоха 0. Итерация 1900/6774. Loss: 0.2988344430923462\n",
            "\tЭпоха 0. Итерация 1950/6774. Loss: 0.28896868228912354\n",
            "\tЭпоха 0. Итерация 2000/6774. Loss: 0.30254513025283813\n",
            "\tЭпоха 0. Итерация 2050/6774. Loss: 0.2099846452474594\n",
            "\tЭпоха 0. Итерация 2100/6774. Loss: 0.42602673172950745\n",
            "\tЭпоха 0. Итерация 2150/6774. Loss: 0.2616986930370331\n",
            "\tЭпоха 0. Итерация 2200/6774. Loss: 0.2928885221481323\n",
            "\tЭпоха 0. Итерация 2250/6774. Loss: 0.2699390649795532\n",
            "\tЭпоха 0. Итерация 2300/6774. Loss: 0.3184402287006378\n",
            "\tЭпоха 0. Итерация 2350/6774. Loss: 0.33588075637817383\n",
            "\tЭпоха 0. Итерация 2400/6774. Loss: 0.30526188015937805\n",
            "\tЭпоха 0. Итерация 2450/6774. Loss: 0.1943347305059433\n",
            "\tЭпоха 0. Итерация 2500/6774. Loss: 0.37360596656799316\n",
            "\tЭпоха 0. Итерация 2550/6774. Loss: 0.35080838203430176\n",
            "\tЭпоха 0. Итерация 2600/6774. Loss: 0.33217939734458923\n",
            "\tЭпоха 0. Итерация 2650/6774. Loss: 0.3111608624458313\n",
            "\tЭпоха 0. Итерация 2700/6774. Loss: 0.3208328187465668\n",
            "\tЭпоха 0. Итерация 2750/6774. Loss: 0.24740852415561676\n",
            "\tЭпоха 0. Итерация 2800/6774. Loss: 0.34518757462501526\n",
            "\tЭпоха 0. Итерация 2850/6774. Loss: 0.2022755891084671\n",
            "\tЭпоха 0. Итерация 2900/6774. Loss: 0.4684189558029175\n",
            "\tЭпоха 0. Итерация 2950/6774. Loss: 0.32487520575523376\n",
            "\tЭпоха 0. Итерация 3000/6774. Loss: 0.24739661812782288\n",
            "\tЭпоха 0. Итерация 3050/6774. Loss: 0.3808477222919464\n",
            "\tЭпоха 0. Итерация 3100/6774. Loss: 0.27301111817359924\n",
            "\tЭпоха 0. Итерация 3150/6774. Loss: 0.3859260380268097\n",
            "\tЭпоха 0. Итерация 3200/6774. Loss: 0.5423765778541565\n",
            "\tЭпоха 0. Итерация 3250/6774. Loss: 0.3773883581161499\n",
            "\tЭпоха 0. Итерация 3300/6774. Loss: 0.41587671637535095\n",
            "\tЭпоха 0. Итерация 3350/6774. Loss: 0.34305375814437866\n",
            "\tЭпоха 0. Итерация 3400/6774. Loss: 0.6083003282546997\n",
            "\tЭпоха 0. Итерация 3450/6774. Loss: 0.3301055133342743\n",
            "\tЭпоха 0. Итерация 3500/6774. Loss: 0.31640180945396423\n",
            "\tЭпоха 0. Итерация 3550/6774. Loss: 0.3548625707626343\n",
            "\tЭпоха 0. Итерация 3600/6774. Loss: 0.3046359419822693\n",
            "\tЭпоха 0. Итерация 3650/6774. Loss: 0.33320552110671997\n",
            "\tЭпоха 0. Итерация 3700/6774. Loss: 0.4526026248931885\n",
            "\tЭпоха 0. Итерация 3750/6774. Loss: 0.34792885184288025\n",
            "\tЭпоха 0. Итерация 3800/6774. Loss: 0.38482552766799927\n",
            "\tЭпоха 0. Итерация 3850/6774. Loss: 0.35100823640823364\n",
            "\tЭпоха 0. Итерация 3900/6774. Loss: 0.23835380375385284\n",
            "\tЭпоха 0. Итерация 3950/6774. Loss: 0.41030141711235046\n",
            "\tЭпоха 0. Итерация 4000/6774. Loss: 0.2948543131351471\n",
            "\tЭпоха 0. Итерация 4050/6774. Loss: 0.2638646960258484\n",
            "\tЭпоха 0. Итерация 4100/6774. Loss: 0.41812703013420105\n",
            "\tЭпоха 0. Итерация 4150/6774. Loss: 0.5085234642028809\n",
            "\tЭпоха 0. Итерация 4200/6774. Loss: 0.2097371220588684\n",
            "\tЭпоха 0. Итерация 4250/6774. Loss: 0.26442912220954895\n",
            "\tЭпоха 0. Итерация 4300/6774. Loss: 0.24154822528362274\n",
            "\tЭпоха 0. Итерация 4350/6774. Loss: 0.4022882878780365\n",
            "\tЭпоха 0. Итерация 4400/6774. Loss: 0.4389779567718506\n",
            "\tЭпоха 0. Итерация 4450/6774. Loss: 0.348263680934906\n",
            "\tЭпоха 0. Итерация 4500/6774. Loss: 0.28931429982185364\n",
            "\tЭпоха 0. Итерация 4550/6774. Loss: 0.3102140426635742\n",
            "\tЭпоха 0. Итерация 4600/6774. Loss: 0.20012907683849335\n",
            "\tЭпоха 0. Итерация 4650/6774. Loss: 0.35621610283851624\n",
            "\tЭпоха 0. Итерация 4700/6774. Loss: 0.291753351688385\n",
            "\tЭпоха 0. Итерация 4750/6774. Loss: 0.24610646069049835\n",
            "\tЭпоха 0. Итерация 4800/6774. Loss: 0.45314761996269226\n",
            "\tЭпоха 0. Итерация 4850/6774. Loss: 0.2888239920139313\n",
            "\tЭпоха 0. Итерация 4900/6774. Loss: 0.2444274127483368\n",
            "\tЭпоха 0. Итерация 4950/6774. Loss: 0.2979982793331146\n",
            "\tЭпоха 0. Итерация 5000/6774. Loss: 0.5813078284263611\n",
            "\tЭпоха 0. Итерация 5050/6774. Loss: 0.3875882923603058\n",
            "\tЭпоха 0. Итерация 5100/6774. Loss: 0.3512566387653351\n",
            "\tЭпоха 0. Итерация 5150/6774. Loss: 0.32033571600914\n",
            "\tЭпоха 0. Итерация 5200/6774. Loss: 0.4603501558303833\n",
            "\tЭпоха 0. Итерация 5250/6774. Loss: 0.43615829944610596\n",
            "\tЭпоха 0. Итерация 5300/6774. Loss: 0.5474340915679932\n",
            "\tЭпоха 0. Итерация 5350/6774. Loss: 0.36110055446624756\n",
            "\tЭпоха 0. Итерация 5400/6774. Loss: 0.31166237592697144\n",
            "\tЭпоха 0. Итерация 5450/6774. Loss: 0.2825218737125397\n",
            "\tЭпоха 0. Итерация 5500/6774. Loss: 0.2806028425693512\n",
            "\tЭпоха 0. Итерация 5550/6774. Loss: 0.31587040424346924\n",
            "\tЭпоха 0. Итерация 5600/6774. Loss: 0.6018278002738953\n",
            "\tЭпоха 0. Итерация 5650/6774. Loss: 0.48541325330734253\n",
            "\tЭпоха 0. Итерация 5700/6774. Loss: 0.1741761565208435\n",
            "\tЭпоха 0. Итерация 5750/6774. Loss: 0.3061968684196472\n",
            "\tЭпоха 0. Итерация 5800/6774. Loss: 0.3103734850883484\n",
            "\tЭпоха 0. Итерация 5850/6774. Loss: 0.46791693568229675\n",
            "\tЭпоха 0. Итерация 5900/6774. Loss: 0.42280831933021545\n",
            "\tЭпоха 0. Итерация 5950/6774. Loss: 0.30640551447868347\n",
            "\tЭпоха 0. Итерация 6000/6774. Loss: 0.42255547642707825\n",
            "\tЭпоха 0. Итерация 6050/6774. Loss: 0.3898535966873169\n",
            "\tЭпоха 0. Итерация 6100/6774. Loss: 0.25518718361854553\n",
            "\tЭпоха 0. Итерация 6150/6774. Loss: 0.3671203553676605\n",
            "\tЭпоха 0. Итерация 6200/6774. Loss: 0.27329227328300476\n",
            "\tЭпоха 0. Итерация 6250/6774. Loss: 0.3945823013782501\n",
            "\tЭпоха 0. Итерация 6300/6774. Loss: 0.38400527834892273\n",
            "\tЭпоха 0. Итерация 6350/6774. Loss: 0.20627932250499725\n",
            "\tЭпоха 0. Итерация 6400/6774. Loss: 0.4845552444458008\n",
            "\tЭпоха 0. Итерация 6450/6774. Loss: 0.3458143174648285\n",
            "\tЭпоха 0. Итерация 6500/6774. Loss: 0.37972334027290344\n",
            "\tЭпоха 0. Итерация 6550/6774. Loss: 0.41420891880989075\n",
            "\tЭпоха 0. Итерация 6600/6774. Loss: 0.34638547897338867\n",
            "\tЭпоха 0. Итерация 6650/6774. Loss: 0.19860349595546722\n",
            "\tЭпоха 0. Итерация 6700/6774. Loss: 0.481199711561203\n",
            "\tЭпоха 0. Итерация 6750/6774. Loss: 0.491936594247818\n",
            "Эпоха #0 train_loss: 0.041939963174074606, val_loss: 0.04971962125450373\n",
            "Потрачено 51.4 минут на 0 эпоху\n",
            "\tЭпоха 1. Итерация 0/6774. Loss: 0.41819116473197937\n",
            "\tЭпоха 1. Итерация 50/6774. Loss: 0.35619866847991943\n",
            "\tЭпоха 1. Итерация 100/6774. Loss: 0.25738027691841125\n",
            "\tЭпоха 1. Итерация 150/6774. Loss: 0.3240741491317749\n",
            "\tЭпоха 1. Итерация 200/6774. Loss: 0.5980733036994934\n",
            "\tЭпоха 1. Итерация 250/6774. Loss: 0.4684480130672455\n",
            "\tЭпоха 1. Итерация 300/6774. Loss: 0.4259324371814728\n",
            "\tЭпоха 1. Итерация 350/6774. Loss: 0.3969480097293854\n",
            "\tЭпоха 1. Итерация 400/6774. Loss: 0.23790697753429413\n",
            "\tЭпоха 1. Итерация 450/6774. Loss: 0.41913461685180664\n",
            "\tЭпоха 1. Итерация 500/6774. Loss: 0.2675626873970032\n",
            "\tЭпоха 1. Итерация 550/6774. Loss: 0.39752694964408875\n",
            "\tЭпоха 1. Итерация 600/6774. Loss: 0.33315804600715637\n",
            "\tЭпоха 1. Итерация 650/6774. Loss: 0.37485313415527344\n",
            "\tЭпоха 1. Итерация 700/6774. Loss: 0.3911009728908539\n",
            "\tЭпоха 1. Итерация 750/6774. Loss: 0.2956126928329468\n",
            "\tЭпоха 1. Итерация 800/6774. Loss: 0.29083970189094543\n",
            "\tЭпоха 1. Итерация 850/6774. Loss: 0.3838546872138977\n",
            "\tЭпоха 1. Итерация 900/6774. Loss: 0.33601146936416626\n",
            "\tЭпоха 1. Итерация 950/6774. Loss: 0.42298623919487\n",
            "\tЭпоха 1. Итерация 1000/6774. Loss: 0.20946303009986877\n",
            "\tЭпоха 1. Итерация 1050/6774. Loss: 0.25266873836517334\n",
            "\tЭпоха 1. Итерация 1100/6774. Loss: 0.36946460604667664\n",
            "\tЭпоха 1. Итерация 1150/6774. Loss: 0.23496907949447632\n",
            "\tЭпоха 1. Итерация 1200/6774. Loss: 0.5798377394676208\n",
            "\tЭпоха 1. Итерация 1250/6774. Loss: 0.36844193935394287\n",
            "\tЭпоха 1. Итерация 1300/6774. Loss: 0.24761724472045898\n",
            "\tЭпоха 1. Итерация 1350/6774. Loss: 0.5298421382904053\n",
            "\tЭпоха 1. Итерация 1400/6774. Loss: 0.4400467276573181\n",
            "\tЭпоха 1. Итерация 1450/6774. Loss: 0.24246622622013092\n",
            "\tЭпоха 1. Итерация 1500/6774. Loss: 0.2236536145210266\n",
            "\tЭпоха 1. Итерация 1550/6774. Loss: 0.6530472040176392\n",
            "\tЭпоха 1. Итерация 1600/6774. Loss: 0.15169815719127655\n",
            "\tЭпоха 1. Итерация 1650/6774. Loss: 0.6787804365158081\n",
            "\tЭпоха 1. Итерация 1700/6774. Loss: 0.4169812798500061\n",
            "\tЭпоха 1. Итерация 1750/6774. Loss: 0.35499730706214905\n",
            "\tЭпоха 1. Итерация 1800/6774. Loss: 0.4295102059841156\n",
            "\tЭпоха 1. Итерация 1850/6774. Loss: 0.30775511264801025\n",
            "\tЭпоха 1. Итерация 1900/6774. Loss: 0.35965874791145325\n",
            "\tЭпоха 1. Итерация 1950/6774. Loss: 0.4489986300468445\n",
            "\tЭпоха 1. Итерация 2000/6774. Loss: 0.43344366550445557\n",
            "\tЭпоха 1. Итерация 2050/6774. Loss: 0.342428594827652\n",
            "\tЭпоха 1. Итерация 2100/6774. Loss: 0.3849497437477112\n",
            "\tЭпоха 1. Итерация 2150/6774. Loss: 0.2826206088066101\n",
            "\tЭпоха 1. Итерация 2200/6774. Loss: 0.3037051558494568\n",
            "\tЭпоха 1. Итерация 2250/6774. Loss: 0.35941824316978455\n",
            "\tЭпоха 1. Итерация 2300/6774. Loss: 0.25653213262557983\n",
            "\tЭпоха 1. Итерация 2350/6774. Loss: 0.24246865510940552\n",
            "\tЭпоха 1. Итерация 2400/6774. Loss: 0.4544875919818878\n",
            "\tЭпоха 1. Итерация 2450/6774. Loss: 0.3290853798389435\n",
            "\tЭпоха 1. Итерация 2500/6774. Loss: 0.3703569769859314\n",
            "\tЭпоха 1. Итерация 2550/6774. Loss: 0.3514910042285919\n",
            "\tЭпоха 1. Итерация 2600/6774. Loss: 0.28617215156555176\n",
            "\tЭпоха 1. Итерация 2650/6774. Loss: 0.235402911901474\n",
            "\tЭпоха 1. Итерация 2700/6774. Loss: 0.2665899693965912\n",
            "\tЭпоха 1. Итерация 2750/6774. Loss: 0.3864673674106598\n",
            "\tЭпоха 1. Итерация 2800/6774. Loss: 0.36783862113952637\n",
            "\tЭпоха 1. Итерация 2850/6774. Loss: 0.3622267246246338\n",
            "\tЭпоха 1. Итерация 2900/6774. Loss: 0.3390768766403198\n",
            "\tЭпоха 1. Итерация 2950/6774. Loss: 0.5326998829841614\n",
            "\tЭпоха 1. Итерация 3000/6774. Loss: 0.2347417175769806\n",
            "\tЭпоха 1. Итерация 3050/6774. Loss: 0.28418806195259094\n",
            "\tЭпоха 1. Итерация 3100/6774. Loss: 0.29809242486953735\n",
            "\tЭпоха 1. Итерация 3150/6774. Loss: 0.3055286705493927\n",
            "\tЭпоха 1. Итерация 3200/6774. Loss: 0.35438743233680725\n",
            "\tЭпоха 1. Итерация 3250/6774. Loss: 0.22692017257213593\n",
            "\tЭпоха 1. Итерация 3300/6774. Loss: 0.27565062046051025\n",
            "\tЭпоха 1. Итерация 3350/6774. Loss: 0.3885766267776489\n",
            "\tЭпоха 1. Итерация 3400/6774. Loss: 0.3618251383304596\n",
            "\tЭпоха 1. Итерация 3450/6774. Loss: 0.4212157726287842\n",
            "\tЭпоха 1. Итерация 3500/6774. Loss: 0.3020871579647064\n",
            "\tЭпоха 1. Итерация 3550/6774. Loss: 0.3398270308971405\n",
            "\tЭпоха 1. Итерация 3600/6774. Loss: 0.4610428810119629\n",
            "\tЭпоха 1. Итерация 3650/6774. Loss: 0.24168196320533752\n",
            "\tЭпоха 1. Итерация 3700/6774. Loss: 0.3224095404148102\n",
            "\tЭпоха 1. Итерация 3750/6774. Loss: 0.4177107512950897\n",
            "\tЭпоха 1. Итерация 3800/6774. Loss: 0.3488139510154724\n",
            "\tЭпоха 1. Итерация 3850/6774. Loss: 0.29283517599105835\n",
            "\tЭпоха 1. Итерация 3900/6774. Loss: 0.6431142687797546\n",
            "\tЭпоха 1. Итерация 3950/6774. Loss: 0.46962928771972656\n",
            "\tЭпоха 1. Итерация 4000/6774. Loss: 0.41944026947021484\n",
            "\tЭпоха 1. Итерация 4050/6774. Loss: 0.47633877396583557\n",
            "\tЭпоха 1. Итерация 4100/6774. Loss: 0.2212451547384262\n",
            "\tЭпоха 1. Итерация 4150/6774. Loss: 0.303644597530365\n",
            "\tЭпоха 1. Итерация 4200/6774. Loss: 0.3483940660953522\n",
            "\tЭпоха 1. Итерация 4250/6774. Loss: 0.32347041368484497\n",
            "\tЭпоха 1. Итерация 4300/6774. Loss: 0.509441614151001\n",
            "\tЭпоха 1. Итерация 4350/6774. Loss: 0.6056998372077942\n",
            "\tЭпоха 1. Итерация 4400/6774. Loss: 0.36725109815597534\n",
            "\tЭпоха 1. Итерация 4450/6774. Loss: 0.5444537997245789\n",
            "\tЭпоха 1. Итерация 4500/6774. Loss: 0.3195989727973938\n",
            "\tЭпоха 1. Итерация 4550/6774. Loss: 0.23488301038742065\n",
            "\tЭпоха 1. Итерация 4600/6774. Loss: 0.37782320380210876\n",
            "\tЭпоха 1. Итерация 4650/6774. Loss: 0.21875934302806854\n",
            "\tЭпоха 1. Итерация 4700/6774. Loss: 0.47045019268989563\n",
            "\tЭпоха 1. Итерация 4750/6774. Loss: 0.34184154868125916\n",
            "\tЭпоха 1. Итерация 4800/6774. Loss: 0.4102199077606201\n",
            "\tЭпоха 1. Итерация 4850/6774. Loss: 0.2346402257680893\n",
            "\tЭпоха 1. Итерация 4900/6774. Loss: 0.4911821484565735\n",
            "\tЭпоха 1. Итерация 4950/6774. Loss: 0.4445916414260864\n",
            "\tЭпоха 1. Итерация 5000/6774. Loss: 0.3917425274848938\n",
            "\tЭпоха 1. Итерация 5050/6774. Loss: 0.4292667508125305\n",
            "\tЭпоха 1. Итерация 5100/6774. Loss: 0.4430619180202484\n",
            "\tЭпоха 1. Итерация 5150/6774. Loss: 0.498257040977478\n",
            "\tЭпоха 1. Итерация 5200/6774. Loss: 0.3104202151298523\n",
            "\tЭпоха 1. Итерация 5250/6774. Loss: 0.5381891131401062\n",
            "\tЭпоха 1. Итерация 5300/6774. Loss: 0.3701520562171936\n",
            "\tЭпоха 1. Итерация 5350/6774. Loss: 0.3301345705986023\n",
            "\tЭпоха 1. Итерация 5400/6774. Loss: 0.363673597574234\n",
            "\tЭпоха 1. Итерация 5450/6774. Loss: 0.41580185294151306\n",
            "\tЭпоха 1. Итерация 5500/6774. Loss: 0.30989667773246765\n",
            "\tЭпоха 1. Итерация 5550/6774. Loss: 0.2724064290523529\n",
            "\tЭпоха 1. Итерация 5600/6774. Loss: 0.5211115479469299\n",
            "\tЭпоха 1. Итерация 5650/6774. Loss: 0.42866191267967224\n",
            "\tЭпоха 1. Итерация 5700/6774. Loss: 0.4435442388057709\n",
            "\tЭпоха 1. Итерация 5750/6774. Loss: 0.44266247749328613\n",
            "\tЭпоха 1. Итерация 5800/6774. Loss: 0.22385050356388092\n",
            "\tЭпоха 1. Итерация 5850/6774. Loss: 0.37382107973098755\n",
            "\tЭпоха 1. Итерация 5900/6774. Loss: 0.40789803862571716\n",
            "\tЭпоха 1. Итерация 5950/6774. Loss: 0.28010573983192444\n",
            "\tЭпоха 1. Итерация 6000/6774. Loss: 0.23171432316303253\n",
            "\tЭпоха 1. Итерация 6050/6774. Loss: 0.27011892199516296\n",
            "\tЭпоха 1. Итерация 6100/6774. Loss: 0.3276524841785431\n",
            "\tЭпоха 1. Итерация 6150/6774. Loss: 0.3281562328338623\n",
            "\tЭпоха 1. Итерация 6200/6774. Loss: 0.41261714696884155\n",
            "\tЭпоха 1. Итерация 6250/6774. Loss: 0.3872956335544586\n",
            "\tЭпоха 1. Итерация 6300/6774. Loss: 0.5138572454452515\n",
            "\tЭпоха 1. Итерация 6350/6774. Loss: 0.26330676674842834\n",
            "\tЭпоха 1. Итерация 6400/6774. Loss: 0.3324149549007416\n",
            "\tЭпоха 1. Итерация 6450/6774. Loss: 0.6742364168167114\n",
            "\tЭпоха 1. Итерация 6500/6774. Loss: 0.23300595581531525\n",
            "\tЭпоха 1. Итерация 6550/6774. Loss: 0.3239038288593292\n",
            "\tЭпоха 1. Итерация 6600/6774. Loss: 0.35350754857063293\n",
            "\tЭпоха 1. Итерация 6650/6774. Loss: 0.2974702715873718\n",
            "\tЭпоха 1. Итерация 6700/6774. Loss: 0.3229328989982605\n",
            "\tЭпоха 1. Итерация 6750/6774. Loss: 0.3328906297683716\n",
            "Эпоха #1 train_loss: 0.04659779232391055, val_loss: 0.054402772963047026\n",
            "Потрачено 48.8 минут на 1 эпоху\n",
            "\tЭпоха 2. Итерация 0/6774. Loss: 0.336588054895401\n",
            "\tЭпоха 2. Итерация 50/6774. Loss: 0.3330010175704956\n",
            "\tЭпоха 2. Итерация 100/6774. Loss: 0.5946797728538513\n",
            "\tЭпоха 2. Итерация 150/6774. Loss: 0.17851068079471588\n",
            "\tЭпоха 2. Итерация 200/6774. Loss: 0.34251269698143005\n",
            "\tЭпоха 2. Итерация 250/6774. Loss: 0.32756441831588745\n",
            "\tЭпоха 2. Итерация 300/6774. Loss: 0.41554316878318787\n",
            "\tЭпоха 2. Итерация 350/6774. Loss: 0.41835808753967285\n",
            "\tЭпоха 2. Итерация 400/6774. Loss: 0.20596261322498322\n",
            "\tЭпоха 2. Итерация 450/6774. Loss: 0.32385000586509705\n",
            "\tЭпоха 2. Итерация 500/6774. Loss: 0.3988465666770935\n",
            "\tЭпоха 2. Итерация 550/6774. Loss: 0.3398951590061188\n",
            "\tЭпоха 2. Итерация 600/6774. Loss: 0.2937109172344208\n",
            "\tЭпоха 2. Итерация 650/6774. Loss: 0.4359780251979828\n",
            "\tЭпоха 2. Итерация 700/6774. Loss: 0.41071727871894836\n",
            "\tЭпоха 2. Итерация 750/6774. Loss: 0.5380074977874756\n",
            "\tЭпоха 2. Итерация 800/6774. Loss: 0.48733973503112793\n",
            "\tЭпоха 2. Итерация 850/6774. Loss: 0.6064988970756531\n",
            "\tЭпоха 2. Итерация 900/6774. Loss: 0.4436124563217163\n",
            "\tЭпоха 2. Итерация 950/6774. Loss: 0.24103766679763794\n",
            "\tЭпоха 2. Итерация 1000/6774. Loss: 0.45375728607177734\n",
            "\tЭпоха 2. Итерация 1050/6774. Loss: 0.6554536819458008\n",
            "\tЭпоха 2. Итерация 1100/6774. Loss: 0.2831757068634033\n",
            "\tЭпоха 2. Итерация 1150/6774. Loss: 0.24177606403827667\n",
            "\tЭпоха 2. Итерация 1200/6774. Loss: 0.37173810601234436\n",
            "\tЭпоха 2. Итерация 1250/6774. Loss: 0.3961319029331207\n",
            "\tЭпоха 2. Итерация 1300/6774. Loss: 0.3727187216281891\n",
            "\tЭпоха 2. Итерация 1350/6774. Loss: 0.16123799979686737\n",
            "\tЭпоха 2. Итерация 1400/6774. Loss: 0.37507233023643494\n",
            "\tЭпоха 2. Итерация 1450/6774. Loss: 0.3982768952846527\n",
            "\tЭпоха 2. Итерация 1500/6774. Loss: 0.4386429488658905\n",
            "\tЭпоха 2. Итерация 1550/6774. Loss: 0.48092517256736755\n",
            "\tЭпоха 2. Итерация 1600/6774. Loss: 0.5660461783409119\n",
            "\tЭпоха 2. Итерация 1650/6774. Loss: 0.3510037958621979\n",
            "\tЭпоха 2. Итерация 1700/6774. Loss: 0.1432289034128189\n",
            "\tЭпоха 2. Итерация 1750/6774. Loss: 0.3895244598388672\n",
            "\tЭпоха 2. Итерация 1800/6774. Loss: 0.2809964120388031\n",
            "\tЭпоха 2. Итерация 1850/6774. Loss: 0.5549435019493103\n",
            "\tЭпоха 2. Итерация 1900/6774. Loss: 0.2604682147502899\n",
            "\tЭпоха 2. Итерация 1950/6774. Loss: 0.5850344896316528\n",
            "\tЭпоха 2. Итерация 2000/6774. Loss: 0.1953851878643036\n",
            "\tЭпоха 2. Итерация 2050/6774. Loss: 0.3426191806793213\n",
            "\tЭпоха 2. Итерация 2100/6774. Loss: 0.43685826659202576\n",
            "\tЭпоха 2. Итерация 2150/6774. Loss: 0.16496910154819489\n",
            "\tЭпоха 2. Итерация 2200/6774. Loss: 0.4110396206378937\n",
            "\tЭпоха 2. Итерация 2250/6774. Loss: 0.5875741243362427\n",
            "\tЭпоха 2. Итерация 2300/6774. Loss: 0.22160044312477112\n",
            "\tЭпоха 2. Итерация 2350/6774. Loss: 0.4129514992237091\n",
            "\tЭпоха 2. Итерация 2400/6774. Loss: 0.3616454303264618\n",
            "\tЭпоха 2. Итерация 2450/6774. Loss: 0.3547167479991913\n",
            "\tЭпоха 2. Итерация 2500/6774. Loss: 0.2614678740501404\n",
            "\tЭпоха 2. Итерация 2550/6774. Loss: 0.4659675061702728\n",
            "\tЭпоха 2. Итерация 2600/6774. Loss: 0.4972081780433655\n",
            "\tЭпоха 2. Итерация 2650/6774. Loss: 0.39271044731140137\n",
            "\tЭпоха 2. Итерация 2700/6774. Loss: 0.31445273756980896\n",
            "\tЭпоха 2. Итерация 2750/6774. Loss: 0.26584190130233765\n",
            "\tЭпоха 2. Итерация 2800/6774. Loss: 0.4953067898750305\n",
            "\tЭпоха 2. Итерация 2850/6774. Loss: 0.42261165380477905\n",
            "\tЭпоха 2. Итерация 2900/6774. Loss: 0.2327653467655182\n",
            "\tЭпоха 2. Итерация 2950/6774. Loss: 0.34685325622558594\n",
            "\tЭпоха 2. Итерация 3000/6774. Loss: 0.31393012404441833\n",
            "\tЭпоха 2. Итерация 3050/6774. Loss: 0.2860867977142334\n",
            "\tЭпоха 2. Итерация 3100/6774. Loss: 0.22650018334388733\n",
            "\tЭпоха 2. Итерация 3150/6774. Loss: 0.36363524198532104\n",
            "\tЭпоха 2. Итерация 3200/6774. Loss: 0.3760872483253479\n",
            "\tЭпоха 2. Итерация 3250/6774. Loss: 0.21308332681655884\n",
            "\tЭпоха 2. Итерация 3300/6774. Loss: 0.30173927545547485\n",
            "\tЭпоха 2. Итерация 3350/6774. Loss: 0.25429007411003113\n",
            "\tЭпоха 2. Итерация 3400/6774. Loss: 0.3555644750595093\n",
            "\tЭпоха 2. Итерация 3450/6774. Loss: 0.540815532207489\n",
            "\tЭпоха 2. Итерация 3500/6774. Loss: 0.21265669167041779\n",
            "\tЭпоха 2. Итерация 3550/6774. Loss: 0.3760349452495575\n",
            "\tЭпоха 2. Итерация 3600/6774. Loss: 0.48704880475997925\n",
            "\tЭпоха 2. Итерация 3650/6774. Loss: 0.4031670391559601\n",
            "\tЭпоха 2. Итерация 3700/6774. Loss: 0.24516525864601135\n",
            "\tЭпоха 2. Итерация 3750/6774. Loss: 0.41909900307655334\n",
            "\tЭпоха 2. Итерация 3800/6774. Loss: 0.4468613266944885\n",
            "\tЭпоха 2. Итерация 3850/6774. Loss: 0.4713948965072632\n",
            "\tЭпоха 2. Итерация 3900/6774. Loss: 0.38938501477241516\n",
            "\tЭпоха 2. Итерация 3950/6774. Loss: 0.39138278365135193\n",
            "\tЭпоха 2. Итерация 4000/6774. Loss: 0.24815011024475098\n",
            "\tЭпоха 2. Итерация 4050/6774. Loss: 0.42394131422042847\n",
            "\tЭпоха 2. Итерация 4100/6774. Loss: 0.35972893238067627\n",
            "\tЭпоха 2. Итерация 4150/6774. Loss: 0.3560599386692047\n",
            "\tЭпоха 2. Итерация 4200/6774. Loss: 0.3321000039577484\n",
            "\tЭпоха 2. Итерация 4250/6774. Loss: 0.31412002444267273\n",
            "\tЭпоха 2. Итерация 4300/6774. Loss: 0.26035434007644653\n",
            "\tЭпоха 2. Итерация 4350/6774. Loss: 0.4388516843318939\n",
            "\tЭпоха 2. Итерация 4400/6774. Loss: 0.4107847213745117\n",
            "\tЭпоха 2. Итерация 4450/6774. Loss: 0.3075743317604065\n",
            "\tЭпоха 2. Итерация 4500/6774. Loss: 0.48476162552833557\n",
            "\tЭпоха 2. Итерация 4550/6774. Loss: 0.38758885860443115\n",
            "\tЭпоха 2. Итерация 4600/6774. Loss: 0.3181326389312744\n",
            "\tЭпоха 2. Итерация 4650/6774. Loss: 0.21759918332099915\n",
            "\tЭпоха 2. Итерация 4700/6774. Loss: 0.2582862079143524\n",
            "\tЭпоха 2. Итерация 4750/6774. Loss: 0.3067563772201538\n",
            "\tЭпоха 2. Итерация 4800/6774. Loss: 0.24123616516590118\n",
            "\tЭпоха 2. Итерация 4850/6774. Loss: 0.2566227614879608\n",
            "\tЭпоха 2. Итерация 4900/6774. Loss: 0.2622562646865845\n",
            "\tЭпоха 2. Итерация 4950/6774. Loss: 0.36167559027671814\n",
            "\tЭпоха 2. Итерация 5000/6774. Loss: 0.27921831607818604\n",
            "\tЭпоха 2. Итерация 5050/6774. Loss: 0.26007336378097534\n",
            "\tЭпоха 2. Итерация 5100/6774. Loss: 0.27689558267593384\n",
            "\tЭпоха 2. Итерация 5150/6774. Loss: 0.3927775025367737\n",
            "\tЭпоха 2. Итерация 5200/6774. Loss: 0.3948075473308563\n",
            "\tЭпоха 2. Итерация 5250/6774. Loss: 0.2905776798725128\n",
            "\tЭпоха 2. Итерация 5300/6774. Loss: 0.2829306721687317\n",
            "\tЭпоха 2. Итерация 5350/6774. Loss: 0.3205646276473999\n",
            "\tЭпоха 2. Итерация 5400/6774. Loss: 0.22966161370277405\n",
            "\tЭпоха 2. Итерация 5450/6774. Loss: 0.2031169980764389\n",
            "\tЭпоха 2. Итерация 5500/6774. Loss: 0.33866503834724426\n",
            "\tЭпоха 2. Итерация 5550/6774. Loss: 0.20330485701560974\n",
            "\tЭпоха 2. Итерация 5600/6774. Loss: 0.3879810869693756\n",
            "\tЭпоха 2. Итерация 5650/6774. Loss: 0.3210204839706421\n",
            "\tЭпоха 2. Итерация 5700/6774. Loss: 0.2465163916349411\n",
            "\tЭпоха 2. Итерация 5750/6774. Loss: 0.4214897155761719\n",
            "\tЭпоха 2. Итерация 5800/6774. Loss: 0.40318062901496887\n",
            "\tЭпоха 2. Итерация 5850/6774. Loss: 0.21728472411632538\n",
            "\tЭпоха 2. Итерация 5900/6774. Loss: 0.2742270529270172\n",
            "\tЭпоха 2. Итерация 5950/6774. Loss: 0.3801407516002655\n",
            "\tЭпоха 2. Итерация 6000/6774. Loss: 0.3961808681488037\n",
            "\tЭпоха 2. Итерация 6050/6774. Loss: 0.2840469181537628\n",
            "\tЭпоха 2. Итерация 6100/6774. Loss: 0.31434494256973267\n",
            "\tЭпоха 2. Итерация 6150/6774. Loss: 0.32145193219184875\n",
            "\tЭпоха 2. Итерация 6200/6774. Loss: 0.34708043932914734\n",
            "\tЭпоха 2. Итерация 6250/6774. Loss: 0.28148433566093445\n",
            "\tЭпоха 2. Итерация 6300/6774. Loss: 0.31410348415374756\n",
            "\tЭпоха 2. Итерация 6350/6774. Loss: 0.2635899782180786\n",
            "\tЭпоха 2. Итерация 6400/6774. Loss: 0.32705065608024597\n",
            "\tЭпоха 2. Итерация 6450/6774. Loss: 0.3229910135269165\n",
            "\tЭпоха 2. Итерация 6500/6774. Loss: 0.32964104413986206\n",
            "\tЭпоха 2. Итерация 6550/6774. Loss: 0.39438924193382263\n",
            "\tЭпоха 2. Итерация 6600/6774. Loss: 0.28204861283302307\n",
            "\tЭпоха 2. Итерация 6650/6774. Loss: 0.2737219035625458\n",
            "\tЭпоха 2. Итерация 6700/6774. Loss: 0.3442721366882324\n",
            "\tЭпоха 2. Итерация 6750/6774. Loss: 0.3330710530281067\n",
            "Эпоха #2 train_loss: 0.046035758322024375, val_loss: 0.056045305943489075\n",
            "Потрачено 49.0 минут на 2 эпоху\n",
            "\tЭпоха 3. Итерация 0/6774. Loss: 0.26013219356536865\n",
            "\tЭпоха 3. Итерация 50/6774. Loss: 0.2921954393386841\n",
            "\tЭпоха 3. Итерация 100/6774. Loss: 0.3363632261753082\n",
            "\tЭпоха 3. Итерация 150/6774. Loss: 0.32091623544692993\n",
            "\tЭпоха 3. Итерация 200/6774. Loss: 0.442366361618042\n",
            "\tЭпоха 3. Итерация 250/6774. Loss: 0.41991063952445984\n",
            "\tЭпоха 3. Итерация 300/6774. Loss: 0.45122766494750977\n",
            "\tЭпоха 3. Итерация 350/6774. Loss: 0.24042728543281555\n",
            "\tЭпоха 3. Итерация 400/6774. Loss: 0.4546917676925659\n",
            "\tЭпоха 3. Итерация 450/6774. Loss: 0.5091292858123779\n",
            "\tЭпоха 3. Итерация 500/6774. Loss: 0.259773313999176\n",
            "\tЭпоха 3. Итерация 550/6774. Loss: 0.33531010150909424\n",
            "\tЭпоха 3. Итерация 600/6774. Loss: 0.5151806473731995\n",
            "\tЭпоха 3. Итерация 650/6774. Loss: 0.2536592483520508\n",
            "\tЭпоха 3. Итерация 700/6774. Loss: 0.3358435034751892\n",
            "\tЭпоха 3. Итерация 750/6774. Loss: 0.35887816548347473\n",
            "\tЭпоха 3. Итерация 800/6774. Loss: 0.3093236982822418\n",
            "\tЭпоха 3. Итерация 850/6774. Loss: 0.4216674268245697\n",
            "\tЭпоха 3. Итерация 900/6774. Loss: 0.3329043388366699\n",
            "\tЭпоха 3. Итерация 950/6774. Loss: 0.23510444164276123\n",
            "\tЭпоха 3. Итерация 1000/6774. Loss: 0.2687258720397949\n",
            "\tЭпоха 3. Итерация 1050/6774. Loss: 0.39611613750457764\n",
            "\tЭпоха 3. Итерация 1100/6774. Loss: 0.259937047958374\n",
            "\tЭпоха 3. Итерация 1150/6774. Loss: 0.4489871561527252\n",
            "\tЭпоха 3. Итерация 1200/6774. Loss: 0.3329002857208252\n",
            "\tЭпоха 3. Итерация 1250/6774. Loss: 0.3072521686553955\n",
            "\tЭпоха 3. Итерация 1300/6774. Loss: 0.3512943983078003\n",
            "\tЭпоха 3. Итерация 1350/6774. Loss: 0.49363771080970764\n",
            "\tЭпоха 3. Итерация 1400/6774. Loss: 0.1956986039876938\n",
            "\tЭпоха 3. Итерация 1450/6774. Loss: 0.3655320107936859\n",
            "\tЭпоха 3. Итерация 1500/6774. Loss: 0.24633002281188965\n",
            "\tЭпоха 3. Итерация 1550/6774. Loss: 0.41871026158332825\n",
            "\tЭпоха 3. Итерация 1600/6774. Loss: 0.3817703127861023\n",
            "\tЭпоха 3. Итерация 1650/6774. Loss: 0.38074561953544617\n",
            "\tЭпоха 3. Итерация 1700/6774. Loss: 0.3349577784538269\n",
            "\tЭпоха 3. Итерация 1750/6774. Loss: 0.5713488459587097\n",
            "\tЭпоха 3. Итерация 1800/6774. Loss: 0.3159545361995697\n",
            "\tЭпоха 3. Итерация 1850/6774. Loss: 0.5425722599029541\n",
            "\tЭпоха 3. Итерация 1900/6774. Loss: 0.7488095760345459\n",
            "\tЭпоха 3. Итерация 1950/6774. Loss: 0.15683482587337494\n",
            "\tЭпоха 3. Итерация 2000/6774. Loss: 0.5029070973396301\n",
            "\tЭпоха 3. Итерация 2050/6774. Loss: 0.3272288143634796\n",
            "\tЭпоха 3. Итерация 2100/6774. Loss: 0.22893033921718597\n",
            "\tЭпоха 3. Итерация 2150/6774. Loss: 0.36053285002708435\n",
            "\tЭпоха 3. Итерация 2200/6774. Loss: 0.3038906455039978\n",
            "\tЭпоха 3. Итерация 2250/6774. Loss: 0.3064747750759125\n",
            "\tЭпоха 3. Итерация 2300/6774. Loss: 0.18578030169010162\n",
            "\tЭпоха 3. Итерация 2350/6774. Loss: 0.33937692642211914\n",
            "\tЭпоха 3. Итерация 2400/6774. Loss: 0.37697872519493103\n",
            "\tЭпоха 3. Итерация 2450/6774. Loss: 0.3261823058128357\n",
            "\tЭпоха 3. Итерация 2500/6774. Loss: 0.21585167944431305\n",
            "\tЭпоха 3. Итерация 2550/6774. Loss: 0.3302173614501953\n",
            "\tЭпоха 3. Итерация 2600/6774. Loss: 0.5426003932952881\n",
            "\tЭпоха 3. Итерация 2650/6774. Loss: 0.5118193626403809\n",
            "\tЭпоха 3. Итерация 2700/6774. Loss: 0.5426220297813416\n",
            "\tЭпоха 3. Итерация 2750/6774. Loss: 0.3890902101993561\n",
            "\tЭпоха 3. Итерация 2800/6774. Loss: 0.36140772700309753\n",
            "\tЭпоха 3. Итерация 2850/6774. Loss: 0.3281515836715698\n",
            "\tЭпоха 3. Итерация 2900/6774. Loss: 0.30975309014320374\n",
            "\tЭпоха 3. Итерация 2950/6774. Loss: 0.283447265625\n",
            "\tЭпоха 3. Итерация 3000/6774. Loss: 0.40519067645072937\n",
            "\tЭпоха 3. Итерация 3050/6774. Loss: 0.29493218660354614\n",
            "\tЭпоха 3. Итерация 3100/6774. Loss: 0.15981321036815643\n",
            "\tЭпоха 3. Итерация 3150/6774. Loss: 0.3260907530784607\n",
            "\tЭпоха 3. Итерация 3200/6774. Loss: 0.2953464686870575\n",
            "\tЭпоха 3. Итерация 3250/6774. Loss: 0.3647482991218567\n",
            "\tЭпоха 3. Итерация 3300/6774. Loss: 0.32170727849006653\n",
            "\tЭпоха 3. Итерация 3350/6774. Loss: 0.4548830986022949\n",
            "\tЭпоха 3. Итерация 3400/6774. Loss: 0.3153432011604309\n",
            "\tЭпоха 3. Итерация 3450/6774. Loss: 0.26069438457489014\n",
            "\tЭпоха 3. Итерация 3500/6774. Loss: 0.29421916604042053\n",
            "\tЭпоха 3. Итерация 3550/6774. Loss: 0.3952752947807312\n",
            "\tЭпоха 3. Итерация 3600/6774. Loss: 0.3227981925010681\n",
            "\tЭпоха 3. Итерация 3650/6774. Loss: 0.3187529146671295\n",
            "\tЭпоха 3. Итерация 3700/6774. Loss: 0.4134458601474762\n",
            "\tЭпоха 3. Итерация 3750/6774. Loss: 0.2345305234193802\n",
            "\tЭпоха 3. Итерация 3800/6774. Loss: 0.3798535466194153\n",
            "\tЭпоха 3. Итерация 3850/6774. Loss: 0.31444716453552246\n",
            "\tЭпоха 3. Итерация 3900/6774. Loss: 0.3496212661266327\n",
            "\tЭпоха 3. Итерация 3950/6774. Loss: 0.3950970768928528\n",
            "\tЭпоха 3. Итерация 4000/6774. Loss: 0.3425307273864746\n",
            "\tЭпоха 3. Итерация 4050/6774. Loss: 0.27806368470191956\n",
            "\tЭпоха 3. Итерация 4100/6774. Loss: 0.2500990033149719\n",
            "\tЭпоха 3. Итерация 4150/6774. Loss: 0.16900408267974854\n",
            "\tЭпоха 3. Итерация 4200/6774. Loss: 0.9071934819221497\n",
            "\tЭпоха 3. Итерация 4250/6774. Loss: 0.44397956132888794\n",
            "\tЭпоха 3. Итерация 4300/6774. Loss: 0.3117855489253998\n",
            "\tЭпоха 3. Итерация 4350/6774. Loss: 0.22881577908992767\n",
            "\tЭпоха 3. Итерация 4400/6774. Loss: 0.42901262640953064\n",
            "\tЭпоха 3. Итерация 4450/6774. Loss: 0.29033419489860535\n",
            "\tЭпоха 3. Итерация 4500/6774. Loss: 0.3512704372406006\n",
            "\tЭпоха 3. Итерация 4550/6774. Loss: 0.44271066784858704\n",
            "\tЭпоха 3. Итерация 4600/6774. Loss: 0.4998128414154053\n",
            "\tЭпоха 3. Итерация 4650/6774. Loss: 0.4320876896381378\n",
            "\tЭпоха 3. Итерация 4700/6774. Loss: 0.35433411598205566\n",
            "\tЭпоха 3. Итерация 4750/6774. Loss: 0.3213806450366974\n",
            "\tЭпоха 3. Итерация 4800/6774. Loss: 0.694284200668335\n",
            "\tЭпоха 3. Итерация 4850/6774. Loss: 0.5857424736022949\n",
            "\tЭпоха 3. Итерация 4900/6774. Loss: 0.3336128294467926\n",
            "\tЭпоха 3. Итерация 4950/6774. Loss: 0.3485924005508423\n",
            "\tЭпоха 3. Итерация 5000/6774. Loss: 0.7560489773750305\n",
            "\tЭпоха 3. Итерация 5050/6774. Loss: 0.21725793182849884\n",
            "\tЭпоха 3. Итерация 5100/6774. Loss: 0.4160654842853546\n",
            "\tЭпоха 3. Итерация 5150/6774. Loss: 0.4252774119377136\n",
            "\tЭпоха 3. Итерация 5200/6774. Loss: 0.14955422282218933\n",
            "\tЭпоха 3. Итерация 5250/6774. Loss: 0.35955771803855896\n",
            "\tЭпоха 3. Итерация 5300/6774. Loss: 0.24321848154067993\n",
            "\tЭпоха 3. Итерация 5350/6774. Loss: 0.3021199703216553\n",
            "\tЭпоха 3. Итерация 5400/6774. Loss: 0.3055301904678345\n",
            "\tЭпоха 3. Итерация 5450/6774. Loss: 0.3643554449081421\n",
            "\tЭпоха 3. Итерация 5500/6774. Loss: 0.41437458992004395\n",
            "\tЭпоха 3. Итерация 5550/6774. Loss: 0.36526817083358765\n",
            "\tЭпоха 3. Итерация 5600/6774. Loss: 0.23715458810329437\n",
            "\tЭпоха 3. Итерация 5650/6774. Loss: 0.3311896026134491\n",
            "\tЭпоха 3. Итерация 5700/6774. Loss: 0.4576210379600525\n",
            "\tЭпоха 3. Итерация 5750/6774. Loss: 0.37005332112312317\n",
            "\tЭпоха 3. Итерация 5800/6774. Loss: 0.3372334837913513\n",
            "\tЭпоха 3. Итерация 5850/6774. Loss: 0.31197842955589294\n",
            "\tЭпоха 3. Итерация 5900/6774. Loss: 0.3063225746154785\n",
            "\tЭпоха 3. Итерация 5950/6774. Loss: 0.4404281675815582\n",
            "\tЭпоха 3. Итерация 6000/6774. Loss: 0.3907303810119629\n",
            "\tЭпоха 3. Итерация 6050/6774. Loss: 0.23124217987060547\n",
            "\tЭпоха 3. Итерация 6100/6774. Loss: 0.364819198846817\n",
            "\tЭпоха 3. Итерация 6150/6774. Loss: 0.407914400100708\n",
            "\tЭпоха 3. Итерация 6200/6774. Loss: 0.4739909768104553\n",
            "\tЭпоха 3. Итерация 6250/6774. Loss: 0.5878323912620544\n",
            "\tЭпоха 3. Итерация 6300/6774. Loss: 0.22749990224838257\n",
            "\tЭпоха 3. Итерация 6350/6774. Loss: 0.34614047408103943\n",
            "\tЭпоха 3. Итерация 6400/6774. Loss: 0.2536269426345825\n",
            "\tЭпоха 3. Итерация 6450/6774. Loss: 0.3601311147212982\n",
            "\tЭпоха 3. Итерация 6500/6774. Loss: 0.42445865273475647\n",
            "\tЭпоха 3. Итерация 6550/6774. Loss: 0.26269257068634033\n",
            "\tЭпоха 3. Итерация 6600/6774. Loss: 0.5084567070007324\n",
            "\tЭпоха 3. Итерация 6650/6774. Loss: 0.36069032549858093\n",
            "\tЭпоха 3. Итерация 6700/6774. Loss: 0.4539448022842407\n",
            "\tЭпоха 3. Итерация 6750/6774. Loss: 0.4517667293548584\n",
            "Эпоха #3 train_loss: 0.04478149950139116, val_loss: 0.04986235699802637\n",
            "Потрачено 49.2 минут на 3 эпоху\n",
            "\tЭпоха 4. Итерация 0/6774. Loss: 0.4020726680755615\n",
            "\tЭпоха 4. Итерация 50/6774. Loss: 0.30905845761299133\n",
            "\tЭпоха 4. Итерация 100/6774. Loss: 0.5285887122154236\n",
            "\tЭпоха 4. Итерация 150/6774. Loss: 0.2678665816783905\n",
            "\tЭпоха 4. Итерация 200/6774. Loss: 0.4048873484134674\n",
            "\tЭпоха 4. Итерация 250/6774. Loss: 0.3988003134727478\n",
            "\tЭпоха 4. Итерация 300/6774. Loss: 0.43511536717414856\n",
            "\tЭпоха 4. Итерация 350/6774. Loss: 0.3894948661327362\n",
            "\tЭпоха 4. Итерация 400/6774. Loss: 0.5065560340881348\n",
            "\tЭпоха 4. Итерация 450/6774. Loss: 0.2763676345348358\n",
            "\tЭпоха 4. Итерация 500/6774. Loss: 0.296188622713089\n",
            "\tЭпоха 4. Итерация 550/6774. Loss: 0.30936604738235474\n",
            "\tЭпоха 4. Итерация 600/6774. Loss: 0.3085092306137085\n",
            "\tЭпоха 4. Итерация 650/6774. Loss: 0.3339523673057556\n",
            "\tЭпоха 4. Итерация 700/6774. Loss: 0.319060742855072\n",
            "\tЭпоха 4. Итерация 750/6774. Loss: 0.5044836401939392\n",
            "\tЭпоха 4. Итерация 800/6774. Loss: 0.2941506803035736\n",
            "\tЭпоха 4. Итерация 850/6774. Loss: 0.4303390383720398\n",
            "\tЭпоха 4. Итерация 900/6774. Loss: 0.3589863181114197\n",
            "\tЭпоха 4. Итерация 950/6774. Loss: 0.4100857973098755\n",
            "\tЭпоха 4. Итерация 1000/6774. Loss: 0.5014880895614624\n",
            "\tЭпоха 4. Итерация 1050/6774. Loss: 0.35582220554351807\n",
            "\tЭпоха 4. Итерация 1100/6774. Loss: 0.5150396823883057\n",
            "\tЭпоха 4. Итерация 1150/6774. Loss: 0.2859395444393158\n",
            "\tЭпоха 4. Итерация 1200/6774. Loss: 0.40352287888526917\n",
            "\tЭпоха 4. Итерация 1250/6774. Loss: 0.2746299207210541\n",
            "\tЭпоха 4. Итерация 1300/6774. Loss: 0.32259246706962585\n",
            "\tЭпоха 4. Итерация 1350/6774. Loss: 0.22694431245326996\n",
            "\tЭпоха 4. Итерация 1400/6774. Loss: 0.38527747988700867\n",
            "\tЭпоха 4. Итерация 1450/6774. Loss: 0.366534024477005\n",
            "\tЭпоха 4. Итерация 1500/6774. Loss: 0.3326556086540222\n",
            "\tЭпоха 4. Итерация 1550/6774. Loss: 0.2541566491127014\n",
            "\tЭпоха 4. Итерация 1600/6774. Loss: 0.4127250611782074\n",
            "\tЭпоха 4. Итерация 1650/6774. Loss: 0.3103575110435486\n",
            "\tЭпоха 4. Итерация 1700/6774. Loss: 0.398375928401947\n",
            "\tЭпоха 4. Итерация 1750/6774. Loss: 0.3259070813655853\n",
            "\tЭпоха 4. Итерация 1800/6774. Loss: 0.3744964003562927\n",
            "\tЭпоха 4. Итерация 1850/6774. Loss: 0.39910587668418884\n",
            "\tЭпоха 4. Итерация 1900/6774. Loss: 0.5379545092582703\n",
            "\tЭпоха 4. Итерация 1950/6774. Loss: 0.49190255999565125\n",
            "\tЭпоха 4. Итерация 2000/6774. Loss: 0.3478332757949829\n",
            "\tЭпоха 4. Итерация 2050/6774. Loss: 0.3286934494972229\n",
            "\tЭпоха 4. Итерация 2100/6774. Loss: 0.3219574987888336\n",
            "\tЭпоха 4. Итерация 2150/6774. Loss: 0.3653348982334137\n",
            "\tЭпоха 4. Итерация 2200/6774. Loss: 0.4589076340198517\n",
            "\tЭпоха 4. Итерация 2250/6774. Loss: 0.3711208701133728\n",
            "\tЭпоха 4. Итерация 2300/6774. Loss: 0.33842331171035767\n",
            "\tЭпоха 4. Итерация 2350/6774. Loss: 0.3257945477962494\n",
            "\tЭпоха 4. Итерация 2400/6774. Loss: 0.25155091285705566\n",
            "\tЭпоха 4. Итерация 2450/6774. Loss: 0.33648160099983215\n",
            "\tЭпоха 4. Итерация 2500/6774. Loss: 0.28473445773124695\n",
            "\tЭпоха 4. Итерация 2550/6774. Loss: 0.36038026213645935\n",
            "\tЭпоха 4. Итерация 2600/6774. Loss: 0.3031115233898163\n",
            "\tЭпоха 4. Итерация 2650/6774. Loss: 0.5799340009689331\n",
            "\tЭпоха 4. Итерация 2700/6774. Loss: 0.45697569847106934\n",
            "\tЭпоха 4. Итерация 2750/6774. Loss: 0.19417989253997803\n",
            "\tЭпоха 4. Итерация 2800/6774. Loss: 0.5111010074615479\n",
            "\tЭпоха 4. Итерация 2850/6774. Loss: 0.31696170568466187\n",
            "\tЭпоха 4. Итерация 2900/6774. Loss: 0.33059191703796387\n",
            "\tЭпоха 4. Итерация 2950/6774. Loss: 0.33908793330192566\n",
            "\tЭпоха 4. Итерация 3000/6774. Loss: 0.12629334628582\n",
            "\tЭпоха 4. Итерация 3050/6774. Loss: 0.330703467130661\n",
            "\tЭпоха 4. Итерация 3100/6774. Loss: 0.19992728531360626\n",
            "\tЭпоха 4. Итерация 3150/6774. Loss: 0.25653907656669617\n",
            "\tЭпоха 4. Итерация 3200/6774. Loss: 0.2424170821905136\n",
            "\tЭпоха 4. Итерация 3250/6774. Loss: 0.42700132727622986\n",
            "\tЭпоха 4. Итерация 3300/6774. Loss: 0.3248606026172638\n",
            "\tЭпоха 4. Итерация 3350/6774. Loss: 0.3647662401199341\n",
            "\tЭпоха 4. Итерация 3400/6774. Loss: 0.3920629322528839\n",
            "\tЭпоха 4. Итерация 3450/6774. Loss: 0.41353875398635864\n",
            "\tЭпоха 4. Итерация 3500/6774. Loss: 0.36867406964302063\n",
            "\tЭпоха 4. Итерация 3550/6774. Loss: 0.4166390597820282\n",
            "\tЭпоха 4. Итерация 3600/6774. Loss: 0.29477420449256897\n",
            "\tЭпоха 4. Итерация 3650/6774. Loss: 0.5487056374549866\n",
            "\tЭпоха 4. Итерация 3700/6774. Loss: 0.32399624586105347\n",
            "\tЭпоха 4. Итерация 3750/6774. Loss: 0.5384054183959961\n",
            "\tЭпоха 4. Итерация 3800/6774. Loss: 0.2858901917934418\n",
            "\tЭпоха 4. Итерация 3850/6774. Loss: 0.3325367271900177\n",
            "\tЭпоха 4. Итерация 3900/6774. Loss: 0.34382036328315735\n",
            "\tЭпоха 4. Итерация 3950/6774. Loss: 0.38186904788017273\n",
            "\tЭпоха 4. Итерация 4000/6774. Loss: 0.3601212501525879\n",
            "\tЭпоха 4. Итерация 4050/6774. Loss: 0.43305066227912903\n",
            "\tЭпоха 4. Итерация 4100/6774. Loss: 0.26439014077186584\n",
            "\tЭпоха 4. Итерация 4150/6774. Loss: 0.38069653511047363\n",
            "\tЭпоха 4. Итерация 4200/6774. Loss: 0.3850792348384857\n",
            "\tЭпоха 4. Итерация 4250/6774. Loss: 0.31490767002105713\n",
            "\tЭпоха 4. Итерация 4300/6774. Loss: 0.5650919079780579\n",
            "\tЭпоха 4. Итерация 4350/6774. Loss: 0.4215516448020935\n",
            "\tЭпоха 4. Итерация 4400/6774. Loss: 0.3098064064979553\n",
            "\tЭпоха 4. Итерация 4450/6774. Loss: 0.21397805213928223\n",
            "\tЭпоха 4. Итерация 4500/6774. Loss: 0.39834344387054443\n",
            "\tЭпоха 4. Итерация 4550/6774. Loss: 0.5519026517868042\n",
            "\tЭпоха 4. Итерация 4600/6774. Loss: 0.27125221490859985\n",
            "\tЭпоха 4. Итерация 4650/6774. Loss: 0.17657919228076935\n",
            "\tЭпоха 4. Итерация 4700/6774. Loss: 0.2882687449455261\n",
            "\tЭпоха 4. Итерация 4750/6774. Loss: 0.39238226413726807\n",
            "\tЭпоха 4. Итерация 4800/6774. Loss: 0.3493354618549347\n",
            "\tЭпоха 4. Итерация 4850/6774. Loss: 0.3810936510562897\n",
            "\tЭпоха 4. Итерация 4900/6774. Loss: 0.5927990674972534\n",
            "\tЭпоха 4. Итерация 4950/6774. Loss: 0.31019532680511475\n",
            "\tЭпоха 4. Итерация 5000/6774. Loss: 0.39705225825309753\n",
            "\tЭпоха 4. Итерация 5050/6774. Loss: 0.6522000432014465\n",
            "\tЭпоха 4. Итерация 5100/6774. Loss: 0.3071192502975464\n",
            "\tЭпоха 4. Итерация 5150/6774. Loss: 0.23154571652412415\n",
            "\tЭпоха 4. Итерация 5200/6774. Loss: 0.29525139927864075\n",
            "\tЭпоха 4. Итерация 5250/6774. Loss: 0.33664199709892273\n",
            "\tЭпоха 4. Итерация 5300/6774. Loss: 0.29689615964889526\n",
            "\tЭпоха 4. Итерация 5350/6774. Loss: 0.28180766105651855\n",
            "\tЭпоха 4. Итерация 5400/6774. Loss: 0.35744553804397583\n",
            "\tЭпоха 4. Итерация 5450/6774. Loss: 0.3217161297798157\n",
            "\tЭпоха 4. Итерация 5500/6774. Loss: 0.21070395410060883\n",
            "\tЭпоха 4. Итерация 5550/6774. Loss: 0.34076228737831116\n",
            "\tЭпоха 4. Итерация 5600/6774. Loss: 0.2828730344772339\n",
            "\tЭпоха 4. Итерация 5650/6774. Loss: 0.29030004143714905\n",
            "\tЭпоха 4. Итерация 5700/6774. Loss: 0.43148717284202576\n",
            "\tЭпоха 4. Итерация 5750/6774. Loss: 0.23357713222503662\n",
            "\tЭпоха 4. Итерация 5800/6774. Loss: 0.3529087007045746\n",
            "\tЭпоха 4. Итерация 5850/6774. Loss: 0.2931641936302185\n",
            "\tЭпоха 4. Итерация 5900/6774. Loss: 0.40897876024246216\n",
            "\tЭпоха 4. Итерация 5950/6774. Loss: 0.4007856845855713\n",
            "\tЭпоха 4. Итерация 6000/6774. Loss: 0.2715589106082916\n",
            "\tЭпоха 4. Итерация 6050/6774. Loss: 0.41973555088043213\n",
            "\tЭпоха 4. Итерация 6100/6774. Loss: 0.41283443570137024\n",
            "\tЭпоха 4. Итерация 6150/6774. Loss: 0.3250635862350464\n",
            "\tЭпоха 4. Итерация 6200/6774. Loss: 0.27974650263786316\n",
            "\tЭпоха 4. Итерация 6250/6774. Loss: 0.4157582223415375\n",
            "\tЭпоха 4. Итерация 6300/6774. Loss: 0.31663745641708374\n",
            "\tЭпоха 4. Итерация 6350/6774. Loss: 0.3239412307739258\n",
            "\tЭпоха 4. Итерация 6400/6774. Loss: 0.31198588013648987\n",
            "\tЭпоха 4. Итерация 6450/6774. Loss: 0.5214074850082397\n",
            "\tЭпоха 4. Итерация 6500/6774. Loss: 0.29540151357650757\n",
            "\tЭпоха 4. Итерация 6550/6774. Loss: 0.39318230748176575\n",
            "\tЭпоха 4. Итерация 6600/6774. Loss: 0.13011229038238525\n",
            "\tЭпоха 4. Итерация 6650/6774. Loss: 0.3366398215293884\n",
            "\tЭпоха 4. Итерация 6700/6774. Loss: 0.17710621654987335\n",
            "\tЭпоха 4. Итерация 6750/6774. Loss: 0.2222580909729004\n",
            "Эпоха #4 train_loss: 0.044319538132561793, val_loss: 0.04664341243952513\n",
            "Потрачено 49.1 минут на 4 эпоху\n",
            "\tЭпоха 5. Итерация 0/6774. Loss: 0.3758436441421509\n",
            "\tЭпоха 5. Итерация 50/6774. Loss: 0.20925109088420868\n",
            "\tЭпоха 5. Итерация 100/6774. Loss: 0.31020069122314453\n",
            "\tЭпоха 5. Итерация 150/6774. Loss: 0.3548519015312195\n",
            "\tЭпоха 5. Итерация 200/6774. Loss: 0.3416458070278168\n",
            "\tЭпоха 5. Итерация 250/6774. Loss: 0.35284313559532166\n",
            "\tЭпоха 5. Итерация 300/6774. Loss: 0.2637600302696228\n",
            "\tЭпоха 5. Итерация 350/6774. Loss: 0.44618648290634155\n",
            "\tЭпоха 5. Итерация 400/6774. Loss: 0.42541733384132385\n",
            "\tЭпоха 5. Итерация 450/6774. Loss: 0.34441274404525757\n",
            "\tЭпоха 5. Итерация 500/6774. Loss: 0.25524604320526123\n",
            "\tЭпоха 5. Итерация 550/6774. Loss: 0.2739761471748352\n",
            "\tЭпоха 5. Итерация 600/6774. Loss: 0.4133385419845581\n",
            "\tЭпоха 5. Итерация 650/6774. Loss: 0.4922897219657898\n",
            "\tЭпоха 5. Итерация 700/6774. Loss: 0.34666189551353455\n",
            "\tЭпоха 5. Итерация 750/6774. Loss: 0.5139595866203308\n",
            "\tЭпоха 5. Итерация 800/6774. Loss: 0.2571624517440796\n",
            "\tЭпоха 5. Итерация 850/6774. Loss: 0.3133081793785095\n",
            "\tЭпоха 5. Итерация 900/6774. Loss: 0.2509181797504425\n",
            "\tЭпоха 5. Итерация 950/6774. Loss: 0.4494488835334778\n",
            "\tЭпоха 5. Итерация 1000/6774. Loss: 0.4951154291629791\n",
            "\tЭпоха 5. Итерация 1050/6774. Loss: 0.24608610570430756\n",
            "\tЭпоха 5. Итерация 1100/6774. Loss: 0.35248643159866333\n",
            "\tЭпоха 5. Итерация 1150/6774. Loss: 0.25678369402885437\n",
            "\tЭпоха 5. Итерация 1200/6774. Loss: 0.3748866617679596\n",
            "\tЭпоха 5. Итерация 1250/6774. Loss: 0.18879029154777527\n",
            "\tЭпоха 5. Итерация 1300/6774. Loss: 0.3002004325389862\n",
            "\tЭпоха 5. Итерация 1350/6774. Loss: 0.22156275808811188\n",
            "\tЭпоха 5. Итерация 1400/6774. Loss: 0.3121890723705292\n",
            "\tЭпоха 5. Итерация 1450/6774. Loss: 0.3947472870349884\n",
            "\tЭпоха 5. Итерация 1500/6774. Loss: 0.6102020144462585\n",
            "\tЭпоха 5. Итерация 1550/6774. Loss: 0.3328612148761749\n",
            "\tЭпоха 5. Итерация 1600/6774. Loss: 0.5092991590499878\n",
            "\tЭпоха 5. Итерация 1650/6774. Loss: 0.3982607126235962\n",
            "\tЭпоха 5. Итерация 1700/6774. Loss: 0.3170596957206726\n",
            "\tЭпоха 5. Итерация 1750/6774. Loss: 0.237863689661026\n",
            "\tЭпоха 5. Итерация 1800/6774. Loss: 0.36173003911972046\n",
            "\tЭпоха 5. Итерация 1850/6774. Loss: 0.43014875054359436\n",
            "\tЭпоха 5. Итерация 1900/6774. Loss: 0.4032423496246338\n",
            "\tЭпоха 5. Итерация 1950/6774. Loss: 0.27086514234542847\n",
            "\tЭпоха 5. Итерация 2000/6774. Loss: 0.3761328160762787\n",
            "\tЭпоха 5. Итерация 2050/6774. Loss: 0.2834015488624573\n",
            "\tЭпоха 5. Итерация 2100/6774. Loss: 0.34518998861312866\n",
            "\tЭпоха 5. Итерация 2150/6774. Loss: 0.3185557425022125\n",
            "\tЭпоха 5. Итерация 2200/6774. Loss: 0.42732399702072144\n",
            "\tЭпоха 5. Итерация 2250/6774. Loss: 0.45419812202453613\n",
            "\tЭпоха 5. Итерация 2300/6774. Loss: 0.44904956221580505\n",
            "\tЭпоха 5. Итерация 2350/6774. Loss: 0.3622377812862396\n",
            "\tЭпоха 5. Итерация 2400/6774. Loss: 0.321633905172348\n",
            "\tЭпоха 5. Итерация 2450/6774. Loss: 0.4258248507976532\n",
            "\tЭпоха 5. Итерация 2500/6774. Loss: 0.6045528054237366\n",
            "\tЭпоха 5. Итерация 2550/6774. Loss: 0.27839258313179016\n",
            "\tЭпоха 5. Итерация 2600/6774. Loss: 0.16753160953521729\n",
            "\tЭпоха 5. Итерация 2650/6774. Loss: 0.3047199547290802\n",
            "\tЭпоха 5. Итерация 2700/6774. Loss: 0.5919455289840698\n",
            "\tЭпоха 5. Итерация 2750/6774. Loss: 0.26927101612091064\n",
            "\tЭпоха 5. Итерация 2800/6774. Loss: 0.25250113010406494\n",
            "\tЭпоха 5. Итерация 2850/6774. Loss: 0.338623583316803\n",
            "\tЭпоха 5. Итерация 2900/6774. Loss: 0.2337440401315689\n",
            "\tЭпоха 5. Итерация 2950/6774. Loss: 0.2721908688545227\n",
            "\tЭпоха 5. Итерация 3000/6774. Loss: 0.22042563557624817\n",
            "\tЭпоха 5. Итерация 3050/6774. Loss: 0.41575488448143005\n",
            "\tЭпоха 5. Итерация 3100/6774. Loss: 0.2641777992248535\n",
            "\tЭпоха 5. Итерация 3150/6774. Loss: 0.2613683044910431\n",
            "\tЭпоха 5. Итерация 3200/6774. Loss: 0.31185904145240784\n",
            "\tЭпоха 5. Итерация 3250/6774. Loss: 0.4130120277404785\n",
            "\tЭпоха 5. Итерация 3300/6774. Loss: 0.39156657457351685\n",
            "\tЭпоха 5. Итерация 3350/6774. Loss: 0.4080267548561096\n",
            "\tЭпоха 5. Итерация 3400/6774. Loss: 0.4089934527873993\n",
            "\tЭпоха 5. Итерация 3450/6774. Loss: 0.15290743112564087\n",
            "\tЭпоха 5. Итерация 3500/6774. Loss: 0.3482365310192108\n",
            "\tЭпоха 5. Итерация 3550/6774. Loss: 0.6660540103912354\n",
            "\tЭпоха 5. Итерация 3600/6774. Loss: 0.5285826325416565\n",
            "\tЭпоха 5. Итерация 3650/6774. Loss: 0.42071256041526794\n",
            "\tЭпоха 5. Итерация 3700/6774. Loss: 0.34599050879478455\n",
            "\tЭпоха 5. Итерация 3750/6774. Loss: 0.2776377499103546\n",
            "\tЭпоха 5. Итерация 3800/6774. Loss: 0.3321521580219269\n",
            "\tЭпоха 5. Итерация 3850/6774. Loss: 0.45775410532951355\n",
            "\tЭпоха 5. Итерация 3900/6774. Loss: 0.39899638295173645\n",
            "\tЭпоха 5. Итерация 3950/6774. Loss: 0.2989654242992401\n",
            "\tЭпоха 5. Итерация 4000/6774. Loss: 0.4866493344306946\n",
            "\tЭпоха 5. Итерация 4050/6774. Loss: 0.36065417528152466\n",
            "\tЭпоха 5. Итерация 4100/6774. Loss: 0.20080316066741943\n",
            "\tЭпоха 5. Итерация 4150/6774. Loss: 0.2772567570209503\n",
            "\tЭпоха 5. Итерация 4200/6774. Loss: 0.31326910853385925\n",
            "\tЭпоха 5. Итерация 4250/6774. Loss: 0.4038548171520233\n",
            "\tЭпоха 5. Итерация 4300/6774. Loss: 0.20003527402877808\n",
            "\tЭпоха 5. Итерация 4350/6774. Loss: 0.3376860022544861\n",
            "\tЭпоха 5. Итерация 4400/6774. Loss: 0.46480754017829895\n",
            "\tЭпоха 5. Итерация 4450/6774. Loss: 0.42101556062698364\n",
            "\tЭпоха 5. Итерация 4500/6774. Loss: 0.28100132942199707\n",
            "\tЭпоха 5. Итерация 4550/6774. Loss: 0.3320327401161194\n",
            "\tЭпоха 5. Итерация 4600/6774. Loss: 0.2943950593471527\n",
            "\tЭпоха 5. Итерация 4650/6774. Loss: 0.3515743315219879\n",
            "\tЭпоха 5. Итерация 4700/6774. Loss: 0.4177195727825165\n",
            "\tЭпоха 5. Итерация 4750/6774. Loss: 0.5276017785072327\n",
            "\tЭпоха 5. Итерация 4800/6774. Loss: 0.19488145411014557\n",
            "\tЭпоха 5. Итерация 4850/6774. Loss: 0.2404385805130005\n",
            "\tЭпоха 5. Итерация 4900/6774. Loss: 0.38848769664764404\n",
            "\tЭпоха 5. Итерация 4950/6774. Loss: 0.2208322137594223\n",
            "\tЭпоха 5. Итерация 5000/6774. Loss: 0.4205673933029175\n",
            "\tЭпоха 5. Итерация 5050/6774. Loss: 0.4369054138660431\n",
            "\tЭпоха 5. Итерация 5100/6774. Loss: 0.3078545033931732\n",
            "\tЭпоха 5. Итерация 5150/6774. Loss: 0.327869713306427\n",
            "\tЭпоха 5. Итерация 5200/6774. Loss: 0.3453092873096466\n",
            "\tЭпоха 5. Итерация 5250/6774. Loss: 0.3151472806930542\n",
            "\tЭпоха 5. Итерация 5300/6774. Loss: 0.36041495203971863\n",
            "\tЭпоха 5. Итерация 5350/6774. Loss: 0.2327437400817871\n",
            "\tЭпоха 5. Итерация 5400/6774. Loss: 0.2085142433643341\n",
            "\tЭпоха 5. Итерация 5450/6774. Loss: 0.26668840646743774\n",
            "\tЭпоха 5. Итерация 5500/6774. Loss: 0.3001214861869812\n",
            "\tЭпоха 5. Итерация 5550/6774. Loss: 0.25886112451553345\n",
            "\tЭпоха 5. Итерация 5600/6774. Loss: 0.3083285093307495\n",
            "\tЭпоха 5. Итерация 5650/6774. Loss: 0.20533129572868347\n",
            "\tЭпоха 5. Итерация 5700/6774. Loss: 0.40928536653518677\n",
            "\tЭпоха 5. Итерация 5750/6774. Loss: 0.3948586583137512\n",
            "\tЭпоха 5. Итерация 5800/6774. Loss: 0.19596463441848755\n",
            "\tЭпоха 5. Итерация 5850/6774. Loss: 0.4160163104534149\n",
            "\tЭпоха 5. Итерация 5900/6774. Loss: 0.2365046590566635\n",
            "\tЭпоха 5. Итерация 5950/6774. Loss: 0.40685606002807617\n",
            "\tЭпоха 5. Итерация 6000/6774. Loss: 0.19018928706645966\n",
            "\tЭпоха 5. Итерация 6050/6774. Loss: 0.3353915214538574\n",
            "\tЭпоха 5. Итерация 6100/6774. Loss: 0.4287140667438507\n",
            "\tЭпоха 5. Итерация 6150/6774. Loss: 0.3505866527557373\n",
            "\tЭпоха 5. Итерация 6200/6774. Loss: 0.5158790946006775\n",
            "\tЭпоха 5. Итерация 6250/6774. Loss: 0.29351818561553955\n",
            "\tЭпоха 5. Итерация 6300/6774. Loss: 0.38936370611190796\n",
            "\tЭпоха 5. Итерация 6350/6774. Loss: 0.27787142992019653\n",
            "\tЭпоха 5. Итерация 6400/6774. Loss: 0.22605493664741516\n",
            "\tЭпоха 5. Итерация 6450/6774. Loss: 0.1885300576686859\n",
            "\tЭпоха 5. Итерация 6500/6774. Loss: 0.35441526770591736\n",
            "\tЭпоха 5. Итерация 6550/6774. Loss: 0.3572927415370941\n",
            "\tЭпоха 5. Итерация 6600/6774. Loss: 0.38069114089012146\n",
            "\tЭпоха 5. Итерация 6650/6774. Loss: 0.19737660884857178\n",
            "\tЭпоха 5. Итерация 6700/6774. Loss: 0.4273449778556824\n",
            "\tЭпоха 5. Итерация 6750/6774. Loss: 0.24095502495765686\n",
            "Эпоха #5 train_loss: 0.043181144488510535, val_loss: 0.05141824644804001\n",
            "Потрачено 49.3 минут на 5 эпоху\n",
            "\tЭпоха 6. Итерация 0/6774. Loss: 0.2815762460231781\n",
            "\tЭпоха 6. Итерация 50/6774. Loss: 0.3093547821044922\n",
            "\tЭпоха 6. Итерация 100/6774. Loss: 0.368071973323822\n",
            "\tЭпоха 6. Итерация 150/6774. Loss: 0.527187705039978\n",
            "\tЭпоха 6. Итерация 200/6774. Loss: 0.3633479177951813\n",
            "\tЭпоха 6. Итерация 250/6774. Loss: 0.2766014039516449\n",
            "\tЭпоха 6. Итерация 300/6774. Loss: 0.28390976786613464\n",
            "\tЭпоха 6. Итерация 350/6774. Loss: 0.3166266083717346\n",
            "\tЭпоха 6. Итерация 400/6774. Loss: 0.37596601247787476\n",
            "\tЭпоха 6. Итерация 450/6774. Loss: 0.2783449590206146\n",
            "\tЭпоха 6. Итерация 500/6774. Loss: 0.4291166663169861\n",
            "\tЭпоха 6. Итерация 550/6774. Loss: 0.31071457266807556\n",
            "\tЭпоха 6. Итерация 600/6774. Loss: 0.34582430124282837\n",
            "\tЭпоха 6. Итерация 650/6774. Loss: 0.3842138350009918\n",
            "\tЭпоха 6. Итерация 700/6774. Loss: 0.32373255491256714\n",
            "\tЭпоха 6. Итерация 750/6774. Loss: 0.4188317656517029\n",
            "\tЭпоха 6. Итерация 800/6774. Loss: 0.3462704122066498\n",
            "\tЭпоха 6. Итерация 850/6774. Loss: 0.42798900604248047\n",
            "\tЭпоха 6. Итерация 900/6774. Loss: 0.27616485953330994\n",
            "\tЭпоха 6. Итерация 950/6774. Loss: 0.3927874267101288\n",
            "\tЭпоха 6. Итерация 1000/6774. Loss: 0.36866769194602966\n",
            "\tЭпоха 6. Итерация 1050/6774. Loss: 0.44455596804618835\n",
            "\tЭпоха 6. Итерация 1100/6774. Loss: 0.22118890285491943\n",
            "\tЭпоха 6. Итерация 1150/6774. Loss: 0.3953229486942291\n",
            "\tЭпоха 6. Итерация 1200/6774. Loss: 0.257404625415802\n",
            "\tЭпоха 6. Итерация 1250/6774. Loss: 0.22356680035591125\n",
            "\tЭпоха 6. Итерация 1300/6774. Loss: 0.25055989623069763\n",
            "\tЭпоха 6. Итерация 1350/6774. Loss: 0.3513164222240448\n",
            "\tЭпоха 6. Итерация 1400/6774. Loss: 0.4412425756454468\n",
            "\tЭпоха 6. Итерация 1450/6774. Loss: 0.3337138891220093\n",
            "\tЭпоха 6. Итерация 1500/6774. Loss: 0.4161282181739807\n",
            "\tЭпоха 6. Итерация 1550/6774. Loss: 0.26319512724876404\n",
            "\tЭпоха 6. Итерация 1600/6774. Loss: 0.29373908042907715\n",
            "\tЭпоха 6. Итерация 1650/6774. Loss: 0.2990269660949707\n",
            "\tЭпоха 6. Итерация 1700/6774. Loss: 0.2785620391368866\n",
            "\tЭпоха 6. Итерация 1750/6774. Loss: 0.37717974185943604\n",
            "\tЭпоха 6. Итерация 1800/6774. Loss: 0.4461340010166168\n",
            "\tЭпоха 6. Итерация 1850/6774. Loss: 0.4559444785118103\n",
            "\tЭпоха 6. Итерация 1900/6774. Loss: 0.2874388098716736\n",
            "\tЭпоха 6. Итерация 1950/6774. Loss: 0.30789288878440857\n",
            "\tЭпоха 6. Итерация 2000/6774. Loss: 0.25539785623550415\n",
            "\tЭпоха 6. Итерация 2050/6774. Loss: 0.4668411910533905\n",
            "\tЭпоха 6. Итерация 2100/6774. Loss: 0.3740527331829071\n",
            "\tЭпоха 6. Итерация 2150/6774. Loss: 0.3470463156700134\n",
            "\tЭпоха 6. Итерация 2200/6774. Loss: 0.22206033766269684\n",
            "\tЭпоха 6. Итерация 2250/6774. Loss: 0.2979929447174072\n",
            "\tЭпоха 6. Итерация 2300/6774. Loss: 0.41100695729255676\n",
            "\tЭпоха 6. Итерация 2350/6774. Loss: 0.28053244948387146\n",
            "\tЭпоха 6. Итерация 2400/6774. Loss: 0.4579372704029083\n",
            "\tЭпоха 6. Итерация 2450/6774. Loss: 0.3410255014896393\n",
            "\tЭпоха 6. Итерация 2500/6774. Loss: 0.42660394310951233\n",
            "\tЭпоха 6. Итерация 2550/6774. Loss: 0.40758469700813293\n",
            "\tЭпоха 6. Итерация 2600/6774. Loss: 0.5545458197593689\n",
            "\tЭпоха 6. Итерация 2650/6774. Loss: 0.14815981686115265\n",
            "\tЭпоха 6. Итерация 2700/6774. Loss: 0.3443581163883209\n",
            "\tЭпоха 6. Итерация 2750/6774. Loss: 0.3910912573337555\n",
            "\tЭпоха 6. Итерация 2800/6774. Loss: 0.3325731158256531\n",
            "\tЭпоха 6. Итерация 2850/6774. Loss: 0.3267570734024048\n",
            "\tЭпоха 6. Итерация 2900/6774. Loss: 0.1822260618209839\n",
            "\tЭпоха 6. Итерация 2950/6774. Loss: 0.2622627019882202\n",
            "\tЭпоха 6. Итерация 3000/6774. Loss: 0.3022352159023285\n",
            "\tЭпоха 6. Итерация 3050/6774. Loss: 0.27413883805274963\n",
            "\tЭпоха 6. Итерация 3100/6774. Loss: 0.33339300751686096\n",
            "\tЭпоха 6. Итерация 3150/6774. Loss: 0.26043763756752014\n",
            "\tЭпоха 6. Итерация 3200/6774. Loss: 0.4299323558807373\n",
            "\tЭпоха 6. Итерация 3250/6774. Loss: 0.2643512487411499\n",
            "\tЭпоха 6. Итерация 3300/6774. Loss: 0.24888716638088226\n",
            "\tЭпоха 6. Итерация 3350/6774. Loss: 0.5260334610939026\n",
            "\tЭпоха 6. Итерация 3400/6774. Loss: 0.38892126083374023\n",
            "\tЭпоха 6. Итерация 3450/6774. Loss: 0.41982588171958923\n",
            "\tЭпоха 6. Итерация 3500/6774. Loss: 0.27358072996139526\n",
            "\tЭпоха 6. Итерация 3550/6774. Loss: 0.27822163701057434\n",
            "\tЭпоха 6. Итерация 3600/6774. Loss: 0.311320960521698\n",
            "\tЭпоха 6. Итерация 3650/6774. Loss: 0.4211319088935852\n",
            "\tЭпоха 6. Итерация 3700/6774. Loss: 0.5171109437942505\n",
            "\tЭпоха 6. Итерация 3750/6774. Loss: 0.41996753215789795\n",
            "\tЭпоха 6. Итерация 3800/6774. Loss: 0.47138985991477966\n",
            "\tЭпоха 6. Итерация 3850/6774. Loss: 0.41854068636894226\n",
            "\tЭпоха 6. Итерация 3900/6774. Loss: 0.23451685905456543\n",
            "\tЭпоха 6. Итерация 3950/6774. Loss: 0.4565872848033905\n",
            "\tЭпоха 6. Итерация 4000/6774. Loss: 0.5792747735977173\n",
            "\tЭпоха 6. Итерация 4050/6774. Loss: 0.515129029750824\n",
            "\tЭпоха 6. Итерация 4100/6774. Loss: 0.4118044674396515\n",
            "\tЭпоха 6. Итерация 4150/6774. Loss: 0.40423086285591125\n",
            "\tЭпоха 6. Итерация 4200/6774. Loss: 0.22917860746383667\n",
            "\tЭпоха 6. Итерация 4250/6774. Loss: 0.3607453405857086\n",
            "\tЭпоха 6. Итерация 4300/6774. Loss: 0.39687031507492065\n",
            "\tЭпоха 6. Итерация 4350/6774. Loss: 0.5367519855499268\n",
            "\tЭпоха 6. Итерация 4400/6774. Loss: 0.4897233247756958\n",
            "\tЭпоха 6. Итерация 4450/6774. Loss: 0.25511908531188965\n",
            "\tЭпоха 6. Итерация 4500/6774. Loss: 0.22429467737674713\n",
            "\tЭпоха 6. Итерация 4550/6774. Loss: 0.25955742597579956\n",
            "\tЭпоха 6. Итерация 4600/6774. Loss: 0.2764075696468353\n",
            "\tЭпоха 6. Итерация 4650/6774. Loss: 0.20817211270332336\n",
            "\tЭпоха 6. Итерация 4700/6774. Loss: 0.3698633015155792\n",
            "\tЭпоха 6. Итерация 4750/6774. Loss: 0.24040962755680084\n",
            "\tЭпоха 6. Итерация 4800/6774. Loss: 0.15634988248348236\n",
            "\tЭпоха 6. Итерация 4850/6774. Loss: 0.23612931370735168\n",
            "\tЭпоха 6. Итерация 4900/6774. Loss: 0.3337491750717163\n",
            "\tЭпоха 6. Итерация 4950/6774. Loss: 0.3706175684928894\n",
            "\tЭпоха 6. Итерация 5000/6774. Loss: 0.3580123782157898\n",
            "\tЭпоха 6. Итерация 5050/6774. Loss: 0.6116147041320801\n",
            "\tЭпоха 6. Итерация 5100/6774. Loss: 0.2435351312160492\n",
            "\tЭпоха 6. Итерация 5150/6774. Loss: 0.4575245678424835\n",
            "\tЭпоха 6. Итерация 5200/6774. Loss: 0.3982146084308624\n",
            "\tЭпоха 6. Итерация 5250/6774. Loss: 0.3581211566925049\n",
            "\tЭпоха 6. Итерация 5300/6774. Loss: 0.3829176425933838\n",
            "\tЭпоха 6. Итерация 5350/6774. Loss: 0.5162315964698792\n",
            "\tЭпоха 6. Итерация 5400/6774. Loss: 0.43951207399368286\n",
            "\tЭпоха 6. Итерация 5450/6774. Loss: 0.15971776843070984\n",
            "\tЭпоха 6. Итерация 5500/6774. Loss: 0.270867258310318\n",
            "\tЭпоха 6. Итерация 5550/6774. Loss: 0.5428766012191772\n",
            "\tЭпоха 6. Итерация 5600/6774. Loss: 0.4024479389190674\n",
            "\tЭпоха 6. Итерация 5650/6774. Loss: 0.34170398116111755\n",
            "\tЭпоха 6. Итерация 5700/6774. Loss: 0.28876161575317383\n",
            "\tЭпоха 6. Итерация 5750/6774. Loss: 0.4046212136745453\n",
            "\tЭпоха 6. Итерация 5800/6774. Loss: 0.15490707755088806\n",
            "\tЭпоха 6. Итерация 5850/6774. Loss: 0.3631691336631775\n",
            "\tЭпоха 6. Итерация 5900/6774. Loss: 0.2362084984779358\n",
            "\tЭпоха 6. Итерация 5950/6774. Loss: 0.3113146424293518\n",
            "\tЭпоха 6. Итерация 6000/6774. Loss: 0.1837039291858673\n",
            "\tЭпоха 6. Итерация 6050/6774. Loss: 0.3482518792152405\n",
            "\tЭпоха 6. Итерация 6100/6774. Loss: 0.2632095217704773\n",
            "\tЭпоха 6. Итерация 6150/6774. Loss: 0.32301968336105347\n",
            "\tЭпоха 6. Итерация 6200/6774. Loss: 0.1212543249130249\n",
            "\tЭпоха 6. Итерация 6250/6774. Loss: 0.374509334564209\n",
            "\tЭпоха 6. Итерация 6300/6774. Loss: 0.2997051477432251\n",
            "\tЭпоха 6. Итерация 6350/6774. Loss: 0.6042682528495789\n",
            "\tЭпоха 6. Итерация 6400/6774. Loss: 0.3707127273082733\n",
            "\tЭпоха 6. Итерация 6450/6774. Loss: 0.2891433835029602\n",
            "\tЭпоха 6. Итерация 6500/6774. Loss: 0.2717711925506592\n",
            "\tЭпоха 6. Итерация 6550/6774. Loss: 0.3523465692996979\n",
            "\tЭпоха 6. Итерация 6600/6774. Loss: 0.33931002020835876\n",
            "\tЭпоха 6. Итерация 6650/6774. Loss: 0.4030422270298004\n",
            "\tЭпоха 6. Итерация 6700/6774. Loss: 0.28314709663391113\n",
            "\tЭпоха 6. Итерация 6750/6774. Loss: 0.37837541103363037\n",
            "Эпоха #6 train_loss: 0.04290648898413795, val_loss: 0.03822999240756035\n",
            "Потрачено 49.2 минут на 6 эпоху\n",
            "\tЭпоха 7. Итерация 0/6774. Loss: 0.17787861824035645\n",
            "\tЭпоха 7. Итерация 50/6774. Loss: 0.24732424318790436\n",
            "\tЭпоха 7. Итерация 100/6774. Loss: 0.23013268411159515\n",
            "\tЭпоха 7. Итерация 150/6774. Loss: 0.19508780539035797\n",
            "\tЭпоха 7. Итерация 200/6774. Loss: 0.21198555827140808\n",
            "\tЭпоха 7. Итерация 250/6774. Loss: 0.2446693480014801\n",
            "\tЭпоха 7. Итерация 300/6774. Loss: 0.2994915544986725\n",
            "\tЭпоха 7. Итерация 350/6774. Loss: 0.18778131902217865\n",
            "\tЭпоха 7. Итерация 400/6774. Loss: 0.19966241717338562\n",
            "\tЭпоха 7. Итерация 450/6774. Loss: 0.25558456778526306\n",
            "\tЭпоха 7. Итерация 500/6774. Loss: 0.42258986830711365\n",
            "\tЭпоха 7. Итерация 550/6774. Loss: 0.2682879567146301\n",
            "\tЭпоха 7. Итерация 600/6774. Loss: 0.27877676486968994\n",
            "\tЭпоха 7. Итерация 650/6774. Loss: 0.428467333316803\n",
            "\tЭпоха 7. Итерация 700/6774. Loss: 0.35359135270118713\n",
            "\tЭпоха 7. Итерация 750/6774. Loss: 0.590308427810669\n",
            "\tЭпоха 7. Итерация 800/6774. Loss: 0.29293060302734375\n",
            "\tЭпоха 7. Итерация 850/6774. Loss: 0.4063366949558258\n",
            "\tЭпоха 7. Итерация 900/6774. Loss: 0.5137606859207153\n",
            "\tЭпоха 7. Итерация 950/6774. Loss: 0.3440510928630829\n",
            "\tЭпоха 7. Итерация 1000/6774. Loss: 0.8028509020805359\n",
            "\tЭпоха 7. Итерация 1050/6774. Loss: 0.41508543491363525\n",
            "\tЭпоха 7. Итерация 1100/6774. Loss: 0.2143482267856598\n",
            "\tЭпоха 7. Итерация 1150/6774. Loss: 0.3388473391532898\n",
            "\tЭпоха 7. Итерация 1200/6774. Loss: 0.30958855152130127\n",
            "\tЭпоха 7. Итерация 1250/6774. Loss: 0.4824536442756653\n",
            "\tЭпоха 7. Итерация 1300/6774. Loss: 0.43264710903167725\n",
            "\tЭпоха 7. Итерация 1350/6774. Loss: 0.24775980412960052\n",
            "\tЭпоха 7. Итерация 1400/6774. Loss: 0.41023534536361694\n",
            "\tЭпоха 7. Итерация 1450/6774. Loss: 0.4310215413570404\n",
            "\tЭпоха 7. Итерация 1500/6774. Loss: 0.34612634778022766\n",
            "\tЭпоха 7. Итерация 1550/6774. Loss: 0.21133282780647278\n",
            "\tЭпоха 7. Итерация 1600/6774. Loss: 0.2886044383049011\n",
            "\tЭпоха 7. Итерация 1650/6774. Loss: 0.3029744625091553\n",
            "\tЭпоха 7. Итерация 1700/6774. Loss: 0.2792109251022339\n",
            "\tЭпоха 7. Итерация 1750/6774. Loss: 0.3783576786518097\n",
            "\tЭпоха 7. Итерация 1800/6774. Loss: 0.3206368386745453\n",
            "\tЭпоха 7. Итерация 1850/6774. Loss: 0.6279773116111755\n",
            "\tЭпоха 7. Итерация 1900/6774. Loss: 0.42977139353752136\n",
            "\tЭпоха 7. Итерация 1950/6774. Loss: 0.23786547780036926\n",
            "\tЭпоха 7. Итерация 2000/6774. Loss: 0.23952753841876984\n",
            "\tЭпоха 7. Итерация 2050/6774. Loss: 0.38712427020072937\n",
            "\tЭпоха 7. Итерация 2100/6774. Loss: 0.30968567728996277\n",
            "\tЭпоха 7. Итерация 2150/6774. Loss: 0.4593641459941864\n",
            "\tЭпоха 7. Итерация 2200/6774. Loss: 0.5444754362106323\n",
            "\tЭпоха 7. Итерация 2250/6774. Loss: 0.4296751916408539\n",
            "\tЭпоха 7. Итерация 2300/6774. Loss: 0.24340224266052246\n",
            "\tЭпоха 7. Итерация 2350/6774. Loss: 0.2471139281988144\n",
            "\tЭпоха 7. Итерация 2400/6774. Loss: 0.3023747205734253\n",
            "\tЭпоха 7. Итерация 2450/6774. Loss: 0.18692409992218018\n",
            "\tЭпоха 7. Итерация 2500/6774. Loss: 0.2129918485879898\n",
            "\tЭпоха 7. Итерация 2550/6774. Loss: 0.3499275743961334\n",
            "\tЭпоха 7. Итерация 2600/6774. Loss: 0.5384036898612976\n",
            "\tЭпоха 7. Итерация 2650/6774. Loss: 0.23542317748069763\n",
            "\tЭпоха 7. Итерация 2700/6774. Loss: 0.42447930574417114\n",
            "\tЭпоха 7. Итерация 2750/6774. Loss: 0.29735639691352844\n",
            "\tЭпоха 7. Итерация 2800/6774. Loss: 0.25397437810897827\n",
            "\tЭпоха 7. Итерация 2850/6774. Loss: 0.27972137928009033\n",
            "\tЭпоха 7. Итерация 2900/6774. Loss: 0.4095824360847473\n",
            "\tЭпоха 7. Итерация 2950/6774. Loss: 0.19879640638828278\n",
            "\tЭпоха 7. Итерация 3000/6774. Loss: 0.31048280000686646\n",
            "\tЭпоха 7. Итерация 3050/6774. Loss: 0.39479389786720276\n",
            "\tЭпоха 7. Итерация 3100/6774. Loss: 0.383653849363327\n",
            "\tЭпоха 7. Итерация 3150/6774. Loss: 0.3161453604698181\n",
            "\tЭпоха 7. Итерация 3200/6774. Loss: 0.35496827960014343\n",
            "\tЭпоха 7. Итерация 3250/6774. Loss: 0.26438724994659424\n",
            "\tЭпоха 7. Итерация 3300/6774. Loss: 0.39666488766670227\n",
            "\tЭпоха 7. Итерация 3350/6774. Loss: 0.20700456202030182\n",
            "\tЭпоха 7. Итерация 3400/6774. Loss: 0.38619741797447205\n",
            "\tЭпоха 7. Итерация 3450/6774. Loss: 0.24168317019939423\n",
            "\tЭпоха 7. Итерация 3500/6774. Loss: 0.2944640815258026\n",
            "\tЭпоха 7. Итерация 3550/6774. Loss: 0.26464080810546875\n",
            "\tЭпоха 7. Итерация 3600/6774. Loss: 0.26128503680229187\n",
            "\tЭпоха 7. Итерация 3650/6774. Loss: 0.31747403740882874\n",
            "\tЭпоха 7. Итерация 3700/6774. Loss: 0.26607269048690796\n",
            "\tЭпоха 7. Итерация 3750/6774. Loss: 0.4543347954750061\n",
            "\tЭпоха 7. Итерация 3800/6774. Loss: 0.2967997193336487\n",
            "\tЭпоха 7. Итерация 3850/6774. Loss: 0.18545348942279816\n",
            "\tЭпоха 7. Итерация 3900/6774. Loss: 0.5092456340789795\n",
            "\tЭпоха 7. Итерация 3950/6774. Loss: 0.3567163646221161\n",
            "\tЭпоха 7. Итерация 4000/6774. Loss: 0.30447274446487427\n",
            "\tЭпоха 7. Итерация 4050/6774. Loss: 0.31312453746795654\n",
            "\tЭпоха 7. Итерация 4100/6774. Loss: 0.34785017371177673\n",
            "\tЭпоха 7. Итерация 4150/6774. Loss: 0.21607916057109833\n",
            "\tЭпоха 7. Итерация 4200/6774. Loss: 0.2605229616165161\n",
            "\tЭпоха 7. Итерация 4250/6774. Loss: 0.23504579067230225\n",
            "\tЭпоха 7. Итерация 4300/6774. Loss: 0.40416449308395386\n",
            "\tЭпоха 7. Итерация 4350/6774. Loss: 0.4697451591491699\n",
            "\tЭпоха 7. Итерация 4400/6774. Loss: 0.220526784658432\n",
            "\tЭпоха 7. Итерация 4450/6774. Loss: 0.23194444179534912\n",
            "\tЭпоха 7. Итерация 4500/6774. Loss: 0.3219800889492035\n",
            "\tЭпоха 7. Итерация 4550/6774. Loss: 0.39621347188949585\n",
            "\tЭпоха 7. Итерация 4600/6774. Loss: 0.3049112856388092\n",
            "\tЭпоха 7. Итерация 4650/6774. Loss: 0.28178104758262634\n",
            "\tЭпоха 7. Итерация 4700/6774. Loss: 0.4269463121891022\n",
            "\tЭпоха 7. Итерация 4750/6774. Loss: 0.21553343534469604\n",
            "\tЭпоха 7. Итерация 4800/6774. Loss: 0.3827556371688843\n",
            "\tЭпоха 7. Итерация 4850/6774. Loss: 0.27445361018180847\n",
            "\tЭпоха 7. Итерация 4900/6774. Loss: 0.3182171881198883\n",
            "\tЭпоха 7. Итерация 4950/6774. Loss: 0.3526778221130371\n",
            "\tЭпоха 7. Итерация 5000/6774. Loss: 0.5893970727920532\n",
            "\tЭпоха 7. Итерация 5050/6774. Loss: 0.2979761064052582\n",
            "\tЭпоха 7. Итерация 5100/6774. Loss: 0.3936857581138611\n",
            "\tЭпоха 7. Итерация 5150/6774. Loss: 0.32585516571998596\n",
            "\tЭпоха 7. Итерация 5200/6774. Loss: 0.3351379632949829\n",
            "\tЭпоха 7. Итерация 5250/6774. Loss: 0.21199481189250946\n",
            "\tЭпоха 7. Итерация 5300/6774. Loss: 0.6569564342498779\n",
            "\tЭпоха 7. Итерация 5350/6774. Loss: 0.20381934940814972\n",
            "\tЭпоха 7. Итерация 5400/6774. Loss: 0.4148431718349457\n",
            "\tЭпоха 7. Итерация 5450/6774. Loss: 0.4003753364086151\n",
            "\tЭпоха 7. Итерация 5500/6774. Loss: 0.30662283301353455\n",
            "\tЭпоха 7. Итерация 5550/6774. Loss: 0.2727898955345154\n",
            "\tЭпоха 7. Итерация 5600/6774. Loss: 0.6428386569023132\n",
            "\tЭпоха 7. Итерация 5650/6774. Loss: 0.20476706326007843\n",
            "\tЭпоха 7. Итерация 5700/6774. Loss: 0.3937765657901764\n",
            "\tЭпоха 7. Итерация 5750/6774. Loss: 0.3243197798728943\n",
            "\tЭпоха 7. Итерация 5800/6774. Loss: 0.3981897830963135\n",
            "\tЭпоха 7. Итерация 5850/6774. Loss: 0.20579823851585388\n",
            "\tЭпоха 7. Итерация 5900/6774. Loss: 0.21678081154823303\n",
            "\tЭпоха 7. Итерация 5950/6774. Loss: 0.17438283562660217\n",
            "\tЭпоха 7. Итерация 6000/6774. Loss: 0.37581756711006165\n",
            "\tЭпоха 7. Итерация 6050/6774. Loss: 0.2144772708415985\n",
            "\tЭпоха 7. Итерация 6100/6774. Loss: 0.45948323607444763\n",
            "\tЭпоха 7. Итерация 6150/6774. Loss: 0.24678966403007507\n",
            "\tЭпоха 7. Итерация 6200/6774. Loss: 0.2871553301811218\n",
            "\tЭпоха 7. Итерация 6250/6774. Loss: 0.39742031693458557\n",
            "\tЭпоха 7. Итерация 6300/6774. Loss: 0.2767331898212433\n",
            "\tЭпоха 7. Итерация 6350/6774. Loss: 0.43364179134368896\n",
            "\tЭпоха 7. Итерация 6400/6774. Loss: 0.34528955817222595\n",
            "\tЭпоха 7. Итерация 6450/6774. Loss: 0.34553322196006775\n",
            "\tЭпоха 7. Итерация 6500/6774. Loss: 0.25798898935317993\n",
            "\tЭпоха 7. Итерация 6550/6774. Loss: 0.312826007604599\n",
            "\tЭпоха 7. Итерация 6600/6774. Loss: 0.3393411636352539\n",
            "\tЭпоха 7. Итерация 6650/6774. Loss: 0.20760278403759003\n",
            "\tЭпоха 7. Итерация 6700/6774. Loss: 0.28417080640792847\n",
            "\tЭпоха 7. Итерация 6750/6774. Loss: 0.3810056149959564\n",
            "Эпоха #7 train_loss: 0.04273540742330695, val_loss: 0.03755336822867394\n",
            "Потрачено 49.8 минут на 7 эпоху\n",
            "\tЭпоха 8. Итерация 0/6774. Loss: 0.3087793290615082\n",
            "\tЭпоха 8. Итерация 50/6774. Loss: 0.2770646810531616\n",
            "\tЭпоха 8. Итерация 100/6774. Loss: 0.27907299995422363\n",
            "\tЭпоха 8. Итерация 150/6774. Loss: 0.40588343143463135\n",
            "\tЭпоха 8. Итерация 200/6774. Loss: 0.15150605142116547\n",
            "\tЭпоха 8. Итерация 250/6774. Loss: 0.4203213155269623\n",
            "\tЭпоха 8. Итерация 300/6774. Loss: 0.43791934847831726\n",
            "\tЭпоха 8. Итерация 350/6774. Loss: 0.44016486406326294\n",
            "\tЭпоха 8. Итерация 400/6774. Loss: 0.28959542512893677\n",
            "\tЭпоха 8. Итерация 450/6774. Loss: 0.37859460711479187\n",
            "\tЭпоха 8. Итерация 500/6774. Loss: 0.5605816841125488\n",
            "\tЭпоха 8. Итерация 550/6774. Loss: 0.17495596408843994\n",
            "\tЭпоха 8. Итерация 600/6774. Loss: 0.19886843860149384\n",
            "\tЭпоха 8. Итерация 650/6774. Loss: 0.34400349855422974\n",
            "\tЭпоха 8. Итерация 700/6774. Loss: 0.3204250633716583\n",
            "\tЭпоха 8. Итерация 750/6774. Loss: 0.22683316469192505\n",
            "\tЭпоха 8. Итерация 800/6774. Loss: 0.18365702033042908\n",
            "\tЭпоха 8. Итерация 850/6774. Loss: 0.4947041869163513\n",
            "\tЭпоха 8. Итерация 900/6774. Loss: 0.49165216088294983\n",
            "\tЭпоха 8. Итерация 950/6774. Loss: 0.4433760941028595\n",
            "\tЭпоха 8. Итерация 1000/6774. Loss: 0.2606891691684723\n",
            "\tЭпоха 8. Итерация 1050/6774. Loss: 0.42981886863708496\n",
            "\tЭпоха 8. Итерация 1100/6774. Loss: 0.30721989274024963\n",
            "\tЭпоха 8. Итерация 1150/6774. Loss: 0.2715396583080292\n",
            "\tЭпоха 8. Итерация 1200/6774. Loss: 0.276582807302475\n",
            "\tЭпоха 8. Итерация 1250/6774. Loss: 0.33587682247161865\n",
            "\tЭпоха 8. Итерация 1300/6774. Loss: 0.4459364712238312\n",
            "\tЭпоха 8. Итерация 1350/6774. Loss: 0.34243765473365784\n",
            "\tЭпоха 8. Итерация 1400/6774. Loss: 0.24366073310375214\n",
            "\tЭпоха 8. Итерация 1450/6774. Loss: 0.5508409738540649\n",
            "\tЭпоха 8. Итерация 1500/6774. Loss: 0.3650822639465332\n",
            "\tЭпоха 8. Итерация 1550/6774. Loss: 0.557246744632721\n",
            "\tЭпоха 8. Итерация 1600/6774. Loss: 0.27577027678489685\n",
            "\tЭпоха 8. Итерация 1650/6774. Loss: 0.32627183198928833\n",
            "\tЭпоха 8. Итерация 1700/6774. Loss: 0.3934969902038574\n",
            "\tЭпоха 8. Итерация 1750/6774. Loss: 0.19731509685516357\n",
            "\tЭпоха 8. Итерация 1800/6774. Loss: 0.24939796328544617\n",
            "\tЭпоха 8. Итерация 1850/6774. Loss: 0.24801769852638245\n",
            "\tЭпоха 8. Итерация 1900/6774. Loss: 0.30377355217933655\n",
            "\tЭпоха 8. Итерация 1950/6774. Loss: 0.2903670072555542\n",
            "\tЭпоха 8. Итерация 2000/6774. Loss: 0.5217910408973694\n",
            "\tЭпоха 8. Итерация 2050/6774. Loss: 0.31292232871055603\n",
            "\tЭпоха 8. Итерация 2100/6774. Loss: 0.459179162979126\n",
            "\tЭпоха 8. Итерация 2150/6774. Loss: 0.45062363147735596\n",
            "\tЭпоха 8. Итерация 2200/6774. Loss: 0.17982986569404602\n",
            "\tЭпоха 8. Итерация 2250/6774. Loss: 0.1996675580739975\n",
            "\tЭпоха 8. Итерация 2300/6774. Loss: 0.5081531405448914\n",
            "\tЭпоха 8. Итерация 2350/6774. Loss: 0.29823675751686096\n",
            "\tЭпоха 8. Итерация 2400/6774. Loss: 0.21884621679782867\n",
            "\tЭпоха 8. Итерация 2450/6774. Loss: 0.28784453868865967\n",
            "\tЭпоха 8. Итерация 2500/6774. Loss: 0.4277581572532654\n",
            "\tЭпоха 8. Итерация 2550/6774. Loss: 0.2589273750782013\n",
            "\tЭпоха 8. Итерация 2600/6774. Loss: 0.19387686252593994\n",
            "\tЭпоха 8. Итерация 2650/6774. Loss: 0.49134665727615356\n",
            "\tЭпоха 8. Итерация 2700/6774. Loss: 0.5977230072021484\n",
            "\tЭпоха 8. Итерация 2750/6774. Loss: 0.20181424915790558\n",
            "\tЭпоха 8. Итерация 2800/6774. Loss: 0.27912914752960205\n",
            "\tЭпоха 8. Итерация 2850/6774. Loss: 0.3072664141654968\n",
            "\tЭпоха 8. Итерация 2900/6774. Loss: 0.3130740225315094\n",
            "\tЭпоха 8. Итерация 2950/6774. Loss: 0.38467520475387573\n",
            "\tЭпоха 8. Итерация 3000/6774. Loss: 0.26430559158325195\n",
            "\tЭпоха 8. Итерация 3050/6774. Loss: 0.5860268473625183\n",
            "\tЭпоха 8. Итерация 3100/6774. Loss: 0.21089062094688416\n",
            "\tЭпоха 8. Итерация 3150/6774. Loss: 0.30349117517471313\n",
            "\tЭпоха 8. Итерация 3200/6774. Loss: 0.3094622492790222\n",
            "\tЭпоха 8. Итерация 3250/6774. Loss: 0.3362242579460144\n",
            "\tЭпоха 8. Итерация 3300/6774. Loss: 0.5301047563552856\n",
            "\tЭпоха 8. Итерация 3350/6774. Loss: 0.6960862874984741\n",
            "\tЭпоха 8. Итерация 3400/6774. Loss: 0.2097790241241455\n",
            "\tЭпоха 8. Итерация 3450/6774. Loss: 0.1967444121837616\n",
            "\tЭпоха 8. Итерация 3500/6774. Loss: 0.31319713592529297\n",
            "\tЭпоха 8. Итерация 3550/6774. Loss: 0.4644884765148163\n",
            "\tЭпоха 8. Итерация 3600/6774. Loss: 0.30415982007980347\n",
            "\tЭпоха 8. Итерация 3650/6774. Loss: 0.3519026041030884\n",
            "\tЭпоха 8. Итерация 3700/6774. Loss: 0.4554121792316437\n",
            "\tЭпоха 8. Итерация 3750/6774. Loss: 0.2998788058757782\n",
            "\tЭпоха 8. Итерация 3800/6774. Loss: 0.25544261932373047\n",
            "\tЭпоха 8. Итерация 3850/6774. Loss: 0.2370937019586563\n",
            "\tЭпоха 8. Итерация 3900/6774. Loss: 0.25204354524612427\n",
            "\tЭпоха 8. Итерация 3950/6774. Loss: 0.2651786208152771\n",
            "\tЭпоха 8. Итерация 4000/6774. Loss: 0.19850938022136688\n",
            "\tЭпоха 8. Итерация 4050/6774. Loss: 0.44091349840164185\n",
            "\tЭпоха 8. Итерация 4100/6774. Loss: 0.3394954204559326\n",
            "\tЭпоха 8. Итерация 4150/6774. Loss: 0.2067784070968628\n",
            "\tЭпоха 8. Итерация 4200/6774. Loss: 0.2964450716972351\n",
            "\tЭпоха 8. Итерация 4250/6774. Loss: 0.2212892323732376\n",
            "\tЭпоха 8. Итерация 4300/6774. Loss: 0.4205445349216461\n",
            "\tЭпоха 8. Итерация 4350/6774. Loss: 0.4032455086708069\n",
            "\tЭпоха 8. Итерация 4400/6774. Loss: 0.2948364317417145\n",
            "\tЭпоха 8. Итерация 4450/6774. Loss: 0.29760637879371643\n",
            "\tЭпоха 8. Итерация 4500/6774. Loss: 0.47210386395454407\n",
            "\tЭпоха 8. Итерация 4550/6774. Loss: 0.2712062895298004\n",
            "\tЭпоха 8. Итерация 4600/6774. Loss: 0.26130977272987366\n",
            "\tЭпоха 8. Итерация 4650/6774. Loss: 0.23108811676502228\n",
            "\tЭпоха 8. Итерация 4700/6774. Loss: 0.34335097670555115\n",
            "\tЭпоха 8. Итерация 4750/6774. Loss: 0.16381704807281494\n",
            "\tЭпоха 8. Итерация 4800/6774. Loss: 0.38141942024230957\n",
            "\tЭпоха 8. Итерация 4850/6774. Loss: 0.3889533579349518\n",
            "\tЭпоха 8. Итерация 4900/6774. Loss: 0.3853711187839508\n",
            "\tЭпоха 8. Итерация 4950/6774. Loss: 0.16779330372810364\n",
            "\tЭпоха 8. Итерация 5000/6774. Loss: 0.5735883712768555\n",
            "\tЭпоха 8. Итерация 5050/6774. Loss: 0.5618215203285217\n",
            "\tЭпоха 8. Итерация 5100/6774. Loss: 0.198208287358284\n",
            "\tЭпоха 8. Итерация 5150/6774. Loss: 0.3206581473350525\n",
            "\tЭпоха 8. Итерация 5200/6774. Loss: 0.46944084763526917\n",
            "\tЭпоха 8. Итерация 5250/6774. Loss: 0.22152890264987946\n",
            "\tЭпоха 8. Итерация 5300/6774. Loss: 0.46255868673324585\n",
            "\tЭпоха 8. Итерация 5350/6774. Loss: 0.38694360852241516\n",
            "\tЭпоха 8. Итерация 5400/6774. Loss: 0.23398636281490326\n",
            "\tЭпоха 8. Итерация 5450/6774. Loss: 0.29497647285461426\n",
            "\tЭпоха 8. Итерация 5500/6774. Loss: 0.3175090253353119\n",
            "\tЭпоха 8. Итерация 5550/6774. Loss: 0.25300222635269165\n",
            "\tЭпоха 8. Итерация 5600/6774. Loss: 0.2322303056716919\n",
            "\tЭпоха 8. Итерация 5650/6774. Loss: 0.4266231656074524\n",
            "\tЭпоха 8. Итерация 5700/6774. Loss: 0.1495191752910614\n",
            "\tЭпоха 8. Итерация 5750/6774. Loss: 0.2162950038909912\n",
            "\tЭпоха 8. Итерация 5800/6774. Loss: 0.22368420660495758\n",
            "\tЭпоха 8. Итерация 5850/6774. Loss: 0.2924843430519104\n",
            "\tЭпоха 8. Итерация 5900/6774. Loss: 0.2578950524330139\n",
            "\tЭпоха 8. Итерация 5950/6774. Loss: 0.27602845430374146\n",
            "\tЭпоха 8. Итерация 6000/6774. Loss: 0.3554413318634033\n",
            "\tЭпоха 8. Итерация 6050/6774. Loss: 0.5716952681541443\n",
            "\tЭпоха 8. Итерация 6100/6774. Loss: 0.527855634689331\n",
            "\tЭпоха 8. Итерация 6150/6774. Loss: 0.3757840394973755\n",
            "\tЭпоха 8. Итерация 6200/6774. Loss: 0.17700381577014923\n",
            "\tЭпоха 8. Итерация 6250/6774. Loss: 0.5280628204345703\n",
            "\tЭпоха 8. Итерация 6300/6774. Loss: 0.479316383600235\n",
            "\tЭпоха 8. Итерация 6350/6774. Loss: 0.40291649103164673\n",
            "\tЭпоха 8. Итерация 6400/6774. Loss: 0.1268724799156189\n",
            "\tЭпоха 8. Итерация 6450/6774. Loss: 0.28423625230789185\n",
            "\tЭпоха 8. Итерация 6500/6774. Loss: 0.33360555768013\n",
            "\tЭпоха 8. Итерация 6550/6774. Loss: 0.16676783561706543\n",
            "\tЭпоха 8. Итерация 6600/6774. Loss: 0.3572913110256195\n",
            "\tЭпоха 8. Итерация 6650/6774. Loss: 0.24917347729206085\n",
            "\tЭпоха 8. Итерация 6700/6774. Loss: 0.2877543270587921\n",
            "\tЭпоха 8. Итерация 6750/6774. Loss: 0.23832951486110687\n",
            "Эпоха #8 train_loss: 0.042460512706871456, val_loss: 0.04190236104726791\n",
            "Потрачено 49.1 минут на 8 эпоху\n",
            "\tЭпоха 9. Итерация 0/6774. Loss: 0.35998788475990295\n",
            "\tЭпоха 9. Итерация 50/6774. Loss: 0.28076156973838806\n",
            "\tЭпоха 9. Итерация 100/6774. Loss: 0.36414435505867004\n",
            "\tЭпоха 9. Итерация 150/6774. Loss: 0.25380459427833557\n",
            "\tЭпоха 9. Итерация 200/6774. Loss: 0.45265084505081177\n",
            "\tЭпоха 9. Итерация 250/6774. Loss: 0.2573263943195343\n",
            "\tЭпоха 9. Итерация 300/6774. Loss: 0.17451035976409912\n",
            "\tЭпоха 9. Итерация 350/6774. Loss: 0.3219403922557831\n",
            "\tЭпоха 9. Итерация 400/6774. Loss: 0.23690439760684967\n",
            "\tЭпоха 9. Итерация 450/6774. Loss: 0.3823149800300598\n",
            "\tЭпоха 9. Итерация 500/6774. Loss: 0.15386809408664703\n",
            "\tЭпоха 9. Итерация 550/6774. Loss: 0.3035529851913452\n",
            "\tЭпоха 9. Итерация 600/6774. Loss: 0.3509402275085449\n",
            "\tЭпоха 9. Итерация 650/6774. Loss: 0.27245160937309265\n",
            "\tЭпоха 9. Итерация 700/6774. Loss: 0.5526943206787109\n",
            "\tЭпоха 9. Итерация 750/6774. Loss: 0.20630109310150146\n",
            "\tЭпоха 9. Итерация 800/6774. Loss: 0.35723549127578735\n",
            "\tЭпоха 9. Итерация 850/6774. Loss: 0.6268380284309387\n",
            "\tЭпоха 9. Итерация 900/6774. Loss: 0.2861962616443634\n",
            "\tЭпоха 9. Итерация 950/6774. Loss: 0.516858696937561\n",
            "\tЭпоха 9. Итерация 1000/6774. Loss: 0.37698623538017273\n",
            "\tЭпоха 9. Итерация 1050/6774. Loss: 0.3601531386375427\n",
            "\tЭпоха 9. Итерация 1100/6774. Loss: 0.3149510324001312\n",
            "\tЭпоха 9. Итерация 1150/6774. Loss: 0.2642801105976105\n",
            "\tЭпоха 9. Итерация 1200/6774. Loss: 0.3406507670879364\n",
            "\tЭпоха 9. Итерация 1250/6774. Loss: 0.5823288559913635\n",
            "\tЭпоха 9. Итерация 1300/6774. Loss: 0.15252655744552612\n",
            "\tЭпоха 9. Итерация 1350/6774. Loss: 0.31300872564315796\n",
            "\tЭпоха 9. Итерация 1400/6774. Loss: 0.3177851140499115\n",
            "\tЭпоха 9. Итерация 1450/6774. Loss: 0.3899063766002655\n",
            "\tЭпоха 9. Итерация 1500/6774. Loss: 0.27790671586990356\n",
            "\tЭпоха 9. Итерация 1550/6774. Loss: 0.34411606192588806\n",
            "\tЭпоха 9. Итерация 1600/6774. Loss: 0.49255144596099854\n",
            "\tЭпоха 9. Итерация 1650/6774. Loss: 0.21597205102443695\n",
            "\tЭпоха 9. Итерация 1700/6774. Loss: 0.3244514465332031\n",
            "\tЭпоха 9. Итерация 1750/6774. Loss: 0.3004091680049896\n",
            "\tЭпоха 9. Итерация 1800/6774. Loss: 0.21613629162311554\n",
            "\tЭпоха 9. Итерация 1850/6774. Loss: 0.33720114827156067\n",
            "\tЭпоха 9. Итерация 1900/6774. Loss: 0.2870434522628784\n",
            "\tЭпоха 9. Итерация 1950/6774. Loss: 0.43351536989212036\n",
            "\tЭпоха 9. Итерация 2000/6774. Loss: 0.22777576744556427\n",
            "\tЭпоха 9. Итерация 2050/6774. Loss: 0.481184184551239\n",
            "\tЭпоха 9. Итерация 2100/6774. Loss: 0.39619970321655273\n",
            "\tЭпоха 9. Итерация 2150/6774. Loss: 0.13947178423404694\n",
            "\tЭпоха 9. Итерация 2200/6774. Loss: 0.19485503435134888\n",
            "\tЭпоха 9. Итерация 2250/6774. Loss: 0.3987400531768799\n",
            "\tЭпоха 9. Итерация 2300/6774. Loss: 0.30692967772483826\n",
            "\tЭпоха 9. Итерация 2350/6774. Loss: 0.5470045208930969\n",
            "\tЭпоха 9. Итерация 2400/6774. Loss: 0.3133790194988251\n",
            "\tЭпоха 9. Итерация 2450/6774. Loss: 0.42250046133995056\n",
            "\tЭпоха 9. Итерация 2500/6774. Loss: 0.2884996235370636\n",
            "\tЭпоха 9. Итерация 2550/6774. Loss: 0.3313884735107422\n",
            "\tЭпоха 9. Итерация 2600/6774. Loss: 0.21619801223278046\n",
            "\tЭпоха 9. Итерация 2650/6774. Loss: 0.32184216380119324\n",
            "\tЭпоха 9. Итерация 2700/6774. Loss: 0.2020002156496048\n",
            "\tЭпоха 9. Итерация 2750/6774. Loss: 0.3641761243343353\n",
            "\tЭпоха 9. Итерация 2800/6774. Loss: 0.35036784410476685\n",
            "\tЭпоха 9. Итерация 2850/6774. Loss: 0.37314024567604065\n",
            "\tЭпоха 9. Итерация 2900/6774. Loss: 0.3302936851978302\n",
            "\tЭпоха 9. Итерация 2950/6774. Loss: 0.43114620447158813\n",
            "\tЭпоха 9. Итерация 3000/6774. Loss: 0.2775346040725708\n",
            "\tЭпоха 9. Итерация 3050/6774. Loss: 0.299007773399353\n",
            "\tЭпоха 9. Итерация 3100/6774. Loss: 0.40716031193733215\n",
            "\tЭпоха 9. Итерация 3150/6774. Loss: 0.17501601576805115\n",
            "\tЭпоха 9. Итерация 3200/6774. Loss: 0.2890874147415161\n",
            "\tЭпоха 9. Итерация 3250/6774. Loss: 0.2779110074043274\n",
            "\tЭпоха 9. Итерация 3300/6774. Loss: 0.20858722925186157\n",
            "\tЭпоха 9. Итерация 3350/6774. Loss: 0.3238360285758972\n",
            "\tЭпоха 9. Итерация 3400/6774. Loss: 0.2689952850341797\n",
            "\tЭпоха 9. Итерация 3450/6774. Loss: 0.4786565899848938\n",
            "\tЭпоха 9. Итерация 3500/6774. Loss: 0.29750528931617737\n",
            "\tЭпоха 9. Итерация 3550/6774. Loss: 0.3759250044822693\n",
            "\tЭпоха 9. Итерация 3600/6774. Loss: 0.22327622771263123\n",
            "\tЭпоха 9. Итерация 3650/6774. Loss: 0.34839797019958496\n",
            "\tЭпоха 9. Итерация 3700/6774. Loss: 0.3823589086532593\n",
            "\tЭпоха 9. Итерация 3750/6774. Loss: 0.2641250491142273\n",
            "\tЭпоха 9. Итерация 3800/6774. Loss: 0.21845929324626923\n",
            "\tЭпоха 9. Итерация 3850/6774. Loss: 0.23222370445728302\n",
            "\tЭпоха 9. Итерация 3900/6774. Loss: 0.32654091715812683\n",
            "\tЭпоха 9. Итерация 3950/6774. Loss: 0.3160858154296875\n",
            "\tЭпоха 9. Итерация 4000/6774. Loss: 0.4110124707221985\n",
            "\tЭпоха 9. Итерация 4050/6774. Loss: 0.3294179141521454\n",
            "\tЭпоха 9. Итерация 4100/6774. Loss: 0.22256489098072052\n",
            "\tЭпоха 9. Итерация 4150/6774. Loss: 0.4413994252681732\n",
            "\tЭпоха 9. Итерация 4200/6774. Loss: 0.4940735995769501\n",
            "\tЭпоха 9. Итерация 4250/6774. Loss: 0.3730546534061432\n",
            "\tЭпоха 9. Итерация 4300/6774. Loss: 0.3392286002635956\n",
            "\tЭпоха 9. Итерация 4350/6774. Loss: 0.48646244406700134\n",
            "\tЭпоха 9. Итерация 4400/6774. Loss: 0.28456681966781616\n",
            "\tЭпоха 9. Итерация 4450/6774. Loss: 0.23954427242279053\n",
            "\tЭпоха 9. Итерация 4500/6774. Loss: 0.47004157304763794\n",
            "\tЭпоха 9. Итерация 4550/6774. Loss: 0.45033353567123413\n",
            "\tЭпоха 9. Итерация 4600/6774. Loss: 0.48263058066368103\n",
            "\tЭпоха 9. Итерация 4650/6774. Loss: 0.6118025183677673\n",
            "\tЭпоха 9. Итерация 4700/6774. Loss: 0.37011703848838806\n",
            "\tЭпоха 9. Итерация 4750/6774. Loss: 0.5519284009933472\n",
            "\tЭпоха 9. Итерация 4800/6774. Loss: 0.22373300790786743\n",
            "\tЭпоха 9. Итерация 4850/6774. Loss: 0.3843504786491394\n",
            "\tЭпоха 9. Итерация 4900/6774. Loss: 0.2646239399909973\n",
            "\tЭпоха 9. Итерация 4950/6774. Loss: 0.2199602872133255\n",
            "\tЭпоха 9. Итерация 5000/6774. Loss: 0.2671646177768707\n",
            "\tЭпоха 9. Итерация 5050/6774. Loss: 0.49198415875434875\n",
            "\tЭпоха 9. Итерация 5100/6774. Loss: 0.20201468467712402\n",
            "\tЭпоха 9. Итерация 5150/6774. Loss: 0.18883995711803436\n",
            "\tЭпоха 9. Итерация 5200/6774. Loss: 0.3475421369075775\n",
            "\tЭпоха 9. Итерация 5250/6774. Loss: 0.26428258419036865\n",
            "\tЭпоха 9. Итерация 5300/6774. Loss: 0.3904266059398651\n",
            "\tЭпоха 9. Итерация 5350/6774. Loss: 0.21149009466171265\n",
            "\tЭпоха 9. Итерация 5400/6774. Loss: 0.22221027314662933\n",
            "\tЭпоха 9. Итерация 5450/6774. Loss: 0.37807801365852356\n",
            "\tЭпоха 9. Итерация 5500/6774. Loss: 0.33879372477531433\n",
            "\tЭпоха 9. Итерация 5550/6774. Loss: 0.28139910101890564\n",
            "\tЭпоха 9. Итерация 5600/6774. Loss: 0.39998242259025574\n",
            "\tЭпоха 9. Итерация 5650/6774. Loss: 0.3076038062572479\n",
            "\tЭпоха 9. Итерация 5700/6774. Loss: 0.484745055437088\n",
            "\tЭпоха 9. Итерация 5750/6774. Loss: 0.2945946455001831\n",
            "\tЭпоха 9. Итерация 5800/6774. Loss: 0.3160901665687561\n",
            "\tЭпоха 9. Итерация 5850/6774. Loss: 0.371288537979126\n",
            "\tЭпоха 9. Итерация 5900/6774. Loss: 0.5453469157218933\n",
            "\tЭпоха 9. Итерация 5950/6774. Loss: 0.31279024481773376\n",
            "\tЭпоха 9. Итерация 6000/6774. Loss: 0.2428692728281021\n",
            "\tЭпоха 9. Итерация 6050/6774. Loss: 0.3138088285923004\n",
            "\tЭпоха 9. Итерация 6100/6774. Loss: 0.5456010103225708\n",
            "\tЭпоха 9. Итерация 6150/6774. Loss: 0.44459742307662964\n",
            "\tЭпоха 9. Итерация 6200/6774. Loss: 0.2638959586620331\n",
            "\tЭпоха 9. Итерация 6250/6774. Loss: 0.1713700145483017\n",
            "\tЭпоха 9. Итерация 6300/6774. Loss: 0.32451125979423523\n",
            "\tЭпоха 9. Итерация 6350/6774. Loss: 0.40607956051826477\n",
            "\tЭпоха 9. Итерация 6400/6774. Loss: 0.34293532371520996\n",
            "\tЭпоха 9. Итерация 6450/6774. Loss: 0.4134407341480255\n",
            "\tЭпоха 9. Итерация 6500/6774. Loss: 0.1880922168493271\n",
            "\tЭпоха 9. Итерация 6550/6774. Loss: 0.4122134745121002\n",
            "\tЭпоха 9. Итерация 6600/6774. Loss: 0.4416220188140869\n",
            "\tЭпоха 9. Итерация 6650/6774. Loss: 0.4661807119846344\n",
            "\tЭпоха 9. Итерация 6700/6774. Loss: 0.39660677313804626\n",
            "\tЭпоха 9. Итерация 6750/6774. Loss: 0.3210393488407135\n",
            "Эпоха #9 train_loss: 0.04243292869874747, val_loss: 0.040583115349709986\n",
            "Потрачено 49.3 минут на 9 эпоху\n"
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "try:\n",
        "    for epoch in range(n_epochs):\n",
        "        start = time.time()\n",
        "        train_loss = train(train_data_loader, epoch)\n",
        "        val_loss = val(val_data_loader, epoch)\n",
        "        #lr_scheduler.step()\n",
        "        print(f\"Эпоха #{epoch} train_loss: {train_loss}, val_loss: {val_loss}\")  \n",
        "        end = time.time()\n",
        "        print(f\"Потрачено {round((end - start) / 60, 1)} минут на {epoch} эпоху\")\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "            'losses_train': train_losses,\n",
        "            'losses_val': val_losses\n",
        "            }, os.path.join(dataset_path, f'../checkpoints/model_detector_resnet50_augmented_{epoch}.pth'))\n",
        "    torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "    'losses_train': train_losses,\n",
        "    'losses_val': val_losses\n",
        "    }, os.path.join(dataset_path, f'../checkpoints/model_detector_resnet50_augmented_full.pth'))\n",
        "except KeyboardInterrupt:\n",
        "    print('Прервано пользователем')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92r83slt8HWu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYImJAxe8HWu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "RLL0C1078HWu",
        "outputId": "d92014cd-dea2-4e7e-ee4f-d54968066738"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(train_losses, label='Train')\n",
        "ax.plot(val_losses, label='Val')\n",
        "#ax.plot(val_losses, label='Val')\n",
        "ax.set(xlabel='Epoch', ylabel='Loss')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pVD7IpU8HWu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "242586dd62d544a39c122c7b1ed6efc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78cb1778f71b45b88ffdb20bfe0cd66e",
              "IPY_MODEL_6d83c78727204f529982e56c3bfe32c1",
              "IPY_MODEL_55191ea6a8eb4574aff8a9bc21fdd55a"
            ],
            "layout": "IPY_MODEL_ae7f4e349b634abd8b36184774421f7a"
          }
        },
        "4146164713eb4c2db70cf52335398a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55191ea6a8eb4574aff8a9bc21fdd55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b17d80f4da05457781be26c19a1dca17",
            "placeholder": "​",
            "style": "IPY_MODEL_8e403bce502349d28da4553899f80c33",
            "value": " 160M/160M [00:00&lt;00:00, 331MB/s]"
          }
        },
        "6d83c78727204f529982e56c3bfe32c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4146164713eb4c2db70cf52335398a3e",
            "max": 167502836,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e66226838c994913b2d58fd0db3f4282",
            "value": 167502836
          }
        },
        "78cb1778f71b45b88ffdb20bfe0cd66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e012c54a3a9f48b38c500c17227f67b8",
            "placeholder": "​",
            "style": "IPY_MODEL_91eb94ac4f6347c6b7d860b73e3742da",
            "value": "100%"
          }
        },
        "8e403bce502349d28da4553899f80c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91eb94ac4f6347c6b7d860b73e3742da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae7f4e349b634abd8b36184774421f7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b17d80f4da05457781be26c19a1dca17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e012c54a3a9f48b38c500c17227f67b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e66226838c994913b2d58fd0db3f4282": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
