{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis-R-V/TSR/blob/main/simple_detector_v2.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Система распознавания дорожных знаков на датасете RTSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import fiftyone as fo\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RTSD_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, annotation, transforms=None):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.coco = COCO(annotation)\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Own coco file\n",
    "        coco = self.coco\n",
    "        # Image ID\n",
    "        img_id = self.ids[index]\n",
    "        # List: get annotation id from coco\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        # Dictionary: target coco_annotation file for an image\n",
    "        coco_annotation = coco.loadAnns(ann_ids)\n",
    "        # path for input image\n",
    "        path = coco.loadImgs(img_id)[0]['file_name']\n",
    "        # open the input image\n",
    "        img = Image.open(os.path.join(self.root, path))\n",
    "\n",
    "        # number of objects in the image\n",
    "        num_objs = len(coco_annotation)\n",
    "\n",
    "        # Bounding boxes for objects\n",
    "        # In coco format, bbox = [xmin, ymin, width, height]\n",
    "        # In pytorch, the input should be [xmin, ymin, xmax, ymax]\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            xmin = coco_annotation[i]['bbox'][0]\n",
    "            ymin = coco_annotation[i]['bbox'][1]\n",
    "            xmax = xmin + coco_annotation[i]['bbox'][2]\n",
    "            ymax = ymin + coco_annotation[i]['bbox'][3]\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # Labels (In my case, I only one class: target class or background)\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        # Tensorise img_id\n",
    "        img_id = torch.tensor([img_id])\n",
    "        # Size of bbox (Rectangular)\n",
    "        areas = []\n",
    "        for i in range(num_objs):\n",
    "            areas.append(coco_annotation[i]['area'])\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "        # Iscrowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        # Annotation is in dictionary format\n",
    "        my_annotation = {}\n",
    "        my_annotation[\"boxes\"] = boxes\n",
    "        my_annotation[\"labels\"] = labels\n",
    "        my_annotation[\"image_id\"] = img_id\n",
    "        my_annotation[\"area\"] = areas\n",
    "        my_annotation[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, my_annotation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In my case, just added ToTensor\n",
    "def get_transform():\n",
    "    custom_transforms = []\n",
    "    custom_transforms.append(torchvision.transforms.ToTensor())\n",
    "    return torchvision.transforms.Compose(custom_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data scaled and normalization for training and testing\n",
    "#data_transforms = {\n",
    "#    'train': transforms.Compose([\n",
    "#        transforms.RandomResizedCrop(32),\n",
    "##        transforms.ToTensor(),\n",
    " #       transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    " #   ]),\n",
    " #   'test': transforms.Compose([\n",
    " #       transforms.RandomResizedCrop(32),\n",
    " #       transforms.ToTensor(),\n",
    " #       transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    " #   ]),\n",
    "#}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# path to your own data and coco file\n",
    "train_data_dir = 'data'\n",
    "train_coco = 'data/train_anno_reduced_bin_class.json'\n",
    "\n",
    "# create own Dataset\n",
    "my_dataset = RTSD_dataset(root=train_data_dir,\n",
    "                          annotation=train_coco,\n",
    "                          transforms=get_transform()\n",
    "                          )\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# Batch size\n",
    "train_batch_size = 4\n",
    "\n",
    "# own DataLoader\n",
    "data_loader = torch.utils.data.DataLoader(my_dataset,\n",
    "                                          batch_size=train_batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          #num_workers=1,\n",
    "                                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select device (whether GPU or CPU)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('mps')\n",
    "\n",
    "# DataLoader is iterable over Dataset\n",
    "#for imgs, annotations in data_loader:\n",
    "#    imgs = list(img.to(device) for img in imgs)\n",
    "#    annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "#    print(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=None)\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1/473, Loss: 1.4519239664077759\n",
      "Iteration: 2/473, Loss: 1.2817339897155762\n",
      "Iteration: 3/473, Loss: 1.132690191268921\n",
      "Iteration: 4/473, Loss: 0.9888722896575928\n",
      "Iteration: 5/473, Loss: 0.9863886833190918\n",
      "Iteration: 6/473, Loss: 0.9339880347251892\n",
      "Iteration: 7/473, Loss: 0.6847689151763916\n",
      "Iteration: 8/473, Loss: 0.5321398377418518\n",
      "Iteration: 9/473, Loss: 0.36475276947021484\n",
      "Iteration: 10/473, Loss: 0.46246615052223206\n",
      "Iteration: 11/473, Loss: 0.29618746042251587\n",
      "Iteration: 12/473, Loss: 0.30712226033210754\n",
      "Iteration: 13/473, Loss: 0.24444308876991272\n",
      "Iteration: 14/473, Loss: 0.30756765604019165\n",
      "Iteration: 15/473, Loss: 0.14773672819137573\n",
      "Iteration: 16/473, Loss: 0.2400197833776474\n",
      "Iteration: 17/473, Loss: 0.1496814340353012\n",
      "Iteration: 18/473, Loss: 0.12262721359729767\n",
      "Iteration: 19/473, Loss: 0.24144229292869568\n",
      "Iteration: 20/473, Loss: 0.14327022433280945\n",
      "Iteration: 21/473, Loss: 0.08851338922977448\n",
      "Iteration: 22/473, Loss: 0.22065573930740356\n",
      "Iteration: 23/473, Loss: 0.14805763959884644\n",
      "Iteration: 24/473, Loss: 0.16032323241233826\n",
      "Iteration: 25/473, Loss: 0.21744495630264282\n",
      "Iteration: 26/473, Loss: 0.20567023754119873\n",
      "Iteration: 27/473, Loss: 0.2700328528881073\n",
      "Iteration: 28/473, Loss: 0.23241011798381805\n",
      "Iteration: 29/473, Loss: 0.20378535985946655\n",
      "Iteration: 30/473, Loss: 0.20216083526611328\n",
      "Iteration: 31/473, Loss: 0.2461620718240738\n",
      "Iteration: 32/473, Loss: 0.2812517583370209\n",
      "Iteration: 33/473, Loss: 0.22411459684371948\n",
      "Iteration: 34/473, Loss: 0.2018708735704422\n",
      "Iteration: 35/473, Loss: 0.28358396887779236\n",
      "Iteration: 36/473, Loss: 0.2069009244441986\n",
      "Iteration: 37/473, Loss: 0.22655940055847168\n",
      "Iteration: 38/473, Loss: 0.28733372688293457\n",
      "Iteration: 39/473, Loss: 0.2095947116613388\n",
      "Iteration: 40/473, Loss: 0.17244289815425873\n",
      "Iteration: 41/473, Loss: 0.41302090883255005\n",
      "Iteration: 42/473, Loss: 0.20495036244392395\n",
      "Iteration: 43/473, Loss: 0.3239859640598297\n",
      "Iteration: 44/473, Loss: 0.16129852831363678\n",
      "Iteration: 45/473, Loss: 0.2728058695793152\n",
      "Iteration: 46/473, Loss: 0.2150864601135254\n",
      "Iteration: 47/473, Loss: 0.23376616835594177\n",
      "Iteration: 48/473, Loss: 0.13855817914009094\n",
      "Iteration: 49/473, Loss: 0.15587905049324036\n",
      "Iteration: 50/473, Loss: 0.2189660221338272\n",
      "Iteration: 51/473, Loss: 0.17025387287139893\n",
      "Iteration: 52/473, Loss: 0.20140476524829865\n",
      "Iteration: 53/473, Loss: 0.16198484599590302\n",
      "Iteration: 54/473, Loss: 0.19418591260910034\n",
      "Iteration: 55/473, Loss: 0.19762229919433594\n",
      "Iteration: 56/473, Loss: 0.1894523948431015\n",
      "Iteration: 57/473, Loss: 0.16275526583194733\n",
      "Iteration: 58/473, Loss: 0.18293407559394836\n",
      "Iteration: 59/473, Loss: 0.1668175309896469\n",
      "Iteration: 60/473, Loss: 0.1595996767282486\n",
      "Iteration: 61/473, Loss: 0.1822899729013443\n",
      "Iteration: 62/473, Loss: 0.1782684028148651\n",
      "Iteration: 63/473, Loss: 0.24497613310813904\n",
      "Iteration: 64/473, Loss: 0.1625380516052246\n",
      "Iteration: 65/473, Loss: 0.16643640398979187\n",
      "Iteration: 66/473, Loss: 0.15746839344501495\n",
      "Iteration: 67/473, Loss: 0.18689125776290894\n",
      "Iteration: 68/473, Loss: 0.2848391830921173\n",
      "Iteration: 69/473, Loss: 0.20865792036056519\n",
      "Iteration: 70/473, Loss: 0.16556698083877563\n",
      "Iteration: 71/473, Loss: 0.25624769926071167\n",
      "Iteration: 72/473, Loss: 0.19700033962726593\n",
      "Iteration: 73/473, Loss: 0.18554574251174927\n",
      "Iteration: 74/473, Loss: 0.186080664396286\n",
      "Iteration: 75/473, Loss: 0.190012589097023\n",
      "Iteration: 76/473, Loss: 0.2223930060863495\n",
      "Iteration: 77/473, Loss: 0.1918572187423706\n",
      "Iteration: 78/473, Loss: 0.1742027997970581\n",
      "Iteration: 79/473, Loss: 0.14652778208255768\n",
      "Iteration: 80/473, Loss: 0.26069068908691406\n",
      "Iteration: 81/473, Loss: 0.20113171637058258\n",
      "Iteration: 82/473, Loss: 0.1701105237007141\n",
      "Iteration: 83/473, Loss: 0.19717678427696228\n",
      "Iteration: 84/473, Loss: 0.255391925573349\n",
      "Iteration: 85/473, Loss: 0.21917562186717987\n",
      "Iteration: 86/473, Loss: 0.19836919009685516\n",
      "Iteration: 87/473, Loss: 0.16043928265571594\n",
      "Iteration: 88/473, Loss: 0.25686538219451904\n",
      "Iteration: 89/473, Loss: 0.182587131857872\n",
      "Iteration: 90/473, Loss: 0.2172257900238037\n",
      "Iteration: 91/473, Loss: 0.1570177674293518\n",
      "Iteration: 92/473, Loss: 0.19349491596221924\n",
      "Iteration: 93/473, Loss: 0.21492168307304382\n",
      "Iteration: 94/473, Loss: 0.21172679960727692\n",
      "Iteration: 95/473, Loss: 0.19137349724769592\n",
      "Iteration: 96/473, Loss: 0.13269078731536865\n",
      "Iteration: 97/473, Loss: 0.17139661312103271\n",
      "Iteration: 98/473, Loss: 0.19452312588691711\n",
      "Iteration: 99/473, Loss: 0.3117263615131378\n",
      "Iteration: 100/473, Loss: 0.20713654160499573\n",
      "Iteration: 101/473, Loss: 0.17933118343353271\n",
      "Iteration: 102/473, Loss: 0.16087335348129272\n",
      "Iteration: 103/473, Loss: 0.2122887521982193\n",
      "Iteration: 104/473, Loss: 0.13387608528137207\n",
      "Iteration: 105/473, Loss: 0.2008342444896698\n",
      "Iteration: 106/473, Loss: 0.2357431799173355\n",
      "Iteration: 107/473, Loss: 0.156528502702713\n",
      "Iteration: 108/473, Loss: 0.29374462366104126\n",
      "Iteration: 109/473, Loss: 0.19057002663612366\n",
      "Iteration: 110/473, Loss: 0.2001807540655136\n",
      "Iteration: 111/473, Loss: 0.1895877718925476\n",
      "Iteration: 112/473, Loss: 0.166712686419487\n",
      "Iteration: 113/473, Loss: 0.1660604327917099\n",
      "Iteration: 114/473, Loss: 0.1979733556509018\n",
      "Iteration: 115/473, Loss: 0.19905027747154236\n",
      "Iteration: 116/473, Loss: 0.221161350607872\n",
      "Iteration: 117/473, Loss: 0.2069334238767624\n",
      "Iteration: 118/473, Loss: 0.1807546615600586\n",
      "Iteration: 119/473, Loss: 0.1693025529384613\n",
      "Iteration: 120/473, Loss: 0.2302224040031433\n",
      "Iteration: 121/473, Loss: 0.17307113111019135\n",
      "Iteration: 122/473, Loss: 0.26594603061676025\n",
      "Iteration: 123/473, Loss: 0.20526304841041565\n",
      "Iteration: 124/473, Loss: 0.35368049144744873\n",
      "Iteration: 125/473, Loss: 0.15948575735092163\n",
      "Iteration: 126/473, Loss: 0.1749688684940338\n",
      "Iteration: 127/473, Loss: 0.29898613691329956\n",
      "Iteration: 128/473, Loss: 0.18775410950183868\n",
      "Iteration: 129/473, Loss: 0.18631397187709808\n",
      "Iteration: 130/473, Loss: 0.15539765357971191\n",
      "Iteration: 131/473, Loss: 0.228919118642807\n",
      "Iteration: 132/473, Loss: 0.18748395144939423\n",
      "Iteration: 133/473, Loss: 0.12040504068136215\n",
      "Iteration: 134/473, Loss: 0.14126500487327576\n",
      "Iteration: 135/473, Loss: 0.16767632961273193\n",
      "Iteration: 136/473, Loss: 0.15475498139858246\n",
      "Iteration: 137/473, Loss: 0.16813044250011444\n",
      "Iteration: 138/473, Loss: 0.2078367918729782\n",
      "Iteration: 139/473, Loss: 0.2249939739704132\n",
      "Iteration: 140/473, Loss: 0.13752055168151855\n",
      "Iteration: 141/473, Loss: 0.19644391536712646\n",
      "Iteration: 142/473, Loss: 0.1498584896326065\n",
      "Iteration: 143/473, Loss: 0.20872431993484497\n",
      "Iteration: 144/473, Loss: 0.2200988233089447\n",
      "Iteration: 145/473, Loss: 0.24917428195476532\n",
      "Iteration: 146/473, Loss: 0.1520097404718399\n",
      "Iteration: 147/473, Loss: 0.19118119776248932\n",
      "Iteration: 148/473, Loss: 0.20915673673152924\n",
      "Iteration: 149/473, Loss: 0.14736336469650269\n",
      "Iteration: 150/473, Loss: 0.18369165062904358\n",
      "Iteration: 151/473, Loss: 0.16722384095191956\n",
      "Iteration: 152/473, Loss: 0.15281155705451965\n",
      "Iteration: 153/473, Loss: 0.18542362749576569\n",
      "Iteration: 154/473, Loss: 0.17251503467559814\n",
      "Iteration: 155/473, Loss: 0.17787803709506989\n",
      "Iteration: 156/473, Loss: 0.16213057935237885\n",
      "Iteration: 157/473, Loss: 0.2325608879327774\n",
      "Iteration: 158/473, Loss: 0.19734060764312744\n",
      "Iteration: 159/473, Loss: 0.19766885042190552\n",
      "Iteration: 160/473, Loss: 0.17855305969715118\n",
      "Iteration: 161/473, Loss: 0.22568650543689728\n",
      "Iteration: 162/473, Loss: 0.11220613867044449\n",
      "Iteration: 163/473, Loss: 0.15854120254516602\n",
      "Iteration: 164/473, Loss: 0.15579836070537567\n",
      "Iteration: 165/473, Loss: 0.1392749696969986\n",
      "Iteration: 166/473, Loss: 0.16809597611427307\n",
      "Iteration: 167/473, Loss: 0.22330255806446075\n",
      "Iteration: 168/473, Loss: 0.16744966804981232\n",
      "Iteration: 169/473, Loss: 0.156656876206398\n",
      "Iteration: 170/473, Loss: 0.10304331034421921\n",
      "Iteration: 171/473, Loss: 0.14325062930583954\n",
      "Iteration: 172/473, Loss: 0.1707140952348709\n",
      "Iteration: 173/473, Loss: 0.19015799462795258\n",
      "Iteration: 174/473, Loss: 0.1694565713405609\n",
      "Iteration: 175/473, Loss: 0.22083476185798645\n",
      "Iteration: 176/473, Loss: 0.16619731485843658\n",
      "Iteration: 177/473, Loss: 0.18546569347381592\n",
      "Iteration: 178/473, Loss: 0.13773083686828613\n",
      "Iteration: 179/473, Loss: 0.28924691677093506\n",
      "Iteration: 180/473, Loss: 0.14225506782531738\n",
      "Iteration: 181/473, Loss: 0.15981072187423706\n",
      "Iteration: 182/473, Loss: 0.11359906941652298\n",
      "Iteration: 183/473, Loss: 0.16468599438667297\n",
      "Iteration: 184/473, Loss: 0.10742834955453873\n",
      "Iteration: 185/473, Loss: 0.14118707180023193\n",
      "Iteration: 186/473, Loss: 0.08062364161014557\n",
      "Iteration: 187/473, Loss: 0.16115881502628326\n",
      "Iteration: 188/473, Loss: 0.14837507903575897\n",
      "Iteration: 189/473, Loss: 0.2041785567998886\n",
      "Iteration: 190/473, Loss: 0.1374169886112213\n",
      "Iteration: 191/473, Loss: 0.19324764609336853\n",
      "Iteration: 192/473, Loss: 0.1526438295841217\n",
      "Iteration: 193/473, Loss: 0.1596761792898178\n",
      "Iteration: 194/473, Loss: 0.17736981809139252\n",
      "Iteration: 195/473, Loss: 0.167448490858078\n",
      "Iteration: 196/473, Loss: 0.14441318809986115\n",
      "Iteration: 197/473, Loss: 0.15092070400714874\n",
      "Iteration: 198/473, Loss: 0.15805409848690033\n",
      "Iteration: 199/473, Loss: 0.15605206787586212\n",
      "Iteration: 200/473, Loss: 0.14389142394065857\n",
      "Iteration: 201/473, Loss: 0.1987491101026535\n",
      "Iteration: 202/473, Loss: 0.09984111040830612\n",
      "Iteration: 203/473, Loss: 0.11814544349908829\n",
      "Iteration: 204/473, Loss: 0.14577805995941162\n",
      "Iteration: 205/473, Loss: 0.18104857206344604\n",
      "Iteration: 206/473, Loss: 0.18863917887210846\n",
      "Iteration: 207/473, Loss: 0.28833991289138794\n",
      "Iteration: 208/473, Loss: 0.1684371531009674\n",
      "Iteration: 209/473, Loss: 0.2070339471101761\n",
      "Iteration: 210/473, Loss: 0.13320377469062805\n",
      "Iteration: 211/473, Loss: 0.1497603803873062\n",
      "Iteration: 212/473, Loss: 0.16821280121803284\n",
      "Iteration: 213/473, Loss: 0.11807018518447876\n",
      "Iteration: 214/473, Loss: 0.18969617784023285\n",
      "Iteration: 215/473, Loss: 0.18380141258239746\n",
      "Iteration: 216/473, Loss: 0.18349015712738037\n",
      "Iteration: 217/473, Loss: 0.14261405169963837\n",
      "Iteration: 218/473, Loss: 0.16656912863254547\n",
      "Iteration: 219/473, Loss: 0.20466452836990356\n",
      "Iteration: 220/473, Loss: 0.15986432135105133\n",
      "Iteration: 221/473, Loss: 0.14185410737991333\n",
      "Iteration: 222/473, Loss: 0.13508430123329163\n",
      "Iteration: 223/473, Loss: 0.19860441982746124\n",
      "Iteration: 224/473, Loss: 0.17288067936897278\n",
      "Iteration: 225/473, Loss: 0.1464792788028717\n",
      "Iteration: 226/473, Loss: 0.1390046328306198\n",
      "Iteration: 227/473, Loss: 0.17850497364997864\n",
      "Iteration: 228/473, Loss: 0.20286773145198822\n",
      "Iteration: 229/473, Loss: 0.16544555127620697\n",
      "Iteration: 230/473, Loss: 0.13951513171195984\n",
      "Iteration: 231/473, Loss: 0.11457595229148865\n",
      "Iteration: 232/473, Loss: 0.18582755327224731\n",
      "Iteration: 233/473, Loss: 0.22640155255794525\n",
      "Iteration: 234/473, Loss: 0.10552273690700531\n",
      "Iteration: 235/473, Loss: 0.34975093603134155\n",
      "Iteration: 236/473, Loss: 0.17610450088977814\n",
      "Iteration: 237/473, Loss: 0.16406524181365967\n",
      "Iteration: 238/473, Loss: 0.20875361561775208\n",
      "Iteration: 239/473, Loss: 0.1965097188949585\n",
      "Iteration: 240/473, Loss: 0.1631028801202774\n",
      "Iteration: 241/473, Loss: 0.1341780424118042\n",
      "Iteration: 242/473, Loss: 0.1233302429318428\n",
      "Iteration: 243/473, Loss: 0.20289123058319092\n",
      "Iteration: 244/473, Loss: 0.1772979199886322\n",
      "Iteration: 245/473, Loss: 0.16914357244968414\n",
      "Iteration: 246/473, Loss: 0.14419665932655334\n",
      "Iteration: 247/473, Loss: 0.15760403871536255\n",
      "Iteration: 248/473, Loss: 0.14169442653656006\n",
      "Iteration: 249/473, Loss: 0.18025656044483185\n",
      "Iteration: 250/473, Loss: 0.14369791746139526\n",
      "Iteration: 251/473, Loss: 0.151275172829628\n",
      "Iteration: 252/473, Loss: 0.19898687303066254\n",
      "Iteration: 253/473, Loss: 0.2442035973072052\n",
      "Iteration: 254/473, Loss: 0.23252476751804352\n",
      "Iteration: 255/473, Loss: 0.1329137682914734\n",
      "Iteration: 256/473, Loss: 0.18707260489463806\n",
      "Iteration: 257/473, Loss: 0.1538921594619751\n",
      "Iteration: 258/473, Loss: 0.12563148140907288\n",
      "Iteration: 259/473, Loss: 0.20307506620883942\n",
      "Iteration: 260/473, Loss: 0.11204467713832855\n",
      "Iteration: 261/473, Loss: 0.16173765063285828\n",
      "Iteration: 262/473, Loss: 0.15381354093551636\n",
      "Iteration: 263/473, Loss: 0.09863938391208649\n",
      "Iteration: 264/473, Loss: 0.13340863585472107\n",
      "Iteration: 265/473, Loss: 0.1503761112689972\n",
      "Iteration: 266/473, Loss: 0.16341440379619598\n",
      "Iteration: 267/473, Loss: 0.10204126685857773\n",
      "Iteration: 268/473, Loss: 0.1526941955089569\n",
      "Iteration: 269/473, Loss: 0.17029346525669098\n",
      "Iteration: 270/473, Loss: 0.15331409871578217\n",
      "Iteration: 271/473, Loss: 0.14210326969623566\n",
      "Iteration: 272/473, Loss: 0.19182823598384857\n",
      "Iteration: 273/473, Loss: 0.1446339190006256\n",
      "Iteration: 274/473, Loss: 0.16577830910682678\n",
      "Iteration: 275/473, Loss: 0.1254151165485382\n",
      "Iteration: 276/473, Loss: 0.13965697586536407\n",
      "Iteration: 277/473, Loss: 0.18638207018375397\n",
      "Iteration: 278/473, Loss: 0.08654861897230148\n",
      "Iteration: 279/473, Loss: 0.17951710522174835\n",
      "Iteration: 280/473, Loss: 0.10110560059547424\n",
      "Iteration: 281/473, Loss: 0.18798410892486572\n",
      "Iteration: 282/473, Loss: 0.178141787648201\n",
      "Iteration: 283/473, Loss: 0.15360058844089508\n",
      "Iteration: 284/473, Loss: 0.13417956233024597\n",
      "Iteration: 285/473, Loss: 0.1073315367102623\n",
      "Iteration: 286/473, Loss: 0.14207862317562103\n",
      "Iteration: 287/473, Loss: 0.09707864373922348\n",
      "Iteration: 288/473, Loss: 0.21042819321155548\n",
      "Iteration: 289/473, Loss: 0.17661505937576294\n",
      "Iteration: 290/473, Loss: 0.1656310260295868\n",
      "Iteration: 291/473, Loss: 0.15458284318447113\n",
      "Iteration: 292/473, Loss: 0.14130553603172302\n",
      "Iteration: 293/473, Loss: 0.14438219368457794\n",
      "Iteration: 294/473, Loss: 0.1424412727355957\n",
      "Iteration: 295/473, Loss: 0.17862017452716827\n",
      "Iteration: 296/473, Loss: 0.12664289772510529\n",
      "Iteration: 297/473, Loss: 0.1015733852982521\n",
      "Iteration: 298/473, Loss: 0.1725398302078247\n",
      "Iteration: 299/473, Loss: 0.2098274677991867\n",
      "Iteration: 300/473, Loss: 0.2281712293624878\n",
      "Iteration: 301/473, Loss: 0.13989299535751343\n",
      "Iteration: 302/473, Loss: 0.13819192349910736\n",
      "Iteration: 303/473, Loss: 0.1947375237941742\n",
      "Iteration: 304/473, Loss: 0.17668041586875916\n",
      "Iteration: 305/473, Loss: 0.16460604965686798\n",
      "Iteration: 306/473, Loss: 0.18757054209709167\n",
      "Iteration: 307/473, Loss: 0.15285052359104156\n",
      "Iteration: 308/473, Loss: 0.19513888657093048\n",
      "Iteration: 309/473, Loss: 0.17253243923187256\n",
      "Iteration: 310/473, Loss: 0.09438767284154892\n",
      "Iteration: 311/473, Loss: 0.13922029733657837\n",
      "Iteration: 312/473, Loss: 0.14578723907470703\n",
      "Iteration: 313/473, Loss: 0.12472857534885406\n",
      "Iteration: 314/473, Loss: 0.12480928003787994\n",
      "Iteration: 315/473, Loss: 0.15529009699821472\n",
      "Iteration: 316/473, Loss: 0.13195574283599854\n",
      "Iteration: 317/473, Loss: 0.1916763186454773\n",
      "Iteration: 318/473, Loss: 0.12235141545534134\n",
      "Iteration: 319/473, Loss: 0.18520885705947876\n",
      "Iteration: 320/473, Loss: 0.17942848801612854\n",
      "Iteration: 321/473, Loss: 0.17348109185695648\n",
      "Iteration: 322/473, Loss: 0.193800151348114\n",
      "Iteration: 323/473, Loss: 0.09086517989635468\n",
      "Iteration: 324/473, Loss: 0.14069432020187378\n",
      "Iteration: 325/473, Loss: 0.13110649585723877\n",
      "Iteration: 326/473, Loss: 0.15530811250209808\n",
      "Iteration: 327/473, Loss: 0.11075270175933838\n",
      "Iteration: 328/473, Loss: 0.17798253893852234\n",
      "Iteration: 329/473, Loss: 0.09923557192087173\n",
      "Iteration: 330/473, Loss: 0.11766194552183151\n",
      "Iteration: 331/473, Loss: 0.1399676352739334\n",
      "Iteration: 332/473, Loss: 0.15150845050811768\n",
      "Iteration: 333/473, Loss: 0.10901781916618347\n",
      "Iteration: 334/473, Loss: 0.1359732449054718\n",
      "Iteration: 335/473, Loss: 0.16696509718894958\n",
      "Iteration: 336/473, Loss: 0.1506459265947342\n",
      "Iteration: 337/473, Loss: 0.13575954735279083\n",
      "Iteration: 338/473, Loss: 0.1634116768836975\n",
      "Iteration: 339/473, Loss: 0.2240365743637085\n",
      "Iteration: 340/473, Loss: 0.15862758457660675\n",
      "Iteration: 341/473, Loss: 0.13100126385688782\n",
      "Iteration: 342/473, Loss: 0.17596331238746643\n",
      "Iteration: 343/473, Loss: 0.11081113666296005\n",
      "Iteration: 344/473, Loss: 0.13442879915237427\n",
      "Iteration: 345/473, Loss: 0.1604926586151123\n",
      "Iteration: 346/473, Loss: 0.1763528287410736\n",
      "Iteration: 347/473, Loss: 0.12556178867816925\n",
      "Iteration: 348/473, Loss: 0.13659614324569702\n",
      "Iteration: 349/473, Loss: 0.1301799863576889\n",
      "Iteration: 350/473, Loss: 0.1294688880443573\n",
      "Iteration: 351/473, Loss: 0.11247257143259048\n",
      "Iteration: 352/473, Loss: 0.10595675557851791\n",
      "Iteration: 353/473, Loss: 0.1449640393257141\n",
      "Iteration: 354/473, Loss: 0.1325364112854004\n",
      "Iteration: 355/473, Loss: 0.13060452044010162\n",
      "Iteration: 356/473, Loss: 0.16151012480258942\n",
      "Iteration: 357/473, Loss: 0.1061847135424614\n",
      "Iteration: 358/473, Loss: 0.12685030698776245\n",
      "Iteration: 359/473, Loss: 0.15172843635082245\n",
      "Iteration: 360/473, Loss: 0.1470969170331955\n",
      "Iteration: 361/473, Loss: 0.16442082822322845\n",
      "Iteration: 362/473, Loss: 0.14397382736206055\n",
      "Iteration: 363/473, Loss: 0.1413959562778473\n",
      "Iteration: 364/473, Loss: 0.10603149980306625\n",
      "Iteration: 365/473, Loss: 0.19126836955547333\n",
      "Iteration: 366/473, Loss: 0.15397687256336212\n",
      "Iteration: 367/473, Loss: 0.14926718175411224\n",
      "Iteration: 368/473, Loss: 0.13882918655872345\n",
      "Iteration: 369/473, Loss: 0.13310866057872772\n",
      "Iteration: 370/473, Loss: 0.1732337921857834\n",
      "Iteration: 371/473, Loss: 0.1329513043165207\n",
      "Iteration: 372/473, Loss: 0.15808188915252686\n",
      "Iteration: 373/473, Loss: 0.13789620995521545\n",
      "Iteration: 374/473, Loss: 0.10649073868989944\n",
      "Iteration: 375/473, Loss: 0.18704885244369507\n",
      "Iteration: 376/473, Loss: 0.1821645349264145\n",
      "Iteration: 377/473, Loss: 0.15107235312461853\n",
      "Iteration: 378/473, Loss: 0.12857866287231445\n",
      "Iteration: 379/473, Loss: 0.17979831993579865\n",
      "Iteration: 380/473, Loss: 0.13591568171977997\n",
      "Iteration: 381/473, Loss: 0.12325852364301682\n",
      "Iteration: 382/473, Loss: 0.1482825130224228\n",
      "Iteration: 383/473, Loss: 0.11830252408981323\n",
      "Iteration: 384/473, Loss: 0.1132822036743164\n",
      "Iteration: 385/473, Loss: 0.11956574022769928\n",
      "Iteration: 386/473, Loss: 0.16336993873119354\n",
      "Iteration: 387/473, Loss: 0.14926177263259888\n",
      "Iteration: 388/473, Loss: 0.1794860064983368\n",
      "Iteration: 389/473, Loss: 0.11851601302623749\n",
      "Iteration: 390/473, Loss: 0.10677099972963333\n",
      "Iteration: 391/473, Loss: 0.16304413974285126\n",
      "Iteration: 392/473, Loss: 0.11499956250190735\n",
      "Iteration: 393/473, Loss: 0.10245271772146225\n",
      "Iteration: 394/473, Loss: 0.1078057661652565\n",
      "Iteration: 395/473, Loss: 0.15014176070690155\n",
      "Iteration: 396/473, Loss: 0.16187874972820282\n",
      "Iteration: 397/473, Loss: 0.16385617852210999\n",
      "Iteration: 398/473, Loss: 0.1886463463306427\n",
      "Iteration: 399/473, Loss: 0.1404692828655243\n",
      "Iteration: 400/473, Loss: 0.15222866833209991\n",
      "Iteration: 401/473, Loss: 0.16202232241630554\n",
      "Iteration: 402/473, Loss: 0.14931434392929077\n",
      "Iteration: 403/473, Loss: 0.1703386902809143\n",
      "Iteration: 404/473, Loss: 0.13980820775032043\n",
      "Iteration: 405/473, Loss: 0.107265904545784\n",
      "Iteration: 406/473, Loss: 0.1465274691581726\n",
      "Iteration: 407/473, Loss: 0.17746664583683014\n",
      "Iteration: 408/473, Loss: 0.16047194600105286\n",
      "Iteration: 409/473, Loss: 0.14531992375850677\n",
      "Iteration: 410/473, Loss: 0.11454302817583084\n",
      "Iteration: 411/473, Loss: 0.147154301404953\n",
      "Iteration: 412/473, Loss: 0.1556287705898285\n",
      "Iteration: 413/473, Loss: 0.13924214243888855\n",
      "Iteration: 414/473, Loss: 0.16066382825374603\n",
      "Iteration: 415/473, Loss: 0.14941087365150452\n",
      "Iteration: 416/473, Loss: 0.20273849368095398\n",
      "Iteration: 417/473, Loss: 0.13118696212768555\n",
      "Iteration: 418/473, Loss: 0.16468752920627594\n",
      "Iteration: 419/473, Loss: 0.1300472915172577\n",
      "Iteration: 420/473, Loss: 0.15429797768592834\n",
      "Iteration: 421/473, Loss: 0.1477743238210678\n",
      "Iteration: 422/473, Loss: 0.1524699181318283\n",
      "Iteration: 423/473, Loss: 0.17538386583328247\n",
      "Iteration: 424/473, Loss: 0.12565653026103973\n",
      "Iteration: 425/473, Loss: 0.10356482118368149\n",
      "Iteration: 426/473, Loss: 0.07208869606256485\n",
      "Iteration: 427/473, Loss: 0.10060257464647293\n",
      "Iteration: 428/473, Loss: 0.16878929734230042\n",
      "Iteration: 429/473, Loss: 0.08684928715229034\n",
      "Iteration: 430/473, Loss: 0.11852746456861496\n",
      "Iteration: 431/473, Loss: 0.09886978566646576\n",
      "Iteration: 432/473, Loss: 0.09358984231948853\n",
      "Iteration: 433/473, Loss: 0.08692783862352371\n",
      "Iteration: 434/473, Loss: 0.1481187641620636\n",
      "Iteration: 435/473, Loss: 0.18766547739505768\n",
      "Iteration: 436/473, Loss: 0.12341559678316116\n",
      "Iteration: 437/473, Loss: 0.1596623808145523\n",
      "Iteration: 438/473, Loss: 0.1945093870162964\n",
      "Iteration: 439/473, Loss: 0.12422634661197662\n",
      "Iteration: 440/473, Loss: 0.17825983464717865\n",
      "Iteration: 441/473, Loss: 0.1519085168838501\n",
      "Iteration: 442/473, Loss: 0.21787375211715698\n",
      "Iteration: 443/473, Loss: 0.09839379787445068\n",
      "Iteration: 444/473, Loss: 0.12331902235746384\n",
      "Iteration: 445/473, Loss: 0.0772896260023117\n",
      "Iteration: 446/473, Loss: 0.10590196400880814\n",
      "Iteration: 447/473, Loss: 0.11494408547878265\n",
      "Iteration: 448/473, Loss: 0.16829977929592133\n",
      "Iteration: 449/473, Loss: 0.11270619183778763\n",
      "Iteration: 450/473, Loss: 0.11654655635356903\n",
      "Iteration: 451/473, Loss: 0.14992009103298187\n",
      "Iteration: 452/473, Loss: 0.18810772895812988\n",
      "Iteration: 453/473, Loss: 0.16717255115509033\n",
      "Iteration: 454/473, Loss: 0.13815774023532867\n",
      "Iteration: 455/473, Loss: 0.19301435351371765\n",
      "Iteration: 456/473, Loss: 0.16590136289596558\n",
      "Iteration: 457/473, Loss: 0.3260865807533264\n",
      "Iteration: 458/473, Loss: 0.17060063779354095\n",
      "Iteration: 459/473, Loss: 0.15046297013759613\n",
      "Iteration: 460/473, Loss: 0.16134588420391083\n",
      "Iteration: 461/473, Loss: 0.16008339822292328\n",
      "Iteration: 462/473, Loss: 0.1292777806520462\n",
      "Iteration: 463/473, Loss: 0.19570879638195038\n",
      "Iteration: 464/473, Loss: 0.11253582686185837\n",
      "Iteration: 465/473, Loss: 0.13376164436340332\n",
      "Iteration: 466/473, Loss: 0.19563323259353638\n",
      "Iteration: 467/473, Loss: 0.18082667887210846\n",
      "Iteration: 468/473, Loss: 0.15275786817073822\n",
      "Iteration: 469/473, Loss: 0.1295454353094101\n",
      "Iteration: 470/473, Loss: 0.1463857740163803\n",
      "Iteration: 471/473, Loss: 0.12704652547836304\n",
      "Iteration: 472/473, Loss: 0.14883223176002502\n",
      "Iteration: 473/473, Loss: 0.1544073224067688\n"
     ]
    }
   ],
   "source": [
    "# 2 classes; Only target class or background\n",
    "num_classes = 2\n",
    "num_epochs = 1\n",
    "model = get_model_instance_segmentation(num_classes)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "    \n",
    "# parameters\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "len_dataloader = len(data_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    i = 0    \n",
    "    for imgs, annotations in data_loader:\n",
    "        i += 1\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "        loss_dict = model(imgs, annotations)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Iteration: {i}/{len_dataloader}, Loss: {losses}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            #'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "            #'loss_train': train_loss,\n",
    "            #'loss_val': val_loss\n",
    "            #}, os.path.join(dataset_path, f'./checkpoints/model_detector_resnet50_{epoch}.pth'))\n",
    "            }, f'./checkpoints/model_detector_resnet50_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('mps')\n",
    "num_classes = 2\n",
    "num_epochs = 1\n",
    "model = get_model_instance_segmentation(num_classes)\n",
    "model.to(device)\n",
    "checkpoint = torch.load('checkpoints/model_detector_resnet50_0.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1144.7318, 41.82097, 1278.5386, 121.2058],\n",
       "  [1152.7927, 5.567641, 1246.3629, 134.04039]],\n",
       " [1, 1],\n",
       " [0.41962793, 0.3895109])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prediction(img_path, img_name, threshold):\n",
    "    model.eval()\n",
    "    img = Image.open(os.path.join(img_path, img_name))\n",
    "    transforms=get_transform()\n",
    "    img = transforms(img).to(device)\n",
    "    prediction = model([img])\n",
    "    pred_boxes = [[i[0], i[1], i[2], i[3]] for i in list(prediction[0]['boxes'].detach().cpu().numpy())]\n",
    "    pred_labels = list(prediction[0].get('labels').cpu().numpy())\n",
    "    pred_scores = list(prediction[0].get('scores').detach().cpu().numpy())\n",
    "    pred_tr = [pred_scores.index(x) for x in pred_scores if x > threshold][-1]\n",
    "    pred_labels = pred_labels[:pred_tr+1]\n",
    "    pred_boxes = pred_boxes[:pred_tr+1]\n",
    "    pred_scores = pred_scores[:pred_tr+1]\n",
    "    \n",
    "    #boxes = []\n",
    "    #for i in range(num_objs):\n",
    "    #    min = coco_annotation[i]['bbox'][0]\n",
    "    #    ymin = coco_annotation[i]['bbox'][1]\n",
    "    #    xmax = xmin + coco_annotation[i]['bbox'][2]\n",
    "    #    ymax = ymin + coco_annotation[i]['bbox'][3]\n",
    "    #    boxes.append([xmin, ymin, xmax, ymax])\n",
    "    \n",
    "    return pred_boxes, pred_labels, pred_scores\n",
    "\n",
    "\n",
    "\n",
    "img_path = 'data'\n",
    "img_name = 'rtsd-frames/autosave16_10_2012_08_58_25_5.jpg'\n",
    "threshold = 0.1\n",
    "prediction = get_prediction(img_path, img_name, threshold)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████████| 1/1 [19.0ms elapsed, 0s remaining, 56.4 samples/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?context=ipython&subscription=044e794a-c702-4ef2-9745-65e2258e361f\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x153e0ee80a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_predict_anno(img_path, img_name, threshold):\n",
    "\n",
    "    pred_boxes, pred_labels, pred_scores = get_prediction(img_path, img_name, threshold)\n",
    "\n",
    "    anno = {}\n",
    "\n",
    "    images = []\n",
    "    image_item = {}\n",
    "    image_item['id'] = 0\n",
    "    img = Image.open(os.path.join(img_path, img_name))\n",
    "    transforms=get_transform()\n",
    "    img = transforms(img).to(device)\n",
    "    image_item['width'] = img.shape[2]\n",
    "    image_item['height'] = img.shape[1]\n",
    "    image_item['file_name'] = img_name\n",
    "    images.append(image_item)\n",
    "    anno['images'] = images\n",
    "\n",
    "    annotations = []\n",
    "    for i in range(len(pred_boxes)):\n",
    "        anno_item = {}\n",
    "        anno_item['id'] = i\n",
    "        anno_item['image_id'] = 0\n",
    "        anno_item['category_id'] = int(pred_labels[i])\n",
    "        anno_item['area'] = (float(pred_boxes[i][2]) - float(pred_boxes[i][0]))*(float(pred_boxes[i][3]) - float(pred_boxes[i][1]))\n",
    "        anno_item['bbox'] = [float(pred_boxes[i][0]), float(pred_boxes[i][1]), float(pred_boxes[i][2]) - float(pred_boxes[i][0]), float(pred_boxes[i][3]) - float(pred_boxes[i][1])]\n",
    "        anno_item['iscrowd'] = 0\n",
    "        annotations.append(anno_item)\n",
    "    anno['annotations'] = annotations\n",
    "    \n",
    "    anno['categories'] = [{'id': 1, 'name': 'sign'}]\n",
    "\n",
    "    with open(os.path.join(img_path, 'predicted_anno.json'), 'w') as f:\n",
    "        json.dump(anno, f)#ensure_ascii=False, indent=4)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "    # загрузка изображения в fiftyone\n",
    "    data_path = img_path      # можно не указывать, если в JSON путь совпадает\n",
    "\n",
    "    # The path yo the COCO labels JSON file\n",
    "    labels_file = \"train_anno_bin_class.json\"\n",
    "    labels_path = os.path.join(img_path, 'predicted_anno.json')\n",
    "\n",
    "\n",
    "    # Import the dataset\n",
    "    dataset = fo.Dataset.from_dir(\n",
    "        dataset_type=fo.types.COCODetectionDataset,\n",
    "        data_path=data_path,\n",
    "        labels_path=labels_path\n",
    "    )\n",
    "    # Визуализация набора данных\n",
    "    session = fo.launch_app(dataset)\n",
    "\n",
    "\n",
    "    return anno\n",
    "\n",
    "\n",
    "img_path = 'data'\n",
    "img_name = 'rtsd-frames/autosave23_10_2012_11_27_23_1.jpg'\n",
    "threshold = 0.6\n",
    "prediction_anno = get_predict_anno(img_path, img_name, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/ds_env/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/anaconda3/envs/ds_env/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RTSD_dataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[39mfor\u001b[39;00m images, labels \u001b[39min\u001b[39;00m data_loader:\n\u001b[1;32m     16\u001b[0m     \u001b[39m# image shape is [batch_size, 3 (due to RGB), height, width]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     img \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mToPILImage()(images[\u001b[39m0\u001b[39m])\n\u001b[1;32m     18\u001b[0m     plt\u001b[39m.\u001b[39mimshow(img)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:443\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    442\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:389\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1044\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1037\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1044\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1046\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds_env/lib/python3.10/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds_env/lib/python3.10/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds_env/lib/python3.10/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds_env/lib/python3.10/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds_env/lib/python3.10/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds_env/lib/python3.10/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel \u001b[39m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(parent_w, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         f\u001b[39m.\u001b[39;49mwrite(fp\u001b[39m.\u001b[39;49mgetbuffer())\n\u001b[1;32m     63\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# data loader\n",
    "batch_size = 1\n",
    "num_workers = 4\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(my_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=num_workers\n",
    "                                         )\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for images, labels in data_loader:\n",
    "    # image shape is [batch_size, 3 (due to RGB), height, width]\n",
    "    img = transforms.ToPILImage()(images[0])\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
