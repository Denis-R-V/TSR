{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Denis-R-V/TSR/blob/main/sign_detector_augmentated_v1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ8-zW_yJ279"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis-R-V/TSR/blob/main/sign_detector.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xtJ8o7tJ27-"
      },
      "source": [
        "# Система распознавания дорожных знаков на датасете RTSD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "colab = False\n",
        "\n",
        "if colab == True:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    !pip install kaggle\n",
        "    !mkdir ~/.kaggle\n",
        "    !cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "    !kaggle datasets download watchman/rtsd-dataset\n",
        "    !unzip rtsd-dataset.zip\n",
        "    !rm rtsd-dataset.zip\n",
        "    !cp -r rtsd-frames/rtsd-frames/ .\n",
        "    !rm -r rtsd-frames/rtsd-frames/\n",
        "    !pip install fiftyone\n",
        "if colab == True:\n",
        "    dataset_path = '.'\n",
        "    checkpoints_path = '../content/drive/MyDrive/TSR/checkpoints'\n",
        "else:\n",
        "    dataset_path = 'data'\n",
        "    checkpoints_path = 'checkpoints'\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "#import matplotlib.patches as patches\n",
        "#%matplotlib inline\n",
        "\n",
        "#from pycocotools.coco import COCO\n",
        "#import fiftyone as fo\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "#from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "#from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models import resnet152\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from sklearn import metrics\n",
        "from torchvision import models\n",
        "#import cv2\n",
        "#PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k69EoY9zJ28Y"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRRoJ7Q4J28Z"
      },
      "source": [
        "### Загрузчик данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RTSD_dataset_classifier(Dataset):\n",
        "    def __init__(self, dataset_path, background_anno_file, dataset_anno_file, transforms, background_size = None):\n",
        "        \n",
        "        self.dataset_path = dataset_path\n",
        "        self.background_anno_file = background_anno_file\n",
        "        self.dataset_anno_file = dataset_anno_file\n",
        "        self.transforms = transforms\n",
        "        self.transforms_lib = None\n",
        "        try:\n",
        "            self.transforms.additional_targets == {}\n",
        "            self.transforms_lib = 'albumentations'\n",
        "        except:\n",
        "            self.transforms_lib = 'torchvision'\n",
        "        \n",
        "        with open(os.path.join(dataset_path, background_anno_file), 'r') as read_file:\n",
        "            self.background_anno = json.load(read_file)\n",
        "        read_file.close()\n",
        "\n",
        "        #self.df_backgrnd_anno = pd.DataFrame(self.background_anno.get('annotations'))[['image_id','bbox','category_id']]\n",
        "        #self.df_backgrnd_images = pd.DataFrame(self.background_anno.get('images'))[['id','file_name']]\n",
        "        #self.df_backgrnd = self.df_backgrnd_anno.merge(self.df_backgrnd_images, left_on='image_id', right_on='id',)[['file_name','bbox','category_id']]\n",
        "        df_backgrnd_anno = pd.DataFrame(self.background_anno.get('annotations'))[['image_id','bbox','category_id']]\n",
        "        df_backgrnd_images = pd.DataFrame(self.background_anno.get('images'))[['id','file_name']]\n",
        "        df_backgrnd = df_backgrnd_anno.merge(df_backgrnd_images, left_on='image_id', right_on='id',)[['file_name','bbox','category_id']]\n",
        "        if background_size is not None:\n",
        "            df_backgrnd = df_backgrnd.groupby('category_id', group_keys= False).apply(lambda x: x.sample(2, replace=True))\n",
        "\n",
        "        with open(os.path.join(dataset_path, dataset_anno_file), 'r') as read_file:\n",
        "            self.anno = json.load(read_file)\n",
        "        read_file.close()\n",
        "\n",
        "        #self.df_anno = pd.DataFrame(self.anno.get('annotations'))[['image_id','bbox','category_id']]\n",
        "        #self.df_images = pd.DataFrame(self.anno.get('images'))[['id','file_name']]\n",
        "        #self.df_dataset = self.df_anno.merge(self.df_images, left_on='image_id', right_on='id',)[['file_name','bbox','category_id']]\n",
        "\n",
        "        df_anno = pd.DataFrame(self.anno.get('annotations'))[['image_id','bbox','category_id']]\n",
        "        df_images = pd.DataFrame(self.anno.get('images'))[['id','file_name']]\n",
        "        self.df_dataset = df_anno.merge(df_images, left_on='image_id', right_on='id',)[['file_name','bbox','category_id']]\n",
        "        \n",
        "        self.df_dataset = pd.concat((df_backgrnd, self.df_dataset), axis=0)\n",
        "        self.df_dataset.reset_index(inplace=True)\n",
        "        del self.df_dataset['index']    \n",
        "        #self.labels = torch.eye(156)[self.df_dataset['category_id']]'''\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df_dataset.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.df_dataset.loc[index,'file_name']\n",
        "        bbox = self.df_dataset.loc[index,'bbox']\n",
        "        bbox = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]\n",
        "        img = Image.open(os.path.join(self.dataset_path, img_name))\n",
        "        img = img.crop(bbox)\n",
        "        \n",
        "        if self.transforms_lib == 'torchvision':\n",
        "            img = self.transforms(img)\n",
        "        elif self.transforms_lib == 'albumentations':\n",
        "            img = np.array(img).astype(np.float32)/255.\n",
        "            img = self.transforms(image=img)['image']\n",
        "            img = img.float()\n",
        "        else:\n",
        "            print('Ошибка выбора библиотеки аугментации')\n",
        "\n",
        "        label = torch.tensor(self.df_dataset.loc[index,'category_id'])\n",
        "    \n",
        "        \n",
        "        #from PIL import ImageOps\n",
        "        #old_img = Image.open(image_path)\n",
        "        # создание нового изображения с белым фоном\n",
        "        #new_image = ImageOps.expand(old_img, border=25, fill=(255,255,255))\n",
        "\n",
        "        return {'images':img, 'labels':label}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Send train=True fro training transforms and False for val/test transforms\n",
        "def get_transform(augmentation_lib = 'torchvision', train=False):\n",
        "    if augmentation_lib =='torchvision':\n",
        "        if train == True:\n",
        "            return transforms.Compose([transforms.Resize((224,224)),\n",
        "                                       #transforms.RandomPerspective(distortion_scale=0.4,p=0.7),\n",
        "                                       #transforms.ColorJitter(brightness=(0.4), contrast=(0.3), saturation=(0.3)),\n",
        "                                       #transforms.GaussianBlur(11, sigma=(0.1, 2.0)),\n",
        "                                       #transforms.RandomAdjustSharpness(5),\n",
        "                                       #transforms.RandomRotation(10),\n",
        "                                       #transforms.RandomResizedCrop((224,224), scale=(0.85, 1)), # Случайная обрезка изображения в диапахоне 85 - 100% и resize в исходный размер\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],      # 1 496\n",
        "                                                            [0.229, 0.224, 0.225]),\n",
        "                                       #transforms.RandomErasing(p = 0.4, scale = (0.003, 0.1)),\n",
        "                                       #transforms.RandomErasing(p = 0.6, scale = (0.003, 0.05)),\n",
        "                                       #transforms.RandomErasing(p = 0.6, scale = (0.003, 0.05)),\n",
        "                                       #transforms.RandomErasing(p = 0.6, scale = (0.003, 0.02)),\n",
        "                                       #transforms.RandomErasing(p = 0.6, scale = (0.003, 0.02)),\n",
        "                                       #transforms.RandomErasing(p = 0.6, scale = (0.001, 0.01)),\n",
        "                                       #transforms.RandomErasing(p = 0.6, scale = (0.001, 0.01)),\n",
        "                                       #transforms.RandomErasing(p = 0.6, scale = (0.001, 0.01)),\n",
        "                                       #transforms.RandomErasing(p = 0.6, scale = (0.001, 0.01)),\n",
        "                                       #transforms.RandomErasing(p = 0.6, scale = (0.001, 0.01)),\n",
        "                                       ])\n",
        "        else:\n",
        "            return transforms.Compose([transforms.Resize((224,224)),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize([0.485, 0.456, 0.406],      # 1 496\n",
        "                                                         [0.229, 0.224, 0.225])\n",
        "                                    ])   \n",
        "    \n",
        "    elif augmentation_lib =='albumentations':\n",
        "        if train==True:\n",
        "            return A.Compose([A.augmentations.geometric.resize.Resize (224, 224, interpolation=1, always_apply=False, p=1),\n",
        "                              A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
        "                              A.RandomFog(fog_coef_lower=0.2, fog_coef_upper=0.3, alpha_coef=0.1, p=0.05), #Туман\n",
        "                              A.RandomRain(brightness_coefficient=0.9, drop_width=1, blur_value=5, p=0.05),\n",
        "                              A.Rotate(limit=10, p=0.5),\n",
        "                              ToTensorV2(p=1.0)\n",
        "                              ])\n",
        "            \n",
        "        else:\n",
        "            return A.Compose([A.augmentations.geometric.resize.Resize (224, 224, interpolation=1, always_apply=False, p=1),\n",
        "                              ToTensorV2(p=1.0)\n",
        "                            ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_tvs = RTSD_dataset_classifier(dataset_path,\n",
        "                               background_anno_file = 'train_anno_reduced_background.json',\n",
        "                               dataset_anno_file = 'train_anno_reduced.json',\n",
        "                               transforms = get_transform(augmentation_lib = 'torchvision', train=True)\n",
        "                               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_sign(dataset, index):\n",
        "    item = dataset.__getitem__(index)\n",
        "    img = item['images']\n",
        "    target = item['labels']\n",
        "    #img, target = test.__getitem__(index)\n",
        "    img = img.permute(1, 2, 0).detach().numpy()\n",
        "    img = img*255\n",
        "    img = img.astype(np.uint8)\n",
        "    fig, a = plt.subplots(1,1)\n",
        "    #fig.set_size_inches(10,10)\n",
        "    display(int(target.cpu().detach().numpy()))\n",
        "    a.imshow(img)\n",
        "    return None\n",
        "plot_sign(test_tvs, 904)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_alb = RTSD_dataset_classifier(dataset_path,\n",
        "                               background_anno_file = 'train_anno_reduced_background.json',\n",
        "                               dataset_anno_file = 'train_anno_reduced.json',\n",
        "                               transforms = get_transform(augmentation_lib = 'albumentations', train=True)\n",
        "                               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_sign(dataset, index):\n",
        "    item = dataset.__getitem__(index)\n",
        "    img = item['images']\n",
        "    target = item['labels']\n",
        "    #img, target = test.__getitem__(index)\n",
        "    img = img.permute(1, 2, 0).detach().numpy()\n",
        "    img = img*255\n",
        "    img = img.astype(np.uint8)\n",
        "    fig, a = plt.subplots(1,1)\n",
        "    #fig.set_size_inches(10,10)\n",
        "    display(int(target.cpu().detach().numpy()))\n",
        "    a.imshow(img)\n",
        "    return None\n",
        "plot_sign(test_alb, 904)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J90qxR2RJ28Z"
      },
      "source": [
        "### Гиперпараметры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CI7vlkQPJ28Z"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device_id = 0\n",
        "if torch.cuda.is_available() == True:\n",
        "    device = f'cuda:{device_id}'\n",
        "elif torch.backends.mps.is_available() == True:\n",
        "    device = 'mps'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "\n",
        "model_name = 'resnet152_test_with_bg_v100_tvs_normalize_adam_001'\n",
        "\n",
        "last_epoch = None\n",
        "n_epochs = 10\n",
        "batch_size = 32\n",
        "num_classes = 156\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo40ASBXJ28Z"
      },
      "source": [
        "### Инициализация модели, задание оптимизатора и функции потерь"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "TNQ4zYcHtHId"
      },
      "outputs": [],
      "source": [
        "def create_model(num_classes):\n",
        "    model = resnet152(weights='ResNet152_Weights.IMAGENET1K_V2')\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    #model.fc = nn.Sequential(nn.Linear(2048, 1024), nn.Linear(1024, num_classes))\n",
        "    #model.fc = nn.Sequential(nn.Linear(2048, num_classes))\n",
        "    for param in model.fc.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    #torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='FasterRCNN_ResNet50_FPN_Weights.COCO_V1')\n",
        "    #in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    #model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint = torch.load(os.path.join(checkpoints_path, f'chkpt_classifier_{model_name}_{last_epoch}.pth'), map_location=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'losses_train', 'losses_val'])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "242586dd62d544a39c122c7b1ed6efc9",
            "78cb1778f71b45b88ffdb20bfe0cd66e",
            "6d83c78727204f529982e56c3bfe32c1",
            "55191ea6a8eb4574aff8a9bc21fdd55a",
            "ae7f4e349b634abd8b36184774421f7a",
            "e012c54a3a9f48b38c500c17227f67b8",
            "91eb94ac4f6347c6b7d860b73e3742da",
            "4146164713eb4c2db70cf52335398a3e",
            "e66226838c994913b2d58fd0db3f4282",
            "b17d80f4da05457781be26c19a1dca17",
            "8e403bce502349d28da4553899f80c33"
          ]
        },
        "id": "ZdWxX5-PJ28Z",
        "outputId": "d572c5f8-341f-46c4-adb3-14866216da69"
      },
      "outputs": [],
      "source": [
        "model = create_model(num_classes).to(device)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# parameters\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "#optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "#params = [p for p in model.parameters() if p.requires_grad]\n",
        "#optimizer = torch.optim.SGD(params, lr=0.003, momentum=0.9, weight_decay=0.0005)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.0005)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)\n",
        "\n",
        "\n",
        "#optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "    # and a learning rate scheduler\n",
        "#lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.9)\n",
        "\n",
        "\n",
        "# Загрузка весов модели, состояния оптимизатора и шедулера\n",
        "if last_epoch is not None:\n",
        "    checkpoint = torch.load(os.path.join(checkpoints_path, f'chkpt_classifier_{model_name}_{last_epoch}.pth'), map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    #lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
        "\n",
        "train_dataset = RTSD_dataset_classifier(dataset_path,\n",
        "                                        background_anno_file = 'train_anno_reduced_background.json',\n",
        "                                        dataset_anno_file = 'train_anno.json',\n",
        "                                        transforms = get_transform(augmentation_lib = 'torchvision', train=True)\n",
        "                                        )\n",
        "\n",
        "val_dataset = RTSD_dataset_classifier(dataset_path,\n",
        "                                      background_anno_file = 'val_anno_background.json',\n",
        "                                      dataset_anno_file = 'val_anno.json',\n",
        "                                      transforms = get_transform(augmentation_lib = 'torchvision', train=False),\n",
        "                                      background_size=100\n",
        "                                      )\n",
        "\n",
        "train_data_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    #sampler=SubsetRandomSampler(),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    #num_workers=4,\n",
        "    #collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_data_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    #sampler=SubsetRandomSampler(),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    #num_workers=4,\n",
        "    #collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YimGoL3J28Z"
      },
      "source": [
        "### Трейн луп"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(train_dataloader, epoch): \n",
        "    len_dataloader = len(train_dataloader)\n",
        "\n",
        "    training_loss=0\n",
        "    # для текущего accuracy\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    # для вывода метрик\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0        # training_loss\n",
        "    \n",
        "    for batch_idx, data in enumerate(train_dataloader):\n",
        "        \n",
        "        \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        #images, targets = data[0], data[1]\n",
        "        #images = images.to(device)\n",
        "        #targets = targets.to(device)\n",
        "        images = data['images'].to(device)\n",
        "        targets = data['labels'].to(device)\n",
        "        output = model(images)\n",
        "        loss = loss_function(output, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "       \n",
        "        running_loss = running_loss + ((1/(batch_idx+1))*(loss.data-running_loss))\n",
        "        if batch_idx%20 == 0:\n",
        "            print(f\"Batch Id {batch_idx} is having training loss of {running_loss}\")\n",
        "            print(loss.item())\n",
        "\n",
        "        pred = output.data.max(1,keepdim=True)[1]\n",
        "\n",
        "        # для текущего accuracy\n",
        "        correct += np.sum(np.squeeze(pred.eq(targets.data.view_as(pred))).cpu().numpy())\n",
        "        total += images.size(0)\n",
        "        print(f\"Epoch #{epoch}. Accuracy on batch {batch_idx}/{len_dataloader}  on Training is {(100*correct/total)}\")\n",
        "        \n",
        "        # для вывода метрик\n",
        "        y_true.extend([int(item) for item in targets])\n",
        "        y_pred.extend([int(item) for item in pred])\n",
        "\n",
        "        #images = list(image.to(device) for image in images)\n",
        "        #targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        #loss_dict = model(images, targets)\n",
        "        #loss = sum(loss for loss in loss_dict.values())\n",
        "        #running_loss += loss.item()\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "        #if batch_idx % 50 == 0:\n",
        "        #    print(f\"\\tЭпоха {epoch}. Итерация {batch_idx}/{len_dataloader}. Loss: {loss}\")\n",
        "    train_loss = running_loss/len(train_dataloader.dataset)\n",
        "    train_accuracy = metrics.accuracy_score(y_true, y_pred)\n",
        "    train_f1_micro = metrics.f1_score(y_true, y_pred, average=\"micro\")\n",
        "    train_f1_macro =  metrics.f1_score(y_true, y_pred, average=\"macro\")\n",
        "    train_f1_weighted = metrics.f1_score(y_true, y_pred, average=\"weighted\")\n",
        "    return train_loss, train_accuracy, train_f1_micro, train_f1_macro, train_f1_weighted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def val (val_dataloader, epoch):\n",
        "    len_dataloader = len(val_dataloader)\n",
        "\n",
        "    validation_loss=0\n",
        "    # для текущего accuracy\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    # для вывода метрик\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for batch_idx, data in enumerate(val_dataloader):\n",
        "        \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        #images, targets = data[0], data[1]\n",
        "        #images = images.to(device)\n",
        "        #targets = targets.to(device)\n",
        "        images = data['images'].to(device)\n",
        "        targets = data['labels'].to(device)\n",
        "        #with torch.no_grad():\n",
        "            \n",
        "        output = model(images)\n",
        "        loss = loss_function(output, targets)\n",
        "        \n",
        "        validation_loss = validation_loss + ((1/(batch_idx+1))*(loss.data-validation_loss))\n",
        "        #if batch_idx%20 == 0:\n",
        "        print(f\"Epoch #{epoch}. Batch Id {batch_idx}/{len_dataloader}  is having validation loss of {validation_loss}\")\n",
        "        print(loss.item())\n",
        "        pred = output.data.max(1,keepdim=True)[1]\n",
        "\n",
        "        # для текущего accuracy\n",
        "        correct += np.sum(np.squeeze(pred.eq(targets.data.view_as(pred))).cpu().numpy())\n",
        "        total += images.size(0)\n",
        "        print(f\"Epoch #{epoch}. Batch Id {batch_idx}/{len_dataloader}  is having validation accuracy of {(100*correct/total)}\")\n",
        "\n",
        "        # для вывода метрик\n",
        "        y_true.extend([int(item) for item in targets])\n",
        "        y_pred.extend([int(item) for item in pred])\n",
        "        #images = list(image.to(device) for image in images)\n",
        "        #targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        #loss_dict = model(images, targets)\n",
        "        #loss = sum(loss for loss in loss_dict.values())\n",
        "        #running_loss += loss.item()\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "        #if batch_idx % 50 == 0:\n",
        "        #    print(f\"\\tЭпоха {epoch}. Итерация {batch_idx}/{len_dataloader}. Loss: {loss}\")\n",
        "    val_loss = validation_loss/len(val_dataloader.dataset)\n",
        "    val_accuracy = metrics.accuracy_score(y_true, y_pred)\n",
        "    val_f1_micro = metrics.f1_score(y_true, y_pred, average=\"micro\")\n",
        "    val_f1_macro =  metrics.f1_score(y_true, y_pred, average=\"macro\")\n",
        "    val_f1_weighted = metrics.f1_score(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "\n",
        "    return val_loss, val_accuracy, val_f1_micro, val_f1_macro, val_f1_weighted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Id 0 is having training loss of 5.047523498535156\n",
            "5.047523498535156\n",
            "Epoch #0. Accuracy on batch 0/3013  on Training is 3.125\n",
            "Epoch #0. Accuracy on batch 1/3013  on Training is 3.125\n",
            "Epoch #0. Accuracy on batch 2/3013  on Training is 4.166666666666667\n",
            "Epoch #0. Accuracy on batch 3/3013  on Training is 5.46875\n",
            "Epoch #0. Accuracy on batch 4/3013  on Training is 7.5\n",
            "Epoch #0. Accuracy on batch 5/3013  on Training is 10.9375\n",
            "Epoch #0. Accuracy on batch 6/3013  on Training is 11.607142857142858\n",
            "Epoch #0. Accuracy on batch 7/3013  on Training is 14.0625\n",
            "Epoch #0. Accuracy on batch 8/3013  on Training is 15.972222222222221\n",
            "Epoch #0. Accuracy on batch 9/3013  on Training is 16.5625\n",
            "Epoch #0. Accuracy on batch 10/3013  on Training is 16.193181818181817\n",
            "Epoch #0. Accuracy on batch 11/3013  on Training is 17.1875\n",
            "Epoch #0. Accuracy on batch 12/3013  on Training is 18.028846153846153\n",
            "Epoch #0. Accuracy on batch 13/3013  on Training is 17.857142857142858\n",
            "Epoch #0. Accuracy on batch 14/3013  on Training is 17.5\n",
            "Epoch #0. Accuracy on batch 15/3013  on Training is 17.578125\n",
            "Epoch #0. Accuracy on batch 16/3013  on Training is 17.647058823529413\n",
            "Epoch #0. Accuracy on batch 17/3013  on Training is 18.229166666666668\n",
            "Epoch #0. Accuracy on batch 18/3013  on Training is 19.07894736842105\n",
            "Epoch #0. Accuracy on batch 19/3013  on Training is 19.375\n",
            "Batch Id 20 is having training loss of 3.8828868865966797\n",
            "3.3416903018951416\n",
            "Epoch #0. Accuracy on batch 20/3013  on Training is 20.089285714285715\n",
            "Epoch #0. Accuracy on batch 21/3013  on Training is 20.170454545454547\n",
            "Epoch #0. Accuracy on batch 22/3013  on Training is 20.78804347826087\n",
            "Epoch #0. Accuracy on batch 23/3013  on Training is 21.223958333333332\n",
            "Epoch #0. Accuracy on batch 24/3013  on Training is 22.125\n",
            "Epoch #0. Accuracy on batch 25/3013  on Training is 22.95673076923077\n",
            "Epoch #0. Accuracy on batch 26/3013  on Training is 23.14814814814815\n",
            "Epoch #0. Accuracy on batch 27/3013  on Training is 23.772321428571427\n",
            "Epoch #0. Accuracy on batch 28/3013  on Training is 24.030172413793103\n",
            "Epoch #0. Accuracy on batch 29/3013  on Training is 25.3125\n",
            "Epoch #0. Accuracy on batch 30/3013  on Training is 25.403225806451612\n",
            "Epoch #0. Accuracy on batch 31/3013  on Training is 25.68359375\n",
            "Epoch #0. Accuracy on batch 32/3013  on Training is 26.231060606060606\n",
            "Epoch #0. Accuracy on batch 33/3013  on Training is 26.378676470588236\n",
            "Epoch #0. Accuracy on batch 34/3013  on Training is 27.410714285714285\n",
            "Epoch #0. Accuracy on batch 35/3013  on Training is 27.69097222222222\n",
            "Epoch #0. Accuracy on batch 36/3013  on Training is 27.78716216216216\n",
            "Epoch #0. Accuracy on batch 37/3013  on Training is 27.87828947368421\n",
            "Epoch #0. Accuracy on batch 38/3013  on Training is 28.044871794871796\n",
            "Epoch #0. Accuracy on batch 39/3013  on Training is 28.203125\n",
            "Batch Id 40 is having training loss of 3.535346746444702\n",
            "3.4198832511901855\n",
            "Epoch #0. Accuracy on batch 40/3013  on Training is 28.125\n",
            "Epoch #0. Accuracy on batch 41/3013  on Training is 28.645833333333332\n",
            "Epoch #0. Accuracy on batch 42/3013  on Training is 29.069767441860463\n",
            "Epoch #0. Accuracy on batch 43/3013  on Training is 29.332386363636363\n",
            "Epoch #0. Accuracy on batch 44/3013  on Training is 29.166666666666668\n",
            "Epoch #0. Accuracy on batch 45/3013  on Training is 29.483695652173914\n",
            "Epoch #0. Accuracy on batch 46/3013  on Training is 29.654255319148938\n",
            "Epoch #0. Accuracy on batch 47/3013  on Training is 30.143229166666668\n",
            "Epoch #0. Accuracy on batch 48/3013  on Training is 30.229591836734695\n",
            "Epoch #0. Accuracy on batch 49/3013  on Training is 30.4375\n",
            "Epoch #0. Accuracy on batch 50/3013  on Training is 30.637254901960784\n",
            "Epoch #0. Accuracy on batch 51/3013  on Training is 30.76923076923077\n",
            "Epoch #0. Accuracy on batch 52/3013  on Training is 30.89622641509434\n",
            "Epoch #0. Accuracy on batch 53/3013  on Training is 31.30787037037037\n",
            "Epoch #0. Accuracy on batch 54/3013  on Training is 31.306818181818183\n",
            "Epoch #0. Accuracy on batch 55/3013  on Training is 31.361607142857142\n",
            "Epoch #0. Accuracy on batch 56/3013  on Training is 31.907894736842106\n",
            "Epoch #0. Accuracy on batch 57/3013  on Training is 32.16594827586207\n",
            "Epoch #0. Accuracy on batch 58/3013  on Training is 32.25635593220339\n",
            "Epoch #0. Accuracy on batch 59/3013  on Training is 32.447916666666664\n",
            "Batch Id 60 is having training loss of 3.2717747688293457\n",
            "2.7617897987365723\n",
            "Epoch #0. Accuracy on batch 60/3013  on Training is 32.53073770491803\n",
            "Epoch #0. Accuracy on batch 61/3013  on Training is 32.86290322580645\n",
            "Epoch #0. Accuracy on batch 62/3013  on Training is 33.08531746031746\n",
            "Epoch #0. Accuracy on batch 63/3013  on Training is 33.447265625\n",
            "Epoch #0. Accuracy on batch 64/3013  on Training is 33.50961538461539\n",
            "Epoch #0. Accuracy on batch 65/3013  on Training is 33.66477272727273\n",
            "Epoch #0. Accuracy on batch 66/3013  on Training is 34.00186567164179\n",
            "Epoch #0. Accuracy on batch 67/3013  on Training is 34.32904411764706\n",
            "Epoch #0. Accuracy on batch 68/3013  on Training is 34.42028985507246\n",
            "Epoch #0. Accuracy on batch 69/3013  on Training is 34.82142857142857\n",
            "Epoch #0. Accuracy on batch 70/3013  on Training is 35.03521126760563\n",
            "Epoch #0. Accuracy on batch 71/3013  on Training is 35.19965277777778\n",
            "Epoch #0. Accuracy on batch 72/3013  on Training is 35.488013698630134\n",
            "Epoch #0. Accuracy on batch 73/3013  on Training is 35.76858108108108\n",
            "Epoch #0. Accuracy on batch 74/3013  on Training is 36.041666666666664\n",
            "Epoch #0. Accuracy on batch 75/3013  on Training is 36.0608552631579\n",
            "Epoch #0. Accuracy on batch 76/3013  on Training is 36.160714285714285\n",
            "Epoch #0. Accuracy on batch 77/3013  on Training is 36.33814102564103\n",
            "Epoch #0. Accuracy on batch 78/3013  on Training is 36.629746835443036\n",
            "Epoch #0. Accuracy on batch 79/3013  on Training is 36.8359375\n",
            "Batch Id 80 is having training loss of 3.105609655380249\n",
            "2.28950834274292\n",
            "Epoch #0. Accuracy on batch 80/3013  on Training is 37.03703703703704\n",
            "Epoch #0. Accuracy on batch 81/3013  on Training is 37.271341463414636\n",
            "Epoch #0. Accuracy on batch 82/3013  on Training is 37.46234939759036\n",
            "Epoch #0. Accuracy on batch 83/3013  on Training is 37.53720238095238\n",
            "Epoch #0. Accuracy on batch 84/3013  on Training is 37.64705882352941\n",
            "Epoch #0. Accuracy on batch 85/3013  on Training is 37.68168604651163\n",
            "Epoch #0. Accuracy on batch 86/3013  on Training is 38.002873563218394\n",
            "Epoch #0. Accuracy on batch 87/3013  on Training is 38.21022727272727\n",
            "Epoch #0. Accuracy on batch 88/3013  on Training is 38.27247191011236\n",
            "Epoch #0. Accuracy on batch 89/3013  on Training is 38.40277777777778\n",
            "Epoch #0. Accuracy on batch 90/3013  on Training is 38.46153846153846\n",
            "Epoch #0. Accuracy on batch 91/3013  on Training is 38.65489130434783\n",
            "Epoch #0. Accuracy on batch 92/3013  on Training is 38.575268817204304\n",
            "Epoch #0. Accuracy on batch 93/3013  on Training is 38.630319148936174\n",
            "Epoch #0. Accuracy on batch 94/3013  on Training is 38.68421052631579\n",
            "Epoch #0. Accuracy on batch 95/3013  on Training is 39.029947916666664\n",
            "Epoch #0. Accuracy on batch 96/3013  on Training is 39.11082474226804\n",
            "Epoch #0. Accuracy on batch 97/3013  on Training is 39.317602040816325\n",
            "Epoch #0. Accuracy on batch 98/3013  on Training is 39.36237373737374\n",
            "Epoch #0. Accuracy on batch 99/3013  on Training is 39.5625\n",
            "Batch Id 100 is having training loss of 2.990072011947632\n",
            "2.8032402992248535\n",
            "Epoch #0. Accuracy on batch 100/3013  on Training is 39.573019801980195\n",
            "Epoch #0. Accuracy on batch 101/3013  on Training is 39.64460784313726\n",
            "Epoch #0. Accuracy on batch 102/3013  on Training is 39.71480582524272\n",
            "Epoch #0. Accuracy on batch 103/3013  on Training is 39.99399038461539\n",
            "Epoch #0. Accuracy on batch 104/3013  on Training is 40.23809523809524\n",
            "Epoch #0. Accuracy on batch 105/3013  on Training is 40.389150943396224\n",
            "Epoch #0. Accuracy on batch 106/3013  on Training is 40.654205607476634\n",
            "Epoch #0. Accuracy on batch 107/3013  on Training is 40.8275462962963\n",
            "Epoch #0. Accuracy on batch 108/3013  on Training is 40.940366972477065\n",
            "Epoch #0. Accuracy on batch 109/3013  on Training is 41.02272727272727\n",
            "Epoch #0. Accuracy on batch 110/3013  on Training is 41.1036036036036\n",
            "Epoch #0. Accuracy on batch 111/3013  on Training is 41.35044642857143\n",
            "Epoch #0. Accuracy on batch 112/3013  on Training is 41.50995575221239\n",
            "Epoch #0. Accuracy on batch 113/3013  on Training is 41.584429824561404\n",
            "Epoch #0. Accuracy on batch 114/3013  on Training is 41.60326086956522\n",
            "Epoch #0. Accuracy on batch 115/3013  on Training is 41.64870689655172\n",
            "Epoch #0. Accuracy on batch 116/3013  on Training is 41.93376068376068\n",
            "Epoch #0. Accuracy on batch 117/3013  on Training is 42.02860169491525\n",
            "Epoch #0. Accuracy on batch 118/3013  on Training is 42.148109243697476\n",
            "Epoch #0. Accuracy on batch 119/3013  on Training is 42.239583333333336\n",
            "Batch Id 120 is having training loss of 2.856966257095337\n",
            "2.201840877532959\n",
            "Epoch #0. Accuracy on batch 120/3013  on Training is 42.35537190082645\n",
            "Epoch #0. Accuracy on batch 121/3013  on Training is 42.443647540983605\n",
            "Epoch #0. Accuracy on batch 122/3013  on Training is 42.53048780487805\n",
            "Epoch #0. Accuracy on batch 123/3013  on Training is 42.54032258064516\n",
            "Epoch #0. Accuracy on batch 124/3013  on Training is 42.675\n",
            "Epoch #0. Accuracy on batch 125/3013  on Training is 42.757936507936506\n",
            "Epoch #0. Accuracy on batch 126/3013  on Training is 42.88877952755905\n",
            "Epoch #0. Accuracy on batch 127/3013  on Training is 42.919921875\n",
            "Epoch #0. Accuracy on batch 128/3013  on Training is 43.04748062015504\n",
            "Epoch #0. Accuracy on batch 129/3013  on Training is 43.19711538461539\n",
            "Epoch #0. Accuracy on batch 130/3013  on Training is 43.3206106870229\n",
            "Epoch #0. Accuracy on batch 131/3013  on Training is 43.39488636363637\n",
            "Epoch #0. Accuracy on batch 132/3013  on Training is 43.49154135338346\n",
            "Epoch #0. Accuracy on batch 133/3013  on Training is 43.54011194029851\n",
            "Epoch #0. Accuracy on batch 134/3013  on Training is 43.63425925925926\n",
            "Epoch #0. Accuracy on batch 135/3013  on Training is 43.79595588235294\n",
            "Epoch #0. Accuracy on batch 136/3013  on Training is 43.97810218978102\n",
            "Epoch #0. Accuracy on batch 137/3013  on Training is 44.134963768115945\n",
            "Epoch #0. Accuracy on batch 138/3013  on Training is 44.132194244604314\n",
            "Epoch #0. Accuracy on batch 139/3013  on Training is 44.19642857142857\n",
            "Batch Id 140 is having training loss of 2.7527337074279785\n",
            "1.6189826726913452\n",
            "Epoch #0. Accuracy on batch 140/3013  on Training is 44.3927304964539\n",
            "Epoch #0. Accuracy on batch 141/3013  on Training is 44.278169014084504\n",
            "Epoch #0. Accuracy on batch 142/3013  on Training is 44.42744755244755\n",
            "Epoch #0. Accuracy on batch 143/3013  on Training is 44.42274305555556\n",
            "Epoch #0. Accuracy on batch 144/3013  on Training is 44.50431034482759\n",
            "Epoch #0. Accuracy on batch 145/3013  on Training is 44.62756849315068\n",
            "Epoch #0. Accuracy on batch 146/3013  on Training is 44.70663265306123\n",
            "Epoch #0. Accuracy on batch 147/3013  on Training is 44.80574324324324\n",
            "Epoch #0. Accuracy on batch 148/3013  on Training is 44.90352348993289\n",
            "Epoch #0. Accuracy on batch 149/3013  on Training is 44.916666666666664\n",
            "Epoch #0. Accuracy on batch 150/3013  on Training is 44.950331125827816\n",
            "Epoch #0. Accuracy on batch 151/3013  on Training is 45.12746710526316\n",
            "Epoch #0. Accuracy on batch 152/3013  on Training is 45.15931372549019\n",
            "Epoch #0. Accuracy on batch 153/3013  on Training is 45.21103896103896\n",
            "Epoch #0. Accuracy on batch 154/3013  on Training is 45.34274193548387\n",
            "Epoch #0. Accuracy on batch 155/3013  on Training is 45.392628205128204\n",
            "Epoch #0. Accuracy on batch 156/3013  on Training is 45.42197452229299\n",
            "Epoch #0. Accuracy on batch 157/3013  on Training is 45.53006329113924\n",
            "Epoch #0. Accuracy on batch 158/3013  on Training is 45.53852201257862\n",
            "Epoch #0. Accuracy on batch 159/3013  on Training is 45.6640625\n",
            "Batch Id 160 is having training loss of 2.6751620769500732\n",
            "1.9120447635650635\n",
            "Epoch #0. Accuracy on batch 160/3013  on Training is 45.74922360248447\n",
            "Epoch #0. Accuracy on batch 161/3013  on Training is 45.77546296296296\n",
            "Epoch #0. Accuracy on batch 162/3013  on Training is 45.85889570552147\n",
            "Epoch #0. Accuracy on batch 163/3013  on Training is 46.017530487804876\n",
            "Epoch #0. Accuracy on batch 164/3013  on Training is 46.15530303030303\n",
            "Epoch #0. Accuracy on batch 165/3013  on Training is 46.31024096385542\n",
            "Epoch #0. Accuracy on batch 166/3013  on Training is 46.369760479041915\n",
            "Epoch #0. Accuracy on batch 167/3013  on Training is 46.42857142857143\n",
            "Epoch #0. Accuracy on batch 168/3013  on Training is 46.542159763313606\n",
            "Epoch #0. Accuracy on batch 169/3013  on Training is 46.67279411764706\n",
            "Epoch #0. Accuracy on batch 170/3013  on Training is 46.692251461988306\n",
            "Epoch #0. Accuracy on batch 171/3013  on Training is 46.80232558139535\n",
            "Epoch #0. Accuracy on batch 172/3013  on Training is 46.80274566473989\n",
            "Epoch #0. Accuracy on batch 173/3013  on Training is 46.839080459770116\n",
            "Epoch #0. Accuracy on batch 174/3013  on Training is 46.839285714285715\n",
            "Epoch #0. Accuracy on batch 175/3013  on Training is 46.94602272727273\n",
            "Epoch #0. Accuracy on batch 176/3013  on Training is 47.08686440677966\n",
            "Epoch #0. Accuracy on batch 177/3013  on Training is 47.208567415730336\n",
            "Epoch #0. Accuracy on batch 178/3013  on Training is 47.17178770949721\n",
            "Epoch #0. Accuracy on batch 179/3013  on Training is 47.22222222222222\n",
            "Batch Id 180 is having training loss of 2.597167730331421\n",
            "2.0018439292907715\n",
            "Epoch #0. Accuracy on batch 180/3013  on Training is 47.32389502762431\n",
            "Epoch #0. Accuracy on batch 181/3013  on Training is 47.37293956043956\n",
            "Epoch #0. Accuracy on batch 182/3013  on Training is 47.42144808743169\n",
            "Epoch #0. Accuracy on batch 183/3013  on Training is 47.41847826086956\n",
            "Epoch #0. Accuracy on batch 184/3013  on Training is 47.5\n",
            "Epoch #0. Accuracy on batch 185/3013  on Training is 47.61424731182796\n",
            "Epoch #0. Accuracy on batch 186/3013  on Training is 47.643716577540104\n",
            "Epoch #0. Accuracy on batch 187/3013  on Training is 47.73936170212766\n",
            "Epoch #0. Accuracy on batch 188/3013  on Training is 47.817460317460316\n",
            "Epoch #0. Accuracy on batch 189/3013  on Training is 47.87828947368421\n",
            "Epoch #0. Accuracy on batch 190/3013  on Training is 47.922120418848166\n",
            "Epoch #0. Accuracy on batch 191/3013  on Training is 47.998046875\n",
            "Epoch #0. Accuracy on batch 192/3013  on Training is 48.056994818652846\n",
            "Epoch #0. Accuracy on batch 193/3013  on Training is 48.09922680412371\n",
            "Epoch #0. Accuracy on batch 194/3013  on Training is 48.17307692307692\n",
            "Epoch #0. Accuracy on batch 195/3013  on Training is 48.19834183673469\n",
            "Epoch #0. Accuracy on batch 196/3013  on Training is 48.30266497461929\n",
            "Epoch #0. Accuracy on batch 197/3013  on Training is 48.405934343434346\n",
            "Epoch #0. Accuracy on batch 198/3013  on Training is 48.539572864321606\n",
            "Epoch #0. Accuracy on batch 199/3013  on Training is 48.578125\n",
            "Batch Id 200 is having training loss of 2.5197412967681885\n",
            "1.6552557945251465\n",
            "Epoch #0. Accuracy on batch 200/3013  on Training is 48.6318407960199\n",
            "Epoch #0. Accuracy on batch 201/3013  on Training is 48.65408415841584\n",
            "Epoch #0. Accuracy on batch 202/3013  on Training is 48.676108374384235\n",
            "Epoch #0. Accuracy on batch 203/3013  on Training is 48.743872549019606\n",
            "Epoch #0. Accuracy on batch 204/3013  on Training is 48.6890243902439\n",
            "Epoch #0. Accuracy on batch 205/3013  on Training is 48.75606796116505\n",
            "Epoch #0. Accuracy on batch 206/3013  on Training is 48.867753623188406\n",
            "Epoch #0. Accuracy on batch 207/3013  on Training is 48.97836538461539\n",
            "Epoch #0. Accuracy on batch 208/3013  on Training is 48.9982057416268\n",
            "Epoch #0. Accuracy on batch 209/3013  on Training is 49.032738095238095\n",
            "Epoch #0. Accuracy on batch 210/3013  on Training is 49.12618483412322\n",
            "Epoch #0. Accuracy on batch 211/3013  on Training is 49.174528301886795\n",
            "Epoch #0. Accuracy on batch 212/3013  on Training is 49.178403755868544\n",
            "Epoch #0. Accuracy on batch 213/3013  on Training is 49.24065420560748\n",
            "Epoch #0. Accuracy on batch 214/3013  on Training is 49.31686046511628\n",
            "Epoch #0. Accuracy on batch 215/3013  on Training is 49.348958333333336\n",
            "Epoch #0. Accuracy on batch 216/3013  on Training is 49.380760368663594\n",
            "Epoch #0. Accuracy on batch 217/3013  on Training is 49.383600917431195\n",
            "Epoch #0. Accuracy on batch 218/3013  on Training is 49.42922374429224\n",
            "Epoch #0. Accuracy on batch 219/3013  on Training is 49.50284090909091\n",
            "Batch Id 220 is having training loss of 2.469716787338257\n",
            "1.8224695920944214\n",
            "Epoch #0. Accuracy on batch 220/3013  on Training is 49.51923076923077\n",
            "Epoch #0. Accuracy on batch 221/3013  on Training is 49.535472972972975\n",
            "Epoch #0. Accuracy on batch 222/3013  on Training is 49.59360986547085\n",
            "Epoch #0. Accuracy on batch 223/3013  on Training is 49.70703125\n",
            "Epoch #0. Accuracy on batch 224/3013  on Training is 49.708333333333336\n",
            "Epoch #0. Accuracy on batch 225/3013  on Training is 49.76493362831859\n",
            "Epoch #0. Accuracy on batch 226/3013  on Training is 49.765969162995596\n",
            "Epoch #0. Accuracy on batch 227/3013  on Training is 49.8766447368421\n",
            "Epoch #0. Accuracy on batch 228/3013  on Training is 49.890829694323145\n",
            "Epoch #0. Accuracy on batch 229/3013  on Training is 49.91847826086956\n",
            "Epoch #0. Accuracy on batch 230/3013  on Training is 49.95941558441559\n",
            "Epoch #0. Accuracy on batch 231/3013  on Training is 49.946120689655174\n",
            "Epoch #0. Accuracy on batch 232/3013  on Training is 49.95976394849785\n",
            "Epoch #0. Accuracy on batch 233/3013  on Training is 49.973290598290596\n",
            "Epoch #0. Accuracy on batch 234/3013  on Training is 49.973404255319146\n",
            "Epoch #0. Accuracy on batch 235/3013  on Training is 50.05296610169491\n",
            "Epoch #0. Accuracy on batch 236/3013  on Training is 50.06592827004219\n",
            "Epoch #0. Accuracy on batch 237/3013  on Training is 50.05252100840336\n",
            "Epoch #0. Accuracy on batch 238/3013  on Training is 50.05230125523013\n",
            "Epoch #0. Accuracy on batch 239/3013  on Training is 50.0390625\n",
            "Batch Id 240 is having training loss of 2.420571804046631\n",
            "1.5840333700180054\n",
            "Epoch #0. Accuracy on batch 240/3013  on Training is 50.11670124481328\n",
            "Epoch #0. Accuracy on batch 241/3013  on Training is 50.15495867768595\n",
            "Epoch #0. Accuracy on batch 242/3013  on Training is 50.21862139917695\n",
            "Epoch #0. Accuracy on batch 243/3013  on Training is 50.28176229508197\n",
            "Epoch #0. Accuracy on batch 244/3013  on Training is 50.28061224489796\n",
            "Epoch #0. Accuracy on batch 245/3013  on Training is 50.41920731707317\n",
            "Epoch #0. Accuracy on batch 246/3013  on Training is 50.506072874493924\n",
            "Epoch #0. Accuracy on batch 247/3013  on Training is 50.604838709677416\n",
            "Epoch #0. Accuracy on batch 248/3013  on Training is 50.640060240963855\n",
            "Epoch #0. Accuracy on batch 249/3013  on Training is 50.7125\n",
            "Epoch #0. Accuracy on batch 250/3013  on Training is 50.69721115537848\n",
            "Epoch #0. Accuracy on batch 251/3013  on Training is 50.75644841269841\n",
            "Epoch #0. Accuracy on batch 252/3013  on Training is 50.790513833992094\n",
            "Epoch #0. Accuracy on batch 253/3013  on Training is 50.86122047244095\n",
            "Epoch #0. Accuracy on batch 254/3013  on Training is 50.870098039215684\n",
            "Epoch #0. Accuracy on batch 255/3013  on Training is 50.87890625\n",
            "Epoch #0. Accuracy on batch 256/3013  on Training is 50.936284046692606\n",
            "Epoch #0. Accuracy on batch 257/3013  on Training is 50.92054263565891\n",
            "Epoch #0. Accuracy on batch 258/3013  on Training is 50.965250965250966\n",
            "Epoch #0. Accuracy on batch 259/3013  on Training is 50.96153846153846\n",
            "Batch Id 260 is having training loss of 2.3683342933654785\n",
            "1.8414517641067505\n",
            "Epoch #0. Accuracy on batch 260/3013  on Training is 50.99377394636015\n",
            "Epoch #0. Accuracy on batch 261/3013  on Training is 51.037690839694655\n",
            "Epoch #0. Accuracy on batch 262/3013  on Training is 51.10503802281369\n",
            "Epoch #0. Accuracy on batch 263/3013  on Training is 51.124526515151516\n",
            "Epoch #0. Accuracy on batch 264/3013  on Training is 51.132075471698116\n",
            "Epoch #0. Accuracy on batch 265/3013  on Training is 51.19830827067669\n",
            "Epoch #0. Accuracy on batch 266/3013  on Training is 51.20552434456929\n",
            "Epoch #0. Accuracy on batch 267/3013  on Training is 51.15438432835821\n",
            "Epoch #0. Accuracy on batch 268/3013  on Training is 51.16171003717472\n",
            "Epoch #0. Accuracy on batch 269/3013  on Training is 51.238425925925924\n",
            "Epoch #0. Accuracy on batch 270/3013  on Training is 51.268450184501845\n",
            "Epoch #0. Accuracy on batch 271/3013  on Training is 51.32123161764706\n",
            "Epoch #0. Accuracy on batch 272/3013  on Training is 51.37362637362637\n",
            "Epoch #0. Accuracy on batch 273/3013  on Training is 51.38001824817518\n",
            "Epoch #0. Accuracy on batch 274/3013  on Training is 51.38636363636363\n",
            "Epoch #0. Accuracy on batch 275/3013  on Training is 51.41530797101449\n",
            "Epoch #0. Accuracy on batch 276/3013  on Training is 51.45532490974729\n",
            "Epoch #0. Accuracy on batch 277/3013  on Training is 51.4613309352518\n",
            "Epoch #0. Accuracy on batch 278/3013  on Training is 51.52329749103943\n",
            "Epoch #0. Accuracy on batch 279/3013  on Training is 51.5625\n",
            "Batch Id 280 is having training loss of 2.3297879695892334\n",
            "2.54097318649292\n",
            "Epoch #0. Accuracy on batch 280/3013  on Training is 51.56806049822064\n",
            "Epoch #0. Accuracy on batch 281/3013  on Training is 51.606826241134755\n",
            "Epoch #0. Accuracy on batch 282/3013  on Training is 51.63427561837456\n",
            "Epoch #0. Accuracy on batch 283/3013  on Training is 51.70554577464789\n",
            "Epoch #0. Accuracy on batch 284/3013  on Training is 51.74342105263158\n",
            "Epoch #0. Accuracy on batch 285/3013  on Training is 51.78103146853147\n",
            "Epoch #0. Accuracy on batch 286/3013  on Training is 51.829268292682926\n",
            "Epoch #0. Accuracy on batch 287/3013  on Training is 51.833767361111114\n",
            "Epoch #0. Accuracy on batch 288/3013  on Training is 51.892301038062286\n",
            "Epoch #0. Accuracy on batch 289/3013  on Training is 51.9073275862069\n",
            "Epoch #0. Accuracy on batch 290/3013  on Training is 51.93298969072165\n",
            "Epoch #0. Accuracy on batch 291/3013  on Training is 51.96917808219178\n",
            "Epoch #0. Accuracy on batch 292/3013  on Training is 52.03711604095563\n",
            "Epoch #0. Accuracy on batch 293/3013  on Training is 52.10459183673469\n",
            "Epoch #0. Accuracy on batch 294/3013  on Training is 52.139830508474574\n",
            "Epoch #0. Accuracy on batch 295/3013  on Training is 52.185388513513516\n",
            "Epoch #0. Accuracy on batch 296/3013  on Training is 52.18855218855219\n",
            "Epoch #0. Accuracy on batch 297/3013  on Training is 52.22315436241611\n",
            "Epoch #0. Accuracy on batch 298/3013  on Training is 52.17391304347826\n",
            "Epoch #0. Accuracy on batch 299/3013  on Training is 52.145833333333336\n",
            "Batch Id 300 is having training loss of 2.29575514793396\n",
            "1.927912950515747\n",
            "Epoch #0. Accuracy on batch 300/3013  on Training is 52.16985049833887\n",
            "Epoch #0. Accuracy on batch 301/3013  on Training is 52.183360927152314\n",
            "Epoch #0. Accuracy on batch 302/3013  on Training is 52.26897689768977\n",
            "Epoch #0. Accuracy on batch 303/3013  on Training is 52.33347039473684\n",
            "Epoch #0. Accuracy on batch 304/3013  on Training is 52.3155737704918\n",
            "Epoch #0. Accuracy on batch 305/3013  on Training is 52.35906862745098\n",
            "Epoch #0. Accuracy on batch 306/3013  on Training is 52.42263843648208\n",
            "Epoch #0. Accuracy on batch 307/3013  on Training is 52.49594155844156\n",
            "Epoch #0. Accuracy on batch 308/3013  on Training is 52.54854368932039\n",
            "Epoch #0. Accuracy on batch 309/3013  on Training is 52.61088709677419\n",
            "Epoch #0. Accuracy on batch 310/3013  on Training is 52.652733118971064\n",
            "Epoch #0. Accuracy on batch 311/3013  on Training is 52.654246794871796\n",
            "Epoch #0. Accuracy on batch 312/3013  on Training is 52.695686900958464\n",
            "Epoch #0. Accuracy on batch 313/3013  on Training is 52.716958598726116\n",
            "Epoch #0. Accuracy on batch 314/3013  on Training is 52.71825396825397\n",
            "Epoch #0. Accuracy on batch 315/3013  on Training is 52.75909810126582\n",
            "Epoch #0. Accuracy on batch 316/3013  on Training is 52.77011041009464\n",
            "Epoch #0. Accuracy on batch 317/3013  on Training is 52.820361635220124\n",
            "Epoch #0. Accuracy on batch 318/3013  on Training is 52.850705329153605\n",
            "Epoch #0. Accuracy on batch 319/3013  on Training is 52.890625\n",
            "Batch Id 320 is having training loss of 2.2535386085510254\n",
            "1.6204957962036133\n",
            "Epoch #0. Accuracy on batch 320/3013  on Training is 52.93029595015577\n",
            "Epoch #0. Accuracy on batch 321/3013  on Training is 52.921195652173914\n",
            "Epoch #0. Accuracy on batch 322/3013  on Training is 52.950851393188856\n",
            "Epoch #0. Accuracy on batch 323/3013  on Training is 52.951388888888886\n",
            "Epoch #0. Accuracy on batch 324/3013  on Training is 52.95192307692308\n",
            "Epoch #0. Accuracy on batch 325/3013  on Training is 52.933282208588956\n",
            "Epoch #0. Accuracy on batch 326/3013  on Training is 53.00076452599389\n",
            "Epoch #0. Accuracy on batch 327/3013  on Training is 53.0297256097561\n",
            "Epoch #0. Accuracy on batch 328/3013  on Training is 53.068009118541035\n",
            "Epoch #0. Accuracy on batch 329/3013  on Training is 53.077651515151516\n",
            "Epoch #0. Accuracy on batch 330/3013  on Training is 53.13444108761329\n",
            "Epoch #0. Accuracy on batch 331/3013  on Training is 53.181475903614455\n",
            "Epoch #0. Accuracy on batch 332/3013  on Training is 53.237612612612615\n",
            "Epoch #0. Accuracy on batch 333/3013  on Training is 53.2747005988024\n",
            "Epoch #0. Accuracy on batch 334/3013  on Training is 53.33022388059702\n",
            "Epoch #0. Accuracy on batch 335/3013  on Training is 53.366815476190474\n",
            "Epoch #0. Accuracy on batch 336/3013  on Training is 53.40318991097923\n",
            "Epoch #0. Accuracy on batch 337/3013  on Training is 53.42085798816568\n",
            "Epoch #0. Accuracy on batch 338/3013  on Training is 53.4476401179941\n",
            "Epoch #0. Accuracy on batch 339/3013  on Training is 53.501838235294116\n",
            "Batch Id 340 is having training loss of 2.2145190238952637\n",
            "1.2594765424728394\n",
            "Epoch #0. Accuracy on batch 340/3013  on Training is 53.55571847507331\n",
            "Epoch #0. Accuracy on batch 341/3013  on Training is 53.59100877192982\n",
            "Epoch #0. Accuracy on batch 342/3013  on Training is 53.60787172011662\n",
            "Epoch #0. Accuracy on batch 343/3013  on Training is 53.633720930232556\n",
            "Epoch #0. Accuracy on batch 344/3013  on Training is 53.65036231884058\n",
            "Epoch #0. Accuracy on batch 345/3013  on Training is 53.64884393063584\n",
            "Epoch #0. Accuracy on batch 346/3013  on Training is 53.674351585014406\n",
            "Epoch #0. Accuracy on batch 347/3013  on Training is 53.68175287356322\n",
            "Epoch #0. Accuracy on batch 348/3013  on Training is 53.6980659025788\n",
            "Epoch #0. Accuracy on batch 349/3013  on Training is 53.74107142857143\n",
            "Epoch #0. Accuracy on batch 350/3013  on Training is 53.774928774928775\n",
            "Epoch #0. Accuracy on batch 351/3013  on Training is 53.76420454545455\n",
            "Epoch #0. Accuracy on batch 352/3013  on Training is 53.83321529745042\n",
            "Epoch #0. Accuracy on batch 353/3013  on Training is 53.89300847457627\n",
            "Epoch #0. Accuracy on batch 354/3013  on Training is 53.87323943661972\n",
            "Epoch #0. Accuracy on batch 355/3013  on Training is 53.88869382022472\n",
            "Epoch #0. Accuracy on batch 356/3013  on Training is 53.94782913165266\n",
            "Epoch #0. Accuracy on batch 357/3013  on Training is 53.94553072625698\n",
            "Epoch #0. Accuracy on batch 358/3013  on Training is 53.969359331476326\n",
            "Epoch #0. Accuracy on batch 359/3013  on Training is 54.01909722222222\n",
            "Batch Id 360 is having training loss of 2.1803321838378906\n",
            "1.2907739877700806\n",
            "Epoch #0. Accuracy on batch 360/3013  on Training is 54.0685595567867\n",
            "Epoch #0. Accuracy on batch 361/3013  on Training is 54.11774861878453\n",
            "Epoch #0. Accuracy on batch 362/3013  on Training is 54.14084022038568\n",
            "Epoch #0. Accuracy on batch 363/3013  on Training is 54.13804945054945\n",
            "Epoch #0. Accuracy on batch 364/3013  on Training is 54.195205479452056\n",
            "Epoch #0. Accuracy on batch 365/3013  on Training is 54.21789617486339\n",
            "Epoch #0. Accuracy on batch 366/3013  on Training is 54.206403269754766\n",
            "Epoch #0. Accuracy on batch 367/3013  on Training is 54.27139945652174\n",
            "Epoch #0. Accuracy on batch 368/3013  on Training is 54.31910569105691\n",
            "Epoch #0. Accuracy on batch 369/3013  on Training is 54.375\n",
            "Epoch #0. Accuracy on batch 370/3013  on Training is 54.40532345013477\n",
            "Epoch #0. Accuracy on batch 371/3013  on Training is 54.41868279569893\n",
            "Epoch #0. Accuracy on batch 372/3013  on Training is 54.44034852546917\n",
            "Epoch #0. Accuracy on batch 373/3013  on Training is 54.45354278074866\n",
            "Epoch #0. Accuracy on batch 374/3013  on Training is 54.44166666666667\n",
            "Epoch #0. Accuracy on batch 375/3013  on Training is 54.454787234042556\n",
            "Epoch #0. Accuracy on batch 376/3013  on Training is 54.451259946949605\n",
            "Epoch #0. Accuracy on batch 377/3013  on Training is 54.47255291005291\n",
            "Epoch #0. Accuracy on batch 378/3013  on Training is 54.51022427440633\n",
            "Epoch #0. Accuracy on batch 379/3013  on Training is 54.52302631578947\n",
            "Batch Id 380 is having training loss of 2.1450016498565674\n",
            "0.9428589940071106\n",
            "Epoch #0. Accuracy on batch 380/3013  on Training is 54.60958005249344\n",
            "Epoch #0. Accuracy on batch 381/3013  on Training is 54.662958115183244\n",
            "Epoch #0. Accuracy on batch 382/3013  on Training is 54.699738903394255\n",
            "Epoch #0. Accuracy on batch 383/3013  on Training is 54.703776041666664\n",
            "Epoch #0. Accuracy on batch 384/3013  on Training is 54.699675324675326\n",
            "Epoch #0. Accuracy on batch 385/3013  on Training is 54.75226683937824\n",
            "Epoch #0. Accuracy on batch 386/3013  on Training is 54.77228682170543\n",
            "Epoch #0. Accuracy on batch 387/3013  on Training is 54.79220360824742\n",
            "Epoch #0. Accuracy on batch 388/3013  on Training is 54.83611825192802\n",
            "Epoch #0. Accuracy on batch 389/3013  on Training is 54.87980769230769\n",
            "Epoch #0. Accuracy on batch 390/3013  on Training is 54.89929667519181\n",
            "Epoch #0. Accuracy on batch 391/3013  on Training is 54.93463010204081\n",
            "Epoch #0. Accuracy on batch 392/3013  on Training is 54.9220737913486\n",
            "Epoch #0. Accuracy on batch 393/3013  on Training is 54.95717005076142\n",
            "Epoch #0. Accuracy on batch 394/3013  on Training is 55.00791139240506\n",
            "Epoch #0. Accuracy on batch 395/3013  on Training is 55.05050505050505\n",
            "Epoch #0. Accuracy on batch 396/3013  on Training is 55.07714105793451\n",
            "Epoch #0. Accuracy on batch 397/3013  on Training is 55.072236180904525\n",
            "Epoch #0. Accuracy on batch 398/3013  on Training is 55.028195488721806\n",
            "Epoch #0. Accuracy on batch 399/3013  on Training is 55.0546875\n",
            "Batch Id 400 is having training loss of 2.1177163124084473\n",
            "1.8983755111694336\n",
            "Epoch #0. Accuracy on batch 400/3013  on Training is 55.0498753117207\n",
            "Epoch #0. Accuracy on batch 401/3013  on Training is 55.09172885572139\n",
            "Epoch #0. Accuracy on batch 402/3013  on Training is 55.133374689826304\n",
            "Epoch #0. Accuracy on batch 403/3013  on Training is 55.15160891089109\n",
            "Epoch #0. Accuracy on batch 404/3013  on Training is 55.20061728395062\n",
            "Epoch #0. Accuracy on batch 405/3013  on Training is 55.21089901477833\n",
            "Epoch #0. Accuracy on batch 406/3013  on Training is 55.20577395577396\n",
            "Epoch #0. Accuracy on batch 407/3013  on Training is 55.26194852941177\n",
            "Epoch #0. Accuracy on batch 408/3013  on Training is 55.279645476772615\n",
            "Epoch #0. Accuracy on batch 409/3013  on Training is 55.327743902439025\n",
            "Epoch #0. Accuracy on batch 410/3013  on Training is 55.33759124087591\n",
            "Epoch #0. Accuracy on batch 411/3013  on Training is 55.35497572815534\n",
            "Epoch #0. Accuracy on batch 412/3013  on Training is 55.402542372881356\n",
            "Epoch #0. Accuracy on batch 413/3013  on Training is 55.42723429951691\n",
            "Epoch #0. Accuracy on batch 414/3013  on Training is 55.43674698795181\n",
            "Epoch #0. Accuracy on batch 415/3013  on Training is 55.48377403846154\n",
            "Epoch #0. Accuracy on batch 416/3013  on Training is 55.485611510791365\n",
            "Epoch #0. Accuracy on batch 417/3013  on Training is 55.51734449760765\n",
            "Epoch #0. Accuracy on batch 418/3013  on Training is 55.52655131264916\n",
            "Epoch #0. Accuracy on batch 419/3013  on Training is 55.52827380952381\n",
            "Batch Id 420 is having training loss of 2.087547779083252\n",
            "1.1694961786270142\n",
            "Epoch #0. Accuracy on batch 420/3013  on Training is 55.56710213776722\n",
            "Epoch #0. Accuracy on batch 421/3013  on Training is 55.59093601895734\n",
            "Epoch #0. Accuracy on batch 422/3013  on Training is 55.636820330969265\n",
            "Epoch #0. Accuracy on batch 423/3013  on Training is 55.667747641509436\n",
            "Epoch #0. Accuracy on batch 424/3013  on Training is 55.69117647058823\n",
            "Epoch #0. Accuracy on batch 425/3013  on Training is 55.721830985915496\n",
            "Epoch #0. Accuracy on batch 426/3013  on Training is 55.72306791569087\n",
            "Epoch #0. Accuracy on batch 427/3013  on Training is 55.73160046728972\n",
            "Epoch #0. Accuracy on batch 428/3013  on Training is 55.74737762237762\n",
            "Epoch #0. Accuracy on batch 429/3013  on Training is 55.763081395348834\n",
            "Epoch #0. Accuracy on batch 430/3013  on Training is 55.785962877030165\n",
            "Epoch #0. Accuracy on batch 431/3013  on Training is 55.837673611111114\n",
            "Epoch #0. Accuracy on batch 432/3013  on Training is 55.89636258660508\n",
            "Epoch #0. Accuracy on batch 433/3013  on Training is 55.933179723502306\n",
            "Epoch #0. Accuracy on batch 434/3013  on Training is 55.94827586206897\n",
            "Epoch #0. Accuracy on batch 435/3013  on Training is 55.96330275229358\n",
            "Epoch #0. Accuracy on batch 436/3013  on Training is 55.97826086956522\n",
            "Epoch #0. Accuracy on batch 437/3013  on Training is 56.03595890410959\n",
            "Epoch #0. Accuracy on batch 438/3013  on Training is 56.07203872437358\n",
            "Epoch #0. Accuracy on batch 439/3013  on Training is 56.08664772727273\n",
            "Batch Id 440 is having training loss of 2.0595381259918213\n",
            "1.6595354080200195\n",
            "Epoch #0. Accuracy on batch 440/3013  on Training is 56.07284580498866\n",
            "Epoch #0. Accuracy on batch 441/3013  on Training is 56.06617647058823\n",
            "Epoch #0. Accuracy on batch 442/3013  on Training is 56.066591422121896\n",
            "Epoch #0. Accuracy on batch 443/3013  on Training is 56.09515765765766\n",
            "Epoch #0. Accuracy on batch 444/3013  on Training is 56.12359550561798\n",
            "Epoch #0. Accuracy on batch 445/3013  on Training is 56.13789237668161\n",
            "Epoch #0. Accuracy on batch 446/3013  on Training is 56.18708053691275\n",
            "Epoch #0. Accuracy on batch 447/3013  on Training is 56.215122767857146\n",
            "Epoch #0. Accuracy on batch 448/3013  on Training is 56.22216035634744\n",
            "Epoch #0. Accuracy on batch 449/3013  on Training is 56.263888888888886\n",
            "Epoch #0. Accuracy on batch 450/3013  on Training is 56.26385809312639\n",
            "Epoch #0. Accuracy on batch 451/3013  on Training is 56.29839601769911\n",
            "Epoch #0. Accuracy on batch 452/3013  on Training is 56.27759381898455\n",
            "Epoch #0. Accuracy on batch 453/3013  on Training is 56.33259911894273\n",
            "Epoch #0. Accuracy on batch 454/3013  on Training is 56.339285714285715\n",
            "Epoch #0. Accuracy on batch 455/3013  on Training is 56.3390899122807\n",
            "Epoch #0. Accuracy on batch 456/3013  on Training is 56.37308533916849\n",
            "Epoch #0. Accuracy on batch 457/3013  on Training is 56.41375545851528\n",
            "Epoch #0. Accuracy on batch 458/3013  on Training is 56.45424836601307\n",
            "Epoch #0. Accuracy on batch 459/3013  on Training is 56.48777173913044\n",
            "Batch Id 460 is having training loss of 2.0339744091033936\n",
            "1.7480416297912598\n",
            "Epoch #0. Accuracy on batch 460/3013  on Training is 56.48047722342733\n",
            "Epoch #0. Accuracy on batch 461/3013  on Training is 56.513798701298704\n",
            "Epoch #0. Accuracy on batch 462/3013  on Training is 56.54697624190065\n",
            "Epoch #0. Accuracy on batch 463/3013  on Training is 56.55307112068966\n",
            "Epoch #0. Accuracy on batch 464/3013  on Training is 56.55241935483871\n",
            "Epoch #0. Accuracy on batch 465/3013  on Training is 56.612124463519315\n",
            "Epoch #0. Accuracy on batch 466/3013  on Training is 56.61134903640257\n",
            "Epoch #0. Accuracy on batch 467/3013  on Training is 56.657318376068375\n",
            "Epoch #0. Accuracy on batch 468/3013  on Training is 56.683102345415776\n",
            "Epoch #0. Accuracy on batch 469/3013  on Training is 56.682180851063826\n",
            "Epoch #0. Accuracy on batch 470/3013  on Training is 56.70116772823779\n",
            "Epoch #0. Accuracy on batch 471/3013  on Training is 56.733315677966104\n",
            "Epoch #0. Accuracy on batch 472/3013  on Training is 56.758720930232556\n",
            "Epoch #0. Accuracy on batch 473/3013  on Training is 56.777426160337555\n",
            "Epoch #0. Accuracy on batch 474/3013  on Training is 56.7828947368421\n",
            "Epoch #0. Accuracy on batch 475/3013  on Training is 56.82773109243698\n",
            "Epoch #0. Accuracy on batch 476/3013  on Training is 56.839622641509436\n",
            "Epoch #0. Accuracy on batch 477/3013  on Training is 56.83838912133891\n",
            "Epoch #0. Accuracy on batch 478/3013  on Training is 56.876304801670145\n",
            "Epoch #0. Accuracy on batch 479/3013  on Training is 56.9140625\n",
            "Batch Id 480 is having training loss of 2.0115768909454346\n",
            "1.6978611946105957\n",
            "Epoch #0. Accuracy on batch 480/3013  on Training is 56.93217255717256\n",
            "Epoch #0. Accuracy on batch 481/3013  on Training is 56.92427385892116\n",
            "Epoch #0. Accuracy on batch 482/3013  on Training is 56.94875776397515\n",
            "Epoch #0. Accuracy on batch 483/3013  on Training is 56.95377066115702\n",
            "Epoch #0. Accuracy on batch 484/3013  on Training is 56.96520618556701\n",
            "Epoch #0. Accuracy on batch 485/3013  on Training is 57.02160493827161\n",
            "Epoch #0. Accuracy on batch 486/3013  on Training is 57.0200205338809\n",
            "Epoch #0. Accuracy on batch 487/3013  on Training is 57.06967213114754\n",
            "Epoch #0. Accuracy on batch 488/3013  on Training is 57.08077709611452\n",
            "Epoch #0. Accuracy on batch 489/3013  on Training is 57.130102040816325\n",
            "Epoch #0. Accuracy on batch 490/3013  on Training is 57.16013238289206\n",
            "Epoch #0. Accuracy on batch 491/3013  on Training is 57.177337398373986\n",
            "Epoch #0. Accuracy on batch 492/3013  on Training is 57.20081135902637\n",
            "Epoch #0. Accuracy on batch 493/3013  on Training is 57.262145748987855\n",
            "Epoch #0. Accuracy on batch 494/3013  on Training is 57.26641414141414\n",
            "Epoch #0. Accuracy on batch 495/3013  on Training is 57.283266129032256\n",
            "Epoch #0. Accuracy on batch 496/3013  on Training is 57.306338028169016\n",
            "Epoch #0. Accuracy on batch 497/3013  on Training is 57.36069277108434\n",
            "Epoch #0. Accuracy on batch 498/3013  on Training is 57.40230460921844\n",
            "Epoch #0. Accuracy on batch 499/3013  on Training is 57.4125\n",
            "Batch Id 500 is having training loss of 1.9868731498718262\n",
            "1.2930246591567993\n",
            "Epoch #0. Accuracy on batch 500/3013  on Training is 57.44760479041916\n",
            "Epoch #0. Accuracy on batch 501/3013  on Training is 57.46389442231076\n",
            "Epoch #0. Accuracy on batch 502/3013  on Training is 57.49254473161034\n",
            "Epoch #0. Accuracy on batch 503/3013  on Training is 57.50868055555556\n",
            "Epoch #0. Accuracy on batch 504/3013  on Training is 57.54331683168317\n",
            "Epoch #0. Accuracy on batch 505/3013  on Training is 57.58399209486166\n",
            "Epoch #0. Accuracy on batch 506/3013  on Training is 57.61834319526627\n",
            "Epoch #0. Accuracy on batch 507/3013  on Training is 57.63410433070866\n",
            "Epoch #0. Accuracy on batch 508/3013  on Training is 57.63752455795678\n",
            "Epoch #0. Accuracy on batch 509/3013  on Training is 57.66544117647059\n",
            "Epoch #0. Accuracy on batch 510/3013  on Training is 57.711594911937375\n",
            "Epoch #0. Accuracy on batch 511/3013  on Training is 57.71484375\n",
            "Epoch #0. Accuracy on batch 512/3013  on Training is 57.73635477582846\n",
            "Epoch #0. Accuracy on batch 513/3013  on Training is 57.757782101167315\n",
            "Epoch #0. Accuracy on batch 514/3013  on Training is 57.76092233009709\n",
            "Epoch #0. Accuracy on batch 515/3013  on Training is 57.78221899224806\n",
            "Epoch #0. Accuracy on batch 516/3013  on Training is 57.76112185686654\n",
            "Epoch #0. Accuracy on batch 517/3013  on Training is 57.770270270270274\n",
            "Epoch #0. Accuracy on batch 518/3013  on Training is 57.77938342967245\n",
            "Epoch #0. Accuracy on batch 519/3013  on Training is 57.80649038461539\n",
            "Batch Id 520 is having training loss of 1.9613986015319824\n",
            "1.0298291444778442\n",
            "Epoch #0. Accuracy on batch 520/3013  on Training is 57.839491362763916\n",
            "Epoch #0. Accuracy on batch 521/3013  on Training is 57.88433908045977\n",
            "Epoch #0. Accuracy on batch 522/3013  on Training is 57.905114722753346\n",
            "Epoch #0. Accuracy on batch 523/3013  on Training is 57.91388358778626\n",
            "Epoch #0. Accuracy on batch 524/3013  on Training is 57.94047619047619\n",
            "Epoch #0. Accuracy on batch 525/3013  on Training is 57.92538022813688\n",
            "Epoch #0. Accuracy on batch 526/3013  on Training is 57.95185009487666\n",
            "Epoch #0. Accuracy on batch 527/3013  on Training is 58.00189393939394\n",
            "Epoch #0. Accuracy on batch 528/3013  on Training is 58.004489603024574\n",
            "Epoch #0. Accuracy on batch 529/3013  on Training is 58.030660377358494\n",
            "Epoch #0. Accuracy on batch 530/3013  on Training is 58.027306967984934\n",
            "Epoch #0. Accuracy on batch 531/3013  on Training is 58.05921052631579\n",
            "Epoch #0. Accuracy on batch 532/3013  on Training is 58.11444652908067\n",
            "Epoch #0. Accuracy on batch 533/3013  on Training is 58.12851123595506\n",
            "Epoch #0. Accuracy on batch 534/3013  on Training is 58.154205607476634\n",
            "Epoch #0. Accuracy on batch 535/3013  on Training is 58.16814365671642\n",
            "Epoch #0. Accuracy on batch 536/3013  on Training is 58.182029795158286\n",
            "Epoch #0. Accuracy on batch 537/3013  on Training is 58.2074814126394\n",
            "Epoch #0. Accuracy on batch 538/3013  on Training is 58.2502319109462\n",
            "Epoch #0. Accuracy on batch 539/3013  on Training is 58.28125\n",
            "Batch Id 540 is having training loss of 1.9388761520385742\n",
            "1.2635704278945923\n",
            "Epoch #0. Accuracy on batch 540/3013  on Training is 58.29482439926063\n",
            "Epoch #0. Accuracy on batch 541/3013  on Training is 58.30834870848709\n",
            "Epoch #0. Accuracy on batch 542/3013  on Training is 58.32182320441989\n",
            "Epoch #0. Accuracy on batch 543/3013  on Training is 58.3352481617647\n",
            "Epoch #0. Accuracy on batch 544/3013  on Training is 58.36009174311926\n",
            "Epoch #0. Accuracy on batch 545/3013  on Training is 58.350503663003664\n",
            "Epoch #0. Accuracy on batch 546/3013  on Training is 58.36380255941499\n",
            "Epoch #0. Accuracy on batch 547/3013  on Training is 58.3485401459854\n",
            "Epoch #0. Accuracy on batch 548/3013  on Training is 58.36748633879781\n",
            "Epoch #0. Accuracy on batch 549/3013  on Training is 58.38068181818182\n",
            "Epoch #0. Accuracy on batch 550/3013  on Training is 58.39382940108893\n",
            "Epoch #0. Accuracy on batch 551/3013  on Training is 58.39560688405797\n",
            "Epoch #0. Accuracy on batch 552/3013  on Training is 58.40302893309222\n",
            "Epoch #0. Accuracy on batch 553/3013  on Training is 58.41606498194946\n",
            "Epoch #0. Accuracy on batch 554/3013  on Training is 58.417792792792795\n",
            "Epoch #0. Accuracy on batch 555/3013  on Training is 58.43637589928058\n",
            "Epoch #0. Accuracy on batch 556/3013  on Training is 58.4661131059246\n",
            "Epoch #0. Accuracy on batch 557/3013  on Training is 58.501344086021504\n",
            "Epoch #0. Accuracy on batch 558/3013  on Training is 58.51408765652952\n",
            "Epoch #0. Accuracy on batch 559/3013  on Training is 58.53236607142857\n",
            "Batch Id 560 is having training loss of 1.9242820739746094\n",
            "2.396087646484375\n",
            "Epoch #0. Accuracy on batch 560/3013  on Training is 58.50601604278075\n",
            "Epoch #0. Accuracy on batch 561/3013  on Training is 58.50756227758007\n",
            "Epoch #0. Accuracy on batch 562/3013  on Training is 58.553507992895206\n",
            "Epoch #0. Accuracy on batch 563/3013  on Training is 58.56050531914894\n",
            "Epoch #0. Accuracy on batch 564/3013  on Training is 58.573008849557525\n",
            "Epoch #0. Accuracy on batch 565/3013  on Training is 58.585468197879855\n",
            "Epoch #0. Accuracy on batch 566/3013  on Training is 58.597883597883595\n",
            "Epoch #0. Accuracy on batch 567/3013  on Training is 58.610255281690144\n",
            "Epoch #0. Accuracy on batch 568/3013  on Training is 58.611599297012305\n",
            "Epoch #0. Accuracy on batch 569/3013  on Training is 58.61842105263158\n",
            "Epoch #0. Accuracy on batch 570/3013  on Training is 58.64711033274956\n",
            "Epoch #0. Accuracy on batch 571/3013  on Training is 58.64838286713287\n",
            "Epoch #0. Accuracy on batch 572/3013  on Training is 58.67691972076789\n",
            "Epoch #0. Accuracy on batch 573/3013  on Training is 58.6890243902439\n",
            "Epoch #0. Accuracy on batch 574/3013  on Training is 58.72282608695652\n",
            "Epoch #0. Accuracy on batch 575/3013  on Training is 58.756510416666664\n",
            "Epoch #0. Accuracy on batch 576/3013  on Training is 58.78466204506066\n",
            "Epoch #0. Accuracy on batch 577/3013  on Training is 58.79108996539792\n",
            "Epoch #0. Accuracy on batch 578/3013  on Training is 58.792098445595855\n",
            "Epoch #0. Accuracy on batch 579/3013  on Training is 58.79849137931034\n",
            "Batch Id 580 is having training loss of 1.907074213027954\n",
            "1.6234606504440308\n",
            "Epoch #0. Accuracy on batch 580/3013  on Training is 58.79948364888124\n",
            "Epoch #0. Accuracy on batch 581/3013  on Training is 58.82195017182131\n",
            "Epoch #0. Accuracy on batch 582/3013  on Training is 58.844339622641506\n",
            "Epoch #0. Accuracy on batch 583/3013  on Training is 58.861301369863014\n",
            "Epoch #0. Accuracy on batch 584/3013  on Training is 58.888888888888886\n",
            "Epoch #0. Accuracy on batch 585/3013  on Training is 58.90038395904437\n",
            "Epoch #0. Accuracy on batch 586/3013  on Training is 58.9118398637138\n",
            "Epoch #0. Accuracy on batch 587/3013  on Training is 58.91262755102041\n",
            "Epoch #0. Accuracy on batch 588/3013  on Training is 58.91341256366723\n",
            "Epoch #0. Accuracy on batch 589/3013  on Training is 58.940677966101696\n",
            "Epoch #0. Accuracy on batch 590/3013  on Training is 58.94670050761421\n",
            "Epoch #0. Accuracy on batch 591/3013  on Training is 58.968538851351354\n",
            "Epoch #0. Accuracy on batch 592/3013  on Training is 58.995573355817875\n",
            "Epoch #0. Accuracy on batch 593/3013  on Training is 59.02777777777778\n",
            "Epoch #0. Accuracy on batch 594/3013  on Training is 59.05987394957983\n",
            "Epoch #0. Accuracy on batch 595/3013  on Training is 59.060402684563755\n",
            "Epoch #0. Accuracy on batch 596/3013  on Training is 59.09233668341709\n",
            "Epoch #0. Accuracy on batch 597/3013  on Training is 59.10326086956522\n",
            "Epoch #0. Accuracy on batch 598/3013  on Training is 59.10893155258765\n",
            "Epoch #0. Accuracy on batch 599/3013  on Training is 59.114583333333336\n",
            "Batch Id 600 is having training loss of 1.8899554014205933\n",
            "1.5165865421295166\n",
            "Epoch #0. Accuracy on batch 600/3013  on Training is 59.12021630615641\n",
            "Epoch #0. Accuracy on batch 601/3013  on Training is 59.12063953488372\n",
            "Epoch #0. Accuracy on batch 602/3013  on Training is 59.13660862354892\n",
            "Epoch #0. Accuracy on batch 603/3013  on Training is 59.16804635761589\n",
            "Epoch #0. Accuracy on batch 604/3013  on Training is 59.18388429752066\n",
            "Epoch #0. Accuracy on batch 605/3013  on Training is 59.1996699669967\n",
            "Epoch #0. Accuracy on batch 606/3013  on Training is 59.215403624382205\n",
            "Epoch #0. Accuracy on batch 607/3013  on Training is 59.22594572368421\n",
            "Epoch #0. Accuracy on batch 608/3013  on Training is 59.23132183908046\n",
            "Epoch #0. Accuracy on batch 609/3013  on Training is 59.23155737704918\n",
            "Epoch #0. Accuracy on batch 610/3013  on Training is 59.24202127659574\n",
            "Epoch #0. Accuracy on batch 611/3013  on Training is 59.27287581699346\n",
            "Epoch #0. Accuracy on batch 612/3013  on Training is 59.29853181076672\n",
            "Epoch #0. Accuracy on batch 613/3013  on Training is 59.313925081433226\n",
            "Epoch #0. Accuracy on batch 614/3013  on Training is 59.31910569105691\n",
            "Epoch #0. Accuracy on batch 615/3013  on Training is 59.34963474025974\n",
            "Epoch #0. Accuracy on batch 616/3013  on Training is 59.38006482982172\n",
            "Epoch #0. Accuracy on batch 617/3013  on Training is 59.390169902912625\n",
            "Epoch #0. Accuracy on batch 618/3013  on Training is 59.405290791599356\n",
            "Epoch #0. Accuracy on batch 619/3013  on Training is 59.40524193548387\n",
            "Batch Id 620 is having training loss of 1.8720033168792725\n",
            "1.283780813217163\n",
            "Epoch #0. Accuracy on batch 620/3013  on Training is 59.42532206119163\n",
            "Epoch #0. Accuracy on batch 621/3013  on Training is 59.445337620578776\n",
            "Epoch #0. Accuracy on batch 622/3013  on Training is 59.47030497592295\n",
            "Epoch #0. Accuracy on batch 623/3013  on Training is 59.455128205128204\n",
            "Epoch #0. Accuracy on batch 624/3013  on Training is 59.465\n",
            "Epoch #0. Accuracy on batch 625/3013  on Training is 59.474840255591054\n",
            "Epoch #0. Accuracy on batch 626/3013  on Training is 59.46969696969697\n",
            "Epoch #0. Accuracy on batch 627/3013  on Training is 59.48447452229299\n",
            "Epoch #0. Accuracy on batch 628/3013  on Training is 59.504173290938\n",
            "Epoch #0. Accuracy on batch 629/3013  on Training is 59.523809523809526\n",
            "Epoch #0. Accuracy on batch 630/3013  on Training is 59.52357369255151\n",
            "Epoch #0. Accuracy on batch 631/3013  on Training is 59.543117088607595\n",
            "Epoch #0. Accuracy on batch 632/3013  on Training is 59.552725118483416\n",
            "Epoch #0. Accuracy on batch 633/3013  on Training is 59.567231861198735\n",
            "Epoch #0. Accuracy on batch 634/3013  on Training is 59.571850393700785\n",
            "Epoch #0. Accuracy on batch 635/3013  on Training is 59.566627358490564\n",
            "Epoch #0. Accuracy on batch 636/3013  on Training is 59.59576138147567\n",
            "Epoch #0. Accuracy on batch 637/3013  on Training is 59.61500783699059\n",
            "Epoch #0. Accuracy on batch 638/3013  on Training is 59.614632237871675\n",
            "Epoch #0. Accuracy on batch 639/3013  on Training is 59.6142578125\n",
            "Batch Id 640 is having training loss of 1.8570019006729126\n",
            "1.4368482828140259\n",
            "Epoch #0. Accuracy on batch 640/3013  on Training is 59.62363494539782\n",
            "Epoch #0. Accuracy on batch 641/3013  on Training is 59.63298286604361\n",
            "Epoch #0. Accuracy on batch 642/3013  on Training is 59.63744167962675\n",
            "Epoch #0. Accuracy on batch 643/3013  on Training is 59.651591614906835\n",
            "Epoch #0. Accuracy on batch 644/3013  on Training is 59.64147286821706\n",
            "Epoch #0. Accuracy on batch 645/3013  on Training is 59.64589783281734\n",
            "Epoch #0. Accuracy on batch 646/3013  on Training is 59.65030911901082\n",
            "Epoch #0. Accuracy on batch 647/3013  on Training is 59.664351851851855\n",
            "Epoch #0. Accuracy on batch 648/3013  on Training is 59.68798151001541\n",
            "Epoch #0. Accuracy on batch 649/3013  on Training is 59.70192307692308\n",
            "Epoch #0. Accuracy on batch 650/3013  on Training is 59.70142089093702\n",
            "Epoch #0. Accuracy on batch 651/3013  on Training is 59.70571319018405\n",
            "Epoch #0. Accuracy on batch 652/3013  on Training is 59.724349157733535\n",
            "Epoch #0. Accuracy on batch 653/3013  on Training is 59.7572629969419\n",
            "Epoch #0. Accuracy on batch 654/3013  on Training is 59.780534351145036\n",
            "Epoch #0. Accuracy on batch 655/3013  on Training is 59.75609756097561\n",
            "Epoch #0. Accuracy on batch 656/3013  on Training is 59.76027397260274\n",
            "Epoch #0. Accuracy on batch 657/3013  on Training is 59.76918693009119\n",
            "Epoch #0. Accuracy on batch 658/3013  on Training is 59.797040971168435\n",
            "Epoch #0. Accuracy on batch 659/3013  on Training is 59.791666666666664\n",
            "Batch Id 660 is having training loss of 1.842574119567871\n",
            "0.9044115543365479\n",
            "Epoch #0. Accuracy on batch 660/3013  on Training is 59.82885779122542\n",
            "Epoch #0. Accuracy on batch 661/3013  on Training is 59.86121601208459\n",
            "Epoch #0. Accuracy on batch 662/3013  on Training is 59.89819004524887\n",
            "Epoch #0. Accuracy on batch 663/3013  on Training is 59.930346385542165\n",
            "Epoch #0. Accuracy on batch 664/3013  on Training is 59.962406015037594\n",
            "Epoch #0. Accuracy on batch 665/3013  on Training is 59.970908408408405\n",
            "Epoch #0. Accuracy on batch 666/3013  on Training is 59.97938530734633\n",
            "Epoch #0. Accuracy on batch 667/3013  on Training is 59.987836826347305\n",
            "Epoch #0. Accuracy on batch 668/3013  on Training is 60.00560538116592\n",
            "Epoch #0. Accuracy on batch 669/3013  on Training is 60.009328358208954\n",
            "Epoch #0. Accuracy on batch 670/3013  on Training is 60.03166915052161\n",
            "Epoch #0. Accuracy on batch 671/3013  on Training is 60.03999255952381\n",
            "Epoch #0. Accuracy on batch 672/3013  on Training is 60.06686478454681\n",
            "Epoch #0. Accuracy on batch 673/3013  on Training is 60.07511127596439\n",
            "Epoch #0. Accuracy on batch 674/3013  on Training is 60.074074074074076\n",
            "Epoch #0. Accuracy on batch 675/3013  on Training is 60.09153106508876\n",
            "Epoch #0. Accuracy on batch 676/3013  on Training is 60.11355243722304\n",
            "Epoch #0. Accuracy on batch 677/3013  on Training is 60.1216814159292\n",
            "Epoch #0. Accuracy on batch 678/3013  on Training is 60.13438880706922\n",
            "Epoch #0. Accuracy on batch 679/3013  on Training is 60.14705882352941\n",
            "Batch Id 680 is having training loss of 1.826066017150879\n",
            "1.7552014589309692\n",
            "Epoch #0. Accuracy on batch 680/3013  on Training is 60.159691629955944\n",
            "Epoch #0. Accuracy on batch 681/3013  on Training is 60.18603372434018\n",
            "Epoch #0. Accuracy on batch 682/3013  on Training is 60.180270863836014\n",
            "Epoch #0. Accuracy on batch 683/3013  on Training is 60.20193713450293\n",
            "Epoch #0. Accuracy on batch 684/3013  on Training is 60.20529197080292\n",
            "Epoch #0. Accuracy on batch 685/3013  on Training is 60.21319241982507\n",
            "Epoch #0. Accuracy on batch 686/3013  on Training is 60.2301673944687\n",
            "Epoch #0. Accuracy on batch 687/3013  on Training is 60.233466569767444\n",
            "Epoch #0. Accuracy on batch 688/3013  on Training is 60.24129172714078\n",
            "Epoch #0. Accuracy on batch 689/3013  on Training is 60.26721014492754\n",
            "Epoch #0. Accuracy on batch 690/3013  on Training is 60.27496382054993\n",
            "Epoch #0. Accuracy on batch 691/3013  on Training is 60.2826950867052\n",
            "Epoch #0. Accuracy on batch 692/3013  on Training is 60.28589466089466\n",
            "Epoch #0. Accuracy on batch 693/3013  on Training is 60.298090778097986\n",
            "Epoch #0. Accuracy on batch 694/3013  on Training is 60.319244604316545\n",
            "Epoch #0. Accuracy on batch 695/3013  on Training is 60.31339798850575\n",
            "Epoch #0. Accuracy on batch 696/3013  on Training is 60.32550215208035\n",
            "Epoch #0. Accuracy on batch 697/3013  on Training is 60.342048710601716\n",
            "Epoch #0. Accuracy on batch 698/3013  on Training is 60.35407725321888\n",
            "Epoch #0. Accuracy on batch 699/3013  on Training is 60.35267857142857\n",
            "Batch Id 700 is having training loss of 1.8140121698379517\n",
            "1.0104196071624756\n",
            "Epoch #0. Accuracy on batch 700/3013  on Training is 60.373573466476465\n",
            "Epoch #0. Accuracy on batch 701/3013  on Training is 60.394408831908834\n",
            "Epoch #0. Accuracy on batch 702/3013  on Training is 60.42852062588905\n",
            "Epoch #0. Accuracy on batch 703/3013  on Training is 60.44477982954545\n",
            "Epoch #0. Accuracy on batch 704/3013  on Training is 60.45656028368794\n",
            "Epoch #0. Accuracy on batch 705/3013  on Training is 60.477160056657226\n",
            "Epoch #0. Accuracy on batch 706/3013  on Training is 60.45350070721358\n",
            "Epoch #0. Accuracy on batch 707/3013  on Training is 60.451977401129945\n",
            "Epoch #0. Accuracy on batch 708/3013  on Training is 60.46808885754584\n",
            "Epoch #0. Accuracy on batch 709/3013  on Training is 60.48855633802817\n",
            "Epoch #0. Accuracy on batch 710/3013  on Training is 60.50896624472574\n",
            "Epoch #0. Accuracy on batch 711/3013  on Training is 60.524929775280896\n",
            "Epoch #0. Accuracy on batch 712/3013  on Training is 60.54961430575035\n",
            "Epoch #0. Accuracy on batch 713/3013  on Training is 60.56547619047619\n",
            "Epoch #0. Accuracy on batch 714/3013  on Training is 60.60314685314685\n",
            "Epoch #0. Accuracy on batch 715/3013  on Training is 60.63198324022346\n",
            "Epoch #0. Accuracy on batch 716/3013  on Training is 60.64330543933055\n",
            "Epoch #0. Accuracy on batch 717/3013  on Training is 60.63718662952646\n",
            "Epoch #0. Accuracy on batch 718/3013  on Training is 60.657162726008345\n",
            "Epoch #0. Accuracy on batch 719/3013  on Training is 60.651041666666664\n",
            "Batch Id 720 is having training loss of 1.7984439134597778\n",
            "0.9958877563476562\n",
            "Epoch #0. Accuracy on batch 720/3013  on Training is 60.67094313453537\n",
            "Epoch #0. Accuracy on batch 721/3013  on Training is 60.669148199445985\n",
            "Epoch #0. Accuracy on batch 722/3013  on Training is 60.680325034578146\n",
            "Epoch #0. Accuracy on batch 723/3013  on Training is 60.687154696132595\n",
            "Epoch #0. Accuracy on batch 724/3013  on Training is 60.706896551724135\n",
            "Epoch #0. Accuracy on batch 725/3013  on Training is 60.71367079889807\n",
            "Epoch #0. Accuracy on batch 726/3013  on Training is 60.74191884456671\n",
            "Epoch #0. Accuracy on batch 727/3013  on Training is 60.731456043956044\n",
            "Epoch #0. Accuracy on batch 728/3013  on Training is 60.746742112482856\n",
            "Epoch #0. Accuracy on batch 729/3013  on Training is 60.76626712328767\n",
            "Epoch #0. Accuracy on batch 730/3013  on Training is 60.76436388508892\n",
            "Epoch #0. Accuracy on batch 731/3013  on Training is 60.771004098360656\n",
            "Epoch #0. Accuracy on batch 732/3013  on Training is 60.78615279672579\n",
            "Epoch #0. Accuracy on batch 733/3013  on Training is 60.80126021798365\n",
            "Epoch #0. Accuracy on batch 734/3013  on Training is 60.829081632653065\n",
            "Epoch #0. Accuracy on batch 735/3013  on Training is 60.83984375\n",
            "Epoch #0. Accuracy on batch 736/3013  on Training is 60.85905698778833\n",
            "Epoch #0. Accuracy on batch 737/3013  on Training is 60.88245257452574\n",
            "Epoch #0. Accuracy on batch 738/3013  on Training is 60.88464140730717\n",
            "Epoch #0. Accuracy on batch 739/3013  on Training is 60.89949324324324\n",
            "Batch Id 740 is having training loss of 1.7863394021987915\n",
            "1.1957573890686035\n",
            "Epoch #0. Accuracy on batch 740/3013  on Training is 60.91852226720648\n",
            "Epoch #0. Accuracy on batch 741/3013  on Training is 60.92907681940701\n",
            "Epoch #0. Accuracy on batch 742/3013  on Training is 60.93539703903095\n",
            "Epoch #0. Accuracy on batch 743/3013  on Training is 60.94590053763441\n",
            "Epoch #0. Accuracy on batch 744/3013  on Training is 60.94798657718121\n",
            "Epoch #0. Accuracy on batch 745/3013  on Training is 60.96263404825737\n",
            "Epoch #0. Accuracy on batch 746/3013  on Training is 60.981425702811244\n",
            "Epoch #0. Accuracy on batch 747/3013  on Training is 60.96674465240642\n",
            "Epoch #0. Accuracy on batch 748/3013  on Training is 60.968791722296395\n",
            "Epoch #0. Accuracy on batch 749/3013  on Training is 60.975\n",
            "Epoch #0. Accuracy on batch 750/3013  on Training is 60.98535286284953\n",
            "Epoch #0. Accuracy on batch 751/3013  on Training is 61.012300531914896\n",
            "Epoch #0. Accuracy on batch 752/3013  on Training is 61.01842629482072\n",
            "Epoch #0. Accuracy on batch 753/3013  on Training is 61.03696949602122\n",
            "Epoch #0. Accuracy on batch 754/3013  on Training is 61.04718543046358\n",
            "Epoch #0. Accuracy on batch 755/3013  on Training is 61.05737433862434\n",
            "Epoch #0. Accuracy on batch 756/3013  on Training is 61.08404887714663\n",
            "Epoch #0. Accuracy on batch 757/3013  on Training is 61.06942612137203\n",
            "Epoch #0. Accuracy on batch 758/3013  on Training is 61.075428194993414\n",
            "Epoch #0. Accuracy on batch 759/3013  on Training is 61.08963815789474\n",
            "Batch Id 760 is having training loss of 1.7746258974075317\n",
            "1.2703458070755005\n",
            "Epoch #0. Accuracy on batch 760/3013  on Training is 61.099704336399476\n",
            "Epoch #0. Accuracy on batch 761/3013  on Training is 61.10974409448819\n",
            "Epoch #0. Accuracy on batch 762/3013  on Training is 61.12794888597641\n",
            "Epoch #0. Accuracy on batch 763/3013  on Training is 61.14610602094241\n",
            "Epoch #0. Accuracy on batch 764/3013  on Training is 61.15604575163399\n",
            "Epoch #0. Accuracy on batch 765/3013  on Training is 61.15372062663185\n",
            "Epoch #0. Accuracy on batch 766/3013  on Training is 61.1839960886571\n",
            "Epoch #0. Accuracy on batch 767/3013  on Training is 61.181640625\n",
            "Epoch #0. Accuracy on batch 768/3013  on Training is 61.20773732119636\n",
            "Epoch #0. Accuracy on batch 769/3013  on Training is 61.22159090909091\n",
            "Epoch #0. Accuracy on batch 770/3013  on Training is 61.231355382619974\n",
            "Epoch #0. Accuracy on batch 771/3013  on Training is 61.24109455958549\n",
            "Epoch #0. Accuracy on batch 772/3013  on Training is 61.254851228978005\n",
            "Epoch #0. Accuracy on batch 773/3013  on Training is 61.27664728682171\n",
            "Epoch #0. Accuracy on batch 774/3013  on Training is 61.29032258064516\n",
            "Epoch #0. Accuracy on batch 775/3013  on Training is 61.29590850515464\n",
            "Epoch #0. Accuracy on batch 776/3013  on Training is 61.30952380952381\n",
            "Epoch #0. Accuracy on batch 777/3013  on Training is 61.327120822622106\n",
            "Epoch #0. Accuracy on batch 778/3013  on Training is 61.344672657252886\n",
            "Epoch #0. Accuracy on batch 779/3013  on Training is 61.37019230769231\n",
            "Batch Id 780 is having training loss of 1.7584495544433594\n",
            "1.2867423295974731\n",
            "Epoch #0. Accuracy on batch 780/3013  on Training is 61.379641485275286\n",
            "Epoch #0. Accuracy on batch 781/3013  on Training is 61.39306265984655\n",
            "Epoch #0. Accuracy on batch 782/3013  on Training is 61.41443167305236\n",
            "Epoch #0. Accuracy on batch 783/3013  on Training is 61.40385841836735\n",
            "Epoch #0. Accuracy on batch 784/3013  on Training is 61.4171974522293\n",
            "Epoch #0. Accuracy on batch 785/3013  on Training is 61.43050254452926\n",
            "Epoch #0. Accuracy on batch 786/3013  on Training is 61.43980304955527\n",
            "Epoch #0. Accuracy on batch 787/3013  on Training is 61.460977157360404\n",
            "Epoch #0. Accuracy on batch 788/3013  on Training is 61.46625475285171\n",
            "Epoch #0. Accuracy on batch 789/3013  on Training is 61.475474683544306\n",
            "Epoch #0. Accuracy on batch 790/3013  on Training is 61.4807206068268\n",
            "Epoch #0. Accuracy on batch 791/3013  on Training is 61.48989898989899\n",
            "Epoch #0. Accuracy on batch 792/3013  on Training is 61.5108764186633\n",
            "Epoch #0. Accuracy on batch 793/3013  on Training is 61.523929471032744\n",
            "Epoch #0. Accuracy on batch 794/3013  on Training is 61.52122641509434\n",
            "Epoch #0. Accuracy on batch 795/3013  on Training is 61.52245603015076\n",
            "Epoch #0. Accuracy on batch 796/3013  on Training is 61.53152446675031\n",
            "Epoch #0. Accuracy on batch 797/3013  on Training is 61.5562343358396\n",
            "Epoch #0. Accuracy on batch 798/3013  on Training is 61.56523779724656\n",
            "Epoch #0. Accuracy on batch 799/3013  on Training is 61.58984375\n",
            "Batch Id 800 is having training loss of 1.7453397512435913\n",
            "0.9298404455184937\n",
            "Epoch #0. Accuracy on batch 800/3013  on Training is 61.60268414481897\n",
            "Epoch #0. Accuracy on batch 801/3013  on Training is 61.61549251870324\n",
            "Epoch #0. Accuracy on batch 802/3013  on Training is 61.60491905354919\n",
            "Epoch #0. Accuracy on batch 803/3013  on Training is 61.617692786069654\n",
            "Epoch #0. Accuracy on batch 804/3013  on Training is 61.630434782608695\n",
            "Epoch #0. Accuracy on batch 805/3013  on Training is 61.61600496277916\n",
            "Epoch #0. Accuracy on batch 806/3013  on Training is 61.63646220570013\n",
            "Epoch #0. Accuracy on batch 807/3013  on Training is 61.633663366336634\n",
            "Epoch #0. Accuracy on batch 808/3013  on Training is 61.6270086526576\n",
            "Epoch #0. Accuracy on batch 809/3013  on Training is 61.635802469135804\n",
            "Epoch #0. Accuracy on batch 810/3013  on Training is 61.64072133168927\n",
            "Epoch #0. Accuracy on batch 811/3013  on Training is 61.64177955665025\n",
            "Epoch #0. Accuracy on batch 812/3013  on Training is 61.646678966789665\n",
            "Epoch #0. Accuracy on batch 813/3013  on Training is 61.64004914004914\n",
            "Epoch #0. Accuracy on batch 814/3013  on Training is 61.660276073619634\n",
            "Epoch #0. Accuracy on batch 815/3013  on Training is 61.66513480392157\n",
            "Epoch #0. Accuracy on batch 816/3013  on Training is 61.66998164014688\n",
            "Epoch #0. Accuracy on batch 817/3013  on Training is 61.67481662591687\n",
            "Epoch #0. Accuracy on batch 818/3013  on Training is 61.675824175824175\n",
            "Epoch #0. Accuracy on batch 819/3013  on Training is 61.69969512195122\n",
            "Batch Id 820 is having training loss of 1.7354627847671509\n",
            "1.160050392150879\n",
            "Epoch #0. Accuracy on batch 820/3013  on Training is 61.71589524969549\n",
            "Epoch #0. Accuracy on batch 821/3013  on Training is 61.72445255474452\n",
            "Epoch #0. Accuracy on batch 822/3013  on Training is 61.73678614823815\n",
            "Epoch #0. Accuracy on batch 823/3013  on Training is 61.73012742718446\n",
            "Epoch #0. Accuracy on batch 824/3013  on Training is 61.72727272727273\n",
            "Epoch #0. Accuracy on batch 825/3013  on Training is 61.743341404358354\n",
            "Epoch #0. Accuracy on batch 826/3013  on Training is 61.748035066505444\n",
            "Epoch #0. Accuracy on batch 827/3013  on Training is 61.75649154589372\n",
            "Epoch #0. Accuracy on batch 828/3013  on Training is 61.75361881785283\n",
            "Epoch #0. Accuracy on batch 829/3013  on Training is 61.77334337349398\n",
            "Epoch #0. Accuracy on batch 830/3013  on Training is 61.77421780986763\n",
            "Epoch #0. Accuracy on batch 831/3013  on Training is 61.80138221153846\n",
            "Epoch #0. Accuracy on batch 832/3013  on Training is 61.82097839135654\n",
            "Epoch #0. Accuracy on batch 833/3013  on Training is 61.848021582733814\n",
            "Epoch #0. Accuracy on batch 834/3013  on Training is 61.8562874251497\n",
            "Epoch #0. Accuracy on batch 835/3013  on Training is 61.875747607655505\n",
            "Epoch #0. Accuracy on batch 836/3013  on Training is 61.8839605734767\n",
            "Epoch #0. Accuracy on batch 837/3013  on Training is 61.89215393794749\n",
            "Epoch #0. Accuracy on batch 838/3013  on Training is 61.904052443384984\n",
            "Epoch #0. Accuracy on batch 839/3013  on Training is 61.91220238095238\n",
            "Batch Id 840 is having training loss of 1.7229185104370117\n",
            "0.6121563911437988\n",
            "Epoch #0. Accuracy on batch 840/3013  on Training is 61.94262782401903\n",
            "Epoch #0. Accuracy on batch 841/3013  on Training is 61.95813539192399\n",
            "Epoch #0. Accuracy on batch 842/3013  on Training is 61.96248517200475\n",
            "Epoch #0. Accuracy on batch 843/3013  on Training is 61.96682464454976\n",
            "Epoch #0. Accuracy on batch 844/3013  on Training is 61.97485207100592\n",
            "Epoch #0. Accuracy on batch 845/3013  on Training is 61.99024822695036\n",
            "Epoch #0. Accuracy on batch 846/3013  on Training is 62.0056080283353\n",
            "Epoch #0. Accuracy on batch 847/3013  on Training is 62.02093160377358\n",
            "Epoch #0. Accuracy on batch 848/3013  on Training is 62.02149587750294\n",
            "Epoch #0. Accuracy on batch 849/3013  on Training is 62.018382352941174\n",
            "Epoch #0. Accuracy on batch 850/3013  on Training is 62.02262044653349\n",
            "Epoch #0. Accuracy on batch 851/3013  on Training is 62.03051643192488\n",
            "Epoch #0. Accuracy on batch 852/3013  on Training is 62.04572098475967\n",
            "Epoch #0. Accuracy on batch 853/3013  on Training is 62.06088992974239\n",
            "Epoch #0. Accuracy on batch 854/3013  on Training is 62.0687134502924\n",
            "Epoch #0. Accuracy on batch 855/3013  on Training is 62.065566588785046\n",
            "Epoch #0. Accuracy on batch 856/3013  on Training is 62.073366394399066\n",
            "Epoch #0. Accuracy on batch 857/3013  on Training is 62.0884324009324\n",
            "Epoch #0. Accuracy on batch 858/3013  on Training is 62.10710128055879\n",
            "Epoch #0. Accuracy on batch 859/3013  on Training is 62.10392441860465\n",
            "Batch Id 860 is having training loss of 1.7113300561904907\n",
            "1.114708662033081\n",
            "Epoch #0. Accuracy on batch 860/3013  on Training is 62.12253193960511\n",
            "Epoch #0. Accuracy on batch 861/3013  on Training is 62.12296983758701\n",
            "Epoch #0. Accuracy on batch 862/3013  on Training is 62.127027809965234\n",
            "Epoch #0. Accuracy on batch 863/3013  on Training is 62.13469328703704\n",
            "Epoch #0. Accuracy on batch 864/3013  on Training is 62.145953757225435\n",
            "Epoch #0. Accuracy on batch 865/3013  on Training is 62.175230946882216\n",
            "Epoch #0. Accuracy on batch 866/3013  on Training is 62.193627450980394\n",
            "Epoch #0. Accuracy on batch 867/3013  on Training is 62.21918202764977\n",
            "Epoch #0. Accuracy on batch 868/3013  on Training is 62.23748561565017\n",
            "Epoch #0. Accuracy on batch 869/3013  on Training is 62.23778735632184\n",
            "Epoch #0. Accuracy on batch 870/3013  on Training is 62.230912743972446\n",
            "Epoch #0. Accuracy on batch 871/3013  on Training is 62.24197247706422\n",
            "Epoch #0. Accuracy on batch 872/3013  on Training is 62.25300687285223\n",
            "Epoch #0. Accuracy on batch 873/3013  on Training is 62.256864988558355\n",
            "Epoch #0. Accuracy on batch 874/3013  on Training is 62.267857142857146\n",
            "Epoch #0. Accuracy on batch 875/3013  on Training is 62.27525684931507\n",
            "Epoch #0. Accuracy on batch 876/3013  on Training is 62.29332953249715\n",
            "Epoch #0. Accuracy on batch 877/3013  on Training is 62.30780182232346\n",
            "Epoch #0. Accuracy on batch 878/3013  on Training is 62.32579635949943\n",
            "Epoch #0. Accuracy on batch 879/3013  on Training is 62.34019886363637\n",
            "Batch Id 880 is having training loss of 1.6989613771438599\n",
            "0.9161372184753418\n",
            "Epoch #0. Accuracy on batch 880/3013  on Training is 62.3616628830874\n",
            "Epoch #0. Accuracy on batch 881/3013  on Training is 62.38662131519274\n",
            "Epoch #0. Accuracy on batch 882/3013  on Training is 62.379671574178936\n",
            "Epoch #0. Accuracy on batch 883/3013  on Training is 62.390412895927604\n",
            "Epoch #0. Accuracy on batch 884/3013  on Training is 62.40112994350282\n",
            "Epoch #0. Accuracy on batch 885/3013  on Training is 62.41182279909707\n",
            "Epoch #0. Accuracy on batch 886/3013  on Training is 62.404875986471254\n",
            "Epoch #0. Accuracy on batch 887/3013  on Training is 62.426097972972975\n",
            "Epoch #0. Accuracy on batch 888/3013  on Training is 62.42266591676041\n",
            "Epoch #0. Accuracy on batch 889/3013  on Training is 62.43328651685393\n",
            "Epoch #0. Accuracy on batch 890/3013  on Training is 62.443883277216614\n",
            "Epoch #0. Accuracy on batch 891/3013  on Training is 62.45095291479821\n",
            "Epoch #0. Accuracy on batch 892/3013  on Training is 62.454507278835386\n",
            "Epoch #0. Accuracy on batch 893/3013  on Training is 62.48252237136465\n",
            "Epoch #0. Accuracy on batch 894/3013  on Training is 62.510474860335194\n",
            "Epoch #0. Accuracy on batch 895/3013  on Training is 62.527901785714285\n",
            "Epoch #0. Accuracy on batch 896/3013  on Training is 62.53832218506132\n",
            "Epoch #0. Accuracy on batch 897/3013  on Training is 62.552199331848556\n",
            "Epoch #0. Accuracy on batch 898/3013  on Training is 62.57647385984427\n",
            "Epoch #0. Accuracy on batch 899/3013  on Training is 62.583333333333336\n",
            "Batch Id 900 is having training loss of 1.685288906097412\n",
            "1.1537978649139404\n",
            "Epoch #0. Accuracy on batch 900/3013  on Training is 62.59017758046615\n",
            "Epoch #0. Accuracy on batch 901/3013  on Training is 62.60393569844789\n",
            "Epoch #0. Accuracy on batch 902/3013  on Training is 62.61074197120709\n",
            "Epoch #0. Accuracy on batch 903/3013  on Training is 62.617533185840706\n",
            "Epoch #0. Accuracy on batch 904/3013  on Training is 62.603591160220994\n",
            "Epoch #0. Accuracy on batch 905/3013  on Training is 62.603476821192054\n",
            "Epoch #0. Accuracy on batch 906/3013  on Training is 62.61369900771775\n",
            "Epoch #0. Accuracy on batch 907/3013  on Training is 62.627340308370044\n",
            "Epoch #0. Accuracy on batch 908/3013  on Training is 62.634075907590756\n",
            "Epoch #0. Accuracy on batch 909/3013  on Training is 62.64766483516483\n",
            "Epoch #0. Accuracy on batch 910/3013  on Training is 62.668084522502745\n",
            "Epoch #0. Accuracy on batch 911/3013  on Training is 62.68160635964912\n",
            "Epoch #0. Accuracy on batch 912/3013  on Training is 62.68825301204819\n",
            "Epoch #0. Accuracy on batch 913/3013  on Training is 62.69830415754923\n",
            "Epoch #0. Accuracy on batch 914/3013  on Training is 62.71857923497268\n",
            "Epoch #0. Accuracy on batch 915/3013  on Training is 62.72857532751092\n",
            "Epoch #0. Accuracy on batch 916/3013  on Training is 62.7419574700109\n",
            "Epoch #0. Accuracy on batch 917/3013  on Training is 62.76211873638344\n",
            "Epoch #0. Accuracy on batch 918/3013  on Training is 62.78903699673558\n",
            "Epoch #0. Accuracy on batch 919/3013  on Training is 62.78532608695652\n",
            "Batch Id 920 is having training loss of 1.673883080482483\n",
            "0.9673806428909302\n",
            "Epoch #0. Accuracy on batch 920/3013  on Training is 62.808767643865366\n",
            "Epoch #0. Accuracy on batch 921/3013  on Training is 62.81860086767896\n",
            "Epoch #0. Accuracy on batch 922/3013  on Training is 62.82502708559046\n",
            "Epoch #0. Accuracy on batch 923/3013  on Training is 62.82805735930736\n",
            "Epoch #0. Accuracy on batch 924/3013  on Training is 62.83445945945946\n",
            "Epoch #0. Accuracy on batch 925/3013  on Training is 62.83409827213823\n",
            "Epoch #0. Accuracy on batch 926/3013  on Training is 62.84722222222222\n",
            "Epoch #0. Accuracy on batch 927/3013  on Training is 62.86031788793103\n",
            "Epoch #0. Accuracy on batch 928/3013  on Training is 62.85320236813778\n",
            "Epoch #0. Accuracy on batch 929/3013  on Training is 62.85618279569893\n",
            "Epoch #0. Accuracy on batch 930/3013  on Training is 62.87258324382385\n",
            "Epoch #0. Accuracy on batch 931/3013  on Training is 62.878889484978544\n",
            "Epoch #0. Accuracy on batch 932/3013  on Training is 62.88518220793141\n",
            "Epoch #0. Accuracy on batch 933/3013  on Training is 62.901498929336185\n",
            "Epoch #0. Accuracy on batch 934/3013  on Training is 62.911096256684495\n",
            "Epoch #0. Accuracy on batch 935/3013  on Training is 62.927350427350426\n",
            "Epoch #0. Accuracy on batch 936/3013  on Training is 62.92355923159018\n",
            "Epoch #0. Accuracy on batch 937/3013  on Training is 62.916444562899784\n",
            "Epoch #0. Accuracy on batch 938/3013  on Training is 62.909345047923324\n",
            "Epoch #0. Accuracy on batch 939/3013  on Training is 62.90558510638298\n",
            "Batch Id 940 is having training loss of 1.665588617324829\n",
            "1.1267306804656982\n",
            "Epoch #0. Accuracy on batch 940/3013  on Training is 62.91843783209352\n",
            "Epoch #0. Accuracy on batch 941/3013  on Training is 62.9146762208068\n",
            "Epoch #0. Accuracy on batch 942/3013  on Training is 62.937433722163306\n",
            "Epoch #0. Accuracy on batch 943/3013  on Training is 62.94359110169491\n",
            "Epoch #0. Accuracy on batch 944/3013  on Training is 62.95304232804233\n",
            "Epoch #0. Accuracy on batch 945/3013  on Training is 62.96247357293869\n",
            "Epoch #0. Accuracy on batch 946/3013  on Training is 62.95208553326294\n",
            "Epoch #0. Accuracy on batch 947/3013  on Training is 62.96479430379747\n",
            "Epoch #0. Accuracy on batch 948/3013  on Training is 62.984062170706004\n",
            "Epoch #0. Accuracy on batch 949/3013  on Training is 62.983552631578945\n",
            "Epoch #0. Accuracy on batch 950/3013  on Training is 62.98304416403786\n",
            "Epoch #0. Accuracy on batch 951/3013  on Training is 63.002232142857146\n",
            "Epoch #0. Accuracy on batch 952/3013  on Training is 63.01810073452256\n",
            "Epoch #0. Accuracy on batch 953/3013  on Training is 63.027384696016775\n",
            "Epoch #0. Accuracy on batch 954/3013  on Training is 63.02356020942408\n",
            "Epoch #0. Accuracy on batch 955/3013  on Training is 63.01647489539749\n",
            "Epoch #0. Accuracy on batch 956/3013  on Training is 63.01920062695925\n",
            "Epoch #0. Accuracy on batch 957/3013  on Training is 63.03170668058455\n",
            "Epoch #0. Accuracy on batch 958/3013  on Training is 63.044186652763294\n",
            "Epoch #0. Accuracy on batch 959/3013  on Training is 63.063151041666664\n",
            "Batch Id 960 is having training loss of 1.6557261943817139\n",
            "0.725489616394043\n",
            "Epoch #0. Accuracy on batch 960/3013  on Training is 63.085327783558796\n",
            "Epoch #0. Accuracy on batch 961/3013  on Training is 63.094464656964654\n",
            "Epoch #0. Accuracy on batch 962/3013  on Training is 63.11656282450675\n",
            "Epoch #0. Accuracy on batch 963/3013  on Training is 63.115923236514526\n",
            "Epoch #0. Accuracy on batch 964/3013  on Training is 63.13147668393783\n",
            "Epoch #0. Accuracy on batch 965/3013  on Training is 63.13729296066253\n",
            "Epoch #0. Accuracy on batch 966/3013  on Training is 63.14956049638056\n",
            "Epoch #0. Accuracy on batch 967/3013  on Training is 63.165030991735534\n",
            "Epoch #0. Accuracy on batch 968/3013  on Training is 63.18369453044376\n",
            "Epoch #0. Accuracy on batch 969/3013  on Training is 63.186211340206185\n",
            "Epoch #0. Accuracy on batch 970/3013  on Training is 63.19194129763131\n",
            "Epoch #0. Accuracy on batch 971/3013  on Training is 63.17836934156379\n",
            "Epoch #0. Accuracy on batch 972/3013  on Training is 63.18409558067832\n",
            "Epoch #0. Accuracy on batch 973/3013  on Training is 63.18981006160164\n",
            "Epoch #0. Accuracy on batch 974/3013  on Training is 63.21153846153846\n",
            "Epoch #0. Accuracy on batch 975/3013  on Training is 63.217213114754095\n",
            "Epoch #0. Accuracy on batch 976/3013  on Training is 63.21967758444217\n",
            "Epoch #0. Accuracy on batch 977/3013  on Training is 63.234918200409\n",
            "Epoch #0. Accuracy on batch 978/3013  on Training is 63.24693564862104\n",
            "Epoch #0. Accuracy on batch 979/3013  on Training is 63.265306122448976\n",
            "Batch Id 980 is having training loss of 1.6447967290878296\n",
            "0.7990992665290833\n",
            "Epoch #0. Accuracy on batch 980/3013  on Training is 63.28363914373089\n",
            "Epoch #0. Accuracy on batch 981/3013  on Training is 63.30829938900204\n",
            "Epoch #0. Accuracy on batch 982/3013  on Training is 63.3042980671414\n",
            "Epoch #0. Accuracy on batch 983/3013  on Training is 63.31618394308943\n",
            "Epoch #0. Accuracy on batch 984/3013  on Training is 63.328045685279186\n",
            "Epoch #0. Accuracy on batch 985/3013  on Training is 63.32720588235294\n",
            "Epoch #0. Accuracy on batch 986/3013  on Training is 63.32953394123607\n",
            "Epoch #0. Accuracy on batch 987/3013  on Training is 63.34134615384615\n",
            "Epoch #0. Accuracy on batch 988/3013  on Training is 63.33417593528817\n",
            "Epoch #0. Accuracy on batch 989/3013  on Training is 63.34911616161616\n",
            "Epoch #0. Accuracy on batch 990/3013  on Training is 63.376639757820385\n",
            "Epoch #0. Accuracy on batch 991/3013  on Training is 63.391507056451616\n",
            "Epoch #0. Accuracy on batch 992/3013  on Training is 63.409491440080565\n",
            "Epoch #0. Accuracy on batch 993/3013  on Training is 63.42115191146881\n",
            "Epoch #0. Accuracy on batch 994/3013  on Training is 63.43278894472362\n",
            "Epoch #0. Accuracy on batch 995/3013  on Training is 63.422439759036145\n",
            "Epoch #0. Accuracy on batch 996/3013  on Training is 63.44032096288866\n",
            "Epoch #0. Accuracy on batch 997/3013  on Training is 63.44877254509018\n",
            "Epoch #0. Accuracy on batch 998/3013  on Training is 63.441566566566564\n",
            "Epoch #0. Accuracy on batch 999/3013  on Training is 63.45\n",
            "Batch Id 1000 is having training loss of 1.634751558303833\n",
            "0.8749265074729919\n",
            "Epoch #0. Accuracy on batch 1000/3013  on Training is 63.46153846153846\n",
            "Epoch #0. Accuracy on batch 1001/3013  on Training is 63.46993512974052\n",
            "Epoch #0. Accuracy on batch 1002/3013  on Training is 63.48454636091725\n",
            "Epoch #0. Accuracy on batch 1003/3013  on Training is 63.48356573705179\n",
            "Epoch #0. Accuracy on batch 1004/3013  on Training is 63.49813432835821\n",
            "Epoch #0. Accuracy on batch 1005/3013  on Training is 63.50335487077535\n",
            "Epoch #0. Accuracy on batch 1006/3013  on Training is 63.52408142999007\n",
            "Epoch #0. Accuracy on batch 1007/3013  on Training is 63.52926587301587\n",
            "Epoch #0. Accuracy on batch 1008/3013  on Training is 63.54682854311199\n",
            "Epoch #0. Accuracy on batch 1009/3013  on Training is 63.54888613861386\n",
            "Epoch #0. Accuracy on batch 1010/3013  on Training is 63.55403066271019\n",
            "Epoch #0. Accuracy on batch 1011/3013  on Training is 63.56534090909091\n",
            "Epoch #0. Accuracy on batch 1012/3013  on Training is 63.58279861796644\n",
            "Epoch #0. Accuracy on batch 1013/3013  on Training is 63.58173076923077\n",
            "Epoch #0. Accuracy on batch 1014/3013  on Training is 63.60221674876847\n",
            "Epoch #0. Accuracy on batch 1015/3013  on Training is 63.610359251968504\n",
            "Epoch #0. Accuracy on batch 1016/3013  on Training is 63.61848574237955\n",
            "Epoch #0. Accuracy on batch 1017/3013  on Training is 63.62352652259332\n",
            "Epoch #0. Accuracy on batch 1018/3013  on Training is 63.61322374877331\n",
            "Epoch #0. Accuracy on batch 1019/3013  on Training is 63.61825980392157\n",
            "Batch Id 1020 is having training loss of 1.6249604225158691\n",
            "0.6751200556755066\n",
            "Epoch #0. Accuracy on batch 1020/3013  on Training is 63.63858961802155\n",
            "Epoch #0. Accuracy on batch 1021/3013  on Training is 63.64664872798434\n",
            "Epoch #0. Accuracy on batch 1022/3013  on Training is 63.64552785923754\n",
            "Epoch #0. Accuracy on batch 1023/3013  on Training is 63.653564453125\n",
            "Epoch #0. Accuracy on batch 1024/3013  on Training is 63.66158536585366\n",
            "Epoch #0. Accuracy on batch 1025/3013  on Training is 63.66349902534113\n",
            "Epoch #0. Accuracy on batch 1026/3013  on Training is 63.66236611489776\n",
            "Epoch #0. Accuracy on batch 1027/3013  on Training is 63.67643482490272\n",
            "Epoch #0. Accuracy on batch 1028/3013  on Training is 63.68743926141885\n",
            "Epoch #0. Accuracy on batch 1029/3013  on Training is 63.70145631067961\n",
            "Epoch #0. Accuracy on batch 1030/3013  on Training is 63.71544616876819\n",
            "Epoch #0. Accuracy on batch 1031/3013  on Training is 63.71124031007752\n",
            "Epoch #0. Accuracy on batch 1032/3013  on Training is 63.72216844143272\n",
            "Epoch #0. Accuracy on batch 1033/3013  on Training is 63.745164410058024\n",
            "Epoch #0. Accuracy on batch 1034/3013  on Training is 63.743961352657\n",
            "Epoch #0. Accuracy on batch 1035/3013  on Training is 63.75180984555985\n",
            "Epoch #0. Accuracy on batch 1036/3013  on Training is 63.74457569913211\n",
            "Epoch #0. Accuracy on batch 1037/3013  on Training is 63.752408477842\n",
            "Epoch #0. Accuracy on batch 1038/3013  on Training is 63.75721847930703\n",
            "Epoch #0. Accuracy on batch 1039/3013  on Training is 63.76201923076923\n",
            "Batch Id 1040 is having training loss of 1.6174501180648804\n",
            "1.5044355392456055\n",
            "Epoch #0. Accuracy on batch 1040/3013  on Training is 63.76080691642651\n",
            "Epoch #0. Accuracy on batch 1041/3013  on Training is 63.76559500959693\n",
            "Epoch #0. Accuracy on batch 1042/3013  on Training is 63.78835091083413\n",
            "Epoch #0. Accuracy on batch 1043/3013  on Training is 63.790110153256705\n",
            "Epoch #0. Accuracy on batch 1044/3013  on Training is 63.785885167464116\n",
            "Epoch #0. Accuracy on batch 1045/3013  on Training is 63.793618546845124\n",
            "Epoch #0. Accuracy on batch 1046/3013  on Training is 63.801337153772685\n",
            "Epoch #0. Accuracy on batch 1047/3013  on Training is 63.80307729007634\n",
            "Epoch #0. Accuracy on batch 1048/3013  on Training is 63.81077216396568\n",
            "Epoch #0. Accuracy on batch 1049/3013  on Training is 63.833333333333336\n",
            "Epoch #0. Accuracy on batch 1050/3013  on Training is 63.840984776403424\n",
            "Epoch #0. Accuracy on batch 1051/3013  on Training is 63.848621673003805\n",
            "Epoch #0. Accuracy on batch 1052/3013  on Training is 63.85921177587844\n",
            "Epoch #0. Accuracy on batch 1053/3013  on Training is 63.87571157495256\n",
            "Epoch #0. Accuracy on batch 1054/3013  on Training is 63.87440758293839\n",
            "Epoch #0. Accuracy on batch 1055/3013  on Training is 63.88790246212121\n",
            "Epoch #0. Accuracy on batch 1056/3013  on Training is 63.89841532639546\n",
            "Epoch #0. Accuracy on batch 1057/3013  on Training is 63.91186200378072\n",
            "Epoch #0. Accuracy on batch 1058/3013  on Training is 63.91938149197356\n",
            "Epoch #0. Accuracy on batch 1059/3013  on Training is 63.941627358490564\n",
            "Batch Id 1060 is having training loss of 1.608741283416748\n",
            "0.8758288025856018\n",
            "Epoch #0. Accuracy on batch 1060/3013  on Training is 63.952049952874646\n",
            "Epoch #0. Accuracy on batch 1061/3013  on Training is 63.965395480225986\n",
            "Epoch #0. Accuracy on batch 1062/3013  on Training is 63.98165569143932\n",
            "Epoch #0. Accuracy on batch 1063/3013  on Training is 64.00375939849624\n",
            "Epoch #0. Accuracy on batch 1064/3013  on Training is 64.02288732394366\n",
            "Epoch #0. Accuracy on batch 1065/3013  on Training is 64.03318480300187\n",
            "Epoch #0. Accuracy on batch 1066/3013  on Training is 64.0200328022493\n",
            "Epoch #0. Accuracy on batch 1067/3013  on Training is 64.03031367041199\n",
            "Epoch #0. Accuracy on batch 1068/3013  on Training is 64.03180542563143\n",
            "Epoch #0. Accuracy on batch 1069/3013  on Training is 64.0391355140187\n",
            "Epoch #0. Accuracy on batch 1070/3013  on Training is 64.04353408029878\n",
            "Epoch #0. Accuracy on batch 1071/3013  on Training is 64.0450093283582\n",
            "Epoch #0. Accuracy on batch 1072/3013  on Training is 64.04648182665424\n",
            "Epoch #0. Accuracy on batch 1073/3013  on Training is 64.04213221601489\n",
            "Epoch #0. Accuracy on batch 1074/3013  on Training is 64.05813953488372\n",
            "Epoch #0. Accuracy on batch 1075/3013  on Training is 64.06830855018588\n",
            "Epoch #0. Accuracy on batch 1076/3013  on Training is 64.09006499535748\n",
            "Epoch #0. Accuracy on batch 1077/3013  on Training is 64.08858998144713\n",
            "Epoch #0. Accuracy on batch 1078/3013  on Training is 64.10159870250232\n",
            "Epoch #0. Accuracy on batch 1079/3013  on Training is 64.12037037037037\n",
            "Batch Id 1080 is having training loss of 1.5993632078170776\n",
            "1.058250069618225\n",
            "Epoch #0. Accuracy on batch 1080/3013  on Training is 64.1304347826087\n",
            "Epoch #0. Accuracy on batch 1081/3013  on Training is 64.14048059149722\n",
            "Epoch #0. Accuracy on batch 1082/3013  on Training is 64.14473684210526\n",
            "Epoch #0. Accuracy on batch 1083/3013  on Training is 64.15475092250922\n",
            "Epoch #0. Accuracy on batch 1084/3013  on Training is 64.1589861751152\n",
            "Epoch #0. Accuracy on batch 1085/3013  on Training is 64.166091160221\n",
            "Epoch #0. Accuracy on batch 1086/3013  on Training is 64.1818077276909\n",
            "Epoch #0. Accuracy on batch 1087/3013  on Training is 64.16877297794117\n",
            "Epoch #0. Accuracy on batch 1088/3013  on Training is 64.17871900826447\n",
            "Epoch #0. Accuracy on batch 1089/3013  on Training is 64.19438073394495\n",
            "Epoch #0. Accuracy on batch 1090/3013  on Training is 64.19855637030247\n",
            "Epoch #0. Accuracy on batch 1091/3013  on Training is 64.21130952380952\n",
            "Epoch #0. Accuracy on batch 1092/3013  on Training is 64.21546203110705\n",
            "Epoch #0. Accuracy on batch 1093/3013  on Training is 64.23674588665448\n",
            "Epoch #0. Accuracy on batch 1094/3013  on Training is 64.23801369863014\n",
            "Epoch #0. Accuracy on batch 1095/3013  on Training is 64.24213047445255\n",
            "Epoch #0. Accuracy on batch 1096/3013  on Training is 64.2376937101185\n",
            "Epoch #0. Accuracy on batch 1097/3013  on Training is 64.24749544626594\n",
            "Epoch #0. Accuracy on batch 1098/3013  on Training is 64.25443585077343\n",
            "Epoch #0. Accuracy on batch 1099/3013  on Training is 64.2528409090909\n",
            "Batch Id 1100 is having training loss of 1.5918301343917847\n",
            "1.3273741006851196\n",
            "Epoch #0. Accuracy on batch 1100/3013  on Training is 64.26827883742052\n",
            "Epoch #0. Accuracy on batch 1101/3013  on Training is 64.28652450090745\n",
            "Epoch #0. Accuracy on batch 1102/3013  on Training is 64.28490480507706\n",
            "Epoch #0. Accuracy on batch 1103/3013  on Training is 64.29461050724638\n",
            "Epoch #0. Accuracy on batch 1104/3013  on Training is 64.30429864253394\n",
            "Epoch #0. Accuracy on batch 1105/3013  on Training is 64.32809674502712\n",
            "Epoch #0. Accuracy on batch 1106/3013  on Training is 64.32644534778682\n",
            "Epoch #0. Accuracy on batch 1107/3013  on Training is 64.33607851985559\n",
            "Epoch #0. Accuracy on batch 1108/3013  on Training is 64.35414788097385\n",
            "Epoch #0. Accuracy on batch 1109/3013  on Training is 64.35810810810811\n",
            "Epoch #0. Accuracy on batch 1110/3013  on Training is 64.35643564356435\n",
            "Epoch #0. Accuracy on batch 1111/3013  on Training is 64.3519559352518\n",
            "Epoch #0. Accuracy on batch 1112/3013  on Training is 64.35871518418688\n",
            "Epoch #0. Accuracy on batch 1113/3013  on Training is 64.36265709156194\n",
            "Epoch #0. Accuracy on batch 1114/3013  on Training is 64.36378923766816\n",
            "Epoch #0. Accuracy on batch 1115/3013  on Training is 64.3649193548387\n",
            "Epoch #0. Accuracy on batch 1116/3013  on Training is 64.36884512085945\n",
            "Epoch #0. Accuracy on batch 1117/3013  on Training is 64.38394454382826\n",
            "Epoch #0. Accuracy on batch 1118/3013  on Training is 64.40460232350313\n",
            "Epoch #0. Accuracy on batch 1119/3013  on Training is 64.41127232142857\n",
            "Batch Id 1120 is having training loss of 1.58201265335083\n",
            "0.9553431272506714\n",
            "Epoch #0. Accuracy on batch 1120/3013  on Training is 64.4207181088314\n",
            "Epoch #0. Accuracy on batch 1121/3013  on Training is 64.43293226381462\n",
            "Epoch #0. Accuracy on batch 1122/3013  on Training is 64.45069011576135\n",
            "Epoch #0. Accuracy on batch 1123/3013  on Training is 64.46563612099644\n",
            "Epoch #0. Accuracy on batch 1124/3013  on Training is 64.47222222222223\n",
            "Epoch #0. Accuracy on batch 1125/3013  on Training is 64.47879662522203\n",
            "Epoch #0. Accuracy on batch 1126/3013  on Training is 64.49645075421473\n",
            "Epoch #0. Accuracy on batch 1127/3013  on Training is 64.50022163120568\n",
            "Epoch #0. Accuracy on batch 1128/3013  on Training is 64.50675376439327\n",
            "Epoch #0. Accuracy on batch 1129/3013  on Training is 64.51327433628319\n",
            "Epoch #0. Accuracy on batch 1130/3013  on Training is 64.519783377542\n",
            "Epoch #0. Accuracy on batch 1131/3013  on Training is 64.5235203180212\n",
            "Epoch #0. Accuracy on batch 1132/3013  on Training is 64.53276699029126\n",
            "Epoch #0. Accuracy on batch 1133/3013  on Training is 64.53924162257496\n",
            "Epoch #0. Accuracy on batch 1134/3013  on Training is 64.556718061674\n",
            "Epoch #0. Accuracy on batch 1135/3013  on Training is 64.56866197183099\n",
            "Epoch #0. Accuracy on batch 1136/3013  on Training is 64.57508795074759\n",
            "Epoch #0. Accuracy on batch 1137/3013  on Training is 64.58150263620387\n",
            "Epoch #0. Accuracy on batch 1138/3013  on Training is 64.58516242317823\n",
            "Epoch #0. Accuracy on batch 1139/3013  on Training is 64.59978070175438\n",
            "Batch Id 1140 is having training loss of 1.5722860097885132\n",
            "1.6012097597122192\n",
            "Epoch #0. Accuracy on batch 1140/3013  on Training is 64.58972392638037\n",
            "Epoch #0. Accuracy on batch 1141/3013  on Training is 64.58789404553416\n",
            "Epoch #0. Accuracy on batch 1142/3013  on Training is 64.59700349956256\n",
            "Epoch #0. Accuracy on batch 1143/3013  on Training is 64.61429195804196\n",
            "Epoch #0. Accuracy on batch 1144/3013  on Training is 64.62882096069869\n",
            "Epoch #0. Accuracy on batch 1145/3013  on Training is 64.63787085514834\n",
            "Epoch #0. Accuracy on batch 1146/3013  on Training is 64.65780296425457\n",
            "Epoch #0. Accuracy on batch 1147/3013  on Training is 64.66408972125436\n",
            "Epoch #0. Accuracy on batch 1148/3013  on Training is 64.66492602262838\n",
            "Epoch #0. Accuracy on batch 1149/3013  on Training is 64.66576086956522\n",
            "Epoch #0. Accuracy on batch 1150/3013  on Training is 64.6747393570808\n",
            "Epoch #0. Accuracy on batch 1151/3013  on Training is 64.67013888888889\n",
            "Epoch #0. Accuracy on batch 1152/3013  on Training is 64.6872289679098\n",
            "Epoch #0. Accuracy on batch 1153/3013  on Training is 64.69616551126516\n",
            "Epoch #0. Accuracy on batch 1154/3013  on Training is 64.69426406926407\n",
            "Epoch #0. Accuracy on batch 1155/3013  on Training is 64.69506920415225\n",
            "Epoch #0. Accuracy on batch 1156/3013  on Training is 64.70667675021608\n",
            "Epoch #0. Accuracy on batch 1157/3013  on Training is 64.72096286701209\n",
            "Epoch #0. Accuracy on batch 1158/3013  on Training is 64.72443917169974\n",
            "Epoch #0. Accuracy on batch 1159/3013  on Training is 64.73599137931035\n",
            "Batch Id 1160 is having training loss of 1.5644545555114746\n",
            "0.8875594735145569\n",
            "Epoch #0. Accuracy on batch 1160/3013  on Training is 64.74752368647718\n",
            "Epoch #0. Accuracy on batch 1161/3013  on Training is 64.75903614457832\n",
            "Epoch #0. Accuracy on batch 1162/3013  on Training is 64.75440670679278\n",
            "Epoch #0. Accuracy on batch 1163/3013  on Training is 64.74441580756013\n",
            "Epoch #0. Accuracy on batch 1164/3013  on Training is 64.74248927038627\n",
            "Epoch #0. Accuracy on batch 1165/3013  on Training is 64.75128644939966\n",
            "Epoch #0. Accuracy on batch 1166/3013  on Training is 64.75471293916024\n",
            "Epoch #0. Accuracy on batch 1167/3013  on Training is 64.75278253424658\n",
            "Epoch #0. Accuracy on batch 1168/3013  on Training is 64.76956800684346\n",
            "Epoch #0. Accuracy on batch 1169/3013  on Training is 64.78098290598291\n",
            "Epoch #0. Accuracy on batch 1170/3013  on Training is 64.78704099060631\n",
            "Epoch #0. Accuracy on batch 1171/3013  on Training is 64.79575511945393\n",
            "Epoch #0. Accuracy on batch 1172/3013  on Training is 64.80179028132993\n",
            "Epoch #0. Accuracy on batch 1173/3013  on Training is 64.82112436115844\n",
            "Epoch #0. Accuracy on batch 1174/3013  on Training is 64.82978723404256\n",
            "Epoch #0. Accuracy on batch 1175/3013  on Training is 64.84109268707483\n",
            "Epoch #0. Accuracy on batch 1176/3013  on Training is 64.84706881903143\n",
            "Epoch #0. Accuracy on batch 1177/3013  on Training is 64.86099320882852\n",
            "Epoch #0. Accuracy on batch 1178/3013  on Training is 64.86959287531806\n",
            "Epoch #0. Accuracy on batch 1179/3013  on Training is 64.88347457627118\n",
            "Batch Id 1180 is having training loss of 1.5562118291854858\n",
            "0.777199387550354\n",
            "Epoch #0. Accuracy on batch 1180/3013  on Training is 64.8946867061812\n",
            "Epoch #0. Accuracy on batch 1181/3013  on Training is 64.89530456852792\n",
            "Epoch #0. Accuracy on batch 1182/3013  on Training is 64.91441251056635\n",
            "Epoch #0. Accuracy on batch 1183/3013  on Training is 64.92029138513513\n",
            "Epoch #0. Accuracy on batch 1184/3013  on Training is 64.91824894514768\n",
            "Epoch #0. Accuracy on batch 1185/3013  on Training is 64.92147976391232\n",
            "Epoch #0. Accuracy on batch 1186/3013  on Training is 64.93260320134793\n",
            "Epoch #0. Accuracy on batch 1187/3013  on Training is 64.94633838383838\n",
            "Epoch #0. Accuracy on batch 1188/3013  on Training is 64.94953742640875\n",
            "Epoch #0. Accuracy on batch 1189/3013  on Training is 64.96060924369748\n",
            "Epoch #0. Accuracy on batch 1190/3013  on Training is 64.97166246851386\n",
            "Epoch #0. Accuracy on batch 1191/3013  on Training is 64.9722105704698\n",
            "Epoch #0. Accuracy on batch 1192/3013  on Training is 64.98585498742665\n",
            "Epoch #0. Accuracy on batch 1193/3013  on Training is 64.99162479061977\n",
            "Epoch #0. Accuracy on batch 1194/3013  on Training is 64.98692468619247\n",
            "Epoch #0. Accuracy on batch 1195/3013  on Training is 64.9926839464883\n",
            "Epoch #0. Accuracy on batch 1196/3013  on Training is 65.00365497076024\n",
            "Epoch #0. Accuracy on batch 1197/3013  on Training is 65.01982470784641\n",
            "Epoch #0. Accuracy on batch 1198/3013  on Training is 65.02814845704754\n",
            "Epoch #0. Accuracy on batch 1199/3013  on Training is 65.03385416666667\n",
            "Batch Id 1200 is having training loss of 1.5479258298873901\n",
            "0.5862846970558167\n",
            "Epoch #0. Accuracy on batch 1200/3013  on Training is 65.05256036636136\n",
            "Epoch #0. Accuracy on batch 1201/3013  on Training is 65.06343594009984\n",
            "Epoch #0. Accuracy on batch 1202/3013  on Training is 65.07429343308395\n",
            "Epoch #0. Accuracy on batch 1203/3013  on Training is 65.07215531561462\n",
            "Epoch #0. Accuracy on batch 1204/3013  on Training is 65.08558091286307\n",
            "Epoch #0. Accuracy on batch 1205/3013  on Training is 65.08343698175787\n",
            "Epoch #0. Accuracy on batch 1206/3013  on Training is 65.08647473073736\n",
            "Epoch #0. Accuracy on batch 1207/3013  on Training is 65.09209437086092\n",
            "Epoch #0. Accuracy on batch 1208/3013  on Training is 65.11321339950372\n",
            "Epoch #0. Accuracy on batch 1209/3013  on Training is 65.12138429752066\n",
            "Epoch #0. Accuracy on batch 1210/3013  on Training is 65.12438067712634\n",
            "Epoch #0. Accuracy on batch 1211/3013  on Training is 65.1299504950495\n",
            "Epoch #0. Accuracy on batch 1212/3013  on Training is 65.13551112943117\n",
            "Epoch #0. Accuracy on batch 1213/3013  on Training is 65.13591433278418\n",
            "Epoch #0. Accuracy on batch 1214/3013  on Training is 65.1440329218107\n",
            "Epoch #0. Accuracy on batch 1215/3013  on Training is 65.15213815789474\n",
            "Epoch #0. Accuracy on batch 1216/3013  on Training is 65.16279786359901\n",
            "Epoch #0. Accuracy on batch 1217/3013  on Training is 65.17344006568145\n",
            "Epoch #0. Accuracy on batch 1218/3013  on Training is 65.18406480721903\n",
            "Epoch #0. Accuracy on batch 1219/3013  on Training is 65.19211065573771\n",
            "Batch Id 1220 is having training loss of 1.5401902198791504\n",
            "1.3611395359039307\n",
            "Epoch #0. Accuracy on batch 1220/3013  on Training is 65.18990581490581\n",
            "Epoch #0. Accuracy on batch 1221/3013  on Training is 65.19537643207856\n",
            "Epoch #0. Accuracy on batch 1222/3013  on Training is 65.1982829108749\n",
            "Epoch #0. Accuracy on batch 1223/3013  on Training is 65.20373774509804\n",
            "Epoch #0. Accuracy on batch 1224/3013  on Training is 65.21173469387755\n",
            "Epoch #0. Accuracy on batch 1225/3013  on Training is 65.22226753670473\n",
            "Epoch #0. Accuracy on batch 1226/3013  on Training is 65.22768948655256\n",
            "Epoch #0. Accuracy on batch 1227/3013  on Training is 65.2356473941368\n",
            "Epoch #0. Accuracy on batch 1228/3013  on Training is 65.24359235150528\n",
            "Epoch #0. Accuracy on batch 1229/3013  on Training is 65.2515243902439\n",
            "Epoch #0. Accuracy on batch 1230/3013  on Training is 65.2594435418359\n",
            "Epoch #0. Accuracy on batch 1231/3013  on Training is 65.26988636363636\n",
            "Epoch #0. Accuracy on batch 1232/3013  on Training is 65.28284671532846\n",
            "Epoch #0. Accuracy on batch 1233/3013  on Training is 65.29072123176661\n",
            "Epoch #0. Accuracy on batch 1234/3013  on Training is 65.30364372469636\n",
            "Epoch #0. Accuracy on batch 1235/3013  on Training is 65.30137540453075\n",
            "Epoch #0. Accuracy on batch 1236/3013  on Training is 65.29911075181892\n",
            "Epoch #0. Accuracy on batch 1237/3013  on Training is 65.3044224555735\n",
            "Epoch #0. Accuracy on batch 1238/3013  on Training is 65.29459241323649\n",
            "Epoch #0. Accuracy on batch 1239/3013  on Training is 65.29989919354838\n",
            "Batch Id 1240 is having training loss of 1.5330084562301636\n",
            "1.1437617540359497\n",
            "Epoch #0. Accuracy on batch 1240/3013  on Training is 65.30519742143433\n",
            "Epoch #0. Accuracy on batch 1241/3013  on Training is 65.3155193236715\n",
            "Epoch #0. Accuracy on batch 1242/3013  on Training is 65.320796460177\n",
            "Epoch #0. Accuracy on batch 1243/3013  on Training is 65.32355305466238\n",
            "Epoch #0. Accuracy on batch 1244/3013  on Training is 65.32630522088354\n",
            "Epoch #0. Accuracy on batch 1245/3013  on Training is 65.32905296950241\n",
            "Epoch #0. Accuracy on batch 1246/3013  on Training is 65.34182036888532\n",
            "Epoch #0. Accuracy on batch 1247/3013  on Training is 65.34204727564102\n",
            "Epoch #0. Accuracy on batch 1248/3013  on Training is 65.35728582866292\n",
            "Epoch #0. Accuracy on batch 1249/3013  on Training is 65.365\n",
            "Epoch #0. Accuracy on batch 1250/3013  on Training is 65.38019584332534\n",
            "Epoch #0. Accuracy on batch 1251/3013  on Training is 65.39037539936102\n",
            "Epoch #0. Accuracy on batch 1252/3013  on Training is 65.39804469273743\n",
            "Epoch #0. Accuracy on batch 1253/3013  on Training is 65.41068580542264\n",
            "Epoch #0. Accuracy on batch 1254/3013  on Training is 65.41583665338645\n",
            "Epoch #0. Accuracy on batch 1255/3013  on Training is 65.43341958598727\n",
            "Epoch #0. Accuracy on batch 1256/3013  on Training is 65.44351630867143\n",
            "Epoch #0. Accuracy on batch 1257/3013  on Training is 65.45359697933227\n",
            "Epoch #0. Accuracy on batch 1258/3013  on Training is 65.45869737887212\n",
            "Epoch #0. Accuracy on batch 1259/3013  on Training is 65.45882936507937\n",
            "Batch Id 1260 is having training loss of 1.52484929561615\n",
            "1.277844786643982\n",
            "Epoch #0. Accuracy on batch 1260/3013  on Training is 65.45648295003966\n",
            "Epoch #0. Accuracy on batch 1261/3013  on Training is 65.47147385103011\n",
            "Epoch #0. Accuracy on batch 1262/3013  on Training is 65.47406967537609\n",
            "Epoch #0. Accuracy on batch 1263/3013  on Training is 65.48407832278481\n",
            "Epoch #0. Accuracy on batch 1264/3013  on Training is 65.48913043478261\n",
            "Epoch #0. Accuracy on batch 1265/3013  on Training is 65.49911137440758\n",
            "Epoch #0. Accuracy on batch 1266/3013  on Training is 65.50661010260458\n",
            "Epoch #0. Accuracy on batch 1267/3013  on Training is 65.50670347003154\n",
            "Epoch #0. Accuracy on batch 1268/3013  on Training is 65.51664696611505\n",
            "Epoch #0. Accuracy on batch 1269/3013  on Training is 65.52165354330708\n",
            "Epoch #0. Accuracy on batch 1270/3013  on Training is 65.52665224232888\n",
            "Epoch #0. Accuracy on batch 1271/3013  on Training is 65.53409984276729\n",
            "Epoch #0. Accuracy on batch 1272/3013  on Training is 65.53908091123331\n",
            "Epoch #0. Accuracy on batch 1273/3013  on Training is 65.5465070643642\n",
            "Epoch #0. Accuracy on batch 1274/3013  on Training is 65.54901960784314\n",
            "Epoch #0. Accuracy on batch 1275/3013  on Training is 65.54907915360502\n",
            "Epoch #0. Accuracy on batch 1276/3013  on Training is 65.55648003132342\n",
            "Epoch #0. Accuracy on batch 1277/3013  on Training is 65.57365023474179\n",
            "Epoch #0. Accuracy on batch 1278/3013  on Training is 65.58835027365129\n",
            "Epoch #0. Accuracy on batch 1279/3013  on Training is 65.58837890625\n",
            "Batch Id 1280 is having training loss of 1.5166043043136597\n",
            "0.9513148069381714\n",
            "Epoch #0. Accuracy on batch 1280/3013  on Training is 65.60304449648712\n",
            "Epoch #0. Accuracy on batch 1281/3013  on Training is 65.6103744149766\n",
            "Epoch #0. Accuracy on batch 1282/3013  on Training is 65.62256430241621\n",
            "Epoch #0. Accuracy on batch 1283/3013  on Training is 65.62256619937695\n",
            "Epoch #0. Accuracy on batch 1284/3013  on Training is 65.62743190661479\n",
            "Epoch #0. Accuracy on batch 1285/3013  on Training is 65.6420101088647\n",
            "Epoch #0. Accuracy on batch 1286/3013  on Training is 65.64442501942501\n",
            "Epoch #0. Accuracy on batch 1287/3013  on Training is 65.65168866459628\n",
            "Epoch #0. Accuracy on batch 1288/3013  on Training is 65.65651667959659\n",
            "Epoch #0. Accuracy on batch 1289/3013  on Training is 65.64922480620154\n",
            "Epoch #0. Accuracy on batch 1290/3013  on Training is 65.65404725019364\n",
            "Epoch #0. Accuracy on batch 1291/3013  on Training is 65.656443498452\n",
            "Epoch #0. Accuracy on batch 1292/3013  on Training is 65.67333720030936\n",
            "Epoch #0. Accuracy on batch 1293/3013  on Training is 65.66846986089645\n",
            "Epoch #0. Accuracy on batch 1294/3013  on Training is 65.66843629343629\n",
            "Epoch #0. Accuracy on batch 1295/3013  on Training is 65.68045910493827\n",
            "Epoch #0. Accuracy on batch 1296/3013  on Training is 65.68282575173477\n",
            "Epoch #0. Accuracy on batch 1297/3013  on Training is 65.69722650231125\n",
            "Epoch #0. Accuracy on batch 1298/3013  on Training is 65.70679368745189\n",
            "Epoch #0. Accuracy on batch 1299/3013  on Training is 65.71875\n",
            "Batch Id 1300 is having training loss of 1.5096834897994995\n",
            "1.0428810119628906\n",
            "Epoch #0. Accuracy on batch 1300/3013  on Training is 65.728285933897\n",
            "Epoch #0. Accuracy on batch 1301/3013  on Training is 65.74020737327189\n",
            "Epoch #0. Accuracy on batch 1302/3013  on Training is 65.7569071373753\n",
            "Epoch #0. Accuracy on batch 1303/3013  on Training is 65.7568059815951\n",
            "Epoch #0. Accuracy on batch 1304/3013  on Training is 65.76867816091954\n",
            "Epoch #0. Accuracy on batch 1305/3013  on Training is 65.77574655436447\n",
            "Epoch #0. Accuracy on batch 1306/3013  on Training is 65.78041315990819\n",
            "Epoch #0. Accuracy on batch 1307/3013  on Training is 65.78268348623853\n",
            "Epoch #0. Accuracy on batch 1308/3013  on Training is 65.77301375095493\n",
            "Epoch #0. Accuracy on batch 1309/3013  on Training is 65.7824427480916\n",
            "Epoch #0. Accuracy on batch 1310/3013  on Training is 65.79185736079329\n",
            "Epoch #0. Accuracy on batch 1311/3013  on Training is 65.79649390243902\n",
            "Epoch #0. Accuracy on batch 1312/3013  on Training is 65.79160319878142\n",
            "Epoch #0. Accuracy on batch 1313/3013  on Training is 65.80336757990868\n",
            "Epoch #0. Accuracy on batch 1314/3013  on Training is 65.80085551330798\n",
            "Epoch #0. Accuracy on batch 1315/3013  on Training is 65.79122340425532\n",
            "Epoch #0. Accuracy on batch 1316/3013  on Training is 65.80058845861807\n",
            "Epoch #0. Accuracy on batch 1317/3013  on Training is 65.79571320182094\n",
            "Epoch #0. Accuracy on batch 1318/3013  on Training is 65.80269143290371\n",
            "Epoch #0. Accuracy on batch 1319/3013  on Training is 65.81676136363636\n",
            "Batch Id 1320 is having training loss of 1.5024431943893433\n",
            "0.9157901406288147\n",
            "Epoch #0. Accuracy on batch 1320/3013  on Training is 65.82607872823618\n",
            "Epoch #0. Accuracy on batch 1321/3013  on Training is 65.83538199697428\n",
            "Epoch #0. Accuracy on batch 1322/3013  on Training is 65.84467120181407\n",
            "Epoch #0. Accuracy on batch 1323/3013  on Training is 65.86102719033232\n",
            "Epoch #0. Accuracy on batch 1324/3013  on Training is 65.87264150943396\n",
            "Epoch #0. Accuracy on batch 1325/3013  on Training is 65.87952488687783\n",
            "Epoch #0. Accuracy on batch 1326/3013  on Training is 65.87933308214016\n",
            "Epoch #0. Accuracy on batch 1327/3013  on Training is 65.89090737951807\n",
            "Epoch #0. Accuracy on batch 1328/3013  on Training is 65.90246425884123\n",
            "Epoch #0. Accuracy on batch 1329/3013  on Training is 65.9093045112782\n",
            "Epoch #0. Accuracy on batch 1330/3013  on Training is 65.9090909090909\n",
            "Epoch #0. Accuracy on batch 1331/3013  on Training is 65.91356981981981\n",
            "Epoch #0. Accuracy on batch 1332/3013  on Training is 65.9274193548387\n",
            "Epoch #0. Accuracy on batch 1333/3013  on Training is 65.94359070464768\n",
            "Epoch #0. Accuracy on batch 1334/3013  on Training is 65.95505617977528\n",
            "Epoch #0. Accuracy on batch 1335/3013  on Training is 65.95480913173652\n",
            "Epoch #0. Accuracy on batch 1336/3013  on Training is 65.96391174270755\n",
            "Epoch #0. Accuracy on batch 1337/3013  on Training is 65.97066517189836\n",
            "Epoch #0. Accuracy on batch 1338/3013  on Training is 65.97974234503361\n",
            "Epoch #0. Accuracy on batch 1339/3013  on Training is 65.9911380597015\n",
            "Batch Id 1340 is having training loss of 1.495126724243164\n",
            "0.943310022354126\n",
            "Epoch #0. Accuracy on batch 1340/3013  on Training is 65.99552572706935\n",
            "Epoch #0. Accuracy on batch 1341/3013  on Training is 66.00456408345752\n",
            "Epoch #0. Accuracy on batch 1342/3013  on Training is 66.01126209977662\n",
            "Epoch #0. Accuracy on batch 1343/3013  on Training is 66.02027529761905\n",
            "Epoch #0. Accuracy on batch 1344/3013  on Training is 66.02695167286245\n",
            "Epoch #0. Accuracy on batch 1345/3013  on Training is 66.03826151560179\n",
            "Epoch #0. Accuracy on batch 1346/3013  on Training is 66.0449146250928\n",
            "Epoch #0. Accuracy on batch 1347/3013  on Training is 66.05387611275964\n",
            "Epoch #0. Accuracy on batch 1348/3013  on Training is 66.0628243143069\n",
            "Epoch #0. Accuracy on batch 1349/3013  on Training is 66.06018518518519\n",
            "Epoch #0. Accuracy on batch 1350/3013  on Training is 66.06680236861584\n",
            "Epoch #0. Accuracy on batch 1351/3013  on Training is 66.06878698224853\n",
            "Epoch #0. Accuracy on batch 1352/3013  on Training is 66.06383961566888\n",
            "Epoch #0. Accuracy on batch 1353/3013  on Training is 66.06351550960119\n",
            "Epoch #0. Accuracy on batch 1354/3013  on Training is 66.07472324723247\n",
            "Epoch #0. Accuracy on batch 1355/3013  on Training is 66.07900073746313\n",
            "Epoch #0. Accuracy on batch 1356/3013  on Training is 66.08327192336036\n",
            "Epoch #0. Accuracy on batch 1357/3013  on Training is 66.09904270986745\n",
            "Epoch #0. Accuracy on batch 1358/3013  on Training is 66.10099337748345\n",
            "Epoch #0. Accuracy on batch 1359/3013  on Training is 66.10523897058823\n",
            "Batch Id 1360 is having training loss of 1.489107370376587\n",
            "0.9702293872833252\n",
            "Epoch #0. Accuracy on batch 1360/3013  on Training is 66.1094783247612\n",
            "Epoch #0. Accuracy on batch 1361/3013  on Training is 66.12059471365639\n",
            "Epoch #0. Accuracy on batch 1362/3013  on Training is 66.129402054292\n",
            "Epoch #0. Accuracy on batch 1363/3013  on Training is 66.13819648093842\n",
            "Epoch #0. Accuracy on batch 1364/3013  on Training is 66.1492673992674\n",
            "Epoch #0. Accuracy on batch 1365/3013  on Training is 66.15117130307468\n",
            "Epoch #0. Accuracy on batch 1366/3013  on Training is 66.14850036576445\n",
            "Epoch #0. Accuracy on batch 1367/3013  on Training is 66.15268640350877\n",
            "Epoch #0. Accuracy on batch 1368/3013  on Training is 66.15914901387875\n",
            "Epoch #0. Accuracy on batch 1369/3013  on Training is 66.16332116788321\n",
            "Epoch #0. Accuracy on batch 1370/3013  on Training is 66.17432530999271\n",
            "Epoch #0. Accuracy on batch 1371/3013  on Training is 66.18303571428571\n",
            "Epoch #0. Accuracy on batch 1372/3013  on Training is 66.19628550619082\n",
            "Epoch #0. Accuracy on batch 1373/3013  on Training is 66.19586972343522\n",
            "Epoch #0. Accuracy on batch 1374/3013  on Training is 66.20454545454545\n",
            "Epoch #0. Accuracy on batch 1375/3013  on Training is 66.20866642441861\n",
            "Epoch #0. Accuracy on batch 1376/3013  on Training is 66.21278140885984\n",
            "Epoch #0. Accuracy on batch 1377/3013  on Training is 66.21689042089986\n",
            "Epoch #0. Accuracy on batch 1378/3013  on Training is 66.2232596084119\n",
            "Epoch #0. Accuracy on batch 1379/3013  on Training is 66.22282608695652\n",
            "Batch Id 1380 is having training loss of 1.4834126234054565\n",
            "0.9297190308570862\n",
            "Epoch #0. Accuracy on batch 1380/3013  on Training is 66.22918175235337\n",
            "Epoch #0. Accuracy on batch 1381/3013  on Training is 66.22422214182345\n",
            "Epoch #0. Accuracy on batch 1382/3013  on Training is 66.22604844540854\n",
            "Epoch #0. Accuracy on batch 1383/3013  on Training is 66.23464595375722\n",
            "Epoch #0. Accuracy on batch 1384/3013  on Training is 66.24097472924188\n",
            "Epoch #0. Accuracy on batch 1385/3013  on Training is 66.24729437229438\n",
            "Epoch #0. Accuracy on batch 1386/3013  on Training is 66.26487022350396\n",
            "Epoch #0. Accuracy on batch 1387/3013  on Training is 66.27791786743516\n",
            "Epoch #0. Accuracy on batch 1388/3013  on Training is 66.29094672426206\n",
            "Epoch #0. Accuracy on batch 1389/3013  on Training is 66.29946043165468\n",
            "Epoch #0. Accuracy on batch 1390/3013  on Training is 66.30122214234363\n",
            "Epoch #0. Accuracy on batch 1391/3013  on Training is 66.30522629310344\n",
            "Epoch #0. Accuracy on batch 1392/3013  on Training is 66.31595477386935\n",
            "Epoch #0. Accuracy on batch 1393/3013  on Training is 66.32666786226686\n",
            "Epoch #0. Accuracy on batch 1394/3013  on Training is 66.32168458781362\n",
            "Epoch #0. Accuracy on batch 1395/3013  on Training is 66.3323782234957\n",
            "Epoch #0. Accuracy on batch 1396/3013  on Training is 66.34529348604151\n",
            "Epoch #0. Accuracy on batch 1397/3013  on Training is 66.34924892703863\n",
            "Epoch #0. Accuracy on batch 1398/3013  on Training is 66.34873123659757\n",
            "Epoch #0. Accuracy on batch 1399/3013  on Training is 66.36160714285714\n",
            "Batch Id 1400 is having training loss of 1.4769152402877808\n",
            "1.5198382139205933\n",
            "Epoch #0. Accuracy on batch 1400/3013  on Training is 66.3633119200571\n",
            "Epoch #0. Accuracy on batch 1401/3013  on Training is 66.37393009985735\n",
            "Epoch #0. Accuracy on batch 1402/3013  on Training is 66.38898788310763\n",
            "Epoch #0. Accuracy on batch 1403/3013  on Training is 66.40179843304843\n",
            "Epoch #0. Accuracy on batch 1404/3013  on Training is 66.4079181494662\n",
            "Epoch #0. Accuracy on batch 1405/3013  on Training is 66.42069701280228\n",
            "Epoch #0. Accuracy on batch 1406/3013  on Training is 66.4223525230988\n",
            "Epoch #0. Accuracy on batch 1407/3013  on Training is 66.42622514204545\n",
            "Epoch #0. Accuracy on batch 1408/3013  on Training is 66.43674591909155\n",
            "Epoch #0. Accuracy on batch 1409/3013  on Training is 66.44946808510639\n",
            "Epoch #0. Accuracy on batch 1410/3013  on Training is 66.45552799433027\n",
            "Epoch #0. Accuracy on batch 1411/3013  on Training is 66.46600566572238\n",
            "Epoch #0. Accuracy on batch 1412/3013  on Training is 66.47204529370134\n",
            "Epoch #0. Accuracy on batch 1413/3013  on Training is 66.48249646393211\n",
            "Epoch #0. Accuracy on batch 1414/3013  on Training is 66.47305653710248\n",
            "Epoch #0. Accuracy on batch 1415/3013  on Training is 66.48790607344633\n",
            "Epoch #0. Accuracy on batch 1416/3013  on Training is 66.48068101623147\n",
            "Epoch #0. Accuracy on batch 1417/3013  on Training is 66.4888928067701\n",
            "Epoch #0. Accuracy on batch 1418/3013  on Training is 66.48608174770966\n",
            "Epoch #0. Accuracy on batch 1419/3013  on Training is 66.48987676056338\n",
            "Batch Id 1420 is having training loss of 1.4707084894180298\n",
            "1.0292537212371826\n",
            "Epoch #0. Accuracy on batch 1420/3013  on Training is 66.49366643209008\n",
            "Epoch #0. Accuracy on batch 1421/3013  on Training is 66.50404360056258\n",
            "Epoch #0. Accuracy on batch 1422/3013  on Training is 66.50781799016163\n",
            "Epoch #0. Accuracy on batch 1423/3013  on Training is 66.51597612359551\n",
            "Epoch #0. Accuracy on batch 1424/3013  on Training is 66.52412280701755\n",
            "Epoch #0. Accuracy on batch 1425/3013  on Training is 66.523492286115\n",
            "Epoch #0. Accuracy on batch 1426/3013  on Training is 66.52943237561317\n",
            "Epoch #0. Accuracy on batch 1427/3013  on Training is 66.53317577030812\n",
            "Epoch #0. Accuracy on batch 1428/3013  on Training is 66.54128761371588\n",
            "Epoch #0. Accuracy on batch 1429/3013  on Training is 66.5472027972028\n",
            "Epoch #0. Accuracy on batch 1430/3013  on Training is 66.55310971348707\n",
            "Epoch #0. Accuracy on batch 1431/3013  on Training is 66.55027932960894\n",
            "Epoch #0. Accuracy on batch 1432/3013  on Training is 66.54745289602234\n",
            "Epoch #0. Accuracy on batch 1433/3013  on Training is 66.55116806136681\n",
            "Epoch #0. Accuracy on batch 1434/3013  on Training is 66.55923344947735\n",
            "Epoch #0. Accuracy on batch 1435/3013  on Training is 66.56728760445682\n",
            "Epoch #0. Accuracy on batch 1436/3013  on Training is 66.57098121085595\n",
            "Epoch #0. Accuracy on batch 1437/3013  on Training is 66.56597705146037\n",
            "Epoch #0. Accuracy on batch 1438/3013  on Training is 66.56966643502432\n",
            "Epoch #0. Accuracy on batch 1439/3013  on Training is 66.57335069444444\n",
            "Batch Id 1440 is having training loss of 1.4648443460464478\n",
            "0.55536288022995\n",
            "Epoch #0. Accuracy on batch 1440/3013  on Training is 66.58570437196391\n",
            "Epoch #0. Accuracy on batch 1441/3013  on Training is 66.59153952843273\n",
            "Epoch #0. Accuracy on batch 1442/3013  on Training is 66.59520097020096\n",
            "Epoch #0. Accuracy on batch 1443/3013  on Training is 66.60751385041551\n",
            "Epoch #0. Accuracy on batch 1444/3013  on Training is 66.61115916955018\n",
            "Epoch #0. Accuracy on batch 1445/3013  on Training is 66.60615491009682\n",
            "Epoch #0. Accuracy on batch 1446/3013  on Training is 66.62059433310297\n",
            "Epoch #0. Accuracy on batch 1447/3013  on Training is 66.62422306629834\n",
            "Epoch #0. Accuracy on batch 1448/3013  on Training is 66.6213768115942\n",
            "Epoch #0. Accuracy on batch 1449/3013  on Training is 66.625\n",
            "Epoch #0. Accuracy on batch 1450/3013  on Training is 66.63077188146106\n",
            "Epoch #0. Accuracy on batch 1451/3013  on Training is 66.64299242424242\n",
            "Epoch #0. Accuracy on batch 1452/3013  on Training is 66.6508947006194\n",
            "Epoch #0. Accuracy on batch 1453/3013  on Training is 66.65448762035763\n",
            "Epoch #0. Accuracy on batch 1454/3013  on Training is 66.66881443298969\n",
            "Epoch #0. Accuracy on batch 1455/3013  on Training is 66.66595123626374\n",
            "Epoch #0. Accuracy on batch 1456/3013  on Training is 66.67167124227865\n",
            "Epoch #0. Accuracy on batch 1457/3013  on Training is 66.67738340192044\n",
            "Epoch #0. Accuracy on batch 1458/3013  on Training is 66.68522960932145\n",
            "Epoch #0. Accuracy on batch 1459/3013  on Training is 66.68878424657534\n",
            "Batch Id 1460 is having training loss of 1.4583680629730225\n",
            "0.9857862591743469\n",
            "Epoch #0. Accuracy on batch 1460/3013  on Training is 66.70302874743327\n",
            "Epoch #0. Accuracy on batch 1461/3013  on Training is 66.7001538987688\n",
            "Epoch #0. Accuracy on batch 1462/3013  on Training is 66.69941900205058\n",
            "Epoch #0. Accuracy on batch 1463/3013  on Training is 66.70722336065573\n",
            "Epoch #0. Accuracy on batch 1464/3013  on Training is 66.70648464163823\n",
            "Epoch #0. Accuracy on batch 1465/3013  on Training is 66.70787858117326\n",
            "Epoch #0. Accuracy on batch 1466/3013  on Training is 66.70927062031356\n",
            "Epoch #0. Accuracy on batch 1467/3013  on Training is 66.71917574931881\n",
            "Epoch #0. Accuracy on batch 1468/3013  on Training is 66.72694009530292\n",
            "Epoch #0. Accuracy on batch 1469/3013  on Training is 66.72831632653062\n",
            "Epoch #0. Accuracy on batch 1470/3013  on Training is 66.7360639021074\n",
            "Epoch #0. Accuracy on batch 1471/3013  on Training is 66.73106317934783\n",
            "Epoch #0. Accuracy on batch 1472/3013  on Training is 66.73455532926002\n",
            "Epoch #0. Accuracy on batch 1473/3013  on Training is 66.7422829036635\n",
            "Epoch #0. Accuracy on batch 1474/3013  on Training is 66.74364406779661\n",
            "Epoch #0. Accuracy on batch 1475/3013  on Training is 66.74923780487805\n",
            "Epoch #0. Accuracy on batch 1476/3013  on Training is 66.76540284360189\n",
            "Epoch #0. Accuracy on batch 1477/3013  on Training is 66.76674560216509\n",
            "Epoch #0. Accuracy on batch 1478/3013  on Training is 66.77019945909399\n",
            "Epoch #0. Accuracy on batch 1479/3013  on Training is 66.77576013513513\n",
            "Batch Id 1480 is having training loss of 1.4524503946304321\n",
            "1.057952642440796\n",
            "Epoch #0. Accuracy on batch 1480/3013  on Training is 66.78131330182309\n",
            "Epoch #0. Accuracy on batch 1481/3013  on Training is 66.7805330634278\n",
            "Epoch #0. Accuracy on batch 1482/3013  on Training is 66.78186109238031\n",
            "Epoch #0. Accuracy on batch 1483/3013  on Training is 66.78318733153638\n",
            "Epoch #0. Accuracy on batch 1484/3013  on Training is 66.78872053872054\n",
            "Epoch #0. Accuracy on batch 1485/3013  on Training is 66.79214333781965\n",
            "Epoch #0. Accuracy on batch 1486/3013  on Training is 66.7955615332885\n",
            "Epoch #0. Accuracy on batch 1487/3013  on Training is 66.81157594086021\n",
            "Epoch #0. Accuracy on batch 1488/3013  on Training is 66.81707521826729\n",
            "Epoch #0. Accuracy on batch 1489/3013  on Training is 66.82256711409396\n",
            "Epoch #0. Accuracy on batch 1490/3013  on Training is 66.83224346076459\n",
            "Epoch #0. Accuracy on batch 1491/3013  on Training is 66.83981233243968\n",
            "Epoch #0. Accuracy on batch 1492/3013  on Training is 66.85574346952444\n",
            "Epoch #0. Accuracy on batch 1493/3013  on Training is 66.86956157965194\n",
            "Epoch #0. Accuracy on batch 1494/3013  on Training is 66.87081939799332\n",
            "Epoch #0. Accuracy on batch 1495/3013  on Training is 66.87625334224599\n",
            "Epoch #0. Accuracy on batch 1496/3013  on Training is 66.89211756847027\n",
            "Epoch #0. Accuracy on batch 1497/3013  on Training is 66.90587449933244\n",
            "Epoch #0. Accuracy on batch 1498/3013  on Training is 66.9008505670447\n",
            "Epoch #0. Accuracy on batch 1499/3013  on Training is 66.90208333333334\n",
            "Batch Id 1500 is having training loss of 1.4452279806137085\n",
            "0.9194291830062866\n",
            "Epoch #0. Accuracy on batch 1500/3013  on Training is 66.91164223850767\n",
            "Epoch #0. Accuracy on batch 1501/3013  on Training is 66.9232689747004\n",
            "Epoch #0. Accuracy on batch 1502/3013  on Training is 66.92864271457086\n",
            "Epoch #0. Accuracy on batch 1503/3013  on Training is 66.93193151595744\n",
            "Epoch #0. Accuracy on batch 1504/3013  on Training is 66.94144518272425\n",
            "Epoch #0. Accuracy on batch 1505/3013  on Training is 66.94472111553785\n",
            "Epoch #0. Accuracy on batch 1506/3013  on Training is 66.94591904445919\n",
            "Epoch #0. Accuracy on batch 1507/3013  on Training is 66.94711538461539\n",
            "Epoch #0. Accuracy on batch 1508/3013  on Training is 66.95659377070908\n",
            "Epoch #0. Accuracy on batch 1509/3013  on Training is 66.95778145695364\n",
            "Epoch #0. Accuracy on batch 1510/3013  on Training is 66.96724023825281\n",
            "Epoch #0. Accuracy on batch 1511/3013  on Training is 66.96428571428571\n",
            "Epoch #0. Accuracy on batch 1512/3013  on Training is 66.9675313945803\n",
            "Epoch #0. Accuracy on batch 1513/3013  on Training is 66.97696499339499\n",
            "Epoch #0. Accuracy on batch 1514/3013  on Training is 66.98226072607261\n",
            "Epoch #0. Accuracy on batch 1515/3013  on Training is 66.99579485488127\n",
            "Epoch #0. Accuracy on batch 1516/3013  on Training is 67.00107119314437\n",
            "Epoch #0. Accuracy on batch 1517/3013  on Training is 67.00634057971014\n",
            "Epoch #0. Accuracy on batch 1518/3013  on Training is 67.00543120473996\n",
            "Epoch #0. Accuracy on batch 1519/3013  on Training is 67.0045230263158\n",
            "Batch Id 1520 is having training loss of 1.4405635595321655\n",
            "0.8744820952415466\n",
            "Epoch #0. Accuracy on batch 1520/3013  on Training is 67.01799802761342\n",
            "Epoch #0. Accuracy on batch 1521/3013  on Training is 67.02118922470433\n",
            "Epoch #0. Accuracy on batch 1522/3013  on Training is 67.01616874589625\n",
            "Epoch #0. Accuracy on batch 1523/3013  on Training is 67.0173064304462\n",
            "Epoch #0. Accuracy on batch 1524/3013  on Training is 67.03073770491804\n",
            "Epoch #0. Accuracy on batch 1525/3013  on Training is 67.04415137614679\n",
            "Epoch #0. Accuracy on batch 1526/3013  on Training is 67.04526850032744\n",
            "Epoch #0. Accuracy on batch 1527/3013  on Training is 67.05456479057591\n",
            "Epoch #0. Accuracy on batch 1528/3013  on Training is 67.05567364290386\n",
            "Epoch #0. Accuracy on batch 1529/3013  on Training is 67.06699346405229\n",
            "Epoch #0. Accuracy on batch 1530/3013  on Training is 67.07829849771392\n",
            "Epoch #0. Accuracy on batch 1531/3013  on Training is 67.08142950391645\n",
            "Epoch #0. Accuracy on batch 1532/3013  on Training is 67.09271037181996\n",
            "Epoch #0. Accuracy on batch 1533/3013  on Training is 67.09582790091265\n",
            "Epoch #0. Accuracy on batch 1534/3013  on Training is 67.0928338762215\n",
            "Epoch #0. Accuracy on batch 1535/3013  on Training is 67.10205078125\n",
            "Epoch #0. Accuracy on batch 1536/3013  on Training is 67.10515614834092\n",
            "Epoch #0. Accuracy on batch 1537/3013  on Training is 67.11638491547464\n",
            "Epoch #0. Accuracy on batch 1538/3013  on Training is 67.12759909031838\n",
            "Epoch #0. Accuracy on batch 1539/3013  on Training is 67.13068181818181\n",
            "Batch Id 1540 is having training loss of 1.4347809553146362\n",
            "1.2485562562942505\n",
            "Epoch #0. Accuracy on batch 1540/3013  on Training is 67.13376054510059\n",
            "Epoch #0. Accuracy on batch 1541/3013  on Training is 67.13683527885863\n",
            "Epoch #0. Accuracy on batch 1542/3013  on Training is 67.14193130265716\n",
            "Epoch #0. Accuracy on batch 1543/3013  on Training is 67.1470207253886\n",
            "Epoch #0. Accuracy on batch 1544/3013  on Training is 67.1460355987055\n",
            "Epoch #0. Accuracy on batch 1545/3013  on Training is 67.14505174644243\n",
            "Epoch #0. Accuracy on batch 1546/3013  on Training is 67.15214932126698\n",
            "Epoch #0. Accuracy on batch 1547/3013  on Training is 67.1592377260982\n",
            "Epoch #0. Accuracy on batch 1548/3013  on Training is 67.16833440929632\n",
            "Epoch #0. Accuracy on batch 1549/3013  on Training is 67.17540322580645\n",
            "Epoch #0. Accuracy on batch 1550/3013  on Training is 67.18447775628627\n",
            "Epoch #0. Accuracy on batch 1551/3013  on Training is 67.19152706185567\n",
            "Epoch #0. Accuracy on batch 1552/3013  on Training is 67.19856728911783\n",
            "Epoch #0. Accuracy on batch 1553/3013  on Training is 67.20358751608751\n",
            "Epoch #0. Accuracy on batch 1554/3013  on Training is 67.20458199356914\n",
            "Epoch #0. Accuracy on batch 1555/3013  on Training is 67.2116002570694\n",
            "Epoch #0. Accuracy on batch 1556/3013  on Training is 67.21660244059088\n",
            "Epoch #0. Accuracy on batch 1557/3013  on Training is 67.22761553273428\n",
            "Epoch #0. Accuracy on batch 1558/3013  on Training is 67.23260102629891\n",
            "Epoch #0. Accuracy on batch 1559/3013  on Training is 67.23958333333333\n",
            "Batch Id 1560 is having training loss of 1.4289672374725342\n",
            "0.5826035141944885\n",
            "Epoch #0. Accuracy on batch 1560/3013  on Training is 67.25256245996157\n",
            "Epoch #0. Accuracy on batch 1561/3013  on Training is 67.25152048655569\n",
            "Epoch #0. Accuracy on batch 1562/3013  on Training is 67.25847728726808\n",
            "Epoch #0. Accuracy on batch 1563/3013  on Training is 67.25743286445012\n",
            "Epoch #0. Accuracy on batch 1564/3013  on Training is 67.2623801916933\n",
            "Epoch #0. Accuracy on batch 1565/3013  on Training is 67.26532567049809\n",
            "Epoch #0. Accuracy on batch 1566/3013  on Training is 67.26427887683472\n",
            "Epoch #0. Accuracy on batch 1567/3013  on Training is 67.26522640306122\n",
            "Epoch #0. Accuracy on batch 1568/3013  on Training is 67.27214786488209\n",
            "Epoch #0. Accuracy on batch 1569/3013  on Training is 67.28304140127389\n",
            "Epoch #0. Accuracy on batch 1570/3013  on Training is 67.28596435391471\n",
            "Epoch #0. Accuracy on batch 1571/3013  on Training is 67.28093193384224\n",
            "Epoch #0. Accuracy on batch 1572/3013  on Training is 67.29179910998093\n",
            "Epoch #0. Accuracy on batch 1573/3013  on Training is 67.29868170266836\n",
            "Epoch #0. Accuracy on batch 1574/3013  on Training is 67.3015873015873\n",
            "Epoch #0. Accuracy on batch 1575/3013  on Training is 67.30845494923858\n",
            "Epoch #0. Accuracy on batch 1576/3013  on Training is 67.3073874445149\n",
            "Epoch #0. Accuracy on batch 1577/3013  on Training is 67.31028200253485\n",
            "Epoch #0. Accuracy on batch 1578/3013  on Training is 67.32108929702343\n",
            "Epoch #0. Accuracy on batch 1579/3013  on Training is 67.32792721518987\n",
            "Batch Id 1580 is having training loss of 1.424103856086731\n",
            "1.0060667991638184\n",
            "Epoch #0. Accuracy on batch 1580/3013  on Training is 67.33080328905756\n",
            "Epoch #0. Accuracy on batch 1581/3013  on Training is 67.33170037926675\n",
            "Epoch #0. Accuracy on batch 1582/3013  on Training is 67.33654453569173\n",
            "Epoch #0. Accuracy on batch 1583/3013  on Training is 67.33349116161617\n",
            "Epoch #0. Accuracy on batch 1584/3013  on Training is 67.34029968454259\n",
            "Epoch #0. Accuracy on batch 1585/3013  on Training is 67.34709962168978\n",
            "Epoch #0. Accuracy on batch 1586/3013  on Training is 67.3499527410208\n",
            "Epoch #0. Accuracy on batch 1587/3013  on Training is 67.35083438287154\n",
            "Epoch #0. Accuracy on batch 1588/3013  on Training is 67.34974826935179\n",
            "Epoch #0. Accuracy on batch 1589/3013  on Training is 67.34866352201257\n",
            "Epoch #0. Accuracy on batch 1590/3013  on Training is 67.35543683218101\n",
            "Epoch #0. Accuracy on batch 1591/3013  on Training is 67.36809045226131\n",
            "Epoch #0. Accuracy on batch 1592/3013  on Training is 67.37091964846202\n",
            "Epoch #0. Accuracy on batch 1593/3013  on Training is 67.37962672521958\n",
            "Epoch #0. Accuracy on batch 1594/3013  on Training is 67.37656739811912\n",
            "Epoch #0. Accuracy on batch 1595/3013  on Training is 67.37742794486215\n",
            "Epoch #0. Accuracy on batch 1596/3013  on Training is 67.37241703193487\n",
            "Epoch #0. Accuracy on batch 1597/3013  on Training is 67.38305694618273\n",
            "Epoch #0. Accuracy on batch 1598/3013  on Training is 67.38195747342088\n",
            "Epoch #0. Accuracy on batch 1599/3013  on Training is 67.392578125\n",
            "Batch Id 1600 is having training loss of 1.41912043094635\n",
            "0.8076187372207642\n",
            "Epoch #0. Accuracy on batch 1600/3013  on Training is 67.40318550905684\n",
            "Epoch #0. Accuracy on batch 1601/3013  on Training is 67.40207553058677\n",
            "Epoch #0. Accuracy on batch 1602/3013  on Training is 67.41461322520274\n",
            "Epoch #0. Accuracy on batch 1603/3013  on Training is 67.41934226932668\n",
            "Epoch #0. Accuracy on batch 1604/3013  on Training is 67.4221183800623\n",
            "Epoch #0. Accuracy on batch 1605/3013  on Training is 67.42683686176836\n",
            "Epoch #0. Accuracy on batch 1606/3013  on Training is 67.43932794026135\n",
            "Epoch #0. Accuracy on batch 1607/3013  on Training is 67.44208644278606\n",
            "Epoch #0. Accuracy on batch 1608/3013  on Training is 67.45066811684276\n",
            "Epoch #0. Accuracy on batch 1609/3013  on Training is 67.45341614906832\n",
            "Epoch #0. Accuracy on batch 1610/3013  on Training is 67.45616076970826\n",
            "Epoch #0. Accuracy on batch 1611/3013  on Training is 67.46277915632754\n",
            "Epoch #0. Accuracy on batch 1612/3013  on Training is 67.46551456912586\n",
            "Epoch #0. Accuracy on batch 1613/3013  on Training is 67.45856567534076\n",
            "Epoch #0. Accuracy on batch 1614/3013  on Training is 67.46323529411765\n",
            "Epoch #0. Accuracy on batch 1615/3013  on Training is 67.47950185643565\n",
            "Epoch #0. Accuracy on batch 1616/3013  on Training is 67.48995052566481\n",
            "Epoch #0. Accuracy on batch 1617/3013  on Training is 67.50231767614339\n",
            "Epoch #0. Accuracy on batch 1618/3013  on Training is 67.51080914144534\n",
            "Epoch #0. Accuracy on batch 1619/3013  on Training is 67.52121913580247\n",
            "Batch Id 1620 is having training loss of 1.4128620624542236\n",
            "1.4798707962036133\n",
            "Epoch #0. Accuracy on batch 1620/3013  on Training is 67.5161937075879\n",
            "Epoch #0. Accuracy on batch 1621/3013  on Training is 67.5188810110974\n",
            "Epoch #0. Accuracy on batch 1622/3013  on Training is 67.52156500308071\n",
            "Epoch #0. Accuracy on batch 1623/3013  on Training is 67.52039716748769\n",
            "Epoch #0. Accuracy on batch 1624/3013  on Training is 67.51923076923077\n",
            "Epoch #0. Accuracy on batch 1625/3013  on Training is 67.52383148831488\n",
            "Epoch #0. Accuracy on batch 1626/3013  on Training is 67.53034726490473\n",
            "Epoch #0. Accuracy on batch 1627/3013  on Training is 67.52149877149877\n",
            "Epoch #0. Accuracy on batch 1628/3013  on Training is 67.52225291589933\n",
            "Epoch #0. Accuracy on batch 1629/3013  on Training is 67.5191717791411\n",
            "Epoch #0. Accuracy on batch 1630/3013  on Training is 67.5218424279583\n",
            "Epoch #0. Accuracy on batch 1631/3013  on Training is 67.52068014705883\n",
            "Epoch #0. Accuracy on batch 1632/3013  on Training is 67.53100122473974\n",
            "Epoch #0. Accuracy on batch 1633/3013  on Training is 67.5374847001224\n",
            "Epoch #0. Accuracy on batch 1634/3013  on Training is 67.54778287461774\n",
            "Epoch #0. Accuracy on batch 1635/3013  on Training is 67.55615831295843\n",
            "Epoch #0. Accuracy on batch 1636/3013  on Training is 67.56834147831398\n",
            "Epoch #0. Accuracy on batch 1637/3013  on Training is 67.5709706959707\n",
            "Epoch #0. Accuracy on batch 1638/3013  on Training is 67.58122330689444\n",
            "Epoch #0. Accuracy on batch 1639/3013  on Training is 67.58384146341463\n",
            "Batch Id 1640 is having training loss of 1.4081406593322754\n",
            "0.9745429158210754\n",
            "Epoch #0. Accuracy on batch 1640/3013  on Training is 67.5845521023766\n",
            "Epoch #0. Accuracy on batch 1641/3013  on Training is 67.58906820950061\n",
            "Epoch #0. Accuracy on batch 1642/3013  on Training is 67.58787279367012\n",
            "Epoch #0. Accuracy on batch 1643/3013  on Training is 67.59808394160584\n",
            "Epoch #0. Accuracy on batch 1644/3013  on Training is 67.60448328267478\n",
            "Epoch #0. Accuracy on batch 1645/3013  on Training is 67.60517922235724\n",
            "Epoch #0. Accuracy on batch 1646/3013  on Training is 67.60587431693989\n",
            "Epoch #0. Accuracy on batch 1647/3013  on Training is 67.61415351941747\n",
            "Epoch #0. Accuracy on batch 1648/3013  on Training is 67.62052759248029\n",
            "Epoch #0. Accuracy on batch 1649/3013  on Training is 67.63068181818181\n",
            "Epoch #0. Accuracy on batch 1650/3013  on Training is 67.63135978195034\n",
            "Epoch #0. Accuracy on batch 1651/3013  on Training is 67.63771186440678\n",
            "Epoch #0. Accuracy on batch 1652/3013  on Training is 67.64594676346037\n",
            "Epoch #0. Accuracy on batch 1653/3013  on Training is 67.64472490931077\n",
            "Epoch #0. Accuracy on batch 1654/3013  on Training is 67.6510574018127\n",
            "Epoch #0. Accuracy on batch 1655/3013  on Training is 67.66115640096618\n",
            "Epoch #0. Accuracy on batch 1656/3013  on Training is 67.66935727217863\n",
            "Epoch #0. Accuracy on batch 1657/3013  on Training is 67.67000904704463\n",
            "Epoch #0. Accuracy on batch 1658/3013  on Training is 67.6838456901748\n",
            "Epoch #0. Accuracy on batch 1659/3013  on Training is 67.68637048192771\n",
            "Batch Id 1660 is having training loss of 1.4027125835418701\n",
            "1.278530240058899\n",
            "Epoch #0. Accuracy on batch 1660/3013  on Training is 67.68889223359422\n",
            "Epoch #0. Accuracy on batch 1661/3013  on Training is 67.70081227436823\n",
            "Epoch #0. Accuracy on batch 1662/3013  on Training is 67.71083884546002\n",
            "Epoch #0. Accuracy on batch 1663/3013  on Training is 67.72085336538461\n",
            "Epoch #0. Accuracy on batch 1664/3013  on Training is 67.72334834834835\n",
            "Epoch #0. Accuracy on batch 1665/3013  on Training is 67.72771608643457\n",
            "Epoch #0. Accuracy on batch 1666/3013  on Training is 67.7245800839832\n",
            "Epoch #0. Accuracy on batch 1667/3013  on Training is 67.73081534772182\n",
            "Epoch #0. Accuracy on batch 1668/3013  on Training is 67.74078789694428\n",
            "Epoch #0. Accuracy on batch 1669/3013  on Training is 67.74513473053892\n",
            "Epoch #0. Accuracy on batch 1670/3013  on Training is 67.74760622381807\n",
            "Epoch #0. Accuracy on batch 1671/3013  on Training is 67.75007476076556\n",
            "Epoch #0. Accuracy on batch 1672/3013  on Training is 67.7506724447101\n",
            "Epoch #0. Accuracy on batch 1673/3013  on Training is 67.75500298685783\n",
            "Epoch #0. Accuracy on batch 1674/3013  on Training is 67.75932835820896\n",
            "Epoch #0. Accuracy on batch 1675/3013  on Training is 67.76178400954655\n",
            "Epoch #0. Accuracy on batch 1676/3013  on Training is 67.76982707215265\n",
            "Epoch #0. Accuracy on batch 1677/3013  on Training is 67.7741358760429\n",
            "Epoch #0. Accuracy on batch 1678/3013  on Training is 67.77285586658725\n",
            "Epoch #0. Accuracy on batch 1679/3013  on Training is 67.7827380952381\n",
            "Batch Id 1680 is having training loss of 1.397701621055603\n",
            "1.0233495235443115\n",
            "Epoch #0. Accuracy on batch 1680/3013  on Training is 67.78889054134444\n",
            "Epoch #0. Accuracy on batch 1681/3013  on Training is 67.7987514863258\n",
            "Epoch #0. Accuracy on batch 1682/3013  on Training is 67.79745989304813\n",
            "Epoch #0. Accuracy on batch 1683/3013  on Training is 67.80915973871734\n",
            "Epoch #0. Accuracy on batch 1684/3013  on Training is 67.81157270029674\n",
            "Epoch #0. Accuracy on batch 1685/3013  on Training is 67.81583629893238\n",
            "Epoch #0. Accuracy on batch 1686/3013  on Training is 67.82194724362775\n",
            "Epoch #0. Accuracy on batch 1687/3013  on Training is 67.8280509478673\n",
            "Epoch #0. Accuracy on batch 1688/3013  on Training is 67.83044701006513\n",
            "Epoch #0. Accuracy on batch 1689/3013  on Training is 67.83653846153847\n",
            "Epoch #0. Accuracy on batch 1690/3013  on Training is 67.84262270845653\n",
            "Epoch #0. Accuracy on batch 1691/3013  on Training is 67.85054669030733\n",
            "Epoch #0. Accuracy on batch 1692/3013  on Training is 67.84923213230951\n",
            "Epoch #0. Accuracy on batch 1693/3013  on Training is 67.85160861865407\n",
            "Epoch #0. Accuracy on batch 1694/3013  on Training is 67.85398230088495\n",
            "Epoch #0. Accuracy on batch 1695/3013  on Training is 67.85819575471699\n",
            "Epoch #0. Accuracy on batch 1696/3013  on Training is 67.85872127283442\n",
            "Epoch #0. Accuracy on batch 1697/3013  on Training is 67.86476737338045\n",
            "Epoch #0. Accuracy on batch 1698/3013  on Training is 67.87448499117127\n",
            "Epoch #0. Accuracy on batch 1699/3013  on Training is 67.87316176470588\n",
            "Batch Id 1700 is having training loss of 1.3922293186187744\n",
            "0.4607820510864258\n",
            "Epoch #0. Accuracy on batch 1700/3013  on Training is 67.88470017636685\n",
            "Epoch #0. Accuracy on batch 1701/3013  on Training is 67.88520857814336\n",
            "Epoch #0. Accuracy on batch 1702/3013  on Training is 67.89305637110981\n",
            "Epoch #0. Accuracy on batch 1703/3013  on Training is 67.89355927230046\n",
            "Epoch #0. Accuracy on batch 1704/3013  on Training is 67.89589442815249\n",
            "Epoch #0. Accuracy on batch 1705/3013  on Training is 67.89639507620164\n",
            "Epoch #0. Accuracy on batch 1706/3013  on Training is 67.90055653192736\n",
            "Epoch #0. Accuracy on batch 1707/3013  on Training is 67.90288348946136\n",
            "Epoch #0. Accuracy on batch 1708/3013  on Training is 67.90337916910474\n",
            "Epoch #0. Accuracy on batch 1709/3013  on Training is 67.9093567251462\n",
            "Epoch #0. Accuracy on batch 1710/3013  on Training is 67.91532729398013\n",
            "Epoch #0. Accuracy on batch 1711/3013  on Training is 67.91946553738318\n",
            "Epoch #0. Accuracy on batch 1712/3013  on Training is 67.92542323409224\n",
            "Epoch #0. Accuracy on batch 1713/3013  on Training is 67.9313739789965\n",
            "Epoch #0. Accuracy on batch 1714/3013  on Training is 67.93367346938776\n",
            "Epoch #0. Accuracy on batch 1715/3013  on Training is 67.93232808857809\n",
            "Epoch #0. Accuracy on batch 1716/3013  on Training is 67.94372451951078\n",
            "Epoch #0. Accuracy on batch 1717/3013  on Training is 67.94783178114086\n",
            "Epoch #0. Accuracy on batch 1718/3013  on Training is 67.95738801628853\n",
            "Epoch #0. Accuracy on batch 1719/3013  on Training is 67.95603197674419\n",
            "Batch Id 1720 is having training loss of 1.3872792720794678\n",
            "0.7103788256645203\n",
            "Epoch #0. Accuracy on batch 1720/3013  on Training is 67.96375653689715\n",
            "Epoch #0. Accuracy on batch 1721/3013  on Training is 67.96239837398375\n",
            "Epoch #0. Accuracy on batch 1722/3013  on Training is 67.9610417875798\n",
            "Epoch #0. Accuracy on batch 1723/3013  on Training is 67.9669373549884\n",
            "Epoch #0. Accuracy on batch 1724/3013  on Training is 67.97463768115942\n",
            "Epoch #0. Accuracy on batch 1725/3013  on Training is 67.978707995365\n",
            "Epoch #0. Accuracy on batch 1726/3013  on Training is 67.97372611464968\n",
            "Epoch #0. Accuracy on batch 1727/3013  on Training is 67.97960069444444\n",
            "Epoch #0. Accuracy on batch 1728/3013  on Training is 67.98727588201272\n",
            "Epoch #0. Accuracy on batch 1729/3013  on Training is 67.98771676300578\n",
            "Epoch #0. Accuracy on batch 1730/3013  on Training is 67.99718370883882\n",
            "Epoch #0. Accuracy on batch 1731/3013  on Training is 68.00844399538106\n",
            "Epoch #0. Accuracy on batch 1732/3013  on Training is 68.00887189844201\n",
            "Epoch #0. Accuracy on batch 1733/3013  on Training is 68.01470588235294\n",
            "Epoch #0. Accuracy on batch 1734/3013  on Training is 68.02233429394812\n",
            "Epoch #0. Accuracy on batch 1735/3013  on Training is 68.02815380184332\n",
            "Epoch #0. Accuracy on batch 1736/3013  on Training is 68.03216753022453\n",
            "Epoch #0. Accuracy on batch 1737/3013  on Training is 68.03437859608745\n",
            "Epoch #0. Accuracy on batch 1738/3013  on Training is 68.03658711903392\n",
            "Epoch #0. Accuracy on batch 1739/3013  on Training is 68.04238505747126\n",
            "Batch Id 1740 is having training loss of 1.382502555847168\n",
            "1.0018439292907715\n",
            "Epoch #0. Accuracy on batch 1740/3013  on Training is 68.04279149913843\n",
            "Epoch #0. Accuracy on batch 1741/3013  on Training is 68.05037313432835\n",
            "Epoch #0. Accuracy on batch 1742/3013  on Training is 68.05973895582329\n",
            "Epoch #0. Accuracy on batch 1743/3013  on Training is 68.06371846330275\n",
            "Epoch #0. Accuracy on batch 1744/3013  on Training is 68.06053008595988\n",
            "Epoch #0. Accuracy on batch 1745/3013  on Training is 68.05197594501718\n",
            "Epoch #0. Accuracy on batch 1746/3013  on Training is 68.05416428162565\n",
            "Epoch #0. Accuracy on batch 1747/3013  on Training is 68.06171338672769\n",
            "Epoch #0. Accuracy on batch 1748/3013  on Training is 68.0710405946255\n",
            "Epoch #0. Accuracy on batch 1749/3013  on Training is 68.06964285714285\n",
            "Epoch #0. Accuracy on batch 1750/3013  on Training is 68.07360079954312\n",
            "Epoch #0. Accuracy on batch 1751/3013  on Training is 68.07220319634703\n",
            "Epoch #0. Accuracy on batch 1752/3013  on Training is 68.07258984597833\n",
            "Epoch #0. Accuracy on batch 1753/3013  on Training is 68.07832098061573\n",
            "Epoch #0. Accuracy on batch 1754/3013  on Training is 68.07336182336182\n",
            "Epoch #0. Accuracy on batch 1755/3013  on Training is 68.07374715261959\n",
            "Epoch #0. Accuracy on batch 1756/3013  on Training is 68.07413204325555\n",
            "Epoch #0. Accuracy on batch 1757/3013  on Training is 68.07629408418657\n",
            "Epoch #0. Accuracy on batch 1758/3013  on Training is 68.07845366685616\n",
            "Epoch #0. Accuracy on batch 1759/3013  on Training is 68.08238636363636\n",
            "Batch Id 1760 is having training loss of 1.3791437149047852\n",
            "0.5772702693939209\n",
            "Epoch #0. Accuracy on batch 1760/3013  on Training is 68.08808915388984\n",
            "Epoch #0. Accuracy on batch 1761/3013  on Training is 68.09555902383654\n",
            "Epoch #0. Accuracy on batch 1762/3013  on Training is 68.10479296653432\n",
            "Epoch #0. Accuracy on batch 1763/3013  on Training is 68.11401643990929\n",
            "Epoch #0. Accuracy on batch 1764/3013  on Training is 68.1179178470255\n",
            "Epoch #0. Accuracy on batch 1765/3013  on Training is 68.12358437146092\n",
            "Epoch #0. Accuracy on batch 1766/3013  on Training is 68.12924448217318\n",
            "Epoch #0. Accuracy on batch 1767/3013  on Training is 68.12429298642535\n",
            "Epoch #0. Accuracy on batch 1768/3013  on Training is 68.12994629734312\n",
            "Epoch #0. Accuracy on batch 1769/3013  on Training is 68.12676553672317\n",
            "Epoch #0. Accuracy on batch 1770/3013  on Training is 68.1341756070017\n",
            "Epoch #0. Accuracy on batch 1771/3013  on Training is 68.13628668171557\n",
            "Epoch #0. Accuracy on batch 1772/3013  on Training is 68.14368302312465\n",
            "Epoch #0. Accuracy on batch 1773/3013  on Training is 68.14930947012401\n",
            "Epoch #0. Accuracy on batch 1774/3013  on Training is 68.15316901408451\n",
            "Epoch #0. Accuracy on batch 1775/3013  on Training is 68.15526463963964\n",
            "Epoch #0. Accuracy on batch 1776/3013  on Training is 68.16439223410242\n",
            "Epoch #0. Accuracy on batch 1777/3013  on Training is 68.16823678290214\n",
            "Epoch #0. Accuracy on batch 1778/3013  on Training is 68.1738336143901\n",
            "Epoch #0. Accuracy on batch 1779/3013  on Training is 68.17591292134831\n",
            "Batch Id 1780 is having training loss of 1.374259114265442\n",
            "0.7357990145683289\n",
            "Epoch #0. Accuracy on batch 1780/3013  on Training is 68.18149915777653\n",
            "Epoch #0. Accuracy on batch 1781/3013  on Training is 68.18532547699215\n",
            "Epoch #0. Accuracy on batch 1782/3013  on Training is 68.19440549635446\n",
            "Epoch #0. Accuracy on batch 1783/3013  on Training is 68.19997197309416\n",
            "Epoch #0. Accuracy on batch 1784/3013  on Training is 68.20203081232494\n",
            "Epoch #0. Accuracy on batch 1785/3013  on Training is 68.20583706606944\n",
            "Epoch #0. Accuracy on batch 1786/3013  on Training is 68.20789031897034\n",
            "Epoch #0. Accuracy on batch 1787/3013  on Training is 68.21868008948546\n",
            "Epoch #0. Accuracy on batch 1788/3013  on Training is 68.22072386808273\n",
            "Epoch #0. Accuracy on batch 1789/3013  on Training is 68.22800279329608\n",
            "Epoch #0. Accuracy on batch 1790/3013  on Training is 68.22480457844779\n",
            "Epoch #0. Accuracy on batch 1791/3013  on Training is 68.22858537946429\n",
            "Epoch #0. Accuracy on batch 1792/3013  on Training is 68.23584774121584\n",
            "Epoch #0. Accuracy on batch 1793/3013  on Training is 68.2378762541806\n",
            "Epoch #0. Accuracy on batch 1794/3013  on Training is 68.23293871866295\n",
            "Epoch #0. Accuracy on batch 1795/3013  on Training is 68.23496659242761\n",
            "Epoch #0. Accuracy on batch 1796/3013  on Training is 68.24047022815805\n",
            "Epoch #0. Accuracy on batch 1797/3013  on Training is 68.24075361512791\n",
            "Epoch #0. Accuracy on batch 1798/3013  on Training is 68.24277376320178\n",
            "Epoch #0. Accuracy on batch 1799/3013  on Training is 68.24826388888889\n",
            "Batch Id 1800 is having training loss of 1.3696529865264893\n",
            "1.3185396194458008\n",
            "Epoch #0. Accuracy on batch 1800/3013  on Training is 68.248542476402\n",
            "Epoch #0. Accuracy on batch 1801/3013  on Training is 68.25749167591565\n",
            "Epoch #0. Accuracy on batch 1802/3013  on Training is 68.2629645036051\n",
            "Epoch #0. Accuracy on batch 1803/3013  on Training is 68.2615022172949\n",
            "Epoch #0. Accuracy on batch 1804/3013  on Training is 68.26004155124653\n",
            "Epoch #0. Accuracy on batch 1805/3013  on Training is 68.2672342192691\n",
            "Epoch #0. Accuracy on batch 1806/3013  on Training is 68.27096015495296\n",
            "Epoch #0. Accuracy on batch 1807/3013  on Training is 68.272953539823\n",
            "Epoch #0. Accuracy on batch 1808/3013  on Training is 68.27667219458264\n",
            "Epoch #0. Accuracy on batch 1809/3013  on Training is 68.28556629834254\n",
            "Epoch #0. Accuracy on batch 1810/3013  on Training is 68.2875483158476\n",
            "Epoch #0. Accuracy on batch 1811/3013  on Training is 68.29470198675497\n",
            "Epoch #0. Accuracy on batch 1812/3013  on Training is 68.30012410369554\n",
            "Epoch #0. Accuracy on batch 1813/3013  on Training is 68.30898566703418\n",
            "Epoch #0. Accuracy on batch 1814/3013  on Training is 68.31267217630854\n",
            "Epoch #0. Accuracy on batch 1815/3013  on Training is 68.31635462555066\n",
            "Epoch #0. Accuracy on batch 1816/3013  on Training is 68.32175288937809\n",
            "Epoch #0. Accuracy on batch 1817/3013  on Training is 68.32370737073707\n",
            "Epoch #0. Accuracy on batch 1818/3013  on Training is 68.33596756459593\n",
            "Epoch #0. Accuracy on batch 1819/3013  on Training is 68.33276098901099\n",
            "Batch Id 1820 is having training loss of 1.36495840549469\n",
            "1.1999330520629883\n",
            "Epoch #0. Accuracy on batch 1820/3013  on Training is 68.33299011532125\n",
            "Epoch #0. Accuracy on batch 1821/3013  on Training is 68.33836443468715\n",
            "Epoch #0. Accuracy on batch 1822/3013  on Training is 68.34030444322545\n",
            "Epoch #0. Accuracy on batch 1823/3013  on Training is 68.34909539473684\n",
            "Epoch #0. Accuracy on batch 1824/3013  on Training is 68.35787671232876\n",
            "Epoch #0. Accuracy on batch 1825/3013  on Training is 68.36664841182913\n",
            "Epoch #0. Accuracy on batch 1826/3013  on Training is 68.36856869184456\n",
            "Epoch #0. Accuracy on batch 1827/3013  on Training is 68.37390590809628\n",
            "Epoch #0. Accuracy on batch 1828/3013  on Training is 68.3792372881356\n",
            "Epoch #0. Accuracy on batch 1829/3013  on Training is 68.3811475409836\n",
            "Epoch #0. Accuracy on batch 1830/3013  on Training is 68.3881758601857\n",
            "Epoch #0. Accuracy on batch 1831/3013  on Training is 68.39007914847161\n",
            "Epoch #0. Accuracy on batch 1832/3013  on Training is 68.39368521549373\n",
            "Epoch #0. Accuracy on batch 1833/3013  on Training is 68.39728735005453\n",
            "Epoch #0. Accuracy on batch 1834/3013  on Training is 68.40599455040872\n",
            "Epoch #0. Accuracy on batch 1835/3013  on Training is 68.4078839869281\n",
            "Epoch #0. Accuracy on batch 1836/3013  on Training is 68.41487479586281\n",
            "Epoch #0. Accuracy on batch 1837/3013  on Training is 68.4150571273123\n",
            "Epoch #0. Accuracy on batch 1838/3013  on Training is 68.41693855356172\n",
            "Epoch #0. Accuracy on batch 1839/3013  on Training is 68.41881793478261\n",
            "Batch Id 1840 is having training loss of 1.360647439956665\n",
            "0.9546215534210205\n",
            "Epoch #0. Accuracy on batch 1840/3013  on Training is 68.42409016838674\n",
            "Epoch #0. Accuracy on batch 1841/3013  on Training is 68.43105320304018\n",
            "Epoch #0. Accuracy on batch 1842/3013  on Training is 68.4363130765057\n",
            "Epoch #0. Accuracy on batch 1843/3013  on Training is 68.44495661605207\n",
            "Epoch #0. Accuracy on batch 1844/3013  on Training is 68.44681571815718\n",
            "Epoch #0. Accuracy on batch 1845/3013  on Training is 68.44697995666306\n",
            "Epoch #0. Accuracy on batch 1846/3013  on Training is 68.4454520844613\n",
            "Epoch #0. Accuracy on batch 1847/3013  on Training is 68.45745400432901\n",
            "Epoch #0. Accuracy on batch 1848/3013  on Training is 68.46606273661439\n",
            "Epoch #0. Accuracy on batch 1849/3013  on Training is 68.47297297297297\n",
            "Epoch #0. Accuracy on batch 1850/3013  on Training is 68.47649918962723\n",
            "Epoch #0. Accuracy on batch 1851/3013  on Training is 68.48677105831534\n",
            "Epoch #0. Accuracy on batch 1852/3013  on Training is 68.49197247706422\n",
            "Epoch #0. Accuracy on batch 1853/3013  on Training is 68.49716828478964\n",
            "Epoch #0. Accuracy on batch 1854/3013  on Training is 68.50572776280323\n",
            "Epoch #0. Accuracy on batch 1855/3013  on Training is 68.50249191810344\n",
            "Epoch #0. Accuracy on batch 1856/3013  on Training is 68.50262520193861\n",
            "Epoch #0. Accuracy on batch 1857/3013  on Training is 68.50612217438106\n",
            "Epoch #0. Accuracy on batch 1858/3013  on Training is 68.51129639591178\n",
            "Epoch #0. Accuracy on batch 1859/3013  on Training is 68.5114247311828\n",
            "Batch Id 1860 is having training loss of 1.3554234504699707\n",
            "1.1682677268981934\n",
            "Epoch #0. Accuracy on batch 1860/3013  on Training is 68.5098737238044\n",
            "Epoch #0. Accuracy on batch 1861/3013  on Training is 68.51839419978518\n",
            "Epoch #0. Accuracy on batch 1862/3013  on Training is 68.51851851851852\n",
            "Epoch #0. Accuracy on batch 1863/3013  on Training is 68.51528969957081\n",
            "Epoch #0. Accuracy on batch 1864/3013  on Training is 68.5137399463807\n",
            "Epoch #0. Accuracy on batch 1865/3013  on Training is 68.52056538049304\n",
            "Epoch #0. Accuracy on batch 1866/3013  on Training is 68.52738350294591\n",
            "Epoch #0. Accuracy on batch 1867/3013  on Training is 68.53252141327623\n",
            "Epoch #0. Accuracy on batch 1868/3013  on Training is 68.54266987693954\n",
            "Epoch #0. Accuracy on batch 1869/3013  on Training is 68.5461229946524\n",
            "Epoch #0. Accuracy on batch 1870/3013  on Training is 68.55124265098878\n",
            "Epoch #0. Accuracy on batch 1871/3013  on Training is 68.5463408119658\n",
            "Epoch #0. Accuracy on batch 1872/3013  on Training is 68.5464495461826\n",
            "Epoch #0. Accuracy on batch 1873/3013  on Training is 68.55322838847385\n",
            "Epoch #0. Accuracy on batch 1874/3013  on Training is 68.55666666666667\n",
            "Epoch #0. Accuracy on batch 1875/3013  on Training is 68.56343283582089\n",
            "Epoch #0. Accuracy on batch 1876/3013  on Training is 68.56686201385189\n",
            "Epoch #0. Accuracy on batch 1877/3013  on Training is 68.5736155484558\n",
            "Epoch #0. Accuracy on batch 1878/3013  on Training is 68.58202501330494\n",
            "Epoch #0. Accuracy on batch 1879/3013  on Training is 68.59042553191489\n",
            "Batch Id 1880 is having training loss of 1.350481390953064\n",
            "0.929858922958374\n",
            "Epoch #0. Accuracy on batch 1880/3013  on Training is 68.59383306751728\n",
            "Epoch #0. Accuracy on batch 1881/3013  on Training is 68.59391604675876\n",
            "Epoch #0. Accuracy on batch 1882/3013  on Training is 68.60395645246946\n",
            "Epoch #0. Accuracy on batch 1883/3013  on Training is 68.60735138004246\n",
            "Epoch #0. Accuracy on batch 1884/3013  on Training is 68.61737400530504\n",
            "Epoch #0. Accuracy on batch 1885/3013  on Training is 68.62241516436903\n",
            "Epoch #0. Accuracy on batch 1886/3013  on Training is 68.620826709062\n",
            "Epoch #0. Accuracy on batch 1887/3013  on Training is 68.62586069915254\n",
            "Epoch #0. Accuracy on batch 1888/3013  on Training is 68.63088935944944\n",
            "Epoch #0. Accuracy on batch 1889/3013  on Training is 68.63425925925925\n",
            "Epoch #0. Accuracy on batch 1890/3013  on Training is 68.63597303014278\n",
            "Epoch #0. Accuracy on batch 1891/3013  on Training is 68.64264006342495\n",
            "Epoch #0. Accuracy on batch 1892/3013  on Training is 68.64764923402008\n",
            "Epoch #0. Accuracy on batch 1893/3013  on Training is 68.65760295670539\n",
            "Epoch #0. Accuracy on batch 1894/3013  on Training is 68.66094986807389\n",
            "Epoch #0. Accuracy on batch 1895/3013  on Training is 68.6659414556962\n",
            "Epoch #0. Accuracy on batch 1896/3013  on Training is 68.67092778070638\n",
            "Epoch #0. Accuracy on batch 1897/3013  on Training is 68.67261591148578\n",
            "Epoch #0. Accuracy on batch 1898/3013  on Training is 68.67101105845181\n",
            "Epoch #0. Accuracy on batch 1899/3013  on Training is 68.67434210526316\n",
            "Batch Id 1900 is having training loss of 1.3459213972091675\n",
            "1.1029784679412842\n",
            "Epoch #0. Accuracy on batch 1900/3013  on Training is 68.67602577590742\n",
            "Epoch #0. Accuracy on batch 1901/3013  on Training is 68.67442166140904\n",
            "Epoch #0. Accuracy on batch 1902/3013  on Training is 68.67774566473989\n",
            "Epoch #0. Accuracy on batch 1903/3013  on Training is 68.6827074579832\n",
            "Epoch #0. Accuracy on batch 1904/3013  on Training is 68.68602362204724\n",
            "Epoch #0. Accuracy on batch 1905/3013  on Training is 68.68933630640083\n",
            "Epoch #0. Accuracy on batch 1906/3013  on Training is 68.68281331934976\n",
            "Epoch #0. Accuracy on batch 1907/3013  on Training is 68.68776205450733\n",
            "Epoch #0. Accuracy on batch 1908/3013  on Training is 68.6976165531692\n",
            "Epoch #0. Accuracy on batch 1909/3013  on Training is 68.70091623036649\n",
            "Epoch #0. Accuracy on batch 1910/3013  on Training is 68.70257718472004\n",
            "Epoch #0. Accuracy on batch 1911/3013  on Training is 68.7107740585774\n",
            "Epoch #0. Accuracy on batch 1912/3013  on Training is 68.71732880292734\n",
            "Epoch #0. Accuracy on batch 1913/3013  on Training is 68.72387669801464\n",
            "Epoch #0. Accuracy on batch 1914/3013  on Training is 68.71899477806788\n",
            "Epoch #0. Accuracy on batch 1915/3013  on Training is 68.72716597077245\n",
            "Epoch #0. Accuracy on batch 1916/3013  on Training is 68.72391757955138\n",
            "Epoch #0. Accuracy on batch 1917/3013  on Training is 68.73207768508864\n",
            "Epoch #0. Accuracy on batch 1918/3013  on Training is 68.74185773840541\n",
            "Epoch #0. Accuracy on batch 1919/3013  on Training is 68.75162760416667\n",
            "Batch Id 1920 is having training loss of 1.3410980701446533\n",
            "0.8090921640396118\n",
            "Epoch #0. Accuracy on batch 1920/3013  on Training is 68.7597605413847\n",
            "Epoch #0. Accuracy on batch 1921/3013  on Training is 68.76300728407908\n",
            "Epoch #0. Accuracy on batch 1922/3013  on Training is 68.7678757150286\n",
            "Epoch #0. Accuracy on batch 1923/3013  on Training is 68.77111486486487\n",
            "Epoch #0. Accuracy on batch 1924/3013  on Training is 68.77597402597402\n",
            "Epoch #0. Accuracy on batch 1925/3013  on Training is 68.78082814122534\n",
            "Epoch #0. Accuracy on batch 1926/3013  on Training is 68.78243383497664\n",
            "Epoch #0. Accuracy on batch 1927/3013  on Training is 68.79214211618257\n",
            "Epoch #0. Accuracy on batch 1928/3013  on Training is 68.80022032141005\n",
            "Epoch #0. Accuracy on batch 1929/3013  on Training is 68.80343264248705\n",
            "Epoch #0. Accuracy on batch 1930/3013  on Training is 68.80987830139824\n",
            "Epoch #0. Accuracy on batch 1931/3013  on Training is 68.81469979296067\n",
            "Epoch #0. Accuracy on batch 1932/3013  on Training is 68.81466632177961\n",
            "Epoch #0. Accuracy on batch 1933/3013  on Training is 68.8162487073423\n",
            "Epoch #0. Accuracy on batch 1934/3013  on Training is 68.82590439276485\n",
            "Epoch #0. Accuracy on batch 1935/3013  on Training is 68.83232179752066\n",
            "Epoch #0. Accuracy on batch 1936/3013  on Training is 68.84034589571502\n",
            "Epoch #0. Accuracy on batch 1937/3013  on Training is 68.8467492260062\n",
            "Epoch #0. Accuracy on batch 1938/3013  on Training is 68.85636926250645\n",
            "Epoch #0. Accuracy on batch 1939/3013  on Training is 68.85631443298969\n",
            "Batch Id 1940 is having training loss of 1.336824893951416\n",
            "1.1934373378753662\n",
            "Epoch #0. Accuracy on batch 1940/3013  on Training is 68.85464966512107\n",
            "Epoch #0. Accuracy on batch 1941/3013  on Training is 68.85781410916582\n",
            "Epoch #0. Accuracy on batch 1942/3013  on Training is 68.86258363355635\n",
            "Epoch #0. Accuracy on batch 1943/3013  on Training is 68.86091820987654\n",
            "Epoch #0. Accuracy on batch 1944/3013  on Training is 68.86246786632391\n",
            "Epoch #0. Accuracy on batch 1945/3013  on Training is 68.86401593011306\n",
            "Epoch #0. Accuracy on batch 1946/3013  on Training is 68.87037750385208\n",
            "Epoch #0. Accuracy on batch 1947/3013  on Training is 68.87191991786447\n",
            "Epoch #0. Accuracy on batch 1948/3013  on Training is 68.87666752180606\n",
            "Epoch #0. Accuracy on batch 1949/3013  on Training is 68.88141025641026\n",
            "Epoch #0. Accuracy on batch 1950/3013  on Training is 68.88134290107637\n",
            "Epoch #0. Accuracy on batch 1951/3013  on Training is 68.88928022540983\n",
            "Epoch #0. Accuracy on batch 1952/3013  on Training is 68.89240911418331\n",
            "Epoch #0. Accuracy on batch 1953/3013  on Training is 68.89233623336744\n",
            "Epoch #0. Accuracy on batch 1954/3013  on Training is 68.90025575447571\n",
            "Epoch #0. Accuracy on batch 1955/3013  on Training is 68.90177658486708\n",
            "Epoch #0. Accuracy on batch 1956/3013  on Training is 68.90169902912622\n",
            "Epoch #0. Accuracy on batch 1957/3013  on Training is 68.90481358529111\n",
            "Epoch #0. Accuracy on batch 1958/3013  on Training is 68.91271056661562\n",
            "Epoch #0. Accuracy on batch 1959/3013  on Training is 68.91581632653062\n",
            "Batch Id 1960 is having training loss of 1.3335204124450684\n",
            "0.6363673210144043\n",
            "Epoch #0. Accuracy on batch 1960/3013  on Training is 68.91891891891892\n",
            "Epoch #0. Accuracy on batch 1961/3013  on Training is 68.92361111111111\n",
            "Epoch #0. Accuracy on batch 1962/3013  on Training is 68.92511462047887\n",
            "Epoch #0. Accuracy on batch 1963/3013  on Training is 68.92502545824847\n",
            "Epoch #0. Accuracy on batch 1964/3013  on Training is 68.93129770992367\n",
            "Epoch #0. Accuracy on batch 1965/3013  on Training is 68.93597405900306\n",
            "Epoch #0. Accuracy on batch 1966/3013  on Training is 68.94223436705643\n",
            "Epoch #0. Accuracy on batch 1967/3013  on Training is 68.94213668699187\n",
            "Epoch #0. Accuracy on batch 1968/3013  on Training is 68.94203910614524\n",
            "Epoch #0. Accuracy on batch 1969/3013  on Training is 68.94828680203045\n",
            "Epoch #0. Accuracy on batch 1970/3013  on Training is 68.9529426686961\n",
            "Epoch #0. Accuracy on batch 1971/3013  on Training is 68.94967038539554\n",
            "Epoch #0. Accuracy on batch 1972/3013  on Training is 68.95590471363406\n",
            "Epoch #0. Accuracy on batch 1973/3013  on Training is 68.95580040526849\n",
            "Epoch #0. Accuracy on batch 1974/3013  on Training is 68.95411392405063\n",
            "Epoch #0. Accuracy on batch 1975/3013  on Training is 68.95559210526316\n",
            "Epoch #0. Accuracy on batch 1976/3013  on Training is 68.95706879109763\n",
            "Epoch #0. Accuracy on batch 1977/3013  on Training is 68.96012386248736\n",
            "Epoch #0. Accuracy on batch 1978/3013  on Training is 68.96317584638706\n",
            "Epoch #0. Accuracy on batch 1979/3013  on Training is 68.96938131313131\n",
            "Batch Id 1980 is having training loss of 1.3294225931167603\n",
            "0.7577264308929443\n",
            "Epoch #0. Accuracy on batch 1980/3013  on Training is 68.97558051489148\n",
            "Epoch #0. Accuracy on batch 1981/3013  on Training is 68.98335015136226\n",
            "Epoch #0. Accuracy on batch 1982/3013  on Training is 68.99268784669692\n",
            "Epoch #0. Accuracy on batch 1983/3013  on Training is 68.994140625\n",
            "Epoch #0. Accuracy on batch 1984/3013  on Training is 68.9940176322418\n",
            "Epoch #0. Accuracy on batch 1985/3013  on Training is 69.00018882175226\n",
            "Epoch #0. Accuracy on batch 1986/3013  on Training is 69.00635379969803\n",
            "Epoch #0. Accuracy on batch 1987/3013  on Training is 69.0077967806841\n",
            "Epoch #0. Accuracy on batch 1988/3013  on Training is 69.00766716943187\n",
            "Epoch #0. Accuracy on batch 1989/3013  on Training is 69.00282663316582\n",
            "Epoch #0. Accuracy on batch 1990/3013  on Training is 69.00740833751884\n",
            "Epoch #0. Accuracy on batch 1991/3013  on Training is 69.01355421686748\n",
            "Epoch #0. Accuracy on batch 1992/3013  on Training is 69.01655795283492\n",
            "Epoch #0. Accuracy on batch 1993/3013  on Training is 69.00545386158475\n",
            "Epoch #0. Accuracy on batch 1994/3013  on Training is 69.01002506265664\n",
            "Epoch #0. Accuracy on batch 1995/3013  on Training is 69.01928857715431\n",
            "Epoch #0. Accuracy on batch 1996/3013  on Training is 69.01758888332499\n",
            "Epoch #0. Accuracy on batch 1997/3013  on Training is 69.01901901901901\n",
            "Epoch #0. Accuracy on batch 1998/3013  on Training is 69.02201100550275\n",
            "Epoch #0. Accuracy on batch 1999/3013  on Training is 69.0296875\n",
            "Batch Id 2000 is having training loss of 1.3261080980300903\n",
            "1.084937334060669\n",
            "Epoch #0. Accuracy on batch 2000/3013  on Training is 69.0279860069965\n",
            "Epoch #0. Accuracy on batch 2001/3013  on Training is 69.03721278721278\n",
            "Epoch #0. Accuracy on batch 2002/3013  on Training is 69.0386295556665\n",
            "Epoch #0. Accuracy on batch 2003/3013  on Training is 69.04160429141717\n",
            "Epoch #0. Accuracy on batch 2004/3013  on Training is 69.03990024937656\n",
            "Epoch #0. Accuracy on batch 2005/3013  on Training is 69.04442921236291\n",
            "Epoch #0. Accuracy on batch 2006/3013  on Training is 69.05518186347783\n",
            "Epoch #0. Accuracy on batch 2007/3013  on Training is 69.0534736055777\n",
            "Epoch #0. Accuracy on batch 2008/3013  on Training is 69.061100049776\n",
            "Epoch #0. Accuracy on batch 2009/3013  on Training is 69.07027363184079\n",
            "Epoch #0. Accuracy on batch 2010/3013  on Training is 69.07011437095971\n",
            "Epoch #0. Accuracy on batch 2011/3013  on Training is 69.07150844930418\n",
            "Epoch #0. Accuracy on batch 2012/3013  on Training is 69.07600596125187\n",
            "Epoch #0. Accuracy on batch 2013/3013  on Training is 69.08360228401192\n",
            "Epoch #0. Accuracy on batch 2014/3013  on Training is 69.08808933002481\n",
            "Epoch #0. Accuracy on batch 2015/3013  on Training is 69.09567212301587\n",
            "Epoch #0. Accuracy on batch 2016/3013  on Training is 69.09705007436787\n",
            "Epoch #0. Accuracy on batch 2017/3013  on Training is 69.10152378592666\n",
            "Epoch #0. Accuracy on batch 2018/3013  on Training is 69.10444526993561\n",
            "Epoch #0. Accuracy on batch 2019/3013  on Training is 69.10581683168317\n",
            "Batch Id 2020 is having training loss of 1.3218739032745361\n",
            "0.6651710271835327\n",
            "Epoch #0. Accuracy on batch 2020/3013  on Training is 69.11337209302326\n",
            "Epoch #0. Accuracy on batch 2021/3013  on Training is 69.1039193867458\n",
            "Epoch #0. Accuracy on batch 2022/3013  on Training is 69.11455758774098\n",
            "Epoch #0. Accuracy on batch 2023/3013  on Training is 69.12209733201581\n",
            "Epoch #0. Accuracy on batch 2024/3013  on Training is 69.12345679012346\n",
            "Epoch #0. Accuracy on batch 2025/3013  on Training is 69.12789980256663\n",
            "Epoch #0. Accuracy on batch 2026/3013  on Training is 69.13233843117908\n",
            "Epoch #0. Accuracy on batch 2027/3013  on Training is 69.14139546351085\n",
            "Epoch #0. Accuracy on batch 2028/3013  on Training is 69.1442828979793\n",
            "Epoch #0. Accuracy on batch 2029/3013  on Training is 69.15024630541872\n",
            "Epoch #0. Accuracy on batch 2030/3013  on Training is 69.15774249138356\n",
            "Epoch #0. Accuracy on batch 2031/3013  on Training is 69.16369340551181\n",
            "Epoch #0. Accuracy on batch 2032/3013  on Training is 69.16656419085096\n",
            "Epoch #0. Accuracy on batch 2033/3013  on Training is 69.17250491642085\n",
            "Epoch #0. Accuracy on batch 2034/3013  on Training is 69.1661547911548\n",
            "Epoch #0. Accuracy on batch 2035/3013  on Training is 69.16902013752456\n",
            "Epoch #0. Accuracy on batch 2036/3013  on Training is 69.1764850270005\n",
            "Epoch #0. Accuracy on batch 2037/3013  on Training is 69.17934249263985\n",
            "Epoch #0. Accuracy on batch 2038/3013  on Training is 69.18679499754782\n",
            "Epoch #0. Accuracy on batch 2039/3013  on Training is 69.19424019607843\n",
            "Batch Id 2040 is having training loss of 1.3173695802688599\n",
            "1.1776237487792969\n",
            "Epoch #0. Accuracy on batch 2040/3013  on Training is 69.19249142577168\n",
            "Epoch #0. Accuracy on batch 2041/3013  on Training is 69.19380509304604\n",
            "Epoch #0. Accuracy on batch 2042/3013  on Training is 69.19970631424376\n",
            "Epoch #0. Accuracy on batch 2043/3013  on Training is 69.19795743639922\n",
            "Epoch #0. Accuracy on batch 2044/3013  on Training is 69.2007946210269\n",
            "Epoch #0. Accuracy on batch 2045/3013  on Training is 69.2005742913001\n",
            "Epoch #0. Accuracy on batch 2046/3013  on Training is 69.2064606741573\n",
            "Epoch #0. Accuracy on batch 2047/3013  on Training is 69.21234130859375\n",
            "Epoch #0. Accuracy on batch 2048/3013  on Training is 69.20448999511957\n",
            "Epoch #0. Accuracy on batch 2049/3013  on Training is 69.20884146341463\n",
            "Epoch #0. Accuracy on batch 2050/3013  on Training is 69.2116650414432\n",
            "Epoch #0. Accuracy on batch 2051/3013  on Training is 69.20382553606238\n",
            "Epoch #0. Accuracy on batch 2052/3013  on Training is 69.20969313200195\n",
            "Epoch #0. Accuracy on batch 2053/3013  on Training is 69.21099074975658\n",
            "Epoch #0. Accuracy on batch 2054/3013  on Training is 69.21532846715328\n",
            "Epoch #0. Accuracy on batch 2055/3013  on Training is 69.22270184824903\n",
            "Epoch #0. Accuracy on batch 2056/3013  on Training is 69.22702965483714\n",
            "Epoch #0. Accuracy on batch 2057/3013  on Training is 69.22831632653062\n",
            "Epoch #0. Accuracy on batch 2058/3013  on Training is 69.23567265662943\n",
            "Epoch #0. Accuracy on batch 2059/3013  on Training is 69.23695388349515\n",
            "Batch Id 2060 is having training loss of 1.3138386011123657\n",
            "0.5971217155456543\n",
            "Epoch #0. Accuracy on batch 2060/3013  on Training is 69.24278262979136\n",
            "Epoch #0. Accuracy on batch 2061/3013  on Training is 69.24405916585839\n",
            "Epoch #0. Accuracy on batch 2062/3013  on Training is 69.24987881725642\n",
            "Epoch #0. Accuracy on batch 2063/3013  on Training is 69.25115067829458\n",
            "Epoch #0. Accuracy on batch 2064/3013  on Training is 69.25393462469734\n",
            "Epoch #0. Accuracy on batch 2065/3013  on Training is 69.25369070667958\n",
            "Epoch #0. Accuracy on batch 2066/3013  on Training is 69.25344702467343\n",
            "Epoch #0. Accuracy on batch 2067/3013  on Training is 69.25773694390716\n",
            "Epoch #0. Accuracy on batch 2068/3013  on Training is 69.25598115031416\n",
            "Epoch #0. Accuracy on batch 2069/3013  on Training is 69.26026570048309\n",
            "Epoch #0. Accuracy on batch 2070/3013  on Training is 69.26756397875423\n",
            "Epoch #0. Accuracy on batch 2071/3013  on Training is 69.27636341698842\n",
            "Epoch #0. Accuracy on batch 2072/3013  on Training is 69.28364688856729\n",
            "Epoch #0. Accuracy on batch 2073/3013  on Training is 69.28941658630666\n",
            "Epoch #0. Accuracy on batch 2074/3013  on Training is 69.28915662650603\n",
            "Epoch #0. Accuracy on batch 2075/3013  on Training is 69.29190751445087\n",
            "Epoch #0. Accuracy on batch 2076/3013  on Training is 69.29766490129995\n",
            "Epoch #0. Accuracy on batch 2077/3013  on Training is 69.30191289701636\n",
            "Epoch #0. Accuracy on batch 2078/3013  on Training is 69.30765993265993\n",
            "Epoch #0. Accuracy on batch 2079/3013  on Training is 69.31490384615384\n",
            "Batch Id 2080 is having training loss of 1.3098145723342896\n",
            "0.4976537823677063\n",
            "Epoch #0. Accuracy on batch 2080/3013  on Training is 69.32364247957713\n",
            "Epoch #0. Accuracy on batch 2081/3013  on Training is 69.32336695485111\n",
            "Epoch #0. Accuracy on batch 2082/3013  on Training is 69.32759241478637\n",
            "Epoch #0. Accuracy on batch 2083/3013  on Training is 69.32881477927063\n",
            "Epoch #0. Accuracy on batch 2084/3013  on Training is 69.33453237410072\n",
            "Epoch #0. Accuracy on batch 2085/3013  on Training is 69.3357502396932\n",
            "Epoch #0. Accuracy on batch 2086/3013  on Training is 69.3369669381888\n",
            "Epoch #0. Accuracy on batch 2087/3013  on Training is 69.34566570881226\n",
            "Epoch #0. Accuracy on batch 2088/3013  on Training is 69.35136428913356\n",
            "Epoch #0. Accuracy on batch 2089/3013  on Training is 69.35556220095694\n",
            "Epoch #0. Accuracy on batch 2090/3013  on Training is 69.35975609756098\n",
            "Epoch #0. Accuracy on batch 2091/3013  on Training is 69.36394598470363\n",
            "Epoch #0. Accuracy on batch 2092/3013  on Training is 69.36663879598662\n",
            "Epoch #0. Accuracy on batch 2093/3013  on Training is 69.36634431709646\n",
            "Epoch #0. Accuracy on batch 2094/3013  on Training is 69.36903341288783\n",
            "Epoch #0. Accuracy on batch 2095/3013  on Training is 69.37022900763358\n",
            "Epoch #0. Accuracy on batch 2096/3013  on Training is 69.37738435860753\n",
            "Epoch #0. Accuracy on batch 2097/3013  on Training is 69.38304337464251\n",
            "Epoch #0. Accuracy on batch 2098/3013  on Training is 69.38274178180086\n",
            "Epoch #0. Accuracy on batch 2099/3013  on Training is 69.38839285714286\n",
            "Batch Id 2100 is having training loss of 1.3062597513198853\n",
            "0.7259886860847473\n",
            "Epoch #0. Accuracy on batch 2100/3013  on Training is 69.39255116611137\n",
            "Epoch #0. Accuracy on batch 2101/3013  on Training is 69.39521883920077\n",
            "Epoch #0. Accuracy on batch 2102/3013  on Training is 69.39639800285306\n",
            "Epoch #0. Accuracy on batch 2103/3013  on Training is 69.40351711026616\n",
            "Epoch #0. Accuracy on batch 2104/3013  on Training is 69.40914489311164\n",
            "Epoch #0. Accuracy on batch 2105/3013  on Training is 69.41328347578347\n",
            "Epoch #0. Accuracy on batch 2106/3013  on Training is 69.41593497864262\n",
            "Epoch #0. Accuracy on batch 2107/3013  on Training is 69.42154886148008\n",
            "Epoch #0. Accuracy on batch 2108/3013  on Training is 69.42271218587008\n",
            "Epoch #0. Accuracy on batch 2109/3013  on Training is 69.42831753554502\n",
            "Epoch #0. Accuracy on batch 2110/3013  on Training is 69.42947655139744\n",
            "Epoch #0. Accuracy on batch 2111/3013  on Training is 69.42767518939394\n",
            "Epoch #0. Accuracy on batch 2112/3013  on Training is 69.43179129200189\n",
            "Epoch #0. Accuracy on batch 2113/3013  on Training is 69.43146877956481\n",
            "Epoch #0. Accuracy on batch 2114/3013  on Training is 69.44148936170212\n",
            "Epoch #0. Accuracy on batch 2115/3013  on Training is 69.44559310018903\n",
            "Epoch #0. Accuracy on batch 2116/3013  on Training is 69.4467406707605\n",
            "Epoch #0. Accuracy on batch 2117/3013  on Training is 69.45083805476865\n",
            "Epoch #0. Accuracy on batch 2118/3013  on Training is 69.45345681925437\n",
            "Epoch #0. Accuracy on batch 2119/3013  on Training is 69.45459905660377\n",
            "Batch Id 2120 is having training loss of 1.3024133443832397\n",
            "1.230973243713379\n",
            "Epoch #0. Accuracy on batch 2120/3013  on Training is 69.45426685525696\n",
            "Epoch #0. Accuracy on batch 2121/3013  on Training is 69.46129830348728\n",
            "Epoch #0. Accuracy on batch 2122/3013  on Training is 69.46390720678285\n",
            "Epoch #0. Accuracy on batch 2123/3013  on Training is 69.46651365348399\n",
            "Epoch #0. Accuracy on batch 2124/3013  on Training is 69.475\n",
            "Epoch #0. Accuracy on batch 2125/3013  on Training is 69.47465898400752\n",
            "Epoch #0. Accuracy on batch 2126/3013  on Training is 69.4743182886695\n",
            "Epoch #0. Accuracy on batch 2127/3013  on Training is 69.4827890037594\n",
            "Epoch #0. Accuracy on batch 2128/3013  on Training is 69.48538046031001\n",
            "Epoch #0. Accuracy on batch 2129/3013  on Training is 69.49237089201878\n",
            "Epoch #0. Accuracy on batch 2130/3013  on Training is 69.49202252463633\n",
            "Epoch #0. Accuracy on batch 2131/3013  on Training is 69.49314024390245\n",
            "Epoch #0. Accuracy on batch 2132/3013  on Training is 69.49279184247538\n",
            "Epoch #0. Accuracy on batch 2133/3013  on Training is 69.49537253983131\n",
            "Epoch #0. Accuracy on batch 2134/3013  on Training is 69.49941451990632\n",
            "Epoch #0. Accuracy on batch 2135/3013  on Training is 69.50491573033707\n",
            "Epoch #0. Accuracy on batch 2136/3013  on Training is 69.51187412260178\n",
            "Epoch #0. Accuracy on batch 2137/3013  on Training is 69.51736435921421\n",
            "Epoch #0. Accuracy on batch 2138/3013  on Training is 69.51992753623189\n",
            "Epoch #0. Accuracy on batch 2139/3013  on Training is 69.52394859813084\n",
            "Batch Id 2140 is having training loss of 1.29909348487854\n",
            "0.9768382906913757\n",
            "Epoch #0. Accuracy on batch 2140/3013  on Training is 69.52504670714619\n",
            "Epoch #0. Accuracy on batch 2141/3013  on Training is 69.52760270774976\n",
            "Epoch #0. Accuracy on batch 2142/3013  on Training is 69.53453103126458\n",
            "Epoch #0. Accuracy on batch 2143/3013  on Training is 69.54145289179104\n",
            "Epoch #0. Accuracy on batch 2144/3013  on Training is 69.5367132867133\n",
            "Epoch #0. Accuracy on batch 2145/3013  on Training is 69.54508387698043\n",
            "Epoch #0. Accuracy on batch 2146/3013  on Training is 69.54034699580811\n",
            "Epoch #0. Accuracy on batch 2147/3013  on Training is 69.54579841713222\n",
            "Epoch #0. Accuracy on batch 2148/3013  on Training is 69.55124476500698\n",
            "Epoch #0. Accuracy on batch 2149/3013  on Training is 69.55813953488372\n",
            "Epoch #0. Accuracy on batch 2150/3013  on Training is 69.56066945606695\n",
            "Epoch #0. Accuracy on batch 2151/3013  on Training is 69.56029275092936\n",
            "Epoch #0. Accuracy on batch 2152/3013  on Training is 69.57152810032512\n",
            "Epoch #0. Accuracy on batch 2153/3013  on Training is 69.57549907149489\n",
            "Epoch #0. Accuracy on batch 2154/3013  on Training is 69.57511600928075\n",
            "Epoch #0. Accuracy on batch 2155/3013  on Training is 69.57328385899814\n",
            "Epoch #0. Accuracy on batch 2156/3013  on Training is 69.57724849327771\n",
            "Epoch #0. Accuracy on batch 2157/3013  on Training is 69.58410565338276\n",
            "Epoch #0. Accuracy on batch 2158/3013  on Training is 69.58950903195924\n",
            "Epoch #0. Accuracy on batch 2159/3013  on Training is 69.58767361111111\n",
            "Batch Id 2160 is having training loss of 1.2955774068832397\n",
            "1.3202316761016846\n",
            "Epoch #0. Accuracy on batch 2160/3013  on Training is 69.5858398889403\n",
            "Epoch #0. Accuracy on batch 2161/3013  on Training is 69.58689870490286\n",
            "Epoch #0. Accuracy on batch 2162/3013  on Training is 69.59373555247342\n",
            "Epoch #0. Accuracy on batch 2163/3013  on Training is 69.59623382624768\n",
            "Epoch #0. Accuracy on batch 2164/3013  on Training is 69.59872979214781\n",
            "Epoch #0. Accuracy on batch 2165/3013  on Training is 69.59545244690673\n",
            "Epoch #0. Accuracy on batch 2166/3013  on Training is 69.59650438394094\n",
            "Epoch #0. Accuracy on batch 2167/3013  on Training is 69.60332103321034\n",
            "Epoch #0. Accuracy on batch 2168/3013  on Training is 69.6043683725219\n",
            "Epoch #0. Accuracy on batch 2169/3013  on Training is 69.60685483870968\n",
            "Epoch #0. Accuracy on batch 2170/3013  on Training is 69.61077844311377\n",
            "Epoch #0. Accuracy on batch 2171/3013  on Training is 69.62045349907919\n",
            "Epoch #0. Accuracy on batch 2172/3013  on Training is 69.62005292222733\n",
            "Epoch #0. Accuracy on batch 2173/3013  on Training is 69.61965271389144\n",
            "Epoch #0. Accuracy on batch 2174/3013  on Training is 69.62212643678161\n",
            "Epoch #0. Accuracy on batch 2175/3013  on Training is 69.62603400735294\n",
            "Epoch #0. Accuracy on batch 2176/3013  on Training is 69.62850252641249\n",
            "Epoch #0. Accuracy on batch 2177/3013  on Training is 69.63240358126721\n",
            "Epoch #0. Accuracy on batch 2178/3013  on Training is 69.64060348783846\n",
            "Epoch #0. Accuracy on batch 2179/3013  on Training is 69.64162844036697\n",
            "Batch Id 2180 is having training loss of 1.291721224784851\n",
            "1.0288481712341309\n",
            "Epoch #0. Accuracy on batch 2180/3013  on Training is 69.64551811095828\n",
            "Epoch #0. Accuracy on batch 2181/3013  on Training is 69.65226856095326\n",
            "Epoch #0. Accuracy on batch 2182/3013  on Training is 69.64899221255153\n",
            "Epoch #0. Accuracy on batch 2183/3013  on Training is 69.6514423076923\n",
            "Epoch #0. Accuracy on batch 2184/3013  on Training is 69.6495995423341\n",
            "Epoch #0. Accuracy on batch 2185/3013  on Training is 69.65061756633119\n",
            "Epoch #0. Accuracy on batch 2186/3013  on Training is 69.65306355738454\n",
            "Epoch #0. Accuracy on batch 2187/3013  on Training is 69.65407906764169\n",
            "Epoch #0. Accuracy on batch 2188/3013  on Training is 69.65366605756053\n",
            "Epoch #0. Accuracy on batch 2189/3013  on Training is 69.65753424657534\n",
            "Epoch #0. Accuracy on batch 2190/3013  on Training is 69.65997261524419\n",
            "Epoch #0. Accuracy on batch 2191/3013  on Training is 69.66383439781022\n",
            "Epoch #0. Accuracy on batch 2192/3013  on Training is 69.66769265845873\n",
            "Epoch #0. Accuracy on batch 2193/3013  on Training is 69.67724475843208\n",
            "Epoch #0. Accuracy on batch 2194/3013  on Training is 69.67824601366742\n",
            "Epoch #0. Accuracy on batch 2195/3013  on Training is 69.68493852459017\n",
            "Epoch #0. Accuracy on batch 2196/3013  on Training is 69.68166818388711\n",
            "Epoch #0. Accuracy on batch 2197/3013  on Training is 69.6826660600546\n",
            "Epoch #0. Accuracy on batch 2198/3013  on Training is 69.6893474306503\n",
            "Epoch #0. Accuracy on batch 2199/3013  on Training is 69.6903409090909\n",
            "Batch Id 2200 is having training loss of 1.2887792587280273\n",
            "0.7873754501342773\n",
            "Epoch #0. Accuracy on batch 2200/3013  on Training is 69.69417310313494\n",
            "Epoch #0. Accuracy on batch 2201/3013  on Training is 69.69516348773843\n",
            "Epoch #0. Accuracy on batch 2202/3013  on Training is 69.69615297321833\n",
            "Epoch #0. Accuracy on batch 2203/3013  on Training is 69.70139519056261\n",
            "Epoch #0. Accuracy on batch 2204/3013  on Training is 69.70521541950113\n",
            "Epoch #0. Accuracy on batch 2205/3013  on Training is 69.70619900271986\n",
            "Epoch #0. Accuracy on batch 2206/3013  on Training is 69.70718169460807\n",
            "Epoch #0. Accuracy on batch 2207/3013  on Training is 69.71240942028986\n",
            "Epoch #0. Accuracy on batch 2208/3013  on Training is 69.71621774558623\n",
            "Epoch #0. Accuracy on batch 2209/3013  on Training is 69.72285067873302\n",
            "Epoch #0. Accuracy on batch 2210/3013  on Training is 69.72806422433288\n",
            "Epoch #0. Accuracy on batch 2211/3013  on Training is 69.73044755877034\n",
            "Epoch #0. Accuracy on batch 2212/3013  on Training is 69.73282873926796\n",
            "Epoch #0. Accuracy on batch 2213/3013  on Training is 69.73520776874436\n",
            "Epoch #0. Accuracy on batch 2214/3013  on Training is 69.73758465011286\n",
            "Epoch #0. Accuracy on batch 2215/3013  on Training is 69.73995938628158\n",
            "Epoch #0. Accuracy on batch 2216/3013  on Training is 69.73951285520974\n",
            "Epoch #0. Accuracy on batch 2217/3013  on Training is 69.74611136158701\n",
            "Epoch #0. Accuracy on batch 2218/3013  on Training is 69.7484790446147\n",
            "Epoch #0. Accuracy on batch 2219/3013  on Training is 69.74521396396396\n",
            "Batch Id 2220 is having training loss of 1.2856814861297607\n",
            "0.8372738361358643\n",
            "Epoch #0. Accuracy on batch 2220/3013  on Training is 69.74898694281855\n",
            "Epoch #0. Accuracy on batch 2221/3013  on Training is 69.74994374437443\n",
            "Epoch #0. Accuracy on batch 2222/3013  on Training is 69.75089968511021\n",
            "Epoch #0. Accuracy on batch 2223/3013  on Training is 69.75747526978417\n",
            "Epoch #0. Accuracy on batch 2224/3013  on Training is 69.75421348314607\n",
            "Epoch #0. Accuracy on batch 2225/3013  on Training is 69.7579739442947\n",
            "Epoch #0. Accuracy on batch 2226/3013  on Training is 69.75892456219128\n",
            "Epoch #0. Accuracy on batch 2227/3013  on Training is 69.76127692998205\n",
            "Epoch #0. Accuracy on batch 2228/3013  on Training is 69.76502916105878\n",
            "Epoch #0. Accuracy on batch 2229/3013  on Training is 69.76457399103138\n",
            "Epoch #0. Accuracy on batch 2230/3013  on Training is 69.76972209771402\n",
            "Epoch #0. Accuracy on batch 2231/3013  on Training is 69.77206541218638\n",
            "Epoch #0. Accuracy on batch 2232/3013  on Training is 69.77160770264219\n",
            "Epoch #0. Accuracy on batch 2233/3013  on Training is 69.77115040286482\n",
            "Epoch #0. Accuracy on batch 2234/3013  on Training is 69.77908277404921\n",
            "Epoch #0. Accuracy on batch 2235/3013  on Training is 69.77722495527728\n",
            "Epoch #0. Accuracy on batch 2236/3013  on Training is 69.77955967814037\n",
            "Epoch #0. Accuracy on batch 2237/3013  on Training is 69.78189231456658\n",
            "Epoch #0. Accuracy on batch 2238/3013  on Training is 69.78561857972309\n",
            "Epoch #0. Accuracy on batch 2239/3013  on Training is 69.79631696428571\n",
            "Batch Id 2240 is having training loss of 1.2828410863876343\n",
            "1.2439522743225098\n",
            "Epoch #0. Accuracy on batch 2240/3013  on Training is 69.7944556001785\n",
            "Epoch #0. Accuracy on batch 2241/3013  on Training is 69.79956512042818\n",
            "Epoch #0. Accuracy on batch 2242/3013  on Training is 69.79909719126171\n",
            "Epoch #0. Accuracy on batch 2243/3013  on Training is 69.80141488413547\n",
            "Epoch #0. Accuracy on batch 2244/3013  on Training is 69.80373051224944\n",
            "Epoch #0. Accuracy on batch 2245/3013  on Training is 69.80186999109529\n",
            "Epoch #0. Accuracy on batch 2246/3013  on Training is 69.8000111259457\n",
            "Epoch #0. Accuracy on batch 2247/3013  on Training is 69.79815391459074\n",
            "Epoch #0. Accuracy on batch 2248/3013  on Training is 69.80046687416629\n",
            "Epoch #0. Accuracy on batch 2249/3013  on Training is 69.80694444444444\n",
            "Epoch #0. Accuracy on batch 2250/3013  on Training is 69.81202798756108\n",
            "Epoch #0. Accuracy on batch 2251/3013  on Training is 69.81710701598578\n",
            "Epoch #0. Accuracy on batch 2252/3013  on Training is 69.82356857523303\n",
            "Epoch #0. Accuracy on batch 2253/3013  on Training is 69.82447870452529\n",
            "Epoch #0. Accuracy on batch 2254/3013  on Training is 69.82815964523282\n",
            "Epoch #0. Accuracy on batch 2255/3013  on Training is 69.83460771276596\n",
            "Epoch #0. Accuracy on batch 2256/3013  on Training is 69.83689632255206\n",
            "Epoch #0. Accuracy on batch 2257/3013  on Training is 69.83641496899911\n",
            "Epoch #0. Accuracy on batch 2258/3013  on Training is 69.84008410801239\n",
            "Epoch #0. Accuracy on batch 2259/3013  on Training is 69.83683628318585\n",
            "Batch Id 2260 is having training loss of 1.2801178693771362\n",
            "1.4047218561172485\n",
            "Epoch #0. Accuracy on batch 2260/3013  on Training is 69.83359133126935\n",
            "Epoch #0. Accuracy on batch 2261/3013  on Training is 69.83863837312113\n",
            "Epoch #0. Accuracy on batch 2262/3013  on Training is 69.84506186478126\n",
            "Epoch #0. Accuracy on batch 2263/3013  on Training is 69.84871908127208\n",
            "Epoch #0. Accuracy on batch 2264/3013  on Training is 69.8537527593819\n",
            "Epoch #0. Accuracy on batch 2265/3013  on Training is 69.86291924095322\n",
            "Epoch #0. Accuracy on batch 2266/3013  on Training is 69.86518526687252\n",
            "Epoch #0. Accuracy on batch 2267/3013  on Training is 69.87296075837743\n",
            "Epoch #0. Accuracy on batch 2268/3013  on Training is 69.87797487880124\n",
            "Epoch #0. Accuracy on batch 2269/3013  on Training is 69.88160792951543\n",
            "Epoch #0. Accuracy on batch 2270/3013  on Training is 69.88523778071334\n",
            "Epoch #0. Accuracy on batch 2271/3013  on Training is 69.88886443661971\n",
            "Epoch #0. Accuracy on batch 2272/3013  on Training is 69.88836339639244\n",
            "Epoch #0. Accuracy on batch 2273/3013  on Training is 69.89610817941953\n",
            "Epoch #0. Accuracy on batch 2274/3013  on Training is 69.8956043956044\n",
            "Epoch #0. Accuracy on batch 2275/3013  on Training is 69.90059314586995\n",
            "Epoch #0. Accuracy on batch 2276/3013  on Training is 69.90420509442248\n",
            "Epoch #0. Accuracy on batch 2277/3013  on Training is 69.90507023705004\n",
            "Epoch #0. Accuracy on batch 2278/3013  on Training is 69.90593462044757\n",
            "Epoch #0. Accuracy on batch 2279/3013  on Training is 69.91365131578948\n",
            "Batch Id 2280 is having training loss of 1.276060938835144\n",
            "1.2655991315841675\n",
            "Epoch #0. Accuracy on batch 2280/3013  on Training is 69.91040113985095\n",
            "Epoch #0. Accuracy on batch 2281/3013  on Training is 69.91400087642418\n",
            "Epoch #0. Accuracy on batch 2282/3013  on Training is 69.91896627244853\n",
            "Epoch #0. Accuracy on batch 2283/3013  on Training is 69.9252955341506\n",
            "Epoch #0. Accuracy on batch 2284/3013  on Training is 69.92478118161925\n",
            "Epoch #0. Accuracy on batch 2285/3013  on Training is 69.92836832895888\n",
            "Epoch #0. Accuracy on batch 2286/3013  on Training is 69.92648666375165\n",
            "Epoch #0. Accuracy on batch 2287/3013  on Training is 69.93006993006993\n",
            "Epoch #0. Accuracy on batch 2288/3013  on Training is 69.93501529051987\n",
            "Epoch #0. Accuracy on batch 2289/3013  on Training is 69.93995633187772\n",
            "Epoch #0. Accuracy on batch 2290/3013  on Training is 69.93943692710607\n",
            "Epoch #0. Accuracy on batch 2291/3013  on Training is 69.94437172774869\n",
            "Epoch #0. Accuracy on batch 2292/3013  on Training is 69.9465765372874\n",
            "Epoch #0. Accuracy on batch 2293/3013  on Training is 69.95559067131647\n",
            "Epoch #0. Accuracy on batch 2294/3013  on Training is 69.95642701525054\n",
            "Epoch #0. Accuracy on batch 2295/3013  on Training is 69.95590156794425\n",
            "Epoch #0. Accuracy on batch 2296/3013  on Training is 69.9580975185024\n",
            "Epoch #0. Accuracy on batch 2297/3013  on Training is 69.96301131418625\n",
            "Epoch #0. Accuracy on batch 2298/3013  on Training is 69.9597651152675\n",
            "Epoch #0. Accuracy on batch 2299/3013  on Training is 69.95923913043478\n",
            "Batch Id 2300 is having training loss of 1.2733697891235352\n",
            "1.2193470001220703\n",
            "Epoch #0. Accuracy on batch 2300/3013  on Training is 69.95735549760974\n",
            "Epoch #0. Accuracy on batch 2301/3013  on Training is 69.96497610773241\n",
            "Epoch #0. Accuracy on batch 2302/3013  on Training is 69.96851932262267\n",
            "Epoch #0. Accuracy on batch 2303/3013  on Training is 69.97341579861111\n",
            "Epoch #0. Accuracy on batch 2304/3013  on Training is 69.97559652928416\n",
            "Epoch #0. Accuracy on batch 2305/3013  on Training is 69.97777536860364\n",
            "Epoch #0. Accuracy on batch 2306/3013  on Training is 69.97724317295189\n",
            "Epoch #0. Accuracy on batch 2307/3013  on Training is 69.97806542461005\n",
            "Epoch #0. Accuracy on batch 2308/3013  on Training is 69.98294716327415\n",
            "Epoch #0. Accuracy on batch 2309/3013  on Training is 69.9891774891775\n",
            "Epoch #0. Accuracy on batch 2310/3013  on Training is 69.99810688013847\n",
            "Epoch #0. Accuracy on batch 2311/3013  on Training is 70.00432525951557\n",
            "Epoch #0. Accuracy on batch 2312/3013  on Training is 70.00513402507566\n",
            "Epoch #0. Accuracy on batch 2313/3013  on Training is 70.00324114088158\n",
            "Epoch #0. Accuracy on batch 2314/3013  on Training is 70.00809935205183\n",
            "Epoch #0. Accuracy on batch 2315/3013  on Training is 70.00890544041451\n",
            "Epoch #0. Accuracy on batch 2316/3013  on Training is 70.00431592576608\n",
            "Epoch #0. Accuracy on batch 2317/3013  on Training is 70.01051553062986\n",
            "Epoch #0. Accuracy on batch 2318/3013  on Training is 70.01401466149203\n",
            "Epoch #0. Accuracy on batch 2319/3013  on Training is 70.01616379310344\n",
            "Batch Id 2320 is having training loss of 1.2696053981781006\n",
            "0.8984695672988892\n",
            "Epoch #0. Accuracy on batch 2320/3013  on Training is 70.0223502800517\n",
            "Epoch #0. Accuracy on batch 2321/3013  on Training is 70.0191106804479\n",
            "Epoch #0. Accuracy on batch 2322/3013  on Training is 70.02798105897546\n",
            "Epoch #0. Accuracy on batch 2323/3013  on Training is 70.03146514629948\n",
            "Epoch #0. Accuracy on batch 2324/3013  on Training is 70.02553763440861\n",
            "Epoch #0. Accuracy on batch 2325/3013  on Training is 70.0276762682717\n",
            "Epoch #0. Accuracy on batch 2326/3013  on Training is 70.02847013321873\n",
            "Epoch #0. Accuracy on batch 2327/3013  on Training is 70.03731743986255\n",
            "Epoch #0. Accuracy on batch 2328/3013  on Training is 70.0407900386432\n",
            "Epoch #0. Accuracy on batch 2329/3013  on Training is 70.04291845493562\n",
            "Epoch #0. Accuracy on batch 2330/3013  on Training is 70.04370441870442\n",
            "Epoch #0. Accuracy on batch 2331/3013  on Training is 70.0444897084048\n",
            "Epoch #0. Accuracy on batch 2332/3013  on Training is 70.04929275610802\n",
            "Epoch #0. Accuracy on batch 2333/3013  on Training is 70.05409168808912\n",
            "Epoch #0. Accuracy on batch 2334/3013  on Training is 70.05888650963597\n",
            "Epoch #0. Accuracy on batch 2335/3013  on Training is 70.05966395547945\n",
            "Epoch #0. Accuracy on batch 2336/3013  on Training is 70.05776636713736\n",
            "Epoch #0. Accuracy on batch 2337/3013  on Training is 70.06255346449957\n",
            "Epoch #0. Accuracy on batch 2338/3013  on Training is 70.07134459170585\n",
            "Epoch #0. Accuracy on batch 2339/3013  on Training is 70.07211538461539\n",
            "Batch Id 2340 is having training loss of 1.266547679901123\n",
            "1.2190722227096558\n",
            "Epoch #0. Accuracy on batch 2340/3013  on Training is 70.07422041862452\n",
            "Epoch #0. Accuracy on batch 2341/3013  on Training is 70.08032664389411\n",
            "Epoch #0. Accuracy on batch 2342/3013  on Training is 70.08109261630388\n",
            "Epoch #0. Accuracy on batch 2343/3013  on Training is 70.07919155290102\n",
            "Epoch #0. Accuracy on batch 2344/3013  on Training is 70.07995735607676\n",
            "Epoch #0. Accuracy on batch 2345/3013  on Training is 70.08072250639387\n",
            "Epoch #0. Accuracy on batch 2346/3013  on Training is 70.08015551768214\n",
            "Epoch #0. Accuracy on batch 2347/3013  on Training is 70.08624361158432\n",
            "Epoch #0. Accuracy on batch 2348/3013  on Training is 70.08966581524052\n",
            "Epoch #0. Accuracy on batch 2349/3013  on Training is 70.09574468085107\n",
            "Epoch #0. Accuracy on batch 2350/3013  on Training is 70.09517226712038\n",
            "Epoch #0. Accuracy on batch 2351/3013  on Training is 70.09858630952381\n",
            "Epoch #0. Accuracy on batch 2352/3013  on Training is 70.09801317467063\n",
            "Epoch #0. Accuracy on batch 2353/3013  on Training is 70.10673322005098\n",
            "Epoch #0. Accuracy on batch 2354/3013  on Training is 70.11279193205945\n",
            "Epoch #0. Accuracy on batch 2355/3013  on Training is 70.11619269949067\n",
            "Epoch #0. Accuracy on batch 2356/3013  on Training is 70.11693890538821\n",
            "Epoch #0. Accuracy on batch 2357/3013  on Training is 70.11900975402884\n",
            "Epoch #0. Accuracy on batch 2358/3013  on Training is 70.12107884696906\n",
            "Epoch #0. Accuracy on batch 2359/3013  on Training is 70.12579449152543\n",
            "Batch Id 2360 is having training loss of 1.2635363340377808\n",
            "0.8884440064430237\n",
            "Epoch #0. Accuracy on batch 2360/3013  on Training is 70.12785895806861\n",
            "Epoch #0. Accuracy on batch 2361/3013  on Training is 70.1299216765453\n",
            "Epoch #0. Accuracy on batch 2362/3013  on Training is 70.12537029200169\n",
            "Epoch #0. Accuracy on batch 2363/3013  on Training is 70.12611040609137\n",
            "Epoch #0. Accuracy on batch 2364/3013  on Training is 70.12949260042284\n",
            "Epoch #0. Accuracy on batch 2365/3013  on Training is 70.13155114116653\n",
            "Epoch #0. Accuracy on batch 2366/3013  on Training is 70.13756865230249\n",
            "Epoch #0. Accuracy on batch 2367/3013  on Training is 70.14358108108108\n",
            "Epoch #0. Accuracy on batch 2368/3013  on Training is 70.15222667792318\n",
            "Epoch #0. Accuracy on batch 2369/3013  on Training is 70.14767932489451\n",
            "Epoch #0. Accuracy on batch 2370/3013  on Training is 70.14840784479122\n",
            "Epoch #0. Accuracy on batch 2371/3013  on Training is 70.15177065767286\n",
            "Epoch #0. Accuracy on batch 2372/3013  on Training is 70.15513063632532\n",
            "Epoch #0. Accuracy on batch 2373/3013  on Training is 70.16243681550127\n",
            "Epoch #0. Accuracy on batch 2374/3013  on Training is 70.16447368421052\n",
            "Epoch #0. Accuracy on batch 2375/3013  on Training is 70.1691393097643\n",
            "Epoch #0. Accuracy on batch 2376/3013  on Training is 70.17248632730332\n",
            "Epoch #0. Accuracy on batch 2377/3013  on Training is 70.17845878889824\n",
            "Epoch #0. Accuracy on batch 2378/3013  on Training is 70.1817990752417\n",
            "Epoch #0. Accuracy on batch 2379/3013  on Training is 70.18776260504201\n",
            "Batch Id 2380 is having training loss of 1.2601500749588013\n",
            "1.202400803565979\n",
            "Epoch #0. Accuracy on batch 2380/3013  on Training is 70.18715875682486\n",
            "Epoch #0. Accuracy on batch 2381/3013  on Training is 70.18786733837112\n",
            "Epoch #0. Accuracy on batch 2382/3013  on Training is 70.18201846412086\n",
            "Epoch #0. Accuracy on batch 2383/3013  on Training is 70.1866610738255\n",
            "Epoch #0. Accuracy on batch 2384/3013  on Training is 70.19261006289308\n",
            "Epoch #0. Accuracy on batch 2385/3013  on Training is 70.20117351215423\n",
            "Epoch #0. Accuracy on batch 2386/3013  on Training is 70.20842061164642\n",
            "Epoch #0. Accuracy on batch 2387/3013  on Training is 70.21304438860972\n",
            "Epoch #0. Accuracy on batch 2388/3013  on Training is 70.220280452072\n",
            "Epoch #0. Accuracy on batch 2389/3013  on Training is 70.22358786610879\n",
            "Epoch #0. Accuracy on batch 2390/3013  on Training is 70.22297156001673\n",
            "Epoch #0. Accuracy on batch 2391/3013  on Training is 70.22758152173913\n",
            "Epoch #0. Accuracy on batch 2392/3013  on Training is 70.23610530714585\n",
            "Epoch #0. Accuracy on batch 2393/3013  on Training is 70.23940058479532\n",
            "Epoch #0. Accuracy on batch 2394/3013  on Training is 70.24008350730689\n",
            "Epoch #0. Accuracy on batch 2395/3013  on Training is 70.24467863105176\n",
            "Epoch #0. Accuracy on batch 2396/3013  on Training is 70.25187734668336\n",
            "Epoch #0. Accuracy on batch 2397/3013  on Training is 70.25385738115097\n",
            "Epoch #0. Accuracy on batch 2398/3013  on Training is 70.25583576490205\n",
            "Epoch #0. Accuracy on batch 2399/3013  on Training is 70.26041666666667\n",
            "Batch Id 2400 is having training loss of 1.256443738937378\n",
            "0.5610486268997192\n",
            "Epoch #0. Accuracy on batch 2400/3013  on Training is 70.26499375260308\n",
            "Epoch #0. Accuracy on batch 2401/3013  on Training is 70.27216902581182\n",
            "Epoch #0. Accuracy on batch 2402/3013  on Training is 70.27153558052434\n",
            "Epoch #0. Accuracy on batch 2403/3013  on Training is 70.27350249584026\n",
            "Epoch #0. Accuracy on batch 2404/3013  on Training is 70.27806652806653\n",
            "Epoch #0. Accuracy on batch 2405/3013  on Training is 70.28522443890274\n",
            "Epoch #0. Accuracy on batch 2406/3013  on Training is 70.28588491898628\n",
            "Epoch #0. Accuracy on batch 2407/3013  on Training is 70.28654485049834\n",
            "Epoch #0. Accuracy on batch 2408/3013  on Training is 70.28850145288501\n",
            "Epoch #0. Accuracy on batch 2409/3013  on Training is 70.29304979253112\n",
            "Epoch #0. Accuracy on batch 2410/3013  on Training is 70.29111364579013\n",
            "Epoch #0. Accuracy on batch 2411/3013  on Training is 70.293065920398\n",
            "Epoch #0. Accuracy on batch 2412/3013  on Training is 70.29242644011603\n",
            "Epoch #0. Accuracy on batch 2413/3013  on Training is 70.29437655343828\n",
            "Epoch #0. Accuracy on batch 2414/3013  on Training is 70.29761904761905\n",
            "Epoch #0. Accuracy on batch 2415/3013  on Training is 70.2969784768212\n",
            "Epoch #0. Accuracy on batch 2416/3013  on Training is 70.30409598676044\n",
            "Epoch #0. Accuracy on batch 2417/3013  on Training is 70.30733043837883\n",
            "Epoch #0. Accuracy on batch 2418/3013  on Training is 70.30668664737495\n",
            "Epoch #0. Accuracy on batch 2419/3013  on Training is 70.31379132231405\n",
            "Batch Id 2420 is having training loss of 1.25362229347229\n",
            "1.0536092519760132\n",
            "Epoch #0. Accuracy on batch 2420/3013  on Training is 70.31572697232548\n",
            "Epoch #0. Accuracy on batch 2421/3013  on Training is 70.31895127993394\n",
            "Epoch #0. Accuracy on batch 2422/3013  on Training is 70.32088320264135\n",
            "Epoch #0. Accuracy on batch 2423/3013  on Training is 70.32539191419141\n",
            "Epoch #0. Accuracy on batch 2424/3013  on Training is 70.32603092783505\n",
            "Epoch #0. Accuracy on batch 2425/3013  on Training is 70.32924567188788\n",
            "Epoch #0. Accuracy on batch 2426/3013  on Training is 70.32859497321796\n",
            "Epoch #0. Accuracy on batch 2427/3013  on Training is 70.33438014827018\n",
            "Epoch #0. Accuracy on batch 2428/3013  on Training is 70.3401605599012\n",
            "Epoch #0. Accuracy on batch 2429/3013  on Training is 70.3395061728395\n",
            "Epoch #0. Accuracy on batch 2430/3013  on Training is 70.34270876182642\n",
            "Epoch #0. Accuracy on batch 2431/3013  on Training is 70.34847861842105\n",
            "Epoch #0. Accuracy on batch 2432/3013  on Training is 70.35938142211262\n",
            "Epoch #0. Accuracy on batch 2433/3013  on Training is 70.36000410846343\n",
            "Epoch #0. Accuracy on batch 2434/3013  on Training is 70.36575975359342\n",
            "Epoch #0. Accuracy on batch 2435/3013  on Training is 70.36253078817734\n",
            "Epoch #0. Accuracy on batch 2436/3013  on Training is 70.3644337299959\n",
            "Epoch #0. Accuracy on batch 2437/3013  on Training is 70.3637715340443\n",
            "Epoch #0. Accuracy on batch 2438/3013  on Training is 70.36823493234932\n",
            "Epoch #0. Accuracy on batch 2439/3013  on Training is 70.37141393442623\n",
            "Batch Id 2440 is having training loss of 1.2502716779708862\n",
            "0.8153611421585083\n",
            "Epoch #0. Accuracy on batch 2440/3013  on Training is 70.37587054485867\n",
            "Epoch #0. Accuracy on batch 2441/3013  on Training is 70.37648443898443\n",
            "Epoch #0. Accuracy on batch 2442/3013  on Training is 70.38221449038068\n",
            "Epoch #0. Accuracy on batch 2443/3013  on Training is 70.3853825695581\n",
            "Epoch #0. Accuracy on batch 2444/3013  on Training is 70.38982617586912\n",
            "Epoch #0. Accuracy on batch 2445/3013  on Training is 70.39171095666394\n",
            "Epoch #0. Accuracy on batch 2446/3013  on Training is 70.39487127094401\n",
            "Epoch #0. Accuracy on batch 2447/3013  on Training is 70.39164624183006\n",
            "Epoch #0. Accuracy on batch 2448/3013  on Training is 70.39608003266639\n",
            "Epoch #0. Accuracy on batch 2449/3013  on Training is 70.39668367346938\n",
            "Epoch #0. Accuracy on batch 2450/3013  on Training is 70.3998368013056\n",
            "Epoch #0. Accuracy on batch 2451/3013  on Training is 70.40426182707994\n",
            "Epoch #0. Accuracy on batch 2452/3013  on Training is 70.40740929474113\n",
            "Epoch #0. Accuracy on batch 2453/3013  on Training is 70.40673390383049\n",
            "Epoch #0. Accuracy on batch 2454/3013  on Training is 70.40733197556008\n",
            "Epoch #0. Accuracy on batch 2455/3013  on Training is 70.40920195439739\n",
            "Epoch #0. Accuracy on batch 2456/3013  on Training is 70.40979853479854\n",
            "Epoch #0. Accuracy on batch 2457/3013  on Training is 70.41166598860862\n",
            "Epoch #0. Accuracy on batch 2458/3013  on Training is 70.417344448963\n",
            "Epoch #0. Accuracy on batch 2459/3013  on Training is 70.41539634146342\n",
            "Batch Id 2460 is having training loss of 1.2475347518920898\n",
            "0.6903023719787598\n",
            "Epoch #0. Accuracy on batch 2460/3013  on Training is 70.42106867127184\n",
            "Epoch #0. Accuracy on batch 2461/3013  on Training is 70.42546709991876\n",
            "Epoch #0. Accuracy on batch 2462/3013  on Training is 70.42986195696305\n",
            "Epoch #0. Accuracy on batch 2463/3013  on Training is 70.43298498376623\n",
            "Epoch #0. Accuracy on batch 2464/3013  on Training is 70.43737322515213\n",
            "Epoch #0. Accuracy on batch 2465/3013  on Training is 70.44049067315491\n",
            "Epoch #0. Accuracy on batch 2466/3013  on Training is 70.438538710985\n",
            "Epoch #0. Accuracy on batch 2467/3013  on Training is 70.43912074554295\n",
            "Epoch #0. Accuracy on batch 2468/3013  on Training is 70.446030781693\n",
            "Epoch #0. Accuracy on batch 2469/3013  on Training is 70.44534412955466\n",
            "Epoch #0. Accuracy on batch 2470/3013  on Training is 70.45098138405504\n",
            "Epoch #0. Accuracy on batch 2471/3013  on Training is 70.4515574433657\n",
            "Epoch #0. Accuracy on batch 2472/3013  on Training is 70.44834209462192\n",
            "Epoch #0. Accuracy on batch 2473/3013  on Training is 70.44891875505255\n",
            "Epoch #0. Accuracy on batch 2474/3013  on Training is 70.45454545454545\n",
            "Epoch #0. Accuracy on batch 2475/3013  on Training is 70.45764337641357\n",
            "Epoch #0. Accuracy on batch 2476/3013  on Training is 70.45569236980218\n",
            "Epoch #0. Accuracy on batch 2477/3013  on Training is 70.46130952380952\n",
            "Epoch #0. Accuracy on batch 2478/3013  on Training is 70.46061920129084\n",
            "Epoch #0. Accuracy on batch 2479/3013  on Training is 70.46622983870968\n",
            "Batch Id 2480 is having training loss of 1.2449568510055542\n",
            "1.018613576889038\n",
            "Epoch #0. Accuracy on batch 2480/3013  on Training is 70.46805723498589\n",
            "Epoch #0. Accuracy on batch 2481/3013  on Training is 70.4711422240129\n",
            "Epoch #0. Accuracy on batch 2482/3013  on Training is 70.47674184454289\n",
            "Epoch #0. Accuracy on batch 2483/3013  on Training is 70.48107890499195\n",
            "Epoch #0. Accuracy on batch 2484/3013  on Training is 70.47912474849095\n",
            "Epoch #0. Accuracy on batch 2485/3013  on Training is 70.4822003218021\n",
            "Epoch #0. Accuracy on batch 2486/3013  on Training is 70.48401688781665\n",
            "Epoch #0. Accuracy on batch 2487/3013  on Training is 70.49085610932475\n",
            "Epoch #0. Accuracy on batch 2488/3013  on Training is 70.4926677380474\n",
            "Epoch #0. Accuracy on batch 2489/3013  on Training is 70.49949799196787\n",
            "Epoch #0. Accuracy on batch 2490/3013  on Training is 70.5025592131674\n",
            "Epoch #0. Accuracy on batch 2491/3013  on Training is 70.5031099518459\n",
            "Epoch #0. Accuracy on batch 2492/3013  on Training is 70.50115322904132\n",
            "Epoch #0. Accuracy on batch 2493/3013  on Training is 70.50045108259823\n",
            "Epoch #0. Accuracy on batch 2494/3013  on Training is 70.50100200400801\n",
            "Epoch #0. Accuracy on batch 2495/3013  on Training is 70.50656049679488\n",
            "Epoch #0. Accuracy on batch 2496/3013  on Training is 70.50836003203844\n",
            "Epoch #0. Accuracy on batch 2497/3013  on Training is 70.5101581265012\n",
            "Epoch #0. Accuracy on batch 2498/3013  on Training is 70.51695678271308\n",
            "Epoch #0. Accuracy on batch 2499/3013  on Training is 70.52125\n",
            "Batch Id 2500 is having training loss of 1.2417601346969604\n",
            "0.8967905044555664\n",
            "Epoch #0. Accuracy on batch 2500/3013  on Training is 70.52304078368653\n",
            "Epoch #0. Accuracy on batch 2501/3013  on Training is 70.52732813749\n",
            "Epoch #0. Accuracy on batch 2502/3013  on Training is 70.52786656012785\n",
            "Epoch #0. Accuracy on batch 2503/3013  on Training is 70.53090055910543\n",
            "Epoch #0. Accuracy on batch 2504/3013  on Training is 70.5314371257485\n",
            "Epoch #0. Accuracy on batch 2505/3013  on Training is 70.53322027134877\n",
            "Epoch #0. Accuracy on batch 2506/3013  on Training is 70.52876944555246\n",
            "Epoch #0. Accuracy on batch 2507/3013  on Training is 70.53553628389155\n",
            "Epoch #0. Accuracy on batch 2508/3013  on Training is 70.53607014746912\n",
            "Epoch #0. Accuracy on batch 2509/3013  on Training is 70.53909362549801\n",
            "Epoch #0. Accuracy on batch 2510/3013  on Training is 70.53962564715253\n",
            "Epoch #0. Accuracy on batch 2511/3013  on Training is 70.54015724522293\n",
            "Epoch #0. Accuracy on batch 2512/3013  on Training is 70.54690608834063\n",
            "Epoch #0. Accuracy on batch 2513/3013  on Training is 70.55613564041369\n",
            "Epoch #0. Accuracy on batch 2514/3013  on Training is 70.56287276341948\n",
            "Epoch #0. Accuracy on batch 2515/3013  on Training is 70.56587837837837\n",
            "Epoch #0. Accuracy on batch 2516/3013  on Training is 70.57136471990465\n",
            "Epoch #0. Accuracy on batch 2517/3013  on Training is 70.57684670373312\n",
            "Epoch #0. Accuracy on batch 2518/3013  on Training is 70.58108376339817\n",
            "Epoch #0. Accuracy on batch 2519/3013  on Training is 70.58531746031746\n",
            "Batch Id 2520 is having training loss of 1.238680124282837\n",
            "1.0481055974960327\n",
            "Epoch #0. Accuracy on batch 2520/3013  on Training is 70.58582903609678\n",
            "Epoch #0. Accuracy on batch 2521/3013  on Training is 70.58757930214115\n",
            "Epoch #0. Accuracy on batch 2522/3013  on Training is 70.58437376139517\n",
            "Epoch #0. Accuracy on batch 2523/3013  on Training is 70.58736133122028\n",
            "Epoch #0. Accuracy on batch 2524/3013  on Training is 70.58539603960396\n",
            "Epoch #0. Accuracy on batch 2525/3013  on Training is 70.59085510688836\n",
            "Epoch #0. Accuracy on batch 2526/3013  on Training is 70.59136327661258\n",
            "Epoch #0. Accuracy on batch 2527/3013  on Training is 70.59434335443038\n",
            "Epoch #0. Accuracy on batch 2528/3013  on Training is 70.59855674179518\n",
            "Epoch #0. Accuracy on batch 2529/3013  on Training is 70.60153162055336\n",
            "Epoch #0. Accuracy on batch 2530/3013  on Training is 70.6057388384038\n",
            "Epoch #0. Accuracy on batch 2531/3013  on Training is 70.61241113744076\n",
            "Epoch #0. Accuracy on batch 2532/3013  on Training is 70.61290959336755\n",
            "Epoch #0. Accuracy on batch 2533/3013  on Training is 70.61587411207577\n",
            "Epoch #0. Accuracy on batch 2534/3013  on Training is 70.61513806706114\n",
            "Epoch #0. Accuracy on batch 2535/3013  on Training is 70.61933162460568\n",
            "Epoch #0. Accuracy on batch 2536/3013  on Training is 70.62721718565234\n",
            "Epoch #0. Accuracy on batch 2537/3013  on Training is 70.6252462568952\n",
            "Epoch #0. Accuracy on batch 2538/3013  on Training is 70.63189247735329\n",
            "Epoch #0. Accuracy on batch 2539/3013  on Training is 70.63607283464567\n",
            "Batch Id 2540 is having training loss of 1.2357149124145508\n",
            "1.3649165630340576\n",
            "Epoch #0. Accuracy on batch 2540/3013  on Training is 70.63287091696182\n",
            "Epoch #0. Accuracy on batch 2541/3013  on Training is 70.63458890637294\n",
            "Epoch #0. Accuracy on batch 2542/3013  on Training is 70.63261895399135\n",
            "Epoch #0. Accuracy on batch 2543/3013  on Training is 70.63310731132076\n",
            "Epoch #0. Accuracy on batch 2544/3013  on Training is 70.6299115913556\n",
            "Epoch #0. Accuracy on batch 2545/3013  on Training is 70.63162804399057\n",
            "Epoch #0. Accuracy on batch 2546/3013  on Training is 70.63211621515508\n",
            "Epoch #0. Accuracy on batch 2547/3013  on Training is 70.63383045525903\n",
            "Epoch #0. Accuracy on batch 2548/3013  on Training is 70.63799529227148\n",
            "Epoch #0. Accuracy on batch 2549/3013  on Training is 70.64338235294117\n",
            "Epoch #0. Accuracy on batch 2550/3013  on Training is 70.64019012152097\n",
            "Epoch #0. Accuracy on batch 2551/3013  on Training is 70.64189851097179\n",
            "Epoch #0. Accuracy on batch 2552/3013  on Training is 70.64727771249511\n",
            "Epoch #0. Accuracy on batch 2553/3013  on Training is 70.65142913077526\n",
            "Epoch #0. Accuracy on batch 2554/3013  on Training is 70.65557729941291\n",
            "Epoch #0. Accuracy on batch 2555/3013  on Training is 70.66461267605634\n",
            "Epoch #0. Accuracy on batch 2556/3013  on Training is 70.66508603832617\n",
            "Epoch #0. Accuracy on batch 2557/3013  on Training is 70.66433737294761\n",
            "Epoch #0. Accuracy on batch 2558/3013  on Training is 70.66481047284095\n",
            "Epoch #0. Accuracy on batch 2559/3013  on Training is 70.66650390625\n",
            "Batch Id 2560 is having training loss of 1.2334051132202148\n",
            "0.8413110971450806\n",
            "Epoch #0. Accuracy on batch 2560/3013  on Training is 70.66697579070676\n",
            "Epoch #0. Accuracy on batch 2561/3013  on Training is 70.67110655737704\n",
            "Epoch #0. Accuracy on batch 2562/3013  on Training is 70.67401482637534\n",
            "Epoch #0. Accuracy on batch 2563/3013  on Training is 70.67813962558502\n",
            "Epoch #0. Accuracy on batch 2564/3013  on Training is 70.67860623781677\n",
            "Epoch #0. Accuracy on batch 2565/3013  on Training is 70.680290335152\n",
            "Epoch #0. Accuracy on batch 2566/3013  on Training is 70.68319049474094\n",
            "Epoch #0. Accuracy on batch 2567/3013  on Training is 70.6848714953271\n",
            "Epoch #0. Accuracy on batch 2568/3013  on Training is 70.68776761385753\n",
            "Epoch #0. Accuracy on batch 2569/3013  on Training is 70.69187743190662\n",
            "Epoch #0. Accuracy on batch 2570/3013  on Training is 70.69233761182419\n",
            "Epoch #0. Accuracy on batch 2571/3013  on Training is 70.69765746500778\n",
            "Epoch #0. Accuracy on batch 2572/3013  on Training is 70.7029731830548\n",
            "Epoch #0. Accuracy on batch 2573/3013  on Training is 70.70707070707071\n",
            "Epoch #0. Accuracy on batch 2574/3013  on Training is 70.7123786407767\n",
            "Epoch #0. Accuracy on batch 2575/3013  on Training is 70.71525621118012\n",
            "Epoch #0. Accuracy on batch 2576/3013  on Training is 70.72055684904929\n",
            "Epoch #0. Accuracy on batch 2577/3013  on Training is 70.72585337470908\n",
            "Epoch #0. Accuracy on batch 2578/3013  on Training is 70.72508724311749\n",
            "Epoch #0. Accuracy on batch 2579/3013  on Training is 70.72553294573643\n",
            "Batch Id 2580 is having training loss of 1.229923963546753\n",
            "0.4895994961261749\n",
            "Epoch #0. Accuracy on batch 2580/3013  on Training is 70.73203215807827\n",
            "Epoch #0. Accuracy on batch 2581/3013  on Training is 70.7361057319907\n",
            "Epoch #0. Accuracy on batch 2582/3013  on Training is 70.73896631823462\n",
            "Epoch #0. Accuracy on batch 2583/3013  on Training is 70.73940595975232\n",
            "Epoch #0. Accuracy on batch 2584/3013  on Training is 70.74588974854932\n",
            "Epoch #0. Accuracy on batch 2585/3013  on Training is 70.74753480278422\n",
            "Epoch #0. Accuracy on batch 2586/3013  on Training is 70.74917858523386\n",
            "Epoch #0. Accuracy on batch 2587/3013  on Training is 70.75806607418856\n",
            "Epoch #0. Accuracy on batch 2588/3013  on Training is 70.76211857860177\n",
            "Epoch #0. Accuracy on batch 2589/3013  on Training is 70.76375482625483\n",
            "Epoch #0. Accuracy on batch 2590/3013  on Training is 70.76780200694712\n",
            "Epoch #0. Accuracy on batch 2591/3013  on Training is 70.76822916666667\n",
            "Epoch #0. Accuracy on batch 2592/3013  on Training is 70.77106633243348\n",
            "Epoch #0. Accuracy on batch 2593/3013  on Training is 70.77149190439475\n",
            "Epoch #0. Accuracy on batch 2594/3013  on Training is 70.77552986512524\n",
            "Epoch #0. Accuracy on batch 2595/3013  on Training is 70.7807684899846\n",
            "Epoch #0. Accuracy on batch 2596/3013  on Training is 70.78118983442434\n",
            "Epoch #0. Accuracy on batch 2597/3013  on Training is 70.78161085450347\n",
            "Epoch #0. Accuracy on batch 2598/3013  on Training is 70.78323393612928\n",
            "Epoch #0. Accuracy on batch 2599/3013  on Training is 70.7860576923077\n",
            "Batch Id 2600 is having training loss of 1.2268201112747192\n",
            "0.5843002200126648\n",
            "Epoch #0. Accuracy on batch 2600/3013  on Training is 70.79128219915417\n",
            "Epoch #0. Accuracy on batch 2601/3013  on Training is 70.79169869331284\n",
            "Epoch #0. Accuracy on batch 2602/3013  on Training is 70.79091432961967\n",
            "Epoch #0. Accuracy on batch 2603/3013  on Training is 70.79493087557604\n",
            "Epoch #0. Accuracy on batch 2604/3013  on Training is 70.80134357005758\n",
            "Epoch #0. Accuracy on batch 2605/3013  on Training is 70.80775134305449\n",
            "Epoch #0. Accuracy on batch 2606/3013  on Training is 70.81055811277331\n",
            "Epoch #0. Accuracy on batch 2607/3013  on Training is 70.8169574386503\n",
            "Epoch #0. Accuracy on batch 2608/3013  on Training is 70.81736297431966\n",
            "Epoch #0. Accuracy on batch 2609/3013  on Training is 70.82614942528735\n",
            "Epoch #0. Accuracy on batch 2610/3013  on Training is 70.82535427039448\n",
            "Epoch #0. Accuracy on batch 2611/3013  on Training is 70.8281489280245\n",
            "Epoch #0. Accuracy on batch 2612/3013  on Training is 70.82735361653272\n",
            "Epoch #0. Accuracy on batch 2613/3013  on Training is 70.83134085692426\n",
            "Epoch #0. Accuracy on batch 2614/3013  on Training is 70.83771510516253\n",
            "Epoch #0. Accuracy on batch 2615/3013  on Training is 70.83930619266054\n",
            "Epoch #0. Accuracy on batch 2616/3013  on Training is 70.83850783339702\n",
            "Epoch #0. Accuracy on batch 2617/3013  on Training is 70.83771008403362\n",
            "Epoch #0. Accuracy on batch 2618/3013  on Training is 70.84407216494846\n",
            "Epoch #0. Accuracy on batch 2619/3013  on Training is 70.84804389312977\n",
            "Batch Id 2620 is having training loss of 1.2236506938934326\n",
            "0.8554391860961914\n",
            "Epoch #0. Accuracy on batch 2620/3013  on Training is 70.8496280045784\n",
            "Epoch #0. Accuracy on batch 2621/3013  on Training is 70.85478642257819\n",
            "Epoch #0. Accuracy on batch 2622/3013  on Training is 70.85636675562333\n",
            "Epoch #0. Accuracy on batch 2623/3013  on Training is 70.85318216463415\n",
            "Epoch #0. Accuracy on batch 2624/3013  on Training is 70.85595238095237\n",
            "Epoch #0. Accuracy on batch 2625/3013  on Training is 70.85396039603961\n",
            "Epoch #0. Accuracy on batch 2626/3013  on Training is 70.85434906737724\n",
            "Epoch #0. Accuracy on batch 2627/3013  on Training is 70.85354832572298\n",
            "Epoch #0. Accuracy on batch 2628/3013  on Training is 70.85869151768733\n",
            "Epoch #0. Accuracy on batch 2629/3013  on Training is 70.86145437262357\n",
            "Epoch #0. Accuracy on batch 2630/3013  on Training is 70.86302736602052\n",
            "Epoch #0. Accuracy on batch 2631/3013  on Training is 70.86459916413374\n",
            "Epoch #0. Accuracy on batch 2632/3013  on Training is 70.86973034561336\n",
            "Epoch #0. Accuracy on batch 2633/3013  on Training is 70.87129840546697\n",
            "Epoch #0. Accuracy on batch 2634/3013  on Training is 70.87523719165085\n",
            "Epoch #0. Accuracy on batch 2635/3013  on Training is 70.87798748103187\n",
            "Epoch #0. Accuracy on batch 2636/3013  on Training is 70.88192074326886\n",
            "Epoch #0. Accuracy on batch 2637/3013  on Training is 70.88703563305535\n",
            "Epoch #0. Accuracy on batch 2638/3013  on Training is 70.88977832512315\n",
            "Epoch #0. Accuracy on batch 2639/3013  on Training is 70.89725378787878\n",
            "Batch Id 2640 is having training loss of 1.2211135625839233\n",
            "0.9591155648231506\n",
            "Epoch #0. Accuracy on batch 2640/3013  on Training is 70.89525747822795\n",
            "Epoch #0. Accuracy on batch 2641/3013  on Training is 70.90035957607873\n",
            "Epoch #0. Accuracy on batch 2642/3013  on Training is 70.90191070752932\n",
            "Epoch #0. Accuracy on batch 2643/3013  on Training is 70.910552193646\n",
            "Epoch #0. Accuracy on batch 2644/3013  on Training is 70.91091682419659\n",
            "Epoch #0. Accuracy on batch 2645/3013  on Training is 70.9136432350718\n",
            "Epoch #0. Accuracy on batch 2646/3013  on Training is 70.91518700415565\n",
            "Epoch #0. Accuracy on batch 2647/3013  on Training is 70.91554947129909\n",
            "Epoch #0. Accuracy on batch 2648/3013  on Training is 70.91827104567761\n",
            "Epoch #0. Accuracy on batch 2649/3013  on Training is 70.92570754716981\n",
            "Epoch #0. Accuracy on batch 2650/3013  on Training is 70.92842323651452\n",
            "Epoch #0. Accuracy on batch 2651/3013  on Training is 70.92995852187029\n",
            "Epoch #0. Accuracy on batch 2652/3013  on Training is 70.92913682623445\n",
            "Epoch #0. Accuracy on batch 2653/3013  on Training is 70.9330256217031\n",
            "Epoch #0. Accuracy on batch 2654/3013  on Training is 70.93808851224105\n",
            "Epoch #0. Accuracy on batch 2655/3013  on Training is 70.93961784638554\n",
            "Epoch #0. Accuracy on batch 2656/3013  on Training is 70.94349830636055\n",
            "Epoch #0. Accuracy on batch 2657/3013  on Training is 70.95090293453724\n",
            "Epoch #0. Accuracy on batch 2658/3013  on Training is 70.94772470853704\n",
            "Epoch #0. Accuracy on batch 2659/3013  on Training is 70.95042293233082\n",
            "Batch Id 2660 is having training loss of 1.2181386947631836\n",
            "0.4644237756729126\n",
            "Epoch #0. Accuracy on batch 2660/3013  on Training is 70.95546786922209\n",
            "Epoch #0. Accuracy on batch 2661/3013  on Training is 70.96285687453043\n",
            "Epoch #0. Accuracy on batch 2662/3013  on Training is 70.96202591062712\n",
            "Epoch #0. Accuracy on batch 2663/3013  on Training is 70.96471471471472\n",
            "Epoch #0. Accuracy on batch 2664/3013  on Training is 70.96388367729831\n",
            "Epoch #0. Accuracy on batch 2665/3013  on Training is 70.96656976744185\n",
            "Epoch #0. Accuracy on batch 2666/3013  on Training is 70.9727690288714\n",
            "Epoch #0. Accuracy on batch 2667/3013  on Training is 70.97544977511244\n",
            "Epoch #0. Accuracy on batch 2668/3013  on Training is 70.9757868115399\n",
            "Epoch #0. Accuracy on batch 2669/3013  on Training is 70.98197565543072\n",
            "Epoch #0. Accuracy on batch 2670/3013  on Training is 70.98347997004868\n",
            "Epoch #0. Accuracy on batch 2671/3013  on Training is 70.98498315868264\n",
            "Epoch #0. Accuracy on batch 2672/3013  on Training is 70.98648522259633\n",
            "Epoch #0. Accuracy on batch 2673/3013  on Training is 70.98915482423335\n",
            "Epoch #0. Accuracy on batch 2674/3013  on Training is 70.9894859813084\n",
            "Epoch #0. Accuracy on batch 2675/3013  on Training is 70.99332025411061\n",
            "Epoch #0. Accuracy on batch 2676/3013  on Training is 70.99948636533433\n",
            "Epoch #0. Accuracy on batch 2677/3013  on Training is 71.00214712471994\n",
            "Epoch #0. Accuracy on batch 2678/3013  on Training is 71.00480589772303\n",
            "Epoch #0. Accuracy on batch 2679/3013  on Training is 71.00279850746269\n",
            "Batch Id 2680 is having training loss of 1.2153791189193726\n",
            "0.7421468496322632\n",
            "Epoch #0. Accuracy on batch 2680/3013  on Training is 71.00895188362551\n",
            "Epoch #0. Accuracy on batch 2681/3013  on Training is 71.01160514541387\n",
            "Epoch #0. Accuracy on batch 2682/3013  on Training is 71.0142564293701\n",
            "Epoch #0. Accuracy on batch 2683/3013  on Training is 71.00875558867362\n",
            "Epoch #0. Accuracy on batch 2684/3013  on Training is 71.01024208566108\n",
            "Epoch #0. Accuracy on batch 2685/3013  on Training is 71.01289091586001\n",
            "Epoch #0. Accuracy on batch 2686/3013  on Training is 71.01088574618534\n",
            "Epoch #0. Accuracy on batch 2687/3013  on Training is 71.01818266369048\n",
            "Epoch #0. Accuracy on batch 2688/3013  on Training is 71.02082558571959\n",
            "Epoch #0. Accuracy on batch 2689/3013  on Training is 71.02230483271376\n",
            "Epoch #0. Accuracy on batch 2690/3013  on Training is 71.0249442586399\n",
            "Epoch #0. Accuracy on batch 2691/3013  on Training is 71.02758172362556\n",
            "Epoch #0. Accuracy on batch 2692/3013  on Training is 71.03021722985518\n",
            "Epoch #0. Accuracy on batch 2693/3013  on Training is 71.03053080920564\n",
            "Epoch #0. Accuracy on batch 2694/3013  on Training is 71.03084415584415\n",
            "Epoch #0. Accuracy on batch 2695/3013  on Training is 71.03231639465875\n",
            "Epoch #0. Accuracy on batch 2696/3013  on Training is 71.03262884686688\n",
            "Epoch #0. Accuracy on batch 2697/3013  on Training is 71.03757412898443\n",
            "Epoch #0. Accuracy on batch 2698/3013  on Training is 71.03788440163024\n",
            "Epoch #0. Accuracy on batch 2699/3013  on Training is 71.04282407407408\n",
            "Batch Id 2700 is having training loss of 1.2132840156555176\n",
            "0.7540850043296814\n",
            "Epoch #0. Accuracy on batch 2700/3013  on Training is 71.04891706775268\n",
            "Epoch #0. Accuracy on batch 2701/3013  on Training is 71.05153589933383\n",
            "Epoch #0. Accuracy on batch 2702/3013  on Training is 71.05530891601924\n",
            "Epoch #0. Accuracy on batch 2703/3013  on Training is 71.05792344674556\n",
            "Epoch #0. Accuracy on batch 2704/3013  on Training is 71.06169131238447\n",
            "Epoch #0. Accuracy on batch 2705/3013  on Training is 71.06430155210643\n",
            "Epoch #0. Accuracy on batch 2706/3013  on Training is 71.0726819357222\n",
            "Epoch #0. Accuracy on batch 2707/3013  on Training is 71.0729782127031\n",
            "Epoch #0. Accuracy on batch 2708/3013  on Training is 71.07442783314876\n",
            "Epoch #0. Accuracy on batch 2709/3013  on Training is 71.07933579335793\n",
            "Epoch #0. Accuracy on batch 2710/3013  on Training is 71.08078199926227\n",
            "Epoch #0. Accuracy on batch 2711/3013  on Training is 71.08453171091445\n",
            "Epoch #0. Accuracy on batch 2712/3013  on Training is 71.09288610394397\n",
            "Epoch #0. Accuracy on batch 2713/3013  on Training is 71.09547715549004\n",
            "Epoch #0. Accuracy on batch 2714/3013  on Training is 71.09806629834254\n",
            "Epoch #0. Accuracy on batch 2715/3013  on Training is 71.09835235640648\n",
            "Epoch #0. Accuracy on batch 2716/3013  on Training is 71.10093853514906\n",
            "Epoch #0. Accuracy on batch 2717/3013  on Training is 71.10007358351729\n",
            "Epoch #0. Accuracy on batch 2718/3013  on Training is 71.10150790731886\n",
            "Epoch #0. Accuracy on batch 2719/3013  on Training is 71.1040900735294\n",
            "Batch Id 2720 is having training loss of 1.2103245258331299\n",
            "1.3175623416900635\n",
            "Epoch #0. Accuracy on batch 2720/3013  on Training is 71.10552186696067\n",
            "Epoch #0. Accuracy on batch 2721/3013  on Training is 71.10350844966936\n",
            "Epoch #0. Accuracy on batch 2722/3013  on Training is 71.10608703635695\n",
            "Epoch #0. Accuracy on batch 2723/3013  on Training is 71.11325256975037\n",
            "Epoch #0. Accuracy on batch 2724/3013  on Training is 71.11353211009174\n",
            "Epoch #0. Accuracy on batch 2725/3013  on Training is 71.11610418195158\n",
            "Epoch #0. Accuracy on batch 2726/3013  on Training is 71.11982031536488\n",
            "Epoch #0. Accuracy on batch 2727/3013  on Training is 71.12467925219941\n",
            "Epoch #0. Accuracy on batch 2728/3013  on Training is 71.12724441187248\n",
            "Epoch #0. Accuracy on batch 2729/3013  on Training is 71.12637362637362\n",
            "Epoch #0. Accuracy on batch 2730/3013  on Training is 71.12893628707432\n",
            "Epoch #0. Accuracy on batch 2731/3013  on Training is 71.13378477306003\n",
            "Epoch #0. Accuracy on batch 2732/3013  on Training is 71.1409165751921\n",
            "Epoch #0. Accuracy on batch 2733/3013  on Training is 71.13775603511338\n",
            "Epoch #0. Accuracy on batch 2734/3013  on Training is 71.13916819012798\n",
            "Epoch #0. Accuracy on batch 2735/3013  on Training is 71.1405793128655\n",
            "Epoch #0. Accuracy on batch 2736/3013  on Training is 71.1408476434052\n",
            "Epoch #0. Accuracy on batch 2737/3013  on Training is 71.14225712198686\n",
            "Epoch #0. Accuracy on batch 2738/3013  on Training is 71.14708835341365\n",
            "Epoch #0. Accuracy on batch 2739/3013  on Training is 71.14963503649635\n",
            "Batch Id 2740 is having training loss of 1.207884430885315\n",
            "0.6903999447822571\n",
            "Epoch #0. Accuracy on batch 2740/3013  on Training is 71.15560014593214\n",
            "Epoch #0. Accuracy on batch 2741/3013  on Training is 71.15928154631656\n",
            "Epoch #0. Accuracy on batch 2742/3013  on Training is 71.16068173532628\n",
            "Epoch #0. Accuracy on batch 2743/3013  on Training is 71.16208090379008\n",
            "Epoch #0. Accuracy on batch 2744/3013  on Training is 71.16917122040073\n",
            "Epoch #0. Accuracy on batch 2745/3013  on Training is 71.17625637290604\n",
            "Epoch #0. Accuracy on batch 2746/3013  on Training is 71.17537313432835\n",
            "Epoch #0. Accuracy on batch 2747/3013  on Training is 71.17562772925764\n",
            "Epoch #0. Accuracy on batch 2748/3013  on Training is 71.18042924699891\n",
            "Epoch #0. Accuracy on batch 2749/3013  on Training is 71.18295454545455\n",
            "Epoch #0. Accuracy on batch 2750/3013  on Training is 71.18888585968739\n",
            "Epoch #0. Accuracy on batch 2751/3013  on Training is 71.19367732558139\n",
            "Epoch #0. Accuracy on batch 2752/3013  on Training is 71.20073556120596\n",
            "Epoch #0. Accuracy on batch 2753/3013  on Training is 71.19757625272331\n",
            "Epoch #0. Accuracy on batch 2754/3013  on Training is 71.20349364791288\n",
            "Epoch #0. Accuracy on batch 2755/3013  on Training is 71.2037373004354\n",
            "Epoch #0. Accuracy on batch 2756/3013  on Training is 71.20511425462459\n",
            "Epoch #0. Accuracy on batch 2757/3013  on Training is 71.20422407541697\n",
            "Epoch #0. Accuracy on batch 2758/3013  on Training is 71.20446719826023\n",
            "Epoch #0. Accuracy on batch 2759/3013  on Training is 71.20584239130434\n",
            "Batch Id 2760 is having training loss of 1.2051509618759155\n",
            "0.4689255952835083\n",
            "Epoch #0. Accuracy on batch 2760/3013  on Training is 71.21061209706627\n",
            "Epoch #0. Accuracy on batch 2761/3013  on Training is 71.21650977552498\n",
            "Epoch #0. Accuracy on batch 2762/3013  on Training is 71.2224031849439\n",
            "Epoch #0. Accuracy on batch 2763/3013  on Training is 71.21924746743849\n",
            "Epoch #0. Accuracy on batch 2764/3013  on Training is 71.22174502712477\n",
            "Epoch #0. Accuracy on batch 2765/3013  on Training is 71.2265003615329\n",
            "Epoch #0. Accuracy on batch 2766/3013  on Training is 71.23012287676184\n",
            "Epoch #0. Accuracy on batch 2767/3013  on Training is 71.2314848265896\n",
            "Epoch #0. Accuracy on batch 2768/3013  on Training is 71.23510292524377\n",
            "Epoch #0. Accuracy on batch 2769/3013  on Training is 71.23871841155234\n",
            "Epoch #0. Accuracy on batch 2770/3013  on Training is 71.23782028148683\n",
            "Epoch #0. Accuracy on batch 2771/3013  on Training is 71.24030483405484\n",
            "Epoch #0. Accuracy on batch 2772/3013  on Training is 71.24278759466281\n",
            "Epoch #0. Accuracy on batch 2773/3013  on Training is 71.247521629416\n",
            "Epoch #0. Accuracy on batch 2774/3013  on Training is 71.24887387387388\n",
            "Epoch #0. Accuracy on batch 2775/3013  on Training is 71.25135086455332\n",
            "Epoch #0. Accuracy on batch 2776/3013  on Training is 71.25495138638819\n",
            "Epoch #0. Accuracy on batch 2777/3013  on Training is 71.25967422606192\n",
            "Epoch #0. Accuracy on batch 2778/3013  on Training is 71.26102015113351\n",
            "Epoch #0. Accuracy on batch 2779/3013  on Training is 71.26124100719424\n",
            "Batch Id 2780 is having training loss of 1.2026652097702026\n",
            "0.6583338975906372\n",
            "Epoch #0. Accuracy on batch 2780/3013  on Training is 71.26595649047105\n",
            "Epoch #0. Accuracy on batch 2781/3013  on Training is 71.26617541337167\n",
            "Epoch #0. Accuracy on batch 2782/3013  on Training is 71.2697628458498\n",
            "Epoch #0. Accuracy on batch 2783/3013  on Training is 71.27334770114942\n",
            "Epoch #0. Accuracy on batch 2784/3013  on Training is 71.27805206463195\n",
            "Epoch #0. Accuracy on batch 2785/3013  on Training is 71.28499641062456\n",
            "Epoch #0. Accuracy on batch 2786/3013  on Training is 71.28745066379619\n",
            "Epoch #0. Accuracy on batch 2787/3013  on Training is 71.29102403156385\n",
            "Epoch #0. Accuracy on batch 2788/3013  on Training is 71.29235389028325\n",
            "Epoch #0. Accuracy on batch 2789/3013  on Training is 71.29368279569893\n",
            "Epoch #0. Accuracy on batch 2790/3013  on Training is 71.29725008957362\n",
            "Epoch #0. Accuracy on batch 2791/3013  on Training is 71.29633775071633\n",
            "Epoch #0. Accuracy on batch 2792/3013  on Training is 71.29542606516291\n",
            "Epoch #0. Accuracy on batch 2793/3013  on Training is 71.30010737294202\n",
            "Epoch #0. Accuracy on batch 2794/3013  on Training is 71.30143112701252\n",
            "Epoch #0. Accuracy on batch 2795/3013  on Training is 71.30722460658083\n",
            "Epoch #0. Accuracy on batch 2796/3013  on Training is 71.31301394351091\n",
            "Epoch #0. Accuracy on batch 2797/3013  on Training is 71.31544853466762\n",
            "Epoch #0. Accuracy on batch 2798/3013  on Training is 71.3145319757056\n",
            "Epoch #0. Accuracy on batch 2799/3013  on Training is 71.31696428571429\n",
            "Batch Id 2800 is having training loss of 1.2002965211868286\n",
            "1.114358901977539\n",
            "Epoch #0. Accuracy on batch 2800/3013  on Training is 71.31270082113531\n",
            "Epoch #0. Accuracy on batch 2801/3013  on Training is 71.31736259814419\n",
            "Epoch #0. Accuracy on batch 2802/3013  on Training is 71.32648055654656\n",
            "Epoch #0. Accuracy on batch 2803/3013  on Training is 71.32779065620542\n",
            "Epoch #0. Accuracy on batch 2804/3013  on Training is 71.33021390374331\n",
            "Epoch #0. Accuracy on batch 2805/3013  on Training is 71.33486279401284\n",
            "Epoch #0. Accuracy on batch 2806/3013  on Training is 71.33839508371928\n",
            "Epoch #0. Accuracy on batch 2807/3013  on Training is 71.34303774928775\n",
            "Epoch #0. Accuracy on batch 2808/3013  on Training is 71.34767710929157\n",
            "Epoch #0. Accuracy on batch 2809/3013  on Training is 71.34341637010677\n",
            "Epoch #0. Accuracy on batch 2810/3013  on Training is 71.34694059053717\n",
            "Epoch #0. Accuracy on batch 2811/3013  on Training is 71.35157361308677\n",
            "Epoch #0. Accuracy on batch 2812/3013  on Training is 71.35287060078208\n",
            "Epoch #0. Accuracy on batch 2813/3013  on Training is 71.35305614783226\n",
            "Epoch #0. Accuracy on batch 2814/3013  on Training is 71.35657193605684\n",
            "Epoch #0. Accuracy on batch 2815/3013  on Training is 71.36119495738636\n",
            "Epoch #0. Accuracy on batch 2816/3013  on Training is 71.36692403265886\n",
            "Epoch #0. Accuracy on batch 2817/3013  on Training is 71.36821327182399\n",
            "Epoch #0. Accuracy on batch 2818/3013  on Training is 71.37171869457255\n",
            "Epoch #0. Accuracy on batch 2819/3013  on Training is 71.37411347517731\n",
            "Batch Id 2820 is having training loss of 1.1974972486495972\n",
            "0.56777423620224\n",
            "Epoch #0. Accuracy on batch 2820/3013  on Training is 71.38093761077631\n",
            "Epoch #0. Accuracy on batch 2821/3013  on Training is 71.37446846208363\n",
            "Epoch #0. Accuracy on batch 2822/3013  on Training is 71.37243181013106\n",
            "Epoch #0. Accuracy on batch 2823/3013  on Training is 71.3759295325779\n",
            "Epoch #0. Accuracy on batch 2824/3013  on Training is 71.37721238938053\n",
            "Epoch #0. Accuracy on batch 2825/3013  on Training is 71.38402335456476\n",
            "Epoch #0. Accuracy on batch 2826/3013  on Training is 71.3886186770428\n",
            "Epoch #0. Accuracy on batch 2827/3013  on Training is 71.3932107496464\n",
            "Epoch #0. Accuracy on batch 2828/3013  on Training is 71.39227642276423\n",
            "Epoch #0. Accuracy on batch 2829/3013  on Training is 71.39355123674912\n",
            "Epoch #0. Accuracy on batch 2830/3013  on Training is 71.39592900035323\n",
            "Epoch #0. Accuracy on batch 2831/3013  on Training is 71.39830508474576\n",
            "Epoch #0. Accuracy on batch 2832/3013  on Training is 71.40398870455347\n",
            "Epoch #0. Accuracy on batch 2833/3013  on Training is 71.4063602681722\n",
            "Epoch #0. Accuracy on batch 2834/3013  on Training is 71.40983245149911\n",
            "Epoch #0. Accuracy on batch 2835/3013  on Training is 71.41109837799718\n",
            "Epoch #0. Accuracy on batch 2836/3013  on Training is 71.41456644342615\n",
            "Epoch #0. Accuracy on batch 2837/3013  on Training is 71.41803206483439\n",
            "Epoch #0. Accuracy on batch 2838/3013  on Training is 71.42039450510744\n",
            "Epoch #0. Accuracy on batch 2839/3013  on Training is 71.42495598591549\n",
            "Batch Id 2840 is having training loss of 1.194944977760315\n",
            "0.6135643124580383\n",
            "Epoch #0. Accuracy on batch 2840/3013  on Training is 71.43171418514608\n",
            "Epoch #0. Accuracy on batch 2841/3013  on Training is 71.4362684729064\n",
            "Epoch #0. Accuracy on batch 2842/3013  on Training is 71.44191874780162\n",
            "Epoch #0. Accuracy on batch 2843/3013  on Training is 71.44536744022504\n",
            "Epoch #0. Accuracy on batch 2844/3013  on Training is 71.45101054481546\n",
            "Epoch #0. Accuracy on batch 2845/3013  on Training is 71.45445361911455\n",
            "Epoch #0. Accuracy on batch 2846/3013  on Training is 71.45679662802951\n",
            "Epoch #0. Accuracy on batch 2847/3013  on Training is 71.46023525280899\n",
            "Epoch #0. Accuracy on batch 2848/3013  on Training is 71.46476833976834\n",
            "Epoch #0. Accuracy on batch 2849/3013  on Training is 71.46820175438596\n",
            "Epoch #0. Accuracy on batch 2850/3013  on Training is 71.47272886706419\n",
            "Epoch #0. Accuracy on batch 2851/3013  on Training is 71.47396563814867\n",
            "Epoch #0. Accuracy on batch 2852/3013  on Training is 71.4762968804767\n",
            "Epoch #0. Accuracy on batch 2853/3013  on Training is 71.47534162578837\n",
            "Epoch #0. Accuracy on batch 2854/3013  on Training is 71.47985989492119\n",
            "Epoch #0. Accuracy on batch 2855/3013  on Training is 71.48218662464986\n",
            "Epoch #0. Accuracy on batch 2856/3013  on Training is 71.48669933496674\n",
            "Epoch #0. Accuracy on batch 2857/3013  on Training is 71.49011546536039\n",
            "Epoch #0. Accuracy on batch 2858/3013  on Training is 71.49243616649179\n",
            "Epoch #0. Accuracy on batch 2859/3013  on Training is 71.49366258741259\n",
            "Batch Id 2860 is having training loss of 1.1916186809539795\n",
            "0.2956537902355194\n",
            "Epoch #0. Accuracy on batch 2860/3013  on Training is 71.50144180356519\n",
            "Epoch #0. Accuracy on batch 2861/3013  on Training is 71.50048043326345\n",
            "Epoch #0. Accuracy on batch 2862/3013  on Training is 71.5049772965421\n",
            "Epoch #0. Accuracy on batch 2863/3013  on Training is 71.51056215083798\n",
            "Epoch #0. Accuracy on batch 2864/3013  on Training is 71.51723385689354\n",
            "Epoch #0. Accuracy on batch 2865/3013  on Training is 71.52062979762735\n",
            "Epoch #0. Accuracy on batch 2866/3013  on Training is 71.52402336937566\n",
            "Epoch #0. Accuracy on batch 2867/3013  on Training is 71.51978730822873\n",
            "Epoch #0. Accuracy on batch 2868/3013  on Training is 71.51991111885674\n",
            "Epoch #0. Accuracy on batch 2869/3013  on Training is 71.52330139372822\n",
            "Epoch #0. Accuracy on batch 2870/3013  on Training is 71.52451236502961\n",
            "Epoch #0. Accuracy on batch 2871/3013  on Training is 71.52463440111421\n",
            "Epoch #0. Accuracy on batch 2872/3013  on Training is 71.52910720501218\n",
            "Epoch #0. Accuracy on batch 2873/3013  on Training is 71.52922755741128\n",
            "Epoch #0. Accuracy on batch 2874/3013  on Training is 71.53152173913044\n",
            "Epoch #0. Accuracy on batch 2875/3013  on Training is 71.53381432545201\n",
            "Epoch #0. Accuracy on batch 2876/3013  on Training is 71.53393291623219\n",
            "Epoch #0. Accuracy on batch 2877/3013  on Training is 71.53513724808894\n",
            "Epoch #0. Accuracy on batch 2878/3013  on Training is 71.53634074331364\n",
            "Epoch #0. Accuracy on batch 2879/3013  on Training is 71.54079861111111\n",
            "Batch Id 2880 is having training loss of 1.1888947486877441\n",
            "0.5696060061454773\n",
            "Epoch #0. Accuracy on batch 2880/3013  on Training is 71.54416869142659\n",
            "Epoch #0. Accuracy on batch 2881/3013  on Training is 71.54428348369188\n",
            "Epoch #0. Accuracy on batch 2882/3013  on Training is 71.54439819632327\n",
            "Epoch #0. Accuracy on batch 2883/3013  on Training is 71.54884708737865\n",
            "Epoch #0. Accuracy on batch 2884/3013  on Training is 71.55004332755632\n",
            "Epoch #0. Accuracy on batch 2885/3013  on Training is 71.55340436590437\n",
            "Epoch #0. Accuracy on batch 2886/3013  on Training is 71.5545981988223\n",
            "Epoch #0. Accuracy on batch 2887/3013  on Training is 71.55795533240997\n",
            "Epoch #0. Accuracy on batch 2888/3013  on Training is 71.56022845275182\n",
            "Epoch #0. Accuracy on batch 2889/3013  on Training is 71.56141868512111\n",
            "Epoch #0. Accuracy on batch 2890/3013  on Training is 71.563689034936\n",
            "Epoch #0. Accuracy on batch 2891/3013  on Training is 71.56487724757953\n",
            "Epoch #0. Accuracy on batch 2892/3013  on Training is 71.57038541306602\n",
            "Epoch #0. Accuracy on batch 2893/3013  on Training is 71.57373013130615\n",
            "Epoch #0. Accuracy on batch 2894/3013  on Training is 71.57707253886011\n",
            "Epoch #0. Accuracy on batch 2895/3013  on Training is 71.57501726519337\n",
            "Epoch #0. Accuracy on batch 2896/3013  on Training is 71.57619951674145\n",
            "Epoch #0. Accuracy on batch 2897/3013  on Training is 71.57630262249828\n",
            "Epoch #0. Accuracy on batch 2898/3013  on Training is 71.57856157295619\n",
            "Epoch #0. Accuracy on batch 2899/3013  on Training is 71.58512931034483\n",
            "Batch Id 2900 is having training loss of 1.186755657196045\n",
            "1.6023286581039429\n",
            "Epoch #0. Accuracy on batch 2900/3013  on Training is 71.58415201654601\n",
            "Epoch #0. Accuracy on batch 2901/3013  on Training is 71.58855961405926\n",
            "Epoch #0. Accuracy on batch 2902/3013  on Training is 71.58973475714778\n",
            "Epoch #0. Accuracy on batch 2903/3013  on Training is 71.59306129476585\n",
            "Epoch #0. Accuracy on batch 2904/3013  on Training is 71.59638554216868\n",
            "Epoch #0. Accuracy on batch 2905/3013  on Training is 71.59970750172057\n",
            "Epoch #0. Accuracy on batch 2906/3013  on Training is 71.60410216718266\n",
            "Epoch #0. Accuracy on batch 2907/3013  on Training is 71.60526994497937\n",
            "Epoch #0. Accuracy on batch 2908/3013  on Training is 71.61288243382606\n",
            "Epoch #0. Accuracy on batch 2909/3013  on Training is 71.61297250859107\n",
            "Epoch #0. Accuracy on batch 2910/3013  on Training is 71.61413603572656\n",
            "Epoch #0. Accuracy on batch 2911/3013  on Training is 71.61422561813187\n",
            "Epoch #0. Accuracy on batch 2912/3013  on Training is 71.61967902506008\n",
            "Epoch #0. Accuracy on batch 2913/3013  on Training is 71.62405628002746\n",
            "Epoch #0. Accuracy on batch 2914/3013  on Training is 71.62843053173242\n",
            "Epoch #0. Accuracy on batch 2915/3013  on Training is 71.63065843621399\n",
            "Epoch #0. Accuracy on batch 2916/3013  on Training is 71.63502742543709\n",
            "Epoch #0. Accuracy on batch 2917/3013  on Training is 71.63296778615491\n",
            "Epoch #0. Accuracy on batch 2918/3013  on Training is 71.63626241863652\n",
            "Epoch #0. Accuracy on batch 2919/3013  on Training is 71.63741438356165\n",
            "Batch Id 2920 is having training loss of 1.184052586555481\n",
            "0.6980990171432495\n",
            "Epoch #0. Accuracy on batch 2920/3013  on Training is 71.63963539883602\n",
            "Epoch #0. Accuracy on batch 2921/3013  on Training is 71.64506331279945\n",
            "Epoch #0. Accuracy on batch 2922/3013  on Training is 71.64621108450223\n",
            "Epoch #0. Accuracy on batch 2923/3013  on Training is 71.64628932968536\n",
            "Epoch #0. Accuracy on batch 2924/3013  on Training is 71.64636752136752\n",
            "Epoch #0. Accuracy on batch 2925/3013  on Training is 71.64644565960356\n",
            "Epoch #0. Accuracy on batch 2926/3013  on Training is 71.65186197471814\n",
            "Epoch #0. Accuracy on batch 2927/3013  on Training is 71.6583418715847\n",
            "Epoch #0. Accuracy on batch 2928/3013  on Training is 71.66054967565722\n",
            "Epoch #0. Accuracy on batch 2929/3013  on Training is 71.66382252559727\n",
            "Epoch #0. Accuracy on batch 2930/3013  on Training is 71.66496076424428\n",
            "Epoch #0. Accuracy on batch 2931/3013  on Training is 71.66929570259208\n",
            "Epoch #0. Accuracy on batch 2932/3013  on Training is 71.67149676099557\n",
            "Epoch #0. Accuracy on batch 2933/3013  on Training is 71.67582651670075\n",
            "Epoch #0. Accuracy on batch 2934/3013  on Training is 71.67802385008518\n",
            "Epoch #0. Accuracy on batch 2935/3013  on Training is 71.6748978201635\n",
            "Epoch #0. Accuracy on batch 2936/3013  on Training is 71.67496595165134\n",
            "Epoch #0. Accuracy on batch 2937/3013  on Training is 71.67716133424098\n",
            "Epoch #0. Accuracy on batch 2938/3013  on Training is 71.67935522286491\n",
            "Epoch #0. Accuracy on batch 2939/3013  on Training is 71.67835884353741\n",
            "Batch Id 2940 is having training loss of 1.18104088306427\n",
            "0.6298630833625793\n",
            "Epoch #0. Accuracy on batch 2940/3013  on Training is 71.68161339680381\n",
            "Epoch #0. Accuracy on batch 2941/3013  on Training is 71.68592794017675\n",
            "Epoch #0. Accuracy on batch 2942/3013  on Training is 71.68493034318722\n",
            "Epoch #0. Accuracy on batch 2943/3013  on Training is 71.68924082880434\n",
            "Epoch #0. Accuracy on batch 2944/3013  on Training is 71.69142614601019\n",
            "Epoch #0. Accuracy on batch 2945/3013  on Training is 71.69573150033945\n",
            "Epoch #0. Accuracy on batch 2946/3013  on Training is 71.70003393281303\n",
            "Epoch #0. Accuracy on batch 2947/3013  on Training is 71.70221336499321\n",
            "Epoch #0. Accuracy on batch 2948/3013  on Training is 71.7054510003391\n",
            "Epoch #0. Accuracy on batch 2949/3013  on Training is 71.70868644067797\n",
            "Epoch #0. Accuracy on batch 2950/3013  on Training is 71.71191968824128\n",
            "Epoch #0. Accuracy on batch 2951/3013  on Training is 71.71303353658537\n",
            "Epoch #0. Accuracy on batch 2952/3013  on Training is 71.71732136810024\n",
            "Epoch #0. Accuracy on batch 2953/3013  on Training is 71.72266418415707\n",
            "Epoch #0. Accuracy on batch 2954/3013  on Training is 71.72483079526226\n",
            "Epoch #0. Accuracy on batch 2955/3013  on Training is 71.72911028416779\n",
            "Epoch #0. Accuracy on batch 2956/3013  on Training is 71.72915962123774\n",
            "Epoch #0. Accuracy on batch 2957/3013  on Training is 71.73343475321163\n",
            "Epoch #0. Accuracy on batch 2958/3013  on Training is 71.73665089557282\n",
            "Epoch #0. Accuracy on batch 2959/3013  on Training is 71.74092060810811\n",
            "Batch Id 2960 is having training loss of 1.1782596111297607\n",
            "1.1535745859146118\n",
            "Epoch #0. Accuracy on batch 2960/3013  on Training is 71.74096588990206\n",
            "Epoch #0. Accuracy on batch 2961/3013  on Training is 71.74417623227549\n",
            "Epoch #0. Accuracy on batch 2962/3013  on Training is 71.74738440769491\n",
            "Epoch #0. Accuracy on batch 2963/3013  on Training is 71.74953609986505\n",
            "Epoch #0. Accuracy on batch 2964/3013  on Training is 71.7506323777403\n",
            "Epoch #0. Accuracy on batch 2965/3013  on Training is 71.756995954147\n",
            "Epoch #0. Accuracy on batch 2966/3013  on Training is 71.76440849342771\n",
            "Epoch #0. Accuracy on batch 2967/3013  on Training is 71.7654986522911\n",
            "Epoch #0. Accuracy on batch 2968/3013  on Training is 71.76553553384979\n",
            "Epoch #0. Accuracy on batch 2969/3013  on Training is 71.76767676767676\n",
            "Epoch #0. Accuracy on batch 2970/3013  on Training is 71.77192022887917\n",
            "Epoch #0. Accuracy on batch 2971/3013  on Training is 71.77721231493943\n",
            "Epoch #0. Accuracy on batch 2972/3013  on Training is 71.78039858728557\n",
            "Epoch #0. Accuracy on batch 2973/3013  on Training is 71.78463349024882\n",
            "Epoch #0. Accuracy on batch 2974/3013  on Training is 71.78886554621849\n",
            "Epoch #0. Accuracy on batch 2975/3013  on Training is 71.79309475806451\n",
            "Epoch #0. Accuracy on batch 2976/3013  on Training is 71.79522169969768\n",
            "Epoch #0. Accuracy on batch 2977/3013  on Training is 71.79734721289456\n",
            "Epoch #0. Accuracy on batch 2978/3013  on Training is 71.79632426988923\n",
            "Epoch #0. Accuracy on batch 2979/3013  on Training is 71.79739932885906\n",
            "Batch Id 2980 is having training loss of 1.1755374670028687\n",
            "1.089073896408081\n",
            "Epoch #0. Accuracy on batch 2980/3013  on Training is 71.79847366655484\n",
            "Epoch #0. Accuracy on batch 2981/3013  on Training is 71.79745137491616\n",
            "Epoch #0. Accuracy on batch 2982/3013  on Training is 71.79957257794167\n",
            "Epoch #0. Accuracy on batch 2983/3013  on Training is 71.80483411528151\n",
            "Epoch #0. Accuracy on batch 2984/3013  on Training is 71.80799832495812\n",
            "Epoch #0. Accuracy on batch 2985/3013  on Training is 71.81011386470195\n",
            "Epoch #0. Accuracy on batch 2986/3013  on Training is 71.8111817877469\n",
            "Epoch #0. Accuracy on batch 2987/3013  on Training is 71.81329484605087\n",
            "Epoch #0. Accuracy on batch 2988/3013  on Training is 71.80913348946136\n",
            "Epoch #0. Accuracy on batch 2989/3013  on Training is 71.80811036789298\n",
            "Epoch #0. Accuracy on batch 2990/3013  on Training is 71.80917753259779\n",
            "Epoch #0. Accuracy on batch 2991/3013  on Training is 71.81546624331551\n",
            "Epoch #0. Accuracy on batch 2992/3013  on Training is 71.81966254594053\n",
            "Epoch #0. Accuracy on batch 2993/3013  on Training is 71.82281229124916\n",
            "Epoch #0. Accuracy on batch 2994/3013  on Training is 71.82178631051752\n",
            "Epoch #0. Accuracy on batch 2995/3013  on Training is 71.82180407209613\n",
            "Epoch #0. Accuracy on batch 2996/3013  on Training is 71.82599265932599\n",
            "Epoch #0. Accuracy on batch 2997/3013  on Training is 71.82913609072715\n",
            "Epoch #0. Accuracy on batch 2998/3013  on Training is 71.8291513837946\n",
            "Epoch #0. Accuracy on batch 2999/3013  on Training is 71.83229166666666\n",
            "Batch Id 3000 is having training loss of 1.1730694770812988\n",
            "0.8065100312232971\n",
            "Epoch #0. Accuracy on batch 3000/3013  on Training is 71.83438853715428\n",
            "Epoch #0. Accuracy on batch 3001/3013  on Training is 71.83752498334444\n",
            "Epoch #0. Accuracy on batch 3002/3013  on Training is 71.84378121878122\n",
            "Epoch #0. Accuracy on batch 3003/3013  on Training is 71.84795272969374\n",
            "Epoch #0. Accuracy on batch 3004/3013  on Training is 71.85004159733776\n",
            "Epoch #0. Accuracy on batch 3005/3013  on Training is 71.84901031270792\n",
            "Epoch #0. Accuracy on batch 3006/3013  on Training is 71.84901895576986\n",
            "Epoch #0. Accuracy on batch 3007/3013  on Training is 71.85318317819149\n",
            "Epoch #0. Accuracy on batch 3008/3013  on Training is 71.85630608175474\n",
            "Epoch #0. Accuracy on batch 3009/3013  on Training is 71.85735049833887\n",
            "Epoch #0. Accuracy on batch 3010/3013  on Training is 71.85839422118897\n",
            "Epoch #0. Accuracy on batch 3011/3013  on Training is 71.85839973439575\n",
            "Epoch #0. Accuracy on batch 3012/3013  on Training is 71.86028176027554\n",
            "Epoch #0. Batch Id 0/278  is having validation loss of 1.1610910892486572\n",
            "1.1610910892486572\n",
            "Epoch #0. Batch Id 0/278  is having validation accuracy of 75.0\n",
            "Epoch #0. Batch Id 1/278  is having validation loss of 0.9094400405883789\n",
            "0.6577889919281006\n",
            "Epoch #0. Batch Id 1/278  is having validation accuracy of 81.25\n",
            "Epoch #0. Batch Id 2/278  is having validation loss of 0.8408214449882507\n",
            "0.7035843133926392\n",
            "Epoch #0. Batch Id 2/278  is having validation accuracy of 82.29166666666667\n",
            "Epoch #0. Batch Id 3/278  is having validation loss of 0.7275305986404419\n",
            "0.38765817880630493\n",
            "Epoch #0. Batch Id 3/278  is having validation accuracy of 82.8125\n",
            "Epoch #0. Batch Id 4/278  is having validation loss of 0.8239164352416992\n",
            "1.209459662437439\n",
            "Epoch #0. Batch Id 4/278  is having validation accuracy of 79.375\n",
            "Epoch #0. Batch Id 5/278  is having validation loss of 0.8091821670532227\n",
            "0.7355106472969055\n",
            "Epoch #0. Batch Id 5/278  is having validation accuracy of 80.20833333333333\n",
            "Epoch #0. Batch Id 6/278  is having validation loss of 0.860616147518158\n",
            "1.1692198514938354\n",
            "Epoch #0. Batch Id 6/278  is having validation accuracy of 78.57142857142857\n",
            "Epoch #0. Batch Id 7/278  is having validation loss of 0.7855650782585144\n",
            "0.2602077126502991\n",
            "Epoch #0. Batch Id 7/278  is having validation accuracy of 80.46875\n",
            "Epoch #0. Batch Id 8/278  is having validation loss of 0.7404336929321289\n",
            "0.37938281893730164\n",
            "Epoch #0. Batch Id 8/278  is having validation accuracy of 81.94444444444444\n",
            "Epoch #0. Batch Id 9/278  is having validation loss of 0.7210357785224915\n",
            "0.5464546084403992\n",
            "Epoch #0. Batch Id 9/278  is having validation accuracy of 82.1875\n",
            "Epoch #0. Batch Id 10/278  is having validation loss of 0.7213888168334961\n",
            "0.7249191999435425\n",
            "Epoch #0. Batch Id 10/278  is having validation accuracy of 82.10227272727273\n",
            "Epoch #0. Batch Id 11/278  is having validation loss of 0.7331082224845886\n",
            "0.8620213866233826\n",
            "Epoch #0. Batch Id 11/278  is having validation accuracy of 81.77083333333333\n",
            "Epoch #0. Batch Id 12/278  is having validation loss of 0.7485018372535706\n",
            "0.9332255721092224\n",
            "Epoch #0. Batch Id 12/278  is having validation accuracy of 81.49038461538461\n",
            "Epoch #0. Batch Id 13/278  is having validation loss of 0.7483994364738464\n",
            "0.7470681667327881\n",
            "Epoch #0. Batch Id 13/278  is having validation accuracy of 81.02678571428571\n",
            "Epoch #0. Batch Id 14/278  is having validation loss of 0.7612016797065735\n",
            "0.9404333233833313\n",
            "Epoch #0. Batch Id 14/278  is having validation accuracy of 80.83333333333333\n",
            "Epoch #0. Batch Id 15/278  is having validation loss of 0.7530480623245239\n",
            "0.6307442784309387\n",
            "Epoch #0. Batch Id 15/278  is having validation accuracy of 81.25\n",
            "Epoch #0. Batch Id 16/278  is having validation loss of 0.7691421508789062\n",
            "1.0266475677490234\n",
            "Epoch #0. Batch Id 16/278  is having validation accuracy of 81.06617647058823\n",
            "Epoch #0. Batch Id 17/278  is having validation loss of 0.7558948397636414\n",
            "0.5306905508041382\n",
            "Epoch #0. Batch Id 17/278  is having validation accuracy of 81.25\n",
            "Epoch #0. Batch Id 18/278  is having validation loss of 0.749367356300354\n",
            "0.631872296333313\n",
            "Epoch #0. Batch Id 18/278  is having validation accuracy of 81.08552631578948\n",
            "Epoch #0. Batch Id 19/278  is having validation loss of 0.7463036775588989\n",
            "0.6880936026573181\n",
            "Epoch #0. Batch Id 19/278  is having validation accuracy of 81.25\n",
            "Epoch #0. Batch Id 20/278  is having validation loss of 0.7436414361000061\n",
            "0.6903969645500183\n",
            "Epoch #0. Batch Id 20/278  is having validation accuracy of 81.39880952380952\n",
            "Epoch #0. Batch Id 21/278  is having validation loss of 0.7341656684875488\n",
            "0.5351746082305908\n",
            "Epoch #0. Batch Id 21/278  is having validation accuracy of 81.5340909090909\n",
            "Epoch #0. Batch Id 22/278  is having validation loss of 0.7168653011322021\n",
            "0.3362579047679901\n",
            "Epoch #0. Batch Id 22/278  is having validation accuracy of 82.20108695652173\n",
            "Epoch #0. Batch Id 23/278  is having validation loss of 0.7212483286857605\n",
            "0.8220582008361816\n",
            "Epoch #0. Batch Id 23/278  is having validation accuracy of 81.90104166666667\n",
            "Epoch #0. Batch Id 24/278  is having validation loss of 0.7049561142921448\n",
            "0.31394314765930176\n",
            "Epoch #0. Batch Id 24/278  is having validation accuracy of 82.5\n",
            "Epoch #0. Batch Id 25/278  is having validation loss of 0.714368999004364\n",
            "0.9496909976005554\n",
            "Epoch #0. Batch Id 25/278  is having validation accuracy of 82.09134615384616\n",
            "Epoch #0. Batch Id 26/278  is having validation loss of 0.7085803747177124\n",
            "0.5580766797065735\n",
            "Epoch #0. Batch Id 26/278  is having validation accuracy of 82.17592592592592\n",
            "Epoch #0. Batch Id 27/278  is having validation loss of 0.7157727479934692\n",
            "0.909966766834259\n",
            "Epoch #0. Batch Id 27/278  is having validation accuracy of 81.91964285714286\n",
            "Epoch #0. Batch Id 28/278  is having validation loss of 0.7278475761413574\n",
            "1.0659421682357788\n",
            "Epoch #0. Batch Id 28/278  is having validation accuracy of 81.78879310344827\n",
            "Epoch #0. Batch Id 29/278  is having validation loss of 0.7143905758857727\n",
            "0.32413703203201294\n",
            "Epoch #0. Batch Id 29/278  is having validation accuracy of 82.29166666666667\n",
            "Epoch #0. Batch Id 30/278  is having validation loss of 0.706915557384491\n",
            "0.48266473412513733\n",
            "Epoch #0. Batch Id 30/278  is having validation accuracy of 82.45967741935483\n",
            "Epoch #0. Batch Id 31/278  is having validation loss of 0.7111824154853821\n",
            "0.8434543013572693\n",
            "Epoch #0. Batch Id 31/278  is having validation accuracy of 82.51953125\n",
            "Epoch #0. Batch Id 32/278  is having validation loss of 0.7071267366409302\n",
            "0.5773456692695618\n",
            "Epoch #0. Batch Id 32/278  is having validation accuracy of 82.76515151515152\n",
            "Epoch #0. Batch Id 33/278  is having validation loss of 0.7038672566413879\n",
            "0.5963050723075867\n",
            "Epoch #0. Batch Id 33/278  is having validation accuracy of 82.8125\n",
            "Epoch #0. Batch Id 34/278  is having validation loss of 0.7137977480888367\n",
            "1.0514343976974487\n",
            "Epoch #0. Batch Id 34/278  is having validation accuracy of 82.58928571428571\n",
            "Epoch #0. Batch Id 35/278  is having validation loss of 0.7145572304725647\n",
            "0.7411389946937561\n",
            "Epoch #0. Batch Id 35/278  is having validation accuracy of 82.46527777777777\n",
            "Epoch #0. Batch Id 36/278  is having validation loss of 0.7159909009933472\n",
            "0.7676024436950684\n",
            "Epoch #0. Batch Id 36/278  is having validation accuracy of 82.51689189189189\n",
            "Epoch #0. Batch Id 37/278  is having validation loss of 0.711939811706543\n",
            "0.5620496869087219\n",
            "Epoch #0. Batch Id 37/278  is having validation accuracy of 82.73026315789474\n",
            "Epoch #0. Batch Id 38/278  is having validation loss of 0.7238272428512573\n",
            "1.1755496263504028\n",
            "Epoch #0. Batch Id 38/278  is having validation accuracy of 82.53205128205128\n",
            "Epoch #0. Batch Id 39/278  is having validation loss of 0.7231894731521606\n",
            "0.6983175873756409\n",
            "Epoch #0. Batch Id 39/278  is having validation accuracy of 82.34375\n",
            "Epoch #0. Batch Id 40/278  is having validation loss of 0.7182357311248779\n",
            "0.520085871219635\n",
            "Epoch #0. Batch Id 40/278  is having validation accuracy of 82.46951219512195\n",
            "Epoch #0. Batch Id 41/278  is having validation loss of 0.7208684682846069\n",
            "0.8288096189498901\n",
            "Epoch #0. Batch Id 41/278  is having validation accuracy of 82.2172619047619\n",
            "Epoch #0. Batch Id 42/278  is having validation loss of 0.722187876701355\n",
            "0.7776033282279968\n",
            "Epoch #0. Batch Id 42/278  is having validation accuracy of 82.12209302325581\n",
            "Epoch #0. Batch Id 43/278  is having validation loss of 0.7193747162818909\n",
            "0.5984084606170654\n",
            "Epoch #0. Batch Id 43/278  is having validation accuracy of 82.03125\n",
            "Epoch #0. Batch Id 44/278  is having validation loss of 0.7239170670509338\n",
            "0.9237810969352722\n",
            "Epoch #0. Batch Id 44/278  is having validation accuracy of 81.73611111111111\n",
            "Epoch #0. Batch Id 45/278  is having validation loss of 0.7241884469985962\n",
            "0.7363991737365723\n",
            "Epoch #0. Batch Id 45/278  is having validation accuracy of 81.72554347826087\n",
            "Epoch #0. Batch Id 46/278  is having validation loss of 0.7210960388183594\n",
            "0.578844428062439\n",
            "Epoch #0. Batch Id 46/278  is having validation accuracy of 81.71542553191489\n",
            "Epoch #0. Batch Id 47/278  is having validation loss of 0.7213926315307617\n",
            "0.7353318929672241\n",
            "Epoch #0. Batch Id 47/278  is having validation accuracy of 81.70572916666667\n",
            "Epoch #0. Batch Id 48/278  is having validation loss of 0.7202683687210083\n",
            "0.6663051843643188\n",
            "Epoch #0. Batch Id 48/278  is having validation accuracy of 81.5688775510204\n",
            "Epoch #0. Batch Id 49/278  is having validation loss of 0.7205577492713928\n",
            "0.7347368001937866\n",
            "Epoch #0. Batch Id 49/278  is having validation accuracy of 81.375\n",
            "Epoch #0. Batch Id 50/278  is having validation loss of 0.7176302671432495\n",
            "0.5712553262710571\n",
            "Epoch #0. Batch Id 50/278  is having validation accuracy of 81.43382352941177\n",
            "Epoch #0. Batch Id 51/278  is having validation loss of 0.7140047550201416\n",
            "0.5291051268577576\n",
            "Epoch #0. Batch Id 51/278  is having validation accuracy of 81.3701923076923\n",
            "Epoch #0. Batch Id 52/278  is having validation loss of 0.7133487462997437\n",
            "0.6792362928390503\n",
            "Epoch #0. Batch Id 52/278  is having validation accuracy of 81.48584905660377\n",
            "Epoch #0. Batch Id 53/278  is having validation loss of 0.719760537147522\n",
            "1.0595850944519043\n",
            "Epoch #0. Batch Id 53/278  is having validation accuracy of 81.30787037037037\n",
            "Epoch #0. Batch Id 54/278  is having validation loss of 0.718332827091217\n",
            "0.6412351727485657\n",
            "Epoch #0. Batch Id 54/278  is having validation accuracy of 81.47727272727273\n",
            "Epoch #0. Batch Id 55/278  is having validation loss of 0.713653028011322\n",
            "0.4562627375125885\n",
            "Epoch #0. Batch Id 55/278  is having validation accuracy of 81.640625\n",
            "Epoch #0. Batch Id 56/278  is having validation loss of 0.7225549221038818\n",
            "1.2210594415664673\n",
            "Epoch #0. Batch Id 56/278  is having validation accuracy of 81.41447368421052\n",
            "Epoch #0. Batch Id 57/278  is having validation loss of 0.7216099500656128\n",
            "0.6677460670471191\n",
            "Epoch #0. Batch Id 57/278  is having validation accuracy of 81.51939655172414\n",
            "Epoch #0. Batch Id 58/278  is having validation loss of 0.7184708714485168\n",
            "0.5364044904708862\n",
            "Epoch #0. Batch Id 58/278  is having validation accuracy of 81.5677966101695\n",
            "Epoch #0. Batch Id 59/278  is having validation loss of 0.7177137732505798\n",
            "0.6730433702468872\n",
            "Epoch #0. Batch Id 59/278  is having validation accuracy of 81.61458333333333\n",
            "Epoch #0. Batch Id 60/278  is having validation loss of 0.7129968404769897\n",
            "0.42998039722442627\n",
            "Epoch #0. Batch Id 60/278  is having validation accuracy of 81.76229508196721\n",
            "Epoch #0. Batch Id 61/278  is having validation loss of 0.7135751247406006\n",
            "0.7488519549369812\n",
            "Epoch #0. Batch Id 61/278  is having validation accuracy of 81.65322580645162\n",
            "Epoch #0. Batch Id 62/278  is having validation loss of 0.7098357081413269\n",
            "0.47799333930015564\n",
            "Epoch #0. Batch Id 62/278  is having validation accuracy of 81.79563492063492\n",
            "Epoch #0. Batch Id 63/278  is having validation loss of 0.7116739153862\n",
            "0.827480137348175\n",
            "Epoch #0. Batch Id 63/278  is having validation accuracy of 81.787109375\n",
            "Epoch #0. Batch Id 64/278  is having validation loss of 0.7139938473701477\n",
            "0.8624711632728577\n",
            "Epoch #0. Batch Id 64/278  is having validation accuracy of 81.63461538461539\n",
            "Epoch #0. Batch Id 65/278  is having validation loss of 0.7091694474220276\n",
            "0.3955826163291931\n",
            "Epoch #0. Batch Id 65/278  is having validation accuracy of 81.77083333333333\n",
            "Epoch #0. Batch Id 66/278  is having validation loss of 0.7065901160240173\n",
            "0.536353588104248\n",
            "Epoch #0. Batch Id 66/278  is having validation accuracy of 81.85634328358209\n",
            "Epoch #0. Batch Id 67/278  is having validation loss of 0.7100151777267456\n",
            "0.9394958019256592\n",
            "Epoch #0. Batch Id 67/278  is having validation accuracy of 81.80147058823529\n",
            "Epoch #0. Batch Id 68/278  is having validation loss of 0.7065443396568298\n",
            "0.4705285131931305\n",
            "Epoch #0. Batch Id 68/278  is having validation accuracy of 81.8840579710145\n",
            "Epoch #0. Batch Id 69/278  is having validation loss of 0.7049761414527893\n",
            "0.5967704057693481\n",
            "Epoch #0. Batch Id 69/278  is having validation accuracy of 81.91964285714286\n",
            "Epoch #0. Batch Id 70/278  is having validation loss of 0.7110503911972046\n",
            "1.1362477540969849\n",
            "Epoch #0. Batch Id 70/278  is having validation accuracy of 81.77816901408451\n",
            "Epoch #0. Batch Id 71/278  is having validation loss of 0.705760657787323\n",
            "0.33018842339515686\n",
            "Epoch #0. Batch Id 71/278  is having validation accuracy of 81.90104166666667\n",
            "Epoch #0. Batch Id 72/278  is having validation loss of 0.7032307982444763\n",
            "0.521078884601593\n",
            "Epoch #0. Batch Id 72/278  is having validation accuracy of 82.02054794520548\n",
            "Epoch #0. Batch Id 73/278  is having validation loss of 0.7032495141029358\n",
            "0.704616367816925\n",
            "Epoch #0. Batch Id 73/278  is having validation accuracy of 82.01013513513513\n",
            "Epoch #0. Batch Id 74/278  is having validation loss of 0.7054216861724854\n",
            "0.8661614656448364\n",
            "Epoch #0. Batch Id 74/278  is having validation accuracy of 81.91666666666667\n",
            "Epoch #0. Batch Id 75/278  is having validation loss of 0.7124864459037781\n",
            "1.2423431873321533\n",
            "Epoch #0. Batch Id 75/278  is having validation accuracy of 81.82565789473684\n",
            "Epoch #0. Batch Id 76/278  is having validation loss of 0.711193859577179\n",
            "0.6129576563835144\n",
            "Epoch #0. Batch Id 76/278  is having validation accuracy of 81.89935064935065\n",
            "Epoch #0. Batch Id 77/278  is having validation loss of 0.7105274796485901\n",
            "0.6592169404029846\n",
            "Epoch #0. Batch Id 77/278  is having validation accuracy of 81.89102564102564\n",
            "Epoch #0. Batch Id 78/278  is having validation loss of 0.7096529603004456\n",
            "0.6414400935173035\n",
            "Epoch #0. Batch Id 78/278  is having validation accuracy of 81.9620253164557\n",
            "Epoch #0. Batch Id 79/278  is having validation loss of 0.7073503136634827\n",
            "0.5254403352737427\n",
            "Epoch #0. Batch Id 79/278  is having validation accuracy of 81.9921875\n",
            "Epoch #0. Batch Id 80/278  is having validation loss of 0.7085927128791809\n",
            "0.8079854249954224\n",
            "Epoch #0. Batch Id 80/278  is having validation accuracy of 81.90586419753086\n",
            "Epoch #0. Batch Id 81/278  is having validation loss of 0.7086219191551208\n",
            "0.7109898328781128\n",
            "Epoch #0. Batch Id 81/278  is having validation accuracy of 81.89786585365853\n",
            "Epoch #0. Batch Id 82/278  is having validation loss of 0.7126575708389282\n",
            "1.0435791015625\n",
            "Epoch #0. Batch Id 82/278  is having validation accuracy of 81.77710843373494\n",
            "Epoch #0. Batch Id 83/278  is having validation loss of 0.7103894948959351\n",
            "0.522140622138977\n",
            "Epoch #0. Batch Id 83/278  is having validation accuracy of 81.8452380952381\n",
            "Epoch #0. Batch Id 84/278  is having validation loss of 0.7118765711784363\n",
            "0.8367887139320374\n",
            "Epoch #0. Batch Id 84/278  is having validation accuracy of 81.80147058823529\n",
            "Epoch #0. Batch Id 85/278  is having validation loss of 0.7119348049163818\n",
            "0.7168828248977661\n",
            "Epoch #0. Batch Id 85/278  is having validation accuracy of 81.79505813953489\n",
            "Epoch #0. Batch Id 86/278  is having validation loss of 0.7117754817008972\n",
            "0.6980748772621155\n",
            "Epoch #0. Batch Id 86/278  is having validation accuracy of 81.75287356321839\n",
            "Epoch #0. Batch Id 87/278  is having validation loss of 0.7102994322776794\n",
            "0.5818846821784973\n",
            "Epoch #0. Batch Id 87/278  is having validation accuracy of 81.81818181818181\n",
            "Epoch #0. Batch Id 88/278  is having validation loss of 0.7104139924049377\n",
            "0.7204976677894592\n",
            "Epoch #0. Batch Id 88/278  is having validation accuracy of 81.81179775280899\n",
            "Epoch #0. Batch Id 89/278  is having validation loss of 0.7081582546234131\n",
            "0.5073977112770081\n",
            "Epoch #0. Batch Id 89/278  is having validation accuracy of 81.90972222222223\n",
            "Epoch #0. Batch Id 90/278  is having validation loss of 0.7078185081481934\n",
            "0.6772417426109314\n",
            "Epoch #0. Batch Id 90/278  is having validation accuracy of 81.90247252747253\n",
            "Epoch #0. Batch Id 91/278  is having validation loss of 0.7088397741317749\n",
            "0.8017724752426147\n",
            "Epoch #0. Batch Id 91/278  is having validation accuracy of 81.89538043478261\n",
            "Epoch #0. Batch Id 92/278  is having validation loss of 0.70719975233078\n",
            "0.556318998336792\n",
            "Epoch #0. Batch Id 92/278  is having validation accuracy of 81.95564516129032\n",
            "Epoch #0. Batch Id 93/278  is having validation loss of 0.7051013112068176\n",
            "0.5099486112594604\n",
            "Epoch #0. Batch Id 93/278  is having validation accuracy of 82.0811170212766\n",
            "Epoch #0. Batch Id 94/278  is having validation loss of 0.7037107944488525\n",
            "0.5730002522468567\n",
            "Epoch #0. Batch Id 94/278  is having validation accuracy of 82.07236842105263\n",
            "Epoch #0. Batch Id 95/278  is having validation loss of 0.7084140777587891\n",
            "1.1552250385284424\n",
            "Epoch #0. Batch Id 95/278  is having validation accuracy of 81.96614583333333\n",
            "Epoch #0. Batch Id 96/278  is having validation loss of 0.710528552532196\n",
            "0.9135205745697021\n",
            "Epoch #0. Batch Id 96/278  is having validation accuracy of 81.86211340206185\n",
            "Epoch #0. Batch Id 97/278  is having validation loss of 0.7125011086463928\n",
            "0.9038384556770325\n",
            "Epoch #0. Batch Id 97/278  is having validation accuracy of 81.85586734693878\n",
            "Epoch #0. Batch Id 98/278  is having validation loss of 0.7113102078437805\n",
            "0.5946010947227478\n",
            "Epoch #0. Batch Id 98/278  is having validation accuracy of 81.91287878787878\n",
            "Epoch #0. Batch Id 99/278  is having validation loss of 0.7130173444747925\n",
            "0.8820222020149231\n",
            "Epoch #0. Batch Id 99/278  is having validation accuracy of 81.875\n",
            "Epoch #0. Batch Id 100/278  is having validation loss of 0.7107135653495789\n",
            "0.480336457490921\n",
            "Epoch #0. Batch Id 100/278  is having validation accuracy of 81.93069306930693\n",
            "Epoch #0. Batch Id 101/278  is having validation loss of 0.7090193629264832\n",
            "0.5379024744033813\n",
            "Epoch #0. Batch Id 101/278  is having validation accuracy of 81.92401960784314\n",
            "Epoch #0. Batch Id 102/278  is having validation loss of 0.7098751664161682\n",
            "0.797170102596283\n",
            "Epoch #0. Batch Id 102/278  is having validation accuracy of 81.85679611650485\n",
            "Epoch #0. Batch Id 103/278  is having validation loss of 0.7104071378707886\n",
            "0.7651984691619873\n",
            "Epoch #0. Batch Id 103/278  is having validation accuracy of 81.85096153846153\n",
            "Epoch #0. Batch Id 104/278  is having validation loss of 0.7103983163833618\n",
            "0.7094798684120178\n",
            "Epoch #0. Batch Id 104/278  is having validation accuracy of 81.9047619047619\n",
            "Epoch #0. Batch Id 105/278  is having validation loss of 0.710777997970581\n",
            "0.7506470680236816\n",
            "Epoch #0. Batch Id 105/278  is having validation accuracy of 81.89858490566037\n",
            "Epoch #0. Batch Id 106/278  is having validation loss of 0.710283637046814\n",
            "0.6578816175460815\n",
            "Epoch #0. Batch Id 106/278  is having validation accuracy of 81.89252336448598\n",
            "Epoch #0. Batch Id 107/278  is having validation loss of 0.7094264030456543\n",
            "0.6177016496658325\n",
            "Epoch #0. Batch Id 107/278  is having validation accuracy of 81.91550925925925\n",
            "Epoch #0. Batch Id 108/278  is having validation loss of 0.7110508680343628\n",
            "0.886493444442749\n",
            "Epoch #0. Batch Id 108/278  is having validation accuracy of 81.7947247706422\n",
            "Epoch #0. Batch Id 109/278  is having validation loss of 0.7109147906303406\n",
            "0.6960854530334473\n",
            "Epoch #0. Batch Id 109/278  is having validation accuracy of 81.78977272727273\n",
            "Epoch #0. Batch Id 110/278  is having validation loss of 0.7101758122444153\n",
            "0.6288898587226868\n",
            "Epoch #0. Batch Id 110/278  is having validation accuracy of 81.81306306306307\n",
            "Epoch #0. Batch Id 111/278  is having validation loss of 0.7090787291526794\n",
            "0.5873041152954102\n",
            "Epoch #0. Batch Id 111/278  is having validation accuracy of 81.80803571428571\n",
            "Epoch #0. Batch Id 112/278  is having validation loss of 0.7137578725814819\n",
            "1.2378236055374146\n",
            "Epoch #0. Batch Id 112/278  is having validation accuracy of 81.66482300884955\n",
            "Epoch #0. Batch Id 113/278  is having validation loss of 0.7129603624343872\n",
            "0.6228429675102234\n",
            "Epoch #0. Batch Id 113/278  is having validation accuracy of 81.71600877192982\n",
            "Epoch #0. Batch Id 114/278  is having validation loss of 0.7125551700592041\n",
            "0.6663598418235779\n",
            "Epoch #0. Batch Id 114/278  is having validation accuracy of 81.68478260869566\n",
            "Epoch #0. Batch Id 115/278  is having validation loss of 0.7131568193435669\n",
            "0.7823497653007507\n",
            "Epoch #0. Batch Id 115/278  is having validation accuracy of 81.6540948275862\n",
            "Epoch #0. Batch Id 116/278  is having validation loss of 0.7144729495048523\n",
            "0.8671466112136841\n",
            "Epoch #0. Batch Id 116/278  is having validation accuracy of 81.62393162393163\n",
            "Epoch #0. Batch Id 117/278  is having validation loss of 0.7133100628852844\n",
            "0.5772498846054077\n",
            "Epoch #0. Batch Id 117/278  is having validation accuracy of 81.67372881355932\n",
            "Epoch #0. Batch Id 118/278  is having validation loss of 0.7131257057189941\n",
            "0.6913712024688721\n",
            "Epoch #0. Batch Id 118/278  is having validation accuracy of 81.69642857142857\n",
            "Epoch #0. Batch Id 119/278  is having validation loss of 0.7128692269325256\n",
            "0.682348370552063\n",
            "Epoch #0. Batch Id 119/278  is having validation accuracy of 81.71875\n",
            "Epoch #0. Batch Id 120/278  is having validation loss of 0.7132843732833862\n",
            "0.7631018161773682\n",
            "Epoch #0. Batch Id 120/278  is having validation accuracy of 81.79235537190083\n",
            "Epoch #0. Batch Id 121/278  is having validation loss of 0.7149041891098022\n",
            "0.9109000563621521\n",
            "Epoch #0. Batch Id 121/278  is having validation accuracy of 81.7110655737705\n",
            "Epoch #0. Batch Id 122/278  is having validation loss of 0.7151538729667664\n",
            "0.7456172704696655\n",
            "Epoch #0. Batch Id 122/278  is having validation accuracy of 81.6819105691057\n",
            "Epoch #0. Batch Id 123/278  is having validation loss of 0.7157888412475586\n",
            "0.7938908338546753\n",
            "Epoch #0. Batch Id 123/278  is having validation accuracy of 81.67842741935483\n",
            "Epoch #0. Batch Id 124/278  is having validation loss of 0.7153980731964111\n",
            "0.6669405698776245\n",
            "Epoch #0. Batch Id 124/278  is having validation accuracy of 81.725\n",
            "Epoch #0. Batch Id 125/278  is having validation loss of 0.7172988653182983\n",
            "0.9548963904380798\n",
            "Epoch #0. Batch Id 125/278  is having validation accuracy of 81.67162698412699\n",
            "Epoch #0. Batch Id 126/278  is having validation loss of 0.7172826528549194\n",
            "0.7152372002601624\n",
            "Epoch #0. Batch Id 126/278  is having validation accuracy of 81.66830708661418\n",
            "Epoch #0. Batch Id 127/278  is having validation loss of 0.7169837951660156\n",
            "0.6790285110473633\n",
            "Epoch #0. Batch Id 127/278  is having validation accuracy of 81.7138671875\n",
            "Epoch #0. Batch Id 128/278  is having validation loss of 0.7162862420082092\n",
            "0.6269980072975159\n",
            "Epoch #0. Batch Id 128/278  is having validation accuracy of 81.68604651162791\n",
            "Epoch #0. Batch Id 129/278  is having validation loss of 0.7175759077072144\n",
            "0.8839407563209534\n",
            "Epoch #0. Batch Id 129/278  is having validation accuracy of 81.63461538461539\n",
            "Epoch #0. Batch Id 130/278  is having validation loss of 0.7161656618118286\n",
            "0.5328340530395508\n",
            "Epoch #0. Batch Id 130/278  is having validation accuracy of 81.63167938931298\n",
            "Epoch #0. Batch Id 131/278  is having validation loss of 0.7155401706695557\n",
            "0.6335998773574829\n",
            "Epoch #0. Batch Id 131/278  is having validation accuracy of 81.65246212121212\n",
            "Epoch #0. Batch Id 132/278  is having validation loss of 0.7148023843765259\n",
            "0.6174157857894897\n",
            "Epoch #0. Batch Id 132/278  is having validation accuracy of 81.64943609022556\n",
            "Epoch #0. Batch Id 133/278  is having validation loss of 0.7144156098365784\n",
            "0.6629752516746521\n",
            "Epoch #0. Batch Id 133/278  is having validation accuracy of 81.66977611940298\n",
            "Epoch #0. Batch Id 134/278  is having validation loss of 0.7171199917793274\n",
            "1.07950758934021\n",
            "Epoch #0. Batch Id 134/278  is having validation accuracy of 81.57407407407408\n",
            "Epoch #0. Batch Id 135/278  is having validation loss of 0.7199680209159851\n",
            "1.1044483184814453\n",
            "Epoch #0. Batch Id 135/278  is having validation accuracy of 81.52573529411765\n",
            "Epoch #0. Batch Id 136/278  is having validation loss of 0.7204352021217346\n",
            "0.783970832824707\n",
            "Epoch #0. Batch Id 136/278  is having validation accuracy of 81.50091240875912\n",
            "Epoch #0. Batch Id 137/278  is having validation loss of 0.7216041088104248\n",
            "0.8817435503005981\n",
            "Epoch #0. Batch Id 137/278  is having validation accuracy of 81.47644927536231\n",
            "Epoch #0. Batch Id 138/278  is having validation loss of 0.7203319072723389\n",
            "0.5447668433189392\n",
            "Epoch #0. Batch Id 138/278  is having validation accuracy of 81.54226618705036\n",
            "Epoch #0. Batch Id 139/278  is having validation loss of 0.7198615670204163\n",
            "0.6544845700263977\n",
            "Epoch #0. Batch Id 139/278  is having validation accuracy of 81.5625\n",
            "Epoch #0. Batch Id 140/278  is having validation loss of 0.7216483950614929\n",
            "0.9718044996261597\n",
            "Epoch #0. Batch Id 140/278  is having validation accuracy of 81.47163120567376\n",
            "Epoch #0. Batch Id 141/278  is having validation loss of 0.7211658954620361\n",
            "0.6531330943107605\n",
            "Epoch #0. Batch Id 141/278  is having validation accuracy of 81.49207746478874\n",
            "Epoch #0. Batch Id 142/278  is having validation loss of 0.7220699191093445\n",
            "0.8504412174224854\n",
            "Epoch #0. Batch Id 142/278  is having validation accuracy of 81.40297202797203\n",
            "Epoch #0. Batch Id 143/278  is having validation loss of 0.724157989025116\n",
            "1.0227550268173218\n",
            "Epoch #0. Batch Id 143/278  is having validation accuracy of 81.35850694444444\n",
            "Epoch #0. Batch Id 144/278  is having validation loss of 0.7222282290458679\n",
            "0.44434118270874023\n",
            "Epoch #0. Batch Id 144/278  is having validation accuracy of 81.42241379310344\n",
            "Epoch #0. Batch Id 145/278  is having validation loss of 0.7226583361625671\n",
            "0.7850278615951538\n",
            "Epoch #0. Batch Id 145/278  is having validation accuracy of 81.42123287671232\n",
            "Epoch #0. Batch Id 146/278  is having validation loss of 0.7227610945701599\n",
            "0.7377656102180481\n",
            "Epoch #0. Batch Id 146/278  is having validation accuracy of 81.44132653061224\n",
            "Epoch #0. Batch Id 147/278  is having validation loss of 0.7240416407585144\n",
            "0.9122804403305054\n",
            "Epoch #0. Batch Id 147/278  is having validation accuracy of 81.44003378378379\n",
            "Epoch #0. Batch Id 148/278  is having validation loss of 0.7242946624755859\n",
            "0.7617397904396057\n",
            "Epoch #0. Batch Id 148/278  is having validation accuracy of 81.41778523489933\n",
            "Epoch #0. Batch Id 149/278  is having validation loss of 0.7222344875335693\n",
            "0.41526487469673157\n",
            "Epoch #0. Batch Id 149/278  is having validation accuracy of 81.45833333333333\n",
            "Epoch #0. Batch Id 150/278  is having validation loss of 0.7240488529205322\n",
            "0.9962069988250732\n",
            "Epoch #0. Batch Id 150/278  is having validation accuracy of 81.37417218543047\n",
            "Epoch #0. Batch Id 151/278  is having validation loss of 0.7254543900489807\n",
            "0.9376916289329529\n",
            "Epoch #0. Batch Id 151/278  is having validation accuracy of 81.35279605263158\n",
            "Epoch #0. Batch Id 152/278  is having validation loss of 0.7266111373901367\n",
            "0.9024351239204407\n",
            "Epoch #0. Batch Id 152/278  is having validation accuracy of 81.33169934640523\n",
            "Epoch #0. Batch Id 153/278  is having validation loss of 0.7257846593856812\n",
            "0.5993320345878601\n",
            "Epoch #0. Batch Id 153/278  is having validation accuracy of 81.37175324675324\n",
            "Epoch #0. Batch Id 154/278  is having validation loss of 0.727279007434845\n",
            "0.957408607006073\n",
            "Epoch #0. Batch Id 154/278  is having validation accuracy of 81.37096774193549\n",
            "Epoch #0. Batch Id 155/278  is having validation loss of 0.724905788898468\n",
            "0.35705992579460144\n",
            "Epoch #0. Batch Id 155/278  is having validation accuracy of 81.41025641025641\n",
            "Epoch #0. Batch Id 156/278  is having validation loss of 0.7286532521247864\n",
            "1.313260793685913\n",
            "Epoch #0. Batch Id 156/278  is having validation accuracy of 81.26990445859873\n",
            "Epoch #0. Batch Id 157/278  is having validation loss of 0.7299844026565552\n",
            "0.9389724135398865\n",
            "Epoch #0. Batch Id 157/278  is having validation accuracy of 81.21044303797468\n",
            "Epoch #0. Batch Id 158/278  is having validation loss of 0.7280262112617493\n",
            "0.418633371591568\n",
            "Epoch #0. Batch Id 158/278  is having validation accuracy of 81.25\n",
            "Epoch #0. Batch Id 159/278  is having validation loss of 0.7288705706596375\n",
            "0.8631226420402527\n",
            "Epoch #0. Batch Id 159/278  is having validation accuracy of 81.23046875\n",
            "Epoch #0. Batch Id 160/278  is having validation loss of 0.7316336035728455\n",
            "1.173722743988037\n",
            "Epoch #0. Batch Id 160/278  is having validation accuracy of 81.152950310559\n",
            "Epoch #0. Batch Id 161/278  is having validation loss of 0.7306475639343262\n",
            "0.5718935132026672\n",
            "Epoch #0. Batch Id 161/278  is having validation accuracy of 81.17283950617283\n",
            "Epoch #0. Batch Id 162/278  is having validation loss of 0.730470597743988\n",
            "0.7018009424209595\n",
            "Epoch #0. Batch Id 162/278  is having validation accuracy of 81.19248466257669\n",
            "Epoch #0. Batch Id 163/278  is having validation loss of 0.7307361364364624\n",
            "0.7740208506584167\n",
            "Epoch #0. Batch Id 163/278  is having validation accuracy of 81.17378048780488\n",
            "Epoch #0. Batch Id 164/278  is having validation loss of 0.730749249458313\n",
            "0.7329014539718628\n",
            "Epoch #0. Batch Id 164/278  is having validation accuracy of 81.19318181818181\n",
            "Epoch #0. Batch Id 165/278  is having validation loss of 0.7295440435409546\n",
            "0.5306851267814636\n",
            "Epoch #0. Batch Id 165/278  is having validation accuracy of 81.23117469879519\n",
            "Epoch #0. Batch Id 166/278  is having validation loss of 0.7279375195503235\n",
            "0.46125510334968567\n",
            "Epoch #0. Batch Id 166/278  is having validation accuracy of 81.2687125748503\n",
            "Epoch #0. Batch Id 167/278  is having validation loss of 0.7281774282455444\n",
            "0.7682395577430725\n",
            "Epoch #0. Batch Id 167/278  is having validation accuracy of 81.30580357142857\n",
            "Epoch #0. Batch Id 168/278  is having validation loss of 0.7249833941459656\n",
            "0.18838460743427277\n",
            "Epoch #0. Batch Id 168/278  is having validation accuracy of 81.37943786982248\n",
            "Epoch #0. Batch Id 169/278  is having validation loss of 0.7232108116149902\n",
            "0.42364341020584106\n",
            "Epoch #0. Batch Id 169/278  is having validation accuracy of 81.4154411764706\n",
            "Epoch #0. Batch Id 170/278  is having validation loss of 0.7235320210456848\n",
            "0.7781379222869873\n",
            "Epoch #0. Batch Id 170/278  is having validation accuracy of 81.37792397660819\n",
            "Epoch #0. Batch Id 171/278  is having validation loss of 0.7249038815498352\n",
            "0.9594968557357788\n",
            "Epoch #0. Batch Id 171/278  is having validation accuracy of 81.34084302325581\n",
            "Epoch #0. Batch Id 172/278  is having validation loss of 0.7236570715904236\n",
            "0.5092015862464905\n",
            "Epoch #0. Batch Id 172/278  is having validation accuracy of 81.35838150289017\n",
            "Epoch #0. Batch Id 173/278  is having validation loss of 0.7239086031913757\n",
            "0.7674267888069153\n",
            "Epoch #0. Batch Id 173/278  is having validation accuracy of 81.3757183908046\n",
            "Epoch #0. Batch Id 174/278  is having validation loss of 0.7245123982429504\n",
            "0.8295689821243286\n",
            "Epoch #0. Batch Id 174/278  is having validation accuracy of 81.33928571428571\n",
            "Epoch #0. Batch Id 175/278  is having validation loss of 0.7249213457107544\n",
            "0.7964875102043152\n",
            "Epoch #0. Batch Id 175/278  is having validation accuracy of 81.3565340909091\n",
            "Epoch #0. Batch Id 176/278  is having validation loss of 0.7237328290939331\n",
            "0.514549970626831\n",
            "Epoch #0. Batch Id 176/278  is having validation accuracy of 81.39124293785311\n",
            "Epoch #0. Batch Id 177/278  is having validation loss of 0.7220797538757324\n",
            "0.4294840693473816\n",
            "Epoch #0. Batch Id 177/278  is having validation accuracy of 81.4255617977528\n",
            "Epoch #0. Batch Id 178/278  is having validation loss of 0.7227001786231995\n",
            "0.8331382274627686\n",
            "Epoch #0. Batch Id 178/278  is having validation accuracy of 81.38966480446928\n",
            "Epoch #0. Batch Id 179/278  is having validation loss of 0.724706768989563\n",
            "1.0838838815689087\n",
            "Epoch #0. Batch Id 179/278  is having validation accuracy of 81.35416666666667\n",
            "Epoch #0. Batch Id 180/278  is having validation loss of 0.7259232401847839\n",
            "0.9448860883712769\n",
            "Epoch #0. Batch Id 180/278  is having validation accuracy of 81.31906077348066\n",
            "Epoch #0. Batch Id 181/278  is having validation loss of 0.7254266738891602\n",
            "0.6355531811714172\n",
            "Epoch #0. Batch Id 181/278  is having validation accuracy of 81.31868131868131\n",
            "Epoch #0. Batch Id 182/278  is having validation loss of 0.7261377573013306\n",
            "0.8555516004562378\n",
            "Epoch #0. Batch Id 182/278  is having validation accuracy of 81.26707650273224\n",
            "Epoch #0. Batch Id 183/278  is having validation loss of 0.7257675528526306\n",
            "0.6580172181129456\n",
            "Epoch #0. Batch Id 183/278  is having validation accuracy of 81.30095108695652\n",
            "Epoch #0. Batch Id 184/278  is having validation loss of 0.7244366407394409\n",
            "0.4795474112033844\n",
            "Epoch #0. Batch Id 184/278  is having validation accuracy of 81.36824324324324\n",
            "Epoch #0. Batch Id 185/278  is having validation loss of 0.7239325642585754\n",
            "0.6306753158569336\n",
            "Epoch #0. Batch Id 185/278  is having validation accuracy of 81.36760752688173\n",
            "Epoch #0. Batch Id 186/278  is having validation loss of 0.7248627543449402\n",
            "0.897879958152771\n",
            "Epoch #0. Batch Id 186/278  is having validation accuracy of 81.31684491978609\n",
            "Epoch #0. Batch Id 187/278  is having validation loss of 0.725480318069458\n",
            "0.8409613370895386\n",
            "Epoch #0. Batch Id 187/278  is having validation accuracy of 81.28324468085107\n",
            "Epoch #0. Batch Id 188/278  is having validation loss of 0.727427065372467\n",
            "1.0934165716171265\n",
            "Epoch #0. Batch Id 188/278  is having validation accuracy of 81.23346560846561\n",
            "Epoch #0. Batch Id 189/278  is having validation loss of 0.72758948802948\n",
            "0.7582909464836121\n",
            "Epoch #0. Batch Id 189/278  is having validation accuracy of 81.21710526315789\n",
            "Epoch #0. Batch Id 190/278  is having validation loss of 0.7265991568565369\n",
            "0.5384381413459778\n",
            "Epoch #0. Batch Id 190/278  is having validation accuracy of 81.25\n",
            "Epoch #0. Batch Id 191/278  is having validation loss of 0.7283853888511658\n",
            "1.0695507526397705\n",
            "Epoch #0. Batch Id 191/278  is having validation accuracy of 81.23372395833333\n",
            "Epoch #0. Batch Id 192/278  is having validation loss of 0.7284849286079407\n",
            "0.7475913763046265\n",
            "Epoch #0. Batch Id 192/278  is having validation accuracy of 81.20142487046633\n",
            "Epoch #0. Batch Id 193/278  is having validation loss of 0.7295017838478088\n",
            "0.9257557392120361\n",
            "Epoch #0. Batch Id 193/278  is having validation accuracy of 81.18556701030928\n",
            "Epoch #0. Batch Id 194/278  is having validation loss of 0.7297695875167847\n",
            "0.7817260026931763\n",
            "Epoch #0. Batch Id 194/278  is having validation accuracy of 81.1698717948718\n",
            "Epoch #0. Batch Id 195/278  is having validation loss of 0.730118453502655\n",
            "0.7981433272361755\n",
            "Epoch #0. Batch Id 195/278  is having validation accuracy of 81.13839285714286\n",
            "Epoch #0. Batch Id 196/278  is having validation loss of 0.7304514646530151\n",
            "0.7957198619842529\n",
            "Epoch #0. Batch Id 196/278  is having validation accuracy of 81.10723350253807\n",
            "Epoch #0. Batch Id 197/278  is having validation loss of 0.7307325601577759\n",
            "0.7861056327819824\n",
            "Epoch #0. Batch Id 197/278  is having validation accuracy of 81.12373737373737\n",
            "Epoch #0. Batch Id 198/278  is having validation loss of 0.7328471541404724\n",
            "1.1515334844589233\n",
            "Epoch #0. Batch Id 198/278  is having validation accuracy of 81.0929648241206\n",
            "Epoch #0. Batch Id 199/278  is having validation loss of 0.7322428822517395\n",
            "0.611987292766571\n",
            "Epoch #0. Batch Id 199/278  is having validation accuracy of 81.078125\n",
            "Epoch #0. Batch Id 200/278  is having validation loss of 0.7318440079689026\n",
            "0.6520748734474182\n",
            "Epoch #0. Batch Id 200/278  is having validation accuracy of 81.07898009950249\n",
            "Epoch #0. Batch Id 201/278  is having validation loss of 0.7329882383346558\n",
            "0.9629841446876526\n",
            "Epoch #0. Batch Id 201/278  is having validation accuracy of 81.03341584158416\n",
            "Epoch #0. Batch Id 202/278  is having validation loss of 0.7323291897773743\n",
            "0.5991954207420349\n",
            "Epoch #0. Batch Id 202/278  is having validation accuracy of 81.00369458128078\n",
            "Epoch #0. Batch Id 203/278  is having validation loss of 0.732422947883606\n",
            "0.7514525651931763\n",
            "Epoch #0. Batch Id 203/278  is having validation accuracy of 80.97426470588235\n",
            "Epoch #0. Batch Id 204/278  is having validation loss of 0.7322799563407898\n",
            "0.7031073570251465\n",
            "Epoch #0. Batch Id 204/278  is having validation accuracy of 80.99085365853658\n",
            "Epoch #0. Batch Id 205/278  is having validation loss of 0.7311291098594666\n",
            "0.4952091574668884\n",
            "Epoch #0. Batch Id 205/278  is having validation accuracy of 81.0376213592233\n",
            "Epoch #0. Batch Id 206/278  is having validation loss of 0.7300512194633484\n",
            "0.508008599281311\n",
            "Epoch #0. Batch Id 206/278  is having validation accuracy of 81.09903381642512\n",
            "Epoch #0. Batch Id 207/278  is having validation loss of 0.7296122908592224\n",
            "0.6387507319450378\n",
            "Epoch #0. Batch Id 207/278  is having validation accuracy of 81.08473557692308\n",
            "Epoch #0. Batch Id 208/278  is having validation loss of 0.7299559116363525\n",
            "0.8014280796051025\n",
            "Epoch #0. Batch Id 208/278  is having validation accuracy of 81.07057416267942\n",
            "Epoch #0. Batch Id 209/278  is having validation loss of 0.7290006875991821\n",
            "0.5293643474578857\n",
            "Epoch #0. Batch Id 209/278  is having validation accuracy of 81.07142857142857\n",
            "Epoch #0. Batch Id 210/278  is having validation loss of 0.7315386533737183\n",
            "1.264512538909912\n",
            "Epoch #0. Batch Id 210/278  is having validation accuracy of 81.01303317535545\n",
            "Epoch #0. Batch Id 211/278  is having validation loss of 0.7308206558227539\n",
            "0.5793284773826599\n",
            "Epoch #0. Batch Id 211/278  is having validation accuracy of 81.01415094339623\n",
            "Epoch #0. Batch Id 212/278  is having validation loss of 0.732698917388916\n",
            "1.130889654159546\n",
            "Epoch #0. Batch Id 212/278  is having validation accuracy of 80.98591549295774\n",
            "Epoch #0. Batch Id 213/278  is having validation loss of 0.7338831424713135\n",
            "0.9861189126968384\n",
            "Epoch #0. Batch Id 213/278  is having validation accuracy of 80.89953271028037\n",
            "Epoch #0. Batch Id 214/278  is having validation loss of 0.7335444688796997\n",
            "0.6610723733901978\n",
            "Epoch #0. Batch Id 214/278  is having validation accuracy of 80.93023255813954\n",
            "Epoch #0. Batch Id 215/278  is having validation loss of 0.733466625213623\n",
            "0.7167301774024963\n",
            "Epoch #0. Batch Id 215/278  is having validation accuracy of 80.93171296296296\n",
            "Epoch #0. Batch Id 216/278  is having validation loss of 0.7337947487831116\n",
            "0.8046669960021973\n",
            "Epoch #0. Batch Id 216/278  is having validation accuracy of 80.91877880184332\n",
            "Epoch #0. Batch Id 217/278  is having validation loss of 0.7348990440368652\n",
            "0.9745263457298279\n",
            "Epoch #0. Batch Id 217/278  is having validation accuracy of 80.86295871559633\n",
            "Epoch #0. Batch Id 218/278  is having validation loss of 0.7357102632522583\n",
            "0.9125511646270752\n",
            "Epoch #0. Batch Id 218/278  is having validation accuracy of 80.85045662100457\n",
            "Epoch #0. Batch Id 219/278  is having validation loss of 0.7358912229537964\n",
            "0.7755275964736938\n",
            "Epoch #0. Batch Id 219/278  is having validation accuracy of 80.83806818181819\n",
            "Epoch #0. Batch Id 220/278  is having validation loss of 0.735534131526947\n",
            "0.6569727063179016\n",
            "Epoch #0. Batch Id 220/278  is having validation accuracy of 80.83993212669684\n",
            "Epoch #0. Batch Id 221/278  is having validation loss of 0.7350965738296509\n",
            "0.638401985168457\n",
            "Epoch #0. Batch Id 221/278  is having validation accuracy of 80.86993243243244\n",
            "Epoch #0. Batch Id 222/278  is having validation loss of 0.7354969382286072\n",
            "0.8243748545646667\n",
            "Epoch #0. Batch Id 222/278  is having validation accuracy of 80.84360986547085\n",
            "Epoch #0. Batch Id 223/278  is having validation loss of 0.7356314659118652\n",
            "0.7656300067901611\n",
            "Epoch #0. Batch Id 223/278  is having validation accuracy of 80.84542410714286\n",
            "Epoch #0. Batch Id 224/278  is having validation loss of 0.736254096031189\n",
            "0.8757166862487793\n",
            "Epoch #0. Batch Id 224/278  is having validation accuracy of 80.84722222222223\n",
            "Epoch #0. Batch Id 225/278  is having validation loss of 0.735959529876709\n",
            "0.6696884632110596\n",
            "Epoch #0. Batch Id 225/278  is having validation accuracy of 80.89048672566372\n",
            "Epoch #0. Batch Id 226/278  is having validation loss of 0.7356007695198059\n",
            "0.6545165181159973\n",
            "Epoch #0. Batch Id 226/278  is having validation accuracy of 80.91960352422907\n",
            "Epoch #0. Batch Id 227/278  is having validation loss of 0.7354757189750671\n",
            "0.7070891261100769\n",
            "Epoch #0. Batch Id 227/278  is having validation accuracy of 80.92105263157895\n",
            "Epoch #0. Batch Id 228/278  is having validation loss of 0.7353183031082153\n",
            "0.6994247436523438\n",
            "Epoch #0. Batch Id 228/278  is having validation accuracy of 80.93613537117903\n",
            "Epoch #0. Batch Id 229/278  is having validation loss of 0.7375025749206543\n",
            "1.2376983165740967\n",
            "Epoch #0. Batch Id 229/278  is having validation accuracy of 80.88315217391305\n",
            "Epoch #0. Batch Id 230/278  is having validation loss of 0.7374423742294312\n",
            "0.7236011624336243\n",
            "Epoch #0. Batch Id 230/278  is having validation accuracy of 80.88474025974025\n",
            "Epoch #0. Batch Id 231/278  is having validation loss of 0.736627995967865\n",
            "0.5485056638717651\n",
            "Epoch #0. Batch Id 231/278  is having validation accuracy of 80.89978448275862\n",
            "Epoch #0. Batch Id 232/278  is having validation loss of 0.7369069457054138\n",
            "0.8016297817230225\n",
            "Epoch #0. Batch Id 232/278  is having validation accuracy of 80.88787553648069\n",
            "Epoch #0. Batch Id 233/278  is having validation loss of 0.7364691495895386\n",
            "0.6344631314277649\n",
            "Epoch #0. Batch Id 233/278  is having validation accuracy of 80.90277777777777\n",
            "Epoch #0. Batch Id 234/278  is having validation loss of 0.7358112931251526\n",
            "0.5818673372268677\n",
            "Epoch #0. Batch Id 234/278  is having validation accuracy of 80.94414893617021\n",
            "Epoch #0. Batch Id 235/278  is having validation loss of 0.7353609204292297\n",
            "0.6295233964920044\n",
            "Epoch #0. Batch Id 235/278  is having validation accuracy of 80.94544491525424\n",
            "Epoch #0. Batch Id 236/278  is having validation loss of 0.7353116869926453\n",
            "0.7236872315406799\n",
            "Epoch #0. Batch Id 236/278  is having validation accuracy of 80.93354430379746\n",
            "Epoch #0. Batch Id 237/278  is having validation loss of 0.7348663210868835\n",
            "0.629308819770813\n",
            "Epoch #0. Batch Id 237/278  is having validation accuracy of 80.92174369747899\n",
            "Epoch #0. Batch Id 238/278  is having validation loss of 0.7361705303192139\n",
            "1.0465760231018066\n",
            "Epoch #0. Batch Id 238/278  is having validation accuracy of 80.88389121338912\n",
            "Epoch #0. Batch Id 239/278  is having validation loss of 0.7341446876525879\n",
            "0.24997171759605408\n",
            "Epoch #0. Batch Id 239/278  is having validation accuracy of 80.95052083333333\n",
            "Epoch #0. Batch Id 240/278  is having validation loss of 0.7346224784851074\n",
            "0.8492865562438965\n",
            "Epoch #0. Batch Id 240/278  is having validation accuracy of 80.91286307053942\n",
            "Epoch #0. Batch Id 241/278  is having validation loss of 0.7348213791847229\n",
            "0.7827529907226562\n",
            "Epoch #0. Batch Id 241/278  is having validation accuracy of 80.9142561983471\n",
            "Epoch #0. Batch Id 242/278  is having validation loss of 0.734056293964386\n",
            "0.548905074596405\n",
            "Epoch #0. Batch Id 242/278  is having validation accuracy of 80.92849794238683\n",
            "Epoch #0. Batch Id 243/278  is having validation loss of 0.7329235672950745\n",
            "0.45767101645469666\n",
            "Epoch #0. Batch Id 243/278  is having validation accuracy of 80.95543032786885\n",
            "Epoch #0. Batch Id 244/278  is having validation loss of 0.7332866787910461\n",
            "0.8218790888786316\n",
            "Epoch #0. Batch Id 244/278  is having validation accuracy of 80.9438775510204\n",
            "Epoch #0. Batch Id 245/278  is having validation loss of 0.7343550324440002\n",
            "0.9961012005805969\n",
            "Epoch #0. Batch Id 245/278  is having validation accuracy of 80.91971544715447\n",
            "Epoch #0. Batch Id 246/278  is having validation loss of 0.7366966605186462\n",
            "1.3127416372299194\n",
            "Epoch #0. Batch Id 246/278  is having validation accuracy of 80.87044534412955\n",
            "Epoch #0. Batch Id 247/278  is having validation loss of 0.7364281415939331\n",
            "0.6701090335845947\n",
            "Epoch #0. Batch Id 247/278  is having validation accuracy of 80.859375\n",
            "Epoch #0. Batch Id 248/278  is having validation loss of 0.7367207407951355\n",
            "0.8092911243438721\n",
            "Epoch #0. Batch Id 248/278  is having validation accuracy of 80.87349397590361\n",
            "Epoch #0. Batch Id 249/278  is having validation loss of 0.7358677983283997\n",
            "0.5234779715538025\n",
            "Epoch #0. Batch Id 249/278  is having validation accuracy of 80.8875\n",
            "Epoch #0. Batch Id 250/278  is having validation loss of 0.7360444068908691\n",
            "0.7801989912986755\n",
            "Epoch #0. Batch Id 250/278  is having validation accuracy of 80.87649402390439\n",
            "Epoch #0. Batch Id 251/278  is having validation loss of 0.7375662326812744\n",
            "1.119543194770813\n",
            "Epoch #0. Batch Id 251/278  is having validation accuracy of 80.84077380952381\n",
            "Epoch #0. Batch Id 252/278  is having validation loss of 0.7372403144836426\n",
            "0.6551157236099243\n",
            "Epoch #0. Batch Id 252/278  is having validation accuracy of 80.85474308300395\n",
            "Epoch #0. Batch Id 253/278  is having validation loss of 0.7393866777420044\n",
            "1.2824124097824097\n",
            "Epoch #0. Batch Id 253/278  is having validation accuracy of 80.79478346456693\n",
            "Epoch #0. Batch Id 254/278  is having validation loss of 0.7395626902580261\n",
            "0.7842630743980408\n",
            "Epoch #0. Batch Id 254/278  is having validation accuracy of 80.7843137254902\n",
            "Epoch #0. Batch Id 255/278  is having validation loss of 0.7384501099586487\n",
            "0.4547494351863861\n",
            "Epoch #0. Batch Id 255/278  is having validation accuracy of 80.79833984375\n",
            "Epoch #0. Batch Id 256/278  is having validation loss of 0.738226592540741\n",
            "0.6810123920440674\n",
            "Epoch #0. Batch Id 256/278  is having validation accuracy of 80.82441634241245\n",
            "Epoch #0. Batch Id 257/278  is having validation loss of 0.7373045086860657\n",
            "0.5003291964530945\n",
            "Epoch #0. Batch Id 257/278  is having validation accuracy of 80.8624031007752\n",
            "Epoch #0. Batch Id 258/278  is having validation loss of 0.7368391752243042\n",
            "0.6167787313461304\n",
            "Epoch #0. Batch Id 258/278  is having validation accuracy of 80.88803088803088\n",
            "Epoch #0. Batch Id 259/278  is having validation loss of 0.7356768250465393\n",
            "0.4346250295639038\n",
            "Epoch #0. Batch Id 259/278  is having validation accuracy of 80.9375\n",
            "Epoch #0. Batch Id 260/278  is having validation loss of 0.7352822422981262\n",
            "0.632692813873291\n",
            "Epoch #0. Batch Id 260/278  is having validation accuracy of 80.93869731800767\n",
            "Epoch #0. Batch Id 261/278  is having validation loss of 0.7350764274597168\n",
            "0.6813617944717407\n",
            "Epoch #0. Batch Id 261/278  is having validation accuracy of 80.93988549618321\n",
            "Epoch #0. Batch Id 262/278  is having validation loss of 0.7352262735366821\n",
            "0.7744935154914856\n",
            "Epoch #0. Batch Id 262/278  is having validation accuracy of 80.94106463878327\n",
            "Epoch #0. Batch Id 263/278  is having validation loss of 0.7353001832962036\n",
            "0.754736065864563\n",
            "Epoch #0. Batch Id 263/278  is having validation accuracy of 80.94223484848484\n",
            "Epoch #0. Batch Id 264/278  is having validation loss of 0.7340614795684814\n",
            "0.4070388376712799\n",
            "Epoch #0. Batch Id 264/278  is having validation accuracy of 80.99056603773585\n",
            "Epoch #0. Batch Id 265/278  is having validation loss of 0.7352295517921448\n",
            "1.044762134552002\n",
            "Epoch #0. Batch Id 265/278  is having validation accuracy of 80.96804511278195\n",
            "Epoch #0. Batch Id 266/278  is having validation loss of 0.735518217086792\n",
            "0.8123098611831665\n",
            "Epoch #0. Batch Id 266/278  is having validation accuracy of 80.98080524344569\n",
            "Epoch #0. Batch Id 267/278  is having validation loss of 0.7346470355987549\n",
            "0.5020432472229004\n",
            "Epoch #0. Batch Id 267/278  is having validation accuracy of 81.01679104477611\n",
            "Epoch #0. Batch Id 268/278  is having validation loss of 0.7340226769447327\n",
            "0.5666921138763428\n",
            "Epoch #0. Batch Id 268/278  is having validation accuracy of 81.04089219330855\n",
            "Epoch #0. Batch Id 269/278  is having validation loss of 0.7325105667114258\n",
            "0.32575589418411255\n",
            "Epoch #0. Batch Id 269/278  is having validation accuracy of 81.08796296296296\n",
            "Epoch #0. Batch Id 270/278  is having validation loss of 0.733104944229126\n",
            "0.8935900926589966\n",
            "Epoch #0. Batch Id 270/278  is having validation accuracy of 81.0770295202952\n",
            "Epoch #0. Batch Id 271/278  is having validation loss of 0.7339442372322083\n",
            "0.9613898396492004\n",
            "Epoch #0. Batch Id 271/278  is having validation accuracy of 81.0546875\n",
            "Epoch #0. Batch Id 272/278  is having validation loss of 0.7344276905059814\n",
            "0.8659332990646362\n",
            "Epoch #0. Batch Id 272/278  is having validation accuracy of 81.03250915750915\n",
            "Epoch #0. Batch Id 273/278  is having validation loss of 0.7353952527046204\n",
            "0.9995346665382385\n",
            "Epoch #0. Batch Id 273/278  is having validation accuracy of 81.04470802919708\n",
            "Epoch #0. Batch Id 274/278  is having validation loss of 0.7350930571556091\n",
            "0.6522958278656006\n",
            "Epoch #0. Batch Id 274/278  is having validation accuracy of 81.06818181818181\n",
            "Epoch #0. Batch Id 275/278  is having validation loss of 0.7348712682723999\n",
            "0.6738867163658142\n",
            "Epoch #0. Batch Id 275/278  is having validation accuracy of 81.08016304347827\n",
            "Epoch #0. Batch Id 276/278  is having validation loss of 0.7347821593284607\n",
            "0.7101836204528809\n",
            "Epoch #0. Batch Id 276/278  is having validation accuracy of 81.0807761732852\n",
            "Epoch #0. Batch Id 277/278  is having validation loss of 0.7326496839523315\n",
            "0.14195750653743744\n",
            "Epoch #0. Batch Id 277/278  is having validation accuracy of 81.0893098782138\n",
            "Эпоха #0 train_loss: 1.2151193004683591e-05, val_loss: 8.261723996838555e-05\n",
            "Потрачено 9.2 минут на 0 эпоху\n",
            "Batch Id 0 is having training loss of 0.9728527069091797\n",
            "0.9728527069091797\n",
            "Epoch #1. Accuracy on batch 0/3013  on Training is 71.875\n",
            "Epoch #1. Accuracy on batch 1/3013  on Training is 79.6875\n",
            "Epoch #1. Accuracy on batch 2/3013  on Training is 80.20833333333333\n",
            "Epoch #1. Accuracy on batch 3/3013  on Training is 80.46875\n",
            "Epoch #1. Accuracy on batch 4/3013  on Training is 82.5\n",
            "Epoch #1. Accuracy on batch 5/3013  on Training is 82.29166666666667\n",
            "Epoch #1. Accuracy on batch 6/3013  on Training is 83.48214285714286\n",
            "Epoch #1. Accuracy on batch 7/3013  on Training is 81.640625\n",
            "Epoch #1. Accuracy on batch 8/3013  on Training is 82.29166666666667\n",
            "Epoch #1. Accuracy on batch 9/3013  on Training is 82.1875\n",
            "Epoch #1. Accuracy on batch 10/3013  on Training is 80.68181818181819\n",
            "Epoch #1. Accuracy on batch 11/3013  on Training is 80.72916666666667\n",
            "Epoch #1. Accuracy on batch 12/3013  on Training is 81.00961538461539\n",
            "Epoch #1. Accuracy on batch 13/3013  on Training is 81.47321428571429\n",
            "Epoch #1. Accuracy on batch 14/3013  on Training is 81.45833333333333\n",
            "Epoch #1. Accuracy on batch 15/3013  on Training is 81.4453125\n",
            "Epoch #1. Accuracy on batch 16/3013  on Training is 81.61764705882354\n",
            "Epoch #1. Accuracy on batch 17/3013  on Training is 82.11805555555556\n",
            "Epoch #1. Accuracy on batch 18/3013  on Training is 82.07236842105263\n",
            "Epoch #1. Accuracy on batch 19/3013  on Training is 82.03125\n",
            "Batch Id 20 is having training loss of 0.6664557456970215\n",
            "0.6409773826599121\n",
            "Epoch #1. Accuracy on batch 20/3013  on Training is 81.8452380952381\n",
            "Epoch #1. Accuracy on batch 21/3013  on Training is 82.24431818181819\n",
            "Epoch #1. Accuracy on batch 22/3013  on Training is 81.65760869565217\n",
            "Epoch #1. Accuracy on batch 23/3013  on Training is 81.90104166666667\n",
            "Epoch #1. Accuracy on batch 24/3013  on Training is 81.5\n",
            "Epoch #1. Accuracy on batch 25/3013  on Training is 81.3701923076923\n",
            "Epoch #1. Accuracy on batch 26/3013  on Training is 80.90277777777777\n",
            "Epoch #1. Accuracy on batch 27/3013  on Training is 80.80357142857143\n",
            "Epoch #1. Accuracy on batch 28/3013  on Training is 80.60344827586206\n",
            "Epoch #1. Accuracy on batch 29/3013  on Training is 80.52083333333333\n",
            "Epoch #1. Accuracy on batch 30/3013  on Training is 80.44354838709677\n",
            "Epoch #1. Accuracy on batch 31/3013  on Training is 80.37109375\n",
            "Epoch #1. Accuracy on batch 32/3013  on Training is 80.49242424242425\n",
            "Epoch #1. Accuracy on batch 33/3013  on Training is 80.51470588235294\n",
            "Epoch #1. Accuracy on batch 34/3013  on Training is 80.26785714285714\n",
            "Epoch #1. Accuracy on batch 35/3013  on Training is 80.38194444444444\n",
            "Epoch #1. Accuracy on batch 36/3013  on Training is 80.23648648648648\n",
            "Epoch #1. Accuracy on batch 37/3013  on Training is 80.09868421052632\n",
            "Epoch #1. Accuracy on batch 38/3013  on Training is 80.36858974358974\n",
            "Epoch #1. Accuracy on batch 39/3013  on Training is 80.3125\n",
            "Batch Id 40 is having training loss of 0.720216691493988\n",
            "0.9947203397750854\n",
            "Epoch #1. Accuracy on batch 40/3013  on Training is 80.1829268292683\n",
            "Epoch #1. Accuracy on batch 41/3013  on Training is 80.13392857142857\n",
            "Epoch #1. Accuracy on batch 42/3013  on Training is 80.30523255813954\n",
            "Epoch #1. Accuracy on batch 43/3013  on Training is 80.53977272727273\n",
            "Epoch #1. Accuracy on batch 44/3013  on Training is 80.55555555555556\n",
            "Epoch #1. Accuracy on batch 45/3013  on Training is 80.84239130434783\n",
            "Epoch #1. Accuracy on batch 46/3013  on Training is 80.78457446808511\n",
            "Epoch #1. Accuracy on batch 47/3013  on Training is 80.98958333333333\n",
            "Epoch #1. Accuracy on batch 48/3013  on Training is 80.99489795918367\n",
            "Epoch #1. Accuracy on batch 49/3013  on Training is 81.0625\n",
            "Epoch #1. Accuracy on batch 50/3013  on Training is 81.00490196078431\n",
            "Epoch #1. Accuracy on batch 51/3013  on Training is 81.18990384615384\n",
            "Epoch #1. Accuracy on batch 52/3013  on Training is 81.25\n",
            "Epoch #1. Accuracy on batch 53/3013  on Training is 81.07638888888889\n",
            "Epoch #1. Accuracy on batch 54/3013  on Training is 80.9659090909091\n",
            "Epoch #1. Accuracy on batch 55/3013  on Training is 81.19419642857143\n",
            "Epoch #1. Accuracy on batch 56/3013  on Training is 81.14035087719299\n",
            "Epoch #1. Accuracy on batch 57/3013  on Training is 81.25\n",
            "Epoch #1. Accuracy on batch 58/3013  on Training is 81.03813559322033\n",
            "Epoch #1. Accuracy on batch 59/3013  on Training is 81.19791666666667\n",
            "Batch Id 60 is having training loss of 0.6956498026847839\n",
            "0.6234079599380493\n",
            "Epoch #1. Accuracy on batch 60/3013  on Training is 81.14754098360656\n",
            "Epoch #1. Accuracy on batch 61/3013  on Training is 81.25\n",
            "Epoch #1. Accuracy on batch 62/3013  on Training is 81.0515873015873\n",
            "Epoch #1. Accuracy on batch 63/3013  on Training is 81.005859375\n",
            "Epoch #1. Accuracy on batch 64/3013  on Training is 81.00961538461539\n",
            "Epoch #1. Accuracy on batch 65/3013  on Training is 81.10795454545455\n",
            "Epoch #1. Accuracy on batch 66/3013  on Training is 81.06343283582089\n",
            "Epoch #1. Accuracy on batch 67/3013  on Training is 81.02022058823529\n",
            "Epoch #1. Accuracy on batch 68/3013  on Training is 81.06884057971014\n",
            "Epoch #1. Accuracy on batch 69/3013  on Training is 81.11607142857143\n",
            "Epoch #1. Accuracy on batch 70/3013  on Training is 81.20598591549296\n",
            "Epoch #1. Accuracy on batch 71/3013  on Training is 80.98958333333333\n",
            "Epoch #1. Accuracy on batch 72/3013  on Training is 80.95034246575342\n",
            "Epoch #1. Accuracy on batch 73/3013  on Training is 81.08108108108108\n",
            "Epoch #1. Accuracy on batch 74/3013  on Training is 81.125\n",
            "Epoch #1. Accuracy on batch 75/3013  on Training is 81.12664473684211\n",
            "Epoch #1. Accuracy on batch 76/3013  on Training is 81.08766233766234\n",
            "Epoch #1. Accuracy on batch 77/3013  on Training is 81.1698717948718\n",
            "Epoch #1. Accuracy on batch 78/3013  on Training is 81.21044303797468\n",
            "Epoch #1. Accuracy on batch 79/3013  on Training is 81.09375\n",
            "Batch Id 80 is having training loss of 0.7128704786300659\n",
            "1.0732005834579468\n",
            "Epoch #1. Accuracy on batch 80/3013  on Training is 80.94135802469135\n",
            "Epoch #1. Accuracy on batch 81/3013  on Training is 80.9451219512195\n",
            "Epoch #1. Accuracy on batch 82/3013  on Training is 80.91114457831326\n",
            "Epoch #1. Accuracy on batch 83/3013  on Training is 80.76636904761905\n",
            "Epoch #1. Accuracy on batch 84/3013  on Training is 80.80882352941177\n",
            "Epoch #1. Accuracy on batch 85/3013  on Training is 80.77761627906976\n",
            "Epoch #1. Accuracy on batch 86/3013  on Training is 80.85488505747126\n",
            "Epoch #1. Accuracy on batch 87/3013  on Training is 80.93039772727273\n",
            "Epoch #1. Accuracy on batch 88/3013  on Training is 81.0744382022472\n",
            "Epoch #1. Accuracy on batch 89/3013  on Training is 81.14583333333333\n",
            "Epoch #1. Accuracy on batch 90/3013  on Training is 81.0782967032967\n",
            "Epoch #1. Accuracy on batch 91/3013  on Training is 81.11413043478261\n",
            "Epoch #1. Accuracy on batch 92/3013  on Training is 81.18279569892474\n",
            "Epoch #1. Accuracy on batch 93/3013  on Training is 81.28324468085107\n",
            "Epoch #1. Accuracy on batch 94/3013  on Training is 81.1842105263158\n",
            "Epoch #1. Accuracy on batch 95/3013  on Training is 81.21744791666667\n",
            "Epoch #1. Accuracy on batch 96/3013  on Training is 81.37886597938144\n",
            "Epoch #1. Accuracy on batch 97/3013  on Training is 81.40943877551021\n",
            "Epoch #1. Accuracy on batch 98/3013  on Training is 81.34469696969697\n",
            "Epoch #1. Accuracy on batch 99/3013  on Training is 81.28125\n",
            "Batch Id 100 is having training loss of 0.7048850655555725\n",
            "0.7250497341156006\n",
            "Epoch #1. Accuracy on batch 100/3013  on Training is 81.2809405940594\n",
            "Epoch #1. Accuracy on batch 101/3013  on Training is 81.25\n",
            "Epoch #1. Accuracy on batch 102/3013  on Training is 81.31067961165049\n",
            "Epoch #1. Accuracy on batch 103/3013  on Training is 81.21995192307692\n",
            "Epoch #1. Accuracy on batch 104/3013  on Training is 81.33928571428571\n",
            "Epoch #1. Accuracy on batch 105/3013  on Training is 81.25\n",
            "Epoch #1. Accuracy on batch 106/3013  on Training is 81.25\n",
            "Epoch #1. Accuracy on batch 107/3013  on Training is 81.42361111111111\n",
            "Epoch #1. Accuracy on batch 108/3013  on Training is 81.39334862385321\n",
            "Epoch #1. Accuracy on batch 109/3013  on Training is 81.33522727272727\n",
            "Epoch #1. Accuracy on batch 110/3013  on Training is 81.27815315315316\n",
            "Epoch #1. Accuracy on batch 111/3013  on Training is 81.16629464285714\n",
            "Epoch #1. Accuracy on batch 112/3013  on Training is 81.13938053097345\n",
            "Epoch #1. Accuracy on batch 113/3013  on Training is 81.22258771929825\n",
            "Epoch #1. Accuracy on batch 114/3013  on Training is 81.27717391304348\n",
            "Epoch #1. Accuracy on batch 115/3013  on Training is 81.27693965517241\n",
            "Epoch #1. Accuracy on batch 116/3013  on Training is 81.3301282051282\n",
            "Epoch #1. Accuracy on batch 117/3013  on Training is 81.25\n",
            "Epoch #1. Accuracy on batch 118/3013  on Training is 81.25\n",
            "Epoch #1. Accuracy on batch 119/3013  on Training is 81.25\n",
            "Batch Id 120 is having training loss of 0.7058470249176025\n",
            "0.8174089193344116\n",
            "Epoch #1. Accuracy on batch 120/3013  on Training is 81.25\n",
            "Epoch #1. Accuracy on batch 121/3013  on Training is 81.30122950819673\n",
            "Epoch #1. Accuracy on batch 122/3013  on Training is 81.27540650406505\n",
            "Epoch #1. Accuracy on batch 123/3013  on Training is 81.37600806451613\n",
            "Epoch #1. Accuracy on batch 124/3013  on Training is 81.375\n",
            "Epoch #1. Accuracy on batch 125/3013  on Training is 81.4484126984127\n",
            "Epoch #1. Accuracy on batch 126/3013  on Training is 81.42224409448819\n",
            "Epoch #1. Accuracy on batch 127/3013  on Training is 81.4453125\n",
            "Epoch #1. Accuracy on batch 128/3013  on Training is 81.4922480620155\n",
            "Epoch #1. Accuracy on batch 129/3013  on Training is 81.4423076923077\n",
            "Epoch #1. Accuracy on batch 130/3013  on Training is 81.4885496183206\n",
            "Epoch #1. Accuracy on batch 131/3013  on Training is 81.51041666666667\n",
            "Epoch #1. Accuracy on batch 132/3013  on Training is 81.39097744360902\n",
            "Epoch #1. Accuracy on batch 133/3013  on Training is 81.38992537313433\n",
            "Epoch #1. Accuracy on batch 134/3013  on Training is 81.43518518518519\n",
            "Epoch #1. Accuracy on batch 135/3013  on Training is 81.43382352941177\n",
            "Epoch #1. Accuracy on batch 136/3013  on Training is 81.38686131386861\n",
            "Epoch #1. Accuracy on batch 137/3013  on Training is 81.38586956521739\n",
            "Epoch #1. Accuracy on batch 138/3013  on Training is 81.36241007194245\n",
            "Epoch #1. Accuracy on batch 139/3013  on Training is 81.47321428571429\n",
            "Batch Id 140 is having training loss of 0.6967833638191223\n",
            "0.7671672701835632\n",
            "Epoch #1. Accuracy on batch 140/3013  on Training is 81.49379432624113\n",
            "Epoch #1. Accuracy on batch 141/3013  on Training is 81.49207746478874\n",
            "Epoch #1. Accuracy on batch 142/3013  on Training is 81.5340909090909\n",
            "Epoch #1. Accuracy on batch 143/3013  on Training is 81.51041666666667\n",
            "Epoch #1. Accuracy on batch 144/3013  on Training is 81.53017241379311\n",
            "Epoch #1. Accuracy on batch 145/3013  on Training is 81.48544520547945\n",
            "Epoch #1. Accuracy on batch 146/3013  on Training is 81.48384353741497\n",
            "Epoch #1. Accuracy on batch 147/3013  on Training is 81.48226351351352\n",
            "Epoch #1. Accuracy on batch 148/3013  on Training is 81.52265100671141\n",
            "Epoch #1. Accuracy on batch 149/3013  on Training is 81.47916666666667\n",
            "Epoch #1. Accuracy on batch 150/3013  on Training is 81.45695364238411\n",
            "Epoch #1. Accuracy on batch 151/3013  on Training is 81.4967105263158\n",
            "Epoch #1. Accuracy on batch 152/3013  on Training is 81.59722222222223\n",
            "Epoch #1. Accuracy on batch 153/3013  on Training is 81.49350649350649\n",
            "Epoch #1. Accuracy on batch 154/3013  on Training is 81.47177419354838\n",
            "Epoch #1. Accuracy on batch 155/3013  on Training is 81.45032051282051\n",
            "Epoch #1. Accuracy on batch 156/3013  on Training is 81.46894904458598\n",
            "Epoch #1. Accuracy on batch 157/3013  on Training is 81.40822784810126\n",
            "Epoch #1. Accuracy on batch 158/3013  on Training is 81.48584905660377\n",
            "Epoch #1. Accuracy on batch 159/3013  on Training is 81.54296875\n",
            "Batch Id 160 is having training loss of 0.6960713863372803\n",
            "0.6450192332267761\n",
            "Epoch #1. Accuracy on batch 160/3013  on Training is 81.54114906832298\n",
            "Epoch #1. Accuracy on batch 161/3013  on Training is 81.59722222222223\n",
            "Epoch #1. Accuracy on batch 162/3013  on Training is 81.61426380368098\n",
            "Epoch #1. Accuracy on batch 163/3013  on Training is 81.57393292682927\n",
            "Epoch #1. Accuracy on batch 164/3013  on Training is 81.5340909090909\n",
            "Epoch #1. Accuracy on batch 165/3013  on Training is 81.49472891566265\n",
            "Epoch #1. Accuracy on batch 166/3013  on Training is 81.49326347305389\n",
            "Epoch #1. Accuracy on batch 167/3013  on Training is 81.51041666666667\n",
            "Epoch #1. Accuracy on batch 168/3013  on Training is 81.47189349112426\n",
            "Epoch #1. Accuracy on batch 169/3013  on Training is 81.34191176470588\n",
            "Epoch #1. Accuracy on batch 170/3013  on Training is 81.28654970760233\n",
            "Epoch #1. Accuracy on batch 171/3013  on Training is 81.32267441860465\n",
            "Epoch #1. Accuracy on batch 172/3013  on Training is 81.35838150289017\n",
            "Epoch #1. Accuracy on batch 173/3013  on Training is 81.3757183908046\n",
            "Epoch #1. Accuracy on batch 174/3013  on Training is 81.35714285714286\n",
            "Epoch #1. Accuracy on batch 175/3013  on Training is 81.37428977272727\n",
            "Epoch #1. Accuracy on batch 176/3013  on Training is 81.40889830508475\n",
            "Epoch #1. Accuracy on batch 177/3013  on Training is 81.49578651685393\n",
            "Epoch #1. Accuracy on batch 178/3013  on Training is 81.51187150837988\n",
            "Epoch #1. Accuracy on batch 179/3013  on Training is 81.45833333333333\n",
            "Batch Id 180 is having training loss of 0.6993156671524048\n",
            "0.4084833264350891\n",
            "Epoch #1. Accuracy on batch 180/3013  on Training is 81.49171270718232\n",
            "Epoch #1. Accuracy on batch 181/3013  on Training is 81.38736263736264\n",
            "Epoch #1. Accuracy on batch 182/3013  on Training is 81.31830601092896\n",
            "Epoch #1. Accuracy on batch 183/3013  on Training is 81.30095108695652\n",
            "Epoch #1. Accuracy on batch 184/3013  on Training is 81.26689189189189\n",
            "Epoch #1. Accuracy on batch 185/3013  on Training is 81.26680107526882\n",
            "Epoch #1. Accuracy on batch 186/3013  on Training is 81.25\n",
            "Epoch #1. Accuracy on batch 187/3013  on Training is 81.26662234042553\n",
            "Epoch #1. Accuracy on batch 188/3013  on Training is 81.25\n",
            "Epoch #1. Accuracy on batch 189/3013  on Training is 81.26644736842105\n",
            "Epoch #1. Accuracy on batch 190/3013  on Training is 81.29908376963351\n",
            "Epoch #1. Accuracy on batch 191/3013  on Training is 81.31510416666667\n",
            "Epoch #1. Accuracy on batch 192/3013  on Training is 81.31476683937824\n",
            "Epoch #1. Accuracy on batch 193/3013  on Training is 81.26610824742268\n",
            "Epoch #1. Accuracy on batch 194/3013  on Training is 81.25\n",
            "Epoch #1. Accuracy on batch 195/3013  on Training is 81.21811224489795\n",
            "Epoch #1. Accuracy on batch 196/3013  on Training is 81.2024111675127\n",
            "Epoch #1. Accuracy on batch 197/3013  on Training is 81.10795454545455\n",
            "Epoch #1. Accuracy on batch 198/3013  on Training is 81.12437185929649\n",
            "Epoch #1. Accuracy on batch 199/3013  on Training is 81.109375\n",
            "Batch Id 200 is having training loss of 0.7116784453392029\n",
            "1.0518378019332886\n",
            "Epoch #1. Accuracy on batch 200/3013  on Training is 81.07898009950249\n",
            "Epoch #1. Accuracy on batch 201/3013  on Training is 81.07982673267327\n",
            "Epoch #1. Accuracy on batch 202/3013  on Training is 81.0652709359606\n",
            "Epoch #1. Accuracy on batch 203/3013  on Training is 81.0968137254902\n",
            "Epoch #1. Accuracy on batch 204/3013  on Training is 81.0060975609756\n",
            "Epoch #1. Accuracy on batch 205/3013  on Training is 81.00728155339806\n",
            "Epoch #1. Accuracy on batch 206/3013  on Training is 80.99335748792271\n",
            "Epoch #1. Accuracy on batch 207/3013  on Training is 80.96454326923077\n",
            "Epoch #1. Accuracy on batch 208/3013  on Training is 80.9061004784689\n",
            "Epoch #1. Accuracy on batch 209/3013  on Training is 80.81845238095238\n",
            "Epoch #1. Accuracy on batch 210/3013  on Training is 80.79087677725119\n",
            "Epoch #1. Accuracy on batch 211/3013  on Training is 80.79304245283019\n",
            "Epoch #1. Accuracy on batch 212/3013  on Training is 80.70715962441315\n",
            "Epoch #1. Accuracy on batch 213/3013  on Training is 80.73890186915888\n",
            "Epoch #1. Accuracy on batch 214/3013  on Training is 80.74127906976744\n",
            "Epoch #1. Accuracy on batch 215/3013  on Training is 80.78703703703704\n",
            "Epoch #1. Accuracy on batch 216/3013  on Training is 80.81797235023042\n",
            "Epoch #1. Accuracy on batch 217/3013  on Training is 80.83428899082568\n",
            "Epoch #1. Accuracy on batch 218/3013  on Training is 80.87899543378995\n",
            "Epoch #1. Accuracy on batch 219/3013  on Training is 80.83806818181819\n",
            "Batch Id 220 is having training loss of 0.7176017165184021\n",
            "0.6342974901199341\n",
            "Epoch #1. Accuracy on batch 220/3013  on Training is 80.8116515837104\n",
            "Epoch #1. Accuracy on batch 221/3013  on Training is 80.74324324324324\n",
            "Epoch #1. Accuracy on batch 222/3013  on Training is 80.67544843049328\n",
            "Epoch #1. Accuracy on batch 223/3013  on Training is 80.6640625\n",
            "Epoch #1. Accuracy on batch 224/3013  on Training is 80.66666666666667\n",
            "Epoch #1. Accuracy on batch 225/3013  on Training is 80.66924778761062\n",
            "Epoch #1. Accuracy on batch 226/3013  on Training is 80.69933920704845\n",
            "Epoch #1. Accuracy on batch 227/3013  on Training is 80.66063596491227\n",
            "Epoch #1. Accuracy on batch 228/3013  on Training is 80.63591703056768\n",
            "Epoch #1. Accuracy on batch 229/3013  on Training is 80.63858695652173\n",
            "Epoch #1. Accuracy on batch 230/3013  on Training is 80.64123376623377\n",
            "Epoch #1. Accuracy on batch 231/3013  on Training is 80.63038793103448\n",
            "Epoch #1. Accuracy on batch 232/3013  on Training is 80.64645922746782\n",
            "Epoch #1. Accuracy on batch 233/3013  on Training is 80.60897435897436\n",
            "Epoch #1. Accuracy on batch 234/3013  on Training is 80.625\n",
            "Epoch #1. Accuracy on batch 235/3013  on Training is 80.70709745762711\n",
            "Epoch #1. Accuracy on batch 236/3013  on Training is 80.66983122362869\n",
            "Epoch #1. Accuracy on batch 237/3013  on Training is 80.65913865546219\n",
            "Epoch #1. Accuracy on batch 238/3013  on Training is 80.63546025104603\n",
            "Epoch #1. Accuracy on batch 239/3013  on Training is 80.63802083333333\n",
            "Batch Id 240 is having training loss of 0.7229498028755188\n",
            "0.8694558143615723\n",
            "Epoch #1. Accuracy on batch 240/3013  on Training is 80.6405601659751\n",
            "Epoch #1. Accuracy on batch 241/3013  on Training is 80.60433884297521\n",
            "Epoch #1. Accuracy on batch 242/3013  on Training is 80.65843621399176\n",
            "Epoch #1. Accuracy on batch 243/3013  on Training is 80.62243852459017\n",
            "Epoch #1. Accuracy on batch 244/3013  on Training is 80.66326530612245\n",
            "Epoch #1. Accuracy on batch 245/3013  on Training is 80.65294715447155\n",
            "Epoch #1. Accuracy on batch 246/3013  on Training is 80.63006072874494\n",
            "Epoch #1. Accuracy on batch 247/3013  on Training is 80.5695564516129\n",
            "Epoch #1. Accuracy on batch 248/3013  on Training is 80.62248995983936\n",
            "Epoch #1. Accuracy on batch 249/3013  on Training is 80.6125\n",
            "Epoch #1. Accuracy on batch 250/3013  on Training is 80.62749003984064\n",
            "Epoch #1. Accuracy on batch 251/3013  on Training is 80.6547619047619\n",
            "Epoch #1. Accuracy on batch 252/3013  on Training is 80.66946640316206\n",
            "Epoch #1. Accuracy on batch 253/3013  on Training is 80.73326771653544\n",
            "Epoch #1. Accuracy on batch 254/3013  on Training is 80.71078431372548\n",
            "Epoch #1. Accuracy on batch 255/3013  on Training is 80.7373046875\n",
            "Epoch #1. Accuracy on batch 256/3013  on Training is 80.70282101167315\n",
            "Epoch #1. Accuracy on batch 257/3013  on Training is 80.69282945736434\n",
            "Epoch #1. Accuracy on batch 258/3013  on Training is 80.65878378378379\n",
            "Epoch #1. Accuracy on batch 259/3013  on Training is 80.6610576923077\n",
            "Batch Id 260 is having training loss of 0.7216352820396423\n",
            "1.388899326324463\n",
            "Epoch #1. Accuracy on batch 260/3013  on Training is 80.60344827586206\n",
            "Epoch #1. Accuracy on batch 261/3013  on Training is 80.61784351145039\n",
            "Epoch #1. Accuracy on batch 262/3013  on Training is 80.6083650190114\n",
            "Epoch #1. Accuracy on batch 263/3013  on Training is 80.52793560606061\n",
            "Epoch #1. Accuracy on batch 264/3013  on Training is 80.53066037735849\n",
            "Epoch #1. Accuracy on batch 265/3013  on Training is 80.56860902255639\n",
            "Epoch #1. Accuracy on batch 266/3013  on Training is 80.57116104868913\n",
            "Epoch #1. Accuracy on batch 267/3013  on Training is 80.55037313432835\n",
            "Epoch #1. Accuracy on batch 268/3013  on Training is 80.54135687732342\n",
            "Epoch #1. Accuracy on batch 269/3013  on Training is 80.54398148148148\n",
            "Epoch #1. Accuracy on batch 270/3013  on Training is 80.56964944649447\n",
            "Epoch #1. Accuracy on batch 271/3013  on Training is 80.57215073529412\n",
            "Epoch #1. Accuracy on batch 272/3013  on Training is 80.5746336996337\n",
            "Epoch #1. Accuracy on batch 273/3013  on Training is 80.59990875912409\n",
            "Epoch #1. Accuracy on batch 274/3013  on Training is 80.56818181818181\n",
            "Epoch #1. Accuracy on batch 275/3013  on Training is 80.57065217391305\n",
            "Epoch #1. Accuracy on batch 276/3013  on Training is 80.61823104693141\n",
            "Epoch #1. Accuracy on batch 277/3013  on Training is 80.58678057553956\n",
            "Epoch #1. Accuracy on batch 278/3013  on Training is 80.61155913978494\n",
            "Epoch #1. Accuracy on batch 279/3013  on Training is 80.55803571428571\n",
            "Batch Id 280 is having training loss of 0.7194169163703918\n",
            "0.8619643449783325\n",
            "Epoch #1. Accuracy on batch 280/3013  on Training is 80.53825622775801\n",
            "Epoch #1. Accuracy on batch 281/3013  on Training is 80.5186170212766\n",
            "Epoch #1. Accuracy on batch 282/3013  on Training is 80.54328621908127\n",
            "Epoch #1. Accuracy on batch 283/3013  on Training is 80.54577464788733\n",
            "Epoch #1. Accuracy on batch 284/3013  on Training is 80.5701754385965\n",
            "Epoch #1. Accuracy on batch 285/3013  on Training is 80.57255244755245\n",
            "Epoch #1. Accuracy on batch 286/3013  on Training is 80.60757839721255\n",
            "Epoch #1. Accuracy on batch 287/3013  on Training is 80.62065972222223\n",
            "Epoch #1. Accuracy on batch 288/3013  on Training is 80.62283737024221\n",
            "Epoch #1. Accuracy on batch 289/3013  on Training is 80.61422413793103\n",
            "Epoch #1. Accuracy on batch 290/3013  on Training is 80.62714776632302\n",
            "Epoch #1. Accuracy on batch 291/3013  on Training is 80.57577054794521\n",
            "Epoch #1. Accuracy on batch 292/3013  on Training is 80.58873720136519\n",
            "Epoch #1. Accuracy on batch 293/3013  on Training is 80.58035714285714\n",
            "Epoch #1. Accuracy on batch 294/3013  on Training is 80.57203389830508\n",
            "Epoch #1. Accuracy on batch 295/3013  on Training is 80.62711148648648\n",
            "Epoch #1. Accuracy on batch 296/3013  on Training is 80.60816498316498\n",
            "Epoch #1. Accuracy on batch 297/3013  on Training is 80.58934563758389\n",
            "Epoch #1. Accuracy on batch 298/3013  on Training is 80.65426421404682\n",
            "Epoch #1. Accuracy on batch 299/3013  on Training is 80.64583333333333\n",
            "Batch Id 300 is having training loss of 0.7163817286491394\n",
            "0.9507626891136169\n",
            "Epoch #1. Accuracy on batch 300/3013  on Training is 80.62707641196013\n",
            "Epoch #1. Accuracy on batch 301/3013  on Training is 80.6498344370861\n",
            "Epoch #1. Accuracy on batch 302/3013  on Training is 80.63118811881188\n",
            "Epoch #1. Accuracy on batch 303/3013  on Training is 80.62294407894737\n",
            "Epoch #1. Accuracy on batch 304/3013  on Training is 80.61475409836065\n",
            "Epoch #1. Accuracy on batch 305/3013  on Training is 80.64746732026144\n",
            "Epoch #1. Accuracy on batch 306/3013  on Training is 80.62907166123779\n",
            "Epoch #1. Accuracy on batch 307/3013  on Training is 80.64123376623377\n",
            "Epoch #1. Accuracy on batch 308/3013  on Training is 80.6836569579288\n",
            "Epoch #1. Accuracy on batch 309/3013  on Training is 80.65524193548387\n",
            "Epoch #1. Accuracy on batch 310/3013  on Training is 80.61696141479099\n",
            "Epoch #1. Accuracy on batch 311/3013  on Training is 80.61899038461539\n",
            "Epoch #1. Accuracy on batch 312/3013  on Training is 80.61102236421725\n",
            "Epoch #1. Accuracy on batch 313/3013  on Training is 80.63296178343948\n",
            "Epoch #1. Accuracy on batch 314/3013  on Training is 80.61507936507937\n",
            "Epoch #1. Accuracy on batch 315/3013  on Training is 80.59731012658227\n",
            "Epoch #1. Accuracy on batch 316/3013  on Training is 80.58951104100946\n",
            "Epoch #1. Accuracy on batch 317/3013  on Training is 80.60141509433963\n",
            "Epoch #1. Accuracy on batch 318/3013  on Training is 80.57405956112852\n",
            "Epoch #1. Accuracy on batch 319/3013  on Training is 80.556640625\n",
            "Batch Id 320 is having training loss of 0.7172490954399109\n",
            "0.8928848505020142\n",
            "Epoch #1. Accuracy on batch 320/3013  on Training is 80.52959501557632\n",
            "Epoch #1. Accuracy on batch 321/3013  on Training is 80.55124223602485\n",
            "Epoch #1. Accuracy on batch 322/3013  on Training is 80.55340557275542\n",
            "Epoch #1. Accuracy on batch 323/3013  on Training is 80.57484567901234\n",
            "Epoch #1. Accuracy on batch 324/3013  on Training is 80.57692307692308\n",
            "Epoch #1. Accuracy on batch 325/3013  on Training is 80.59815950920246\n",
            "Epoch #1. Accuracy on batch 326/3013  on Training is 80.63837920489297\n",
            "Epoch #1. Accuracy on batch 327/3013  on Training is 80.64024390243902\n",
            "Epoch #1. Accuracy on batch 328/3013  on Training is 80.6420972644377\n",
            "Epoch #1. Accuracy on batch 329/3013  on Training is 80.625\n",
            "Epoch #1. Accuracy on batch 330/3013  on Training is 80.63632930513594\n",
            "Epoch #1. Accuracy on batch 331/3013  on Training is 80.62876506024097\n",
            "Epoch #1. Accuracy on batch 332/3013  on Training is 80.64001501501501\n",
            "Epoch #1. Accuracy on batch 333/3013  on Training is 80.67926646706587\n",
            "Epoch #1. Accuracy on batch 334/3013  on Training is 80.66231343283582\n",
            "Epoch #1. Accuracy on batch 335/3013  on Training is 80.63616071428571\n",
            "Epoch #1. Accuracy on batch 336/3013  on Training is 80.6379821958457\n",
            "Epoch #1. Accuracy on batch 337/3013  on Training is 80.63979289940828\n",
            "Epoch #1. Accuracy on batch 338/3013  on Training is 80.61393805309734\n",
            "Epoch #1. Accuracy on batch 339/3013  on Training is 80.56985294117646\n",
            "Batch Id 340 is having training loss of 0.7163017988204956\n",
            "0.7992651462554932\n",
            "Epoch #1. Accuracy on batch 340/3013  on Training is 80.56268328445748\n",
            "Epoch #1. Accuracy on batch 341/3013  on Training is 80.57383040935673\n",
            "Epoch #1. Accuracy on batch 342/3013  on Training is 80.53024781341108\n",
            "Epoch #1. Accuracy on batch 343/3013  on Training is 80.51417151162791\n",
            "Epoch #1. Accuracy on batch 344/3013  on Training is 80.53442028985508\n",
            "Epoch #1. Accuracy on batch 345/3013  on Training is 80.53648843930635\n",
            "Epoch #1. Accuracy on batch 346/3013  on Training is 80.52053314121038\n",
            "Epoch #1. Accuracy on batch 347/3013  on Training is 80.5316091954023\n",
            "Epoch #1. Accuracy on batch 348/3013  on Training is 80.5426217765043\n",
            "Epoch #1. Accuracy on batch 349/3013  on Training is 80.52678571428571\n",
            "Epoch #1. Accuracy on batch 350/3013  on Training is 80.50213675213675\n",
            "Epoch #1. Accuracy on batch 351/3013  on Training is 80.4598721590909\n",
            "Epoch #1. Accuracy on batch 352/3013  on Training is 80.45325779036827\n",
            "Epoch #1. Accuracy on batch 353/3013  on Training is 80.45550847457628\n",
            "Epoch #1. Accuracy on batch 354/3013  on Training is 80.47535211267606\n",
            "Epoch #1. Accuracy on batch 355/3013  on Training is 80.45997191011236\n",
            "Epoch #1. Accuracy on batch 356/3013  on Training is 80.4359243697479\n",
            "Epoch #1. Accuracy on batch 357/3013  on Training is 80.44692737430168\n",
            "Epoch #1. Accuracy on batch 358/3013  on Training is 80.45786908077994\n",
            "Epoch #1. Accuracy on batch 359/3013  on Training is 80.46006944444444\n",
            "Batch Id 360 is having training loss of 0.7174330949783325\n",
            "0.6841062903404236\n",
            "Epoch #1. Accuracy on batch 360/3013  on Training is 80.45360110803324\n",
            "Epoch #1. Accuracy on batch 361/3013  on Training is 80.49033149171271\n",
            "Epoch #1. Accuracy on batch 362/3013  on Training is 80.51825068870524\n",
            "Epoch #1. Accuracy on batch 363/3013  on Training is 80.52026098901099\n",
            "Epoch #1. Accuracy on batch 364/3013  on Training is 80.5222602739726\n",
            "Epoch #1. Accuracy on batch 365/3013  on Training is 80.51571038251366\n",
            "Epoch #1. Accuracy on batch 366/3013  on Training is 80.5432561307902\n",
            "Epoch #1. Accuracy on batch 367/3013  on Training is 80.55366847826087\n",
            "Epoch #1. Accuracy on batch 368/3013  on Training is 80.55555555555556\n",
            "Epoch #1. Accuracy on batch 369/3013  on Training is 80.56587837837837\n",
            "Epoch #1. Accuracy on batch 370/3013  on Training is 80.57614555256065\n",
            "Epoch #1. Accuracy on batch 371/3013  on Training is 80.5695564516129\n",
            "Epoch #1. Accuracy on batch 372/3013  on Training is 80.57138069705094\n",
            "Epoch #1. Accuracy on batch 373/3013  on Training is 80.59826203208556\n",
            "Epoch #1. Accuracy on batch 374/3013  on Training is 80.56666666666666\n",
            "Epoch #1. Accuracy on batch 375/3013  on Training is 80.5684840425532\n",
            "Epoch #1. Accuracy on batch 376/3013  on Training is 80.60344827586206\n",
            "Epoch #1. Accuracy on batch 377/3013  on Training is 80.60515873015873\n",
            "Epoch #1. Accuracy on batch 378/3013  on Training is 80.5821240105541\n",
            "Epoch #1. Accuracy on batch 379/3013  on Training is 80.5592105263158\n",
            "Batch Id 380 is having training loss of 0.7156351804733276\n",
            "0.923037588596344\n",
            "Epoch #1. Accuracy on batch 380/3013  on Training is 80.54461942257218\n",
            "Epoch #1. Accuracy on batch 381/3013  on Training is 80.51374345549738\n",
            "Epoch #1. Accuracy on batch 382/3013  on Training is 80.52382506527415\n",
            "Epoch #1. Accuracy on batch 383/3013  on Training is 80.5419921875\n",
            "Epoch #1. Accuracy on batch 384/3013  on Training is 80.53571428571429\n",
            "Epoch #1. Accuracy on batch 385/3013  on Training is 80.51327720207254\n",
            "Epoch #1. Accuracy on batch 386/3013  on Training is 80.52325581395348\n",
            "Epoch #1. Accuracy on batch 387/3013  on Training is 80.5090206185567\n",
            "Epoch #1. Accuracy on batch 388/3013  on Training is 80.50289203084833\n",
            "Epoch #1. Accuracy on batch 389/3013  on Training is 80.53685897435898\n",
            "Epoch #1. Accuracy on batch 390/3013  on Training is 80.55466751918159\n",
            "Epoch #1. Accuracy on batch 391/3013  on Training is 80.5484693877551\n",
            "Epoch #1. Accuracy on batch 392/3013  on Training is 80.53435114503817\n",
            "Epoch #1. Accuracy on batch 393/3013  on Training is 80.52823604060913\n",
            "Epoch #1. Accuracy on batch 394/3013  on Training is 80.50632911392405\n",
            "Epoch #1. Accuracy on batch 395/3013  on Training is 80.50031565656566\n",
            "Epoch #1. Accuracy on batch 396/3013  on Training is 80.51794710327457\n",
            "Epoch #1. Accuracy on batch 397/3013  on Training is 80.55119346733669\n",
            "Epoch #1. Accuracy on batch 398/3013  on Training is 80.55294486215539\n",
            "Epoch #1. Accuracy on batch 399/3013  on Training is 80.5546875\n",
            "Batch Id 400 is having training loss of 0.7158913016319275\n",
            "0.8347254991531372\n",
            "Epoch #1. Accuracy on batch 400/3013  on Training is 80.54083541147132\n",
            "Epoch #1. Accuracy on batch 401/3013  on Training is 80.55037313432835\n",
            "Epoch #1. Accuracy on batch 402/3013  on Training is 80.56761786600497\n",
            "Epoch #1. Accuracy on batch 403/3013  on Training is 80.55383663366337\n",
            "Epoch #1. Accuracy on batch 404/3013  on Training is 80.56327160493827\n",
            "Epoch #1. Accuracy on batch 405/3013  on Training is 80.57266009852216\n",
            "Epoch #1. Accuracy on batch 406/3013  on Training is 80.54361179361179\n",
            "Epoch #1. Accuracy on batch 407/3013  on Training is 80.53002450980392\n",
            "Epoch #1. Accuracy on batch 408/3013  on Training is 80.53178484107579\n",
            "Epoch #1. Accuracy on batch 409/3013  on Training is 80.5030487804878\n",
            "Epoch #1. Accuracy on batch 410/3013  on Training is 80.49726277372262\n",
            "Epoch #1. Accuracy on batch 411/3013  on Training is 80.49150485436893\n",
            "Epoch #1. Accuracy on batch 412/3013  on Training is 80.48577481840194\n",
            "Epoch #1. Accuracy on batch 413/3013  on Training is 80.48762077294685\n",
            "Epoch #1. Accuracy on batch 414/3013  on Training is 80.519578313253\n",
            "Epoch #1. Accuracy on batch 415/3013  on Training is 80.5438701923077\n",
            "Epoch #1. Accuracy on batch 416/3013  on Training is 80.5380695443645\n",
            "Epoch #1. Accuracy on batch 417/3013  on Training is 80.54724880382776\n",
            "Epoch #1. Accuracy on batch 418/3013  on Training is 80.5489260143198\n",
            "Epoch #1. Accuracy on batch 419/3013  on Training is 80.55803571428571\n",
            "Batch Id 420 is having training loss of 0.7180458903312683\n",
            "0.9939855337142944\n",
            "Epoch #1. Accuracy on batch 420/3013  on Training is 80.55225653206651\n",
            "Epoch #1. Accuracy on batch 421/3013  on Training is 80.5835308056872\n",
            "Epoch #1. Accuracy on batch 422/3013  on Training is 80.60726950354609\n",
            "Epoch #1. Accuracy on batch 423/3013  on Training is 80.59404481132076\n",
            "Epoch #1. Accuracy on batch 424/3013  on Training is 80.58823529411765\n",
            "Epoch #1. Accuracy on batch 425/3013  on Training is 80.58978873239437\n",
            "Epoch #1. Accuracy on batch 426/3013  on Training is 80.60597189695551\n",
            "Epoch #1. Accuracy on batch 427/3013  on Training is 80.5928738317757\n",
            "Epoch #1. Accuracy on batch 428/3013  on Training is 80.57255244755245\n",
            "Epoch #1. Accuracy on batch 429/3013  on Training is 80.5813953488372\n",
            "Epoch #1. Accuracy on batch 430/3013  on Training is 80.59019721577727\n",
            "Epoch #1. Accuracy on batch 431/3013  on Training is 80.57725694444444\n",
            "Epoch #1. Accuracy on batch 432/3013  on Training is 80.57881062355658\n",
            "Epoch #1. Accuracy on batch 433/3013  on Training is 80.60195852534562\n",
            "Epoch #1. Accuracy on batch 434/3013  on Training is 80.59626436781609\n",
            "Epoch #1. Accuracy on batch 435/3013  on Training is 80.61209862385321\n",
            "Epoch #1. Accuracy on batch 436/3013  on Training is 80.61355835240275\n",
            "Epoch #1. Accuracy on batch 437/3013  on Training is 80.62214611872146\n",
            "Epoch #1. Accuracy on batch 438/3013  on Training is 80.61645785876993\n",
            "Epoch #1. Accuracy on batch 439/3013  on Training is 80.61079545454545\n",
            "Batch Id 440 is having training loss of 0.7172313332557678\n",
            "0.5647369623184204\n",
            "Epoch #1. Accuracy on batch 440/3013  on Training is 80.61224489795919\n",
            "Epoch #1. Accuracy on batch 441/3013  on Training is 80.60661764705883\n",
            "Epoch #1. Accuracy on batch 442/3013  on Training is 80.62923250564334\n",
            "Epoch #1. Accuracy on batch 443/3013  on Training is 80.63766891891892\n",
            "Epoch #1. Accuracy on batch 444/3013  on Training is 80.63904494382022\n",
            "Epoch #1. Accuracy on batch 445/3013  on Training is 80.64041479820628\n",
            "Epoch #1. Accuracy on batch 446/3013  on Training is 80.64177852348993\n",
            "Epoch #1. Accuracy on batch 447/3013  on Training is 80.65011160714286\n",
            "Epoch #1. Accuracy on batch 448/3013  on Training is 80.6792873051225\n",
            "Epoch #1. Accuracy on batch 449/3013  on Training is 80.69444444444444\n",
            "Epoch #1. Accuracy on batch 450/3013  on Training is 80.68181818181819\n",
            "Epoch #1. Accuracy on batch 451/3013  on Training is 80.68307522123894\n",
            "Epoch #1. Accuracy on batch 452/3013  on Training is 80.69122516556291\n",
            "Epoch #1. Accuracy on batch 453/3013  on Training is 80.6511563876652\n",
            "Epoch #1. Accuracy on batch 454/3013  on Training is 80.67307692307692\n",
            "Epoch #1. Accuracy on batch 455/3013  on Training is 80.67434210526316\n",
            "Epoch #1. Accuracy on batch 456/3013  on Training is 80.6687636761488\n",
            "Epoch #1. Accuracy on batch 457/3013  on Training is 80.6700327510917\n",
            "Epoch #1. Accuracy on batch 458/3013  on Training is 80.6849128540305\n",
            "Epoch #1. Accuracy on batch 459/3013  on Training is 80.65896739130434\n",
            "Batch Id 460 is having training loss of 0.7157432436943054\n",
            "0.7316806316375732\n",
            "Epoch #1. Accuracy on batch 460/3013  on Training is 80.66024945770064\n",
            "Epoch #1. Accuracy on batch 461/3013  on Training is 80.6547619047619\n",
            "Epoch #1. Accuracy on batch 462/3013  on Training is 80.63579913606911\n",
            "Epoch #1. Accuracy on batch 463/3013  on Training is 80.63038793103448\n",
            "Epoch #1. Accuracy on batch 464/3013  on Training is 80.63844086021506\n",
            "Epoch #1. Accuracy on batch 465/3013  on Training is 80.6531652360515\n",
            "Epoch #1. Accuracy on batch 466/3013  on Training is 80.66113490364026\n",
            "Epoch #1. Accuracy on batch 467/3013  on Training is 80.66239316239316\n",
            "Epoch #1. Accuracy on batch 468/3013  on Training is 80.6703091684435\n",
            "Epoch #1. Accuracy on batch 469/3013  on Training is 80.69148936170212\n",
            "Epoch #1. Accuracy on batch 470/3013  on Training is 80.67277070063695\n",
            "Epoch #1. Accuracy on batch 471/3013  on Training is 80.67399364406779\n",
            "Epoch #1. Accuracy on batch 472/3013  on Training is 80.69503171247358\n",
            "Epoch #1. Accuracy on batch 473/3013  on Training is 80.69620253164557\n",
            "Epoch #1. Accuracy on batch 474/3013  on Training is 80.67763157894737\n",
            "Epoch #1. Accuracy on batch 475/3013  on Training is 80.67883403361344\n",
            "Epoch #1. Accuracy on batch 476/3013  on Training is 80.68658280922432\n",
            "Epoch #1. Accuracy on batch 477/3013  on Training is 80.71391213389121\n",
            "Epoch #1. Accuracy on batch 478/3013  on Training is 80.71503131524008\n",
            "Epoch #1. Accuracy on batch 479/3013  on Training is 80.73567708333333\n",
            "Batch Id 480 is having training loss of 0.7156814932823181\n",
            "0.7464836239814758\n",
            "Epoch #1. Accuracy on batch 480/3013  on Training is 80.74324324324324\n",
            "Epoch #1. Accuracy on batch 481/3013  on Training is 80.73132780082987\n",
            "Epoch #1. Accuracy on batch 482/3013  on Training is 80.73887163561076\n",
            "Epoch #1. Accuracy on batch 483/3013  on Training is 80.75929752066116\n",
            "Epoch #1. Accuracy on batch 484/3013  on Training is 80.7667525773196\n",
            "Epoch #1. Accuracy on batch 485/3013  on Training is 80.78060699588477\n",
            "Epoch #1. Accuracy on batch 486/3013  on Training is 80.76232032854209\n",
            "Epoch #1. Accuracy on batch 487/3013  on Training is 80.76972336065573\n",
            "Epoch #1. Accuracy on batch 488/3013  on Training is 80.78348670756647\n",
            "Epoch #1. Accuracy on batch 489/3013  on Training is 80.77806122448979\n",
            "Epoch #1. Accuracy on batch 490/3013  on Training is 80.75356415478615\n",
            "Epoch #1. Accuracy on batch 491/3013  on Training is 80.74822154471545\n",
            "Epoch #1. Accuracy on batch 492/3013  on Training is 80.7619168356998\n",
            "Epoch #1. Accuracy on batch 493/3013  on Training is 80.76923076923077\n",
            "Epoch #1. Accuracy on batch 494/3013  on Training is 80.76388888888889\n",
            "Epoch #1. Accuracy on batch 495/3013  on Training is 80.7648689516129\n",
            "Epoch #1. Accuracy on batch 496/3013  on Training is 80.77213279678068\n",
            "Epoch #1. Accuracy on batch 497/3013  on Training is 80.77936746987952\n",
            "Epoch #1. Accuracy on batch 498/3013  on Training is 80.79283567134269\n",
            "Epoch #1. Accuracy on batch 499/3013  on Training is 80.83125\n",
            "Batch Id 500 is having training loss of 0.7133103013038635\n",
            "0.6001124978065491\n",
            "Epoch #1. Accuracy on batch 500/3013  on Training is 80.85079840319361\n",
            "Epoch #1. Accuracy on batch 501/3013  on Training is 80.83914342629483\n",
            "Epoch #1. Accuracy on batch 502/3013  on Training is 80.82753479125249\n",
            "Epoch #1. Accuracy on batch 503/3013  on Training is 80.81597222222223\n",
            "Epoch #1. Accuracy on batch 504/3013  on Training is 80.79826732673267\n",
            "Epoch #1. Accuracy on batch 505/3013  on Training is 80.79916007905139\n",
            "Epoch #1. Accuracy on batch 506/3013  on Training is 80.78772189349112\n",
            "Epoch #1. Accuracy on batch 507/3013  on Training is 80.78248031496064\n",
            "Epoch #1. Accuracy on batch 508/3013  on Training is 80.78339882121807\n",
            "Epoch #1. Accuracy on batch 509/3013  on Training is 80.7781862745098\n",
            "Epoch #1. Accuracy on batch 510/3013  on Training is 80.77299412915852\n",
            "Epoch #1. Accuracy on batch 511/3013  on Training is 80.7861328125\n",
            "Epoch #1. Accuracy on batch 512/3013  on Training is 80.78094541910332\n",
            "Epoch #1. Accuracy on batch 513/3013  on Training is 80.7636186770428\n",
            "Epoch #1. Accuracy on batch 514/3013  on Training is 80.75849514563107\n",
            "Epoch #1. Accuracy on batch 515/3013  on Training is 80.75944767441861\n",
            "Epoch #1. Accuracy on batch 516/3013  on Training is 80.76039651837525\n",
            "Epoch #1. Accuracy on batch 517/3013  on Training is 80.74927606177606\n",
            "Epoch #1. Accuracy on batch 518/3013  on Training is 80.74421965317919\n",
            "Epoch #1. Accuracy on batch 519/3013  on Training is 80.76923076923077\n",
            "Batch Id 520 is having training loss of 0.7152161002159119\n",
            "0.715561032295227\n",
            "Epoch #1. Accuracy on batch 520/3013  on Training is 80.77615163147793\n",
            "Epoch #1. Accuracy on batch 521/3013  on Training is 80.7830459770115\n",
            "Epoch #1. Accuracy on batch 522/3013  on Training is 80.78991395793498\n",
            "Epoch #1. Accuracy on batch 523/3013  on Training is 80.76097328244275\n",
            "Epoch #1. Accuracy on batch 524/3013  on Training is 80.76190476190476\n",
            "Epoch #1. Accuracy on batch 525/3013  on Training is 80.76283269961978\n",
            "Epoch #1. Accuracy on batch 526/3013  on Training is 80.76968690702087\n",
            "Epoch #1. Accuracy on batch 527/3013  on Training is 80.79427083333333\n",
            "Epoch #1. Accuracy on batch 528/3013  on Training is 80.80694706994329\n",
            "Epoch #1. Accuracy on batch 529/3013  on Training is 80.79599056603773\n",
            "Epoch #1. Accuracy on batch 530/3013  on Training is 80.7909604519774\n",
            "Epoch #1. Accuracy on batch 531/3013  on Training is 80.77420112781955\n",
            "Epoch #1. Accuracy on batch 532/3013  on Training is 80.78095684803002\n",
            "Epoch #1. Accuracy on batch 533/3013  on Training is 80.81109550561797\n",
            "Epoch #1. Accuracy on batch 534/3013  on Training is 80.78855140186916\n",
            "Epoch #1. Accuracy on batch 535/3013  on Training is 80.77775186567165\n",
            "Epoch #1. Accuracy on batch 536/3013  on Training is 80.79027001862197\n",
            "Epoch #1. Accuracy on batch 537/3013  on Training is 80.78531598513011\n",
            "Epoch #1. Accuracy on batch 538/3013  on Training is 80.77458256029685\n",
            "Epoch #1. Accuracy on batch 539/3013  on Training is 80.78125\n",
            "Batch Id 540 is having training loss of 0.7157377600669861\n",
            "0.6523035168647766\n",
            "Epoch #1. Accuracy on batch 540/3013  on Training is 80.78789279112755\n",
            "Epoch #1. Accuracy on batch 541/3013  on Training is 80.78874538745387\n",
            "Epoch #1. Accuracy on batch 542/3013  on Training is 80.77232965009208\n",
            "Epoch #1. Accuracy on batch 543/3013  on Training is 80.77895220588235\n",
            "Epoch #1. Accuracy on batch 544/3013  on Training is 80.76834862385321\n",
            "Epoch #1. Accuracy on batch 545/3013  on Training is 80.78067765567765\n",
            "Epoch #1. Accuracy on batch 546/3013  on Training is 80.7758226691042\n",
            "Epoch #1. Accuracy on batch 547/3013  on Training is 80.77098540145985\n",
            "Epoch #1. Accuracy on batch 548/3013  on Training is 80.77755009107469\n",
            "Epoch #1. Accuracy on batch 549/3013  on Training is 80.7784090909091\n",
            "Epoch #1. Accuracy on batch 550/3013  on Training is 80.77926497277677\n",
            "Epoch #1. Accuracy on batch 551/3013  on Training is 80.78011775362319\n",
            "Epoch #1. Accuracy on batch 552/3013  on Training is 80.7753164556962\n",
            "Epoch #1. Accuracy on batch 553/3013  on Training is 80.77617328519855\n",
            "Epoch #1. Accuracy on batch 554/3013  on Training is 80.76576576576576\n",
            "Epoch #1. Accuracy on batch 555/3013  on Training is 80.78911870503597\n",
            "Epoch #1. Accuracy on batch 556/3013  on Training is 80.78433572710952\n",
            "Epoch #1. Accuracy on batch 557/3013  on Training is 80.79637096774194\n",
            "Epoch #1. Accuracy on batch 558/3013  on Training is 80.80277280858677\n",
            "Epoch #1. Accuracy on batch 559/3013  on Training is 80.82589285714286\n",
            "Batch Id 560 is having training loss of 0.7151309847831726\n",
            "1.093459963798523\n",
            "Epoch #1. Accuracy on batch 560/3013  on Training is 80.80436720142602\n",
            "Epoch #1. Accuracy on batch 561/3013  on Training is 80.78847864768683\n",
            "Epoch #1. Accuracy on batch 562/3013  on Training is 80.77819715808171\n",
            "Epoch #1. Accuracy on batch 563/3013  on Training is 80.78457446808511\n",
            "Epoch #1. Accuracy on batch 564/3013  on Training is 80.78539823008849\n",
            "Epoch #1. Accuracy on batch 565/3013  on Training is 80.78621908127208\n",
            "Epoch #1. Accuracy on batch 566/3013  on Training is 80.79805996472663\n",
            "Epoch #1. Accuracy on batch 567/3013  on Training is 80.80985915492958\n",
            "Epoch #1. Accuracy on batch 568/3013  on Training is 80.79964850615114\n",
            "Epoch #1. Accuracy on batch 569/3013  on Training is 80.80592105263158\n",
            "Epoch #1. Accuracy on batch 570/3013  on Training is 80.81217162872154\n",
            "Epoch #1. Accuracy on batch 571/3013  on Training is 80.80747377622377\n",
            "Epoch #1. Accuracy on batch 572/3013  on Training is 80.79733856893543\n",
            "Epoch #1. Accuracy on batch 573/3013  on Training is 80.79812717770035\n",
            "Epoch #1. Accuracy on batch 574/3013  on Training is 80.79891304347827\n",
            "Epoch #1. Accuracy on batch 575/3013  on Training is 80.79969618055556\n",
            "Epoch #1. Accuracy on batch 576/3013  on Training is 80.81130849220104\n",
            "Epoch #1. Accuracy on batch 577/3013  on Training is 80.79584775086505\n",
            "Epoch #1. Accuracy on batch 578/3013  on Training is 80.79663212435233\n",
            "Epoch #1. Accuracy on batch 579/3013  on Training is 80.80280172413794\n",
            "Batch Id 580 is having training loss of 0.7134333848953247\n",
            "0.6688154339790344\n",
            "Epoch #1. Accuracy on batch 580/3013  on Training is 80.79281411359725\n",
            "Epoch #1. Accuracy on batch 581/3013  on Training is 80.79896907216495\n",
            "Epoch #1. Accuracy on batch 582/3013  on Training is 80.78902229845626\n",
            "Epoch #1. Accuracy on batch 583/3013  on Training is 80.7791095890411\n",
            "Epoch #1. Accuracy on batch 584/3013  on Training is 80.77991452991454\n",
            "Epoch #1. Accuracy on batch 585/3013  on Training is 80.78071672354949\n",
            "Epoch #1. Accuracy on batch 586/3013  on Training is 80.77619250425894\n",
            "Epoch #1. Accuracy on batch 587/3013  on Training is 80.78231292517007\n",
            "Epoch #1. Accuracy on batch 588/3013  on Training is 80.76719015280136\n",
            "Epoch #1. Accuracy on batch 589/3013  on Training is 80.77330508474576\n",
            "Epoch #1. Accuracy on batch 590/3013  on Training is 80.76882402707275\n",
            "Epoch #1. Accuracy on batch 591/3013  on Training is 80.74852195945945\n",
            "Epoch #1. Accuracy on batch 592/3013  on Training is 80.73882799325463\n",
            "Epoch #1. Accuracy on batch 593/3013  on Training is 80.76599326599326\n",
            "Epoch #1. Accuracy on batch 594/3013  on Training is 80.76680672268908\n",
            "Epoch #1. Accuracy on batch 595/3013  on Training is 80.78334731543625\n",
            "Epoch #1. Accuracy on batch 596/3013  on Training is 80.7893634840871\n",
            "Epoch #1. Accuracy on batch 597/3013  on Training is 80.76923076923077\n",
            "Epoch #1. Accuracy on batch 598/3013  on Training is 80.77003338898163\n",
            "Epoch #1. Accuracy on batch 599/3013  on Training is 80.77083333333333\n",
            "Batch Id 600 is having training loss of 0.7133646011352539\n",
            "0.636406421661377\n",
            "Epoch #1. Accuracy on batch 600/3013  on Training is 80.7664309484193\n",
            "Epoch #1. Accuracy on batch 601/3013  on Training is 80.75685215946844\n",
            "Epoch #1. Accuracy on batch 602/3013  on Training is 80.75248756218906\n",
            "Epoch #1. Accuracy on batch 603/3013  on Training is 80.74296357615894\n",
            "Epoch #1. Accuracy on batch 604/3013  on Training is 80.74896694214875\n",
            "Epoch #1. Accuracy on batch 605/3013  on Training is 80.74979372937294\n",
            "Epoch #1. Accuracy on batch 606/3013  on Training is 80.75061779242175\n",
            "Epoch #1. Accuracy on batch 607/3013  on Training is 80.75657894736842\n",
            "Epoch #1. Accuracy on batch 608/3013  on Training is 80.76765188834155\n",
            "Epoch #1. Accuracy on batch 609/3013  on Training is 80.77868852459017\n",
            "Epoch #1. Accuracy on batch 610/3013  on Training is 80.79480360065466\n",
            "Epoch #1. Accuracy on batch 611/3013  on Training is 80.79554738562092\n",
            "Epoch #1. Accuracy on batch 612/3013  on Training is 80.78099510603589\n",
            "Epoch #1. Accuracy on batch 613/3013  on Training is 80.79702768729642\n",
            "Epoch #1. Accuracy on batch 614/3013  on Training is 80.8180894308943\n",
            "Epoch #1. Accuracy on batch 615/3013  on Training is 80.83400974025975\n",
            "Epoch #1. Accuracy on batch 616/3013  on Training is 80.83974878444084\n",
            "Epoch #1. Accuracy on batch 617/3013  on Training is 80.85558252427184\n",
            "Epoch #1. Accuracy on batch 618/3013  on Training is 80.85117124394183\n",
            "Epoch #1. Accuracy on batch 619/3013  on Training is 80.84677419354838\n",
            "Batch Id 620 is having training loss of 0.7108054757118225\n",
            "0.952134370803833\n",
            "Epoch #1. Accuracy on batch 620/3013  on Training is 80.847423510467\n",
            "Epoch #1. Accuracy on batch 621/3013  on Training is 80.85309485530547\n",
            "Epoch #1. Accuracy on batch 622/3013  on Training is 80.83868378812198\n",
            "Epoch #1. Accuracy on batch 623/3013  on Training is 80.85436698717949\n",
            "Epoch #1. Accuracy on batch 624/3013  on Training is 80.84\n",
            "Epoch #1. Accuracy on batch 625/3013  on Training is 80.84564696485623\n",
            "Epoch #1. Accuracy on batch 626/3013  on Training is 80.84130781499202\n",
            "Epoch #1. Accuracy on batch 627/3013  on Training is 80.84195859872611\n",
            "Epoch #1. Accuracy on batch 628/3013  on Training is 80.85254372019078\n",
            "Epoch #1. Accuracy on batch 629/3013  on Training is 80.85317460317461\n",
            "Epoch #1. Accuracy on batch 630/3013  on Training is 80.8587559429477\n",
            "Epoch #1. Accuracy on batch 631/3013  on Training is 80.85443037974683\n",
            "Epoch #1. Accuracy on batch 632/3013  on Training is 80.83530805687204\n",
            "Epoch #1. Accuracy on batch 633/3013  on Training is 80.83596214511041\n",
            "Epoch #1. Accuracy on batch 634/3013  on Training is 80.82185039370079\n",
            "Epoch #1. Accuracy on batch 635/3013  on Training is 80.7881289308176\n",
            "Epoch #1. Accuracy on batch 636/3013  on Training is 80.78885400313972\n",
            "Epoch #1. Accuracy on batch 637/3013  on Training is 80.77978056426332\n",
            "Epoch #1. Accuracy on batch 638/3013  on Training is 80.77562597809077\n",
            "Epoch #1. Accuracy on batch 639/3013  on Training is 80.78125\n",
            "Batch Id 640 is having training loss of 0.7104869484901428\n",
            "0.8522499203681946\n",
            "Epoch #1. Accuracy on batch 640/3013  on Training is 80.78685647425897\n",
            "Epoch #1. Accuracy on batch 641/3013  on Training is 80.80704828660436\n",
            "Epoch #1. Accuracy on batch 642/3013  on Training is 80.81745723172628\n",
            "Epoch #1. Accuracy on batch 643/3013  on Training is 80.78901397515529\n",
            "Epoch #1. Accuracy on batch 644/3013  on Training is 80.79941860465117\n",
            "Epoch #1. Accuracy on batch 645/3013  on Training is 80.78560371517028\n",
            "Epoch #1. Accuracy on batch 646/3013  on Training is 80.7911514683153\n",
            "Epoch #1. Accuracy on batch 647/3013  on Training is 80.79185956790124\n",
            "Epoch #1. Accuracy on batch 648/3013  on Training is 80.77330508474576\n",
            "Epoch #1. Accuracy on batch 649/3013  on Training is 80.78365384615384\n",
            "Epoch #1. Accuracy on batch 650/3013  on Training is 80.79877112135176\n",
            "Epoch #1. Accuracy on batch 651/3013  on Training is 80.79946319018404\n",
            "Epoch #1. Accuracy on batch 652/3013  on Training is 80.78101071975497\n",
            "Epoch #1. Accuracy on batch 653/3013  on Training is 80.76739296636086\n",
            "Epoch #1. Accuracy on batch 654/3013  on Training is 80.76335877862596\n",
            "Epoch #1. Accuracy on batch 655/3013  on Training is 80.7498094512195\n",
            "Epoch #1. Accuracy on batch 656/3013  on Training is 80.74581430745815\n",
            "Epoch #1. Accuracy on batch 657/3013  on Training is 80.73233282674772\n",
            "Epoch #1. Accuracy on batch 658/3013  on Training is 80.747344461305\n",
            "Epoch #1. Accuracy on batch 659/3013  on Training is 80.7528409090909\n",
            "Batch Id 660 is having training loss of 0.7107420563697815\n",
            "0.6132026314735413\n",
            "Epoch #1. Accuracy on batch 660/3013  on Training is 80.74886535552194\n",
            "Epoch #1. Accuracy on batch 661/3013  on Training is 80.7637839879154\n",
            "Epoch #1. Accuracy on batch 662/3013  on Training is 80.7645173453997\n",
            "Epoch #1. Accuracy on batch 663/3013  on Training is 80.77936746987952\n",
            "Epoch #1. Accuracy on batch 664/3013  on Training is 80.78477443609023\n",
            "Epoch #1. Accuracy on batch 665/3013  on Training is 80.77608858858859\n",
            "Epoch #1. Accuracy on batch 666/3013  on Training is 80.77679910044978\n",
            "Epoch #1. Accuracy on batch 667/3013  on Training is 80.75411676646706\n",
            "Epoch #1. Accuracy on batch 668/3013  on Training is 80.75952914798206\n",
            "Epoch #1. Accuracy on batch 669/3013  on Training is 80.75559701492537\n",
            "Epoch #1. Accuracy on batch 670/3013  on Training is 80.77961997019374\n",
            "Epoch #1. Accuracy on batch 671/3013  on Training is 80.77566964285714\n",
            "Epoch #1. Accuracy on batch 672/3013  on Training is 80.78101783060922\n",
            "Epoch #1. Accuracy on batch 673/3013  on Training is 80.77244065281899\n",
            "Epoch #1. Accuracy on batch 674/3013  on Training is 80.78703703703704\n",
            "Epoch #1. Accuracy on batch 675/3013  on Training is 80.8015902366864\n",
            "Epoch #1. Accuracy on batch 676/3013  on Training is 80.82071639586411\n",
            "Epoch #1. Accuracy on batch 677/3013  on Training is 80.81674041297936\n",
            "Epoch #1. Accuracy on batch 678/3013  on Training is 80.82198085419735\n",
            "Epoch #1. Accuracy on batch 679/3013  on Training is 80.82261029411765\n",
            "Batch Id 680 is having training loss of 0.7087729573249817\n",
            "0.5829375982284546\n",
            "Epoch #1. Accuracy on batch 680/3013  on Training is 80.8415932452276\n",
            "Epoch #1. Accuracy on batch 681/3013  on Training is 80.83302785923753\n",
            "Epoch #1. Accuracy on batch 682/3013  on Training is 80.83821376281112\n",
            "Epoch #1. Accuracy on batch 683/3013  on Training is 80.8296783625731\n",
            "Epoch #1. Accuracy on batch 684/3013  on Training is 80.84397810218978\n",
            "Epoch #1. Accuracy on batch 685/3013  on Training is 80.84001457725948\n",
            "Epoch #1. Accuracy on batch 686/3013  on Training is 80.83151382823871\n",
            "Epoch #1. Accuracy on batch 687/3013  on Training is 80.84120639534883\n",
            "Epoch #1. Accuracy on batch 688/3013  on Training is 80.85087082728592\n",
            "Epoch #1. Accuracy on batch 689/3013  on Training is 80.84692028985508\n",
            "Epoch #1. Accuracy on batch 690/3013  on Training is 80.82941389290883\n",
            "Epoch #1. Accuracy on batch 691/3013  on Training is 80.83453757225433\n",
            "Epoch #1. Accuracy on batch 692/3013  on Training is 80.81709956709956\n",
            "Epoch #1. Accuracy on batch 693/3013  on Training is 80.82222622478386\n",
            "Epoch #1. Accuracy on batch 694/3013  on Training is 80.8363309352518\n",
            "Epoch #1. Accuracy on batch 695/3013  on Training is 80.85039511494253\n",
            "Epoch #1. Accuracy on batch 696/3013  on Training is 80.85993543758967\n",
            "Epoch #1. Accuracy on batch 697/3013  on Training is 80.88287965616045\n",
            "Epoch #1. Accuracy on batch 698/3013  on Training is 80.88340486409156\n",
            "Epoch #1. Accuracy on batch 699/3013  on Training is 80.88839285714286\n",
            "Batch Id 700 is having training loss of 0.7077316045761108\n",
            "0.745872437953949\n",
            "Epoch #1. Accuracy on batch 700/3013  on Training is 80.87999286733238\n",
            "Epoch #1. Accuracy on batch 701/3013  on Training is 80.87161680911682\n",
            "Epoch #1. Accuracy on batch 702/3013  on Training is 80.87215504978663\n",
            "Epoch #1. Accuracy on batch 703/3013  on Training is 80.8682528409091\n",
            "Epoch #1. Accuracy on batch 704/3013  on Training is 80.8377659574468\n",
            "Epoch #1. Accuracy on batch 705/3013  on Training is 80.82949716713881\n",
            "Epoch #1. Accuracy on batch 706/3013  on Training is 80.83451202263083\n",
            "Epoch #1. Accuracy on batch 707/3013  on Training is 80.83068502824858\n",
            "Epoch #1. Accuracy on batch 708/3013  on Training is 80.84890691114245\n",
            "Epoch #1. Accuracy on batch 709/3013  on Training is 80.86267605633803\n",
            "Epoch #1. Accuracy on batch 710/3013  on Training is 80.88080168776371\n",
            "Epoch #1. Accuracy on batch 711/3013  on Training is 80.88570926966293\n",
            "Epoch #1. Accuracy on batch 712/3013  on Training is 80.90375175315567\n",
            "Epoch #1. Accuracy on batch 713/3013  on Training is 80.91299019607843\n",
            "Epoch #1. Accuracy on batch 714/3013  on Training is 80.90034965034965\n",
            "Epoch #1. Accuracy on batch 715/3013  on Training is 80.89210893854748\n",
            "Epoch #1. Accuracy on batch 716/3013  on Training is 80.9013249651325\n",
            "Epoch #1. Accuracy on batch 717/3013  on Training is 80.87569637883009\n",
            "Epoch #1. Accuracy on batch 718/3013  on Training is 80.88056328233658\n",
            "Epoch #1. Accuracy on batch 719/3013  on Training is 80.87673611111111\n",
            "Batch Id 720 is having training loss of 0.706475555896759\n",
            "0.5281315445899963\n",
            "Epoch #1. Accuracy on batch 720/3013  on Training is 80.87725381414702\n",
            "Epoch #1. Accuracy on batch 721/3013  on Training is 80.88642659279779\n",
            "Epoch #1. Accuracy on batch 722/3013  on Training is 80.89125172890733\n",
            "Epoch #1. Accuracy on batch 723/3013  on Training is 80.89606353591161\n",
            "Epoch #1. Accuracy on batch 724/3013  on Training is 80.90517241379311\n",
            "Epoch #1. Accuracy on batch 725/3013  on Training is 80.90564738292011\n",
            "Epoch #1. Accuracy on batch 726/3013  on Training is 80.90182255845943\n",
            "Epoch #1. Accuracy on batch 727/3013  on Training is 80.91517857142857\n",
            "Epoch #1. Accuracy on batch 728/3013  on Training is 80.91992455418381\n",
            "Epoch #1. Accuracy on batch 729/3013  on Training is 80.92465753424658\n",
            "Epoch #1. Accuracy on batch 730/3013  on Training is 80.92510259917921\n",
            "Epoch #1. Accuracy on batch 731/3013  on Training is 80.90420081967213\n",
            "Epoch #1. Accuracy on batch 732/3013  on Training is 80.88761937244202\n",
            "Epoch #1. Accuracy on batch 733/3013  on Training is 80.89237057220708\n",
            "Epoch #1. Accuracy on batch 734/3013  on Training is 80.89710884353741\n",
            "Epoch #1. Accuracy on batch 735/3013  on Training is 80.90183423913044\n",
            "Epoch #1. Accuracy on batch 736/3013  on Training is 80.91502713704206\n",
            "Epoch #1. Accuracy on batch 737/3013  on Training is 80.9154810298103\n",
            "Epoch #1. Accuracy on batch 738/3013  on Training is 80.93284844384303\n",
            "Epoch #1. Accuracy on batch 739/3013  on Training is 80.93327702702703\n",
            "Batch Id 740 is having training loss of 0.7043191194534302\n",
            "0.5602943897247314\n",
            "Epoch #1. Accuracy on batch 740/3013  on Training is 80.9379217273954\n",
            "Epoch #1. Accuracy on batch 741/3013  on Training is 80.9341307277628\n",
            "Epoch #1. Accuracy on batch 742/3013  on Training is 80.93034993270525\n",
            "Epoch #1. Accuracy on batch 743/3013  on Training is 80.92657930107526\n",
            "Epoch #1. Accuracy on batch 744/3013  on Training is 80.92281879194631\n",
            "Epoch #1. Accuracy on batch 745/3013  on Training is 80.93163538873995\n",
            "Epoch #1. Accuracy on batch 746/3013  on Training is 80.93206157965194\n",
            "Epoch #1. Accuracy on batch 747/3013  on Training is 80.9283088235294\n",
            "Epoch #1. Accuracy on batch 748/3013  on Training is 80.92456608811749\n",
            "Epoch #1. Accuracy on batch 749/3013  on Training is 80.925\n",
            "Epoch #1. Accuracy on batch 750/3013  on Training is 80.91711051930758\n",
            "Epoch #1. Accuracy on batch 751/3013  on Training is 80.9092420212766\n",
            "Epoch #1. Accuracy on batch 752/3013  on Training is 80.92214475431607\n",
            "Epoch #1. Accuracy on batch 753/3013  on Training is 80.92257957559681\n",
            "Epoch #1. Accuracy on batch 754/3013  on Training is 80.91059602649007\n",
            "Epoch #1. Accuracy on batch 755/3013  on Training is 80.90277777777777\n",
            "Epoch #1. Accuracy on batch 756/3013  on Training is 80.91974900924703\n",
            "Epoch #1. Accuracy on batch 757/3013  on Training is 80.91606200527704\n",
            "Epoch #1. Accuracy on batch 758/3013  on Training is 80.93297101449275\n",
            "Epoch #1. Accuracy on batch 759/3013  on Training is 80.94161184210526\n",
            "Batch Id 760 is having training loss of 0.7031573057174683\n",
            "0.5589462518692017\n",
            "Epoch #1. Accuracy on batch 760/3013  on Training is 80.946123521682\n",
            "Epoch #1. Accuracy on batch 761/3013  on Training is 80.93832020997375\n",
            "Epoch #1. Accuracy on batch 762/3013  on Training is 80.94692005242464\n",
            "Epoch #1. Accuracy on batch 763/3013  on Training is 80.95958769633508\n",
            "Epoch #1. Accuracy on batch 764/3013  on Training is 80.9640522875817\n",
            "Epoch #1. Accuracy on batch 765/3013  on Training is 80.96442558746736\n",
            "Epoch #1. Accuracy on batch 766/3013  on Training is 80.95664928292047\n",
            "Epoch #1. Accuracy on batch 767/3013  on Training is 80.95296223958333\n",
            "Epoch #1. Accuracy on batch 768/3013  on Training is 80.9574122236671\n",
            "Epoch #1. Accuracy on batch 769/3013  on Training is 80.95779220779221\n",
            "Epoch #1. Accuracy on batch 770/3013  on Training is 80.96222438391699\n",
            "Epoch #1. Accuracy on batch 771/3013  on Training is 80.95045336787565\n",
            "Epoch #1. Accuracy on batch 772/3013  on Training is 80.96296895213455\n",
            "Epoch #1. Accuracy on batch 773/3013  on Training is 80.95526485788113\n",
            "Epoch #1. Accuracy on batch 774/3013  on Training is 80.9475806451613\n",
            "Epoch #1. Accuracy on batch 775/3013  on Training is 80.96005154639175\n",
            "Epoch #1. Accuracy on batch 776/3013  on Training is 80.95238095238095\n",
            "Epoch #1. Accuracy on batch 777/3013  on Training is 80.94071336760925\n",
            "Epoch #1. Accuracy on batch 778/3013  on Training is 80.93308729139923\n",
            "Epoch #1. Accuracy on batch 779/3013  on Training is 80.94551282051282\n",
            "Batch Id 780 is having training loss of 0.7032803893089294\n",
            "0.8568515181541443\n",
            "Epoch #1. Accuracy on batch 780/3013  on Training is 80.94990396927017\n",
            "Epoch #1. Accuracy on batch 781/3013  on Training is 80.93829923273657\n",
            "Epoch #1. Accuracy on batch 782/3013  on Training is 80.94268837803321\n",
            "Epoch #1. Accuracy on batch 783/3013  on Training is 80.93510841836735\n",
            "Epoch #1. Accuracy on batch 784/3013  on Training is 80.93550955414013\n",
            "Epoch #1. Accuracy on batch 785/3013  on Training is 80.94386132315522\n",
            "Epoch #1. Accuracy on batch 786/3013  on Training is 80.94425031766201\n",
            "Epoch #1. Accuracy on batch 787/3013  on Training is 80.9446383248731\n",
            "Epoch #1. Accuracy on batch 788/3013  on Training is 80.94106463878327\n",
            "Epoch #1. Accuracy on batch 789/3013  on Training is 80.9493670886076\n",
            "Epoch #1. Accuracy on batch 790/3013  on Training is 80.94974715549937\n",
            "Epoch #1. Accuracy on batch 791/3013  on Training is 80.93828914141415\n",
            "Epoch #1. Accuracy on batch 792/3013  on Training is 80.94262295081967\n",
            "Epoch #1. Accuracy on batch 793/3013  on Training is 80.95481738035265\n",
            "Epoch #1. Accuracy on batch 794/3013  on Training is 80.95125786163523\n",
            "Epoch #1. Accuracy on batch 795/3013  on Training is 80.93985552763819\n",
            "Epoch #1. Accuracy on batch 796/3013  on Training is 80.95200752823087\n",
            "Epoch #1. Accuracy on batch 797/3013  on Training is 80.9328007518797\n",
            "Epoch #1. Accuracy on batch 798/3013  on Training is 80.91755319148936\n",
            "Epoch #1. Accuracy on batch 799/3013  on Training is 80.8984375\n",
            "Batch Id 800 is having training loss of 0.7043687105178833\n",
            "0.9476621150970459\n",
            "Epoch #1. Accuracy on batch 800/3013  on Training is 80.89497503121099\n",
            "Epoch #1. Accuracy on batch 801/3013  on Training is 80.8876246882793\n",
            "Epoch #1. Accuracy on batch 802/3013  on Training is 80.88807596513075\n",
            "Epoch #1. Accuracy on batch 803/3013  on Training is 80.89241293532338\n",
            "Epoch #1. Accuracy on batch 804/3013  on Training is 80.90062111801242\n",
            "Epoch #1. Accuracy on batch 805/3013  on Training is 80.90880893300248\n",
            "Epoch #1. Accuracy on batch 806/3013  on Training is 80.90923172242874\n",
            "Epoch #1. Accuracy on batch 807/3013  on Training is 80.91738861386139\n",
            "Epoch #1. Accuracy on batch 808/3013  on Training is 80.93325092707046\n",
            "Epoch #1. Accuracy on batch 809/3013  on Training is 80.95293209876543\n",
            "Epoch #1. Accuracy on batch 810/3013  on Training is 80.94173859432799\n",
            "Epoch #1. Accuracy on batch 811/3013  on Training is 80.94211822660098\n",
            "Epoch #1. Accuracy on batch 812/3013  on Training is 80.94634071340714\n",
            "Epoch #1. Accuracy on batch 813/3013  on Training is 80.94671375921376\n",
            "Epoch #1. Accuracy on batch 814/3013  on Training is 80.92791411042944\n",
            "Epoch #1. Accuracy on batch 815/3013  on Training is 80.91299019607843\n",
            "Epoch #1. Accuracy on batch 816/3013  on Training is 80.92105263157895\n",
            "Epoch #1. Accuracy on batch 817/3013  on Training is 80.92909535452323\n",
            "Epoch #1. Accuracy on batch 818/3013  on Training is 80.94093406593407\n",
            "Epoch #1. Accuracy on batch 819/3013  on Training is 80.95655487804878\n",
            "Batch Id 820 is having training loss of 0.7024082541465759\n",
            "0.44808506965637207\n",
            "Epoch #1. Accuracy on batch 820/3013  on Training is 80.97213763702801\n",
            "Epoch #1. Accuracy on batch 821/3013  on Training is 80.96867396593674\n",
            "Epoch #1. Accuracy on batch 822/3013  on Training is 80.97281287970839\n",
            "Epoch #1. Accuracy on batch 823/3013  on Training is 80.98831917475728\n",
            "Epoch #1. Accuracy on batch 824/3013  on Training is 81.0\n",
            "Epoch #1. Accuracy on batch 825/3013  on Training is 80.99651937046005\n",
            "Epoch #1. Accuracy on batch 826/3013  on Training is 81.0006045949214\n",
            "Epoch #1. Accuracy on batch 827/3013  on Training is 81.00090579710145\n",
            "Epoch #1. Accuracy on batch 828/3013  on Training is 80.9898974668275\n",
            "Epoch #1. Accuracy on batch 829/3013  on Training is 80.99774096385542\n",
            "Epoch #1. Accuracy on batch 830/3013  on Training is 80.99804452466907\n",
            "Epoch #1. Accuracy on batch 831/3013  on Training is 81.00210336538461\n",
            "Epoch #1. Accuracy on batch 832/3013  on Training is 81.00240096038415\n",
            "Epoch #1. Accuracy on batch 833/3013  on Training is 81.00269784172662\n",
            "Epoch #1. Accuracy on batch 834/3013  on Training is 81.00673652694611\n",
            "Epoch #1. Accuracy on batch 835/3013  on Training is 80.99581339712918\n",
            "Epoch #1. Accuracy on batch 836/3013  on Training is 80.98118279569893\n",
            "Epoch #1. Accuracy on batch 837/3013  on Training is 80.98523269689737\n",
            "Epoch #1. Accuracy on batch 838/3013  on Training is 80.97437425506556\n",
            "Epoch #1. Accuracy on batch 839/3013  on Training is 80.96354166666667\n",
            "Batch Id 840 is having training loss of 0.7022536993026733\n",
            "0.7794469594955444\n",
            "Epoch #1. Accuracy on batch 840/3013  on Training is 80.96016646848989\n",
            "Epoch #1. Accuracy on batch 841/3013  on Training is 80.95679928741093\n",
            "Epoch #1. Accuracy on batch 842/3013  on Training is 80.95714709371293\n",
            "Epoch #1. Accuracy on batch 843/3013  on Training is 80.96489928909952\n",
            "Epoch #1. Accuracy on batch 844/3013  on Training is 80.97263313609467\n",
            "Epoch #1. Accuracy on batch 845/3013  on Training is 80.96926713947991\n",
            "Epoch #1. Accuracy on batch 846/3013  on Training is 80.96221959858323\n",
            "Epoch #1. Accuracy on batch 847/3013  on Training is 80.96992924528301\n",
            "Epoch #1. Accuracy on batch 848/3013  on Training is 80.97025912838633\n",
            "Epoch #1. Accuracy on batch 849/3013  on Training is 80.98161764705883\n",
            "Epoch #1. Accuracy on batch 850/3013  on Training is 80.97826086956522\n",
            "Epoch #1. Accuracy on batch 851/3013  on Training is 80.98224765258216\n",
            "Epoch #1. Accuracy on batch 852/3013  on Training is 80.97523446658852\n",
            "Epoch #1. Accuracy on batch 853/3013  on Training is 80.975556206089\n",
            "Epoch #1. Accuracy on batch 854/3013  on Training is 80.97222222222223\n",
            "Epoch #1. Accuracy on batch 855/3013  on Training is 80.97254672897196\n",
            "Epoch #1. Accuracy on batch 856/3013  on Training is 80.96922403733956\n",
            "Epoch #1. Accuracy on batch 857/3013  on Training is 80.97683566433567\n",
            "Epoch #1. Accuracy on batch 858/3013  on Training is 80.98079161816065\n",
            "Epoch #1. Accuracy on batch 859/3013  on Training is 80.98837209302326\n",
            "Batch Id 860 is having training loss of 0.702178955078125\n",
            "0.8842981457710266\n",
            "Epoch #1. Accuracy on batch 860/3013  on Training is 80.98867595818815\n",
            "Epoch #1. Accuracy on batch 861/3013  on Training is 81.00710556844548\n",
            "Epoch #1. Accuracy on batch 862/3013  on Training is 80.98928157589803\n",
            "Epoch #1. Accuracy on batch 863/3013  on Training is 80.99320023148148\n",
            "Epoch #1. Accuracy on batch 864/3013  on Training is 80.98988439306359\n",
            "Epoch #1. Accuracy on batch 865/3013  on Training is 80.99379330254041\n",
            "Epoch #1. Accuracy on batch 866/3013  on Training is 80.98327566320646\n",
            "Epoch #1. Accuracy on batch 867/3013  on Training is 80.98358294930875\n",
            "Epoch #1. Accuracy on batch 868/3013  on Training is 80.97310126582279\n",
            "Epoch #1. Accuracy on batch 869/3013  on Training is 80.98778735632185\n",
            "Epoch #1. Accuracy on batch 870/3013  on Training is 80.98808840413318\n",
            "Epoch #1. Accuracy on batch 871/3013  on Training is 80.98480504587155\n",
            "Epoch #1. Accuracy on batch 872/3013  on Training is 80.98510882016036\n",
            "Epoch #1. Accuracy on batch 873/3013  on Training is 80.98898741418765\n",
            "Epoch #1. Accuracy on batch 874/3013  on Training is 80.98928571428571\n",
            "Epoch #1. Accuracy on batch 875/3013  on Training is 80.99671803652969\n",
            "Epoch #1. Accuracy on batch 876/3013  on Training is 80.99344355758267\n",
            "Epoch #1. Accuracy on batch 877/3013  on Training is 80.9866173120729\n",
            "Epoch #1. Accuracy on batch 878/3013  on Training is 80.98691695108077\n",
            "Epoch #1. Accuracy on batch 879/3013  on Training is 80.9659090909091\n",
            "Batch Id 880 is having training loss of 0.701434314250946\n",
            "0.6106675863265991\n",
            "Epoch #1. Accuracy on batch 880/3013  on Training is 80.97687287173666\n",
            "Epoch #1. Accuracy on batch 881/3013  on Training is 80.97718253968254\n",
            "Epoch #1. Accuracy on batch 882/3013  on Training is 80.97749150622876\n",
            "Epoch #1. Accuracy on batch 883/3013  on Training is 80.97426470588235\n",
            "Epoch #1. Accuracy on batch 884/3013  on Training is 80.98516949152543\n",
            "Epoch #1. Accuracy on batch 885/3013  on Training is 80.9854683972912\n",
            "Epoch #1. Accuracy on batch 886/3013  on Training is 80.99633596392334\n",
            "Epoch #1. Accuracy on batch 887/3013  on Training is 80.9860641891892\n",
            "Epoch #1. Accuracy on batch 888/3013  on Training is 80.99690663667042\n",
            "Epoch #1. Accuracy on batch 889/3013  on Training is 81.00070224719101\n",
            "Epoch #1. Accuracy on batch 890/3013  on Training is 81.00448933782268\n",
            "Epoch #1. Accuracy on batch 891/3013  on Training is 81.01177130044843\n",
            "Epoch #1. Accuracy on batch 892/3013  on Training is 81.01203807390817\n",
            "Epoch #1. Accuracy on batch 893/3013  on Training is 81.00880872483222\n",
            "Epoch #1. Accuracy on batch 894/3013  on Training is 81.00558659217877\n",
            "Epoch #1. Accuracy on batch 895/3013  on Training is 81.005859375\n",
            "Epoch #1. Accuracy on batch 896/3013  on Training is 81.0200668896321\n",
            "Epoch #1. Accuracy on batch 897/3013  on Training is 81.0168429844098\n",
            "Epoch #1. Accuracy on batch 898/3013  on Training is 81.01362625139043\n",
            "Epoch #1. Accuracy on batch 899/3013  on Training is 81.0\n",
            "Batch Id 900 is having training loss of 0.7003835439682007\n",
            "0.7634370923042297\n",
            "Epoch #1. Accuracy on batch 900/3013  on Training is 80.99680910099889\n",
            "Epoch #1. Accuracy on batch 901/3013  on Training is 80.99016075388026\n",
            "Epoch #1. Accuracy on batch 902/3013  on Training is 81.00083056478405\n",
            "Epoch #1. Accuracy on batch 903/3013  on Training is 81.00456305309734\n",
            "Epoch #1. Accuracy on batch 904/3013  on Training is 80.99792817679558\n",
            "Epoch #1. Accuracy on batch 905/3013  on Training is 81.00165562913908\n",
            "Epoch #1. Accuracy on batch 906/3013  on Training is 81.00192943770672\n",
            "Epoch #1. Accuracy on batch 907/3013  on Training is 81.0090859030837\n",
            "Epoch #1. Accuracy on batch 908/3013  on Training is 81.01278877887789\n",
            "Epoch #1. Accuracy on batch 909/3013  on Training is 81.01304945054945\n",
            "Epoch #1. Accuracy on batch 910/3013  on Training is 81.0098792535675\n",
            "Epoch #1. Accuracy on batch 911/3013  on Training is 81.00671600877193\n",
            "Epoch #1. Accuracy on batch 912/3013  on Training is 81.01725082146768\n",
            "Epoch #1. Accuracy on batch 913/3013  on Training is 81.02092450765865\n",
            "Epoch #1. Accuracy on batch 914/3013  on Training is 81.02459016393442\n",
            "Epoch #1. Accuracy on batch 915/3013  on Training is 81.03507096069869\n",
            "Epoch #1. Accuracy on batch 916/3013  on Training is 81.02508178844057\n",
            "Epoch #1. Accuracy on batch 917/3013  on Training is 81.02532679738562\n",
            "Epoch #1. Accuracy on batch 918/3013  on Training is 81.02217083786725\n",
            "Epoch #1. Accuracy on batch 919/3013  on Training is 81.01902173913044\n",
            "Batch Id 920 is having training loss of 0.6992928981781006\n",
            "0.5516685247421265\n",
            "Epoch #1. Accuracy on batch 920/3013  on Training is 81.02266558089033\n",
            "Epoch #1. Accuracy on batch 921/3013  on Training is 81.03308026030369\n",
            "Epoch #1. Accuracy on batch 922/3013  on Training is 81.03670097508126\n",
            "Epoch #1. Accuracy on batch 923/3013  on Training is 81.03354978354979\n",
            "Epoch #1. Accuracy on batch 924/3013  on Training is 81.03378378378379\n",
            "Epoch #1. Accuracy on batch 925/3013  on Training is 81.03401727861771\n",
            "Epoch #1. Accuracy on batch 926/3013  on Training is 81.01739482200647\n",
            "Epoch #1. Accuracy on batch 927/3013  on Training is 81.02101293103448\n",
            "Epoch #1. Accuracy on batch 928/3013  on Training is 81.03135091496233\n",
            "Epoch #1. Accuracy on batch 929/3013  on Training is 81.02822580645162\n",
            "Epoch #1. Accuracy on batch 930/3013  on Training is 81.01839419978518\n",
            "Epoch #1. Accuracy on batch 931/3013  on Training is 81.00858369098712\n",
            "Epoch #1. Accuracy on batch 932/3013  on Training is 81.00549303322616\n",
            "Epoch #1. Accuracy on batch 933/3013  on Training is 81.00575481798715\n",
            "Epoch #1. Accuracy on batch 934/3013  on Training is 80.99933155080214\n",
            "Epoch #1. Accuracy on batch 935/3013  on Training is 80.98958333333333\n",
            "Epoch #1. Accuracy on batch 936/3013  on Training is 80.97652081109925\n",
            "Epoch #1. Accuracy on batch 937/3013  on Training is 80.97348081023455\n",
            "Epoch #1. Accuracy on batch 938/3013  on Training is 80.97044728434504\n",
            "Epoch #1. Accuracy on batch 939/3013  on Training is 80.97406914893617\n",
            "Batch Id 940 is having training loss of 0.7003821134567261\n",
            "0.915582001209259\n",
            "Epoch #1. Accuracy on batch 940/3013  on Training is 80.97768331562168\n",
            "Epoch #1. Accuracy on batch 941/3013  on Training is 80.97797239915074\n",
            "Epoch #1. Accuracy on batch 942/3013  on Training is 80.98157476139978\n",
            "Epoch #1. Accuracy on batch 943/3013  on Training is 80.98516949152543\n",
            "Epoch #1. Accuracy on batch 944/3013  on Training is 80.97883597883597\n",
            "Epoch #1. Accuracy on batch 945/3013  on Training is 80.9659090909091\n",
            "Epoch #1. Accuracy on batch 946/3013  on Training is 80.9662090813094\n",
            "Epoch #1. Accuracy on batch 947/3013  on Training is 80.96980485232068\n",
            "Epoch #1. Accuracy on batch 948/3013  on Training is 80.97668598524763\n",
            "Epoch #1. Accuracy on batch 949/3013  on Training is 80.97697368421052\n",
            "Epoch #1. Accuracy on batch 950/3013  on Training is 80.97726077812828\n",
            "Epoch #1. Accuracy on batch 951/3013  on Training is 80.96441701680672\n",
            "Epoch #1. Accuracy on batch 952/3013  on Training is 80.9647166841553\n",
            "Epoch #1. Accuracy on batch 953/3013  on Training is 80.96829140461216\n",
            "Epoch #1. Accuracy on batch 954/3013  on Training is 80.95549738219896\n",
            "Epoch #1. Accuracy on batch 955/3013  on Training is 80.95253661087867\n",
            "Epoch #1. Accuracy on batch 956/3013  on Training is 80.94305120167189\n",
            "Epoch #1. Accuracy on batch 957/3013  on Training is 80.94010960334029\n",
            "Epoch #1. Accuracy on batch 958/3013  on Training is 80.94043274244004\n",
            "Epoch #1. Accuracy on batch 959/3013  on Training is 80.9375\n",
            "Batch Id 960 is having training loss of 0.7009307742118835\n",
            "0.5408042669296265\n",
            "Epoch #1. Accuracy on batch 960/3013  on Training is 80.93782518210197\n",
            "Epoch #1. Accuracy on batch 961/3013  on Training is 80.92840436590437\n",
            "Epoch #1. Accuracy on batch 962/3013  on Training is 80.92873831775701\n",
            "Epoch #1. Accuracy on batch 963/3013  on Training is 80.93555497925311\n",
            "Epoch #1. Accuracy on batch 964/3013  on Training is 80.92292746113989\n",
            "Epoch #1. Accuracy on batch 965/3013  on Training is 80.92003105590062\n",
            "Epoch #1. Accuracy on batch 966/3013  on Training is 80.92683557394002\n",
            "Epoch #1. Accuracy on batch 967/3013  on Training is 80.91748450413223\n",
            "Epoch #1. Accuracy on batch 968/3013  on Training is 80.91137770897832\n",
            "Epoch #1. Accuracy on batch 969/3013  on Training is 80.90528350515464\n",
            "Epoch #1. Accuracy on batch 970/3013  on Training is 80.91207518022657\n",
            "Epoch #1. Accuracy on batch 971/3013  on Training is 80.9059927983539\n",
            "Epoch #1. Accuracy on batch 972/3013  on Training is 80.91276978417267\n",
            "Epoch #1. Accuracy on batch 973/3013  on Training is 80.91632443531827\n",
            "Epoch #1. Accuracy on batch 974/3013  on Training is 80.92948717948718\n",
            "Epoch #1. Accuracy on batch 975/3013  on Training is 80.92661372950819\n",
            "Epoch #1. Accuracy on batch 976/3013  on Training is 80.93654042988742\n",
            "Epoch #1. Accuracy on batch 977/3013  on Training is 80.93366564417178\n",
            "Epoch #1. Accuracy on batch 978/3013  on Training is 80.92122063329928\n",
            "Epoch #1. Accuracy on batch 979/3013  on Training is 80.92474489795919\n",
            "Batch Id 980 is having training loss of 0.7012277841567993\n",
            "0.7056325674057007\n",
            "Epoch #1. Accuracy on batch 980/3013  on Training is 80.92507645259938\n",
            "Epoch #1. Accuracy on batch 981/3013  on Training is 80.91904276985743\n",
            "Epoch #1. Accuracy on batch 982/3013  on Training is 80.92255849440488\n",
            "Epoch #1. Accuracy on batch 983/3013  on Training is 80.9133638211382\n",
            "Epoch #1. Accuracy on batch 984/3013  on Training is 80.9232233502538\n",
            "Epoch #1. Accuracy on batch 985/3013  on Training is 80.92038539553752\n",
            "Epoch #1. Accuracy on batch 986/3013  on Training is 80.91122087132726\n",
            "Epoch #1. Accuracy on batch 987/3013  on Training is 80.89891194331983\n",
            "Epoch #1. Accuracy on batch 988/3013  on Training is 80.89610717896865\n",
            "Epoch #1. Accuracy on batch 989/3013  on Training is 80.89962121212122\n",
            "Epoch #1. Accuracy on batch 990/3013  on Training is 80.89366801210898\n",
            "Epoch #1. Accuracy on batch 991/3013  on Training is 80.89717741935483\n",
            "Epoch #1. Accuracy on batch 992/3013  on Training is 80.88809164149043\n",
            "Epoch #1. Accuracy on batch 993/3013  on Training is 80.90103118712274\n",
            "Epoch #1. Accuracy on batch 994/3013  on Training is 80.90138190954774\n",
            "Epoch #1. Accuracy on batch 995/3013  on Training is 80.90486947791165\n",
            "Epoch #1. Accuracy on batch 996/3013  on Training is 80.89581243731193\n",
            "Epoch #1. Accuracy on batch 997/3013  on Training is 80.88990480961924\n",
            "Epoch #1. Accuracy on batch 998/3013  on Training is 80.89026526526527\n",
            "Epoch #1. Accuracy on batch 999/3013  on Training is 80.884375\n",
            "Batch Id 1000 is having training loss of 0.7017252445220947\n",
            "0.6406978368759155\n",
            "Epoch #1. Accuracy on batch 1000/3013  on Training is 80.88161838161838\n",
            "Epoch #1. Accuracy on batch 1001/3013  on Training is 80.87886726546907\n",
            "Epoch #1. Accuracy on batch 1002/3013  on Training is 80.87612163509472\n",
            "Epoch #1. Accuracy on batch 1003/3013  on Training is 80.87026892430279\n",
            "Epoch #1. Accuracy on batch 1004/3013  on Training is 80.86753731343283\n",
            "Epoch #1. Accuracy on batch 1005/3013  on Training is 80.87102385685884\n",
            "Epoch #1. Accuracy on batch 1006/3013  on Training is 80.88071002979146\n",
            "Epoch #1. Accuracy on batch 1007/3013  on Training is 80.88107638888889\n",
            "Epoch #1. Accuracy on batch 1008/3013  on Training is 80.88144202180376\n",
            "Epoch #1. Accuracy on batch 1009/3013  on Training is 80.87561881188118\n",
            "Epoch #1. Accuracy on batch 1010/3013  on Training is 80.87908011869436\n",
            "Epoch #1. Accuracy on batch 1011/3013  on Training is 80.88253458498023\n",
            "Epoch #1. Accuracy on batch 1012/3013  on Training is 80.88906712734452\n",
            "Epoch #1. Accuracy on batch 1013/3013  on Training is 80.8801775147929\n",
            "Epoch #1. Accuracy on batch 1014/3013  on Training is 80.87746305418719\n",
            "Epoch #1. Accuracy on batch 1015/3013  on Training is 80.88398129921259\n",
            "Epoch #1. Accuracy on batch 1016/3013  on Training is 80.88741396263521\n",
            "Epoch #1. Accuracy on batch 1017/3013  on Training is 80.89083988212181\n",
            "Epoch #1. Accuracy on batch 1018/3013  on Training is 80.89425907752698\n",
            "Epoch #1. Accuracy on batch 1019/3013  on Training is 80.89154411764706\n",
            "Batch Id 1020 is having training loss of 0.7020838856697083\n",
            "0.5765679478645325\n",
            "Epoch #1. Accuracy on batch 1020/3013  on Training is 80.8980166503428\n",
            "Epoch #1. Accuracy on batch 1021/3013  on Training is 80.89530332681018\n",
            "Epoch #1. Accuracy on batch 1022/3013  on Training is 80.89565004887585\n",
            "Epoch #1. Accuracy on batch 1023/3013  on Training is 80.889892578125\n",
            "Epoch #1. Accuracy on batch 1024/3013  on Training is 80.89024390243902\n",
            "Epoch #1. Accuracy on batch 1025/3013  on Training is 80.89364035087719\n",
            "Epoch #1. Accuracy on batch 1026/3013  on Training is 80.89398734177215\n",
            "Epoch #1. Accuracy on batch 1027/3013  on Training is 80.90041342412451\n",
            "Epoch #1. Accuracy on batch 1028/3013  on Training is 80.90379008746356\n",
            "Epoch #1. Accuracy on batch 1029/3013  on Training is 80.90716019417475\n",
            "Epoch #1. Accuracy on batch 1030/3013  on Training is 80.92264791464598\n",
            "Epoch #1. Accuracy on batch 1031/3013  on Training is 80.92902131782945\n",
            "Epoch #1. Accuracy on batch 1032/3013  on Training is 80.9263068731849\n",
            "Epoch #1. Accuracy on batch 1033/3013  on Training is 80.93568665377175\n",
            "Epoch #1. Accuracy on batch 1034/3013  on Training is 80.93900966183575\n",
            "Epoch #1. Accuracy on batch 1035/3013  on Training is 80.92121138996139\n",
            "Epoch #1. Accuracy on batch 1036/3013  on Training is 80.91550144648023\n",
            "Epoch #1. Accuracy on batch 1037/3013  on Training is 80.92184489402698\n",
            "Epoch #1. Accuracy on batch 1038/3013  on Training is 80.90712223291627\n",
            "Epoch #1. Accuracy on batch 1039/3013  on Training is 80.91045673076923\n",
            "Batch Id 1040 is having training loss of 0.7017382979393005\n",
            "0.8796424865722656\n",
            "Epoch #1. Accuracy on batch 1040/3013  on Training is 80.9047790585975\n",
            "Epoch #1. Accuracy on batch 1041/3013  on Training is 80.9141074856046\n",
            "Epoch #1. Accuracy on batch 1042/3013  on Training is 80.91442953020135\n",
            "Epoch #1. Accuracy on batch 1043/3013  on Training is 80.92073754789271\n",
            "Epoch #1. Accuracy on batch 1044/3013  on Training is 80.92105263157895\n",
            "Epoch #1. Accuracy on batch 1045/3013  on Training is 80.93032982791587\n",
            "Epoch #1. Accuracy on batch 1046/3013  on Training is 80.93063514804203\n",
            "Epoch #1. Accuracy on batch 1047/3013  on Training is 80.9369036259542\n",
            "Epoch #1. Accuracy on batch 1048/3013  on Training is 80.94018112488084\n",
            "Epoch #1. Accuracy on batch 1049/3013  on Training is 80.95238095238095\n",
            "Epoch #1. Accuracy on batch 1050/3013  on Training is 80.95861084681256\n",
            "Epoch #1. Accuracy on batch 1051/3013  on Training is 80.96185836501901\n",
            "Epoch #1. Accuracy on batch 1052/3013  on Training is 80.95322886989554\n",
            "Epoch #1. Accuracy on batch 1053/3013  on Training is 80.96537001897534\n",
            "Epoch #1. Accuracy on batch 1054/3013  on Training is 80.98045023696683\n",
            "Epoch #1. Accuracy on batch 1055/3013  on Training is 80.98958333333333\n",
            "Epoch #1. Accuracy on batch 1056/3013  on Training is 80.98096026490066\n",
            "Epoch #1. Accuracy on batch 1057/3013  on Training is 80.98416824196597\n",
            "Epoch #1. Accuracy on batch 1058/3013  on Training is 80.98441926345609\n",
            "Epoch #1. Accuracy on batch 1059/3013  on Training is 80.98761792452831\n",
            "Batch Id 1060 is having training loss of 0.6999953985214233\n",
            "0.6181688904762268\n",
            "Epoch #1. Accuracy on batch 1060/3013  on Training is 80.99081055607917\n",
            "Epoch #1. Accuracy on batch 1061/3013  on Training is 81.00282485875707\n",
            "Epoch #1. Accuracy on batch 1062/3013  on Training is 80.99717779868297\n",
            "Epoch #1. Accuracy on batch 1063/3013  on Training is 80.99447838345864\n",
            "Epoch #1. Accuracy on batch 1064/3013  on Training is 80.99178403755869\n",
            "Epoch #1. Accuracy on batch 1065/3013  on Training is 80.99495778611632\n",
            "Epoch #1. Accuracy on batch 1066/3013  on Training is 80.98641049671977\n",
            "Epoch #1. Accuracy on batch 1067/3013  on Training is 80.97787921348315\n",
            "Epoch #1. Accuracy on batch 1068/3013  on Training is 80.9810570626754\n",
            "Epoch #1. Accuracy on batch 1069/3013  on Training is 80.98422897196262\n",
            "Epoch #1. Accuracy on batch 1070/3013  on Training is 80.984477124183\n",
            "Epoch #1. Accuracy on batch 1071/3013  on Training is 80.98763992537313\n",
            "Epoch #1. Accuracy on batch 1072/3013  on Training is 80.99370922646784\n",
            "Epoch #1. Accuracy on batch 1073/3013  on Training is 80.99103817504655\n",
            "Epoch #1. Accuracy on batch 1074/3013  on Training is 80.99418604651163\n",
            "Epoch #1. Accuracy on batch 1075/3013  on Training is 80.99732806691449\n",
            "Epoch #1. Accuracy on batch 1076/3013  on Training is 81.00046425255339\n",
            "Epoch #1. Accuracy on batch 1077/3013  on Training is 80.98910018552876\n",
            "Epoch #1. Accuracy on batch 1078/3013  on Training is 80.99223818350325\n",
            "Epoch #1. Accuracy on batch 1079/3013  on Training is 80.99537037037037\n",
            "Batch Id 1080 is having training loss of 0.6989079117774963\n",
            "0.2990802526473999\n",
            "Epoch #1. Accuracy on batch 1080/3013  on Training is 81.01006012950971\n",
            "Epoch #1. Accuracy on batch 1081/3013  on Training is 81.01894639556377\n",
            "Epoch #1. Accuracy on batch 1082/3013  on Training is 81.01338873499539\n",
            "Epoch #1. Accuracy on batch 1083/3013  on Training is 81.0136070110701\n",
            "Epoch #1. Accuracy on batch 1084/3013  on Training is 81.01382488479263\n",
            "Epoch #1. Accuracy on batch 1085/3013  on Training is 81.00253222836096\n",
            "Epoch #1. Accuracy on batch 1086/3013  on Training is 80.99413523459062\n",
            "Epoch #1. Accuracy on batch 1087/3013  on Training is 81.00011488970588\n",
            "Epoch #1. Accuracy on batch 1088/3013  on Training is 81.00034435261708\n",
            "Epoch #1. Accuracy on batch 1089/3013  on Training is 81.0091743119266\n",
            "Epoch #1. Accuracy on batch 1090/3013  on Training is 81.0122593950504\n",
            "Epoch #1. Accuracy on batch 1091/3013  on Training is 81.01533882783883\n",
            "Epoch #1. Accuracy on batch 1092/3013  on Training is 81.0126944190302\n",
            "Epoch #1. Accuracy on batch 1093/3013  on Training is 81.01576782449726\n",
            "Epoch #1. Accuracy on batch 1094/3013  on Training is 81.01598173515981\n",
            "Epoch #1. Accuracy on batch 1095/3013  on Training is 81.01904653284672\n",
            "Epoch #1. Accuracy on batch 1096/3013  on Training is 81.02210574293528\n",
            "Epoch #1. Accuracy on batch 1097/3013  on Training is 81.02515938069217\n",
            "Epoch #1. Accuracy on batch 1098/3013  on Training is 81.02820746132848\n",
            "Epoch #1. Accuracy on batch 1099/3013  on Training is 81.03693181818181\n",
            "Batch Id 1100 is having training loss of 0.6969195008277893\n",
            "0.6178691983222961\n",
            "Epoch #1. Accuracy on batch 1100/3013  on Training is 81.03712534059946\n",
            "Epoch #1. Accuracy on batch 1101/3013  on Training is 81.0486615245009\n",
            "Epoch #1. Accuracy on batch 1102/3013  on Training is 81.04601087941977\n",
            "Epoch #1. Accuracy on batch 1103/3013  on Training is 81.03770380434783\n",
            "Epoch #1. Accuracy on batch 1104/3013  on Training is 81.04355203619909\n",
            "Epoch #1. Accuracy on batch 1105/3013  on Training is 81.04656419529837\n",
            "Epoch #1. Accuracy on batch 1106/3013  on Training is 81.04392502258357\n",
            "Epoch #1. Accuracy on batch 1107/3013  on Training is 81.04693140794224\n",
            "Epoch #1. Accuracy on batch 1108/3013  on Training is 81.03866095581606\n",
            "Epoch #1. Accuracy on batch 1109/3013  on Training is 81.03603603603604\n",
            "Epoch #1. Accuracy on batch 1110/3013  on Training is 81.04185418541854\n",
            "Epoch #1. Accuracy on batch 1111/3013  on Training is 81.0336106115108\n",
            "Epoch #1. Accuracy on batch 1112/3013  on Training is 81.02818957771788\n",
            "Epoch #1. Accuracy on batch 1113/3013  on Training is 81.02558348294434\n",
            "Epoch #1. Accuracy on batch 1114/3013  on Training is 81.0285874439462\n",
            "Epoch #1. Accuracy on batch 1115/3013  on Training is 81.03438620071685\n",
            "Epoch #1. Accuracy on batch 1116/3013  on Training is 81.02898388540734\n",
            "Epoch #1. Accuracy on batch 1117/3013  on Training is 81.03756708407872\n",
            "Epoch #1. Accuracy on batch 1118/3013  on Training is 81.03775692582663\n",
            "Epoch #1. Accuracy on batch 1119/3013  on Training is 81.04352678571429\n",
            "Batch Id 1120 is having training loss of 0.6971070766448975\n",
            "0.5315954089164734\n",
            "Epoch #1. Accuracy on batch 1120/3013  on Training is 81.05207404103479\n",
            "Epoch #1. Accuracy on batch 1121/3013  on Training is 81.05503565062389\n",
            "Epoch #1. Accuracy on batch 1122/3013  on Training is 81.05799198575245\n",
            "Epoch #1. Accuracy on batch 1123/3013  on Training is 81.06094306049822\n",
            "Epoch #1. Accuracy on batch 1124/3013  on Training is 81.05833333333334\n",
            "Epoch #1. Accuracy on batch 1125/3013  on Training is 81.05850355239787\n",
            "Epoch #1. Accuracy on batch 1126/3013  on Training is 81.05867346938776\n",
            "Epoch #1. Accuracy on batch 1127/3013  on Training is 81.06715425531915\n",
            "Epoch #1. Accuracy on batch 1128/3013  on Training is 81.0645482728078\n",
            "Epoch #1. Accuracy on batch 1129/3013  on Training is 81.0591814159292\n",
            "Epoch #1. Accuracy on batch 1130/3013  on Training is 81.06763925729443\n",
            "Epoch #1. Accuracy on batch 1131/3013  on Training is 81.08160335689045\n",
            "Epoch #1. Accuracy on batch 1132/3013  on Training is 81.08726831421006\n",
            "Epoch #1. Accuracy on batch 1133/3013  on Training is 81.07914462081129\n",
            "Epoch #1. Accuracy on batch 1134/3013  on Training is 81.08204845814979\n",
            "Epoch #1. Accuracy on batch 1135/3013  on Training is 81.08769806338029\n",
            "Epoch #1. Accuracy on batch 1136/3013  on Training is 81.0768469656992\n",
            "Epoch #1. Accuracy on batch 1137/3013  on Training is 81.07699912126537\n",
            "Epoch #1. Accuracy on batch 1138/3013  on Training is 81.07989464442494\n",
            "Epoch #1. Accuracy on batch 1139/3013  on Training is 81.08826754385964\n",
            "Batch Id 1140 is having training loss of 0.6956166625022888\n",
            "0.66495281457901\n",
            "Epoch #1. Accuracy on batch 1140/3013  on Training is 81.09388694127958\n",
            "Epoch #1. Accuracy on batch 1141/3013  on Training is 81.08581436077058\n",
            "Epoch #1. Accuracy on batch 1142/3013  on Training is 81.09142607174103\n",
            "Epoch #1. Accuracy on batch 1143/3013  on Training is 81.09156468531468\n",
            "Epoch #1. Accuracy on batch 1144/3013  on Training is 81.09443231441048\n",
            "Epoch #1. Accuracy on batch 1145/3013  on Training is 81.09729493891797\n",
            "Epoch #1. Accuracy on batch 1146/3013  on Training is 81.09742807323452\n",
            "Epoch #1. Accuracy on batch 1147/3013  on Training is 81.0866724738676\n",
            "Epoch #1. Accuracy on batch 1148/3013  on Training is 81.08681462140993\n",
            "Epoch #1. Accuracy on batch 1149/3013  on Training is 81.08423913043478\n",
            "Epoch #1. Accuracy on batch 1150/3013  on Training is 81.08709817549956\n",
            "Epoch #1. Accuracy on batch 1151/3013  on Training is 81.09537760416667\n",
            "Epoch #1. Accuracy on batch 1152/3013  on Training is 81.0900910667823\n",
            "Epoch #1. Accuracy on batch 1153/3013  on Training is 81.08752166377816\n",
            "Epoch #1. Accuracy on batch 1154/3013  on Training is 81.09577922077922\n",
            "Epoch #1. Accuracy on batch 1155/3013  on Training is 81.10131920415225\n",
            "Epoch #1. Accuracy on batch 1156/3013  on Training is 81.10414866032843\n",
            "Epoch #1. Accuracy on batch 1157/3013  on Training is 81.09887737478411\n",
            "Epoch #1. Accuracy on batch 1158/3013  on Training is 81.09631147540983\n",
            "Epoch #1. Accuracy on batch 1159/3013  on Training is 81.09913793103448\n",
            "Batch Id 1160 is having training loss of 0.695726752281189\n",
            "0.5469644665718079\n",
            "Epoch #1. Accuracy on batch 1160/3013  on Training is 81.10195951765719\n",
            "Epoch #1. Accuracy on batch 1161/3013  on Training is 81.09939759036145\n",
            "Epoch #1. Accuracy on batch 1162/3013  on Training is 81.09952708512468\n",
            "Epoch #1. Accuracy on batch 1163/3013  on Training is 81.09965635738831\n",
            "Epoch #1. Accuracy on batch 1164/3013  on Training is 81.09710300429184\n",
            "Epoch #1. Accuracy on batch 1165/3013  on Training is 81.09455403087479\n",
            "Epoch #1. Accuracy on batch 1166/3013  on Training is 81.09736503856041\n",
            "Epoch #1. Accuracy on batch 1167/3013  on Training is 81.09749571917808\n",
            "Epoch #1. Accuracy on batch 1168/3013  on Training is 81.10297262617622\n",
            "Epoch #1. Accuracy on batch 1169/3013  on Training is 81.10042735042735\n",
            "Epoch #1. Accuracy on batch 1170/3013  on Training is 81.108561058924\n",
            "Epoch #1. Accuracy on batch 1171/3013  on Training is 81.1113481228669\n",
            "Epoch #1. Accuracy on batch 1172/3013  on Training is 81.11413043478261\n",
            "Epoch #1. Accuracy on batch 1173/3013  on Training is 81.11956984667802\n",
            "Epoch #1. Accuracy on batch 1174/3013  on Training is 81.11968085106383\n",
            "Epoch #1. Accuracy on batch 1175/3013  on Training is 81.125106292517\n",
            "Epoch #1. Accuracy on batch 1176/3013  on Training is 81.1305225148683\n",
            "Epoch #1. Accuracy on batch 1177/3013  on Training is 81.12797113752123\n",
            "Epoch #1. Accuracy on batch 1178/3013  on Training is 81.13867684478372\n",
            "Epoch #1. Accuracy on batch 1179/3013  on Training is 81.14141949152543\n",
            "Batch Id 1180 is having training loss of 0.6955791711807251\n",
            "1.2449392080307007\n",
            "Epoch #1. Accuracy on batch 1180/3013  on Training is 81.1335732430144\n",
            "Epoch #1. Accuracy on batch 1181/3013  on Training is 81.14424703891709\n",
            "Epoch #1. Accuracy on batch 1182/3013  on Training is 81.14433643279797\n",
            "Epoch #1. Accuracy on batch 1183/3013  on Training is 81.14178631756756\n",
            "Epoch #1. Accuracy on batch 1184/3013  on Training is 81.14978902953587\n",
            "Epoch #1. Accuracy on batch 1185/3013  on Training is 81.15514333895447\n",
            "Epoch #1. Accuracy on batch 1186/3013  on Training is 81.14995787700084\n",
            "Epoch #1. Accuracy on batch 1187/3013  on Training is 81.14741161616162\n",
            "Epoch #1. Accuracy on batch 1188/3013  on Training is 81.14224137931035\n",
            "Epoch #1. Accuracy on batch 1189/3013  on Training is 81.13970588235294\n",
            "Epoch #1. Accuracy on batch 1190/3013  on Training is 81.13455079764904\n",
            "Epoch #1. Accuracy on batch 1191/3013  on Training is 81.12940436241611\n",
            "Epoch #1. Accuracy on batch 1192/3013  on Training is 81.12164710813076\n",
            "Epoch #1. Accuracy on batch 1193/3013  on Training is 81.12175460636516\n",
            "Epoch #1. Accuracy on batch 1194/3013  on Training is 81.12186192468619\n",
            "Epoch #1. Accuracy on batch 1195/3013  on Training is 81.12458193979933\n",
            "Epoch #1. Accuracy on batch 1196/3013  on Training is 81.12207602339181\n",
            "Epoch #1. Accuracy on batch 1197/3013  on Training is 81.1273998330551\n",
            "Epoch #1. Accuracy on batch 1198/3013  on Training is 81.13532110091744\n",
            "Epoch #1. Accuracy on batch 1199/3013  on Training is 81.140625\n",
            "Batch Id 1200 is having training loss of 0.6952853202819824\n",
            "0.41252264380455017\n",
            "Epoch #1. Accuracy on batch 1200/3013  on Training is 81.14071606994172\n",
            "Epoch #1. Accuracy on batch 1201/3013  on Training is 81.14080698835275\n",
            "Epoch #1. Accuracy on batch 1202/3013  on Training is 81.13310473815461\n",
            "Epoch #1. Accuracy on batch 1203/3013  on Training is 81.12281976744185\n",
            "Epoch #1. Accuracy on batch 1204/3013  on Training is 81.12033195020747\n",
            "Epoch #1. Accuracy on batch 1205/3013  on Training is 81.12043946932006\n",
            "Epoch #1. Accuracy on batch 1206/3013  on Training is 81.13090306545153\n",
            "Epoch #1. Accuracy on batch 1207/3013  on Training is 81.12324089403974\n",
            "Epoch #1. Accuracy on batch 1208/3013  on Training is 81.1285153019024\n",
            "Epoch #1. Accuracy on batch 1209/3013  on Training is 81.13378099173553\n",
            "Epoch #1. Accuracy on batch 1210/3013  on Training is 81.1338769611891\n",
            "Epoch #1. Accuracy on batch 1211/3013  on Training is 81.13912953795379\n",
            "Epoch #1. Accuracy on batch 1212/3013  on Training is 81.14437345424567\n",
            "Epoch #1. Accuracy on batch 1213/3013  on Training is 81.14446046128501\n",
            "Epoch #1. Accuracy on batch 1214/3013  on Training is 81.14711934156378\n",
            "Epoch #1. Accuracy on batch 1215/3013  on Training is 81.1497738486842\n",
            "Epoch #1. Accuracy on batch 1216/3013  on Training is 81.1575595727198\n",
            "Epoch #1. Accuracy on batch 1217/3013  on Training is 81.16020114942529\n",
            "Epoch #1. Accuracy on batch 1218/3013  on Training is 81.16540196882691\n",
            "Epoch #1. Accuracy on batch 1219/3013  on Training is 81.16034836065573\n",
            "Batch Id 1220 is having training loss of 0.6943319439888\n",
            "0.6590258479118347\n",
            "Epoch #1. Accuracy on batch 1220/3013  on Training is 81.15786240786241\n",
            "Epoch #1. Accuracy on batch 1221/3013  on Training is 81.1553805237316\n",
            "Epoch #1. Accuracy on batch 1222/3013  on Training is 81.1580130825838\n",
            "Epoch #1. Accuracy on batch 1223/3013  on Training is 81.15553513071896\n",
            "Epoch #1. Accuracy on batch 1224/3013  on Training is 81.16581632653062\n",
            "Epoch #1. Accuracy on batch 1225/3013  on Training is 81.1658849918434\n",
            "Epoch #1. Accuracy on batch 1226/3013  on Training is 81.16340668296658\n",
            "Epoch #1. Accuracy on batch 1227/3013  on Training is 81.15329804560261\n",
            "Epoch #1. Accuracy on batch 1228/3013  on Training is 81.153376729048\n",
            "Epoch #1. Accuracy on batch 1229/3013  on Training is 81.15853658536585\n",
            "Epoch #1. Accuracy on batch 1230/3013  on Training is 81.15861088545897\n",
            "Epoch #1. Accuracy on batch 1231/3013  on Training is 81.15107548701299\n",
            "Epoch #1. Accuracy on batch 1232/3013  on Training is 81.14862124898622\n",
            "Epoch #1. Accuracy on batch 1233/3013  on Training is 81.1512358184765\n",
            "Epoch #1. Accuracy on batch 1234/3013  on Training is 81.16143724696356\n",
            "Epoch #1. Accuracy on batch 1235/3013  on Training is 81.16150889967638\n",
            "Epoch #1. Accuracy on batch 1236/3013  on Training is 81.17168552950687\n",
            "Epoch #1. Accuracy on batch 1237/3013  on Training is 81.17427302100161\n",
            "Epoch #1. Accuracy on batch 1238/3013  on Training is 81.17937853107344\n",
            "Epoch #1. Accuracy on batch 1239/3013  on Training is 81.18699596774194\n",
            "Batch Id 1240 is having training loss of 0.6929486989974976\n",
            "0.5118358731269836\n",
            "Epoch #1. Accuracy on batch 1240/3013  on Training is 81.19208299758259\n",
            "Epoch #1. Accuracy on batch 1241/3013  on Training is 81.19716183574879\n",
            "Epoch #1. Accuracy on batch 1242/3013  on Training is 81.19469026548673\n",
            "Epoch #1. Accuracy on batch 1243/3013  on Training is 81.19222266881029\n",
            "Epoch #1. Accuracy on batch 1244/3013  on Training is 81.19728915662651\n",
            "Epoch #1. Accuracy on batch 1245/3013  on Training is 81.19983948635634\n",
            "Epoch #1. Accuracy on batch 1246/3013  on Training is 81.19987971130713\n",
            "Epoch #1. Accuracy on batch 1247/3013  on Training is 81.19991987179488\n",
            "Epoch #1. Accuracy on batch 1248/3013  on Training is 81.19495596477182\n",
            "Epoch #1. Accuracy on batch 1249/3013  on Training is 81.1975\n",
            "Epoch #1. Accuracy on batch 1250/3013  on Training is 81.20003996802558\n",
            "Epoch #1. Accuracy on batch 1251/3013  on Training is 81.20507188498402\n",
            "Epoch #1. Accuracy on batch 1252/3013  on Training is 81.19762569832402\n",
            "Epoch #1. Accuracy on batch 1253/3013  on Training is 81.1951754385965\n",
            "Epoch #1. Accuracy on batch 1254/3013  on Training is 81.20268924302789\n",
            "Epoch #1. Accuracy on batch 1255/3013  on Training is 81.19775079617834\n",
            "Epoch #1. Accuracy on batch 1256/3013  on Training is 81.20773667462211\n",
            "Epoch #1. Accuracy on batch 1257/3013  on Training is 81.20528616852147\n",
            "Epoch #1. Accuracy on batch 1258/3013  on Training is 81.19539316918188\n",
            "Epoch #1. Accuracy on batch 1259/3013  on Training is 81.1954365079365\n",
            "Batch Id 1260 is having training loss of 0.6928441524505615\n",
            "0.8311460614204407\n",
            "Epoch #1. Accuracy on batch 1260/3013  on Training is 81.19300158604283\n",
            "Epoch #1. Accuracy on batch 1261/3013  on Training is 81.20047543581616\n",
            "Epoch #1. Accuracy on batch 1262/3013  on Training is 81.20298891528108\n",
            "Epoch #1. Accuracy on batch 1263/3013  on Training is 81.20549841772151\n",
            "Epoch #1. Accuracy on batch 1264/3013  on Training is 81.19812252964427\n",
            "Epoch #1. Accuracy on batch 1265/3013  on Training is 81.20310031595577\n",
            "Epoch #1. Accuracy on batch 1266/3013  on Training is 81.20067087608524\n",
            "Epoch #1. Accuracy on batch 1267/3013  on Training is 81.20317429022082\n",
            "Epoch #1. Accuracy on batch 1268/3013  on Training is 81.21059889676911\n",
            "Epoch #1. Accuracy on batch 1269/3013  on Training is 81.21062992125984\n",
            "Epoch #1. Accuracy on batch 1270/3013  on Training is 81.20820220298977\n",
            "Epoch #1. Accuracy on batch 1271/3013  on Training is 81.2057783018868\n",
            "Epoch #1. Accuracy on batch 1272/3013  on Training is 81.20826787117046\n",
            "Epoch #1. Accuracy on batch 1273/3013  on Training is 81.20584772370486\n",
            "Epoch #1. Accuracy on batch 1274/3013  on Training is 81.20833333333333\n",
            "Epoch #1. Accuracy on batch 1275/3013  on Training is 81.1985697492163\n",
            "Epoch #1. Accuracy on batch 1276/3013  on Training is 81.201057165231\n",
            "Epoch #1. Accuracy on batch 1277/3013  on Training is 81.20843114241002\n",
            "Epoch #1. Accuracy on batch 1278/3013  on Training is 81.20846364347146\n",
            "Epoch #1. Accuracy on batch 1279/3013  on Training is 81.2158203125\n",
            "Batch Id 1280 is having training loss of 0.6926908493041992\n",
            "0.834122359752655\n",
            "Epoch #1. Accuracy on batch 1280/3013  on Training is 81.2134074941452\n",
            "Epoch #1. Accuracy on batch 1281/3013  on Training is 81.2231864274571\n",
            "Epoch #1. Accuracy on batch 1282/3013  on Training is 81.22077162899454\n",
            "Epoch #1. Accuracy on batch 1283/3013  on Training is 81.2183605919003\n",
            "Epoch #1. Accuracy on batch 1284/3013  on Training is 81.20865758754864\n",
            "Epoch #1. Accuracy on batch 1285/3013  on Training is 81.21111975116641\n",
            "Epoch #1. Accuracy on batch 1286/3013  on Training is 81.21357808857809\n",
            "Epoch #1. Accuracy on batch 1287/3013  on Training is 81.20390139751552\n",
            "Epoch #1. Accuracy on batch 1288/3013  on Training is 81.2039371605896\n",
            "Epoch #1. Accuracy on batch 1289/3013  on Training is 81.19912790697674\n",
            "Epoch #1. Accuracy on batch 1290/3013  on Training is 81.20158791634393\n",
            "Epoch #1. Accuracy on batch 1291/3013  on Training is 81.19920665634675\n",
            "Epoch #1. Accuracy on batch 1292/3013  on Training is 81.20166279969064\n",
            "Epoch #1. Accuracy on batch 1293/3013  on Training is 81.19687017001546\n",
            "Epoch #1. Accuracy on batch 1294/3013  on Training is 81.18484555984556\n",
            "Epoch #1. Accuracy on batch 1295/3013  on Training is 81.18971836419753\n",
            "Epoch #1. Accuracy on batch 1296/3013  on Training is 81.19940246723208\n",
            "Epoch #1. Accuracy on batch 1297/3013  on Training is 81.19944144838213\n",
            "Epoch #1. Accuracy on batch 1298/3013  on Training is 81.19707467282525\n",
            "Epoch #1. Accuracy on batch 1299/3013  on Training is 81.1923076923077\n",
            "Batch Id 1300 is having training loss of 0.6942240595817566\n",
            "1.0217543840408325\n",
            "Epoch #1. Accuracy on batch 1300/3013  on Training is 81.18995003843197\n",
            "Epoch #1. Accuracy on batch 1301/3013  on Training is 81.18519585253456\n",
            "Epoch #1. Accuracy on batch 1302/3013  on Training is 81.18524558710668\n",
            "Epoch #1. Accuracy on batch 1303/3013  on Training is 81.18769171779141\n",
            "Epoch #1. Accuracy on batch 1304/3013  on Training is 81.1853448275862\n",
            "Epoch #1. Accuracy on batch 1305/3013  on Training is 81.19017993874425\n",
            "Epoch #1. Accuracy on batch 1306/3013  on Training is 81.19261667941852\n",
            "Epoch #1. Accuracy on batch 1307/3013  on Training is 81.1950496941896\n",
            "Epoch #1. Accuracy on batch 1308/3013  on Training is 81.20225362872422\n",
            "Epoch #1. Accuracy on batch 1309/3013  on Training is 81.19274809160305\n",
            "Epoch #1. Accuracy on batch 1310/3013  on Training is 81.19040808543097\n",
            "Epoch #1. Accuracy on batch 1311/3013  on Training is 81.18807164634147\n",
            "Epoch #1. Accuracy on batch 1312/3013  on Training is 81.18573876618431\n",
            "Epoch #1. Accuracy on batch 1313/3013  on Training is 81.19054414003044\n",
            "Epoch #1. Accuracy on batch 1314/3013  on Training is 81.19058935361217\n",
            "Epoch #1. Accuracy on batch 1315/3013  on Training is 81.18825987841946\n",
            "Epoch #1. Accuracy on batch 1316/3013  on Training is 81.18593394077449\n",
            "Epoch #1. Accuracy on batch 1317/3013  on Training is 81.1883535660091\n",
            "Epoch #1. Accuracy on batch 1318/3013  on Training is 81.18603108415466\n",
            "Epoch #1. Accuracy on batch 1319/3013  on Training is 81.18844696969697\n",
            "Batch Id 1320 is having training loss of 0.6933547854423523\n",
            "0.5923939943313599\n",
            "Epoch #1. Accuracy on batch 1320/3013  on Training is 81.1861279333838\n",
            "Epoch #1. Accuracy on batch 1321/3013  on Training is 81.18381240544629\n",
            "Epoch #1. Accuracy on batch 1322/3013  on Training is 81.18858654572941\n",
            "Epoch #1. Accuracy on batch 1323/3013  on Training is 81.19335347432025\n",
            "Epoch #1. Accuracy on batch 1324/3013  on Training is 81.19575471698113\n",
            "Epoch #1. Accuracy on batch 1325/3013  on Training is 81.20050904977376\n",
            "Epoch #1. Accuracy on batch 1326/3013  on Training is 81.2052562170309\n",
            "Epoch #1. Accuracy on batch 1327/3013  on Training is 81.21234939759036\n",
            "Epoch #1. Accuracy on batch 1328/3013  on Training is 81.21472911963883\n",
            "Epoch #1. Accuracy on batch 1329/3013  on Training is 81.2218045112782\n",
            "Epoch #1. Accuracy on batch 1330/3013  on Training is 81.22652141247183\n",
            "Epoch #1. Accuracy on batch 1331/3013  on Training is 81.22184684684684\n",
            "Epoch #1. Accuracy on batch 1332/3013  on Training is 81.23124531132783\n",
            "Epoch #1. Accuracy on batch 1333/3013  on Training is 81.22891679160419\n",
            "Epoch #1. Accuracy on batch 1334/3013  on Training is 81.22893258426966\n",
            "Epoch #1. Accuracy on batch 1335/3013  on Training is 81.22894835329342\n",
            "Epoch #1. Accuracy on batch 1336/3013  on Training is 81.2383133881825\n",
            "Epoch #1. Accuracy on batch 1337/3013  on Training is 81.2429932735426\n",
            "Epoch #1. Accuracy on batch 1338/3013  on Training is 81.25\n",
            "Epoch #1. Accuracy on batch 1339/3013  on Training is 81.25\n",
            "Batch Id 1340 is having training loss of 0.6922003626823425\n",
            "0.22271502017974854\n",
            "Epoch #1. Accuracy on batch 1340/3013  on Training is 81.25932140193885\n",
            "Epoch #1. Accuracy on batch 1341/3013  on Training is 81.26164307004471\n",
            "Epoch #1. Accuracy on batch 1342/3013  on Training is 81.25698064035741\n",
            "Epoch #1. Accuracy on batch 1343/3013  on Training is 81.25697544642857\n",
            "Epoch #1. Accuracy on batch 1344/3013  on Training is 81.2592936802974\n",
            "Epoch #1. Accuracy on batch 1345/3013  on Training is 81.26393016344726\n",
            "Epoch #1. Accuracy on batch 1346/3013  on Training is 81.26159985152191\n",
            "Epoch #1. Accuracy on batch 1347/3013  on Training is 81.26622774480713\n",
            "Epoch #1. Accuracy on batch 1348/3013  on Training is 81.26158265381764\n",
            "Epoch #1. Accuracy on batch 1349/3013  on Training is 81.26851851851852\n",
            "Epoch #1. Accuracy on batch 1350/3013  on Training is 81.2708179126573\n",
            "Epoch #1. Accuracy on batch 1351/3013  on Training is 81.27773668639053\n",
            "Epoch #1. Accuracy on batch 1352/3013  on Training is 81.2800258684405\n",
            "Epoch #1. Accuracy on batch 1353/3013  on Training is 81.2823116691285\n",
            "Epoch #1. Accuracy on batch 1354/3013  on Training is 81.2799815498155\n",
            "Epoch #1. Accuracy on batch 1355/3013  on Training is 81.2845685840708\n",
            "Epoch #1. Accuracy on batch 1356/3013  on Training is 81.28454310980104\n",
            "Epoch #1. Accuracy on batch 1357/3013  on Training is 81.29142120765832\n",
            "Epoch #1. Accuracy on batch 1358/3013  on Training is 81.28679175864606\n",
            "Epoch #1. Accuracy on batch 1359/3013  on Training is 81.29136029411765\n",
            "Batch Id 1360 is having training loss of 0.6912678480148315\n",
            "0.8026539087295532\n",
            "Epoch #1. Accuracy on batch 1360/3013  on Training is 81.28903379867744\n",
            "Epoch #1. Accuracy on batch 1361/3013  on Training is 81.293593979442\n",
            "Epoch #1. Accuracy on batch 1362/3013  on Training is 81.29585473220837\n",
            "Epoch #1. Accuracy on batch 1363/3013  on Training is 81.2958211143695\n",
            "Epoch #1. Accuracy on batch 1364/3013  on Training is 81.29807692307692\n",
            "Epoch #1. Accuracy on batch 1365/3013  on Training is 81.31176793557833\n",
            "Epoch #1. Accuracy on batch 1366/3013  on Training is 81.31172275054864\n",
            "Epoch #1. Accuracy on batch 1367/3013  on Training is 81.30710891812865\n",
            "Epoch #1. Accuracy on batch 1368/3013  on Training is 81.30934989043097\n",
            "Epoch #1. Accuracy on batch 1369/3013  on Training is 81.30474452554745\n",
            "Epoch #1. Accuracy on batch 1370/3013  on Training is 81.304704595186\n",
            "Epoch #1. Accuracy on batch 1371/3013  on Training is 81.30010932944606\n",
            "Epoch #1. Accuracy on batch 1372/3013  on Training is 81.29552075746541\n",
            "Epoch #1. Accuracy on batch 1373/3013  on Training is 81.29093886462883\n",
            "Epoch #1. Accuracy on batch 1374/3013  on Training is 81.28181818181818\n",
            "Epoch #1. Accuracy on batch 1375/3013  on Training is 81.28860828488372\n",
            "Epoch #1. Accuracy on batch 1376/3013  on Training is 81.28177196804648\n",
            "Epoch #1. Accuracy on batch 1377/3013  on Training is 81.2817489114659\n",
            "Epoch #1. Accuracy on batch 1378/3013  on Training is 81.27719361856418\n",
            "Epoch #1. Accuracy on batch 1379/3013  on Training is 81.27490942028986\n",
            "Batch Id 1380 is having training loss of 0.6914041638374329\n",
            "1.0512815713882446\n",
            "Epoch #1. Accuracy on batch 1380/3013  on Training is 81.27036567704562\n",
            "Epoch #1. Accuracy on batch 1381/3013  on Training is 81.26130607814761\n",
            "Epoch #1. Accuracy on batch 1382/3013  on Training is 81.26581706435286\n",
            "Epoch #1. Accuracy on batch 1383/3013  on Training is 81.27032153179191\n",
            "Epoch #1. Accuracy on batch 1384/3013  on Training is 81.26353790613719\n",
            "Epoch #1. Accuracy on batch 1385/3013  on Training is 81.2725468975469\n",
            "Epoch #1. Accuracy on batch 1386/3013  on Training is 81.27478370583994\n",
            "Epoch #1. Accuracy on batch 1387/3013  on Training is 81.27476585014409\n",
            "Epoch #1. Accuracy on batch 1388/3013  on Training is 81.27924766018718\n",
            "Epoch #1. Accuracy on batch 1389/3013  on Training is 81.27697841726619\n",
            "Epoch #1. Accuracy on batch 1390/3013  on Training is 81.27471243709562\n",
            "Epoch #1. Accuracy on batch 1391/3013  on Training is 81.27693965517241\n",
            "Epoch #1. Accuracy on batch 1392/3013  on Training is 81.27692031586504\n",
            "Epoch #1. Accuracy on batch 1393/3013  on Training is 81.27690100430416\n",
            "Epoch #1. Accuracy on batch 1394/3013  on Training is 81.27240143369175\n",
            "Epoch #1. Accuracy on batch 1395/3013  on Training is 81.27686246418338\n",
            "Epoch #1. Accuracy on batch 1396/3013  on Training is 81.2790801717967\n",
            "Epoch #1. Accuracy on batch 1397/3013  on Training is 81.28353004291846\n",
            "Epoch #1. Accuracy on batch 1398/3013  on Training is 81.27680486061473\n",
            "Epoch #1. Accuracy on batch 1399/3013  on Training is 81.28348214285714\n",
            "Batch Id 1400 is having training loss of 0.6911782026290894\n",
            "0.8397653698921204\n",
            "Epoch #1. Accuracy on batch 1400/3013  on Training is 81.28345824411134\n",
            "Epoch #1. Accuracy on batch 1401/3013  on Training is 81.28789229671898\n",
            "Epoch #1. Accuracy on batch 1402/3013  on Training is 81.27450106913756\n",
            "Epoch #1. Accuracy on batch 1403/3013  on Training is 81.27448361823362\n",
            "Epoch #1. Accuracy on batch 1404/3013  on Training is 81.27224199288256\n",
            "Epoch #1. Accuracy on batch 1405/3013  on Training is 81.27222617354197\n",
            "Epoch #1. Accuracy on batch 1406/3013  on Training is 81.27443141435678\n",
            "Epoch #1. Accuracy on batch 1407/3013  on Training is 81.27219460227273\n",
            "Epoch #1. Accuracy on batch 1408/3013  on Training is 81.26996096522356\n",
            "Epoch #1. Accuracy on batch 1409/3013  on Training is 81.26994680851064\n",
            "Epoch #1. Accuracy on batch 1410/3013  on Training is 81.27214741318214\n",
            "Epoch #1. Accuracy on batch 1411/3013  on Training is 81.27213172804532\n",
            "Epoch #1. Accuracy on batch 1412/3013  on Training is 81.2721160651097\n",
            "Epoch #1. Accuracy on batch 1413/3013  on Training is 81.26768033946252\n",
            "Epoch #1. Accuracy on batch 1414/3013  on Training is 81.2720848056537\n",
            "Epoch #1. Accuracy on batch 1415/3013  on Training is 81.27206920903954\n",
            "Epoch #1. Accuracy on batch 1416/3013  on Training is 81.28087508821454\n",
            "Epoch #1. Accuracy on batch 1417/3013  on Training is 81.26763046544428\n",
            "Epoch #1. Accuracy on batch 1418/3013  on Training is 81.26761804087386\n",
            "Epoch #1. Accuracy on batch 1419/3013  on Training is 81.27200704225352\n",
            "Batch Id 1420 is having training loss of 0.6911517977714539\n",
            "0.5502053499221802\n",
            "Epoch #1. Accuracy on batch 1420/3013  on Training is 81.27638986629134\n",
            "Epoch #1. Accuracy on batch 1421/3013  on Training is 81.27856891701829\n",
            "Epoch #1. Accuracy on batch 1422/3013  on Training is 81.27854884047787\n",
            "Epoch #1. Accuracy on batch 1423/3013  on Training is 81.27413974719101\n",
            "Epoch #1. Accuracy on batch 1424/3013  on Training is 81.27412280701755\n",
            "Epoch #1. Accuracy on batch 1425/3013  on Training is 81.28287166900421\n",
            "Epoch #1. Accuracy on batch 1426/3013  on Training is 81.2937981779958\n",
            "Epoch #1. Accuracy on batch 1427/3013  on Training is 81.29157913165267\n",
            "Epoch #1. Accuracy on batch 1428/3013  on Training is 81.29592372288313\n",
            "Epoch #1. Accuracy on batch 1429/3013  on Training is 81.30026223776224\n",
            "Epoch #1. Accuracy on batch 1430/3013  on Training is 81.30241090146751\n",
            "Epoch #1. Accuracy on batch 1431/3013  on Training is 81.30019203910615\n",
            "Epoch #1. Accuracy on batch 1432/3013  on Training is 81.30887997208653\n",
            "Epoch #1. Accuracy on batch 1433/3013  on Training is 81.30230125523012\n",
            "Epoch #1. Accuracy on batch 1434/3013  on Training is 81.2979094076655\n",
            "Epoch #1. Accuracy on batch 1435/3013  on Training is 81.30440459610028\n",
            "Epoch #1. Accuracy on batch 1436/3013  on Training is 81.30871607515658\n",
            "Epoch #1. Accuracy on batch 1437/3013  on Training is 81.31084840055632\n",
            "Epoch #1. Accuracy on batch 1438/3013  on Training is 81.30211952744962\n",
            "Epoch #1. Accuracy on batch 1439/3013  on Training is 81.30425347222223\n",
            "Batch Id 1440 is having training loss of 0.6899881958961487\n",
            "0.5949287414550781\n",
            "Epoch #1. Accuracy on batch 1440/3013  on Training is 81.30638445523941\n",
            "Epoch #1. Accuracy on batch 1441/3013  on Training is 81.30201109570042\n",
            "Epoch #1. Accuracy on batch 1442/3013  on Training is 81.30630630630631\n",
            "Epoch #1. Accuracy on batch 1443/3013  on Training is 81.30843144044321\n",
            "Epoch #1. Accuracy on batch 1444/3013  on Training is 81.31055363321799\n",
            "Epoch #1. Accuracy on batch 1445/3013  on Training is 81.30402835408022\n",
            "Epoch #1. Accuracy on batch 1446/3013  on Training is 81.30183137525916\n",
            "Epoch #1. Accuracy on batch 1447/3013  on Training is 81.29963743093923\n",
            "Epoch #1. Accuracy on batch 1448/3013  on Training is 81.2888198757764\n",
            "Epoch #1. Accuracy on batch 1449/3013  on Training is 81.29310344827586\n",
            "Epoch #1. Accuracy on batch 1450/3013  on Training is 81.2801516195727\n",
            "Epoch #1. Accuracy on batch 1451/3013  on Training is 81.28228305785125\n",
            "Epoch #1. Accuracy on batch 1452/3013  on Training is 81.28441156228493\n",
            "Epoch #1. Accuracy on batch 1453/3013  on Training is 81.2865371389271\n",
            "Epoch #1. Accuracy on batch 1454/3013  on Training is 81.28221649484536\n",
            "Epoch #1. Accuracy on batch 1455/3013  on Training is 81.28434065934066\n",
            "Epoch #1. Accuracy on batch 1456/3013  on Training is 81.2864619080302\n",
            "Epoch #1. Accuracy on batch 1457/3013  on Training is 81.28215020576131\n",
            "Epoch #1. Accuracy on batch 1458/3013  on Training is 81.2864119259767\n",
            "Epoch #1. Accuracy on batch 1459/3013  on Training is 81.28638698630137\n",
            "Batch Id 1460 is having training loss of 0.6894801259040833\n",
            "0.5783362984657288\n",
            "Epoch #1. Accuracy on batch 1460/3013  on Training is 81.28850102669405\n",
            "Epoch #1. Accuracy on batch 1461/3013  on Training is 81.28419972640219\n",
            "Epoch #1. Accuracy on batch 1462/3013  on Training is 81.28204032809296\n",
            "Epoch #1. Accuracy on batch 1463/3013  on Training is 81.27348019125684\n",
            "Epoch #1. Accuracy on batch 1464/3013  on Training is 81.27559726962457\n",
            "Epoch #1. Accuracy on batch 1465/3013  on Training is 81.27984311050477\n",
            "Epoch #1. Accuracy on batch 1466/3013  on Training is 81.2734321745058\n",
            "Epoch #1. Accuracy on batch 1467/3013  on Training is 81.27128746594005\n",
            "Epoch #1. Accuracy on batch 1468/3013  on Training is 81.27765486725664\n",
            "Epoch #1. Accuracy on batch 1469/3013  on Training is 81.2797619047619\n",
            "Epoch #1. Accuracy on batch 1470/3013  on Training is 81.27974167233175\n",
            "Epoch #1. Accuracy on batch 1471/3013  on Training is 81.28184442934783\n",
            "Epoch #1. Accuracy on batch 1472/3013  on Training is 81.28394433129667\n",
            "Epoch #1. Accuracy on batch 1473/3013  on Training is 81.28604138398914\n",
            "Epoch #1. Accuracy on batch 1474/3013  on Training is 81.29025423728814\n",
            "Epoch #1. Accuracy on batch 1475/3013  on Training is 81.29022696476964\n",
            "Epoch #1. Accuracy on batch 1476/3013  on Training is 81.29019972918077\n",
            "Epoch #1. Accuracy on batch 1477/3013  on Training is 81.28805818673884\n",
            "Epoch #1. Accuracy on batch 1478/3013  on Training is 81.29014536849222\n",
            "Epoch #1. Accuracy on batch 1479/3013  on Training is 81.29434121621621\n",
            "Batch Id 1480 is having training loss of 0.6892284750938416\n",
            "1.2685539722442627\n",
            "Epoch #1. Accuracy on batch 1480/3013  on Training is 81.2795408507765\n",
            "Epoch #1. Accuracy on batch 1481/3013  on Training is 81.28162955465586\n",
            "Epoch #1. Accuracy on batch 1482/3013  on Training is 81.27950101146325\n",
            "Epoch #1. Accuracy on batch 1483/3013  on Training is 81.27948113207547\n",
            "Epoch #1. Accuracy on batch 1484/3013  on Training is 81.27525252525253\n",
            "Epoch #1. Accuracy on batch 1485/3013  on Training is 81.28575033647375\n",
            "Epoch #1. Accuracy on batch 1486/3013  on Training is 81.28782784129119\n",
            "Epoch #1. Accuracy on batch 1487/3013  on Training is 81.29410282258064\n",
            "Epoch #1. Accuracy on batch 1488/3013  on Training is 81.29197447951645\n",
            "Epoch #1. Accuracy on batch 1489/3013  on Training is 81.28775167785236\n",
            "Epoch #1. Accuracy on batch 1490/3013  on Training is 81.29610999329309\n",
            "Epoch #1. Accuracy on batch 1491/3013  on Training is 81.30026809651474\n",
            "Epoch #1. Accuracy on batch 1492/3013  on Training is 81.30442062960482\n",
            "Epoch #1. Accuracy on batch 1493/3013  on Training is 81.29392570281125\n",
            "Epoch #1. Accuracy on batch 1494/3013  on Training is 81.29807692307692\n",
            "Epoch #1. Accuracy on batch 1495/3013  on Training is 81.29177807486631\n",
            "Epoch #1. Accuracy on batch 1496/3013  on Training is 81.3001002004008\n",
            "Epoch #1. Accuracy on batch 1497/3013  on Training is 81.30423898531375\n",
            "Epoch #1. Accuracy on batch 1498/3013  on Training is 81.30420280186792\n",
            "Epoch #1. Accuracy on batch 1499/3013  on Training is 81.30625\n",
            "Batch Id 1500 is having training loss of 0.687984049320221\n",
            "0.8379144072532654\n",
            "Epoch #1. Accuracy on batch 1500/3013  on Training is 81.30413057961358\n",
            "Epoch #1. Accuracy on batch 1501/3013  on Training is 81.3103362183755\n",
            "Epoch #1. Accuracy on batch 1502/3013  on Training is 81.312375249501\n",
            "Epoch #1. Accuracy on batch 1503/3013  on Training is 81.31025598404256\n",
            "Epoch #1. Accuracy on batch 1504/3013  on Training is 81.30398671096346\n",
            "Epoch #1. Accuracy on batch 1505/3013  on Training is 81.29772576361222\n",
            "Epoch #1. Accuracy on batch 1506/3013  on Training is 81.30391506303916\n",
            "Epoch #1. Accuracy on batch 1507/3013  on Training is 81.30180702917772\n",
            "Epoch #1. Accuracy on batch 1508/3013  on Training is 81.30177269715043\n",
            "Epoch #1. Accuracy on batch 1509/3013  on Training is 81.29966887417218\n",
            "Epoch #1. Accuracy on batch 1510/3013  on Training is 81.29549966909332\n",
            "Epoch #1. Accuracy on batch 1511/3013  on Training is 81.29753637566138\n",
            "Epoch #1. Accuracy on batch 1512/3013  on Training is 81.30576668869796\n",
            "Epoch #1. Accuracy on batch 1513/3013  on Training is 81.30572985468956\n",
            "Epoch #1. Accuracy on batch 1514/3013  on Training is 81.30981848184818\n",
            "Epoch #1. Accuracy on batch 1515/3013  on Training is 81.31390171503958\n",
            "Epoch #1. Accuracy on batch 1516/3013  on Training is 81.31385959129861\n",
            "Epoch #1. Accuracy on batch 1517/3013  on Training is 81.31999341238472\n",
            "Epoch #1. Accuracy on batch 1518/3013  on Training is 81.32200460829493\n",
            "Epoch #1. Accuracy on batch 1519/3013  on Training is 81.32401315789474\n",
            "Batch Id 1520 is having training loss of 0.6883103847503662\n",
            "0.8855332732200623\n",
            "Epoch #1. Accuracy on batch 1520/3013  on Training is 81.32190992767916\n",
            "Epoch #1. Accuracy on batch 1521/3013  on Training is 81.31775624178712\n",
            "Epoch #1. Accuracy on batch 1522/3013  on Training is 81.31976362442548\n",
            "Epoch #1. Accuracy on batch 1523/3013  on Training is 81.32176837270342\n",
            "Epoch #1. Accuracy on batch 1524/3013  on Training is 81.32581967213115\n",
            "Epoch #1. Accuracy on batch 1525/3013  on Training is 81.3319134993447\n",
            "Epoch #1. Accuracy on batch 1526/3013  on Training is 81.32162737393583\n",
            "Epoch #1. Accuracy on batch 1527/3013  on Training is 81.32362565445027\n",
            "Epoch #1. Accuracy on batch 1528/3013  on Training is 81.32357750163506\n",
            "Epoch #1. Accuracy on batch 1529/3013  on Training is 81.32148692810458\n",
            "Epoch #1. Accuracy on batch 1530/3013  on Training is 81.32960483344219\n",
            "Epoch #1. Accuracy on batch 1531/3013  on Training is 81.33363250652741\n",
            "Epoch #1. Accuracy on batch 1532/3013  on Training is 81.33357795172864\n",
            "Epoch #1. Accuracy on batch 1533/3013  on Training is 81.34167209908735\n",
            "Epoch #1. Accuracy on batch 1534/3013  on Training is 81.34771986970684\n",
            "Epoch #1. Accuracy on batch 1535/3013  on Training is 81.35172526041667\n",
            "Epoch #1. Accuracy on batch 1536/3013  on Training is 81.33945998698763\n",
            "Epoch #1. Accuracy on batch 1537/3013  on Training is 81.34549739921977\n",
            "Epoch #1. Accuracy on batch 1538/3013  on Training is 81.34543534762832\n",
            "Epoch #1. Accuracy on batch 1539/3013  on Training is 81.34943181818181\n",
            "Batch Id 1540 is having training loss of 0.6872661113739014\n",
            "0.6144186854362488\n",
            "Epoch #1. Accuracy on batch 1540/3013  on Training is 81.35139519792342\n",
            "Epoch #1. Accuracy on batch 1541/3013  on Training is 81.34524967574579\n",
            "Epoch #1. Accuracy on batch 1542/3013  on Training is 81.34721322099806\n",
            "Epoch #1. Accuracy on batch 1543/3013  on Training is 81.34107836787565\n",
            "Epoch #1. Accuracy on batch 1544/3013  on Training is 81.3450647249191\n",
            "Epoch #1. Accuracy on batch 1545/3013  on Training is 81.34904592496765\n",
            "Epoch #1. Accuracy on batch 1546/3013  on Training is 81.35100193923724\n",
            "Epoch #1. Accuracy on batch 1547/3013  on Training is 81.35093669250647\n",
            "Epoch #1. Accuracy on batch 1548/3013  on Training is 81.35490639122014\n",
            "Epoch #1. Accuracy on batch 1549/3013  on Training is 81.35685483870968\n",
            "Epoch #1. Accuracy on batch 1550/3013  on Training is 81.36081560283688\n",
            "Epoch #1. Accuracy on batch 1551/3013  on Training is 81.36678479381443\n",
            "Epoch #1. Accuracy on batch 1552/3013  on Training is 81.3646973599485\n",
            "Epoch #1. Accuracy on batch 1553/3013  on Training is 81.36462355212355\n",
            "Epoch #1. Accuracy on batch 1554/3013  on Training is 81.37057877813506\n",
            "Epoch #1. Accuracy on batch 1555/3013  on Training is 81.37853470437018\n",
            "Epoch #1. Accuracy on batch 1556/3013  on Training is 81.38246628131022\n",
            "Epoch #1. Accuracy on batch 1557/3013  on Training is 81.3803754813864\n",
            "Epoch #1. Accuracy on batch 1558/3013  on Training is 81.38029185375241\n",
            "Epoch #1. Accuracy on batch 1559/3013  on Training is 81.38020833333333\n",
            "Batch Id 1560 is having training loss of 0.6862584352493286\n",
            "0.6617316007614136\n",
            "Epoch #1. Accuracy on batch 1560/3013  on Training is 81.37612107623319\n",
            "Epoch #1. Accuracy on batch 1561/3013  on Training is 81.3720390524968\n",
            "Epoch #1. Accuracy on batch 1562/3013  on Training is 81.37795905310301\n",
            "Epoch #1. Accuracy on batch 1563/3013  on Training is 81.38187340153452\n",
            "Epoch #1. Accuracy on batch 1564/3013  on Training is 81.38378594249201\n",
            "Epoch #1. Accuracy on batch 1565/3013  on Training is 81.38170498084291\n",
            "Epoch #1. Accuracy on batch 1566/3013  on Training is 81.3895979578813\n",
            "Epoch #1. Accuracy on batch 1567/3013  on Training is 81.37954400510205\n",
            "Epoch #1. Accuracy on batch 1568/3013  on Training is 81.37946144040791\n",
            "Epoch #1. Accuracy on batch 1569/3013  on Training is 81.37738853503184\n",
            "Epoch #1. Accuracy on batch 1570/3013  on Training is 81.36935073201782\n",
            "Epoch #1. Accuracy on batch 1571/3013  on Training is 81.37325063613231\n",
            "Epoch #1. Accuracy on batch 1572/3013  on Training is 81.3731722822632\n",
            "Epoch #1. Accuracy on batch 1573/3013  on Training is 81.3790501905972\n",
            "Epoch #1. Accuracy on batch 1574/3013  on Training is 81.37896825396825\n",
            "Epoch #1. Accuracy on batch 1575/3013  on Training is 81.37293781725889\n",
            "Epoch #1. Accuracy on batch 1576/3013  on Training is 81.37484147114775\n",
            "Epoch #1. Accuracy on batch 1577/3013  on Training is 81.36882129277566\n",
            "Epoch #1. Accuracy on batch 1578/3013  on Training is 81.37468334388853\n",
            "Epoch #1. Accuracy on batch 1579/3013  on Training is 81.38053797468355\n",
            "Batch Id 1580 is having training loss of 0.6864350438117981\n",
            "0.755893349647522\n",
            "Epoch #1. Accuracy on batch 1580/3013  on Training is 81.38243200506008\n",
            "Epoch #1. Accuracy on batch 1581/3013  on Training is 81.38432364096082\n",
            "Epoch #1. Accuracy on batch 1582/3013  on Training is 81.3802905874921\n",
            "Epoch #1. Accuracy on batch 1583/3013  on Training is 81.38612689393939\n",
            "Epoch #1. Accuracy on batch 1584/3013  on Training is 81.39195583596215\n",
            "Epoch #1. Accuracy on batch 1585/3013  on Training is 81.3938366960908\n",
            "Epoch #1. Accuracy on batch 1586/3013  on Training is 81.3976843100189\n",
            "Epoch #1. Accuracy on batch 1587/3013  on Training is 81.39759130982368\n",
            "Epoch #1. Accuracy on batch 1588/3013  on Training is 81.40339836375078\n",
            "Epoch #1. Accuracy on batch 1589/3013  on Training is 81.40526729559748\n",
            "Epoch #1. Accuracy on batch 1590/3013  on Training is 81.4032055311125\n",
            "Epoch #1. Accuracy on batch 1591/3013  on Training is 81.40899811557789\n",
            "Epoch #1. Accuracy on batch 1592/3013  on Training is 81.41282172002511\n",
            "Epoch #1. Accuracy on batch 1593/3013  on Training is 81.42056148055207\n",
            "Epoch #1. Accuracy on batch 1594/3013  on Training is 81.42241379310344\n",
            "Epoch #1. Accuracy on batch 1595/3013  on Training is 81.42230576441102\n",
            "Epoch #1. Accuracy on batch 1596/3013  on Training is 81.4124139010645\n",
            "Epoch #1. Accuracy on batch 1597/3013  on Training is 81.41035669586984\n",
            "Epoch #1. Accuracy on batch 1598/3013  on Training is 81.41025641025641\n",
            "Epoch #1. Accuracy on batch 1599/3013  on Training is 81.408203125\n",
            "Batch Id 1600 is having training loss of 0.6858640313148499\n",
            "0.8445497751235962\n",
            "Epoch #1. Accuracy on batch 1600/3013  on Training is 81.40615240474703\n",
            "Epoch #1. Accuracy on batch 1601/3013  on Training is 81.41190699126092\n",
            "Epoch #1. Accuracy on batch 1602/3013  on Training is 81.4079070492826\n",
            "Epoch #1. Accuracy on batch 1603/3013  on Training is 81.40391209476309\n",
            "Epoch #1. Accuracy on batch 1604/3013  on Training is 81.39992211838006\n",
            "Epoch #1. Accuracy on batch 1605/3013  on Training is 81.39982876712328\n",
            "Epoch #1. Accuracy on batch 1606/3013  on Training is 81.4016801493466\n",
            "Epoch #1. Accuracy on batch 1607/3013  on Training is 81.40547263681592\n",
            "Epoch #1. Accuracy on batch 1608/3013  on Training is 81.41120261031696\n",
            "Epoch #1. Accuracy on batch 1609/3013  on Training is 81.41304347826087\n",
            "Epoch #1. Accuracy on batch 1610/3013  on Training is 81.41488206083179\n",
            "Epoch #1. Accuracy on batch 1611/3013  on Training is 81.41671836228288\n",
            "Epoch #1. Accuracy on batch 1612/3013  on Training is 81.41467761934284\n",
            "Epoch #1. Accuracy on batch 1613/3013  on Training is 81.41844795539033\n",
            "Epoch #1. Accuracy on batch 1614/3013  on Training is 81.41834365325077\n",
            "Epoch #1. Accuracy on batch 1615/3013  on Training is 81.42017326732673\n",
            "Epoch #1. Accuracy on batch 1616/3013  on Training is 81.42586580086581\n",
            "Epoch #1. Accuracy on batch 1617/3013  on Training is 81.4334826946848\n",
            "Epoch #1. Accuracy on batch 1618/3013  on Training is 81.43722977146386\n",
            "Epoch #1. Accuracy on batch 1619/3013  on Training is 81.44483024691358\n",
            "Batch Id 1620 is having training loss of 0.6846878528594971\n",
            "0.6201815605163574\n",
            "Epoch #1. Accuracy on batch 1620/3013  on Training is 81.44278223318939\n",
            "Epoch #1. Accuracy on batch 1621/3013  on Training is 81.442663378545\n",
            "Epoch #1. Accuracy on batch 1622/3013  on Training is 81.44254467036352\n",
            "Epoch #1. Accuracy on batch 1623/3013  on Training is 81.45012315270937\n",
            "Epoch #1. Accuracy on batch 1624/3013  on Training is 81.45192307692308\n",
            "Epoch #1. Accuracy on batch 1625/3013  on Training is 81.44795510455104\n",
            "Epoch #1. Accuracy on batch 1626/3013  on Training is 81.45167486170867\n",
            "Epoch #1. Accuracy on batch 1627/3013  on Training is 81.44963144963145\n",
            "Epoch #1. Accuracy on batch 1628/3013  on Training is 81.44567219152854\n",
            "Epoch #1. Accuracy on batch 1629/3013  on Training is 81.44938650306749\n",
            "Epoch #1. Accuracy on batch 1630/3013  on Training is 81.45118025751073\n",
            "Epoch #1. Accuracy on batch 1631/3013  on Training is 81.45105698529412\n",
            "Epoch #1. Accuracy on batch 1632/3013  on Training is 81.45284751990202\n",
            "Epoch #1. Accuracy on batch 1633/3013  on Training is 81.45846083231334\n",
            "Epoch #1. Accuracy on batch 1634/3013  on Training is 81.46215596330275\n",
            "Epoch #1. Accuracy on batch 1635/3013  on Training is 81.46584657701712\n",
            "Epoch #1. Accuracy on batch 1636/3013  on Training is 81.46762370189371\n",
            "Epoch #1. Accuracy on batch 1637/3013  on Training is 81.47321428571429\n",
            "Epoch #1. Accuracy on batch 1638/3013  on Training is 81.46926479560707\n",
            "Epoch #1. Accuracy on batch 1639/3013  on Training is 81.46532012195122\n",
            "Batch Id 1640 is having training loss of 0.6838353872299194\n",
            "0.7735359072685242\n",
            "Epoch #1. Accuracy on batch 1640/3013  on Training is 81.4651889092017\n",
            "Epoch #1. Accuracy on batch 1641/3013  on Training is 81.46505785627284\n",
            "Epoch #1. Accuracy on batch 1642/3013  on Training is 81.4668289713938\n",
            "Epoch #1. Accuracy on batch 1643/3013  on Training is 81.46479622871047\n",
            "Epoch #1. Accuracy on batch 1644/3013  on Training is 81.46846504559271\n",
            "Epoch #1. Accuracy on batch 1645/3013  on Training is 81.47023086269745\n",
            "Epoch #1. Accuracy on batch 1646/3013  on Training is 81.47199453551913\n",
            "Epoch #1. Accuracy on batch 1647/3013  on Training is 81.46617111650485\n",
            "Epoch #1. Accuracy on batch 1648/3013  on Training is 81.46604002425713\n",
            "Epoch #1. Accuracy on batch 1649/3013  on Training is 81.46212121212122\n",
            "Epoch #1. Accuracy on batch 1650/3013  on Training is 81.46199273167777\n",
            "Epoch #1. Accuracy on batch 1651/3013  on Training is 81.46375605326877\n",
            "Epoch #1. Accuracy on batch 1652/3013  on Training is 81.46551724137932\n",
            "Epoch #1. Accuracy on batch 1653/3013  on Training is 81.46160822249094\n",
            "Epoch #1. Accuracy on batch 1654/3013  on Training is 81.46336858006042\n",
            "Epoch #1. Accuracy on batch 1655/3013  on Training is 81.46890096618357\n",
            "Epoch #1. Accuracy on batch 1656/3013  on Training is 81.46688292094146\n",
            "Epoch #1. Accuracy on batch 1657/3013  on Training is 81.4686369119421\n",
            "Epoch #1. Accuracy on batch 1658/3013  on Training is 81.47038878842676\n",
            "Epoch #1. Accuracy on batch 1659/3013  on Training is 81.47590361445783\n",
            "Batch Id 1660 is having training loss of 0.6835609078407288\n",
            "0.9218056797981262\n",
            "Epoch #1. Accuracy on batch 1660/3013  on Training is 81.47012341962673\n",
            "Epoch #1. Accuracy on batch 1661/3013  on Training is 81.46811070998797\n",
            "Epoch #1. Accuracy on batch 1662/3013  on Training is 81.46797955502105\n",
            "Epoch #1. Accuracy on batch 1663/3013  on Training is 81.4697265625\n",
            "Epoch #1. Accuracy on batch 1664/3013  on Training is 81.46396396396396\n",
            "Epoch #1. Accuracy on batch 1665/3013  on Training is 81.45820828331333\n",
            "Epoch #1. Accuracy on batch 1666/3013  on Training is 81.45995800839832\n",
            "Epoch #1. Accuracy on batch 1667/3013  on Training is 81.45983213429257\n",
            "Epoch #1. Accuracy on batch 1668/3013  on Training is 81.4578340323547\n",
            "Epoch #1. Accuracy on batch 1669/3013  on Training is 81.45958083832335\n",
            "Epoch #1. Accuracy on batch 1670/3013  on Training is 81.46880610412926\n",
            "Epoch #1. Accuracy on batch 1671/3013  on Training is 81.46306818181819\n",
            "Epoch #1. Accuracy on batch 1672/3013  on Training is 81.46294082486551\n",
            "Epoch #1. Accuracy on batch 1673/3013  on Training is 81.46468040621266\n",
            "Epoch #1. Accuracy on batch 1674/3013  on Training is 81.4589552238806\n",
            "Epoch #1. Accuracy on batch 1675/3013  on Training is 81.4551014319809\n",
            "Epoch #1. Accuracy on batch 1676/3013  on Training is 81.44938878950506\n",
            "Epoch #1. Accuracy on batch 1677/3013  on Training is 81.44926996424314\n",
            "Epoch #1. Accuracy on batch 1678/3013  on Training is 81.44915128052412\n",
            "Epoch #1. Accuracy on batch 1679/3013  on Training is 81.45089285714286\n",
            "Batch Id 1680 is having training loss of 0.6843184232711792\n",
            "0.6868007779121399\n",
            "Epoch #1. Accuracy on batch 1680/3013  on Training is 81.45077334919691\n",
            "Epoch #1. Accuracy on batch 1681/3013  on Training is 81.4413644470868\n",
            "Epoch #1. Accuracy on batch 1682/3013  on Training is 81.44867795603089\n",
            "Epoch #1. Accuracy on batch 1683/3013  on Training is 81.44855997624703\n",
            "Epoch #1. Accuracy on batch 1684/3013  on Training is 81.44844213649851\n",
            "Epoch #1. Accuracy on batch 1685/3013  on Training is 81.45017793594306\n",
            "Epoch #1. Accuracy on batch 1686/3013  on Training is 81.43709247184351\n",
            "Epoch #1. Accuracy on batch 1687/3013  on Training is 81.42957642180095\n",
            "Epoch #1. Accuracy on batch 1688/3013  on Training is 81.42947010065127\n",
            "Epoch #1. Accuracy on batch 1689/3013  on Training is 81.43121301775147\n",
            "Epoch #1. Accuracy on batch 1690/3013  on Training is 81.43480189237138\n",
            "Epoch #1. Accuracy on batch 1691/3013  on Training is 81.43099881796691\n",
            "Epoch #1. Accuracy on batch 1692/3013  on Training is 81.41981689308919\n",
            "Epoch #1. Accuracy on batch 1693/3013  on Training is 81.4215613931523\n",
            "Epoch #1. Accuracy on batch 1694/3013  on Training is 81.42146017699115\n",
            "Epoch #1. Accuracy on batch 1695/3013  on Training is 81.41951650943396\n",
            "Epoch #1. Accuracy on batch 1696/3013  on Training is 81.42678255745433\n",
            "Epoch #1. Accuracy on batch 1697/3013  on Training is 81.42667844522968\n",
            "Epoch #1. Accuracy on batch 1698/3013  on Training is 81.42841377280753\n",
            "Epoch #1. Accuracy on batch 1699/3013  on Training is 81.43014705882354\n",
            "Batch Id 1700 is having training loss of 0.6849290132522583\n",
            "0.3177199363708496\n",
            "Epoch #1. Accuracy on batch 1700/3013  on Training is 81.43922692533803\n",
            "Epoch #1. Accuracy on batch 1701/3013  on Training is 81.43727967097533\n",
            "Epoch #1. Accuracy on batch 1702/3013  on Training is 81.43900469759248\n",
            "Epoch #1. Accuracy on batch 1703/3013  on Training is 81.43705985915493\n",
            "Epoch #1. Accuracy on batch 1704/3013  on Training is 81.43695014662757\n",
            "Epoch #1. Accuracy on batch 1705/3013  on Training is 81.43684056271981\n",
            "Epoch #1. Accuracy on batch 1706/3013  on Training is 81.43490041007615\n",
            "Epoch #1. Accuracy on batch 1707/3013  on Training is 81.43662177985948\n",
            "Epoch #1. Accuracy on batch 1708/3013  on Training is 81.4328554710357\n",
            "Epoch #1. Accuracy on batch 1709/3013  on Training is 81.44005847953217\n",
            "Epoch #1. Accuracy on batch 1710/3013  on Training is 81.44360023378141\n",
            "Epoch #1. Accuracy on batch 1711/3013  on Training is 81.4453125\n",
            "Epoch #1. Accuracy on batch 1712/3013  on Training is 81.44884705195564\n",
            "Epoch #1. Accuracy on batch 1713/3013  on Training is 81.44873103850642\n",
            "Epoch #1. Accuracy on batch 1714/3013  on Training is 81.44132653061224\n",
            "Epoch #1. Accuracy on batch 1715/3013  on Training is 81.43939393939394\n",
            "Epoch #1. Accuracy on batch 1716/3013  on Training is 81.44110366919045\n",
            "Epoch #1. Accuracy on batch 1717/3013  on Training is 81.4409924330617\n",
            "Epoch #1. Accuracy on batch 1718/3013  on Training is 81.43724549156487\n",
            "Epoch #1. Accuracy on batch 1719/3013  on Training is 81.43531976744185\n",
            "Batch Id 1720 is having training loss of 0.6847785115242004\n",
            "0.7389259934425354\n",
            "Epoch #1. Accuracy on batch 1720/3013  on Training is 81.43702789076119\n",
            "Epoch #1. Accuracy on batch 1721/3013  on Training is 81.43873403019745\n",
            "Epoch #1. Accuracy on batch 1722/3013  on Training is 81.44406558328497\n",
            "Epoch #1. Accuracy on batch 1723/3013  on Training is 81.4403277262181\n",
            "Epoch #1. Accuracy on batch 1724/3013  on Training is 81.44021739130434\n",
            "Epoch #1. Accuracy on batch 1725/3013  on Training is 81.4473493626883\n",
            "Epoch #1. Accuracy on batch 1726/3013  on Training is 81.44723508975102\n",
            "Epoch #1. Accuracy on batch 1727/3013  on Training is 81.44169560185185\n",
            "Epoch #1. Accuracy on batch 1728/3013  on Training is 81.43616252168884\n",
            "Epoch #1. Accuracy on batch 1729/3013  on Training is 81.4342485549133\n",
            "Epoch #1. Accuracy on batch 1730/3013  on Training is 81.43775274407857\n",
            "Epoch #1. Accuracy on batch 1731/3013  on Training is 81.4304272517321\n",
            "Epoch #1. Accuracy on batch 1732/3013  on Training is 81.42851990767456\n",
            "Epoch #1. Accuracy on batch 1733/3013  on Training is 81.43021914648212\n",
            "Epoch #1. Accuracy on batch 1734/3013  on Training is 81.42471181556196\n",
            "Epoch #1. Accuracy on batch 1735/3013  on Training is 81.42281105990783\n",
            "Epoch #1. Accuracy on batch 1736/3013  on Training is 81.42271157167531\n",
            "Epoch #1. Accuracy on batch 1737/3013  on Training is 81.42261219792866\n",
            "Epoch #1. Accuracy on batch 1738/3013  on Training is 81.42251293847039\n",
            "Epoch #1. Accuracy on batch 1739/3013  on Training is 81.42780172413794\n",
            "Batch Id 1740 is having training loss of 0.6848832368850708\n",
            "0.7108365297317505\n",
            "Epoch #1. Accuracy on batch 1740/3013  on Training is 81.42590465249856\n",
            "Epoch #1. Accuracy on batch 1741/3013  on Training is 81.42400975889782\n",
            "Epoch #1. Accuracy on batch 1742/3013  on Training is 81.43108146873207\n",
            "Epoch #1. Accuracy on batch 1743/3013  on Training is 81.43097763761467\n",
            "Epoch #1. Accuracy on batch 1744/3013  on Training is 81.42729226361031\n",
            "Epoch #1. Accuracy on batch 1745/3013  on Training is 81.43077033218786\n",
            "Epoch #1. Accuracy on batch 1746/3013  on Training is 81.42530051516886\n",
            "Epoch #1. Accuracy on batch 1747/3013  on Training is 81.4216247139588\n",
            "Epoch #1. Accuracy on batch 1748/3013  on Training is 81.41616638078902\n",
            "Epoch #1. Accuracy on batch 1749/3013  on Training is 81.41428571428571\n",
            "Epoch #1. Accuracy on batch 1750/3013  on Training is 81.41419189034838\n",
            "Epoch #1. Accuracy on batch 1751/3013  on Training is 81.42123287671232\n",
            "Epoch #1. Accuracy on batch 1752/3013  on Training is 81.42291785510554\n",
            "Epoch #1. Accuracy on batch 1753/3013  on Training is 81.42638255416192\n",
            "Epoch #1. Accuracy on batch 1754/3013  on Training is 81.42628205128206\n",
            "Epoch #1. Accuracy on batch 1755/3013  on Training is 81.42618166287016\n",
            "Epoch #1. Accuracy on batch 1756/3013  on Training is 81.42963858850312\n",
            "Epoch #1. Accuracy on batch 1757/3013  on Training is 81.43309158134244\n",
            "Epoch #1. Accuracy on batch 1758/3013  on Training is 81.42588118249004\n",
            "Epoch #1. Accuracy on batch 1759/3013  on Training is 81.43288352272727\n",
            "Batch Id 1760 is having training loss of 0.6845502257347107\n",
            "0.6295850276947021\n",
            "Epoch #1. Accuracy on batch 1760/3013  on Training is 81.43455423055083\n",
            "Epoch #1. Accuracy on batch 1761/3013  on Training is 81.43267593643587\n",
            "Epoch #1. Accuracy on batch 1762/3013  on Training is 81.4254821327283\n",
            "Epoch #1. Accuracy on batch 1763/3013  on Training is 81.421839569161\n",
            "Epoch #1. Accuracy on batch 1764/3013  on Training is 81.42174220963173\n",
            "Epoch #1. Accuracy on batch 1765/3013  on Training is 81.42695356738392\n",
            "Epoch #1. Accuracy on batch 1766/3013  on Training is 81.43392756083757\n",
            "Epoch #1. Accuracy on batch 1767/3013  on Training is 81.42852092760181\n",
            "Epoch #1. Accuracy on batch 1768/3013  on Training is 81.42665347654042\n",
            "Epoch #1. Accuracy on batch 1769/3013  on Training is 81.41949152542372\n",
            "Epoch #1. Accuracy on batch 1770/3013  on Training is 81.42645398080181\n",
            "Epoch #1. Accuracy on batch 1771/3013  on Training is 81.42988148984199\n",
            "Epoch #1. Accuracy on batch 1772/3013  on Training is 81.43330513254371\n",
            "Epoch #1. Accuracy on batch 1773/3013  on Training is 81.43320180383314\n",
            "Epoch #1. Accuracy on batch 1774/3013  on Training is 81.43661971830986\n",
            "Epoch #1. Accuracy on batch 1775/3013  on Training is 81.43475506756756\n",
            "Epoch #1. Accuracy on batch 1776/3013  on Training is 81.43816826111424\n",
            "Epoch #1. Accuracy on batch 1777/3013  on Training is 81.43806242969629\n",
            "Epoch #1. Accuracy on batch 1778/3013  on Training is 81.43795671725688\n",
            "Epoch #1. Accuracy on batch 1779/3013  on Training is 81.43960674157303\n",
            "Batch Id 1780 is having training loss of 0.6840842962265015\n",
            "0.5705616474151611\n",
            "Epoch #1. Accuracy on batch 1780/3013  on Training is 81.44300954519933\n",
            "Epoch #1. Accuracy on batch 1781/3013  on Training is 81.4429012345679\n",
            "Epoch #1. Accuracy on batch 1782/3013  on Training is 81.4410403813797\n",
            "Epoch #1. Accuracy on batch 1783/3013  on Training is 81.43567825112108\n",
            "Epoch #1. Accuracy on batch 1784/3013  on Training is 81.437324929972\n",
            "Epoch #1. Accuracy on batch 1785/3013  on Training is 81.43372060470325\n",
            "Epoch #1. Accuracy on batch 1786/3013  on Training is 81.44061275881366\n",
            "Epoch #1. Accuracy on batch 1787/3013  on Training is 81.44050615212528\n",
            "Epoch #1. Accuracy on batch 1788/3013  on Training is 81.44389323644494\n",
            "Epoch #1. Accuracy on batch 1789/3013  on Training is 81.44553072625699\n",
            "Epoch #1. Accuracy on batch 1790/3013  on Training is 81.44716638749303\n",
            "Epoch #1. Accuracy on batch 1791/3013  on Training is 81.45054408482143\n",
            "Epoch #1. Accuracy on batch 1792/3013  on Training is 81.45217512548801\n",
            "Epoch #1. Accuracy on batch 1793/3013  on Training is 81.4538043478261\n",
            "Epoch #1. Accuracy on batch 1794/3013  on Training is 81.45717270194986\n",
            "Epoch #1. Accuracy on batch 1795/3013  on Training is 81.4605373051225\n",
            "Epoch #1. Accuracy on batch 1796/3013  on Training is 81.4621591541458\n",
            "Epoch #1. Accuracy on batch 1797/3013  on Training is 81.4672552836485\n",
            "Epoch #1. Accuracy on batch 1798/3013  on Training is 81.46366036687049\n",
            "Epoch #1. Accuracy on batch 1799/3013  on Training is 81.46354166666667\n",
            "Batch Id 1800 is having training loss of 0.6832006573677063\n",
            "1.274033546447754\n",
            "Epoch #1. Accuracy on batch 1800/3013  on Training is 81.4582176568573\n",
            "Epoch #1. Accuracy on batch 1801/3013  on Training is 81.45810210876803\n",
            "Epoch #1. Accuracy on batch 1802/3013  on Training is 81.46145313366611\n",
            "Epoch #1. Accuracy on batch 1803/3013  on Training is 81.45960365853658\n",
            "Epoch #1. Accuracy on batch 1804/3013  on Training is 81.45948753462604\n",
            "Epoch #1. Accuracy on batch 1805/3013  on Training is 81.44898947951273\n",
            "Epoch #1. Accuracy on batch 1806/3013  on Training is 81.45060874377421\n",
            "Epoch #1. Accuracy on batch 1807/3013  on Training is 81.44876935840708\n",
            "Epoch #1. Accuracy on batch 1808/3013  on Training is 81.45211442786069\n",
            "Epoch #1. Accuracy on batch 1809/3013  on Training is 81.45545580110497\n",
            "Epoch #1. Accuracy on batch 1810/3013  on Training is 81.45189122032026\n",
            "Epoch #1. Accuracy on batch 1811/3013  on Training is 81.4517798013245\n",
            "Epoch #1. Accuracy on batch 1812/3013  on Training is 81.4430501930502\n",
            "Epoch #1. Accuracy on batch 1813/3013  on Training is 81.44638919514884\n",
            "Epoch #1. Accuracy on batch 1814/3013  on Training is 81.44800275482093\n",
            "Epoch #1. Accuracy on batch 1815/3013  on Training is 81.44617290748899\n",
            "Epoch #1. Accuracy on batch 1816/3013  on Training is 81.44606494221244\n",
            "Epoch #1. Accuracy on batch 1817/3013  on Training is 81.44767601760176\n",
            "Epoch #1. Accuracy on batch 1818/3013  on Training is 81.45272127542606\n",
            "Epoch #1. Accuracy on batch 1819/3013  on Training is 81.45776098901099\n",
            "Batch Id 1820 is having training loss of 0.6831022500991821\n",
            "0.7156907916069031\n",
            "Epoch #1. Accuracy on batch 1820/3013  on Training is 81.45593080724876\n",
            "Epoch #1. Accuracy on batch 1821/3013  on Training is 81.45753293084522\n",
            "Epoch #1. Accuracy on batch 1822/3013  on Training is 81.45913329676358\n",
            "Epoch #1. Accuracy on batch 1823/3013  on Training is 81.46587171052632\n",
            "Epoch #1. Accuracy on batch 1824/3013  on Training is 81.46575342465754\n",
            "Epoch #1. Accuracy on batch 1825/3013  on Training is 81.46734665936474\n",
            "Epoch #1. Accuracy on batch 1826/3013  on Training is 81.4706486042693\n",
            "Epoch #1. Accuracy on batch 1827/3013  on Training is 81.47052789934355\n",
            "Epoch #1. Accuracy on batch 1828/3013  on Training is 81.4755330781848\n",
            "Epoch #1. Accuracy on batch 1829/3013  on Training is 81.4771174863388\n",
            "Epoch #1. Accuracy on batch 1830/3013  on Training is 81.4684598580011\n",
            "Epoch #1. Accuracy on batch 1831/3013  on Training is 81.47004639737992\n",
            "Epoch #1. Accuracy on batch 1832/3013  on Training is 81.46822149481724\n",
            "Epoch #1. Accuracy on batch 1833/3013  on Training is 81.47151035986914\n",
            "Epoch #1. Accuracy on batch 1834/3013  on Training is 81.47820163487738\n",
            "Epoch #1. Accuracy on batch 1835/3013  on Training is 81.48148148148148\n",
            "Epoch #1. Accuracy on batch 1836/3013  on Training is 81.48135547087642\n",
            "Epoch #1. Accuracy on batch 1837/3013  on Training is 81.48292981501632\n",
            "Epoch #1. Accuracy on batch 1838/3013  on Training is 81.4879010331702\n",
            "Epoch #1. Accuracy on batch 1839/3013  on Training is 81.48777173913044\n",
            "Batch Id 1840 is having training loss of 0.6820916533470154\n",
            "0.4429498612880707\n",
            "Epoch #1. Accuracy on batch 1840/3013  on Training is 81.4927349266703\n",
            "Epoch #1. Accuracy on batch 1841/3013  on Training is 81.49260314875136\n",
            "Epoch #1. Accuracy on batch 1842/3013  on Training is 81.48908030385242\n",
            "Epoch #1. Accuracy on batch 1843/3013  on Training is 81.49403470715835\n",
            "Epoch #1. Accuracy on batch 1844/3013  on Training is 81.49559620596206\n",
            "Epoch #1. Accuracy on batch 1845/3013  on Training is 81.4988488624052\n",
            "Epoch #1. Accuracy on batch 1846/3013  on Training is 81.49871413102328\n",
            "Epoch #1. Accuracy on batch 1847/3013  on Training is 81.49350649350649\n",
            "Epoch #1. Accuracy on batch 1848/3013  on Training is 81.49844510546241\n",
            "Epoch #1. Accuracy on batch 1849/3013  on Training is 81.4983108108108\n",
            "Epoch #1. Accuracy on batch 1850/3013  on Training is 81.50492976769314\n",
            "Epoch #1. Accuracy on batch 1851/3013  on Training is 81.49973002159827\n",
            "Epoch #1. Accuracy on batch 1852/3013  on Training is 81.49959525094441\n",
            "Epoch #1. Accuracy on batch 1853/3013  on Training is 81.50451725997843\n",
            "Epoch #1. Accuracy on batch 1854/3013  on Training is 81.49932614555256\n",
            "Epoch #1. Accuracy on batch 1855/3013  on Training is 81.50255926724138\n",
            "Epoch #1. Accuracy on batch 1856/3013  on Training is 81.49569197630586\n",
            "Epoch #1. Accuracy on batch 1857/3013  on Training is 81.49724165769645\n",
            "Epoch #1. Accuracy on batch 1858/3013  on Training is 81.4971086605702\n",
            "Epoch #1. Accuracy on batch 1859/3013  on Training is 81.4986559139785\n",
            "Batch Id 1860 is having training loss of 0.6820409297943115\n",
            "0.5789536237716675\n",
            "Epoch #1. Accuracy on batch 1860/3013  on Training is 81.50188070929607\n",
            "Epoch #1. Accuracy on batch 1861/3013  on Training is 81.50510204081633\n",
            "Epoch #1. Accuracy on batch 1862/3013  on Training is 81.50328770799786\n",
            "Epoch #1. Accuracy on batch 1863/3013  on Training is 81.50482832618026\n",
            "Epoch #1. Accuracy on batch 1864/3013  on Training is 81.5063672922252\n",
            "Epoch #1. Accuracy on batch 1865/3013  on Training is 81.50622990353698\n",
            "Epoch #1. Accuracy on batch 1866/3013  on Training is 81.50441885377612\n",
            "Epoch #1. Accuracy on batch 1867/3013  on Training is 81.50093683083512\n",
            "Epoch #1. Accuracy on batch 1868/3013  on Training is 81.5008025682183\n",
            "Epoch #1. Accuracy on batch 1869/3013  on Training is 81.50066844919786\n",
            "Epoch #1. Accuracy on batch 1870/3013  on Training is 81.50721539283805\n",
            "Epoch #1. Accuracy on batch 1871/3013  on Training is 81.50540865384616\n",
            "Epoch #1. Accuracy on batch 1872/3013  on Training is 81.50694073678591\n",
            "Epoch #1. Accuracy on batch 1873/3013  on Training is 81.50180096051227\n",
            "Epoch #1. Accuracy on batch 1874/3013  on Training is 81.50666666666666\n",
            "Epoch #1. Accuracy on batch 1875/3013  on Training is 81.50986140724947\n",
            "Epoch #1. Accuracy on batch 1876/3013  on Training is 81.50306339904103\n",
            "Epoch #1. Accuracy on batch 1877/3013  on Training is 81.50292864749734\n",
            "Epoch #1. Accuracy on batch 1878/3013  on Training is 81.50113092070251\n",
            "Epoch #1. Accuracy on batch 1879/3013  on Training is 81.50099734042553\n",
            "Batch Id 1880 is having training loss of 0.6817715764045715\n",
            "0.40143731236457825\n",
            "Epoch #1. Accuracy on batch 1880/3013  on Training is 81.50418660287082\n",
            "Epoch #1. Accuracy on batch 1881/3013  on Training is 81.50903294367694\n",
            "Epoch #1. Accuracy on batch 1882/3013  on Training is 81.51221455124801\n",
            "Epoch #1. Accuracy on batch 1883/3013  on Training is 81.50378184713375\n",
            "Epoch #1. Accuracy on batch 1884/3013  on Training is 81.50364721485411\n",
            "Epoch #1. Accuracy on batch 1885/3013  on Training is 81.50682661717921\n",
            "Epoch #1. Accuracy on batch 1886/3013  on Training is 81.50503444621091\n",
            "Epoch #1. Accuracy on batch 1887/3013  on Training is 81.51152012711864\n",
            "Epoch #1. Accuracy on batch 1888/3013  on Training is 81.5080730545262\n",
            "Epoch #1. Accuracy on batch 1889/3013  on Training is 81.51289682539682\n",
            "Epoch #1. Accuracy on batch 1890/3013  on Training is 81.50780010576415\n",
            "Epoch #1. Accuracy on batch 1891/3013  on Training is 81.50766384778012\n",
            "Epoch #1. Accuracy on batch 1892/3013  on Training is 81.50917855256208\n",
            "Epoch #1. Accuracy on batch 1893/3013  on Training is 81.51069165786694\n",
            "Epoch #1. Accuracy on batch 1894/3013  on Training is 81.51220316622691\n",
            "Epoch #1. Accuracy on batch 1895/3013  on Training is 81.51536128691983\n",
            "Epoch #1. Accuracy on batch 1896/3013  on Training is 81.51357406431207\n",
            "Epoch #1. Accuracy on batch 1897/3013  on Training is 81.51837460484721\n",
            "Epoch #1. Accuracy on batch 1898/3013  on Training is 81.5149420747762\n",
            "Epoch #1. Accuracy on batch 1899/3013  on Training is 81.51644736842105\n",
            "Batch Id 1900 is having training loss of 0.6813957691192627\n",
            "0.6037619709968567\n",
            "Epoch #1. Accuracy on batch 1900/3013  on Training is 81.5195949500263\n",
            "Epoch #1. Accuracy on batch 1901/3013  on Training is 81.51452418506835\n",
            "Epoch #1. Accuracy on batch 1902/3013  on Training is 81.50781660535996\n",
            "Epoch #1. Accuracy on batch 1903/3013  on Training is 81.50932247899159\n",
            "Epoch #1. Accuracy on batch 1904/3013  on Training is 81.51082677165354\n",
            "Epoch #1. Accuracy on batch 1905/3013  on Training is 81.51396904512067\n",
            "Epoch #1. Accuracy on batch 1906/3013  on Training is 81.51219192448873\n",
            "Epoch #1. Accuracy on batch 1907/3013  on Training is 81.51533018867924\n",
            "Epoch #1. Accuracy on batch 1908/3013  on Training is 81.52173913043478\n",
            "Epoch #1. Accuracy on batch 1909/3013  on Training is 81.52159685863874\n",
            "Epoch #1. Accuracy on batch 1910/3013  on Training is 81.51654892726322\n",
            "Epoch #1. Accuracy on batch 1911/3013  on Training is 81.51804393305439\n",
            "Epoch #1. Accuracy on batch 1912/3013  on Training is 81.51300313643492\n",
            "Epoch #1. Accuracy on batch 1913/3013  on Training is 81.52102925809822\n",
            "Epoch #1. Accuracy on batch 1914/3013  on Training is 81.51762402088772\n",
            "Epoch #1. Accuracy on batch 1915/3013  on Training is 81.51911534446764\n",
            "Epoch #1. Accuracy on batch 1916/3013  on Training is 81.52386541471049\n",
            "Epoch #1. Accuracy on batch 1917/3013  on Training is 81.52698123044838\n",
            "Epoch #1. Accuracy on batch 1918/3013  on Training is 81.53009379885357\n",
            "Epoch #1. Accuracy on batch 1919/3013  on Training is 81.533203125\n",
            "Batch Id 1920 is having training loss of 0.6814568042755127\n",
            "0.8669681549072266\n",
            "Epoch #1. Accuracy on batch 1920/3013  on Training is 81.52817542946381\n",
            "Epoch #1. Accuracy on batch 1921/3013  on Training is 81.52965660770032\n",
            "Epoch #1. Accuracy on batch 1922/3013  on Training is 81.53113624544982\n",
            "Epoch #1. Accuracy on batch 1923/3013  on Training is 81.53423856548856\n",
            "Epoch #1. Accuracy on batch 1924/3013  on Training is 81.53084415584415\n",
            "Epoch #1. Accuracy on batch 1925/3013  on Training is 81.52745327102804\n",
            "Epoch #1. Accuracy on batch 1926/3013  on Training is 81.52406590555267\n",
            "Epoch #1. Accuracy on batch 1927/3013  on Training is 81.5174403526971\n",
            "Epoch #1. Accuracy on batch 1928/3013  on Training is 81.51730171073095\n",
            "Epoch #1. Accuracy on batch 1929/3013  on Training is 81.51554404145078\n",
            "Epoch #1. Accuracy on batch 1930/3013  on Training is 81.51216986017607\n",
            "Epoch #1. Accuracy on batch 1931/3013  on Training is 81.5136516563147\n",
            "Epoch #1. Accuracy on batch 1932/3013  on Training is 81.51513191929644\n",
            "Epoch #1. Accuracy on batch 1933/3013  on Training is 81.51984229576009\n",
            "Epoch #1. Accuracy on batch 1934/3013  on Training is 81.51970284237726\n",
            "Epoch #1. Accuracy on batch 1935/3013  on Training is 81.52440599173553\n",
            "Epoch #1. Accuracy on batch 1936/3013  on Training is 81.52265100671141\n",
            "Epoch #1. Accuracy on batch 1937/3013  on Training is 81.52734778121776\n",
            "Epoch #1. Accuracy on batch 1938/3013  on Training is 81.5288164002063\n",
            "Epoch #1. Accuracy on batch 1939/3013  on Training is 81.52867268041237\n",
            "Batch Id 1940 is having training loss of 0.6814918518066406\n",
            "0.7545276284217834\n",
            "Epoch #1. Accuracy on batch 1940/3013  on Training is 81.52852910870685\n",
            "Epoch #1. Accuracy on batch 1941/3013  on Training is 81.53482234809475\n",
            "Epoch #1. Accuracy on batch 1942/3013  on Training is 81.5362840967576\n",
            "Epoch #1. Accuracy on batch 1943/3013  on Training is 81.53935185185185\n",
            "Epoch #1. Accuracy on batch 1944/3013  on Training is 81.5392030848329\n",
            "Epoch #1. Accuracy on batch 1945/3013  on Training is 81.53744861253854\n",
            "Epoch #1. Accuracy on batch 1946/3013  on Training is 81.54372110939907\n",
            "Epoch #1. Accuracy on batch 1947/3013  on Training is 81.54677874743327\n",
            "Epoch #1. Accuracy on batch 1948/3013  on Training is 81.5498332478194\n",
            "Epoch #1. Accuracy on batch 1949/3013  on Training is 81.53685897435898\n",
            "Epoch #1. Accuracy on batch 1950/3013  on Training is 81.53350845720144\n",
            "Epoch #1. Accuracy on batch 1951/3013  on Training is 81.53176229508196\n",
            "Epoch #1. Accuracy on batch 1952/3013  on Training is 81.53321812596006\n",
            "Epoch #1. Accuracy on batch 1953/3013  on Training is 81.53147389969294\n",
            "Epoch #1. Accuracy on batch 1954/3013  on Training is 81.5361253196931\n",
            "Epoch #1. Accuracy on batch 1955/3013  on Training is 81.54077198364008\n",
            "Epoch #1. Accuracy on batch 1956/3013  on Training is 81.5438170669392\n",
            "Epoch #1. Accuracy on batch 1957/3013  on Training is 81.54207099080695\n",
            "Epoch #1. Accuracy on batch 1958/3013  on Training is 81.54351710056152\n",
            "Epoch #1. Accuracy on batch 1959/3013  on Training is 81.54177295918367\n",
            "Batch Id 1960 is having training loss of 0.6810832023620605\n",
            "0.29466933012008667\n",
            "Epoch #1. Accuracy on batch 1960/3013  on Training is 81.54799847016828\n",
            "Epoch #1. Accuracy on batch 1961/3013  on Training is 81.55581039755351\n",
            "Epoch #1. Accuracy on batch 1962/3013  on Training is 81.54928680590932\n",
            "Epoch #1. Accuracy on batch 1963/3013  on Training is 81.55390784114053\n",
            "Epoch #1. Accuracy on batch 1964/3013  on Training is 81.56011450381679\n",
            "Epoch #1. Accuracy on batch 1965/3013  on Training is 81.5615462868769\n",
            "Epoch #1. Accuracy on batch 1966/3013  on Training is 81.56456532791053\n",
            "Epoch #1. Accuracy on batch 1967/3013  on Training is 81.55646595528455\n",
            "Epoch #1. Accuracy on batch 1968/3013  on Training is 81.55789740985271\n",
            "Epoch #1. Accuracy on batch 1969/3013  on Training is 81.56091370558376\n",
            "Epoch #1. Accuracy on batch 1970/3013  on Training is 81.55917047184171\n",
            "Epoch #1. Accuracy on batch 1971/3013  on Training is 81.55901369168357\n",
            "Epoch #1. Accuracy on batch 1972/3013  on Training is 81.55727318803852\n",
            "Epoch #1. Accuracy on batch 1973/3013  on Training is 81.56186676798379\n",
            "Epoch #1. Accuracy on batch 1974/3013  on Training is 81.55696202531645\n",
            "Epoch #1. Accuracy on batch 1975/3013  on Training is 81.55996963562752\n",
            "Epoch #1. Accuracy on batch 1976/3013  on Training is 81.55823216995448\n",
            "Epoch #1. Accuracy on batch 1977/3013  on Training is 81.55017694641052\n",
            "Epoch #1. Accuracy on batch 1978/3013  on Training is 81.5516043456291\n",
            "Epoch #1. Accuracy on batch 1979/3013  on Training is 81.55145202020202\n",
            "Batch Id 1980 is having training loss of 0.681290328502655\n",
            "0.6976407766342163\n",
            "Epoch #1. Accuracy on batch 1980/3013  on Training is 81.55129984856133\n",
            "Epoch #1. Accuracy on batch 1981/3013  on Training is 81.54957114026236\n",
            "Epoch #1. Accuracy on batch 1982/3013  on Training is 81.5494200706001\n",
            "Epoch #1. Accuracy on batch 1983/3013  on Training is 81.5461189516129\n",
            "Epoch #1. Accuracy on batch 1984/3013  on Training is 81.54754408060454\n",
            "Epoch #1. Accuracy on batch 1985/3013  on Training is 81.54896777442094\n",
            "Epoch #1. Accuracy on batch 1986/3013  on Training is 81.55039003522899\n",
            "Epoch #1. Accuracy on batch 1987/3013  on Training is 81.545523138833\n",
            "Epoch #1. Accuracy on batch 1988/3013  on Training is 81.54537456008045\n",
            "Epoch #1. Accuracy on batch 1989/3013  on Training is 81.55150753768844\n",
            "Epoch #1. Accuracy on batch 1990/3013  on Training is 81.55449522852838\n",
            "Epoch #1. Accuracy on batch 1991/3013  on Training is 81.56218624497993\n",
            "Epoch #1. Accuracy on batch 1992/3013  on Training is 81.56202960361264\n",
            "Epoch #1. Accuracy on batch 1993/3013  on Training is 81.5650075225677\n",
            "Epoch #1. Accuracy on batch 1994/3013  on Training is 81.56641604010025\n",
            "Epoch #1. Accuracy on batch 1995/3013  on Training is 81.56782314629258\n",
            "Epoch #1. Accuracy on batch 1996/3013  on Training is 81.56296945418127\n",
            "Epoch #1. Accuracy on batch 1997/3013  on Training is 81.56437687687688\n",
            "Epoch #1. Accuracy on batch 1998/3013  on Training is 81.56890945472736\n",
            "Epoch #1. Accuracy on batch 1999/3013  on Training is 81.571875\n",
            "Batch Id 2000 is having training loss of 0.6805148720741272\n",
            "0.8548372983932495\n",
            "Epoch #1. Accuracy on batch 2000/3013  on Training is 81.5701524237881\n",
            "Epoch #1. Accuracy on batch 2001/3013  on Training is 81.57311438561439\n",
            "Epoch #1. Accuracy on batch 2002/3013  on Training is 81.56983275087369\n",
            "Epoch #1. Accuracy on batch 2003/3013  on Training is 81.57279191616766\n",
            "Epoch #1. Accuracy on batch 2004/3013  on Training is 81.57418952618454\n",
            "Epoch #1. Accuracy on batch 2005/3013  on Training is 81.580259222333\n",
            "Epoch #1. Accuracy on batch 2006/3013  on Training is 81.5754235176881\n",
            "Epoch #1. Accuracy on batch 2007/3013  on Training is 81.57214890438247\n",
            "Epoch #1. Accuracy on batch 2008/3013  on Training is 81.57198855151817\n",
            "Epoch #1. Accuracy on batch 2009/3013  on Training is 81.57649253731343\n",
            "Epoch #1. Accuracy on batch 2010/3013  on Training is 81.57477623073098\n",
            "Epoch #1. Accuracy on batch 2011/3013  on Training is 81.57306163021869\n",
            "Epoch #1. Accuracy on batch 2012/3013  on Training is 81.57445355191257\n",
            "Epoch #1. Accuracy on batch 2013/3013  on Training is 81.57894736842105\n",
            "Epoch #1. Accuracy on batch 2014/3013  on Training is 81.58188585607941\n",
            "Epoch #1. Accuracy on batch 2015/3013  on Training is 81.58327132936508\n",
            "Epoch #1. Accuracy on batch 2016/3013  on Training is 81.58155676747646\n",
            "Epoch #1. Accuracy on batch 2017/3013  on Training is 81.58448959365708\n",
            "Epoch #1. Accuracy on batch 2018/3013  on Training is 81.58432392273403\n",
            "Epoch #1. Accuracy on batch 2019/3013  on Training is 81.58106435643565\n",
            "Batch Id 2020 is having training loss of 0.6798948645591736\n",
            "0.8178277611732483\n",
            "Epoch #1. Accuracy on batch 2020/3013  on Training is 81.57780801583374\n",
            "Epoch #1. Accuracy on batch 2021/3013  on Training is 81.57764589515331\n",
            "Epoch #1. Accuracy on batch 2022/3013  on Training is 81.57748393475038\n",
            "Epoch #1. Accuracy on batch 2023/3013  on Training is 81.58041007905139\n",
            "Epoch #1. Accuracy on batch 2024/3013  on Training is 81.58333333333333\n",
            "Epoch #1. Accuracy on batch 2025/3013  on Training is 81.58471125370187\n",
            "Epoch #1. Accuracy on batch 2026/3013  on Training is 81.57992106561422\n",
            "Epoch #1. Accuracy on batch 2027/3013  on Training is 81.57975838264299\n",
            "Epoch #1. Accuracy on batch 2028/3013  on Training is 81.58883686545096\n",
            "Epoch #1. Accuracy on batch 2029/3013  on Training is 81.58713054187191\n",
            "Epoch #1. Accuracy on batch 2030/3013  on Training is 81.58388724766125\n",
            "Epoch #1. Accuracy on batch 2031/3013  on Training is 81.58218503937007\n",
            "Epoch #1. Accuracy on batch 2032/3013  on Training is 81.58048450565667\n",
            "Epoch #1. Accuracy on batch 2033/3013  on Training is 81.5833947885939\n",
            "Epoch #1. Accuracy on batch 2034/3013  on Training is 81.57708845208845\n",
            "Epoch #1. Accuracy on batch 2035/3013  on Training is 81.58306728880157\n",
            "Epoch #1. Accuracy on batch 2036/3013  on Training is 81.58597201767304\n",
            "Epoch #1. Accuracy on batch 2037/3013  on Training is 81.58274043179588\n",
            "Epoch #1. Accuracy on batch 2038/3013  on Training is 81.58870769985288\n",
            "Epoch #1. Accuracy on batch 2039/3013  on Training is 81.59160539215686\n",
            "Batch Id 2040 is having training loss of 0.6800081729888916\n",
            "0.6534759402275085\n",
            "Epoch #1. Accuracy on batch 2040/3013  on Training is 81.59143802057815\n",
            "Epoch #1. Accuracy on batch 2041/3013  on Training is 81.5912708129285\n",
            "Epoch #1. Accuracy on batch 2042/3013  on Training is 81.5880445423397\n",
            "Epoch #1. Accuracy on batch 2043/3013  on Training is 81.58940802348337\n",
            "Epoch #1. Accuracy on batch 2044/3013  on Training is 81.59382640586797\n",
            "Epoch #1. Accuracy on batch 2045/3013  on Training is 81.59976783968719\n",
            "Epoch #1. Accuracy on batch 2046/3013  on Training is 81.60112359550561\n",
            "Epoch #1. Accuracy on batch 2047/3013  on Training is 81.60247802734375\n",
            "Epoch #1. Accuracy on batch 2048/3013  on Training is 81.60535627135188\n",
            "Epoch #1. Accuracy on batch 2049/3013  on Training is 81.60975609756098\n",
            "Epoch #1. Accuracy on batch 2050/3013  on Training is 81.6095806923452\n",
            "Epoch #1. Accuracy on batch 2051/3013  on Training is 81.60331384015595\n",
            "Epoch #1. Accuracy on batch 2052/3013  on Training is 81.60618606916707\n",
            "Epoch #1. Accuracy on batch 2053/3013  on Training is 81.6075340798442\n",
            "Epoch #1. Accuracy on batch 2054/3013  on Training is 81.61192214111922\n",
            "Epoch #1. Accuracy on batch 2055/3013  on Training is 81.61326605058366\n",
            "Epoch #1. Accuracy on batch 2056/3013  on Training is 81.60397423432183\n",
            "Epoch #1. Accuracy on batch 2057/3013  on Training is 81.60683916423713\n",
            "Epoch #1. Accuracy on batch 2058/3013  on Training is 81.61121903836813\n",
            "Epoch #1. Accuracy on batch 2059/3013  on Training is 81.61559466019418\n",
            "Batch Id 2060 is having training loss of 0.6794562339782715\n",
            "0.9040929675102234\n",
            "Epoch #1. Accuracy on batch 2060/3013  on Training is 81.61390101892286\n",
            "Epoch #1. Accuracy on batch 2061/3013  on Training is 81.61524005819592\n",
            "Epoch #1. Accuracy on batch 2062/3013  on Training is 81.6196073679108\n",
            "Epoch #1. Accuracy on batch 2063/3013  on Training is 81.62397044573643\n",
            "Epoch #1. Accuracy on batch 2064/3013  on Training is 81.62984261501211\n",
            "Epoch #1. Accuracy on batch 2065/3013  on Training is 81.62663359148112\n",
            "Epoch #1. Accuracy on batch 2066/3013  on Training is 81.6309869375907\n",
            "Epoch #1. Accuracy on batch 2067/3013  on Training is 81.6292915860735\n",
            "Epoch #1. Accuracy on batch 2068/3013  on Training is 81.62457709038183\n",
            "Epoch #1. Accuracy on batch 2069/3013  on Training is 81.62590579710145\n",
            "Epoch #1. Accuracy on batch 2070/3013  on Training is 81.61516175760502\n",
            "Epoch #1. Accuracy on batch 2071/3013  on Training is 81.61649372586872\n",
            "Epoch #1. Accuracy on batch 2072/3013  on Training is 81.61480945489629\n",
            "Epoch #1. Accuracy on batch 2073/3013  on Training is 81.61764705882354\n",
            "Epoch #1. Accuracy on batch 2074/3013  on Training is 81.625\n",
            "Epoch #1. Accuracy on batch 2075/3013  on Training is 81.62481936416185\n",
            "Epoch #1. Accuracy on batch 2076/3013  on Training is 81.6231343283582\n",
            "Epoch #1. Accuracy on batch 2077/3013  on Training is 81.62145091434071\n",
            "Epoch #1. Accuracy on batch 2078/3013  on Training is 81.61976911976912\n",
            "Epoch #1. Accuracy on batch 2079/3013  on Training is 81.6180889423077\n",
            "Batch Id 2080 is having training loss of 0.6791780591011047\n",
            "0.666585385799408\n",
            "Epoch #1. Accuracy on batch 2080/3013  on Training is 81.6194137433926\n",
            "Epoch #1. Accuracy on batch 2081/3013  on Training is 81.61323246878001\n",
            "Epoch #1. Accuracy on batch 2082/3013  on Training is 81.61305808929428\n",
            "Epoch #1. Accuracy on batch 2083/3013  on Training is 81.61438339731286\n",
            "Epoch #1. Accuracy on batch 2084/3013  on Training is 81.61420863309353\n",
            "Epoch #1. Accuracy on batch 2085/3013  on Training is 81.61852828379673\n",
            "Epoch #1. Accuracy on batch 2086/3013  on Training is 81.62284379492094\n",
            "Epoch #1. Accuracy on batch 2087/3013  on Training is 81.6271551724138\n",
            "Epoch #1. Accuracy on batch 2088/3013  on Training is 81.6269746290091\n",
            "Epoch #1. Accuracy on batch 2089/3013  on Training is 81.62679425837321\n",
            "Epoch #1. Accuracy on batch 2090/3013  on Training is 81.62810856049737\n",
            "Epoch #1. Accuracy on batch 2091/3013  on Training is 81.63091539196941\n",
            "Epoch #1. Accuracy on batch 2092/3013  on Training is 81.63371954132823\n",
            "Epoch #1. Accuracy on batch 2093/3013  on Training is 81.63055157593124\n",
            "Epoch #1. Accuracy on batch 2094/3013  on Training is 81.62589498806683\n",
            "Epoch #1. Accuracy on batch 2095/3013  on Training is 81.62571564885496\n",
            "Epoch #1. Accuracy on batch 2096/3013  on Training is 81.62255603242728\n",
            "Epoch #1. Accuracy on batch 2097/3013  on Training is 81.6193994280267\n",
            "Epoch #1. Accuracy on batch 2098/3013  on Training is 81.61475702715579\n",
            "Epoch #1. Accuracy on batch 2099/3013  on Training is 81.61904761904762\n",
            "Batch Id 2100 is having training loss of 0.6795454025268555\n",
            "0.6113696098327637\n",
            "Epoch #1. Accuracy on batch 2100/3013  on Training is 81.6218467396478\n",
            "Epoch #1. Accuracy on batch 2101/3013  on Training is 81.6157231208373\n",
            "Epoch #1. Accuracy on batch 2102/3013  on Training is 81.62000713266762\n",
            "Epoch #1. Accuracy on batch 2103/3013  on Training is 81.62131653992395\n",
            "Epoch #1. Accuracy on batch 2104/3013  on Training is 81.62262470308788\n",
            "Epoch #1. Accuracy on batch 2105/3013  on Training is 81.61799620132953\n",
            "Epoch #1. Accuracy on batch 2106/3013  on Training is 81.61337209302326\n",
            "Epoch #1. Accuracy on batch 2107/3013  on Training is 81.61023481973434\n",
            "Epoch #1. Accuracy on batch 2108/3013  on Training is 81.6130275011854\n",
            "Epoch #1. Accuracy on batch 2109/3013  on Training is 81.61729857819905\n",
            "Epoch #1. Accuracy on batch 2110/3013  on Training is 81.61268356229276\n",
            "Epoch #1. Accuracy on batch 2111/3013  on Training is 81.61251183712122\n",
            "Epoch #1. Accuracy on batch 2112/3013  on Training is 81.61086133459536\n",
            "Epoch #1. Accuracy on batch 2113/3013  on Training is 81.61512535477767\n",
            "Epoch #1. Accuracy on batch 2114/3013  on Training is 81.62086288416076\n",
            "Epoch #1. Accuracy on batch 2115/3013  on Training is 81.62068761814744\n",
            "Epoch #1. Accuracy on batch 2116/3013  on Training is 81.62641709966934\n",
            "Epoch #1. Accuracy on batch 2117/3013  on Training is 81.62476392823419\n",
            "Epoch #1. Accuracy on batch 2118/3013  on Training is 81.6216375648891\n",
            "Epoch #1. Accuracy on batch 2119/3013  on Training is 81.61998820754717\n",
            "Batch Id 2120 is having training loss of 0.6797233819961548\n",
            "0.6610348224639893\n",
            "Epoch #1. Accuracy on batch 2120/3013  on Training is 81.61686704384724\n",
            "Epoch #1. Accuracy on batch 2121/3013  on Training is 81.61816682375118\n",
            "Epoch #1. Accuracy on batch 2122/3013  on Training is 81.6150494583137\n",
            "Epoch #1. Accuracy on batch 2123/3013  on Training is 81.61340630885122\n",
            "Epoch #1. Accuracy on batch 2124/3013  on Training is 81.61029411764706\n",
            "Epoch #1. Accuracy on batch 2125/3013  on Training is 81.61012464722484\n",
            "Epoch #1. Accuracy on batch 2126/3013  on Training is 81.60260930888576\n",
            "Epoch #1. Accuracy on batch 2127/3013  on Training is 81.59950657894737\n",
            "Epoch #1. Accuracy on batch 2128/3013  on Training is 81.60374589008924\n",
            "Epoch #1. Accuracy on batch 2129/3013  on Training is 81.6006455399061\n",
            "Epoch #1. Accuracy on batch 2130/3013  on Training is 81.60488033786955\n",
            "Epoch #1. Accuracy on batch 2131/3013  on Training is 81.60911116322701\n",
            "Epoch #1. Accuracy on batch 2132/3013  on Training is 81.60601265822785\n",
            "Epoch #1. Accuracy on batch 2133/3013  on Training is 81.6058458294283\n",
            "Epoch #1. Accuracy on batch 2134/3013  on Training is 81.60275175644028\n",
            "Epoch #1. Accuracy on batch 2135/3013  on Training is 81.59527153558052\n",
            "Epoch #1. Accuracy on batch 2136/3013  on Training is 81.59803462798315\n",
            "Epoch #1. Accuracy on batch 2137/3013  on Training is 81.59787184284377\n",
            "Epoch #1. Accuracy on batch 2138/3013  on Training is 81.59624824684433\n",
            "Epoch #1. Accuracy on batch 2139/3013  on Training is 81.60046728971963\n",
            "Batch Id 2140 is having training loss of 0.6795564293861389\n",
            "0.7312127947807312\n",
            "Epoch #1. Accuracy on batch 2140/3013  on Training is 81.60322279308734\n",
            "Epoch #1. Accuracy on batch 2141/3013  on Training is 81.6030578898226\n",
            "Epoch #1. Accuracy on batch 2142/3013  on Training is 81.60726784881008\n",
            "Epoch #1. Accuracy on batch 2143/3013  on Training is 81.60710121268657\n",
            "Epoch #1. Accuracy on batch 2144/3013  on Training is 81.60984848484848\n",
            "Epoch #1. Accuracy on batch 2145/3013  on Training is 81.60968080149115\n",
            "Epoch #1. Accuracy on batch 2146/3013  on Training is 81.60951327433628\n",
            "Epoch #1. Accuracy on batch 2147/3013  on Training is 81.6064362197393\n",
            "Epoch #1. Accuracy on batch 2148/3013  on Training is 81.60917868776176\n",
            "Epoch #1. Accuracy on batch 2149/3013  on Training is 81.61191860465117\n",
            "Epoch #1. Accuracy on batch 2150/3013  on Training is 81.61175034867503\n",
            "Epoch #1. Accuracy on batch 2151/3013  on Training is 81.61013011152416\n",
            "Epoch #1. Accuracy on batch 2152/3013  on Training is 81.61286576869485\n",
            "Epoch #1. Accuracy on batch 2153/3013  on Training is 81.6126973073352\n",
            "Epoch #1. Accuracy on batch 2154/3013  on Training is 81.61397911832947\n",
            "Epoch #1. Accuracy on batch 2155/3013  on Training is 81.61525974025975\n",
            "Epoch #1. Accuracy on batch 2156/3013  on Training is 81.61943671766342\n",
            "Epoch #1. Accuracy on batch 2157/3013  on Training is 81.62071362372568\n",
            "Epoch #1. Accuracy on batch 2158/3013  on Training is 81.62054191755442\n",
            "Epoch #1. Accuracy on batch 2159/3013  on Training is 81.62181712962963\n",
            "Batch Id 2160 is having training loss of 0.6788156628608704\n",
            "0.8077365756034851\n",
            "Epoch #1. Accuracy on batch 2160/3013  on Training is 81.6201989819528\n",
            "Epoch #1. Accuracy on batch 2161/3013  on Training is 81.62002775208141\n",
            "Epoch #1. Accuracy on batch 2162/3013  on Training is 81.61841192787794\n",
            "Epoch #1. Accuracy on batch 2163/3013  on Training is 81.61246534195934\n",
            "Epoch #1. Accuracy on batch 2164/3013  on Training is 81.61374133949192\n",
            "Epoch #1. Accuracy on batch 2165/3013  on Training is 81.61934441366574\n",
            "Epoch #1. Accuracy on batch 2166/3013  on Training is 81.62205814490079\n",
            "Epoch #1. Accuracy on batch 2167/3013  on Training is 81.62188653136532\n",
            "Epoch #1. Accuracy on batch 2168/3013  on Training is 81.62027431996312\n",
            "Epoch #1. Accuracy on batch 2169/3013  on Training is 81.62154377880184\n",
            "Epoch #1. Accuracy on batch 2170/3013  on Training is 81.61993321050207\n",
            "Epoch #1. Accuracy on batch 2171/3013  on Training is 81.61400782688766\n",
            "Epoch #1. Accuracy on batch 2172/3013  on Training is 81.61527841693511\n",
            "Epoch #1. Accuracy on batch 2173/3013  on Training is 81.61223551057958\n",
            "Epoch #1. Accuracy on batch 2174/3013  on Training is 81.61637931034483\n",
            "Epoch #1. Accuracy on batch 2175/3013  on Training is 81.61477481617646\n",
            "Epoch #1. Accuracy on batch 2176/3013  on Training is 81.61460725769408\n",
            "Epoch #1. Accuracy on batch 2177/3013  on Training is 81.62017906336088\n",
            "Epoch #1. Accuracy on batch 2178/3013  on Training is 81.62000917852225\n",
            "Epoch #1. Accuracy on batch 2179/3013  on Training is 81.61553899082568\n",
            "Batch Id 2180 is having training loss of 0.6790009140968323\n",
            "0.6628312468528748\n",
            "Epoch #1. Accuracy on batch 2180/3013  on Training is 81.61537138927098\n",
            "Epoch #1. Accuracy on batch 2181/3013  on Training is 81.61520394133822\n",
            "Epoch #1. Accuracy on batch 2182/3013  on Training is 81.61646816307834\n",
            "Epoch #1. Accuracy on batch 2183/3013  on Training is 81.61630036630036\n",
            "Epoch #1. Accuracy on batch 2184/3013  on Training is 81.61756292906179\n",
            "Epoch #1. Accuracy on batch 2185/3013  on Training is 81.6202538883806\n",
            "Epoch #1. Accuracy on batch 2186/3013  on Training is 81.6200845907636\n",
            "Epoch #1. Accuracy on batch 2187/3013  on Training is 81.6213436928702\n",
            "Epoch #1. Accuracy on batch 2188/3013  on Training is 81.62117405207857\n",
            "Epoch #1. Accuracy on batch 2189/3013  on Training is 81.62671232876713\n",
            "Epoch #1. Accuracy on batch 2190/3013  on Training is 81.62654039251484\n",
            "Epoch #1. Accuracy on batch 2191/3013  on Training is 81.62921989051095\n",
            "Epoch #1. Accuracy on batch 2192/3013  on Training is 81.62904696762426\n",
            "Epoch #1. Accuracy on batch 2193/3013  on Training is 81.62744986326345\n",
            "Epoch #1. Accuracy on batch 2194/3013  on Training is 81.624430523918\n",
            "Epoch #1. Accuracy on batch 2195/3013  on Training is 81.62141393442623\n",
            "Epoch #1. Accuracy on batch 2196/3013  on Training is 81.62266727355485\n",
            "Epoch #1. Accuracy on batch 2197/3013  on Training is 81.6196542311192\n",
            "Epoch #1. Accuracy on batch 2198/3013  on Training is 81.61522282855843\n",
            "Epoch #1. Accuracy on batch 2199/3013  on Training is 81.61647727272727\n",
            "Batch Id 2200 is having training loss of 0.6787921786308289\n",
            "0.7602933645248413\n",
            "Epoch #1. Accuracy on batch 2200/3013  on Training is 81.6134711494775\n",
            "Epoch #1. Accuracy on batch 2201/3013  on Training is 81.61330608537693\n",
            "Epoch #1. Accuracy on batch 2202/3013  on Training is 81.61314117113028\n",
            "Epoch #1. Accuracy on batch 2203/3013  on Training is 81.60872277676951\n",
            "Epoch #1. Accuracy on batch 2204/3013  on Training is 81.60997732426304\n",
            "Epoch #1. Accuracy on batch 2205/3013  on Training is 81.6098141432457\n",
            "Epoch #1. Accuracy on batch 2206/3013  on Training is 81.60965111010421\n",
            "Epoch #1. Accuracy on batch 2207/3013  on Training is 81.6109035326087\n",
            "Epoch #1. Accuracy on batch 2208/3013  on Training is 81.61215482118605\n",
            "Epoch #1. Accuracy on batch 2209/3013  on Training is 81.61057692307692\n",
            "Epoch #1. Accuracy on batch 2210/3013  on Training is 81.61182722749886\n",
            "Epoch #1. Accuracy on batch 2211/3013  on Training is 81.61166365280289\n",
            "Epoch #1. Accuracy on batch 2212/3013  on Training is 81.61432444645278\n",
            "Epoch #1. Accuracy on batch 2213/3013  on Training is 81.6113369467028\n",
            "Epoch #1. Accuracy on batch 2214/3013  on Training is 81.61117381489842\n",
            "Epoch #1. Accuracy on batch 2215/3013  on Training is 81.60960063176896\n",
            "Epoch #1. Accuracy on batch 2216/3013  on Training is 81.60661930536762\n",
            "Epoch #1. Accuracy on batch 2217/3013  on Training is 81.60504959422903\n",
            "Epoch #1. Accuracy on batch 2218/3013  on Training is 81.60348129788193\n",
            "Epoch #1. Accuracy on batch 2219/3013  on Training is 81.60332207207207\n",
            "Batch Id 2220 is having training loss of 0.6791324019432068\n",
            "0.5955869555473328\n",
            "Epoch #1. Accuracy on batch 2220/3013  on Training is 81.60597703737055\n",
            "Epoch #1. Accuracy on batch 2221/3013  on Training is 81.60581683168317\n",
            "Epoch #1. Accuracy on batch 2222/3013  on Training is 81.60425101214575\n",
            "Epoch #1. Accuracy on batch 2223/3013  on Training is 81.60549685251799\n",
            "Epoch #1. Accuracy on batch 2224/3013  on Training is 81.6067415730337\n",
            "Epoch #1. Accuracy on batch 2225/3013  on Training is 81.60658131176999\n",
            "Epoch #1. Accuracy on batch 2226/3013  on Training is 81.60501796138303\n",
            "Epoch #1. Accuracy on batch 2227/3013  on Training is 81.60485861759426\n",
            "Epoch #1. Accuracy on batch 2228/3013  on Training is 81.6018954688201\n",
            "Epoch #1. Accuracy on batch 2229/3013  on Training is 81.60313901345292\n",
            "Epoch #1. Accuracy on batch 2230/3013  on Training is 81.60578216046616\n",
            "Epoch #1. Accuracy on batch 2231/3013  on Training is 81.60982302867383\n",
            "Epoch #1. Accuracy on batch 2232/3013  on Training is 81.61106135244066\n",
            "Epoch #1. Accuracy on batch 2233/3013  on Training is 81.61089973142346\n",
            "Epoch #1. Accuracy on batch 2234/3013  on Training is 81.60654362416108\n",
            "Epoch #1. Accuracy on batch 2235/3013  on Training is 81.60638416815742\n",
            "Epoch #1. Accuracy on batch 2236/3013  on Training is 81.60622485471613\n",
            "Epoch #1. Accuracy on batch 2237/3013  on Training is 81.60885835567471\n",
            "Epoch #1. Accuracy on batch 2238/3013  on Training is 81.60730236712818\n",
            "Epoch #1. Accuracy on batch 2239/3013  on Training is 81.6015625\n",
            "Batch Id 2240 is having training loss of 0.6791300773620605\n",
            "0.9297584891319275\n",
            "Epoch #1. Accuracy on batch 2240/3013  on Training is 81.5958277554663\n",
            "Epoch #1. Accuracy on batch 2241/3013  on Training is 81.59567350579839\n",
            "Epoch #1. Accuracy on batch 2242/3013  on Training is 81.59691261703077\n",
            "Epoch #1. Accuracy on batch 2243/3013  on Training is 81.59536541889483\n",
            "Epoch #1. Accuracy on batch 2244/3013  on Training is 81.59799554565701\n",
            "Epoch #1. Accuracy on batch 2245/3013  on Training is 81.6006233303651\n",
            "Epoch #1. Accuracy on batch 2246/3013  on Training is 81.60463951935914\n",
            "Epoch #1. Accuracy on batch 2247/3013  on Training is 81.60031138790036\n",
            "Epoch #1. Accuracy on batch 2248/3013  on Training is 81.60015562472209\n",
            "Epoch #1. Accuracy on batch 2249/3013  on Training is 81.59583333333333\n",
            "Epoch #1. Accuracy on batch 2250/3013  on Training is 81.59567969791203\n",
            "Epoch #1. Accuracy on batch 2251/3013  on Training is 81.60385213143873\n",
            "Epoch #1. Accuracy on batch 2252/3013  on Training is 81.6023080337328\n",
            "Epoch #1. Accuracy on batch 2253/3013  on Training is 81.6035381543922\n",
            "Epoch #1. Accuracy on batch 2254/3013  on Training is 81.60753880266076\n",
            "Epoch #1. Accuracy on batch 2255/3013  on Training is 81.6087655141844\n",
            "Epoch #1. Accuracy on batch 2256/3013  on Training is 81.60722197607444\n",
            "Epoch #1. Accuracy on batch 2257/3013  on Training is 81.60983170947742\n",
            "Epoch #1. Accuracy on batch 2258/3013  on Training is 81.61382248782647\n",
            "Epoch #1. Accuracy on batch 2259/3013  on Training is 81.61227876106194\n",
            "Batch Id 2260 is having training loss of 0.6787961721420288\n",
            "0.6539545059204102\n",
            "Epoch #1. Accuracy on batch 2260/3013  on Training is 81.61350066342327\n",
            "Epoch #1. Accuracy on batch 2261/3013  on Training is 81.61472148541114\n",
            "Epoch #1. Accuracy on batch 2262/3013  on Training is 81.61041758727353\n",
            "Epoch #1. Accuracy on batch 2263/3013  on Training is 81.61025839222614\n",
            "Epoch #1. Accuracy on batch 2264/3013  on Training is 81.6073399558499\n",
            "Epoch #1. Accuracy on batch 2265/3013  on Training is 81.60994042365401\n",
            "Epoch #1. Accuracy on batch 2266/3013  on Training is 81.60702470224967\n",
            "Epoch #1. Accuracy on batch 2267/3013  on Training is 81.60548941798942\n",
            "Epoch #1. Accuracy on batch 2268/3013  on Training is 81.60533274570295\n",
            "Epoch #1. Accuracy on batch 2269/3013  on Training is 81.60379955947137\n",
            "Epoch #1. Accuracy on batch 2270/3013  on Training is 81.61052399823866\n",
            "Epoch #1. Accuracy on batch 2271/3013  on Training is 81.61036531690141\n",
            "Epoch #1. Accuracy on batch 2272/3013  on Training is 81.60883194016718\n",
            "Epoch #1. Accuracy on batch 2273/3013  on Training is 81.60867414248021\n",
            "Epoch #1. Accuracy on batch 2274/3013  on Training is 81.60851648351648\n",
            "Epoch #1. Accuracy on batch 2275/3013  on Training is 81.60973198594024\n",
            "Epoch #1. Accuracy on batch 2276/3013  on Training is 81.60820158102767\n",
            "Epoch #1. Accuracy on batch 2277/3013  on Training is 81.60392888498683\n",
            "Epoch #1. Accuracy on batch 2278/3013  on Training is 81.59965993856954\n",
            "Epoch #1. Accuracy on batch 2279/3013  on Training is 81.60224780701755\n",
            "Batch Id 2280 is having training loss of 0.6788474917411804\n",
            "0.8486831188201904\n",
            "Epoch #1. Accuracy on batch 2280/3013  on Training is 81.59798334064007\n",
            "Epoch #1. Accuracy on batch 2281/3013  on Training is 81.59646143733568\n",
            "Epoch #1. Accuracy on batch 2282/3013  on Training is 81.59357205431449\n",
            "Epoch #1. Accuracy on batch 2283/3013  on Training is 81.59342162872154\n",
            "Epoch #1. Accuracy on batch 2284/3013  on Training is 81.59600656455142\n",
            "Epoch #1. Accuracy on batch 2285/3013  on Training is 81.59312117235345\n",
            "Epoch #1. Accuracy on batch 2286/3013  on Training is 81.59433756012243\n",
            "Epoch #1. Accuracy on batch 2287/3013  on Training is 81.5969187062937\n",
            "Epoch #1. Accuracy on batch 2288/3013  on Training is 81.6008628221931\n",
            "Epoch #1. Accuracy on batch 2289/3013  on Training is 81.60207423580786\n",
            "Epoch #1. Accuracy on batch 2290/3013  on Training is 81.60601265822785\n",
            "Epoch #1. Accuracy on batch 2291/3013  on Training is 81.60585732984293\n",
            "Epoch #1. Accuracy on batch 2292/3013  on Training is 81.60433929350197\n",
            "Epoch #1. Accuracy on batch 2293/3013  on Training is 81.60690932868353\n",
            "Epoch #1. Accuracy on batch 2294/3013  on Training is 81.60675381263617\n",
            "Epoch #1. Accuracy on batch 2295/3013  on Training is 81.60795949477352\n",
            "Epoch #1. Accuracy on batch 2296/3013  on Training is 81.60508271658685\n",
            "Epoch #1. Accuracy on batch 2297/3013  on Training is 81.61036771105309\n",
            "Epoch #1. Accuracy on batch 2298/3013  on Training is 81.61292953458025\n",
            "Epoch #1. Accuracy on batch 2299/3013  on Training is 81.6100543478261\n",
            "Batch Id 2300 is having training loss of 0.6787015795707703\n",
            "1.0631479024887085\n",
            "Epoch #1. Accuracy on batch 2300/3013  on Training is 81.6098978704911\n",
            "Epoch #1. Accuracy on batch 2301/3013  on Training is 81.60431146828844\n",
            "Epoch #1. Accuracy on batch 2302/3013  on Training is 81.60551454624402\n",
            "Epoch #1. Accuracy on batch 2303/3013  on Training is 81.60671657986111\n",
            "Epoch #1. Accuracy on batch 2304/3013  on Training is 81.60520607375271\n",
            "Epoch #1. Accuracy on batch 2305/3013  on Training is 81.60640719861232\n",
            "Epoch #1. Accuracy on batch 2306/3013  on Training is 81.60760728218466\n",
            "Epoch #1. Accuracy on batch 2307/3013  on Training is 81.60474436741768\n",
            "Epoch #1. Accuracy on batch 2308/3013  on Training is 81.60865093113902\n",
            "Epoch #1. Accuracy on batch 2309/3013  on Training is 81.61525974025975\n",
            "Epoch #1. Accuracy on batch 2310/3013  on Training is 81.6137494591086\n",
            "Epoch #1. Accuracy on batch 2311/3013  on Training is 81.6149437716263\n",
            "Epoch #1. Accuracy on batch 2312/3013  on Training is 81.61613705144833\n",
            "Epoch #1. Accuracy on batch 2313/3013  on Training is 81.62138072601556\n",
            "Epoch #1. Accuracy on batch 2314/3013  on Training is 81.61852051835854\n",
            "Epoch #1. Accuracy on batch 2315/3013  on Training is 81.62375863557858\n",
            "Epoch #1. Accuracy on batch 2316/3013  on Training is 81.61820241691844\n",
            "Epoch #1. Accuracy on batch 2317/3013  on Training is 81.61399913718724\n",
            "Epoch #1. Accuracy on batch 2318/3013  on Training is 81.61518973695559\n",
            "Epoch #1. Accuracy on batch 2319/3013  on Training is 81.62042025862068\n",
            "Batch Id 2320 is having training loss of 0.6787653565406799\n",
            "0.8708187341690063\n",
            "Epoch #1. Accuracy on batch 2320/3013  on Training is 81.61891426109436\n",
            "Epoch #1. Accuracy on batch 2321/3013  on Training is 81.62279285099052\n",
            "Epoch #1. Accuracy on batch 2322/3013  on Training is 81.62666810159277\n",
            "Epoch #1. Accuracy on batch 2323/3013  on Training is 81.62650602409639\n",
            "Epoch #1. Accuracy on batch 2324/3013  on Training is 81.62903225806451\n",
            "Epoch #1. Accuracy on batch 2325/3013  on Training is 81.63424333619949\n",
            "Epoch #1. Accuracy on batch 2326/3013  on Training is 81.63676407391492\n",
            "Epoch #1. Accuracy on batch 2327/3013  on Training is 81.63525558419244\n",
            "Epoch #1. Accuracy on batch 2328/3013  on Training is 81.63509016745384\n",
            "Epoch #1. Accuracy on batch 2329/3013  on Training is 81.63760729613733\n",
            "Epoch #1. Accuracy on batch 2330/3013  on Training is 81.63744101244102\n",
            "Epoch #1. Accuracy on batch 2331/3013  on Training is 81.63727487135506\n",
            "Epoch #1. Accuracy on batch 2332/3013  on Training is 81.6397878268324\n",
            "Epoch #1. Accuracy on batch 2333/3013  on Training is 81.63828191945159\n",
            "Epoch #1. Accuracy on batch 2334/3013  on Training is 81.64213062098501\n",
            "Epoch #1. Accuracy on batch 2335/3013  on Training is 81.63794948630137\n",
            "Epoch #1. Accuracy on batch 2336/3013  on Training is 81.63510911424903\n",
            "Epoch #1. Accuracy on batch 2337/3013  on Training is 81.62959794696322\n",
            "Epoch #1. Accuracy on batch 2338/3013  on Training is 81.62809961522018\n",
            "Epoch #1. Accuracy on batch 2339/3013  on Training is 81.62526709401709\n",
            "Batch Id 2340 is having training loss of 0.6784611940383911\n",
            "0.41428664326667786\n",
            "Epoch #1. Accuracy on batch 2340/3013  on Training is 81.63044639043144\n",
            "Epoch #1. Accuracy on batch 2341/3013  on Training is 81.63028394534585\n",
            "Epoch #1. Accuracy on batch 2342/3013  on Training is 81.62478659837815\n",
            "Epoch #1. Accuracy on batch 2343/3013  on Training is 81.6272930887372\n",
            "Epoch #1. Accuracy on batch 2344/3013  on Training is 81.63113006396588\n",
            "Epoch #1. Accuracy on batch 2345/3013  on Training is 81.63096760443308\n",
            "Epoch #1. Accuracy on batch 2346/3013  on Training is 81.62947379633574\n",
            "Epoch #1. Accuracy on batch 2347/3013  on Training is 81.63197402044293\n",
            "Epoch #1. Accuracy on batch 2348/3013  on Training is 81.63314176245211\n",
            "Epoch #1. Accuracy on batch 2349/3013  on Training is 81.63297872340425\n",
            "Epoch #1. Accuracy on batch 2350/3013  on Training is 81.63547426626967\n",
            "Epoch #1. Accuracy on batch 2351/3013  on Training is 81.63663903061224\n",
            "Epoch #1. Accuracy on batch 2352/3013  on Training is 81.63780280492988\n",
            "Epoch #1. Accuracy on batch 2353/3013  on Training is 81.63498300764655\n",
            "Epoch #1. Accuracy on batch 2354/3013  on Training is 81.63614649681529\n",
            "Epoch #1. Accuracy on batch 2355/3013  on Training is 81.63067699490662\n",
            "Epoch #1. Accuracy on batch 2356/3013  on Training is 81.63449299957573\n",
            "Epoch #1. Accuracy on batch 2357/3013  on Training is 81.63167938931298\n",
            "Epoch #1. Accuracy on batch 2358/3013  on Training is 81.63284230606189\n",
            "Epoch #1. Accuracy on batch 2359/3013  on Training is 81.63003177966101\n",
            "Batch Id 2360 is having training loss of 0.6788135170936584\n",
            "1.0452879667282104\n",
            "Epoch #1. Accuracy on batch 2360/3013  on Training is 81.6285472257518\n",
            "Epoch #1. Accuracy on batch 2361/3013  on Training is 81.62706392887384\n",
            "Epoch #1. Accuracy on batch 2362/3013  on Training is 81.62954930173508\n",
            "Epoch #1. Accuracy on batch 2363/3013  on Training is 81.63335448392554\n",
            "Epoch #1. Accuracy on batch 2364/3013  on Training is 81.63451374207189\n",
            "Epoch #1. Accuracy on batch 2365/3013  on Training is 81.6356720202874\n",
            "Epoch #1. Accuracy on batch 2366/3013  on Training is 81.63418884664132\n",
            "Epoch #1. Accuracy on batch 2367/3013  on Training is 81.63270692567568\n",
            "Epoch #1. Accuracy on batch 2368/3013  on Training is 81.62990713381174\n",
            "Epoch #1. Accuracy on batch 2369/3013  on Training is 81.63370253164557\n",
            "Epoch #1. Accuracy on batch 2370/3013  on Training is 81.63485870940531\n",
            "Epoch #1. Accuracy on batch 2371/3013  on Training is 81.63996627318718\n",
            "Epoch #1. Accuracy on batch 2372/3013  on Training is 81.6398019384745\n",
            "Epoch #1. Accuracy on batch 2373/3013  on Training is 81.64358677337826\n",
            "Epoch #1. Accuracy on batch 2374/3013  on Training is 81.64736842105263\n",
            "Epoch #1. Accuracy on batch 2375/3013  on Training is 81.64983164983165\n",
            "Epoch #1. Accuracy on batch 2376/3013  on Training is 81.65229280605806\n",
            "Epoch #1. Accuracy on batch 2377/3013  on Training is 81.6521236333053\n",
            "Epoch #1. Accuracy on batch 2378/3013  on Training is 81.64538671710802\n",
            "Epoch #1. Accuracy on batch 2379/3013  on Training is 81.64259453781513\n",
            "Batch Id 2380 is having training loss of 0.6782159805297852\n",
            "0.48899126052856445\n",
            "Epoch #1. Accuracy on batch 2380/3013  on Training is 81.64505459890802\n",
            "Epoch #1. Accuracy on batch 2381/3013  on Training is 81.63964105793451\n",
            "Epoch #1. Accuracy on batch 2382/3013  on Training is 81.6394775493076\n",
            "Epoch #1. Accuracy on batch 2383/3013  on Training is 81.64455746644295\n",
            "Epoch #1. Accuracy on batch 2384/3013  on Training is 81.64832285115304\n",
            "Epoch #1. Accuracy on batch 2385/3013  on Training is 81.65077535624476\n",
            "Epoch #1. Accuracy on batch 2386/3013  on Training is 81.64537075827398\n",
            "Epoch #1. Accuracy on batch 2387/3013  on Training is 81.63997068676717\n",
            "Epoch #1. Accuracy on batch 2388/3013  on Training is 81.63849937212223\n",
            "Epoch #1. Accuracy on batch 2389/3013  on Training is 81.63833682008368\n",
            "Epoch #1. Accuracy on batch 2390/3013  on Training is 81.63948138854036\n",
            "Epoch #1. Accuracy on batch 2391/3013  on Training is 81.64454431438126\n",
            "Epoch #1. Accuracy on batch 2392/3013  on Training is 81.64699122440452\n",
            "Epoch #1. Accuracy on batch 2393/3013  on Training is 81.64682539682539\n",
            "Epoch #1. Accuracy on batch 2394/3013  on Training is 81.65187891440502\n",
            "Epoch #1. Accuracy on batch 2395/3013  on Training is 81.64910267111853\n",
            "Epoch #1. Accuracy on batch 2396/3013  on Training is 81.65284730913642\n",
            "Epoch #1. Accuracy on batch 2397/3013  on Training is 81.64876980817348\n",
            "Epoch #1. Accuracy on batch 2398/3013  on Training is 81.64860358482701\n",
            "Epoch #1. Accuracy on batch 2399/3013  on Training is 81.6484375\n",
            "Batch Id 2400 is having training loss of 0.6779437065124512\n",
            "0.3820827305316925\n",
            "Epoch #1. Accuracy on batch 2400/3013  on Training is 81.65347771761766\n",
            "Epoch #1. Accuracy on batch 2401/3013  on Training is 81.65461074104913\n",
            "Epoch #1. Accuracy on batch 2402/3013  on Training is 81.65834373699542\n",
            "Epoch #1. Accuracy on batch 2403/3013  on Training is 81.65947379367721\n",
            "Epoch #1. Accuracy on batch 2404/3013  on Training is 81.65150727650727\n",
            "Epoch #1. Accuracy on batch 2405/3013  on Training is 81.6565357439734\n",
            "Epoch #1. Accuracy on batch 2406/3013  on Training is 81.65377025342751\n",
            "Epoch #1. Accuracy on batch 2407/3013  on Training is 81.65100705980066\n",
            "Epoch #1. Accuracy on batch 2408/3013  on Training is 81.65602947281029\n",
            "Epoch #1. Accuracy on batch 2409/3013  on Training is 81.65845435684648\n",
            "Epoch #1. Accuracy on batch 2410/3013  on Training is 81.65698880132724\n",
            "Epoch #1. Accuracy on batch 2411/3013  on Training is 81.66070688225538\n",
            "Epoch #1. Accuracy on batch 2412/3013  on Training is 81.6605366763365\n",
            "Epoch #1. Accuracy on batch 2413/3013  on Training is 81.6603666114333\n",
            "Epoch #1. Accuracy on batch 2414/3013  on Training is 81.65890269151139\n",
            "Epoch #1. Accuracy on batch 2415/3013  on Training is 81.6561465231788\n",
            "Epoch #1. Accuracy on batch 2416/3013  on Training is 81.65597848572611\n",
            "Epoch #1. Accuracy on batch 2417/3013  on Training is 81.65968775847809\n",
            "Epoch #1. Accuracy on batch 2418/3013  on Training is 81.66210210830921\n",
            "Epoch #1. Accuracy on batch 2419/3013  on Training is 81.65805785123968\n",
            "Batch Id 2420 is having training loss of 0.6781156063079834\n",
            "0.6773894429206848\n",
            "Epoch #1. Accuracy on batch 2420/3013  on Training is 81.65788930194135\n",
            "Epoch #1. Accuracy on batch 2421/3013  on Training is 81.64997935590421\n",
            "Epoch #1. Accuracy on batch 2422/3013  on Training is 81.64723483285184\n",
            "Epoch #1. Accuracy on batch 2423/3013  on Training is 81.64964933993399\n",
            "Epoch #1. Accuracy on batch 2424/3013  on Training is 81.64690721649484\n",
            "Epoch #1. Accuracy on batch 2425/3013  on Training is 81.64803173948887\n",
            "Epoch #1. Accuracy on batch 2426/3013  on Training is 81.64915533580552\n",
            "Epoch #1. Accuracy on batch 2427/3013  on Training is 81.65156507413509\n",
            "Epoch #1. Accuracy on batch 2428/3013  on Training is 81.65139975298477\n",
            "Epoch #1. Accuracy on batch 2429/3013  on Training is 81.64866255144032\n",
            "Epoch #1. Accuracy on batch 2430/3013  on Training is 81.64721308103661\n",
            "Epoch #1. Accuracy on batch 2431/3013  on Training is 81.64704975328948\n",
            "Epoch #1. Accuracy on batch 2432/3013  on Training is 81.64817098232635\n",
            "Epoch #1. Accuracy on batch 2433/3013  on Training is 81.65057518488085\n",
            "Epoch #1. Accuracy on batch 2434/3013  on Training is 81.6452772073922\n",
            "Epoch #1. Accuracy on batch 2435/3013  on Training is 81.64126642036125\n",
            "Epoch #1. Accuracy on batch 2436/3013  on Training is 81.64110586787034\n",
            "Epoch #1. Accuracy on batch 2437/3013  on Training is 81.64222723543888\n",
            "Epoch #1. Accuracy on batch 2438/3013  on Training is 81.63950389503896\n",
            "Epoch #1. Accuracy on batch 2439/3013  on Training is 81.64318647540983\n",
            "Batch Id 2440 is having training loss of 0.6782337427139282\n",
            "0.5063251256942749\n",
            "Epoch #1. Accuracy on batch 2440/3013  on Training is 81.6443056124539\n",
            "Epoch #1. Accuracy on batch 2441/3013  on Training is 81.64670352170351\n",
            "Epoch #1. Accuracy on batch 2442/3013  on Training is 81.64654113794515\n",
            "Epoch #1. Accuracy on batch 2443/3013  on Training is 81.64510024549918\n",
            "Epoch #1. Accuracy on batch 2444/3013  on Training is 81.64366053169734\n",
            "Epoch #1. Accuracy on batch 2445/3013  on Training is 81.64733237939492\n",
            "Epoch #1. Accuracy on batch 2446/3013  on Training is 81.64972415202288\n",
            "Epoch #1. Accuracy on batch 2447/3013  on Training is 81.6546670751634\n",
            "Epoch #1. Accuracy on batch 2448/3013  on Training is 81.64939771335239\n",
            "Epoch #1. Accuracy on batch 2449/3013  on Training is 81.65306122448979\n",
            "Epoch #1. Accuracy on batch 2450/3013  on Training is 81.6516217870257\n",
            "Epoch #1. Accuracy on batch 2451/3013  on Training is 81.65273246329527\n",
            "Epoch #1. Accuracy on batch 2452/3013  on Training is 81.65384223399919\n",
            "Epoch #1. Accuracy on batch 2453/3013  on Training is 81.65749796251019\n",
            "Epoch #1. Accuracy on batch 2454/3013  on Training is 81.65733197556008\n",
            "Epoch #1. Accuracy on batch 2455/3013  on Training is 81.65843851791531\n",
            "Epoch #1. Accuracy on batch 2456/3013  on Training is 81.65827228327228\n",
            "Epoch #1. Accuracy on batch 2457/3013  on Training is 81.65937754271765\n",
            "Epoch #1. Accuracy on batch 2458/3013  on Training is 81.65794021960146\n",
            "Epoch #1. Accuracy on batch 2459/3013  on Training is 81.6628556910569\n",
            "Batch Id 2460 is having training loss of 0.6778120398521423\n",
            "0.9016443490982056\n",
            "Epoch #1. Accuracy on batch 2460/3013  on Training is 81.66141812271434\n",
            "Epoch #1. Accuracy on batch 2461/3013  on Training is 81.66252030869212\n",
            "Epoch #1. Accuracy on batch 2462/3013  on Training is 81.6636215996752\n",
            "Epoch #1. Accuracy on batch 2463/3013  on Training is 81.66725852272727\n",
            "Epoch #1. Accuracy on batch 2464/3013  on Training is 81.66962474645031\n",
            "Epoch #1. Accuracy on batch 2465/3013  on Training is 81.66311841038119\n",
            "Epoch #1. Accuracy on batch 2466/3013  on Training is 81.66168423186056\n",
            "Epoch #1. Accuracy on batch 2467/3013  on Training is 81.65898500810373\n",
            "Epoch #1. Accuracy on batch 2468/3013  on Training is 81.66388213851762\n",
            "Epoch #1. Accuracy on batch 2469/3013  on Training is 81.66244939271255\n",
            "Epoch #1. Accuracy on batch 2470/3013  on Training is 81.6635471469041\n",
            "Epoch #1. Accuracy on batch 2471/3013  on Training is 81.66590817152104\n",
            "Epoch #1. Accuracy on batch 2472/3013  on Training is 81.66700363930448\n",
            "Epoch #1. Accuracy on batch 2473/3013  on Training is 81.66936135812449\n",
            "Epoch #1. Accuracy on batch 2474/3013  on Training is 81.67045454545455\n",
            "Epoch #1. Accuracy on batch 2475/3013  on Training is 81.6690226171244\n",
            "Epoch #1. Accuracy on batch 2476/3013  on Training is 81.67137666532095\n",
            "Epoch #1. Accuracy on batch 2477/3013  on Training is 81.66868442292171\n",
            "Epoch #1. Accuracy on batch 2478/3013  on Training is 81.66851553045584\n",
            "Epoch #1. Accuracy on batch 2479/3013  on Training is 81.67338709677419\n",
            "Batch Id 2480 is having training loss of 0.6776232123374939\n",
            "0.47542476654052734\n",
            "Epoch #1. Accuracy on batch 2480/3013  on Training is 81.67447601773479\n",
            "Epoch #1. Accuracy on batch 2481/3013  on Training is 81.67682312651088\n",
            "Epoch #1. Accuracy on batch 2482/3013  on Training is 81.6728755537656\n",
            "Epoch #1. Accuracy on batch 2483/3013  on Training is 81.67773752012883\n",
            "Epoch #1. Accuracy on batch 2484/3013  on Training is 81.67882293762575\n",
            "Epoch #1. Accuracy on batch 2485/3013  on Training is 81.67613636363636\n",
            "Epoch #1. Accuracy on batch 2486/3013  on Training is 81.67847808604745\n",
            "Epoch #1. Accuracy on batch 2487/3013  on Training is 81.68081792604502\n",
            "Epoch #1. Accuracy on batch 2488/3013  on Training is 81.68064483728405\n",
            "Epoch #1. Accuracy on batch 2489/3013  on Training is 81.68298192771084\n",
            "Epoch #1. Accuracy on batch 2490/3013  on Training is 81.68029907667604\n",
            "Epoch #1. Accuracy on batch 2491/3013  on Training is 81.68138041733548\n",
            "Epoch #1. Accuracy on batch 2492/3013  on Training is 81.6837144003209\n",
            "Epoch #1. Accuracy on batch 2493/3013  on Training is 81.68729951884522\n",
            "Epoch #1. Accuracy on batch 2494/3013  on Training is 81.68962925851703\n",
            "Epoch #1. Accuracy on batch 2495/3013  on Training is 81.69446113782051\n",
            "Epoch #1. Accuracy on batch 2496/3013  on Training is 81.69428313976772\n",
            "Epoch #1. Accuracy on batch 2497/3013  on Training is 81.69035228182545\n",
            "Epoch #1. Accuracy on batch 2498/3013  on Training is 81.69142657062825\n",
            "Epoch #1. Accuracy on batch 2499/3013  on Training is 81.69\n",
            "Batch Id 2500 is having training loss of 0.6772514581680298\n",
            "0.6940320134162903\n",
            "Epoch #1. Accuracy on batch 2500/3013  on Training is 81.68982407037186\n",
            "Epoch #1. Accuracy on batch 2501/3013  on Training is 81.69089728217426\n",
            "Epoch #1. Accuracy on batch 2502/3013  on Training is 81.68947263284059\n",
            "Epoch #1. Accuracy on batch 2503/3013  on Training is 81.69304113418531\n",
            "Epoch #1. Accuracy on batch 2504/3013  on Training is 81.6941117764471\n",
            "Epoch #1. Accuracy on batch 2505/3013  on Training is 81.69518156424581\n",
            "Epoch #1. Accuracy on batch 2506/3013  on Training is 81.70123653769446\n",
            "Epoch #1. Accuracy on batch 2507/3013  on Training is 81.70230263157895\n",
            "Epoch #1. Accuracy on batch 2508/3013  on Training is 81.69714029493822\n",
            "Epoch #1. Accuracy on batch 2509/3013  on Training is 81.69322709163346\n",
            "Epoch #1. Accuracy on batch 2510/3013  on Training is 81.6918060533652\n",
            "Epoch #1. Accuracy on batch 2511/3013  on Training is 81.6953622611465\n",
            "Epoch #1. Accuracy on batch 2512/3013  on Training is 81.69394150417827\n",
            "Epoch #1. Accuracy on batch 2513/3013  on Training is 81.69500795544948\n",
            "Epoch #1. Accuracy on batch 2514/3013  on Training is 81.69358846918489\n",
            "Epoch #1. Accuracy on batch 2515/3013  on Training is 81.69341216216216\n",
            "Epoch #1. Accuracy on batch 2516/3013  on Training is 81.69571911005166\n",
            "Epoch #1. Accuracy on batch 2517/3013  on Training is 81.69430103256553\n",
            "Epoch #1. Accuracy on batch 2518/3013  on Training is 81.69536522429536\n",
            "Epoch #1. Accuracy on batch 2519/3013  on Training is 81.69394841269842\n",
            "Batch Id 2520 is having training loss of 0.6771742701530457\n",
            "0.7172775864601135\n",
            "Epoch #1. Accuracy on batch 2520/3013  on Training is 81.69253272510909\n",
            "Epoch #1. Accuracy on batch 2521/3013  on Training is 81.69359635210151\n",
            "Epoch #1. Accuracy on batch 2522/3013  on Training is 81.69589774078479\n",
            "Epoch #1. Accuracy on batch 2523/3013  on Training is 81.69819730586372\n",
            "Epoch #1. Accuracy on batch 2524/3013  on Training is 81.70049504950495\n",
            "Epoch #1. Accuracy on batch 2525/3013  on Training is 81.69907957244655\n",
            "Epoch #1. Accuracy on batch 2526/3013  on Training is 81.70013850415512\n",
            "Epoch #1. Accuracy on batch 2527/3013  on Training is 81.6962519778481\n",
            "Epoch #1. Accuracy on batch 2528/3013  on Training is 81.69483985765125\n",
            "Epoch #1. Accuracy on batch 2529/3013  on Training is 81.69589920948617\n",
            "Epoch #1. Accuracy on batch 2530/3013  on Training is 81.69325365468194\n",
            "Epoch #1. Accuracy on batch 2531/3013  on Training is 81.69307859399684\n",
            "Epoch #1. Accuracy on batch 2532/3013  on Training is 81.68920252664824\n",
            "Epoch #1. Accuracy on batch 2533/3013  on Training is 81.69026243093923\n",
            "Epoch #1. Accuracy on batch 2534/3013  on Training is 81.6888560157791\n",
            "Epoch #1. Accuracy on batch 2535/3013  on Training is 81.68991522082018\n",
            "Epoch #1. Accuracy on batch 2536/3013  on Training is 81.68851005124162\n",
            "Epoch #1. Accuracy on batch 2537/3013  on Training is 81.69326241134752\n",
            "Epoch #1. Accuracy on batch 2538/3013  on Training is 81.69431862938164\n",
            "Epoch #1. Accuracy on batch 2539/3013  on Training is 81.69537401574803\n",
            "Batch Id 2540 is having training loss of 0.6768133044242859\n",
            "0.7143844962120056\n",
            "Epoch #1. Accuracy on batch 2540/3013  on Training is 81.69642857142857\n",
            "Epoch #1. Accuracy on batch 2541/3013  on Training is 81.69625295043274\n",
            "Epoch #1. Accuracy on batch 2542/3013  on Training is 81.697306331105\n",
            "Epoch #1. Accuracy on batch 2543/3013  on Training is 81.69344536163523\n",
            "Epoch #1. Accuracy on batch 2544/3013  on Training is 81.68958742632613\n",
            "Epoch #1. Accuracy on batch 2545/3013  on Training is 81.69064218381776\n",
            "Epoch #1. Accuracy on batch 2546/3013  on Training is 81.69537691401649\n",
            "Epoch #1. Accuracy on batch 2547/3013  on Training is 81.69029631083203\n",
            "Epoch #1. Accuracy on batch 2548/3013  on Training is 81.68889760690467\n",
            "Epoch #1. Accuracy on batch 2549/3013  on Training is 81.69117647058823\n",
            "Epoch #1. Accuracy on batch 2550/3013  on Training is 81.69345354762838\n",
            "Epoch #1. Accuracy on batch 2551/3013  on Training is 81.69327978056427\n",
            "Epoch #1. Accuracy on batch 2552/3013  on Training is 81.6931061496279\n",
            "Epoch #1. Accuracy on batch 2553/3013  on Training is 81.69048551292092\n",
            "Epoch #1. Accuracy on batch 2554/3013  on Training is 81.69275929549902\n",
            "Epoch #1. Accuracy on batch 2555/3013  on Training is 81.69014084507042\n",
            "Epoch #1. Accuracy on batch 2556/3013  on Training is 81.69241298396558\n",
            "Epoch #1. Accuracy on batch 2557/3013  on Training is 81.69224003127444\n",
            "Epoch #1. Accuracy on batch 2558/3013  on Training is 81.69084603360687\n",
            "Epoch #1. Accuracy on batch 2559/3013  on Training is 81.689453125\n",
            "Batch Id 2560 is having training loss of 0.67691570520401\n",
            "0.46568650007247925\n",
            "Epoch #1. Accuracy on batch 2560/3013  on Training is 81.6929422100742\n",
            "Epoch #1. Accuracy on batch 2561/3013  on Training is 81.6927693208431\n",
            "Epoch #1. Accuracy on batch 2562/3013  on Training is 81.68893874365978\n",
            "Epoch #1. Accuracy on batch 2563/3013  on Training is 81.68876755070202\n",
            "Epoch #1. Accuracy on batch 2564/3013  on Training is 81.68737816764133\n",
            "Epoch #1. Accuracy on batch 2565/3013  on Training is 81.68964341387374\n",
            "Epoch #1. Accuracy on batch 2566/3013  on Training is 81.69312426957538\n",
            "Epoch #1. Accuracy on batch 2567/3013  on Training is 81.69295171339564\n",
            "Epoch #1. Accuracy on batch 2568/3013  on Training is 81.69521214480342\n",
            "Epoch #1. Accuracy on batch 2569/3013  on Training is 81.69625486381322\n",
            "Epoch #1. Accuracy on batch 2570/3013  on Training is 81.69851225204201\n",
            "Epoch #1. Accuracy on batch 2571/3013  on Training is 81.69712286158631\n",
            "Epoch #1. Accuracy on batch 2572/3013  on Training is 81.69452001554606\n",
            "Epoch #1. Accuracy on batch 2573/3013  on Training is 81.6979895104895\n",
            "Epoch #1. Accuracy on batch 2574/3013  on Training is 81.69660194174757\n",
            "Epoch #1. Accuracy on batch 2575/3013  on Training is 81.69764169254658\n",
            "Epoch #1. Accuracy on batch 2576/3013  on Training is 81.69989328676756\n",
            "Epoch #1. Accuracy on batch 2577/3013  on Training is 81.70093095422808\n",
            "Epoch #1. Accuracy on batch 2578/3013  on Training is 81.70439123691354\n",
            "Epoch #1. Accuracy on batch 2579/3013  on Training is 81.70300387596899\n",
            "Batch Id 2580 is having training loss of 0.6766471862792969\n",
            "0.6011223793029785\n",
            "Epoch #1. Accuracy on batch 2580/3013  on Training is 81.70403913211933\n",
            "Epoch #1. Accuracy on batch 2581/3013  on Training is 81.70386328427576\n",
            "Epoch #1. Accuracy on batch 2582/3013  on Training is 81.7024777390631\n",
            "Epoch #1. Accuracy on batch 2583/3013  on Training is 81.6998839009288\n",
            "Epoch #1. Accuracy on batch 2584/3013  on Training is 81.70091876208897\n",
            "Epoch #1. Accuracy on batch 2585/3013  on Training is 81.7019528228925\n",
            "Epoch #1. Accuracy on batch 2586/3013  on Training is 81.70177812137611\n",
            "Epoch #1. Accuracy on batch 2587/3013  on Training is 81.70643353941267\n",
            "Epoch #1. Accuracy on batch 2588/3013  on Training is 81.70746427191966\n",
            "Epoch #1. Accuracy on batch 2589/3013  on Training is 81.70366795366796\n",
            "Epoch #1. Accuracy on batch 2590/3013  on Training is 81.7046989579313\n",
            "Epoch #1. Accuracy on batch 2591/3013  on Training is 81.70814043209876\n",
            "Epoch #1. Accuracy on batch 2592/3013  on Training is 81.70434824527574\n",
            "Epoch #1. Accuracy on batch 2593/3013  on Training is 81.70055898226677\n",
            "Epoch #1. Accuracy on batch 2594/3013  on Training is 81.70279383429673\n",
            "Epoch #1. Accuracy on batch 2595/3013  on Training is 81.70502696456086\n",
            "Epoch #1. Accuracy on batch 2596/3013  on Training is 81.70605506353485\n",
            "Epoch #1. Accuracy on batch 2597/3013  on Training is 81.7106909160893\n",
            "Epoch #1. Accuracy on batch 2598/3013  on Training is 81.71051365909966\n",
            "Epoch #1. Accuracy on batch 2599/3013  on Training is 81.71153846153847\n",
            "Batch Id 2600 is having training loss of 0.6760554313659668\n",
            "0.27057453989982605\n",
            "Epoch #1. Accuracy on batch 2600/3013  on Training is 81.71616685890042\n",
            "Epoch #1. Accuracy on batch 2601/3013  on Training is 81.71598770176787\n",
            "Epoch #1. Accuracy on batch 2602/3013  on Training is 81.71941029581252\n",
            "Epoch #1. Accuracy on batch 2603/3013  on Training is 81.7216301843318\n",
            "Epoch #1. Accuracy on batch 2604/3013  on Training is 81.72384836852207\n",
            "Epoch #1. Accuracy on batch 2605/3013  on Training is 81.72126822716807\n",
            "Epoch #1. Accuracy on batch 2606/3013  on Training is 81.72108745684694\n",
            "Epoch #1. Accuracy on batch 2607/3013  on Training is 81.71731211656441\n",
            "Epoch #1. Accuracy on batch 2608/3013  on Training is 81.7183307780759\n",
            "Epoch #1. Accuracy on batch 2609/3013  on Training is 81.7205459770115\n",
            "Epoch #1. Accuracy on batch 2610/3013  on Training is 81.7239563385676\n",
            "Epoch #1. Accuracy on batch 2611/3013  on Training is 81.7261676875957\n",
            "Epoch #1. Accuracy on batch 2612/3013  on Training is 81.72718140068886\n",
            "Epoch #1. Accuracy on batch 2613/3013  on Training is 81.73178079571538\n",
            "Epoch #1. Accuracy on batch 2614/3013  on Training is 81.73279158699809\n",
            "Epoch #1. Accuracy on batch 2615/3013  on Training is 81.73738532110092\n",
            "Epoch #1. Accuracy on batch 2616/3013  on Training is 81.73481085212075\n",
            "Epoch #1. Accuracy on batch 2617/3013  on Training is 81.72865737203972\n",
            "Epoch #1. Accuracy on batch 2618/3013  on Training is 81.72966781214204\n",
            "Epoch #1. Accuracy on batch 2619/3013  on Training is 81.72709923664122\n",
            "Batch Id 2620 is having training loss of 0.6755936145782471\n",
            "0.7273262739181519\n",
            "Epoch #1. Accuracy on batch 2620/3013  on Training is 81.72691720717283\n",
            "Epoch #1. Accuracy on batch 2621/3013  on Training is 81.71958428680396\n",
            "Epoch #1. Accuracy on batch 2622/3013  on Training is 81.72059664506291\n",
            "Epoch #1. Accuracy on batch 2623/3013  on Training is 81.72279916158537\n",
            "Epoch #1. Accuracy on batch 2624/3013  on Training is 81.72619047619048\n",
            "Epoch #1. Accuracy on batch 2625/3013  on Training is 81.72719916222391\n",
            "Epoch #1. Accuracy on batch 2626/3013  on Training is 81.7293966501713\n",
            "Epoch #1. Accuracy on batch 2627/3013  on Training is 81.72683599695586\n",
            "Epoch #1. Accuracy on batch 2628/3013  on Training is 81.72189996196272\n",
            "Epoch #1. Accuracy on batch 2629/3013  on Training is 81.72053231939164\n",
            "Epoch #1. Accuracy on batch 2630/3013  on Training is 81.7215412390726\n",
            "Epoch #1. Accuracy on batch 2631/3013  on Training is 81.71780015197568\n",
            "Epoch #1. Accuracy on batch 2632/3013  on Training is 81.7188093429548\n",
            "Epoch #1. Accuracy on batch 2633/3013  on Training is 81.72337699316628\n",
            "Epoch #1. Accuracy on batch 2634/3013  on Training is 81.7196394686907\n",
            "Epoch #1. Accuracy on batch 2635/3013  on Training is 81.72064681335357\n",
            "Epoch #1. Accuracy on batch 2636/3013  on Training is 81.72165339400834\n",
            "Epoch #1. Accuracy on batch 2637/3013  on Training is 81.72502843062927\n",
            "Epoch #1. Accuracy on batch 2638/3013  on Training is 81.72721674876847\n",
            "Epoch #1. Accuracy on batch 2639/3013  on Training is 81.73295454545455\n",
            "Batch Id 2640 is having training loss of 0.6752324104309082\n",
            "0.5407151579856873\n",
            "Epoch #1. Accuracy on batch 2640/3013  on Training is 81.73277167739492\n",
            "Epoch #1. Accuracy on batch 2641/3013  on Training is 81.7314061317184\n",
            "Epoch #1. Accuracy on batch 2642/3013  on Training is 81.73713583049565\n",
            "Epoch #1. Accuracy on batch 2643/3013  on Training is 81.73813350983359\n",
            "Epoch #1. Accuracy on batch 2644/3013  on Training is 81.73322306238185\n",
            "Epoch #1. Accuracy on batch 2645/3013  on Training is 81.7365835222978\n",
            "Epoch #1. Accuracy on batch 2646/3013  on Training is 81.73639969777106\n",
            "Epoch #1. Accuracy on batch 2647/3013  on Training is 81.73975641993958\n",
            "Epoch #1. Accuracy on batch 2648/3013  on Training is 81.73839184597962\n",
            "Epoch #1. Accuracy on batch 2649/3013  on Training is 81.73820754716981\n",
            "Epoch #1. Accuracy on batch 2650/3013  on Training is 81.73920218785364\n",
            "Epoch #1. Accuracy on batch 2651/3013  on Training is 81.7354826546003\n",
            "Epoch #1. Accuracy on batch 2652/3013  on Training is 81.7352996607614\n",
            "Epoch #1. Accuracy on batch 2653/3013  on Training is 81.73747174076865\n",
            "Epoch #1. Accuracy on batch 2654/3013  on Training is 81.73964218455744\n",
            "Epoch #1. Accuracy on batch 2655/3013  on Training is 81.7429875753012\n",
            "Epoch #1. Accuracy on batch 2656/3013  on Training is 81.7439781708694\n",
            "Epoch #1. Accuracy on batch 2657/3013  on Training is 81.74144093303235\n",
            "Epoch #1. Accuracy on batch 2658/3013  on Training is 81.73890560361038\n",
            "Epoch #1. Accuracy on batch 2659/3013  on Training is 81.73989661654136\n",
            "Batch Id 2660 is having training loss of 0.6750814914703369\n",
            "0.7566781640052795\n",
            "Epoch #1. Accuracy on batch 2660/3013  on Training is 81.73971251409245\n",
            "Epoch #1. Accuracy on batch 2661/3013  on Training is 81.73952854996243\n",
            "Epoch #1. Accuracy on batch 2662/3013  on Training is 81.74286518963575\n",
            "Epoch #1. Accuracy on batch 2663/3013  on Training is 81.74268018018019\n",
            "Epoch #1. Accuracy on batch 2664/3013  on Training is 81.74484052532833\n",
            "Epoch #1. Accuracy on batch 2665/3013  on Training is 81.74231057764442\n",
            "Epoch #1. Accuracy on batch 2666/3013  on Training is 81.7397825271841\n",
            "Epoch #1. Accuracy on batch 2667/3013  on Training is 81.73842766116941\n",
            "Epoch #1. Accuracy on batch 2668/3013  on Training is 81.7394155114275\n",
            "Epoch #1. Accuracy on batch 2669/3013  on Training is 81.74040262172285\n",
            "Epoch #1. Accuracy on batch 2670/3013  on Training is 81.74138899288656\n",
            "Epoch #1. Accuracy on batch 2671/3013  on Training is 81.73886601796407\n",
            "Epoch #1. Accuracy on batch 2672/3013  on Training is 81.73868312757202\n",
            "Epoch #1. Accuracy on batch 2673/3013  on Training is 81.74434367988033\n",
            "Epoch #1. Accuracy on batch 2674/3013  on Training is 81.74299065420561\n",
            "Epoch #1. Accuracy on batch 2675/3013  on Training is 81.74630979073244\n",
            "Epoch #1. Accuracy on batch 2676/3013  on Training is 81.7472917444901\n",
            "Epoch #1. Accuracy on batch 2677/3013  on Training is 81.74943988050784\n",
            "Epoch #1. Accuracy on batch 2678/3013  on Training is 81.75041993281074\n",
            "Epoch #1. Accuracy on batch 2679/3013  on Training is 81.75139925373135\n",
            "Batch Id 2680 is having training loss of 0.6746582984924316\n",
            "0.39070090651512146\n",
            "Epoch #1. Accuracy on batch 2680/3013  on Training is 81.7535434539351\n",
            "Epoch #1. Accuracy on batch 2681/3013  on Training is 81.75685123042506\n",
            "Epoch #1. Accuracy on batch 2682/3013  on Training is 81.75666231830041\n",
            "Epoch #1. Accuracy on batch 2683/3013  on Training is 81.75298062593144\n",
            "Epoch #1. Accuracy on batch 2684/3013  on Training is 81.75046554934823\n",
            "Epoch #1. Accuracy on batch 2685/3013  on Training is 81.75027922561429\n",
            "Epoch #1. Accuracy on batch 2686/3013  on Training is 81.75474506885001\n",
            "Epoch #1. Accuracy on batch 2687/3013  on Training is 81.75106956845238\n",
            "Epoch #1. Accuracy on batch 2688/3013  on Training is 81.75320751208628\n",
            "Epoch #1. Accuracy on batch 2689/3013  on Training is 81.755343866171\n",
            "Epoch #1. Accuracy on batch 2690/3013  on Training is 81.75283351913787\n",
            "Epoch #1. Accuracy on batch 2691/3013  on Training is 81.7503250371471\n",
            "Epoch #1. Accuracy on batch 2692/3013  on Training is 81.75362049758634\n",
            "Epoch #1. Accuracy on batch 2693/3013  on Training is 81.75459354120267\n",
            "Epoch #1. Accuracy on batch 2694/3013  on Training is 81.75440630797773\n",
            "Epoch #1. Accuracy on batch 2695/3013  on Training is 81.75885571216617\n",
            "Epoch #1. Accuracy on batch 2696/3013  on Training is 81.75750834260289\n",
            "Epoch #1. Accuracy on batch 2697/3013  on Training is 81.76079503335804\n",
            "Epoch #1. Accuracy on batch 2698/3013  on Training is 81.75829010744721\n",
            "Epoch #1. Accuracy on batch 2699/3013  on Training is 81.76041666666667\n",
            "Batch Id 2700 is having training loss of 0.67484450340271\n",
            "1.155989408493042\n",
            "Epoch #1. Accuracy on batch 2700/3013  on Training is 81.75675675675676\n",
            "Epoch #1. Accuracy on batch 2701/3013  on Training is 81.76003886010362\n",
            "Epoch #1. Accuracy on batch 2702/3013  on Training is 81.76100628930817\n",
            "Epoch #1. Accuracy on batch 2703/3013  on Training is 81.75735022189349\n",
            "Epoch #1. Accuracy on batch 2704/3013  on Training is 81.75716266173752\n",
            "Epoch #1. Accuracy on batch 2705/3013  on Training is 81.76159460458241\n",
            "Epoch #1. Accuracy on batch 2706/3013  on Training is 81.76140561507204\n",
            "Epoch #1. Accuracy on batch 2707/3013  on Training is 81.7646787296898\n",
            "Epoch #1. Accuracy on batch 2708/3013  on Training is 81.76448874123292\n",
            "Epoch #1. Accuracy on batch 2709/3013  on Training is 81.76429889298893\n",
            "Epoch #1. Accuracy on batch 2710/3013  on Training is 81.76410918480265\n",
            "Epoch #1. Accuracy on batch 2711/3013  on Training is 81.76276733038348\n",
            "Epoch #1. Accuracy on batch 2712/3013  on Training is 81.76488204939182\n",
            "Epoch #1. Accuracy on batch 2713/3013  on Training is 81.76469233603537\n",
            "Epoch #1. Accuracy on batch 2714/3013  on Training is 81.76565377532228\n",
            "Epoch #1. Accuracy on batch 2715/3013  on Training is 81.76891568483063\n",
            "Epoch #1. Accuracy on batch 2716/3013  on Training is 81.76757453073243\n",
            "Epoch #1. Accuracy on batch 2717/3013  on Training is 81.76968359087564\n",
            "Epoch #1. Accuracy on batch 2718/3013  on Training is 81.771791099669\n",
            "Epoch #1. Accuracy on batch 2719/3013  on Training is 81.7681525735294\n",
            "Batch Id 2720 is having training loss of 0.6743099689483643\n",
            "0.36699002981185913\n",
            "Epoch #1. Accuracy on batch 2720/3013  on Training is 81.77255604557148\n",
            "Epoch #1. Accuracy on batch 2721/3013  on Training is 81.7758082292432\n",
            "Epoch #1. Accuracy on batch 2722/3013  on Training is 81.7744674990819\n",
            "Epoch #1. Accuracy on batch 2723/3013  on Training is 81.77083333333333\n",
            "Epoch #1. Accuracy on batch 2724/3013  on Training is 81.76834862385321\n",
            "Epoch #1. Accuracy on batch 2725/3013  on Training is 81.76930484225971\n",
            "Epoch #1. Accuracy on batch 2726/3013  on Training is 81.76796846351301\n",
            "Epoch #1. Accuracy on batch 2727/3013  on Training is 81.76777859237536\n",
            "Epoch #1. Accuracy on batch 2728/3013  on Training is 81.76873396848663\n",
            "Epoch #1. Accuracy on batch 2729/3013  on Training is 81.77197802197803\n",
            "Epoch #1. Accuracy on batch 2730/3013  on Training is 81.77636396924204\n",
            "Epoch #1. Accuracy on batch 2731/3013  on Training is 81.77731515373353\n",
            "Epoch #1. Accuracy on batch 2732/3013  on Training is 81.77712221002561\n",
            "Epoch #1. Accuracy on batch 2733/3013  on Training is 81.77578639356254\n",
            "Epoch #1. Accuracy on batch 2734/3013  on Training is 81.77787934186472\n",
            "Epoch #1. Accuracy on batch 2735/3013  on Training is 81.7765442251462\n",
            "Epoch #1. Accuracy on batch 2736/3013  on Training is 81.77635184508586\n",
            "Epoch #1. Accuracy on batch 2737/3013  on Training is 81.7761596055515\n",
            "Epoch #1. Accuracy on batch 2738/3013  on Training is 81.77710843373494\n",
            "Epoch #1. Accuracy on batch 2739/3013  on Training is 81.77919708029196\n",
            "Batch Id 2740 is having training loss of 0.674148678779602\n",
            "0.523583710193634\n",
            "Epoch #1. Accuracy on batch 2740/3013  on Training is 81.78014410798978\n",
            "Epoch #1. Accuracy on batch 2741/3013  on Training is 81.77995076586433\n",
            "Epoch #1. Accuracy on batch 2742/3013  on Training is 81.77747903755012\n",
            "Epoch #1. Accuracy on batch 2743/3013  on Training is 81.77500911078717\n",
            "Epoch #1. Accuracy on batch 2744/3013  on Training is 81.77823315118397\n",
            "Epoch #1. Accuracy on batch 2745/3013  on Training is 81.77462672978878\n",
            "Epoch #1. Accuracy on batch 2746/3013  on Training is 81.77443574808882\n",
            "Epoch #1. Accuracy on batch 2747/3013  on Training is 81.77424490538573\n",
            "Epoch #1. Accuracy on batch 2748/3013  on Training is 81.77519097853765\n",
            "Epoch #1. Accuracy on batch 2749/3013  on Training is 81.77386363636364\n",
            "Epoch #1. Accuracy on batch 2750/3013  on Training is 81.77367320974192\n",
            "Epoch #1. Accuracy on batch 2751/3013  on Training is 81.77575399709302\n",
            "Epoch #1. Accuracy on batch 2752/3013  on Training is 81.77669814747549\n",
            "Epoch #1. Accuracy on batch 2753/3013  on Training is 81.77537218591141\n",
            "Epoch #1. Accuracy on batch 2754/3013  on Training is 81.77177858439201\n",
            "Epoch #1. Accuracy on batch 2755/3013  on Training is 81.77272314949202\n",
            "Epoch #1. Accuracy on batch 2756/3013  on Training is 81.77026659412405\n",
            "Epoch #1. Accuracy on batch 2757/3013  on Training is 81.76441261783901\n",
            "Epoch #1. Accuracy on batch 2758/3013  on Training is 81.76422616890177\n",
            "Epoch #1. Accuracy on batch 2759/3013  on Training is 81.76403985507247\n",
            "Batch Id 2760 is having training loss of 0.674350917339325\n",
            "0.3890896141529083\n",
            "Epoch #1. Accuracy on batch 2760/3013  on Training is 81.76724918507787\n",
            "Epoch #1. Accuracy on batch 2761/3013  on Training is 81.76819333816076\n",
            "Epoch #1. Accuracy on batch 2762/3013  on Training is 81.7680057908071\n",
            "Epoch #1. Accuracy on batch 2763/3013  on Training is 81.76555716353111\n",
            "Epoch #1. Accuracy on batch 2764/3013  on Training is 81.76650090415913\n",
            "Epoch #1. Accuracy on batch 2765/3013  on Training is 81.7685737527115\n",
            "Epoch #1. Accuracy on batch 2766/3013  on Training is 81.7683863389953\n",
            "Epoch #1. Accuracy on batch 2767/3013  on Training is 81.76819906069365\n",
            "Epoch #1. Accuracy on batch 2768/3013  on Training is 81.7680119176598\n",
            "Epoch #1. Accuracy on batch 2769/3013  on Training is 81.76331227436823\n",
            "Epoch #1. Accuracy on batch 2770/3013  on Training is 81.76538253338146\n",
            "Epoch #1. Accuracy on batch 2771/3013  on Training is 81.76406926406926\n",
            "Epoch #1. Accuracy on batch 2772/3013  on Training is 81.7616300036062\n",
            "Epoch #1. Accuracy on batch 2773/3013  on Training is 81.76144556596972\n",
            "Epoch #1. Accuracy on batch 2774/3013  on Training is 81.76013513513513\n",
            "Epoch #1. Accuracy on batch 2775/3013  on Training is 81.76107708933718\n",
            "Epoch #1. Accuracy on batch 2776/3013  on Training is 81.76201836514224\n",
            "Epoch #1. Accuracy on batch 2777/3013  on Training is 81.76295896328294\n",
            "Epoch #1. Accuracy on batch 2778/3013  on Training is 81.76389888449083\n",
            "Epoch #1. Accuracy on batch 2779/3013  on Training is 81.7648381294964\n",
            "Batch Id 2780 is having training loss of 0.6743056774139404\n",
            "0.6385731101036072\n",
            "Epoch #1. Accuracy on batch 2780/3013  on Training is 81.76240560949299\n",
            "Epoch #1. Accuracy on batch 2781/3013  on Training is 81.76446800862689\n",
            "Epoch #1. Accuracy on batch 2782/3013  on Training is 81.7654060366511\n",
            "Epoch #1. Accuracy on batch 2783/3013  on Training is 81.76971084770115\n",
            "Epoch #1. Accuracy on batch 2784/3013  on Training is 81.76952423698384\n",
            "Epoch #1. Accuracy on batch 2785/3013  on Training is 81.77045944005744\n",
            "Epoch #1. Accuracy on batch 2786/3013  on Training is 81.77251524937209\n",
            "Epoch #1. Accuracy on batch 2787/3013  on Training is 81.7734487087518\n",
            "Epoch #1. Accuracy on batch 2788/3013  on Training is 81.77326102545716\n",
            "Epoch #1. Accuracy on batch 2789/3013  on Training is 81.76859318996416\n",
            "Epoch #1. Accuracy on batch 2790/3013  on Training is 81.76840738086707\n",
            "Epoch #1. Accuracy on batch 2791/3013  on Training is 81.76934097421203\n",
            "Epoch #1. Accuracy on batch 2792/3013  on Training is 81.76915503043323\n",
            "Epoch #1. Accuracy on batch 2793/3013  on Training is 81.77008768790265\n",
            "Epoch #1. Accuracy on batch 2794/3013  on Training is 81.76990161001788\n",
            "Epoch #1. Accuracy on batch 2795/3013  on Training is 81.77083333333333\n",
            "Epoch #1. Accuracy on batch 2796/3013  on Training is 81.77176439041831\n",
            "Epoch #1. Accuracy on batch 2797/3013  on Training is 81.77157791279485\n",
            "Epoch #1. Accuracy on batch 2798/3013  on Training is 81.76692568774563\n",
            "Epoch #1. Accuracy on batch 2799/3013  on Training is 81.76785714285714\n",
            "Batch Id 2800 is having training loss of 0.6739169955253601\n",
            "0.3524043560028076\n",
            "Epoch #1. Accuracy on batch 2800/3013  on Training is 81.77101927882899\n",
            "Epoch #1. Accuracy on batch 2801/3013  on Training is 81.76971805852962\n",
            "Epoch #1. Accuracy on batch 2802/3013  on Training is 81.76841776667855\n",
            "Epoch #1. Accuracy on batch 2803/3013  on Training is 81.77046184022825\n",
            "Epoch #1. Accuracy on batch 2804/3013  on Training is 81.77250445632798\n",
            "Epoch #1. Accuracy on batch 2805/3013  on Training is 81.7723182466144\n",
            "Epoch #1. Accuracy on batch 2806/3013  on Training is 81.76990559315996\n",
            "Epoch #1. Accuracy on batch 2807/3013  on Training is 81.76972044159544\n",
            "Epoch #1. Accuracy on batch 2808/3013  on Training is 81.77398540405838\n",
            "Epoch #1. Accuracy on batch 2809/3013  on Training is 81.7682384341637\n",
            "Epoch #1. Accuracy on batch 2810/3013  on Training is 81.77027748132338\n",
            "Epoch #1. Accuracy on batch 2811/3013  on Training is 81.77009246088194\n",
            "Epoch #1. Accuracy on batch 2812/3013  on Training is 81.76879665837184\n",
            "Epoch #1. Accuracy on batch 2813/3013  on Training is 81.77305437100213\n",
            "Epoch #1. Accuracy on batch 2814/3013  on Training is 81.77175843694494\n",
            "Epoch #1. Accuracy on batch 2815/3013  on Training is 81.77046342329545\n",
            "Epoch #1. Accuracy on batch 2816/3013  on Training is 81.77027866524672\n",
            "Epoch #1. Accuracy on batch 2817/3013  on Training is 81.77231192334989\n",
            "Epoch #1. Accuracy on batch 2818/3013  on Training is 81.7765608371763\n",
            "Epoch #1. Accuracy on batch 2819/3013  on Training is 81.77859042553192\n",
            "Batch Id 2820 is having training loss of 0.6735674738883972\n",
            "0.47318708896636963\n",
            "Epoch #1. Accuracy on batch 2820/3013  on Training is 81.78061857497342\n",
            "Epoch #1. Accuracy on batch 2821/3013  on Training is 81.78375265768958\n",
            "Epoch #1. Accuracy on batch 2822/3013  on Training is 81.78356358483883\n",
            "Epoch #1. Accuracy on batch 2823/3013  on Training is 81.78337464589235\n",
            "Epoch #1. Accuracy on batch 2824/3013  on Training is 81.78207964601769\n",
            "Epoch #1. Accuracy on batch 2825/3013  on Training is 81.78299716914367\n",
            "Epoch #1. Accuracy on batch 2826/3013  on Training is 81.78170321896003\n",
            "Epoch #1. Accuracy on batch 2827/3013  on Training is 81.78151520509194\n",
            "Epoch #1. Accuracy on batch 2828/3013  on Training is 81.78132732414281\n",
            "Epoch #1. Accuracy on batch 2829/3013  on Training is 81.7844522968198\n",
            "Epoch #1. Accuracy on batch 2830/3013  on Training is 81.78647121158602\n",
            "Epoch #1. Accuracy on batch 2831/3013  on Training is 81.78186793785311\n",
            "Epoch #1. Accuracy on batch 2832/3013  on Training is 81.78057712672079\n",
            "Epoch #1. Accuracy on batch 2833/3013  on Training is 81.78038990825688\n",
            "Epoch #1. Accuracy on batch 2834/3013  on Training is 81.77910052910053\n",
            "Epoch #1. Accuracy on batch 2835/3013  on Training is 81.78221967559944\n",
            "Epoch #1. Accuracy on batch 2836/3013  on Training is 81.78093056045118\n",
            "Epoch #1. Accuracy on batch 2837/3013  on Training is 81.77964235377026\n",
            "Epoch #1. Accuracy on batch 2838/3013  on Training is 81.77835505459669\n",
            "Epoch #1. Accuracy on batch 2839/3013  on Training is 81.77706866197182\n",
            "Batch Id 2840 is having training loss of 0.6738746762275696\n",
            "1.0242592096328735\n",
            "Epoch #1. Accuracy on batch 2840/3013  on Training is 81.77248328053503\n",
            "Epoch #1. Accuracy on batch 2841/3013  on Training is 81.77449859254047\n",
            "Epoch #1. Accuracy on batch 2842/3013  on Training is 81.77761167780514\n",
            "Epoch #1. Accuracy on batch 2843/3013  on Training is 81.77962376933895\n",
            "Epoch #1. Accuracy on batch 2844/3013  on Training is 81.78273286467487\n",
            "Epoch #1. Accuracy on batch 2845/3013  on Training is 81.78583977512298\n",
            "Epoch #1. Accuracy on batch 2846/3013  on Training is 81.78674920969442\n",
            "Epoch #1. Accuracy on batch 2847/3013  on Training is 81.78656074438203\n",
            "Epoch #1. Accuracy on batch 2848/3013  on Training is 81.78746928746929\n",
            "Epoch #1. Accuracy on batch 2849/3013  on Training is 81.78728070175438\n",
            "Epoch #1. Accuracy on batch 2850/3013  on Training is 81.78928446159243\n",
            "Epoch #1. Accuracy on batch 2851/3013  on Training is 81.79019109396914\n",
            "Epoch #1. Accuracy on batch 2852/3013  on Training is 81.78562039957939\n",
            "Epoch #1. Accuracy on batch 2853/3013  on Training is 81.78652768044849\n",
            "Epoch #1. Accuracy on batch 2854/3013  on Training is 81.78305604203152\n",
            "Epoch #1. Accuracy on batch 2855/3013  on Training is 81.77958683473389\n",
            "Epoch #1. Accuracy on batch 2856/3013  on Training is 81.78158907945398\n",
            "Epoch #1. Accuracy on batch 2857/3013  on Training is 81.77812281315606\n",
            "Epoch #1. Accuracy on batch 2858/3013  on Training is 81.78012416928996\n",
            "Epoch #1. Accuracy on batch 2859/3013  on Training is 81.78321678321679\n",
            "Batch Id 2860 is having training loss of 0.6733419299125671\n",
            "0.6409037113189697\n",
            "Epoch #1. Accuracy on batch 2860/3013  on Training is 81.78303040894792\n",
            "Epoch #1. Accuracy on batch 2861/3013  on Training is 81.78175227113907\n",
            "Epoch #1. Accuracy on batch 2862/3013  on Training is 81.77938351379672\n",
            "Epoch #1. Accuracy on batch 2863/3013  on Training is 81.77810754189944\n",
            "Epoch #1. Accuracy on batch 2864/3013  on Training is 81.77792321116928\n",
            "Epoch #1. Accuracy on batch 2865/3013  on Training is 81.77991974877878\n",
            "Epoch #1. Accuracy on batch 2866/3013  on Training is 81.77537495640041\n",
            "Epoch #1. Accuracy on batch 2867/3013  on Training is 81.77628138075313\n",
            "Epoch #1. Accuracy on batch 2868/3013  on Training is 81.78045486232136\n",
            "Epoch #1. Accuracy on batch 2869/3013  on Training is 81.78244773519164\n",
            "Epoch #1. Accuracy on batch 2870/3013  on Training is 81.78443921978405\n",
            "Epoch #1. Accuracy on batch 2871/3013  on Training is 81.77881267409471\n",
            "Epoch #1. Accuracy on batch 2872/3013  on Training is 81.77754089801601\n",
            "Epoch #1. Accuracy on batch 2873/3013  on Training is 81.77735734168407\n",
            "Epoch #1. Accuracy on batch 2874/3013  on Training is 81.775\n",
            "Epoch #1. Accuracy on batch 2875/3013  on Training is 81.77699061196105\n",
            "Epoch #1. Accuracy on batch 2876/3013  on Training is 81.77897984011123\n",
            "Epoch #1. Accuracy on batch 2877/3013  on Training is 81.77662439193885\n",
            "Epoch #1. Accuracy on batch 2878/3013  on Training is 81.77535602639806\n",
            "Epoch #1. Accuracy on batch 2879/3013  on Training is 81.77734375\n",
            "Batch Id 2880 is having training loss of 0.6736572980880737\n",
            "0.928565502166748\n",
            "Epoch #1. Accuracy on batch 2880/3013  on Training is 81.77499132245748\n",
            "Epoch #1. Accuracy on batch 2881/3013  on Training is 81.77480916030534\n",
            "Epoch #1. Accuracy on batch 2882/3013  on Training is 81.78004682622269\n",
            "Epoch #1. Accuracy on batch 2883/3013  on Training is 81.779863037448\n",
            "Epoch #1. Accuracy on batch 2884/3013  on Training is 81.78184575389947\n",
            "Epoch #1. Accuracy on batch 2885/3013  on Training is 81.78274428274429\n",
            "Epoch #1. Accuracy on batch 2886/3013  on Training is 81.78472462764115\n",
            "Epoch #1. Accuracy on batch 2887/3013  on Training is 81.7845394736842\n",
            "Epoch #1. Accuracy on batch 2888/3013  on Training is 81.78327275874005\n",
            "Epoch #1. Accuracy on batch 2889/3013  on Training is 81.78200692041523\n",
            "Epoch #1. Accuracy on batch 2890/3013  on Training is 81.78398478035282\n",
            "Epoch #1. Accuracy on batch 2891/3013  on Training is 81.78380013831259\n",
            "Epoch #1. Accuracy on batch 2892/3013  on Training is 81.78577601106119\n",
            "Epoch #1. Accuracy on batch 2893/3013  on Training is 81.78667069799586\n",
            "Epoch #1. Accuracy on batch 2894/3013  on Training is 81.78972366148533\n",
            "Epoch #1. Accuracy on batch 2895/3013  on Training is 81.79277451657458\n",
            "Epoch #1. Accuracy on batch 2896/3013  on Training is 81.79042975491888\n",
            "Epoch #1. Accuracy on batch 2897/3013  on Training is 81.78916494133885\n",
            "Epoch #1. Accuracy on batch 2898/3013  on Training is 81.79113487409451\n",
            "Epoch #1. Accuracy on batch 2899/3013  on Training is 81.79202586206897\n",
            "Batch Id 2900 is having training loss of 0.6730507016181946\n",
            "0.8356583714485168\n",
            "Epoch #1. Accuracy on batch 2900/3013  on Training is 81.78968459152017\n",
            "Epoch #1. Accuracy on batch 2901/3013  on Training is 81.79165230875259\n",
            "Epoch #1. Accuracy on batch 2902/3013  on Training is 81.79038925249742\n",
            "Epoch #1. Accuracy on batch 2903/3013  on Training is 81.79235537190083\n",
            "Epoch #1. Accuracy on batch 2904/3013  on Training is 81.78894148020655\n",
            "Epoch #1. Accuracy on batch 2905/3013  on Training is 81.7909067446662\n",
            "Epoch #1. Accuracy on batch 2906/3013  on Training is 81.78857069143447\n",
            "Epoch #1. Accuracy on batch 2907/3013  on Training is 81.79053473177441\n",
            "Epoch #1. Accuracy on batch 2908/3013  on Training is 81.7882004125129\n",
            "Epoch #1. Accuracy on batch 2909/3013  on Training is 81.79231099656357\n",
            "Epoch #1. Accuracy on batch 2910/3013  on Training is 81.79212469941601\n",
            "Epoch #1. Accuracy on batch 2911/3013  on Training is 81.7887190934066\n",
            "Epoch #1. Accuracy on batch 2912/3013  on Training is 81.78960693443186\n",
            "Epoch #1. Accuracy on batch 2913/3013  on Training is 81.79049416609472\n",
            "Epoch #1. Accuracy on batch 2914/3013  on Training is 81.79030874785592\n",
            "Epoch #1. Accuracy on batch 2915/3013  on Training is 81.78798010973937\n",
            "Epoch #1. Accuracy on batch 2916/3013  on Training is 81.78993829276654\n",
            "Epoch #1. Accuracy on batch 2917/3013  on Training is 81.79189513365318\n",
            "Epoch #1. Accuracy on batch 2918/3013  on Training is 81.79599177800617\n",
            "Epoch #1. Accuracy on batch 2919/3013  on Training is 81.79580479452055\n",
            "Batch Id 2920 is having training loss of 0.672490656375885\n",
            "0.6689320802688599\n",
            "Epoch #1. Accuracy on batch 2920/3013  on Training is 81.79775761725436\n",
            "Epoch #1. Accuracy on batch 2921/3013  on Training is 81.79970910335386\n",
            "Epoch #1. Accuracy on batch 2922/3013  on Training is 81.79738282586383\n",
            "Epoch #1. Accuracy on batch 2923/3013  on Training is 81.79719562243503\n",
            "Epoch #1. Accuracy on batch 2924/3013  on Training is 81.7991452991453\n",
            "Epoch #1. Accuracy on batch 2925/3013  on Training is 81.79682159945318\n",
            "Epoch #1. Accuracy on batch 2926/3013  on Training is 81.79449948752989\n",
            "Epoch #1. Accuracy on batch 2927/3013  on Training is 81.79751536885246\n",
            "Epoch #1. Accuracy on batch 2928/3013  on Training is 81.79732843974053\n",
            "Epoch #1. Accuracy on batch 2929/3013  on Training is 81.79820819112628\n",
            "Epoch #1. Accuracy on batch 2930/3013  on Training is 81.79695496417605\n",
            "Epoch #1. Accuracy on batch 2931/3013  on Training is 81.79357094133697\n",
            "Epoch #1. Accuracy on batch 2932/3013  on Training is 81.79232015001705\n",
            "Epoch #1. Accuracy on batch 2933/3013  on Training is 81.79320040899796\n",
            "Epoch #1. Accuracy on batch 2934/3013  on Training is 81.79514480408858\n",
            "Epoch #1. Accuracy on batch 2935/3013  on Training is 81.7960235013624\n",
            "Epoch #1. Accuracy on batch 2936/3013  on Training is 81.79583758937692\n",
            "Epoch #1. Accuracy on batch 2937/3013  on Training is 81.79246085772634\n",
            "Epoch #1. Accuracy on batch 2938/3013  on Training is 81.78695985028921\n",
            "Epoch #1. Accuracy on batch 2939/3013  on Training is 81.78890306122449\n",
            "Batch Id 2940 is having training loss of 0.6726654171943665\n",
            "0.5465927124023438\n",
            "Epoch #1. Accuracy on batch 2940/3013  on Training is 81.79190751445087\n",
            "Epoch #1. Accuracy on batch 2941/3013  on Training is 81.79066111488783\n",
            "Epoch #1. Accuracy on batch 2942/3013  on Training is 81.79047740400951\n",
            "Epoch #1. Accuracy on batch 2943/3013  on Training is 81.78392493206522\n",
            "Epoch #1. Accuracy on batch 2944/3013  on Training is 81.78374363327674\n",
            "Epoch #1. Accuracy on batch 2945/3013  on Training is 81.78568397827563\n",
            "Epoch #1. Accuracy on batch 2946/3013  on Training is 81.78762300644723\n",
            "Epoch #1. Accuracy on batch 2947/3013  on Training is 81.78956071913161\n",
            "Epoch #1. Accuracy on batch 2948/3013  on Training is 81.78513903017972\n",
            "Epoch #1. Accuracy on batch 2949/3013  on Training is 81.78389830508475\n",
            "Epoch #1. Accuracy on batch 2950/3013  on Training is 81.78371738393764\n",
            "Epoch #1. Accuracy on batch 2951/3013  on Training is 81.78565379403794\n",
            "Epoch #1. Accuracy on batch 2952/3013  on Training is 81.78758889265154\n",
            "Epoch #1. Accuracy on batch 2953/3013  on Training is 81.79058056872037\n",
            "Epoch #1. Accuracy on batch 2954/3013  on Training is 81.79357021996616\n",
            "Epoch #1. Accuracy on batch 2955/3013  on Training is 81.7976150202977\n",
            "Epoch #1. Accuracy on batch 2956/3013  on Training is 81.79954345620561\n",
            "Epoch #1. Accuracy on batch 2957/3013  on Training is 81.8004141311697\n",
            "Epoch #1. Accuracy on batch 2958/3013  on Training is 81.8002281176073\n",
            "Epoch #1. Accuracy on batch 2959/3013  on Training is 81.80109797297297\n",
            "Batch Id 2960 is having training loss of 0.6722140908241272\n",
            "1.0909312963485718\n",
            "Epoch #1. Accuracy on batch 2960/3013  on Training is 81.79880108071598\n",
            "Epoch #1. Accuracy on batch 2961/3013  on Training is 81.79861580013504\n",
            "Epoch #1. Accuracy on batch 2962/3013  on Training is 81.79843064461694\n",
            "Epoch #1. Accuracy on batch 2963/3013  on Training is 81.80140856950068\n",
            "Epoch #1. Accuracy on batch 2964/3013  on Training is 81.80333052276559\n",
            "Epoch #1. Accuracy on batch 2965/3013  on Training is 81.80209035738368\n",
            "Epoch #1. Accuracy on batch 2966/3013  on Training is 81.80190428041793\n",
            "Epoch #1. Accuracy on batch 2967/3013  on Training is 81.80277122641509\n",
            "Epoch #1. Accuracy on batch 2968/3013  on Training is 81.80574267430111\n",
            "Epoch #1. Accuracy on batch 2969/3013  on Training is 81.80555555555556\n",
            "Epoch #1. Accuracy on batch 2970/3013  on Training is 81.80852406597106\n",
            "Epoch #1. Accuracy on batch 2971/3013  on Training is 81.80728465679677\n",
            "Epoch #1. Accuracy on batch 2972/3013  on Training is 81.80394382778339\n",
            "Epoch #1. Accuracy on batch 2973/3013  on Training is 81.80690988567586\n",
            "Epoch #1. Accuracy on batch 2974/3013  on Training is 81.80882352941177\n",
            "Epoch #1. Accuracy on batch 2975/3013  on Training is 81.81073588709677\n",
            "Epoch #1. Accuracy on batch 2976/3013  on Training is 81.81054753107155\n",
            "Epoch #1. Accuracy on batch 2977/3013  on Training is 81.80826057756884\n",
            "Epoch #1. Accuracy on batch 2978/3013  on Training is 81.81122020812353\n",
            "Epoch #1. Accuracy on batch 2979/3013  on Training is 81.80893456375838\n",
            "Batch Id 2980 is having training loss of 0.6716041564941406\n",
            "0.5607104897499084\n",
            "Epoch #1. Accuracy on batch 2980/3013  on Training is 81.80769875880577\n",
            "Epoch #1. Accuracy on batch 2981/3013  on Training is 81.80960764587525\n",
            "Epoch #1. Accuracy on batch 2982/3013  on Training is 81.80837244384847\n",
            "Epoch #1. Accuracy on batch 2983/3013  on Training is 81.80713806970509\n",
            "Epoch #1. Accuracy on batch 2984/3013  on Training is 81.80799832495812\n",
            "Epoch #1. Accuracy on batch 2985/3013  on Training is 81.8067649028801\n",
            "Epoch #1. Accuracy on batch 2986/3013  on Training is 81.8055323066622\n",
            "Epoch #1. Accuracy on batch 2987/3013  on Training is 81.80534638554217\n",
            "Epoch #1. Accuracy on batch 2988/3013  on Training is 81.80620608899298\n",
            "Epoch #1. Accuracy on batch 2989/3013  on Training is 81.80811036789298\n",
            "Epoch #1. Accuracy on batch 2990/3013  on Training is 81.80687897024407\n",
            "Epoch #1. Accuracy on batch 2991/3013  on Training is 81.81087065508021\n",
            "Epoch #1. Accuracy on batch 2992/3013  on Training is 81.81172736384899\n",
            "Epoch #1. Accuracy on batch 2993/3013  on Training is 81.812583500334\n",
            "Epoch #1. Accuracy on batch 2994/3013  on Training is 81.81761268781302\n",
            "Epoch #1. Accuracy on batch 2995/3013  on Training is 81.81742323097463\n",
            "Epoch #1. Accuracy on batch 2996/3013  on Training is 81.81202035368702\n",
            "Epoch #1. Accuracy on batch 2997/3013  on Training is 81.80766344229487\n",
            "Epoch #1. Accuracy on batch 2998/3013  on Training is 81.80539346448816\n",
            "Epoch #1. Accuracy on batch 2999/3013  on Training is 81.80416666666666\n",
            "Batch Id 3000 is having training loss of 0.6713852286338806\n",
            "0.4121157228946686\n",
            "Epoch #1. Accuracy on batch 3000/3013  on Training is 81.8060646451183\n",
            "Epoch #1. Accuracy on batch 3001/3013  on Training is 81.80483844103931\n",
            "Epoch #1. Accuracy on batch 3002/3013  on Training is 81.8056943056943\n",
            "Epoch #1. Accuracy on batch 3003/3013  on Training is 81.80550932090546\n",
            "Epoch #1. Accuracy on batch 3004/3013  on Training is 81.8105241264559\n",
            "Epoch #1. Accuracy on batch 3005/3013  on Training is 81.8103376580173\n",
            "Epoch #1. Accuracy on batch 3006/3013  on Training is 81.80911207183239\n",
            "Epoch #1. Accuracy on batch 3007/3013  on Training is 81.81100398936171\n",
            "Epoch #1. Accuracy on batch 3008/3013  on Training is 81.81601030242605\n",
            "Epoch #1. Accuracy on batch 3009/3013  on Training is 81.81478405315615\n",
            "Epoch #1. Accuracy on batch 3010/3013  on Training is 81.81252075722351\n",
            "Epoch #1. Accuracy on batch 3011/3013  on Training is 81.81440903054448\n",
            "Epoch #1. Accuracy on batch 3012/3013  on Training is 81.81318339315725\n",
            "Epoch #1. Batch Id 0/278  is having validation loss of 1.1591804027557373\n",
            "1.1591804027557373\n",
            "Epoch #1. Batch Id 0/278  is having validation accuracy of 71.875\n",
            "Epoch #1. Batch Id 1/278  is having validation loss of 0.9012609720230103\n",
            "0.6433415412902832\n",
            "Epoch #1. Batch Id 1/278  is having validation accuracy of 81.25\n",
            "Epoch #1. Batch Id 2/278  is having validation loss of 0.764259397983551\n",
            "0.49025627970695496\n",
            "Epoch #1. Batch Id 2/278  is having validation accuracy of 83.33333333333333\n",
            "Epoch #1. Batch Id 3/278  is having validation loss of 0.674586296081543\n",
            "0.40556687116622925\n",
            "Epoch #1. Batch Id 3/278  is having validation accuracy of 83.59375\n",
            "Epoch #1. Batch Id 4/278  is having validation loss of 0.777492105960846\n",
            "1.189115285873413\n",
            "Epoch #1. Batch Id 4/278  is having validation accuracy of 80.625\n",
            "Epoch #1. Batch Id 5/278  is having validation loss of 0.7404474020004272\n",
            "0.5552238821983337\n",
            "Epoch #1. Batch Id 5/278  is having validation accuracy of 82.29166666666667\n",
            "Epoch #1. Batch Id 6/278  is having validation loss of 0.7879013419151306\n",
            "1.0726248025894165\n",
            "Epoch #1. Batch Id 6/278  is having validation accuracy of 80.35714285714286\n",
            "Epoch #1. Batch Id 7/278  is having validation loss of 0.7133461236953735\n",
            "0.19145935773849487\n",
            "Epoch #1. Batch Id 7/278  is having validation accuracy of 82.03125\n",
            "Epoch #1. Batch Id 8/278  is having validation loss of 0.6716529130935669\n",
            "0.3381073474884033\n",
            "Epoch #1. Batch Id 8/278  is having validation accuracy of 83.68055555555556\n",
            "Epoch #1. Batch Id 9/278  is having validation loss of 0.6328255534172058\n",
            "0.2833794355392456\n",
            "Epoch #1. Batch Id 9/278  is having validation accuracy of 84.6875\n",
            "Epoch #1. Batch Id 10/278  is having validation loss of 0.6443279385566711\n",
            "0.7593514919281006\n",
            "Epoch #1. Batch Id 10/278  is having validation accuracy of 84.375\n",
            "Epoch #1. Batch Id 11/278  is having validation loss of 0.651357889175415\n",
            "0.728687584400177\n",
            "Epoch #1. Batch Id 11/278  is having validation accuracy of 83.85416666666667\n",
            "Epoch #1. Batch Id 12/278  is having validation loss of 0.6744252443313599\n",
            "0.9512336254119873\n",
            "Epoch #1. Batch Id 12/278  is having validation accuracy of 83.89423076923077\n",
            "Epoch #1. Batch Id 13/278  is having validation loss of 0.6767675876617432\n",
            "0.7072180509567261\n",
            "Epoch #1. Batch Id 13/278  is having validation accuracy of 83.03571428571429\n",
            "Epoch #1. Batch Id 14/278  is having validation loss of 0.6759885549545288\n",
            "0.665081799030304\n",
            "Epoch #1. Batch Id 14/278  is having validation accuracy of 82.5\n",
            "Epoch #1. Batch Id 15/278  is having validation loss of 0.6751144528388977\n",
            "0.6620029211044312\n",
            "Epoch #1. Batch Id 15/278  is having validation accuracy of 82.6171875\n",
            "Epoch #1. Batch Id 16/278  is having validation loss of 0.6925181746482849\n",
            "0.9709779620170593\n",
            "Epoch #1. Batch Id 16/278  is having validation accuracy of 82.3529411764706\n",
            "Epoch #1. Batch Id 17/278  is having validation loss of 0.6861697435379028\n",
            "0.5782469511032104\n",
            "Epoch #1. Batch Id 17/278  is having validation accuracy of 82.46527777777777\n",
            "Epoch #1. Batch Id 18/278  is having validation loss of 0.6754871606826782\n",
            "0.4832006096839905\n",
            "Epoch #1. Batch Id 18/278  is having validation accuracy of 82.73026315789474\n",
            "Epoch #1. Batch Id 19/278  is having validation loss of 0.6717186570167542\n",
            "0.6001166105270386\n",
            "Epoch #1. Batch Id 19/278  is having validation accuracy of 82.8125\n",
            "Epoch #1. Batch Id 20/278  is having validation loss of 0.6675317287445068\n",
            "0.5837931036949158\n",
            "Epoch #1. Batch Id 20/278  is having validation accuracy of 82.58928571428571\n",
            "Epoch #1. Batch Id 21/278  is having validation loss of 0.6571856141090393\n",
            "0.4399174451828003\n",
            "Epoch #1. Batch Id 21/278  is having validation accuracy of 83.0965909090909\n",
            "Epoch #1. Batch Id 22/278  is having validation loss of 0.6448598504066467\n",
            "0.3736925423145294\n",
            "Epoch #1. Batch Id 22/278  is having validation accuracy of 83.42391304347827\n",
            "Epoch #1. Batch Id 23/278  is having validation loss of 0.6547771692276001\n",
            "0.882875919342041\n",
            "Epoch #1. Batch Id 23/278  is having validation accuracy of 83.07291666666667\n",
            "Epoch #1. Batch Id 24/278  is having validation loss of 0.6431158781051636\n",
            "0.36324459314346313\n",
            "Epoch #1. Batch Id 24/278  is having validation accuracy of 83.375\n",
            "Epoch #1. Batch Id 25/278  is having validation loss of 0.6486332416534424\n",
            "0.7865679264068604\n",
            "Epoch #1. Batch Id 25/278  is having validation accuracy of 83.29326923076923\n",
            "Epoch #1. Batch Id 26/278  is having validation loss of 0.6511931419372559\n",
            "0.717750072479248\n",
            "Epoch #1. Batch Id 26/278  is having validation accuracy of 83.33333333333333\n",
            "Epoch #1. Batch Id 27/278  is having validation loss of 0.6536469459533691\n",
            "0.7199002504348755\n",
            "Epoch #1. Batch Id 27/278  is having validation accuracy of 83.25892857142857\n",
            "Epoch #1. Batch Id 28/278  is having validation loss of 0.6619274020195007\n",
            "0.8937796950340271\n",
            "Epoch #1. Batch Id 28/278  is having validation accuracy of 82.97413793103448\n",
            "Epoch #1. Batch Id 29/278  is having validation loss of 0.6510030031204224\n",
            "0.3341955244541168\n",
            "Epoch #1. Batch Id 29/278  is having validation accuracy of 83.33333333333333\n",
            "Epoch #1. Batch Id 30/278  is having validation loss of 0.6407961845397949\n",
            "0.3345925211906433\n",
            "Epoch #1. Batch Id 30/278  is having validation accuracy of 83.66935483870968\n",
            "Epoch #1. Batch Id 31/278  is having validation loss of 0.6418014764785767\n",
            "0.6729663610458374\n",
            "Epoch #1. Batch Id 31/278  is having validation accuracy of 83.7890625\n",
            "Epoch #1. Batch Id 32/278  is having validation loss of 0.6390727162361145\n",
            "0.551753044128418\n",
            "Epoch #1. Batch Id 32/278  is having validation accuracy of 84.0909090909091\n",
            "Epoch #1. Batch Id 33/278  is having validation loss of 0.6357623338699341\n",
            "0.5265187621116638\n",
            "Epoch #1. Batch Id 33/278  is having validation accuracy of 84.00735294117646\n",
            "Epoch #1. Batch Id 34/278  is having validation loss of 0.6473634243011475\n",
            "1.041799545288086\n",
            "Epoch #1. Batch Id 34/278  is having validation accuracy of 83.75\n",
            "Epoch #1. Batch Id 35/278  is having validation loss of 0.6474158763885498\n",
            "0.6492520570755005\n",
            "Epoch #1. Batch Id 35/278  is having validation accuracy of 83.59375\n",
            "Epoch #1. Batch Id 36/278  is having validation loss of 0.6459583044052124\n",
            "0.593486487865448\n",
            "Epoch #1. Batch Id 36/278  is having validation accuracy of 83.61486486486487\n",
            "Epoch #1. Batch Id 37/278  is having validation loss of 0.6421432495117188\n",
            "0.5009861588478088\n",
            "Epoch #1. Batch Id 37/278  is having validation accuracy of 83.71710526315789\n",
            "Epoch #1. Batch Id 38/278  is having validation loss of 0.6485508680343628\n",
            "0.8920395970344543\n",
            "Epoch #1. Batch Id 38/278  is having validation accuracy of 83.81410256410257\n",
            "Epoch #1. Batch Id 39/278  is having validation loss of 0.6494957208633423\n",
            "0.6863455176353455\n",
            "Epoch #1. Batch Id 39/278  is having validation accuracy of 83.671875\n",
            "Epoch #1. Batch Id 40/278  is having validation loss of 0.6458762884140015\n",
            "0.5010985136032104\n",
            "Epoch #1. Batch Id 40/278  is having validation accuracy of 83.61280487804878\n",
            "Epoch #1. Batch Id 41/278  is having validation loss of 0.6455374956130981\n",
            "0.6316465139389038\n",
            "Epoch #1. Batch Id 41/278  is having validation accuracy of 83.55654761904762\n",
            "Epoch #1. Batch Id 42/278  is having validation loss of 0.6471720337867737\n",
            "0.7158222198486328\n",
            "Epoch #1. Batch Id 42/278  is having validation accuracy of 83.43023255813954\n",
            "Epoch #1. Batch Id 43/278  is having validation loss of 0.6451972723007202\n",
            "0.5602823495864868\n",
            "Epoch #1. Batch Id 43/278  is having validation accuracy of 83.23863636363636\n",
            "Epoch #1. Batch Id 44/278  is having validation loss of 0.6503058075904846\n",
            "0.875080943107605\n",
            "Epoch #1. Batch Id 44/278  is having validation accuracy of 83.05555555555556\n",
            "Epoch #1. Batch Id 45/278  is having validation loss of 0.6509183049201965\n",
            "0.6784800291061401\n",
            "Epoch #1. Batch Id 45/278  is having validation accuracy of 83.0163043478261\n",
            "Epoch #1. Batch Id 46/278  is having validation loss of 0.6466739177703857\n",
            "0.45143261551856995\n",
            "Epoch #1. Batch Id 46/278  is having validation accuracy of 83.17819148936171\n",
            "Epoch #1. Batch Id 47/278  is having validation loss of 0.6454013586044312\n",
            "0.5855923295021057\n",
            "Epoch #1. Batch Id 47/278  is having validation accuracy of 83.26822916666667\n",
            "Epoch #1. Batch Id 48/278  is having validation loss of 0.6445184350013733\n",
            "0.6021386981010437\n",
            "Epoch #1. Batch Id 48/278  is having validation accuracy of 83.09948979591837\n",
            "Epoch #1. Batch Id 49/278  is having validation loss of 0.6449927091598511\n",
            "0.6682314276695251\n",
            "Epoch #1. Batch Id 49/278  is having validation accuracy of 83.0625\n",
            "Epoch #1. Batch Id 50/278  is having validation loss of 0.640237033367157\n",
            "0.4024529457092285\n",
            "Epoch #1. Batch Id 50/278  is having validation accuracy of 83.2720588235294\n",
            "Epoch #1. Batch Id 51/278  is having validation loss of 0.6337100863456726\n",
            "0.3008350431919098\n",
            "Epoch #1. Batch Id 51/278  is having validation accuracy of 83.41346153846153\n",
            "Epoch #1. Batch Id 52/278  is having validation loss of 0.6341348886489868\n",
            "0.6562259793281555\n",
            "Epoch #1. Batch Id 52/278  is having validation accuracy of 83.37264150943396\n",
            "Epoch #1. Batch Id 53/278  is having validation loss of 0.6362112164497375\n",
            "0.7462565898895264\n",
            "Epoch #1. Batch Id 53/278  is having validation accuracy of 83.33333333333333\n",
            "Epoch #1. Batch Id 54/278  is having validation loss of 0.6338562369346619\n",
            "0.5066870450973511\n",
            "Epoch #1. Batch Id 54/278  is having validation accuracy of 83.35227272727273\n",
            "Epoch #1. Batch Id 55/278  is having validation loss of 0.6301888823509216\n",
            "0.4284839332103729\n",
            "Epoch #1. Batch Id 55/278  is having validation accuracy of 83.48214285714286\n",
            "Epoch #1. Batch Id 56/278  is having validation loss of 0.637336254119873\n",
            "1.0375899076461792\n",
            "Epoch #1. Batch Id 56/278  is having validation accuracy of 83.33333333333333\n",
            "Epoch #1. Batch Id 57/278  is having validation loss of 0.6368151307106018\n",
            "0.607110857963562\n",
            "Epoch #1. Batch Id 57/278  is having validation accuracy of 83.45905172413794\n",
            "Epoch #1. Batch Id 58/278  is having validation loss of 0.6313304305076599\n",
            "0.3132171034812927\n",
            "Epoch #1. Batch Id 58/278  is having validation accuracy of 83.58050847457628\n",
            "Epoch #1. Batch Id 59/278  is having validation loss of 0.62893146276474\n",
            "0.48739150166511536\n",
            "Epoch #1. Batch Id 59/278  is having validation accuracy of 83.64583333333333\n",
            "Epoch #1. Batch Id 60/278  is having validation loss of 0.6244840025901794\n",
            "0.3576359152793884\n",
            "Epoch #1. Batch Id 60/278  is having validation accuracy of 83.81147540983606\n",
            "Epoch #1. Batch Id 61/278  is having validation loss of 0.6243147850036621\n",
            "0.6139911413192749\n",
            "Epoch #1. Batch Id 61/278  is having validation accuracy of 83.71975806451613\n",
            "Epoch #1. Batch Id 62/278  is having validation loss of 0.6215280890464783\n",
            "0.44875386357307434\n",
            "Epoch #1. Batch Id 62/278  is having validation accuracy of 83.73015873015873\n",
            "Epoch #1. Batch Id 63/278  is having validation loss of 0.6202445030212402\n",
            "0.5393784642219543\n",
            "Epoch #1. Batch Id 63/278  is having validation accuracy of 83.69140625\n",
            "Epoch #1. Batch Id 64/278  is having validation loss of 0.6206056475639343\n",
            "0.6437195539474487\n",
            "Epoch #1. Batch Id 64/278  is having validation accuracy of 83.65384615384616\n",
            "Epoch #1. Batch Id 65/278  is having validation loss of 0.6152459383010864\n",
            "0.2668635845184326\n",
            "Epoch #1. Batch Id 65/278  is having validation accuracy of 83.7594696969697\n",
            "Epoch #1. Batch Id 66/278  is having validation loss of 0.6119101047515869\n",
            "0.39174553751945496\n",
            "Epoch #1. Batch Id 66/278  is having validation accuracy of 83.81529850746269\n",
            "Epoch #1. Batch Id 67/278  is having validation loss of 0.6146637201309204\n",
            "0.7991554141044617\n",
            "Epoch #1. Batch Id 67/278  is having validation accuracy of 83.77757352941177\n",
            "Epoch #1. Batch Id 68/278  is having validation loss of 0.6106594800949097\n",
            "0.33837223052978516\n",
            "Epoch #1. Batch Id 68/278  is having validation accuracy of 83.78623188405797\n",
            "Epoch #1. Batch Id 69/278  is having validation loss of 0.6077940464019775\n",
            "0.41008102893829346\n",
            "Epoch #1. Batch Id 69/278  is having validation accuracy of 83.83928571428571\n",
            "Epoch #1. Batch Id 70/278  is having validation loss of 0.6106011271476746\n",
            "0.8070970177650452\n",
            "Epoch #1. Batch Id 70/278  is having validation accuracy of 83.75880281690141\n",
            "Epoch #1. Batch Id 71/278  is having validation loss of 0.6053622364997864\n",
            "0.23339985311031342\n",
            "Epoch #1. Batch Id 71/278  is having validation accuracy of 83.85416666666667\n",
            "Epoch #1. Batch Id 72/278  is having validation loss of 0.6027010679244995\n",
            "0.41109800338745117\n",
            "Epoch #1. Batch Id 72/278  is having validation accuracy of 83.94691780821918\n",
            "Epoch #1. Batch Id 73/278  is having validation loss of 0.6014079451560974\n",
            "0.5070104598999023\n",
            "Epoch #1. Batch Id 73/278  is having validation accuracy of 83.91047297297297\n",
            "Epoch #1. Batch Id 74/278  is having validation loss of 0.602657675743103\n",
            "0.6951369643211365\n",
            "Epoch #1. Batch Id 74/278  is having validation accuracy of 83.91666666666667\n",
            "Epoch #1. Batch Id 75/278  is having validation loss of 0.6084191799163818\n",
            "1.0405329465866089\n",
            "Epoch #1. Batch Id 75/278  is having validation accuracy of 83.67598684210526\n",
            "Epoch #1. Batch Id 76/278  is having validation loss of 0.6070307493209839\n",
            "0.5015113353729248\n",
            "Epoch #1. Batch Id 76/278  is having validation accuracy of 83.76623376623377\n",
            "Epoch #1. Batch Id 77/278  is having validation loss of 0.6073600053787231\n",
            "0.6327106356620789\n",
            "Epoch #1. Batch Id 77/278  is having validation accuracy of 83.69391025641026\n",
            "Epoch #1. Batch Id 78/278  is having validation loss of 0.6073371767997742\n",
            "0.605557918548584\n",
            "Epoch #1. Batch Id 78/278  is having validation accuracy of 83.70253164556962\n",
            "Epoch #1. Batch Id 79/278  is having validation loss of 0.6064633727073669\n",
            "0.5374342203140259\n",
            "Epoch #1. Batch Id 79/278  is having validation accuracy of 83.75\n",
            "Epoch #1. Batch Id 80/278  is having validation loss of 0.6048707365989685\n",
            "0.47745805978775024\n",
            "Epoch #1. Batch Id 80/278  is having validation accuracy of 83.75771604938272\n",
            "Epoch #1. Batch Id 81/278  is having validation loss of 0.6037689447402954\n",
            "0.514523983001709\n",
            "Epoch #1. Batch Id 81/278  is having validation accuracy of 83.76524390243902\n",
            "Epoch #1. Batch Id 82/278  is having validation loss of 0.6071391105651855\n",
            "0.8834928870201111\n",
            "Epoch #1. Batch Id 82/278  is having validation accuracy of 83.62198795180723\n",
            "Epoch #1. Batch Id 83/278  is having validation loss of 0.6050782203674316\n",
            "0.43402597308158875\n",
            "Epoch #1. Batch Id 83/278  is having validation accuracy of 83.66815476190476\n",
            "Epoch #1. Batch Id 84/278  is having validation loss of 0.6056366562843323\n",
            "0.6525463461875916\n",
            "Epoch #1. Batch Id 84/278  is having validation accuracy of 83.67647058823529\n",
            "Epoch #1. Batch Id 85/278  is having validation loss of 0.6060361266136169\n",
            "0.6399896144866943\n",
            "Epoch #1. Batch Id 85/278  is having validation accuracy of 83.57558139534883\n",
            "Epoch #1. Batch Id 86/278  is having validation loss of 0.6063584685325623\n",
            "0.6340808272361755\n",
            "Epoch #1. Batch Id 86/278  is having validation accuracy of 83.54885057471265\n",
            "Epoch #1. Batch Id 87/278  is having validation loss of 0.6044322848320007\n",
            "0.4368519186973572\n",
            "Epoch #1. Batch Id 87/278  is having validation accuracy of 83.55823863636364\n",
            "Epoch #1. Batch Id 88/278  is having validation loss of 0.6046680808067322\n",
            "0.6254184246063232\n",
            "Epoch #1. Batch Id 88/278  is having validation accuracy of 83.49719101123596\n",
            "Epoch #1. Batch Id 89/278  is having validation loss of 0.6020783185958862\n",
            "0.3715892732143402\n",
            "Epoch #1. Batch Id 89/278  is having validation accuracy of 83.57638888888889\n",
            "Epoch #1. Batch Id 90/278  is having validation loss of 0.6002019643783569\n",
            "0.4313312768936157\n",
            "Epoch #1. Batch Id 90/278  is having validation accuracy of 83.61950549450549\n",
            "Epoch #1. Batch Id 91/278  is having validation loss of 0.5999670624732971\n",
            "0.5785907506942749\n",
            "Epoch #1. Batch Id 91/278  is having validation accuracy of 83.62771739130434\n",
            "Epoch #1. Batch Id 92/278  is having validation loss of 0.5979157090187073\n",
            "0.40919384360313416\n",
            "Epoch #1. Batch Id 92/278  is having validation accuracy of 83.70295698924731\n",
            "Epoch #1. Batch Id 93/278  is having validation loss of 0.5964367389678955\n",
            "0.45889461040496826\n",
            "Epoch #1. Batch Id 93/278  is having validation accuracy of 83.71010638297872\n",
            "Epoch #1. Batch Id 94/278  is having validation loss of 0.5958812236785889\n",
            "0.5436650514602661\n",
            "Epoch #1. Batch Id 94/278  is having validation accuracy of 83.71710526315789\n",
            "Epoch #1. Batch Id 95/278  is having validation loss of 0.6004089117050171\n",
            "1.0305410623550415\n",
            "Epoch #1. Batch Id 95/278  is having validation accuracy of 83.59375\n",
            "Epoch #1. Batch Id 96/278  is having validation loss of 0.6011921763420105\n",
            "0.6763835549354553\n",
            "Epoch #1. Batch Id 96/278  is having validation accuracy of 83.56958762886597\n",
            "Epoch #1. Batch Id 97/278  is having validation loss of 0.6034473776817322\n",
            "0.8222000598907471\n",
            "Epoch #1. Batch Id 97/278  is having validation accuracy of 83.5140306122449\n",
            "Epoch #1. Batch Id 98/278  is having validation loss of 0.6035128831863403\n",
            "0.6099308729171753\n",
            "Epoch #1. Batch Id 98/278  is having validation accuracy of 83.58585858585859\n",
            "Epoch #1. Batch Id 99/278  is having validation loss of 0.6055004000663757\n",
            "0.8022671937942505\n",
            "Epoch #1. Batch Id 99/278  is having validation accuracy of 83.53125\n",
            "Epoch #1. Batch Id 100/278  is having validation loss of 0.6050555109977722\n",
            "0.5605692863464355\n",
            "Epoch #1. Batch Id 100/278  is having validation accuracy of 83.57054455445545\n",
            "Epoch #1. Batch Id 101/278  is having validation loss of 0.6034718751907349\n",
            "0.44352519512176514\n",
            "Epoch #1. Batch Id 101/278  is having validation accuracy of 83.60906862745098\n",
            "Epoch #1. Batch Id 102/278  is having validation loss of 0.6041285395622253\n",
            "0.6711111068725586\n",
            "Epoch #1. Batch Id 102/278  is having validation accuracy of 83.61650485436893\n",
            "Epoch #1. Batch Id 103/278  is having validation loss of 0.6037821173667908\n",
            "0.5681005716323853\n",
            "Epoch #1. Batch Id 103/278  is having validation accuracy of 83.62379807692308\n",
            "Epoch #1. Batch Id 104/278  is having validation loss of 0.6049975752830505\n",
            "0.7314052581787109\n",
            "Epoch #1. Batch Id 104/278  is having validation accuracy of 83.60119047619048\n",
            "Epoch #1. Batch Id 105/278  is having validation loss of 0.6049696207046509\n",
            "0.6020362377166748\n",
            "Epoch #1. Batch Id 105/278  is having validation accuracy of 83.6379716981132\n",
            "Epoch #1. Batch Id 106/278  is having validation loss of 0.603718638420105\n",
            "0.4711136519908905\n",
            "Epoch #1. Batch Id 106/278  is having validation accuracy of 83.64485981308411\n",
            "Epoch #1. Batch Id 107/278  is having validation loss of 0.6027186512947083\n",
            "0.49571692943573\n",
            "Epoch #1. Batch Id 107/278  is having validation accuracy of 83.62268518518519\n",
            "Epoch #1. Batch Id 108/278  is having validation loss of 0.6012487411499023\n",
            "0.4424969255924225\n",
            "Epoch #1. Batch Id 108/278  is having validation accuracy of 83.65825688073394\n",
            "Epoch #1. Batch Id 109/278  is having validation loss of 0.6012359857559204\n",
            "0.5998444557189941\n",
            "Epoch #1. Batch Id 109/278  is having validation accuracy of 83.69318181818181\n",
            "Epoch #1. Batch Id 110/278  is having validation loss of 0.6005836129188538\n",
            "0.5288221836090088\n",
            "Epoch #1. Batch Id 110/278  is having validation accuracy of 83.69932432432432\n",
            "Epoch #1. Batch Id 111/278  is having validation loss of 0.6003286242485046\n",
            "0.572027862071991\n",
            "Epoch #1. Batch Id 111/278  is having validation accuracy of 83.64955357142857\n",
            "Epoch #1. Batch Id 112/278  is having validation loss of 0.6038941740989685\n",
            "1.0032367706298828\n",
            "Epoch #1. Batch Id 112/278  is having validation accuracy of 83.51769911504425\n",
            "Epoch #1. Batch Id 113/278  is having validation loss of 0.6024705171585083\n",
            "0.44159653782844543\n",
            "Epoch #1. Batch Id 113/278  is having validation accuracy of 83.55263157894737\n",
            "Epoch #1. Batch Id 114/278  is having validation loss of 0.6019182801246643\n",
            "0.5389644503593445\n",
            "Epoch #1. Batch Id 114/278  is having validation accuracy of 83.55978260869566\n",
            "Epoch #1. Batch Id 115/278  is having validation loss of 0.6013646125793457\n",
            "0.5376919507980347\n",
            "Epoch #1. Batch Id 115/278  is having validation accuracy of 83.59375\n",
            "Epoch #1. Batch Id 116/278  is having validation loss of 0.6017540693283081\n",
            "0.6469290852546692\n",
            "Epoch #1. Batch Id 116/278  is having validation accuracy of 83.62713675213675\n",
            "Epoch #1. Batch Id 117/278  is having validation loss of 0.6012563705444336\n",
            "0.5430234670639038\n",
            "Epoch #1. Batch Id 117/278  is having validation accuracy of 83.6864406779661\n",
            "Epoch #1. Batch Id 118/278  is having validation loss of 0.6016275882720947\n",
            "0.6454287767410278\n",
            "Epoch #1. Batch Id 118/278  is having validation accuracy of 83.66596638655462\n",
            "Epoch #1. Batch Id 119/278  is having validation loss of 0.6011683344841003\n",
            "0.5465168356895447\n",
            "Epoch #1. Batch Id 119/278  is having validation accuracy of 83.64583333333333\n",
            "Epoch #1. Batch Id 120/278  is having validation loss of 0.601309597492218\n",
            "0.6182634830474854\n",
            "Epoch #1. Batch Id 120/278  is having validation accuracy of 83.67768595041322\n",
            "Epoch #1. Batch Id 121/278  is having validation loss of 0.6036271452903748\n",
            "0.8840493559837341\n",
            "Epoch #1. Batch Id 121/278  is having validation accuracy of 83.63217213114754\n",
            "Epoch #1. Batch Id 122/278  is having validation loss of 0.6040763258934021\n",
            "0.6588741540908813\n",
            "Epoch #1. Batch Id 122/278  is having validation accuracy of 83.5619918699187\n",
            "Epoch #1. Batch Id 123/278  is having validation loss of 0.6053224802017212\n",
            "0.7586015462875366\n",
            "Epoch #1. Batch Id 123/278  is having validation accuracy of 83.51814516129032\n",
            "Epoch #1. Batch Id 124/278  is having validation loss of 0.6057029366493225\n",
            "0.6528785824775696\n",
            "Epoch #1. Batch Id 124/278  is having validation accuracy of 83.55\n",
            "Epoch #1. Batch Id 125/278  is having validation loss of 0.6075513362884521\n",
            "0.8386032581329346\n",
            "Epoch #1. Batch Id 125/278  is having validation accuracy of 83.48214285714286\n",
            "Epoch #1. Batch Id 126/278  is having validation loss of 0.6083728671073914\n",
            "0.7118853330612183\n",
            "Epoch #1. Batch Id 126/278  is having validation accuracy of 83.43996062992126\n",
            "Epoch #1. Batch Id 127/278  is having validation loss of 0.6076464653015137\n",
            "0.5153927206993103\n",
            "Epoch #1. Batch Id 127/278  is having validation accuracy of 83.4716796875\n",
            "Epoch #1. Batch Id 128/278  is having validation loss of 0.6072511076927185\n",
            "0.556647539138794\n",
            "Epoch #1. Batch Id 128/278  is having validation accuracy of 83.47868217054264\n",
            "Epoch #1. Batch Id 129/278  is having validation loss of 0.6084210276603699\n",
            "0.7593375444412231\n",
            "Epoch #1. Batch Id 129/278  is having validation accuracy of 83.46153846153847\n",
            "Epoch #1. Batch Id 130/278  is having validation loss of 0.6059906482696533\n",
            "0.29003769159317017\n",
            "Epoch #1. Batch Id 130/278  is having validation accuracy of 83.49236641221374\n",
            "Epoch #1. Batch Id 131/278  is having validation loss of 0.6062273383140564\n",
            "0.6372301578521729\n",
            "Epoch #1. Batch Id 131/278  is having validation accuracy of 83.49905303030303\n",
            "Epoch #1. Batch Id 132/278  is having validation loss of 0.6055212616920471\n",
            "0.5123172998428345\n",
            "Epoch #1. Batch Id 132/278  is having validation accuracy of 83.50563909774436\n",
            "Epoch #1. Batch Id 133/278  is having validation loss of 0.6049618721008301\n",
            "0.5305630564689636\n",
            "Epoch #1. Batch Id 133/278  is having validation accuracy of 83.51212686567165\n",
            "Epoch #1. Batch Id 134/278  is having validation loss of 0.606445848941803\n",
            "0.8052992224693298\n",
            "Epoch #1. Batch Id 134/278  is having validation accuracy of 83.40277777777777\n",
            "Epoch #1. Batch Id 135/278  is having validation loss of 0.6085091233253479\n",
            "0.8870541453361511\n",
            "Epoch #1. Batch Id 135/278  is having validation accuracy of 83.31801470588235\n",
            "Epoch #1. Batch Id 136/278  is having validation loss of 0.6091150045394897\n",
            "0.6915127635002136\n",
            "Epoch #1. Batch Id 136/278  is having validation accuracy of 83.25729927007299\n",
            "Epoch #1. Batch Id 137/278  is having validation loss of 0.6106781363487244\n",
            "0.8248291611671448\n",
            "Epoch #1. Batch Id 137/278  is having validation accuracy of 83.26539855072464\n",
            "Epoch #1. Batch Id 138/278  is having validation loss of 0.6100773215293884\n",
            "0.5271683931350708\n",
            "Epoch #1. Batch Id 138/278  is having validation accuracy of 83.22841726618705\n",
            "Epoch #1. Batch Id 139/278  is having validation loss of 0.6091538667678833\n",
            "0.48079603910446167\n",
            "Epoch #1. Batch Id 139/278  is having validation accuracy of 83.25892857142857\n",
            "Epoch #1. Batch Id 140/278  is having validation loss of 0.6096050143241882\n",
            "0.6727672219276428\n",
            "Epoch #1. Batch Id 140/278  is having validation accuracy of 83.17819148936171\n",
            "Epoch #1. Batch Id 141/278  is having validation loss of 0.6095225214958191\n",
            "0.5978896021842957\n",
            "Epoch #1. Batch Id 141/278  is having validation accuracy of 83.16461267605634\n",
            "Epoch #1. Batch Id 142/278  is having validation loss of 0.6118289828300476\n",
            "0.9393458366394043\n",
            "Epoch #1. Batch Id 142/278  is having validation accuracy of 83.08566433566433\n",
            "Epoch #1. Batch Id 143/278  is having validation loss of 0.6122027039527893\n",
            "0.6656450629234314\n",
            "Epoch #1. Batch Id 143/278  is having validation accuracy of 83.11631944444444\n",
            "Epoch #1. Batch Id 144/278  is having validation loss of 0.6103411316871643\n",
            "0.3422781229019165\n",
            "Epoch #1. Batch Id 144/278  is having validation accuracy of 83.16810344827586\n",
            "Epoch #1. Batch Id 145/278  is having validation loss of 0.6106212735176086\n",
            "0.6512434482574463\n",
            "Epoch #1. Batch Id 145/278  is having validation accuracy of 83.13356164383562\n",
            "Epoch #1. Batch Id 146/278  is having validation loss of 0.6117959022521973\n",
            "0.7832930088043213\n",
            "Epoch #1. Batch Id 146/278  is having validation accuracy of 83.12074829931973\n",
            "Epoch #1. Batch Id 147/278  is having validation loss of 0.6126232743263245\n",
            "0.7342461347579956\n",
            "Epoch #1. Batch Id 147/278  is having validation accuracy of 83.12922297297297\n",
            "Epoch #1. Batch Id 148/278  is having validation loss of 0.6128113865852356\n",
            "0.6406476497650146\n",
            "Epoch #1. Batch Id 148/278  is having validation accuracy of 83.09563758389261\n",
            "Epoch #1. Batch Id 149/278  is having validation loss of 0.6103821992874146\n",
            "0.24843139946460724\n",
            "Epoch #1. Batch Id 149/278  is having validation accuracy of 83.16666666666667\n",
            "Epoch #1. Batch Id 150/278  is having validation loss of 0.6129375100135803\n",
            "0.9962376356124878\n",
            "Epoch #1. Batch Id 150/278  is having validation accuracy of 83.13327814569537\n",
            "Epoch #1. Batch Id 151/278  is having validation loss of 0.613084614276886\n",
            "0.6352943778038025\n",
            "Epoch #1. Batch Id 151/278  is having validation accuracy of 83.12088815789474\n",
            "Epoch #1. Batch Id 152/278  is having validation loss of 0.6138894557952881\n",
            "0.7362297773361206\n",
            "Epoch #1. Batch Id 152/278  is having validation accuracy of 83.08823529411765\n",
            "Epoch #1. Batch Id 153/278  is having validation loss of 0.6134493350982666\n",
            "0.546113133430481\n",
            "Epoch #1. Batch Id 153/278  is having validation accuracy of 83.0762987012987\n",
            "Epoch #1. Batch Id 154/278  is having validation loss of 0.6152925491333008\n",
            "0.8991503715515137\n",
            "Epoch #1. Batch Id 154/278  is having validation accuracy of 83.08467741935483\n",
            "Epoch #1. Batch Id 155/278  is having validation loss of 0.6137751340866089\n",
            "0.37857693433761597\n",
            "Epoch #1. Batch Id 155/278  is having validation accuracy of 83.09294871794872\n",
            "Epoch #1. Batch Id 156/278  is having validation loss of 0.6168158054351807\n",
            "1.091156244277954\n",
            "Epoch #1. Batch Id 156/278  is having validation accuracy of 82.96178343949045\n",
            "Epoch #1. Batch Id 157/278  is having validation loss of 0.6177826523780823\n",
            "0.7695731520652771\n",
            "Epoch #1. Batch Id 157/278  is having validation accuracy of 82.93117088607595\n",
            "Epoch #1. Batch Id 158/278  is having validation loss of 0.615337073802948\n",
            "0.22893689572811127\n",
            "Epoch #1. Batch Id 158/278  is having validation accuracy of 83.01886792452831\n",
            "Epoch #1. Batch Id 159/278  is having validation loss of 0.6149874925613403\n",
            "0.5594006180763245\n",
            "Epoch #1. Batch Id 159/278  is having validation accuracy of 83.046875\n",
            "Epoch #1. Batch Id 160/278  is having validation loss of 0.6167819499969482\n",
            "0.903899610042572\n",
            "Epoch #1. Batch Id 160/278  is having validation accuracy of 83.03571428571429\n",
            "Epoch #1. Batch Id 161/278  is having validation loss of 0.6157840490341187\n",
            "0.45512354373931885\n",
            "Epoch #1. Batch Id 161/278  is having validation accuracy of 83.0246913580247\n",
            "Epoch #1. Batch Id 162/278  is having validation loss of 0.6152190566062927\n",
            "0.5236884355545044\n",
            "Epoch #1. Batch Id 162/278  is having validation accuracy of 83.0521472392638\n",
            "Epoch #1. Batch Id 163/278  is having validation loss of 0.6147876381874084\n",
            "0.5444651246070862\n",
            "Epoch #1. Batch Id 163/278  is having validation accuracy of 83.04115853658537\n",
            "Epoch #1. Batch Id 164/278  is having validation loss of 0.6146033406257629\n",
            "0.5843762755393982\n",
            "Epoch #1. Batch Id 164/278  is having validation accuracy of 83.04924242424242\n",
            "Epoch #1. Batch Id 165/278  is having validation loss of 0.6144615411758423\n",
            "0.591063380241394\n",
            "Epoch #1. Batch Id 165/278  is having validation accuracy of 83.0007530120482\n",
            "Epoch #1. Batch Id 166/278  is having validation loss of 0.6131601929664612\n",
            "0.3971368670463562\n",
            "Epoch #1. Batch Id 166/278  is having validation accuracy of 83.06511976047904\n",
            "Epoch #1. Batch Id 167/278  is having validation loss of 0.6139041781425476\n",
            "0.7381542921066284\n",
            "Epoch #1. Batch Id 167/278  is having validation accuracy of 83.05431547619048\n",
            "Epoch #1. Batch Id 168/278  is having validation loss of 0.6116490364074707\n",
            "0.2327885925769806\n",
            "Epoch #1. Batch Id 168/278  is having validation accuracy of 83.11760355029585\n",
            "Epoch #1. Batch Id 169/278  is having validation loss of 0.6097124814987183\n",
            "0.2824365794658661\n",
            "Epoch #1. Batch Id 169/278  is having validation accuracy of 83.16176470588235\n",
            "Epoch #1. Batch Id 170/278  is having validation loss of 0.6092091202735901\n",
            "0.5236419439315796\n",
            "Epoch #1. Batch Id 170/278  is having validation accuracy of 83.18713450292398\n",
            "Epoch #1. Batch Id 171/278  is having validation loss of 0.6096708178520203\n",
            "0.6886206865310669\n",
            "Epoch #1. Batch Id 171/278  is having validation accuracy of 83.13953488372093\n",
            "Epoch #1. Batch Id 172/278  is having validation loss of 0.6080121397972107\n",
            "0.32272225618362427\n",
            "Epoch #1. Batch Id 172/278  is having validation accuracy of 83.20086705202313\n",
            "Epoch #1. Batch Id 173/278  is having validation loss of 0.6079625487327576\n",
            "0.5993822813034058\n",
            "Epoch #1. Batch Id 173/278  is having validation accuracy of 83.20761494252874\n",
            "Epoch #1. Batch Id 174/278  is having validation loss of 0.6089950799942017\n",
            "0.7886585593223572\n",
            "Epoch #1. Batch Id 174/278  is having validation accuracy of 83.16071428571429\n",
            "Epoch #1. Batch Id 175/278  is having validation loss of 0.6097330451011658\n",
            "0.7388771772384644\n",
            "Epoch #1. Batch Id 175/278  is having validation accuracy of 83.16761363636364\n",
            "Epoch #1. Batch Id 176/278  is having validation loss of 0.6087371110916138\n",
            "0.4334575831890106\n",
            "Epoch #1. Batch Id 176/278  is having validation accuracy of 83.20974576271186\n",
            "Epoch #1. Batch Id 177/278  is having validation loss of 0.6072937846183777\n",
            "0.35182157158851624\n",
            "Epoch #1. Batch Id 177/278  is having validation accuracy of 83.25140449438203\n",
            "Epoch #1. Batch Id 178/278  is having validation loss of 0.6074740290641785\n",
            "0.6395525336265564\n",
            "Epoch #1. Batch Id 178/278  is having validation accuracy of 83.25768156424581\n",
            "Epoch #1. Batch Id 179/278  is having validation loss of 0.6092438101768494\n",
            "0.9260302782058716\n",
            "Epoch #1. Batch Id 179/278  is having validation accuracy of 83.17708333333333\n",
            "Epoch #1. Batch Id 180/278  is having validation loss of 0.6106723546981812\n",
            "0.8678073883056641\n",
            "Epoch #1. Batch Id 180/278  is having validation accuracy of 83.1146408839779\n",
            "Epoch #1. Batch Id 181/278  is having validation loss of 0.610206663608551\n",
            "0.5259150266647339\n",
            "Epoch #1. Batch Id 181/278  is having validation accuracy of 83.12156593406593\n",
            "Epoch #1. Batch Id 182/278  is having validation loss of 0.611069917678833\n",
            "0.7681803703308105\n",
            "Epoch #1. Batch Id 182/278  is having validation accuracy of 83.07718579234972\n",
            "Epoch #1. Batch Id 183/278  is having validation loss of 0.6109220385551453\n",
            "0.5838599801063538\n",
            "Epoch #1. Batch Id 183/278  is having validation accuracy of 83.08423913043478\n",
            "Epoch #1. Batch Id 184/278  is having validation loss of 0.609695553779602\n",
            "0.3840205669403076\n",
            "Epoch #1. Batch Id 184/278  is having validation accuracy of 83.14189189189189\n",
            "Epoch #1. Batch Id 185/278  is having validation loss of 0.6087360978126526\n",
            "0.4312354326248169\n",
            "Epoch #1. Batch Id 185/278  is having validation accuracy of 83.1989247311828\n",
            "Epoch #1. Batch Id 186/278  is having validation loss of 0.6098394989967346\n",
            "0.8150684237480164\n",
            "Epoch #1. Batch Id 186/278  is having validation accuracy of 83.15508021390374\n",
            "Epoch #1. Batch Id 187/278  is having validation loss of 0.6099607944488525\n",
            "0.6326453685760498\n",
            "Epoch #1. Batch Id 187/278  is having validation accuracy of 83.16156914893617\n",
            "Epoch #1. Batch Id 188/278  is having validation loss of 0.6115031838417053\n",
            "0.9014713764190674\n",
            "Epoch #1. Batch Id 188/278  is having validation accuracy of 83.11838624338624\n",
            "Epoch #1. Batch Id 189/278  is having validation loss of 0.6123691201210022\n",
            "0.7760351300239563\n",
            "Epoch #1. Batch Id 189/278  is having validation accuracy of 83.10855263157895\n",
            "Epoch #1. Batch Id 190/278  is having validation loss of 0.6113647222518921\n",
            "0.420525461435318\n",
            "Epoch #1. Batch Id 190/278  is having validation accuracy of 83.0988219895288\n",
            "Epoch #1. Batch Id 191/278  is having validation loss of 0.6139968633651733\n",
            "1.1167376041412354\n",
            "Epoch #1. Batch Id 191/278  is having validation accuracy of 83.056640625\n",
            "Epoch #1. Batch Id 192/278  is having validation loss of 0.6139518022537231\n",
            "0.6052988767623901\n",
            "Epoch #1. Batch Id 192/278  is having validation accuracy of 83.06347150259067\n",
            "Epoch #1. Batch Id 193/278  is having validation loss of 0.6148537397384644\n",
            "0.7889326810836792\n",
            "Epoch #1. Batch Id 193/278  is having validation accuracy of 83.00579896907216\n",
            "Epoch #1. Batch Id 194/278  is having validation loss of 0.6147183179855347\n",
            "0.5884479284286499\n",
            "Epoch #1. Batch Id 194/278  is having validation accuracy of 83.01282051282051\n",
            "Epoch #1. Batch Id 195/278  is having validation loss of 0.6155986785888672\n",
            "0.7872636914253235\n",
            "Epoch #1. Batch Id 195/278  is having validation accuracy of 82.95599489795919\n",
            "Epoch #1. Batch Id 196/278  is having validation loss of 0.6156701445579529\n",
            "0.6296748518943787\n",
            "Epoch #1. Batch Id 196/278  is having validation accuracy of 82.94733502538071\n",
            "Epoch #1. Batch Id 197/278  is having validation loss of 0.615475058555603\n",
            "0.5770413279533386\n",
            "Epoch #1. Batch Id 197/278  is having validation accuracy of 82.97032828282828\n",
            "Epoch #1. Batch Id 198/278  is having validation loss of 0.6167882084846497\n",
            "0.8767912983894348\n",
            "Epoch #1. Batch Id 198/278  is having validation accuracy of 82.91457286432161\n",
            "Epoch #1. Batch Id 199/278  is having validation loss of 0.6167030930519104\n",
            "0.5997592806816101\n",
            "Epoch #1. Batch Id 199/278  is having validation accuracy of 82.890625\n",
            "Epoch #1. Batch Id 200/278  is having validation loss of 0.6168835163116455\n",
            "0.6529672145843506\n",
            "Epoch #1. Batch Id 200/278  is having validation accuracy of 82.88246268656717\n",
            "Epoch #1. Batch Id 201/278  is having validation loss of 0.6177670955657959\n",
            "0.7953691482543945\n",
            "Epoch #1. Batch Id 201/278  is having validation accuracy of 82.82797029702971\n",
            "Epoch #1. Batch Id 202/278  is having validation loss of 0.6168484091758728\n",
            "0.4312734007835388\n",
            "Epoch #1. Batch Id 202/278  is having validation accuracy of 82.83559113300493\n",
            "Epoch #1. Batch Id 203/278  is having validation loss of 0.617104709148407\n",
            "0.6691319346427917\n",
            "Epoch #1. Batch Id 203/278  is having validation accuracy of 82.8125\n",
            "Epoch #1. Batch Id 204/278  is having validation loss of 0.6171237826347351\n",
            "0.6210131645202637\n",
            "Epoch #1. Batch Id 204/278  is having validation accuracy of 82.83536585365853\n",
            "Epoch #1. Batch Id 205/278  is having validation loss of 0.6164319515228271\n",
            "0.4746077060699463\n",
            "Epoch #1. Batch Id 205/278  is having validation accuracy of 82.84283980582525\n",
            "Epoch #1. Batch Id 206/278  is having validation loss of 0.6155392527580261\n",
            "0.43164604902267456\n",
            "Epoch #1. Batch Id 206/278  is having validation accuracy of 82.83514492753623\n",
            "Epoch #1. Batch Id 207/278  is having validation loss of 0.6151002645492554\n",
            "0.5242251753807068\n",
            "Epoch #1. Batch Id 207/278  is having validation accuracy of 82.84254807692308\n",
            "Epoch #1. Batch Id 208/278  is having validation loss of 0.6157669425010681\n",
            "0.7544421553611755\n",
            "Epoch #1. Batch Id 208/278  is having validation accuracy of 82.81997607655502\n",
            "Epoch #1. Batch Id 209/278  is having validation loss of 0.6145225763320923\n",
            "0.35444459319114685\n",
            "Epoch #1. Batch Id 209/278  is having validation accuracy of 82.87202380952381\n",
            "Epoch #1. Batch Id 210/278  is having validation loss of 0.6171754002571106\n",
            "1.1742645502090454\n",
            "Epoch #1. Batch Id 210/278  is having validation accuracy of 82.81990521327015\n",
            "Epoch #1. Batch Id 211/278  is having validation loss of 0.6162785887718201\n",
            "0.4270528554916382\n",
            "Epoch #1. Batch Id 211/278  is having validation accuracy of 82.84198113207547\n",
            "Epoch #1. Batch Id 212/278  is having validation loss of 0.6172393560409546\n",
            "0.8209252953529358\n",
            "Epoch #1. Batch Id 212/278  is having validation accuracy of 82.81983568075117\n",
            "Epoch #1. Batch Id 213/278  is having validation loss of 0.6185319423675537\n",
            "0.8938472270965576\n",
            "Epoch #1. Batch Id 213/278  is having validation accuracy of 82.75408878504673\n",
            "Epoch #1. Batch Id 214/278  is having validation loss of 0.6185977458953857\n",
            "0.6326843500137329\n",
            "Epoch #1. Batch Id 214/278  is having validation accuracy of 82.76162790697674\n",
            "Epoch #1. Batch Id 215/278  is having validation loss of 0.618413507938385\n",
            "0.5787968635559082\n",
            "Epoch #1. Batch Id 215/278  is having validation accuracy of 82.76909722222223\n",
            "Epoch #1. Batch Id 216/278  is having validation loss of 0.6192784309387207\n",
            "0.8060990571975708\n",
            "Epoch #1. Batch Id 216/278  is having validation accuracy of 82.76209677419355\n",
            "Epoch #1. Batch Id 217/278  is having validation loss of 0.6202764511108398\n",
            "0.8368462324142456\n",
            "Epoch #1. Batch Id 217/278  is having validation accuracy of 82.69782110091744\n",
            "Epoch #1. Batch Id 218/278  is having validation loss of 0.6206421256065369\n",
            "0.7003553509712219\n",
            "Epoch #1. Batch Id 218/278  is having validation accuracy of 82.70547945205479\n",
            "Epoch #1. Batch Id 219/278  is having validation loss of 0.6208125352859497\n",
            "0.658129096031189\n",
            "Epoch #1. Batch Id 219/278  is having validation accuracy of 82.67045454545455\n",
            "Epoch #1. Batch Id 220/278  is having validation loss of 0.6204491853713989\n",
            "0.5405135154724121\n",
            "Epoch #1. Batch Id 220/278  is having validation accuracy of 82.6923076923077\n",
            "Epoch #1. Batch Id 221/278  is having validation loss of 0.6207970976829529\n",
            "0.6976794004440308\n",
            "Epoch #1. Batch Id 221/278  is having validation accuracy of 82.65765765765765\n",
            "Epoch #1. Batch Id 222/278  is having validation loss of 0.6213710308074951\n",
            "0.7487785816192627\n",
            "Epoch #1. Batch Id 222/278  is having validation accuracy of 82.62331838565022\n",
            "Epoch #1. Batch Id 223/278  is having validation loss of 0.6207043528556824\n",
            "0.4720343351364136\n",
            "Epoch #1. Batch Id 223/278  is having validation accuracy of 82.6171875\n",
            "Epoch #1. Batch Id 224/278  is having validation loss of 0.6215566992759705\n",
            "0.8124885559082031\n",
            "Epoch #1. Batch Id 224/278  is having validation accuracy of 82.59722222222223\n",
            "Epoch #1. Batch Id 225/278  is having validation loss of 0.6209349632263184\n",
            "0.48103922605514526\n",
            "Epoch #1. Batch Id 225/278  is having validation accuracy of 82.61891592920354\n",
            "Epoch #1. Batch Id 226/278  is having validation loss of 0.6208512187004089\n",
            "0.6019271016120911\n",
            "Epoch #1. Batch Id 226/278  is having validation accuracy of 82.64041850220265\n",
            "Epoch #1. Batch Id 227/278  is having validation loss of 0.6218723654747009\n",
            "0.8536736965179443\n",
            "Epoch #1. Batch Id 227/278  is having validation accuracy of 82.6343201754386\n",
            "Epoch #1. Batch Id 228/278  is having validation loss of 0.6217181086540222\n",
            "0.5865427851676941\n",
            "Epoch #1. Batch Id 228/278  is having validation accuracy of 82.65556768558952\n",
            "Epoch #1. Batch Id 229/278  is having validation loss of 0.6241418123245239\n",
            "1.1791675090789795\n",
            "Epoch #1. Batch Id 229/278  is having validation accuracy of 82.6086956521739\n",
            "Epoch #1. Batch Id 230/278  is having validation loss of 0.6241661310195923\n",
            "0.6297533512115479\n",
            "Epoch #1. Batch Id 230/278  is having validation accuracy of 82.60281385281385\n",
            "Epoch #1. Batch Id 231/278  is having validation loss of 0.6231772899627686\n",
            "0.394753098487854\n",
            "Epoch #1. Batch Id 231/278  is having validation accuracy of 82.65086206896552\n",
            "Epoch #1. Batch Id 232/278  is having validation loss of 0.6231659054756165\n",
            "0.6205234527587891\n",
            "Epoch #1. Batch Id 232/278  is having validation accuracy of 82.63143776824035\n",
            "Epoch #1. Batch Id 233/278  is having validation loss of 0.6225951910018921\n",
            "0.48961594700813293\n",
            "Epoch #1. Batch Id 233/278  is having validation accuracy of 82.63888888888889\n",
            "Epoch #1. Batch Id 234/278  is having validation loss of 0.6216540932655334\n",
            "0.4014381468296051\n",
            "Epoch #1. Batch Id 234/278  is having validation accuracy of 82.67287234042553\n",
            "Epoch #1. Batch Id 235/278  is having validation loss of 0.6213701367378235\n",
            "0.554633617401123\n",
            "Epoch #1. Batch Id 235/278  is having validation accuracy of 82.65360169491525\n",
            "Epoch #1. Batch Id 236/278  is having validation loss of 0.6215894222259521\n",
            "0.6733434200286865\n",
            "Epoch #1. Batch Id 236/278  is having validation accuracy of 82.62130801687763\n",
            "Epoch #1. Batch Id 237/278  is having validation loss of 0.6207031607627869\n",
            "0.41065770387649536\n",
            "Epoch #1. Batch Id 237/278  is having validation accuracy of 82.64180672268908\n",
            "Epoch #1. Batch Id 238/278  is having validation loss of 0.6221519112586975\n",
            "0.9669613838195801\n",
            "Epoch #1. Batch Id 238/278  is having validation accuracy of 82.5836820083682\n",
            "Epoch #1. Batch Id 239/278  is having validation loss of 0.6205568313598633\n",
            "0.23932650685310364\n",
            "Epoch #1. Batch Id 239/278  is having validation accuracy of 82.64322916666667\n",
            "Epoch #1. Batch Id 240/278  is having validation loss of 0.620820939540863\n",
            "0.6842001080513\n",
            "Epoch #1. Batch Id 240/278  is having validation accuracy of 82.63744813278008\n",
            "Epoch #1. Batch Id 241/278  is having validation loss of 0.6203981637954712\n",
            "0.5185049176216125\n",
            "Epoch #1. Batch Id 241/278  is having validation accuracy of 82.65754132231405\n",
            "Epoch #1. Batch Id 242/278  is having validation loss of 0.6193020939826965\n",
            "0.3540480136871338\n",
            "Epoch #1. Batch Id 242/278  is having validation accuracy of 82.70318930041152\n",
            "Epoch #1. Batch Id 243/278  is having validation loss of 0.6179855465888977\n",
            "0.2980640232563019\n",
            "Epoch #1. Batch Id 243/278  is having validation accuracy of 82.73565573770492\n",
            "Epoch #1. Batch Id 244/278  is having validation loss of 0.6188119053840637\n",
            "0.8204365372657776\n",
            "Epoch #1. Batch Id 244/278  is having validation accuracy of 82.71683673469387\n",
            "Epoch #1. Batch Id 245/278  is having validation loss of 0.6193025708198547\n",
            "0.7395199537277222\n",
            "Epoch #1. Batch Id 245/278  is having validation accuracy of 82.69817073170732\n",
            "Epoch #1. Batch Id 246/278  is having validation loss of 0.6212617754936218\n",
            "1.1032291650772095\n",
            "Epoch #1. Batch Id 246/278  is having validation accuracy of 82.667004048583\n",
            "Epoch #1. Batch Id 247/278  is having validation loss of 0.6212361454963684\n",
            "0.6149105429649353\n",
            "Epoch #1. Batch Id 247/278  is having validation accuracy of 82.67389112903226\n",
            "Epoch #1. Batch Id 248/278  is having validation loss of 0.6221628785133362\n",
            "0.8519967794418335\n",
            "Epoch #1. Batch Id 248/278  is having validation accuracy of 82.66817269076306\n",
            "Epoch #1. Batch Id 249/278  is having validation loss of 0.6218956708908081\n",
            "0.5553539395332336\n",
            "Epoch #1. Batch Id 249/278  is having validation accuracy of 82.675\n",
            "Epoch #1. Batch Id 250/278  is having validation loss of 0.6221932172775269\n",
            "0.6965731382369995\n",
            "Epoch #1. Batch Id 250/278  is having validation accuracy of 82.65687250996017\n",
            "Epoch #1. Batch Id 251/278  is having validation loss of 0.6237407922744751\n",
            "1.0121865272521973\n",
            "Epoch #1. Batch Id 251/278  is having validation accuracy of 82.6264880952381\n",
            "Epoch #1. Batch Id 252/278  is having validation loss of 0.623927116394043\n",
            "0.6708883047103882\n",
            "Epoch #1. Batch Id 252/278  is having validation accuracy of 82.62104743083005\n",
            "Epoch #1. Batch Id 253/278  is having validation loss of 0.6259640455245972\n",
            "1.1413054466247559\n",
            "Epoch #1. Batch Id 253/278  is having validation accuracy of 82.56643700787401\n",
            "Epoch #1. Batch Id 254/278  is having validation loss of 0.6257096529006958\n",
            "0.561095654964447\n",
            "Epoch #1. Batch Id 254/278  is having validation accuracy of 82.57352941176471\n",
            "Epoch #1. Batch Id 255/278  is having validation loss of 0.6248866319656372\n",
            "0.41501492261886597\n",
            "Epoch #1. Batch Id 255/278  is having validation accuracy of 82.58056640625\n",
            "Epoch #1. Batch Id 256/278  is having validation loss of 0.6239516735076904\n",
            "0.38460665941238403\n",
            "Epoch #1. Batch Id 256/278  is having validation accuracy of 82.58754863813229\n",
            "Epoch #1. Batch Id 257/278  is having validation loss of 0.6228678226470947\n",
            "0.3443223536014557\n",
            "Epoch #1. Batch Id 257/278  is having validation accuracy of 82.6187015503876\n",
            "Epoch #1. Batch Id 258/278  is having validation loss of 0.622227668762207\n",
            "0.45706725120544434\n",
            "Epoch #1. Batch Id 258/278  is having validation accuracy of 82.63754826254826\n",
            "Epoch #1. Batch Id 259/278  is having validation loss of 0.6212599873542786\n",
            "0.3706261217594147\n",
            "Epoch #1. Batch Id 259/278  is having validation accuracy of 82.68028846153847\n",
            "Epoch #1. Batch Id 260/278  is having validation loss of 0.6200655102729797\n",
            "0.3094945549964905\n",
            "Epoch #1. Batch Id 260/278  is having validation accuracy of 82.69875478927203\n",
            "Epoch #1. Batch Id 261/278  is having validation loss of 0.6196854710578918\n",
            "0.5204991698265076\n",
            "Epoch #1. Batch Id 261/278  is having validation accuracy of 82.6932251908397\n",
            "Epoch #1. Batch Id 262/278  is having validation loss of 0.6197222471237183\n",
            "0.6293595433235168\n",
            "Epoch #1. Batch Id 262/278  is having validation accuracy of 82.68773764258555\n",
            "Epoch #1. Batch Id 263/278  is having validation loss of 0.6198458671569824\n",
            "0.6523554921150208\n",
            "Epoch #1. Batch Id 263/278  is having validation accuracy of 82.68229166666667\n",
            "Epoch #1. Batch Id 264/278  is having validation loss of 0.6184813380241394\n",
            "0.2582404315471649\n",
            "Epoch #1. Batch Id 264/278  is having validation accuracy of 82.73584905660377\n",
            "Epoch #1. Batch Id 265/278  is having validation loss of 0.6196911931037903\n",
            "0.940296471118927\n",
            "Epoch #1. Batch Id 265/278  is having validation accuracy of 82.69501879699249\n",
            "Epoch #1. Batch Id 266/278  is having validation loss of 0.6208508014678955\n",
            "0.9292997121810913\n",
            "Epoch #1. Batch Id 266/278  is having validation accuracy of 82.67790262172285\n",
            "Epoch #1. Batch Id 267/278  is having validation loss of 0.6197046041488647\n",
            "0.313663125038147\n",
            "Epoch #1. Batch Id 267/278  is having validation accuracy of 82.71921641791045\n",
            "Epoch #1. Batch Id 268/278  is having validation loss of 0.6195142269134521\n",
            "0.5685005187988281\n",
            "Epoch #1. Batch Id 268/278  is having validation accuracy of 82.71375464684014\n",
            "Epoch #1. Batch Id 269/278  is having validation loss of 0.6186495423316956\n",
            "0.3860451579093933\n",
            "Epoch #1. Batch Id 269/278  is having validation accuracy of 82.73148148148148\n",
            "Epoch #1. Batch Id 270/278  is having validation loss of 0.6188963055610657\n",
            "0.6855151653289795\n",
            "Epoch #1. Batch Id 270/278  is having validation accuracy of 82.73754612546125\n",
            "Epoch #1. Batch Id 271/278  is having validation loss of 0.6190665364265442\n",
            "0.6651914715766907\n",
            "Epoch #1. Batch Id 271/278  is having validation accuracy of 82.7435661764706\n",
            "Epoch #1. Batch Id 272/278  is having validation loss of 0.6201359629631042\n",
            "0.9110255837440491\n",
            "Epoch #1. Batch Id 272/278  is having validation accuracy of 82.6923076923077\n",
            "Epoch #1. Batch Id 273/278  is having validation loss of 0.6215401887893677\n",
            "1.004886507987976\n",
            "Epoch #1. Batch Id 273/278  is having validation accuracy of 82.65282846715328\n",
            "Epoch #1. Batch Id 274/278  is having validation loss of 0.6211144924163818\n",
            "0.5044659376144409\n",
            "Epoch #1. Batch Id 274/278  is having validation accuracy of 82.67045454545455\n",
            "Epoch #1. Batch Id 275/278  is having validation loss of 0.621645450592041\n",
            "0.7676571011543274\n",
            "Epoch #1. Batch Id 275/278  is having validation accuracy of 82.68795289855072\n",
            "Epoch #1. Batch Id 276/278  is having validation loss of 0.6217942833900452\n",
            "0.6628707051277161\n",
            "Epoch #1. Batch Id 276/278  is having validation accuracy of 82.68276173285199\n",
            "Epoch #1. Batch Id 277/278  is having validation loss of 0.6197389364242554\n",
            "0.050402283668518066\n",
            "Epoch #1. Batch Id 277/278  is having validation accuracy of 82.69057284618854\n",
            "Эпоха #1 train_loss: 6.965963166294387e-06, val_loss: 6.988485984038562e-05\n",
            "Потрачено 8.8 минут на 1 эпоху\n",
            "Batch Id 0 is having training loss of 1.0249749422073364\n",
            "1.0249749422073364\n",
            "Epoch #2. Accuracy on batch 0/3013  on Training is 75.0\n",
            "Epoch #2. Accuracy on batch 1/3013  on Training is 79.6875\n",
            "Epoch #2. Accuracy on batch 2/3013  on Training is 81.25\n",
            "Epoch #2. Accuracy on batch 3/3013  on Training is 82.8125\n",
            "Epoch #2. Accuracy on batch 4/3013  on Training is 83.75\n",
            "Epoch #2. Accuracy on batch 5/3013  on Training is 82.8125\n",
            "Epoch #2. Accuracy on batch 6/3013  on Training is 83.03571428571429\n",
            "Epoch #2. Accuracy on batch 7/3013  on Training is 83.59375\n",
            "Epoch #2. Accuracy on batch 8/3013  on Training is 82.98611111111111\n",
            "Epoch #2. Accuracy on batch 9/3013  on Training is 83.125\n",
            "Epoch #2. Accuracy on batch 10/3013  on Training is 83.52272727272727\n",
            "Epoch #2. Accuracy on batch 11/3013  on Training is 83.33333333333333\n",
            "Epoch #2. Accuracy on batch 12/3013  on Training is 83.41346153846153\n",
            "Epoch #2. Accuracy on batch 13/3013  on Training is 81.91964285714286\n",
            "Epoch #2. Accuracy on batch 14/3013  on Training is 82.29166666666667\n",
            "Epoch #2. Accuracy on batch 15/3013  on Training is 82.421875\n",
            "Epoch #2. Accuracy on batch 16/3013  on Training is 82.16911764705883\n",
            "Epoch #2. Accuracy on batch 17/3013  on Training is 82.29166666666667\n",
            "Epoch #2. Accuracy on batch 18/3013  on Training is 83.0592105263158\n",
            "Epoch #2. Accuracy on batch 19/3013  on Training is 83.4375\n",
            "Batch Id 20 is having training loss of 0.624365508556366\n",
            "0.5194277763366699\n",
            "Epoch #2. Accuracy on batch 20/3013  on Training is 83.63095238095238\n",
            "Epoch #2. Accuracy on batch 21/3013  on Training is 83.80681818181819\n",
            "Epoch #2. Accuracy on batch 22/3013  on Training is 83.28804347826087\n",
            "Epoch #2. Accuracy on batch 23/3013  on Training is 83.59375\n",
            "Epoch #2. Accuracy on batch 24/3013  on Training is 83.375\n",
            "Epoch #2. Accuracy on batch 25/3013  on Training is 83.53365384615384\n",
            "Epoch #2. Accuracy on batch 26/3013  on Training is 83.79629629629629\n",
            "Epoch #2. Accuracy on batch 27/3013  on Training is 84.15178571428571\n",
            "Epoch #2. Accuracy on batch 28/3013  on Training is 84.05172413793103\n",
            "Epoch #2. Accuracy on batch 29/3013  on Training is 83.95833333333333\n",
            "Epoch #2. Accuracy on batch 30/3013  on Training is 83.97177419354838\n",
            "Epoch #2. Accuracy on batch 31/3013  on Training is 83.88671875\n",
            "Epoch #2. Accuracy on batch 32/3013  on Training is 84.0909090909091\n",
            "Epoch #2. Accuracy on batch 33/3013  on Training is 84.00735294117646\n",
            "Epoch #2. Accuracy on batch 34/3013  on Training is 83.92857142857143\n",
            "Epoch #2. Accuracy on batch 35/3013  on Training is 83.85416666666667\n",
            "Epoch #2. Accuracy on batch 36/3013  on Training is 83.86824324324324\n",
            "Epoch #2. Accuracy on batch 37/3013  on Training is 83.96381578947368\n",
            "Epoch #2. Accuracy on batch 38/3013  on Training is 84.13461538461539\n",
            "Epoch #2. Accuracy on batch 39/3013  on Training is 84.140625\n",
            "Batch Id 40 is having training loss of 0.5971370339393616\n",
            "0.8017045259475708\n",
            "Epoch #2. Accuracy on batch 40/3013  on Training is 83.9939024390244\n",
            "Epoch #2. Accuracy on batch 41/3013  on Training is 84.07738095238095\n",
            "Epoch #2. Accuracy on batch 42/3013  on Training is 84.15697674418605\n",
            "Epoch #2. Accuracy on batch 43/3013  on Training is 83.73579545454545\n",
            "Epoch #2. Accuracy on batch 44/3013  on Training is 84.02777777777777\n",
            "Epoch #2. Accuracy on batch 45/3013  on Training is 84.10326086956522\n",
            "Epoch #2. Accuracy on batch 46/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 47/3013  on Training is 84.30989583333333\n",
            "Epoch #2. Accuracy on batch 48/3013  on Training is 84.31122448979592\n",
            "Epoch #2. Accuracy on batch 49/3013  on Training is 84.4375\n",
            "Epoch #2. Accuracy on batch 50/3013  on Training is 84.31372549019608\n",
            "Epoch #2. Accuracy on batch 51/3013  on Training is 84.2548076923077\n",
            "Epoch #2. Accuracy on batch 52/3013  on Training is 84.31603773584905\n",
            "Epoch #2. Accuracy on batch 53/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 54/3013  on Training is 84.31818181818181\n",
            "Epoch #2. Accuracy on batch 55/3013  on Training is 84.09598214285714\n",
            "Epoch #2. Accuracy on batch 56/3013  on Training is 84.04605263157895\n",
            "Epoch #2. Accuracy on batch 57/3013  on Training is 84.05172413793103\n",
            "Epoch #2. Accuracy on batch 58/3013  on Training is 84.11016949152543\n",
            "Epoch #2. Accuracy on batch 59/3013  on Training is 84.16666666666667\n",
            "Batch Id 60 is having training loss of 0.5912931561470032\n",
            "0.5536331534385681\n",
            "Epoch #2. Accuracy on batch 60/3013  on Training is 84.17008196721312\n",
            "Epoch #2. Accuracy on batch 61/3013  on Training is 84.02217741935483\n",
            "Epoch #2. Accuracy on batch 62/3013  on Training is 83.92857142857143\n",
            "Epoch #2. Accuracy on batch 63/3013  on Training is 84.033203125\n",
            "Epoch #2. Accuracy on batch 64/3013  on Training is 84.03846153846153\n",
            "Epoch #2. Accuracy on batch 65/3013  on Training is 83.90151515151516\n",
            "Epoch #2. Accuracy on batch 66/3013  on Training is 84.04850746268657\n",
            "Epoch #2. Accuracy on batch 67/3013  on Training is 83.9154411764706\n",
            "Epoch #2. Accuracy on batch 68/3013  on Training is 83.96739130434783\n",
            "Epoch #2. Accuracy on batch 69/3013  on Training is 84.01785714285714\n",
            "Epoch #2. Accuracy on batch 70/3013  on Training is 84.0669014084507\n",
            "Epoch #2. Accuracy on batch 71/3013  on Training is 84.02777777777777\n",
            "Epoch #2. Accuracy on batch 72/3013  on Training is 84.1181506849315\n",
            "Epoch #2. Accuracy on batch 73/3013  on Training is 84.07939189189189\n",
            "Epoch #2. Accuracy on batch 74/3013  on Training is 84.16666666666667\n",
            "Epoch #2. Accuracy on batch 75/3013  on Training is 84.21052631578948\n",
            "Epoch #2. Accuracy on batch 76/3013  on Training is 84.05032467532467\n",
            "Epoch #2. Accuracy on batch 77/3013  on Training is 83.97435897435898\n",
            "Epoch #2. Accuracy on batch 78/3013  on Training is 83.9003164556962\n",
            "Epoch #2. Accuracy on batch 79/3013  on Training is 83.8671875\n",
            "Batch Id 80 is having training loss of 0.5905612707138062\n",
            "0.44273507595062256\n",
            "Epoch #2. Accuracy on batch 80/3013  on Training is 83.91203703703704\n",
            "Epoch #2. Accuracy on batch 81/3013  on Training is 83.8795731707317\n",
            "Epoch #2. Accuracy on batch 82/3013  on Training is 83.96084337349397\n",
            "Epoch #2. Accuracy on batch 83/3013  on Training is 83.96577380952381\n",
            "Epoch #2. Accuracy on batch 84/3013  on Training is 84.08088235294117\n",
            "Epoch #2. Accuracy on batch 85/3013  on Training is 83.97529069767442\n",
            "Epoch #2. Accuracy on batch 86/3013  on Training is 83.97988505747126\n",
            "Epoch #2. Accuracy on batch 87/3013  on Training is 83.8778409090909\n",
            "Epoch #2. Accuracy on batch 88/3013  on Training is 83.84831460674157\n",
            "Epoch #2. Accuracy on batch 89/3013  on Training is 83.92361111111111\n",
            "Epoch #2. Accuracy on batch 90/3013  on Training is 83.92857142857143\n",
            "Epoch #2. Accuracy on batch 91/3013  on Training is 83.96739130434783\n",
            "Epoch #2. Accuracy on batch 92/3013  on Training is 83.97177419354838\n",
            "Epoch #2. Accuracy on batch 93/3013  on Training is 84.00930851063829\n",
            "Epoch #2. Accuracy on batch 94/3013  on Training is 84.01315789473684\n",
            "Epoch #2. Accuracy on batch 95/3013  on Training is 83.984375\n",
            "Epoch #2. Accuracy on batch 96/3013  on Training is 84.0528350515464\n",
            "Epoch #2. Accuracy on batch 97/3013  on Training is 84.02423469387755\n",
            "Epoch #2. Accuracy on batch 98/3013  on Training is 84.05934343434343\n",
            "Epoch #2. Accuracy on batch 99/3013  on Training is 83.96875\n",
            "Batch Id 100 is having training loss of 0.5829116702079773\n",
            "0.7020444869995117\n",
            "Epoch #2. Accuracy on batch 100/3013  on Training is 83.8799504950495\n",
            "Epoch #2. Accuracy on batch 101/3013  on Training is 84.00735294117646\n",
            "Epoch #2. Accuracy on batch 102/3013  on Training is 84.01092233009709\n",
            "Epoch #2. Accuracy on batch 103/3013  on Training is 83.95432692307692\n",
            "Epoch #2. Accuracy on batch 104/3013  on Training is 83.86904761904762\n",
            "Epoch #2. Accuracy on batch 105/3013  on Training is 83.87382075471699\n",
            "Epoch #2. Accuracy on batch 106/3013  on Training is 83.8785046728972\n",
            "Epoch #2. Accuracy on batch 107/3013  on Training is 83.88310185185185\n",
            "Epoch #2. Accuracy on batch 108/3013  on Training is 83.91628440366972\n",
            "Epoch #2. Accuracy on batch 109/3013  on Training is 83.86363636363636\n",
            "Epoch #2. Accuracy on batch 110/3013  on Training is 83.86824324324324\n",
            "Epoch #2. Accuracy on batch 111/3013  on Training is 83.87276785714286\n",
            "Epoch #2. Accuracy on batch 112/3013  on Training is 83.79424778761062\n",
            "Epoch #2. Accuracy on batch 113/3013  on Training is 83.85416666666667\n",
            "Epoch #2. Accuracy on batch 114/3013  on Training is 83.94021739130434\n",
            "Epoch #2. Accuracy on batch 115/3013  on Training is 83.9978448275862\n",
            "Epoch #2. Accuracy on batch 116/3013  on Training is 84.13461538461539\n",
            "Epoch #2. Accuracy on batch 117/3013  on Training is 84.11016949152543\n",
            "Epoch #2. Accuracy on batch 118/3013  on Training is 84.19117647058823\n",
            "Epoch #2. Accuracy on batch 119/3013  on Training is 84.19270833333333\n",
            "Batch Id 120 is having training loss of 0.5798277854919434\n",
            "0.5652973651885986\n",
            "Epoch #2. Accuracy on batch 120/3013  on Training is 84.22004132231405\n",
            "Epoch #2. Accuracy on batch 121/3013  on Training is 84.27254098360656\n",
            "Epoch #2. Accuracy on batch 122/3013  on Training is 84.19715447154472\n",
            "Epoch #2. Accuracy on batch 123/3013  on Training is 84.19858870967742\n",
            "Epoch #2. Accuracy on batch 124/3013  on Training is 84.175\n",
            "Epoch #2. Accuracy on batch 125/3013  on Training is 84.15178571428571\n",
            "Epoch #2. Accuracy on batch 126/3013  on Training is 84.17814960629921\n",
            "Epoch #2. Accuracy on batch 127/3013  on Training is 84.2529296875\n",
            "Epoch #2. Accuracy on batch 128/3013  on Training is 84.3265503875969\n",
            "Epoch #2. Accuracy on batch 129/3013  on Training is 84.32692307692308\n",
            "Epoch #2. Accuracy on batch 130/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 131/3013  on Training is 84.35132575757575\n",
            "Epoch #2. Accuracy on batch 132/3013  on Training is 84.28101503759399\n",
            "Epoch #2. Accuracy on batch 133/3013  on Training is 84.21175373134328\n",
            "Epoch #2. Accuracy on batch 134/3013  on Training is 84.21296296296296\n",
            "Epoch #2. Accuracy on batch 135/3013  on Training is 84.21415441176471\n",
            "Epoch #2. Accuracy on batch 136/3013  on Training is 84.21532846715328\n",
            "Epoch #2. Accuracy on batch 137/3013  on Training is 84.23913043478261\n",
            "Epoch #2. Accuracy on batch 138/3013  on Training is 84.24010791366906\n",
            "Epoch #2. Accuracy on batch 139/3013  on Training is 84.26339285714286\n",
            "Batch Id 140 is having training loss of 0.5750874280929565\n",
            "0.7919151782989502\n",
            "Epoch #2. Accuracy on batch 140/3013  on Training is 84.26418439716312\n",
            "Epoch #2. Accuracy on batch 141/3013  on Training is 84.33098591549296\n",
            "Epoch #2. Accuracy on batch 142/3013  on Training is 84.30944055944056\n",
            "Epoch #2. Accuracy on batch 143/3013  on Training is 84.33159722222223\n",
            "Epoch #2. Accuracy on batch 144/3013  on Training is 84.35344827586206\n",
            "Epoch #2. Accuracy on batch 145/3013  on Training is 84.26797945205479\n",
            "Epoch #2. Accuracy on batch 146/3013  on Training is 84.2687074829932\n",
            "Epoch #2. Accuracy on batch 147/3013  on Training is 84.26942567567568\n",
            "Epoch #2. Accuracy on batch 148/3013  on Training is 84.18624161073825\n",
            "Epoch #2. Accuracy on batch 149/3013  on Training is 84.20833333333333\n",
            "Epoch #2. Accuracy on batch 150/3013  on Training is 84.12665562913908\n",
            "Epoch #2. Accuracy on batch 151/3013  on Training is 84.1282894736842\n",
            "Epoch #2. Accuracy on batch 152/3013  on Training is 84.15032679738562\n",
            "Epoch #2. Accuracy on batch 153/3013  on Training is 84.0909090909091\n",
            "Epoch #2. Accuracy on batch 154/3013  on Training is 84.09274193548387\n",
            "Epoch #2. Accuracy on batch 155/3013  on Training is 84.13461538461539\n",
            "Epoch #2. Accuracy on batch 156/3013  on Training is 84.11624203821655\n",
            "Epoch #2. Accuracy on batch 157/3013  on Training is 84.07832278481013\n",
            "Epoch #2. Accuracy on batch 158/3013  on Training is 84.0998427672956\n",
            "Epoch #2. Accuracy on batch 159/3013  on Training is 84.08203125\n",
            "Batch Id 160 is having training loss of 0.577783465385437\n",
            "0.924588143825531\n",
            "Epoch #2. Accuracy on batch 160/3013  on Training is 84.04503105590062\n",
            "Epoch #2. Accuracy on batch 161/3013  on Training is 84.08564814814815\n",
            "Epoch #2. Accuracy on batch 162/3013  on Training is 84.04907975460122\n",
            "Epoch #2. Accuracy on batch 163/3013  on Training is 84.03201219512195\n",
            "Epoch #2. Accuracy on batch 164/3013  on Training is 84.0909090909091\n",
            "Epoch #2. Accuracy on batch 165/3013  on Training is 84.13027108433735\n",
            "Epoch #2. Accuracy on batch 166/3013  on Training is 84.1130239520958\n",
            "Epoch #2. Accuracy on batch 167/3013  on Training is 84.13318452380952\n",
            "Epoch #2. Accuracy on batch 168/3013  on Training is 84.11612426035504\n",
            "Epoch #2. Accuracy on batch 169/3013  on Training is 84.11764705882354\n",
            "Epoch #2. Accuracy on batch 170/3013  on Training is 84.11915204678363\n",
            "Epoch #2. Accuracy on batch 171/3013  on Training is 84.10247093023256\n",
            "Epoch #2. Accuracy on batch 172/3013  on Training is 84.1221098265896\n",
            "Epoch #2. Accuracy on batch 173/3013  on Training is 84.08764367816092\n",
            "Epoch #2. Accuracy on batch 174/3013  on Training is 84.125\n",
            "Epoch #2. Accuracy on batch 175/3013  on Training is 84.0731534090909\n",
            "Epoch #2. Accuracy on batch 176/3013  on Training is 84.12782485875707\n",
            "Epoch #2. Accuracy on batch 177/3013  on Training is 84.11165730337079\n",
            "Epoch #2. Accuracy on batch 178/3013  on Training is 84.09567039106145\n",
            "Epoch #2. Accuracy on batch 179/3013  on Training is 84.04513888888889\n",
            "Batch Id 180 is having training loss of 0.5704659819602966\n",
            "0.40578964352607727\n",
            "Epoch #2. Accuracy on batch 180/3013  on Training is 84.04696132596685\n",
            "Epoch #2. Accuracy on batch 181/3013  on Training is 84.04876373626374\n",
            "Epoch #2. Accuracy on batch 182/3013  on Training is 84.10177595628416\n",
            "Epoch #2. Accuracy on batch 183/3013  on Training is 84.15421195652173\n",
            "Epoch #2. Accuracy on batch 184/3013  on Training is 84.13851351351352\n",
            "Epoch #2. Accuracy on batch 185/3013  on Training is 84.10618279569893\n",
            "Epoch #2. Accuracy on batch 186/3013  on Training is 84.14104278074866\n",
            "Epoch #2. Accuracy on batch 187/3013  on Training is 84.19215425531915\n",
            "Epoch #2. Accuracy on batch 188/3013  on Training is 84.1765873015873\n",
            "Epoch #2. Accuracy on batch 189/3013  on Training is 84.21052631578948\n",
            "Epoch #2. Accuracy on batch 190/3013  on Training is 84.19502617801047\n",
            "Epoch #2. Accuracy on batch 191/3013  on Training is 84.1796875\n",
            "Epoch #2. Accuracy on batch 192/3013  on Training is 84.2130829015544\n",
            "Epoch #2. Accuracy on batch 193/3013  on Training is 84.16559278350516\n",
            "Epoch #2. Accuracy on batch 194/3013  on Training is 84.1826923076923\n",
            "Epoch #2. Accuracy on batch 195/3013  on Training is 84.24744897959184\n",
            "Epoch #2. Accuracy on batch 196/3013  on Training is 84.29568527918782\n",
            "Epoch #2. Accuracy on batch 197/3013  on Training is 84.28030303030303\n",
            "Epoch #2. Accuracy on batch 198/3013  on Training is 84.23366834170854\n",
            "Epoch #2. Accuracy on batch 199/3013  on Training is 84.28125\n",
            "Batch Id 200 is having training loss of 0.5620277523994446\n",
            "0.3485797941684723\n",
            "Epoch #2. Accuracy on batch 200/3013  on Training is 84.28171641791045\n",
            "Epoch #2. Accuracy on batch 201/3013  on Training is 84.28217821782178\n",
            "Epoch #2. Accuracy on batch 202/3013  on Training is 84.2826354679803\n",
            "Epoch #2. Accuracy on batch 203/3013  on Training is 84.34436274509804\n",
            "Epoch #2. Accuracy on batch 204/3013  on Training is 84.34451219512195\n",
            "Epoch #2. Accuracy on batch 205/3013  on Training is 84.28398058252426\n",
            "Epoch #2. Accuracy on batch 206/3013  on Training is 84.32971014492753\n",
            "Epoch #2. Accuracy on batch 207/3013  on Training is 84.31490384615384\n",
            "Epoch #2. Accuracy on batch 208/3013  on Training is 84.30023923444976\n",
            "Epoch #2. Accuracy on batch 209/3013  on Training is 84.27083333333333\n",
            "Epoch #2. Accuracy on batch 210/3013  on Training is 84.2861374407583\n",
            "Epoch #2. Accuracy on batch 211/3013  on Training is 84.25707547169812\n",
            "Epoch #2. Accuracy on batch 212/3013  on Training is 84.28697183098592\n",
            "Epoch #2. Accuracy on batch 213/3013  on Training is 84.3019859813084\n",
            "Epoch #2. Accuracy on batch 214/3013  on Training is 84.30232558139535\n",
            "Epoch #2. Accuracy on batch 215/3013  on Training is 84.25925925925925\n",
            "Epoch #2. Accuracy on batch 216/3013  on Training is 84.18778801843318\n",
            "Epoch #2. Accuracy on batch 217/3013  on Training is 84.14564220183486\n",
            "Epoch #2. Accuracy on batch 218/3013  on Training is 84.20376712328768\n",
            "Epoch #2. Accuracy on batch 219/3013  on Training is 84.21875\n",
            "Batch Id 220 is having training loss of 0.5619505047798157\n",
            "0.6789339780807495\n",
            "Epoch #2. Accuracy on batch 220/3013  on Training is 84.20531674208145\n",
            "Epoch #2. Accuracy on batch 221/3013  on Training is 84.20608108108108\n",
            "Epoch #2. Accuracy on batch 222/3013  on Training is 84.17881165919283\n",
            "Epoch #2. Accuracy on batch 223/3013  on Training is 84.23549107142857\n",
            "Epoch #2. Accuracy on batch 224/3013  on Training is 84.25\n",
            "Epoch #2. Accuracy on batch 225/3013  on Training is 84.26438053097345\n",
            "Epoch #2. Accuracy on batch 226/3013  on Training is 84.30616740088105\n",
            "Epoch #2. Accuracy on batch 227/3013  on Training is 84.33388157894737\n",
            "Epoch #2. Accuracy on batch 228/3013  on Training is 84.33406113537117\n",
            "Epoch #2. Accuracy on batch 229/3013  on Training is 84.33423913043478\n",
            "Epoch #2. Accuracy on batch 230/3013  on Training is 84.33441558441558\n",
            "Epoch #2. Accuracy on batch 231/3013  on Training is 84.33459051724138\n",
            "Epoch #2. Accuracy on batch 232/3013  on Training is 84.33476394849785\n",
            "Epoch #2. Accuracy on batch 233/3013  on Training is 84.32158119658119\n",
            "Epoch #2. Accuracy on batch 234/3013  on Training is 84.33510638297872\n",
            "Epoch #2. Accuracy on batch 235/3013  on Training is 84.33527542372882\n",
            "Epoch #2. Accuracy on batch 236/3013  on Training is 84.29588607594937\n",
            "Epoch #2. Accuracy on batch 237/3013  on Training is 84.32247899159664\n",
            "Epoch #2. Accuracy on batch 238/3013  on Training is 84.34884937238493\n",
            "Epoch #2. Accuracy on batch 239/3013  on Training is 84.32291666666667\n",
            "Batch Id 240 is having training loss of 0.5604063272476196\n",
            "0.7037395238876343\n",
            "Epoch #2. Accuracy on batch 240/3013  on Training is 84.32313278008299\n",
            "Epoch #2. Accuracy on batch 241/3013  on Training is 84.32334710743801\n",
            "Epoch #2. Accuracy on batch 242/3013  on Training is 84.32355967078189\n",
            "Epoch #2. Accuracy on batch 243/3013  on Training is 84.36219262295081\n",
            "Epoch #2. Accuracy on batch 244/3013  on Training is 84.38775510204081\n",
            "Epoch #2. Accuracy on batch 245/3013  on Training is 84.32418699186992\n",
            "Epoch #2. Accuracy on batch 246/3013  on Training is 84.36234817813765\n",
            "Epoch #2. Accuracy on batch 247/3013  on Training is 84.33719758064517\n",
            "Epoch #2. Accuracy on batch 248/3013  on Training is 84.32479919678715\n",
            "Epoch #2. Accuracy on batch 249/3013  on Training is 84.35\n",
            "Epoch #2. Accuracy on batch 250/3013  on Training is 84.33764940239044\n",
            "Epoch #2. Accuracy on batch 251/3013  on Training is 84.35019841269842\n",
            "Epoch #2. Accuracy on batch 252/3013  on Training is 84.33794466403162\n",
            "Epoch #2. Accuracy on batch 253/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 254/3013  on Training is 84.38725490196079\n",
            "Epoch #2. Accuracy on batch 255/3013  on Training is 84.3994140625\n",
            "Epoch #2. Accuracy on batch 256/3013  on Training is 84.4114785992218\n",
            "Epoch #2. Accuracy on batch 257/3013  on Training is 84.4234496124031\n",
            "Epoch #2. Accuracy on batch 258/3013  on Training is 84.45945945945945\n",
            "Epoch #2. Accuracy on batch 259/3013  on Training is 84.47115384615384\n",
            "Batch Id 260 is having training loss of 0.5601972937583923\n",
            "0.9779568910598755\n",
            "Epoch #2. Accuracy on batch 260/3013  on Training is 84.44683908045977\n",
            "Epoch #2. Accuracy on batch 261/3013  on Training is 84.43463740458016\n",
            "Epoch #2. Accuracy on batch 262/3013  on Training is 84.42252851711027\n",
            "Epoch #2. Accuracy on batch 263/3013  on Training is 84.44602272727273\n",
            "Epoch #2. Accuracy on batch 264/3013  on Training is 84.41037735849056\n",
            "Epoch #2. Accuracy on batch 265/3013  on Training is 84.41024436090225\n",
            "Epoch #2. Accuracy on batch 266/3013  on Training is 84.41011235955057\n",
            "Epoch #2. Accuracy on batch 267/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 268/3013  on Training is 84.38661710037175\n",
            "Epoch #2. Accuracy on batch 269/3013  on Training is 84.38657407407408\n",
            "Epoch #2. Accuracy on batch 270/3013  on Training is 84.42112546125462\n",
            "Epoch #2. Accuracy on batch 271/3013  on Training is 84.4439338235294\n",
            "Epoch #2. Accuracy on batch 272/3013  on Training is 84.44368131868131\n",
            "Epoch #2. Accuracy on batch 273/3013  on Training is 84.44343065693431\n",
            "Epoch #2. Accuracy on batch 274/3013  on Training is 84.44318181818181\n",
            "Epoch #2. Accuracy on batch 275/3013  on Training is 84.43161231884058\n",
            "Epoch #2. Accuracy on batch 276/3013  on Training is 84.44268953068593\n",
            "Epoch #2. Accuracy on batch 277/3013  on Training is 84.45368705035972\n",
            "Epoch #2. Accuracy on batch 278/3013  on Training is 84.43100358422939\n",
            "Epoch #2. Accuracy on batch 279/3013  on Training is 84.41964285714286\n",
            "Batch Id 280 is having training loss of 0.561305582523346\n",
            "0.33465927839279175\n",
            "Epoch #2. Accuracy on batch 280/3013  on Training is 84.44172597864768\n",
            "Epoch #2. Accuracy on batch 281/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 282/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 283/3013  on Training is 84.38600352112677\n",
            "Epoch #2. Accuracy on batch 284/3013  on Training is 84.4298245614035\n",
            "Epoch #2. Accuracy on batch 285/3013  on Training is 84.40777972027972\n",
            "Epoch #2. Accuracy on batch 286/3013  on Training is 84.38588850174216\n",
            "Epoch #2. Accuracy on batch 287/3013  on Training is 84.41840277777777\n",
            "Epoch #2. Accuracy on batch 288/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 289/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 290/3013  on Training is 84.38573883161511\n",
            "Epoch #2. Accuracy on batch 291/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 292/3013  on Training is 84.34300341296928\n",
            "Epoch #2. Accuracy on batch 293/3013  on Training is 84.3218537414966\n",
            "Epoch #2. Accuracy on batch 294/3013  on Training is 84.32203389830508\n",
            "Epoch #2. Accuracy on batch 295/3013  on Training is 84.3116554054054\n",
            "Epoch #2. Accuracy on batch 296/3013  on Training is 84.29082491582491\n",
            "Epoch #2. Accuracy on batch 297/3013  on Training is 84.30159395973155\n",
            "Epoch #2. Accuracy on batch 298/3013  on Training is 84.32274247491638\n",
            "Epoch #2. Accuracy on batch 299/3013  on Training is 84.3125\n",
            "Batch Id 300 is having training loss of 0.5639779567718506\n",
            "0.4106126129627228\n",
            "Epoch #2. Accuracy on batch 300/3013  on Training is 84.32308970099668\n",
            "Epoch #2. Accuracy on batch 301/3013  on Training is 84.32326158940397\n",
            "Epoch #2. Accuracy on batch 302/3013  on Training is 84.33374587458746\n",
            "Epoch #2. Accuracy on batch 303/3013  on Training is 84.33388157894737\n",
            "Epoch #2. Accuracy on batch 304/3013  on Training is 84.32377049180327\n",
            "Epoch #2. Accuracy on batch 305/3013  on Training is 84.32393790849673\n",
            "Epoch #2. Accuracy on batch 306/3013  on Training is 84.3444625407166\n",
            "Epoch #2. Accuracy on batch 307/3013  on Training is 84.29383116883118\n",
            "Epoch #2. Accuracy on batch 308/3013  on Training is 84.29409385113269\n",
            "Epoch #2. Accuracy on batch 309/3013  on Training is 84.28427419354838\n",
            "Epoch #2. Accuracy on batch 310/3013  on Training is 84.26446945337621\n",
            "Epoch #2. Accuracy on batch 311/3013  on Training is 84.24479166666667\n",
            "Epoch #2. Accuracy on batch 312/3013  on Training is 84.29512779552715\n",
            "Epoch #2. Accuracy on batch 313/3013  on Training is 84.28542993630573\n",
            "Epoch #2. Accuracy on batch 314/3013  on Training is 84.30555555555556\n",
            "Epoch #2. Accuracy on batch 315/3013  on Training is 84.31566455696202\n",
            "Epoch #2. Accuracy on batch 316/3013  on Training is 84.34542586750788\n",
            "Epoch #2. Accuracy on batch 317/3013  on Training is 84.35534591194968\n",
            "Epoch #2. Accuracy on batch 318/3013  on Training is 84.32601880877743\n",
            "Epoch #2. Accuracy on batch 319/3013  on Training is 84.3359375\n",
            "Batch Id 320 is having training loss of 0.5622038841247559\n",
            "0.4079686105251312\n",
            "Epoch #2. Accuracy on batch 320/3013  on Training is 84.34579439252336\n",
            "Epoch #2. Accuracy on batch 321/3013  on Training is 84.3264751552795\n",
            "Epoch #2. Accuracy on batch 322/3013  on Training is 84.33630030959752\n",
            "Epoch #2. Accuracy on batch 323/3013  on Training is 84.32677469135803\n",
            "Epoch #2. Accuracy on batch 324/3013  on Training is 84.32692307692308\n",
            "Epoch #2. Accuracy on batch 325/3013  on Training is 84.31748466257669\n",
            "Epoch #2. Accuracy on batch 326/3013  on Training is 84.32721712538226\n",
            "Epoch #2. Accuracy on batch 327/3013  on Training is 84.33689024390245\n",
            "Epoch #2. Accuracy on batch 328/3013  on Training is 84.30851063829788\n",
            "Epoch #2. Accuracy on batch 329/3013  on Training is 84.33712121212122\n",
            "Epoch #2. Accuracy on batch 330/3013  on Training is 84.35611782477342\n",
            "Epoch #2. Accuracy on batch 331/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 332/3013  on Training is 84.36561561561561\n",
            "Epoch #2. Accuracy on batch 333/3013  on Training is 84.3562874251497\n",
            "Epoch #2. Accuracy on batch 334/3013  on Training is 84.35634328358209\n",
            "Epoch #2. Accuracy on batch 335/3013  on Training is 84.3656994047619\n",
            "Epoch #2. Accuracy on batch 336/3013  on Training is 84.35645400593472\n",
            "Epoch #2. Accuracy on batch 337/3013  on Training is 84.34726331360947\n",
            "Epoch #2. Accuracy on batch 338/3013  on Training is 84.34734513274336\n",
            "Epoch #2. Accuracy on batch 339/3013  on Training is 84.35661764705883\n",
            "Batch Id 340 is having training loss of 0.5627270340919495\n",
            "0.6298835873603821\n",
            "Epoch #2. Accuracy on batch 340/3013  on Training is 84.3566715542522\n",
            "Epoch #2. Accuracy on batch 341/3013  on Training is 84.36586257309942\n",
            "Epoch #2. Accuracy on batch 342/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 343/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 344/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 345/3013  on Training is 84.39306358381504\n",
            "Epoch #2. Accuracy on batch 346/3013  on Training is 84.38400576368876\n",
            "Epoch #2. Accuracy on batch 347/3013  on Training is 84.36602011494253\n",
            "Epoch #2. Accuracy on batch 348/3013  on Training is 84.34813753581662\n",
            "Epoch #2. Accuracy on batch 349/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 350/3013  on Training is 84.39280626780626\n",
            "Epoch #2. Accuracy on batch 351/3013  on Training is 84.3838778409091\n",
            "Epoch #2. Accuracy on batch 352/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 353/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 354/3013  on Training is 84.41021126760563\n",
            "Epoch #2. Accuracy on batch 355/3013  on Training is 84.42766853932584\n",
            "Epoch #2. Accuracy on batch 356/3013  on Training is 84.44502801120449\n",
            "Epoch #2. Accuracy on batch 357/3013  on Training is 84.43610335195531\n",
            "Epoch #2. Accuracy on batch 358/3013  on Training is 84.42722841225627\n",
            "Epoch #2. Accuracy on batch 359/3013  on Training is 84.43576388888889\n",
            "Batch Id 360 is having training loss of 0.5586248636245728\n",
            "0.46242550015449524\n",
            "Epoch #2. Accuracy on batch 360/3013  on Training is 84.42693905817174\n",
            "Epoch #2. Accuracy on batch 361/3013  on Training is 84.39226519337016\n",
            "Epoch #2. Accuracy on batch 362/3013  on Training is 84.40943526170798\n",
            "Epoch #2. Accuracy on batch 363/3013  on Training is 84.40075549450549\n",
            "Epoch #2. Accuracy on batch 364/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 365/3013  on Training is 84.35792349726776\n",
            "Epoch #2. Accuracy on batch 366/3013  on Training is 84.36648501362397\n",
            "Epoch #2. Accuracy on batch 367/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 368/3013  on Training is 84.39193766937669\n",
            "Epoch #2. Accuracy on batch 369/3013  on Training is 84.39189189189189\n",
            "Epoch #2. Accuracy on batch 370/3013  on Training is 84.40026954177898\n",
            "Epoch #2. Accuracy on batch 371/3013  on Training is 84.36659946236558\n",
            "Epoch #2. Accuracy on batch 372/3013  on Training is 84.38337801608579\n",
            "Epoch #2. Accuracy on batch 373/3013  on Training is 84.40006684491979\n",
            "Epoch #2. Accuracy on batch 374/3013  on Training is 84.38333333333334\n",
            "Epoch #2. Accuracy on batch 375/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 376/3013  on Training is 84.35013262599469\n",
            "Epoch #2. Accuracy on batch 377/3013  on Training is 84.35019841269842\n",
            "Epoch #2. Accuracy on batch 378/3013  on Training is 84.38324538258576\n",
            "Epoch #2. Accuracy on batch 379/3013  on Training is 84.39967105263158\n",
            "Batch Id 380 is having training loss of 0.5591431856155396\n",
            "0.14003822207450867\n",
            "Epoch #2. Accuracy on batch 380/3013  on Training is 84.43241469816273\n",
            "Epoch #2. Accuracy on batch 381/3013  on Training is 84.44044502617801\n",
            "Epoch #2. Accuracy on batch 382/3013  on Training is 84.46475195822454\n",
            "Epoch #2. Accuracy on batch 383/3013  on Training is 84.47265625\n",
            "Epoch #2. Accuracy on batch 384/3013  on Training is 84.48863636363636\n",
            "Epoch #2. Accuracy on batch 385/3013  on Training is 84.51262953367876\n",
            "Epoch #2. Accuracy on batch 386/3013  on Training is 84.53649870801034\n",
            "Epoch #2. Accuracy on batch 387/3013  on Training is 84.5360824742268\n",
            "Epoch #2. Accuracy on batch 388/3013  on Training is 84.52763496143959\n",
            "Epoch #2. Accuracy on batch 389/3013  on Training is 84.53525641025641\n",
            "Epoch #2. Accuracy on batch 390/3013  on Training is 84.55083120204604\n",
            "Epoch #2. Accuracy on batch 391/3013  on Training is 84.55038265306122\n",
            "Epoch #2. Accuracy on batch 392/3013  on Training is 84.53403307888041\n",
            "Epoch #2. Accuracy on batch 393/3013  on Training is 84.54156091370558\n",
            "Epoch #2. Accuracy on batch 394/3013  on Training is 84.54113924050633\n",
            "Epoch #2. Accuracy on batch 395/3013  on Training is 84.55650252525253\n",
            "Epoch #2. Accuracy on batch 396/3013  on Training is 84.57178841309823\n",
            "Epoch #2. Accuracy on batch 397/3013  on Training is 84.56344221105527\n",
            "Epoch #2. Accuracy on batch 398/3013  on Training is 84.55513784461152\n",
            "Epoch #2. Accuracy on batch 399/3013  on Training is 84.5546875\n",
            "Batch Id 400 is having training loss of 0.5568459033966064\n",
            "0.9885224103927612\n",
            "Epoch #2. Accuracy on batch 400/3013  on Training is 84.5464463840399\n",
            "Epoch #2. Accuracy on batch 401/3013  on Training is 84.5693407960199\n",
            "Epoch #2. Accuracy on batch 402/3013  on Training is 84.57661290322581\n",
            "Epoch #2. Accuracy on batch 403/3013  on Training is 84.56064356435644\n",
            "Epoch #2. Accuracy on batch 404/3013  on Training is 84.53703703703704\n",
            "Epoch #2. Accuracy on batch 405/3013  on Training is 84.5289408866995\n",
            "Epoch #2. Accuracy on batch 406/3013  on Training is 84.52088452088452\n",
            "Epoch #2. Accuracy on batch 407/3013  on Training is 84.49754901960785\n",
            "Epoch #2. Accuracy on batch 408/3013  on Training is 84.489608801956\n",
            "Epoch #2. Accuracy on batch 409/3013  on Training is 84.48932926829268\n",
            "Epoch #2. Accuracy on batch 410/3013  on Training is 84.48905109489051\n",
            "Epoch #2. Accuracy on batch 411/3013  on Training is 84.48877427184466\n",
            "Epoch #2. Accuracy on batch 412/3013  on Training is 84.48093220338983\n",
            "Epoch #2. Accuracy on batch 413/3013  on Training is 84.50332125603865\n",
            "Epoch #2. Accuracy on batch 414/3013  on Training is 84.52560240963855\n",
            "Epoch #2. Accuracy on batch 415/3013  on Training is 84.52524038461539\n",
            "Epoch #2. Accuracy on batch 416/3013  on Training is 84.53237410071942\n",
            "Epoch #2. Accuracy on batch 417/3013  on Training is 84.55442583732058\n",
            "Epoch #2. Accuracy on batch 418/3013  on Training is 84.56145584725537\n",
            "Epoch #2. Accuracy on batch 419/3013  on Training is 84.55357142857143\n",
            "Batch Id 420 is having training loss of 0.556225061416626\n",
            "0.4933585226535797\n",
            "Epoch #2. Accuracy on batch 420/3013  on Training is 84.56057007125891\n",
            "Epoch #2. Accuracy on batch 421/3013  on Training is 84.56013033175356\n",
            "Epoch #2. Accuracy on batch 422/3013  on Training is 84.58185579196217\n",
            "Epoch #2. Accuracy on batch 423/3013  on Training is 84.58873820754717\n",
            "Epoch #2. Accuracy on batch 424/3013  on Training is 84.6029411764706\n",
            "Epoch #2. Accuracy on batch 425/3013  on Training is 84.58773474178403\n",
            "Epoch #2. Accuracy on batch 426/3013  on Training is 84.57991803278688\n",
            "Epoch #2. Accuracy on batch 427/3013  on Training is 84.59404205607477\n",
            "Epoch #2. Accuracy on batch 428/3013  on Training is 84.60081585081585\n",
            "Epoch #2. Accuracy on batch 429/3013  on Training is 84.56395348837209\n",
            "Epoch #2. Accuracy on batch 430/3013  on Training is 84.5635150812065\n",
            "Epoch #2. Accuracy on batch 431/3013  on Training is 84.5558449074074\n",
            "Epoch #2. Accuracy on batch 432/3013  on Training is 84.53377598152424\n",
            "Epoch #2. Accuracy on batch 433/3013  on Training is 84.51180875576037\n",
            "Epoch #2. Accuracy on batch 434/3013  on Training is 84.50431034482759\n",
            "Epoch #2. Accuracy on batch 435/3013  on Training is 84.52551605504587\n",
            "Epoch #2. Accuracy on batch 436/3013  on Training is 84.52517162471396\n",
            "Epoch #2. Accuracy on batch 437/3013  on Training is 84.53196347031964\n",
            "Epoch #2. Accuracy on batch 438/3013  on Training is 84.5244874715262\n",
            "Epoch #2. Accuracy on batch 439/3013  on Training is 84.53125\n",
            "Batch Id 440 is having training loss of 0.5571230053901672\n",
            "0.5580155253410339\n",
            "Epoch #2. Accuracy on batch 440/3013  on Training is 84.54506802721089\n",
            "Epoch #2. Accuracy on batch 441/3013  on Training is 84.55882352941177\n",
            "Epoch #2. Accuracy on batch 442/3013  on Training is 84.5795711060948\n",
            "Epoch #2. Accuracy on batch 443/3013  on Training is 84.59318693693693\n",
            "Epoch #2. Accuracy on batch 444/3013  on Training is 84.6067415730337\n",
            "Epoch #2. Accuracy on batch 445/3013  on Training is 84.61322869955157\n",
            "Epoch #2. Accuracy on batch 446/3013  on Training is 84.60570469798658\n",
            "Epoch #2. Accuracy on batch 447/3013  on Training is 84.61216517857143\n",
            "Epoch #2. Accuracy on batch 448/3013  on Training is 84.60467706013362\n",
            "Epoch #2. Accuracy on batch 449/3013  on Training is 84.60416666666667\n",
            "Epoch #2. Accuracy on batch 450/3013  on Training is 84.63137472283813\n",
            "Epoch #2. Accuracy on batch 451/3013  on Training is 84.64463495575221\n",
            "Epoch #2. Accuracy on batch 452/3013  on Training is 84.62334437086092\n",
            "Epoch #2. Accuracy on batch 453/3013  on Training is 84.62968061674009\n",
            "Epoch #2. Accuracy on batch 454/3013  on Training is 84.63598901098901\n",
            "Epoch #2. Accuracy on batch 455/3013  on Training is 84.63541666666667\n",
            "Epoch #2. Accuracy on batch 456/3013  on Training is 84.63484682713347\n",
            "Epoch #2. Accuracy on batch 457/3013  on Training is 84.61381004366812\n",
            "Epoch #2. Accuracy on batch 458/3013  on Training is 84.61328976034858\n",
            "Epoch #2. Accuracy on batch 459/3013  on Training is 84.63315217391305\n",
            "Batch Id 460 is having training loss of 0.5540426969528198\n",
            "0.42227813601493835\n",
            "Epoch #2. Accuracy on batch 460/3013  on Training is 84.64614967462039\n",
            "Epoch #2. Accuracy on batch 461/3013  on Training is 84.65232683982684\n",
            "Epoch #2. Accuracy on batch 462/3013  on Training is 84.64497840172787\n",
            "Epoch #2. Accuracy on batch 463/3013  on Training is 84.65786637931035\n",
            "Epoch #2. Accuracy on batch 464/3013  on Training is 84.65053763440861\n",
            "Epoch #2. Accuracy on batch 465/3013  on Training is 84.64994635193133\n",
            "Epoch #2. Accuracy on batch 466/3013  on Training is 84.66943254817987\n",
            "Epoch #2. Accuracy on batch 467/3013  on Training is 84.68215811965813\n",
            "Epoch #2. Accuracy on batch 468/3013  on Training is 84.68816631130063\n",
            "Epoch #2. Accuracy on batch 469/3013  on Training is 84.67420212765957\n",
            "Epoch #2. Accuracy on batch 470/3013  on Training is 84.70010615711253\n",
            "Epoch #2. Accuracy on batch 471/3013  on Training is 84.68617584745763\n",
            "Epoch #2. Accuracy on batch 472/3013  on Training is 84.6921247357294\n",
            "Epoch #2. Accuracy on batch 473/3013  on Training is 84.70464135021098\n",
            "Epoch #2. Accuracy on batch 474/3013  on Training is 84.71052631578948\n",
            "Epoch #2. Accuracy on batch 475/3013  on Training is 84.71638655462185\n",
            "Epoch #2. Accuracy on batch 476/3013  on Training is 84.71567085953879\n",
            "Epoch #2. Accuracy on batch 477/3013  on Training is 84.7345711297071\n",
            "Epoch #2. Accuracy on batch 478/3013  on Training is 84.72077244258872\n",
            "Epoch #2. Accuracy on batch 479/3013  on Training is 84.73307291666667\n",
            "Batch Id 480 is having training loss of 0.5506033897399902\n",
            "0.40762820839881897\n",
            "Epoch #2. Accuracy on batch 480/3013  on Training is 84.74532224532224\n",
            "Epoch #2. Accuracy on batch 481/3013  on Training is 84.75103734439834\n",
            "Epoch #2. Accuracy on batch 482/3013  on Training is 84.76319875776397\n",
            "Epoch #2. Accuracy on batch 483/3013  on Training is 84.75594008264463\n",
            "Epoch #2. Accuracy on batch 484/3013  on Training is 84.76159793814433\n",
            "Epoch #2. Accuracy on batch 485/3013  on Training is 84.75437242798354\n",
            "Epoch #2. Accuracy on batch 486/3013  on Training is 84.73434291581108\n",
            "Epoch #2. Accuracy on batch 487/3013  on Training is 84.72720286885246\n",
            "Epoch #2. Accuracy on batch 488/3013  on Training is 84.71370143149284\n",
            "Epoch #2. Accuracy on batch 489/3013  on Training is 84.71938775510205\n",
            "Epoch #2. Accuracy on batch 490/3013  on Training is 84.70595723014257\n",
            "Epoch #2. Accuracy on batch 491/3013  on Training is 84.692581300813\n",
            "Epoch #2. Accuracy on batch 492/3013  on Training is 84.70461460446248\n",
            "Epoch #2. Accuracy on batch 493/3013  on Training is 84.6912955465587\n",
            "Epoch #2. Accuracy on batch 494/3013  on Training is 84.6969696969697\n",
            "Epoch #2. Accuracy on batch 495/3013  on Training is 84.69002016129032\n",
            "Epoch #2. Accuracy on batch 496/3013  on Training is 84.71453722334005\n",
            "Epoch #2. Accuracy on batch 497/3013  on Training is 84.72013052208835\n",
            "Epoch #2. Accuracy on batch 498/3013  on Training is 84.72570140280561\n",
            "Epoch #2. Accuracy on batch 499/3013  on Training is 84.7125\n",
            "Batch Id 500 is having training loss of 0.5520137548446655\n",
            "0.7359000444412231\n",
            "Epoch #2. Accuracy on batch 500/3013  on Training is 84.7055888223553\n",
            "Epoch #2. Accuracy on batch 501/3013  on Training is 84.69870517928287\n",
            "Epoch #2. Accuracy on batch 502/3013  on Training is 84.69806163021869\n",
            "Epoch #2. Accuracy on batch 503/3013  on Training is 84.68501984126983\n",
            "Epoch #2. Accuracy on batch 504/3013  on Training is 84.67202970297029\n",
            "Epoch #2. Accuracy on batch 505/3013  on Training is 84.67144268774703\n",
            "Epoch #2. Accuracy on batch 506/3013  on Training is 84.68318540433926\n",
            "Epoch #2. Accuracy on batch 507/3013  on Training is 84.66412401574803\n",
            "Epoch #2. Accuracy on batch 508/3013  on Training is 84.66355599214145\n",
            "Epoch #2. Accuracy on batch 509/3013  on Training is 84.66299019607843\n",
            "Epoch #2. Accuracy on batch 510/3013  on Training is 84.67465753424658\n",
            "Epoch #2. Accuracy on batch 511/3013  on Training is 84.686279296875\n",
            "Epoch #2. Accuracy on batch 512/3013  on Training is 84.67958089668616\n",
            "Epoch #2. Accuracy on batch 513/3013  on Training is 84.66682879377431\n",
            "Epoch #2. Accuracy on batch 514/3013  on Training is 84.69053398058253\n",
            "Epoch #2. Accuracy on batch 515/3013  on Training is 84.68386627906976\n",
            "Epoch #2. Accuracy on batch 516/3013  on Training is 84.68931334622825\n",
            "Epoch #2. Accuracy on batch 517/3013  on Training is 84.68870656370656\n",
            "Epoch #2. Accuracy on batch 518/3013  on Training is 84.67605973025049\n",
            "Epoch #2. Accuracy on batch 519/3013  on Training is 84.66346153846153\n",
            "Batch Id 520 is having training loss of 0.5535691380500793\n",
            "0.4922437071800232\n",
            "Epoch #2. Accuracy on batch 520/3013  on Training is 84.66890595009598\n",
            "Epoch #2. Accuracy on batch 521/3013  on Training is 84.65636973180077\n",
            "Epoch #2. Accuracy on batch 522/3013  on Training is 84.63790630975143\n",
            "Epoch #2. Accuracy on batch 523/3013  on Training is 84.64336832061069\n",
            "Epoch #2. Accuracy on batch 524/3013  on Training is 84.6547619047619\n",
            "Epoch #2. Accuracy on batch 525/3013  on Training is 84.64828897338403\n",
            "Epoch #2. Accuracy on batch 526/3013  on Training is 84.64777039848197\n",
            "Epoch #2. Accuracy on batch 527/3013  on Training is 84.63541666666667\n",
            "Epoch #2. Accuracy on batch 528/3013  on Training is 84.64083175803403\n",
            "Epoch #2. Accuracy on batch 529/3013  on Training is 84.64622641509433\n",
            "Epoch #2. Accuracy on batch 530/3013  on Training is 84.62806026365348\n",
            "Epoch #2. Accuracy on batch 531/3013  on Training is 84.6217105263158\n",
            "Epoch #2. Accuracy on batch 532/3013  on Training is 84.63297373358348\n",
            "Epoch #2. Accuracy on batch 533/3013  on Training is 84.62663857677903\n",
            "Epoch #2. Accuracy on batch 534/3013  on Training is 84.64369158878505\n",
            "Epoch #2. Accuracy on batch 535/3013  on Training is 84.64902052238806\n",
            "Epoch #2. Accuracy on batch 536/3013  on Training is 84.63105214152701\n",
            "Epoch #2. Accuracy on batch 537/3013  on Training is 84.65381040892193\n",
            "Epoch #2. Accuracy on batch 538/3013  on Training is 84.63589981447124\n",
            "Epoch #2. Accuracy on batch 539/3013  on Training is 84.61226851851852\n",
            "Batch Id 540 is having training loss of 0.5545030832290649\n",
            "0.6198903918266296\n",
            "Epoch #2. Accuracy on batch 540/3013  on Training is 84.59450092421442\n",
            "Epoch #2. Accuracy on batch 541/3013  on Training is 84.5940959409594\n",
            "Epoch #2. Accuracy on batch 542/3013  on Training is 84.58793738489871\n",
            "Epoch #2. Accuracy on batch 543/3013  on Training is 84.5703125\n",
            "Epoch #2. Accuracy on batch 544/3013  on Training is 84.5756880733945\n",
            "Epoch #2. Accuracy on batch 545/3013  on Training is 84.59249084249085\n",
            "Epoch #2. Accuracy on batch 546/3013  on Training is 84.59780621572212\n",
            "Epoch #2. Accuracy on batch 547/3013  on Training is 84.58599452554745\n",
            "Epoch #2. Accuracy on batch 548/3013  on Training is 84.59130236794171\n",
            "Epoch #2. Accuracy on batch 549/3013  on Training is 84.5909090909091\n",
            "Epoch #2. Accuracy on batch 550/3013  on Training is 84.5961887477314\n",
            "Epoch #2. Accuracy on batch 551/3013  on Training is 84.59578804347827\n",
            "Epoch #2. Accuracy on batch 552/3013  on Training is 84.58408679927668\n",
            "Epoch #2. Accuracy on batch 553/3013  on Training is 84.60063176895306\n",
            "Epoch #2. Accuracy on batch 554/3013  on Training is 84.58896396396396\n",
            "Epoch #2. Accuracy on batch 555/3013  on Training is 84.56047661870504\n",
            "Epoch #2. Accuracy on batch 556/3013  on Training is 84.55453321364452\n",
            "Epoch #2. Accuracy on batch 557/3013  on Training is 84.55421146953405\n",
            "Epoch #2. Accuracy on batch 558/3013  on Training is 84.54271019677996\n",
            "Epoch #2. Accuracy on batch 559/3013  on Training is 84.54799107142857\n",
            "Batch Id 560 is having training loss of 0.5555136203765869\n",
            "0.604930579662323\n",
            "Epoch #2. Accuracy on batch 560/3013  on Training is 84.53654188948306\n",
            "Epoch #2. Accuracy on batch 561/3013  on Training is 84.53069395017793\n",
            "Epoch #2. Accuracy on batch 562/3013  on Training is 84.52486678507992\n",
            "Epoch #2. Accuracy on batch 563/3013  on Training is 84.52460106382979\n",
            "Epoch #2. Accuracy on batch 564/3013  on Training is 84.51880530973452\n",
            "Epoch #2. Accuracy on batch 565/3013  on Training is 84.51855123674912\n",
            "Epoch #2. Accuracy on batch 566/3013  on Training is 84.51278659611992\n",
            "Epoch #2. Accuracy on batch 567/3013  on Training is 84.52354753521126\n",
            "Epoch #2. Accuracy on batch 568/3013  on Training is 84.52877855887522\n",
            "Epoch #2. Accuracy on batch 569/3013  on Training is 84.54495614035088\n",
            "Epoch #2. Accuracy on batch 570/3013  on Training is 84.53371278458845\n",
            "Epoch #2. Accuracy on batch 571/3013  on Training is 84.53343531468532\n",
            "Epoch #2. Accuracy on batch 572/3013  on Training is 84.54406631762653\n",
            "Epoch #2. Accuracy on batch 573/3013  on Training is 84.5383275261324\n",
            "Epoch #2. Accuracy on batch 574/3013  on Training is 84.54891304347827\n",
            "Epoch #2. Accuracy on batch 575/3013  on Training is 84.54861111111111\n",
            "Epoch #2. Accuracy on batch 576/3013  on Training is 84.55914211438476\n",
            "Epoch #2. Accuracy on batch 577/3013  on Training is 84.5534169550173\n",
            "Epoch #2. Accuracy on batch 578/3013  on Training is 84.54771157167531\n",
            "Epoch #2. Accuracy on batch 579/3013  on Training is 84.53125\n",
            "Batch Id 580 is having training loss of 0.5560592412948608\n",
            "0.5800033807754517\n",
            "Epoch #2. Accuracy on batch 580/3013  on Training is 84.53098106712565\n",
            "Epoch #2. Accuracy on batch 581/3013  on Training is 84.51997422680412\n",
            "Epoch #2. Accuracy on batch 582/3013  on Training is 84.53044596912521\n",
            "Epoch #2. Accuracy on batch 583/3013  on Training is 84.5355308219178\n",
            "Epoch #2. Accuracy on batch 584/3013  on Training is 84.54594017094017\n",
            "Epoch #2. Accuracy on batch 585/3013  on Training is 84.55098122866895\n",
            "Epoch #2. Accuracy on batch 586/3013  on Training is 84.56132879045997\n",
            "Epoch #2. Accuracy on batch 587/3013  on Training is 84.5610119047619\n",
            "Epoch #2. Accuracy on batch 588/3013  on Training is 84.5606960950764\n",
            "Epoch #2. Accuracy on batch 589/3013  on Training is 84.55508474576271\n",
            "Epoch #2. Accuracy on batch 590/3013  on Training is 84.55478003384094\n",
            "Epoch #2. Accuracy on batch 591/3013  on Training is 84.5703125\n",
            "Epoch #2. Accuracy on batch 592/3013  on Training is 84.57525295109612\n",
            "Epoch #2. Accuracy on batch 593/3013  on Training is 84.58017676767676\n",
            "Epoch #2. Accuracy on batch 594/3013  on Training is 84.5798319327731\n",
            "Epoch #2. Accuracy on batch 595/3013  on Training is 84.58473154362416\n",
            "Epoch #2. Accuracy on batch 596/3013  on Training is 84.57914572864321\n",
            "Epoch #2. Accuracy on batch 597/3013  on Training is 84.59448160535118\n",
            "Epoch #2. Accuracy on batch 598/3013  on Training is 84.59933222036727\n",
            "Epoch #2. Accuracy on batch 599/3013  on Training is 84.609375\n",
            "Batch Id 600 is having training loss of 0.5539093017578125\n",
            "0.4524509906768799\n",
            "Epoch #2. Accuracy on batch 600/3013  on Training is 84.60378535773711\n",
            "Epoch #2. Accuracy on batch 601/3013  on Training is 84.61897840531562\n",
            "Epoch #2. Accuracy on batch 602/3013  on Training is 84.62893864013267\n",
            "Epoch #2. Accuracy on batch 603/3013  on Training is 84.61817052980132\n",
            "Epoch #2. Accuracy on batch 604/3013  on Training is 84.62293388429752\n",
            "Epoch #2. Accuracy on batch 605/3013  on Training is 84.61221122112211\n",
            "Epoch #2. Accuracy on batch 606/3013  on Training is 84.59637561779242\n",
            "Epoch #2. Accuracy on batch 607/3013  on Training is 84.6217105263158\n",
            "Epoch #2. Accuracy on batch 608/3013  on Training is 84.61617405582923\n",
            "Epoch #2. Accuracy on batch 609/3013  on Training is 84.61577868852459\n",
            "Epoch #2. Accuracy on batch 610/3013  on Training is 84.62049918166939\n",
            "Epoch #2. Accuracy on batch 611/3013  on Training is 84.62009803921569\n",
            "Epoch #2. Accuracy on batch 612/3013  on Training is 84.6196982055465\n",
            "Epoch #2. Accuracy on batch 613/3013  on Training is 84.62438925081433\n",
            "Epoch #2. Accuracy on batch 614/3013  on Training is 84.6290650406504\n",
            "Epoch #2. Accuracy on batch 615/3013  on Training is 84.61850649350649\n",
            "Epoch #2. Accuracy on batch 616/3013  on Training is 84.61811183144246\n",
            "Epoch #2. Accuracy on batch 617/3013  on Training is 84.61771844660194\n",
            "Epoch #2. Accuracy on batch 618/3013  on Training is 84.59208400646203\n",
            "Epoch #2. Accuracy on batch 619/3013  on Training is 84.59677419354838\n",
            "Batch Id 620 is having training loss of 0.5544768571853638\n",
            "0.4110909700393677\n",
            "Epoch #2. Accuracy on batch 620/3013  on Training is 84.60648148148148\n",
            "Epoch #2. Accuracy on batch 621/3013  on Training is 84.60610932475885\n",
            "Epoch #2. Accuracy on batch 622/3013  on Training is 84.60573836276083\n",
            "Epoch #2. Accuracy on batch 623/3013  on Training is 84.61538461538461\n",
            "Epoch #2. Accuracy on batch 624/3013  on Training is 84.61\n",
            "Epoch #2. Accuracy on batch 625/3013  on Training is 84.60463258785943\n",
            "Epoch #2. Accuracy on batch 626/3013  on Training is 84.61423444976077\n",
            "Epoch #2. Accuracy on batch 627/3013  on Training is 84.59892515923566\n",
            "Epoch #2. Accuracy on batch 628/3013  on Training is 84.58863275039745\n",
            "Epoch #2. Accuracy on batch 629/3013  on Training is 84.59821428571429\n",
            "Epoch #2. Accuracy on batch 630/3013  on Training is 84.59290808240887\n",
            "Epoch #2. Accuracy on batch 631/3013  on Training is 84.5975079113924\n",
            "Epoch #2. Accuracy on batch 632/3013  on Training is 84.59221958925751\n",
            "Epoch #2. Accuracy on batch 633/3013  on Training is 84.58694794952682\n",
            "Epoch #2. Accuracy on batch 634/3013  on Training is 84.59645669291339\n",
            "Epoch #2. Accuracy on batch 635/3013  on Training is 84.6059355345912\n",
            "Epoch #2. Accuracy on batch 636/3013  on Training is 84.6006671899529\n",
            "Epoch #2. Accuracy on batch 637/3013  on Training is 84.60031347962382\n",
            "Epoch #2. Accuracy on batch 638/3013  on Training is 84.59996087636932\n",
            "Epoch #2. Accuracy on batch 639/3013  on Training is 84.6142578125\n",
            "Batch Id 640 is having training loss of 0.5532421469688416\n",
            "0.32042625546455383\n",
            "Epoch #2. Accuracy on batch 640/3013  on Training is 84.62363494539781\n",
            "Epoch #2. Accuracy on batch 641/3013  on Training is 84.62811526479751\n",
            "Epoch #2. Accuracy on batch 642/3013  on Training is 84.63258164852255\n",
            "Epoch #2. Accuracy on batch 643/3013  on Training is 84.61762422360249\n",
            "Epoch #2. Accuracy on batch 644/3013  on Training is 84.59786821705427\n",
            "Epoch #2. Accuracy on batch 645/3013  on Training is 84.60236068111455\n",
            "Epoch #2. Accuracy on batch 646/3013  on Training is 84.59234930448223\n",
            "Epoch #2. Accuracy on batch 647/3013  on Training is 84.5823688271605\n",
            "Epoch #2. Accuracy on batch 648/3013  on Training is 84.59167950693374\n",
            "Epoch #2. Accuracy on batch 649/3013  on Training is 84.59134615384616\n",
            "Epoch #2. Accuracy on batch 650/3013  on Training is 84.58141321044546\n",
            "Epoch #2. Accuracy on batch 651/3013  on Training is 84.5763036809816\n",
            "Epoch #2. Accuracy on batch 652/3013  on Training is 84.56642419601837\n",
            "Epoch #2. Accuracy on batch 653/3013  on Training is 84.56613149847095\n",
            "Epoch #2. Accuracy on batch 654/3013  on Training is 84.58015267175573\n",
            "Epoch #2. Accuracy on batch 655/3013  on Training is 84.5798399390244\n",
            "Epoch #2. Accuracy on batch 656/3013  on Training is 84.58428462709284\n",
            "Epoch #2. Accuracy on batch 657/3013  on Training is 84.57446808510639\n",
            "Epoch #2. Accuracy on batch 658/3013  on Training is 84.56942336874052\n",
            "Epoch #2. Accuracy on batch 659/3013  on Training is 84.56439393939394\n",
            "Batch Id 660 is having training loss of 0.5540146827697754\n",
            "0.7278887629508972\n",
            "Epoch #2. Accuracy on batch 660/3013  on Training is 84.5499243570348\n",
            "Epoch #2. Accuracy on batch 661/3013  on Training is 84.54966012084593\n",
            "Epoch #2. Accuracy on batch 662/3013  on Training is 84.54468325791855\n",
            "Epoch #2. Accuracy on batch 663/3013  on Training is 84.5679593373494\n",
            "Epoch #2. Accuracy on batch 664/3013  on Training is 84.57236842105263\n",
            "Epoch #2. Accuracy on batch 665/3013  on Training is 84.56737987987988\n",
            "Epoch #2. Accuracy on batch 666/3013  on Training is 84.56709145427287\n",
            "Epoch #2. Accuracy on batch 667/3013  on Training is 84.55744760479043\n",
            "Epoch #2. Accuracy on batch 668/3013  on Training is 84.57118834080717\n",
            "Epoch #2. Accuracy on batch 669/3013  on Training is 84.57089552238806\n",
            "Epoch #2. Accuracy on batch 670/3013  on Training is 84.57060357675111\n",
            "Epoch #2. Accuracy on batch 671/3013  on Training is 84.5796130952381\n",
            "Epoch #2. Accuracy on batch 672/3013  on Training is 84.58395245170877\n",
            "Epoch #2. Accuracy on batch 673/3013  on Training is 84.58364243323442\n",
            "Epoch #2. Accuracy on batch 674/3013  on Training is 84.5925925925926\n",
            "Epoch #2. Accuracy on batch 675/3013  on Training is 84.58302514792899\n",
            "Epoch #2. Accuracy on batch 676/3013  on Training is 84.5642540620384\n",
            "Epoch #2. Accuracy on batch 677/3013  on Training is 84.56858407079646\n",
            "Epoch #2. Accuracy on batch 678/3013  on Training is 84.54988954344624\n",
            "Epoch #2. Accuracy on batch 679/3013  on Training is 84.54963235294117\n",
            "Batch Id 680 is having training loss of 0.5550870895385742\n",
            "0.4725864827632904\n",
            "Epoch #2. Accuracy on batch 680/3013  on Training is 84.55396475770925\n",
            "Epoch #2. Accuracy on batch 681/3013  on Training is 84.55828445747801\n",
            "Epoch #2. Accuracy on batch 682/3013  on Training is 84.54428989751098\n",
            "Epoch #2. Accuracy on batch 683/3013  on Training is 84.53947368421052\n",
            "Epoch #2. Accuracy on batch 684/3013  on Training is 84.53923357664233\n",
            "Epoch #2. Accuracy on batch 685/3013  on Training is 84.53899416909621\n",
            "Epoch #2. Accuracy on batch 686/3013  on Training is 84.53875545851528\n",
            "Epoch #2. Accuracy on batch 687/3013  on Training is 84.52943313953489\n",
            "Epoch #2. Accuracy on batch 688/3013  on Training is 84.52467343976778\n",
            "Epoch #2. Accuracy on batch 689/3013  on Training is 84.52898550724638\n",
            "Epoch #2. Accuracy on batch 690/3013  on Training is 84.52876266280752\n",
            "Epoch #2. Accuracy on batch 691/3013  on Training is 84.51950867052022\n",
            "Epoch #2. Accuracy on batch 692/3013  on Training is 84.52380952380952\n",
            "Epoch #2. Accuracy on batch 693/3013  on Training is 84.53260086455332\n",
            "Epoch #2. Accuracy on batch 694/3013  on Training is 84.54586330935251\n",
            "Epoch #2. Accuracy on batch 695/3013  on Training is 84.53214798850574\n",
            "Epoch #2. Accuracy on batch 696/3013  on Training is 84.54088952654233\n",
            "Epoch #2. Accuracy on batch 697/3013  on Training is 84.54065186246419\n",
            "Epoch #2. Accuracy on batch 698/3013  on Training is 84.53594420600858\n",
            "Epoch #2. Accuracy on batch 699/3013  on Training is 84.52678571428571\n",
            "Batch Id 700 is having training loss of 0.5559787154197693\n",
            "0.7680513858795166\n",
            "Epoch #2. Accuracy on batch 700/3013  on Training is 84.50873751783166\n",
            "Epoch #2. Accuracy on batch 701/3013  on Training is 84.51299857549857\n",
            "Epoch #2. Accuracy on batch 702/3013  on Training is 84.51280227596017\n",
            "Epoch #2. Accuracy on batch 703/3013  on Training is 84.51704545454545\n",
            "Epoch #2. Accuracy on batch 704/3013  on Training is 84.50354609929079\n",
            "Epoch #2. Accuracy on batch 705/3013  on Training is 84.5033640226629\n",
            "Epoch #2. Accuracy on batch 706/3013  on Training is 84.50318246110325\n",
            "Epoch #2. Accuracy on batch 707/3013  on Training is 84.50741525423729\n",
            "Epoch #2. Accuracy on batch 708/3013  on Training is 84.51163610719323\n",
            "Epoch #2. Accuracy on batch 709/3013  on Training is 84.49823943661971\n",
            "Epoch #2. Accuracy on batch 710/3013  on Training is 84.48048523206751\n",
            "Epoch #2. Accuracy on batch 711/3013  on Training is 84.4627808988764\n",
            "Epoch #2. Accuracy on batch 712/3013  on Training is 84.47142356241234\n",
            "Epoch #2. Accuracy on batch 713/3013  on Training is 84.46691176470588\n",
            "Epoch #2. Accuracy on batch 714/3013  on Training is 84.47115384615384\n",
            "Epoch #2. Accuracy on batch 715/3013  on Training is 84.45356145251397\n",
            "Epoch #2. Accuracy on batch 716/3013  on Training is 84.44037656903765\n",
            "Epoch #2. Accuracy on batch 717/3013  on Training is 84.4533426183844\n",
            "Epoch #2. Accuracy on batch 718/3013  on Training is 84.4575799721836\n",
            "Epoch #2. Accuracy on batch 719/3013  on Training is 84.453125\n",
            "Batch Id 720 is having training loss of 0.5576997995376587\n",
            "0.2604939937591553\n",
            "Epoch #2. Accuracy on batch 720/3013  on Training is 84.47035367545077\n",
            "Epoch #2. Accuracy on batch 721/3013  on Training is 84.48320637119113\n",
            "Epoch #2. Accuracy on batch 722/3013  on Training is 84.47441217150761\n",
            "Epoch #2. Accuracy on batch 723/3013  on Training is 84.47427486187846\n",
            "Epoch #2. Accuracy on batch 724/3013  on Training is 84.47844827586206\n",
            "Epoch #2. Accuracy on batch 725/3013  on Training is 84.47830578512396\n",
            "Epoch #2. Accuracy on batch 726/3013  on Training is 84.47386519944979\n",
            "Epoch #2. Accuracy on batch 727/3013  on Training is 84.47802197802197\n",
            "Epoch #2. Accuracy on batch 728/3013  on Training is 84.47788065843622\n",
            "Epoch #2. Accuracy on batch 729/3013  on Training is 84.46917808219177\n",
            "Epoch #2. Accuracy on batch 730/3013  on Training is 84.47759917920656\n",
            "Epoch #2. Accuracy on batch 731/3013  on Training is 84.46892076502732\n",
            "Epoch #2. Accuracy on batch 732/3013  on Training is 84.46452933151433\n",
            "Epoch #2. Accuracy on batch 733/3013  on Training is 84.4558923705722\n",
            "Epoch #2. Accuracy on batch 734/3013  on Training is 84.46003401360544\n",
            "Epoch #2. Accuracy on batch 735/3013  on Training is 84.45991847826087\n",
            "Epoch #2. Accuracy on batch 736/3013  on Training is 84.4555630936228\n",
            "Epoch #2. Accuracy on batch 737/3013  on Training is 84.45968834688347\n",
            "Epoch #2. Accuracy on batch 738/3013  on Training is 84.45111637347767\n",
            "Epoch #2. Accuracy on batch 739/3013  on Training is 84.45523648648648\n",
            "Batch Id 740 is having training loss of 0.557053804397583\n",
            "0.31195324659347534\n",
            "Epoch #2. Accuracy on batch 740/3013  on Training is 84.46356275303644\n",
            "Epoch #2. Accuracy on batch 741/3013  on Training is 84.45923180592992\n",
            "Epoch #2. Accuracy on batch 742/3013  on Training is 84.46332436069987\n",
            "Epoch #2. Accuracy on batch 743/3013  on Training is 84.4674059139785\n",
            "Epoch #2. Accuracy on batch 744/3013  on Training is 84.46308724832215\n",
            "Epoch #2. Accuracy on batch 745/3013  on Training is 84.48391420911528\n",
            "Epoch #2. Accuracy on batch 746/3013  on Training is 84.4963186077644\n",
            "Epoch #2. Accuracy on batch 747/3013  on Training is 84.50033422459893\n",
            "Epoch #2. Accuracy on batch 748/3013  on Training is 84.50016688918558\n",
            "Epoch #2. Accuracy on batch 749/3013  on Training is 84.50833333333334\n",
            "Epoch #2. Accuracy on batch 750/3013  on Training is 84.51647802929428\n",
            "Epoch #2. Accuracy on batch 751/3013  on Training is 84.5204454787234\n",
            "Epoch #2. Accuracy on batch 752/3013  on Training is 84.53270252324037\n",
            "Epoch #2. Accuracy on batch 753/3013  on Training is 84.53663793103448\n",
            "Epoch #2. Accuracy on batch 754/3013  on Training is 84.53228476821192\n",
            "Epoch #2. Accuracy on batch 755/3013  on Training is 84.54861111111111\n",
            "Epoch #2. Accuracy on batch 756/3013  on Training is 84.54838177014531\n",
            "Epoch #2. Accuracy on batch 757/3013  on Training is 84.53166226912928\n",
            "Epoch #2. Accuracy on batch 758/3013  on Training is 84.53145586297761\n",
            "Epoch #2. Accuracy on batch 759/3013  on Training is 84.53125\n",
            "Batch Id 760 is having training loss of 0.5563828349113464\n",
            "1.027728796005249\n",
            "Epoch #2. Accuracy on batch 760/3013  on Training is 84.51461892247043\n",
            "Epoch #2. Accuracy on batch 761/3013  on Training is 84.51033464566929\n",
            "Epoch #2. Accuracy on batch 762/3013  on Training is 84.49787024901704\n",
            "Epoch #2. Accuracy on batch 763/3013  on Training is 84.49770942408377\n",
            "Epoch #2. Accuracy on batch 764/3013  on Training is 84.48120915032679\n",
            "Epoch #2. Accuracy on batch 765/3013  on Training is 84.4851501305483\n",
            "Epoch #2. Accuracy on batch 766/3013  on Training is 84.49315514993481\n",
            "Epoch #2. Accuracy on batch 767/3013  on Training is 84.48486328125\n",
            "Epoch #2. Accuracy on batch 768/3013  on Training is 84.48065669700911\n",
            "Epoch #2. Accuracy on batch 769/3013  on Training is 84.46834415584415\n",
            "Epoch #2. Accuracy on batch 770/3013  on Training is 84.47227626459144\n",
            "Epoch #2. Accuracy on batch 771/3013  on Training is 84.47215025906736\n",
            "Epoch #2. Accuracy on batch 772/3013  on Training is 84.47202457956016\n",
            "Epoch #2. Accuracy on batch 773/3013  on Training is 84.48804909560724\n",
            "Epoch #2. Accuracy on batch 774/3013  on Training is 84.47983870967742\n",
            "Epoch #2. Accuracy on batch 775/3013  on Training is 84.47567654639175\n",
            "Epoch #2. Accuracy on batch 776/3013  on Training is 84.47956885456885\n",
            "Epoch #2. Accuracy on batch 777/3013  on Training is 84.48746786632391\n",
            "Epoch #2. Accuracy on batch 778/3013  on Training is 84.47127727856225\n",
            "Epoch #2. Accuracy on batch 779/3013  on Training is 84.46314102564102\n",
            "Batch Id 780 is having training loss of 0.5576995015144348\n",
            "0.507178783416748\n",
            "Epoch #2. Accuracy on batch 780/3013  on Training is 84.46702944942382\n",
            "Epoch #2. Accuracy on batch 781/3013  on Training is 84.46291560102301\n",
            "Epoch #2. Accuracy on batch 782/3013  on Training is 84.47078544061303\n",
            "Epoch #2. Accuracy on batch 783/3013  on Training is 84.47464923469387\n",
            "Epoch #2. Accuracy on batch 784/3013  on Training is 84.46656050955414\n",
            "Epoch #2. Accuracy on batch 785/3013  on Training is 84.47041984732824\n",
            "Epoch #2. Accuracy on batch 786/3013  on Training is 84.47029860228717\n",
            "Epoch #2. Accuracy on batch 787/3013  on Training is 84.47017766497461\n",
            "Epoch #2. Accuracy on batch 788/3013  on Training is 84.46609632446135\n",
            "Epoch #2. Accuracy on batch 789/3013  on Training is 84.46993670886076\n",
            "Epoch #2. Accuracy on batch 790/3013  on Training is 84.4777180783818\n",
            "Epoch #2. Accuracy on batch 791/3013  on Training is 84.48547979797979\n",
            "Epoch #2. Accuracy on batch 792/3013  on Training is 84.48928121059268\n",
            "Epoch #2. Accuracy on batch 793/3013  on Training is 84.48913727959697\n",
            "Epoch #2. Accuracy on batch 794/3013  on Training is 84.48113207547169\n",
            "Epoch #2. Accuracy on batch 795/3013  on Training is 84.47707286432161\n",
            "Epoch #2. Accuracy on batch 796/3013  on Training is 84.48478670012547\n",
            "Epoch #2. Accuracy on batch 797/3013  on Training is 84.49248120300751\n",
            "Epoch #2. Accuracy on batch 798/3013  on Training is 84.48842302878599\n",
            "Epoch #2. Accuracy on batch 799/3013  on Training is 84.47265625\n",
            "Batch Id 800 is having training loss of 0.557481050491333\n",
            "0.32186758518218994\n",
            "Epoch #2. Accuracy on batch 800/3013  on Training is 84.48033707865169\n",
            "Epoch #2. Accuracy on batch 801/3013  on Training is 84.48020573566085\n",
            "Epoch #2. Accuracy on batch 802/3013  on Training is 84.48396637608967\n",
            "Epoch #2. Accuracy on batch 803/3013  on Training is 84.49160447761194\n",
            "Epoch #2. Accuracy on batch 804/3013  on Training is 84.49145962732919\n",
            "Epoch #2. Accuracy on batch 805/3013  on Training is 84.49131513647643\n",
            "Epoch #2. Accuracy on batch 806/3013  on Training is 84.4834262701363\n",
            "Epoch #2. Accuracy on batch 807/3013  on Training is 84.4794245049505\n",
            "Epoch #2. Accuracy on batch 808/3013  on Training is 84.48702101359703\n",
            "Epoch #2. Accuracy on batch 809/3013  on Training is 84.49074074074075\n",
            "Epoch #2. Accuracy on batch 810/3013  on Training is 84.49445129469791\n",
            "Epoch #2. Accuracy on batch 811/3013  on Training is 84.47891009852216\n",
            "Epoch #2. Accuracy on batch 812/3013  on Training is 84.47878228782288\n",
            "Epoch #2. Accuracy on batch 813/3013  on Training is 84.48633292383292\n",
            "Epoch #2. Accuracy on batch 814/3013  on Training is 84.48236196319019\n",
            "Epoch #2. Accuracy on batch 815/3013  on Training is 84.48988970588235\n",
            "Epoch #2. Accuracy on batch 816/3013  on Training is 84.48209914320685\n",
            "Epoch #2. Accuracy on batch 817/3013  on Training is 84.47432762836186\n",
            "Epoch #2. Accuracy on batch 818/3013  on Training is 84.48946886446886\n",
            "Epoch #2. Accuracy on batch 819/3013  on Training is 84.48932926829268\n",
            "Batch Id 820 is having training loss of 0.5572028160095215\n",
            "0.47938916087150574\n",
            "Epoch #2. Accuracy on batch 820/3013  on Training is 84.49299634591961\n",
            "Epoch #2. Accuracy on batch 821/3013  on Training is 84.50425790754258\n",
            "Epoch #2. Accuracy on batch 822/3013  on Training is 84.511695018226\n",
            "Epoch #2. Accuracy on batch 823/3013  on Training is 84.51532160194175\n",
            "Epoch #2. Accuracy on batch 824/3013  on Training is 84.50757575757575\n",
            "Epoch #2. Accuracy on batch 825/3013  on Training is 84.5111985472155\n",
            "Epoch #2. Accuracy on batch 826/3013  on Training is 84.51481257557437\n",
            "Epoch #2. Accuracy on batch 827/3013  on Training is 84.52596618357488\n",
            "Epoch #2. Accuracy on batch 828/3013  on Training is 84.5220144752714\n",
            "Epoch #2. Accuracy on batch 829/3013  on Training is 84.52560240963855\n",
            "Epoch #2. Accuracy on batch 830/3013  on Training is 84.5216606498195\n",
            "Epoch #2. Accuracy on batch 831/3013  on Training is 84.50270432692308\n",
            "Epoch #2. Accuracy on batch 832/3013  on Training is 84.51005402160864\n",
            "Epoch #2. Accuracy on batch 833/3013  on Training is 84.52113309352518\n",
            "Epoch #2. Accuracy on batch 834/3013  on Training is 84.51721556886227\n",
            "Epoch #2. Accuracy on batch 835/3013  on Training is 84.528259569378\n",
            "Epoch #2. Accuracy on batch 836/3013  on Training is 84.51687574671446\n",
            "Epoch #2. Accuracy on batch 837/3013  on Training is 84.52043556085918\n",
            "Epoch #2. Accuracy on batch 838/3013  on Training is 84.5202622169249\n",
            "Epoch #2. Accuracy on batch 839/3013  on Training is 84.51636904761905\n",
            "Batch Id 840 is having training loss of 0.5560650825500488\n",
            "0.5106222629547119\n",
            "Epoch #2. Accuracy on batch 840/3013  on Training is 84.52363258026159\n",
            "Epoch #2. Accuracy on batch 841/3013  on Training is 84.53459026128266\n",
            "Epoch #2. Accuracy on batch 842/3013  on Training is 84.52327995255041\n",
            "Epoch #2. Accuracy on batch 843/3013  on Training is 84.53791469194313\n",
            "Epoch #2. Accuracy on batch 844/3013  on Training is 84.54511834319527\n",
            "Epoch #2. Accuracy on batch 845/3013  on Training is 84.53752955082743\n",
            "Epoch #2. Accuracy on batch 846/3013  on Training is 84.52257969303425\n",
            "Epoch #2. Accuracy on batch 847/3013  on Training is 84.53346108490567\n",
            "Epoch #2. Accuracy on batch 848/3013  on Training is 84.52959363957598\n",
            "Epoch #2. Accuracy on batch 849/3013  on Training is 84.53308823529412\n",
            "Epoch #2. Accuracy on batch 850/3013  on Training is 84.54024676850764\n",
            "Epoch #2. Accuracy on batch 851/3013  on Training is 84.52904929577464\n",
            "Epoch #2. Accuracy on batch 852/3013  on Training is 84.53253223915593\n",
            "Epoch #2. Accuracy on batch 853/3013  on Training is 84.53600702576112\n",
            "Epoch #2. Accuracy on batch 854/3013  on Training is 84.52850877192982\n",
            "Epoch #2. Accuracy on batch 855/3013  on Training is 84.51372663551402\n",
            "Epoch #2. Accuracy on batch 856/3013  on Training is 84.51721120186697\n",
            "Epoch #2. Accuracy on batch 857/3013  on Training is 84.52068764568764\n",
            "Epoch #2. Accuracy on batch 858/3013  on Training is 84.51688009313155\n",
            "Epoch #2. Accuracy on batch 859/3013  on Training is 84.51308139534883\n",
            "Batch Id 860 is having training loss of 0.5558715462684631\n",
            "0.5126684904098511\n",
            "Epoch #2. Accuracy on batch 860/3013  on Training is 84.5201800232288\n",
            "Epoch #2. Accuracy on batch 861/3013  on Training is 84.52726218097447\n",
            "Epoch #2. Accuracy on batch 862/3013  on Training is 84.52708574739282\n",
            "Epoch #2. Accuracy on batch 863/3013  on Training is 84.53052662037037\n",
            "Epoch #2. Accuracy on batch 864/3013  on Training is 84.53034682080924\n",
            "Epoch #2. Accuracy on batch 865/3013  on Training is 84.52655889145497\n",
            "Epoch #2. Accuracy on batch 866/3013  on Training is 84.53359284890426\n",
            "Epoch #2. Accuracy on batch 867/3013  on Training is 84.52260944700461\n",
            "Epoch #2. Accuracy on batch 868/3013  on Training is 84.52603567318758\n",
            "Epoch #2. Accuracy on batch 869/3013  on Training is 84.51149425287356\n",
            "Epoch #2. Accuracy on batch 870/3013  on Training is 84.51133754305395\n",
            "Epoch #2. Accuracy on batch 871/3013  on Training is 84.50759747706422\n",
            "Epoch #2. Accuracy on batch 872/3013  on Training is 84.4967067583047\n",
            "Epoch #2. Accuracy on batch 873/3013  on Training is 84.49299199084668\n",
            "Epoch #2. Accuracy on batch 874/3013  on Training is 84.49285714285715\n",
            "Epoch #2. Accuracy on batch 875/3013  on Training is 84.49985730593608\n",
            "Epoch #2. Accuracy on batch 876/3013  on Training is 84.50684150513113\n",
            "Epoch #2. Accuracy on batch 877/3013  on Training is 84.50313211845102\n",
            "Epoch #2. Accuracy on batch 878/3013  on Training is 84.49943117178611\n",
            "Epoch #2. Accuracy on batch 879/3013  on Training is 84.48863636363636\n",
            "Batch Id 880 is having training loss of 0.5567038059234619\n",
            "0.5037603378295898\n",
            "Epoch #2. Accuracy on batch 880/3013  on Training is 84.48850737797957\n",
            "Epoch #2. Accuracy on batch 881/3013  on Training is 84.49546485260771\n",
            "Epoch #2. Accuracy on batch 882/3013  on Training is 84.49886749716875\n",
            "Epoch #2. Accuracy on batch 883/3013  on Training is 84.4951923076923\n",
            "Epoch #2. Accuracy on batch 884/3013  on Training is 84.48093220338983\n",
            "Epoch #2. Accuracy on batch 885/3013  on Training is 84.46670428893906\n",
            "Epoch #2. Accuracy on batch 886/3013  on Training is 84.47012401352875\n",
            "Epoch #2. Accuracy on batch 887/3013  on Training is 84.46649774774775\n",
            "Epoch #2. Accuracy on batch 888/3013  on Training is 84.45233408323959\n",
            "Epoch #2. Accuracy on batch 889/3013  on Training is 84.4557584269663\n",
            "Epoch #2. Accuracy on batch 890/3013  on Training is 84.45917508417509\n",
            "Epoch #2. Accuracy on batch 891/3013  on Training is 84.4660874439462\n",
            "Epoch #2. Accuracy on batch 892/3013  on Training is 84.45898656215006\n",
            "Epoch #2. Accuracy on batch 893/3013  on Training is 84.4658836689038\n",
            "Epoch #2. Accuracy on batch 894/3013  on Training is 84.46927374301676\n",
            "Epoch #2. Accuracy on batch 895/3013  on Training is 84.47614397321429\n",
            "Epoch #2. Accuracy on batch 896/3013  on Training is 84.48648272017837\n",
            "Epoch #2. Accuracy on batch 897/3013  on Training is 84.48287861915368\n",
            "Epoch #2. Accuracy on batch 898/3013  on Training is 84.49318687430478\n",
            "Epoch #2. Accuracy on batch 899/3013  on Training is 84.5\n",
            "Batch Id 900 is having training loss of 0.5563852787017822\n",
            "0.9012721180915833\n",
            "Epoch #2. Accuracy on batch 900/3013  on Training is 84.48598779134295\n",
            "Epoch #2. Accuracy on batch 901/3013  on Training is 84.49625831485588\n",
            "Epoch #2. Accuracy on batch 902/3013  on Training is 84.49958471760797\n",
            "Epoch #2. Accuracy on batch 903/3013  on Training is 84.49599004424779\n",
            "Epoch #2. Accuracy on batch 904/3013  on Training is 84.50621546961327\n",
            "Epoch #2. Accuracy on batch 905/3013  on Training is 84.50951986754967\n",
            "Epoch #2. Accuracy on batch 906/3013  on Training is 84.51281697905182\n",
            "Epoch #2. Accuracy on batch 907/3013  on Training is 84.51610682819383\n",
            "Epoch #2. Accuracy on batch 908/3013  on Training is 84.51938943894389\n",
            "Epoch #2. Accuracy on batch 909/3013  on Training is 84.50892857142857\n",
            "Epoch #2. Accuracy on batch 910/3013  on Training is 84.50535126234907\n",
            "Epoch #2. Accuracy on batch 911/3013  on Training is 84.50520833333333\n",
            "Epoch #2. Accuracy on batch 912/3013  on Training is 84.50164293537787\n",
            "Epoch #2. Accuracy on batch 913/3013  on Training is 84.50492341356674\n",
            "Epoch #2. Accuracy on batch 914/3013  on Training is 84.50136612021858\n",
            "Epoch #2. Accuracy on batch 915/3013  on Training is 84.50805131004367\n",
            "Epoch #2. Accuracy on batch 916/3013  on Training is 84.49086695747\n",
            "Epoch #2. Accuracy on batch 917/3013  on Training is 84.48733660130719\n",
            "Epoch #2. Accuracy on batch 918/3013  on Training is 84.49061479869424\n",
            "Epoch #2. Accuracy on batch 919/3013  on Training is 84.48709239130434\n",
            "Batch Id 920 is having training loss of 0.5568233728408813\n",
            "1.1138241291046143\n",
            "Epoch #2. Accuracy on batch 920/3013  on Training is 84.47339847991314\n",
            "Epoch #2. Accuracy on batch 921/3013  on Training is 84.47668112798264\n",
            "Epoch #2. Accuracy on batch 922/3013  on Training is 84.47318526543879\n",
            "Epoch #2. Accuracy on batch 923/3013  on Training is 84.47984307359307\n",
            "Epoch #2. Accuracy on batch 924/3013  on Training is 84.47297297297297\n",
            "Epoch #2. Accuracy on batch 925/3013  on Training is 84.45936825053995\n",
            "Epoch #2. Accuracy on batch 926/3013  on Training is 84.46264832793959\n",
            "Epoch #2. Accuracy on batch 927/3013  on Training is 84.46928879310344\n",
            "Epoch #2. Accuracy on batch 928/3013  on Training is 84.46918729817007\n",
            "Epoch #2. Accuracy on batch 929/3013  on Training is 84.4758064516129\n",
            "Epoch #2. Accuracy on batch 930/3013  on Training is 84.47905477980666\n",
            "Epoch #2. Accuracy on batch 931/3013  on Training is 84.47894313304721\n",
            "Epoch #2. Accuracy on batch 932/3013  on Training is 84.47883172561629\n",
            "Epoch #2. Accuracy on batch 933/3013  on Training is 84.46533725910064\n",
            "Epoch #2. Accuracy on batch 934/3013  on Training is 84.46189839572193\n",
            "Epoch #2. Accuracy on batch 935/3013  on Training is 84.46514423076923\n",
            "Epoch #2. Accuracy on batch 936/3013  on Training is 84.4517075773746\n",
            "Epoch #2. Accuracy on batch 937/3013  on Training is 84.44829424307036\n",
            "Epoch #2. Accuracy on batch 938/3013  on Training is 84.44821618743345\n",
            "Epoch #2. Accuracy on batch 939/3013  on Training is 84.46143617021276\n",
            "Batch Id 940 is having training loss of 0.5566428899765015\n",
            "0.3910338878631592\n",
            "Epoch #2. Accuracy on batch 940/3013  on Training is 84.46798618490968\n",
            "Epoch #2. Accuracy on batch 941/3013  on Training is 84.46788747346072\n",
            "Epoch #2. Accuracy on batch 942/3013  on Training is 84.47441675503711\n",
            "Epoch #2. Accuracy on batch 943/3013  on Training is 84.47100105932203\n",
            "Epoch #2. Accuracy on batch 944/3013  on Training is 84.47420634920636\n",
            "Epoch #2. Accuracy on batch 945/3013  on Training is 84.47410147991543\n",
            "Epoch #2. Accuracy on batch 946/3013  on Training is 84.47729672650475\n",
            "Epoch #2. Accuracy on batch 947/3013  on Training is 84.47059599156118\n",
            "Epoch #2. Accuracy on batch 948/3013  on Training is 84.48037407797682\n",
            "Epoch #2. Accuracy on batch 949/3013  on Training is 84.47368421052632\n",
            "Epoch #2. Accuracy on batch 950/3013  on Training is 84.47029442691904\n",
            "Epoch #2. Accuracy on batch 951/3013  on Training is 84.48004201680672\n",
            "Epoch #2. Accuracy on batch 952/3013  on Training is 84.47993179433368\n",
            "Epoch #2. Accuracy on batch 953/3013  on Training is 84.48637316561845\n",
            "Epoch #2. Accuracy on batch 954/3013  on Training is 84.47643979057591\n",
            "Epoch #2. Accuracy on batch 955/3013  on Training is 84.47633368200837\n",
            "Epoch #2. Accuracy on batch 956/3013  on Training is 84.46969696969697\n",
            "Epoch #2. Accuracy on batch 957/3013  on Training is 84.47938413361169\n",
            "Epoch #2. Accuracy on batch 958/3013  on Training is 84.4825338894682\n",
            "Epoch #2. Accuracy on batch 959/3013  on Training is 84.47916666666667\n",
            "Batch Id 960 is having training loss of 0.5556458830833435\n",
            "0.449767142534256\n",
            "Epoch #2. Accuracy on batch 960/3013  on Training is 84.48556191467222\n",
            "Epoch #2. Accuracy on batch 961/3013  on Training is 84.4789501039501\n",
            "Epoch #2. Accuracy on batch 962/3013  on Training is 84.47235202492212\n",
            "Epoch #2. Accuracy on batch 963/3013  on Training is 84.47873443983403\n",
            "Epoch #2. Accuracy on batch 964/3013  on Training is 84.49158031088083\n",
            "Epoch #2. Accuracy on batch 965/3013  on Training is 84.49469461697723\n",
            "Epoch #2. Accuracy on batch 966/3013  on Training is 84.4978024819028\n",
            "Epoch #2. Accuracy on batch 967/3013  on Training is 84.50413223140495\n",
            "Epoch #2. Accuracy on batch 968/3013  on Training is 84.49754901960785\n",
            "Epoch #2. Accuracy on batch 969/3013  on Training is 84.50708762886597\n",
            "Epoch #2. Accuracy on batch 970/3013  on Training is 84.51016992790937\n",
            "Epoch #2. Accuracy on batch 971/3013  on Training is 84.50038580246914\n",
            "Epoch #2. Accuracy on batch 972/3013  on Training is 84.5002569373073\n",
            "Epoch #2. Accuracy on batch 973/3013  on Training is 84.50654517453799\n",
            "Epoch #2. Accuracy on batch 974/3013  on Training is 84.50961538461539\n",
            "Epoch #2. Accuracy on batch 975/3013  on Training is 84.51588114754098\n",
            "Epoch #2. Accuracy on batch 976/3013  on Training is 84.51573694984647\n",
            "Epoch #2. Accuracy on batch 977/3013  on Training is 84.51559304703477\n",
            "Epoch #2. Accuracy on batch 978/3013  on Training is 84.51544943820225\n",
            "Epoch #2. Accuracy on batch 979/3013  on Training is 84.52168367346938\n",
            "Batch Id 980 is having training loss of 0.5553774833679199\n",
            "0.4898250699043274\n",
            "Epoch #2. Accuracy on batch 980/3013  on Training is 84.52153414882773\n",
            "Epoch #2. Accuracy on batch 981/3013  on Training is 84.5213849287169\n",
            "Epoch #2. Accuracy on batch 982/3013  on Training is 84.52123601220752\n",
            "Epoch #2. Accuracy on batch 983/3013  on Training is 84.52743902439025\n",
            "Epoch #2. Accuracy on batch 984/3013  on Training is 84.51776649746193\n",
            "Epoch #2. Accuracy on batch 985/3013  on Training is 84.52712981744422\n",
            "Epoch #2. Accuracy on batch 986/3013  on Training is 84.52064336372847\n",
            "Epoch #2. Accuracy on batch 987/3013  on Training is 84.52365890688259\n",
            "Epoch #2. Accuracy on batch 988/3013  on Training is 84.51402932254803\n",
            "Epoch #2. Accuracy on batch 989/3013  on Training is 84.51704545454545\n",
            "Epoch #2. Accuracy on batch 990/3013  on Training is 84.52005549949546\n",
            "Epoch #2. Accuracy on batch 991/3013  on Training is 84.50730846774194\n",
            "Epoch #2. Accuracy on batch 992/3013  on Training is 84.51346928499497\n",
            "Epoch #2. Accuracy on batch 993/3013  on Training is 84.5101861167002\n",
            "Epoch #2. Accuracy on batch 994/3013  on Training is 84.51319095477388\n",
            "Epoch #2. Accuracy on batch 995/3013  on Training is 84.52560240963855\n",
            "Epoch #2. Accuracy on batch 996/3013  on Training is 84.52545135406218\n",
            "Epoch #2. Accuracy on batch 997/3013  on Training is 84.52843186372745\n",
            "Epoch #2. Accuracy on batch 998/3013  on Training is 84.52515015015015\n",
            "Epoch #2. Accuracy on batch 999/3013  on Training is 84.51875\n",
            "Batch Id 1000 is having training loss of 0.5561721920967102\n",
            "0.4206981658935547\n",
            "Epoch #2. Accuracy on batch 1000/3013  on Training is 84.52485014985015\n",
            "Epoch #2. Accuracy on batch 1001/3013  on Training is 84.52781936127745\n",
            "Epoch #2. Accuracy on batch 1002/3013  on Training is 84.53389830508475\n",
            "Epoch #2. Accuracy on batch 1003/3013  on Training is 84.51506474103586\n",
            "Epoch #2. Accuracy on batch 1004/3013  on Training is 84.52114427860697\n",
            "Epoch #2. Accuracy on batch 1005/3013  on Training is 84.53031809145129\n",
            "Epoch #2. Accuracy on batch 1006/3013  on Training is 84.5301638530288\n",
            "Epoch #2. Accuracy on batch 1007/3013  on Training is 84.53000992063492\n",
            "Epoch #2. Accuracy on batch 1008/3013  on Training is 84.52056491575817\n",
            "Epoch #2. Accuracy on batch 1009/3013  on Training is 84.52660891089108\n",
            "Epoch #2. Accuracy on batch 1010/3013  on Training is 84.52645895153313\n",
            "Epoch #2. Accuracy on batch 1011/3013  on Training is 84.51704545454545\n",
            "Epoch #2. Accuracy on batch 1012/3013  on Training is 84.51999012833168\n",
            "Epoch #2. Accuracy on batch 1013/3013  on Training is 84.52601084812623\n",
            "Epoch #2. Accuracy on batch 1014/3013  on Training is 84.53509852216749\n",
            "Epoch #2. Accuracy on batch 1015/3013  on Training is 84.53186515748031\n",
            "Epoch #2. Accuracy on batch 1016/3013  on Training is 84.53478367748279\n",
            "Epoch #2. Accuracy on batch 1017/3013  on Training is 84.53462671905697\n",
            "Epoch #2. Accuracy on batch 1018/3013  on Training is 84.54060353287537\n",
            "Epoch #2. Accuracy on batch 1019/3013  on Training is 84.54350490196079\n",
            "Batch Id 1020 is having training loss of 0.5556604266166687\n",
            "0.7610953450202942\n",
            "Epoch #2. Accuracy on batch 1020/3013  on Training is 84.53415768854065\n",
            "Epoch #2. Accuracy on batch 1021/3013  on Training is 84.53094422700588\n",
            "Epoch #2. Accuracy on batch 1022/3013  on Training is 84.52468230694038\n",
            "Epoch #2. Accuracy on batch 1023/3013  on Training is 84.521484375\n",
            "Epoch #2. Accuracy on batch 1024/3013  on Training is 84.51829268292683\n",
            "Epoch #2. Accuracy on batch 1025/3013  on Training is 84.51206140350877\n",
            "Epoch #2. Accuracy on batch 1026/3013  on Training is 84.50584225900681\n",
            "Epoch #2. Accuracy on batch 1027/3013  on Training is 84.50267509727627\n",
            "Epoch #2. Accuracy on batch 1028/3013  on Training is 84.50255102040816\n",
            "Epoch #2. Accuracy on batch 1029/3013  on Training is 84.50546116504854\n",
            "Epoch #2. Accuracy on batch 1030/3013  on Training is 84.51139670223084\n",
            "Epoch #2. Accuracy on batch 1031/3013  on Training is 84.50823643410853\n",
            "Epoch #2. Accuracy on batch 1032/3013  on Training is 84.50508228460794\n",
            "Epoch #2. Accuracy on batch 1033/3013  on Training is 84.50193423597679\n",
            "Epoch #2. Accuracy on batch 1034/3013  on Training is 84.5078502415459\n",
            "Epoch #2. Accuracy on batch 1035/3013  on Training is 84.50772200772201\n",
            "Epoch #2. Accuracy on batch 1036/3013  on Training is 84.51060752169721\n",
            "Epoch #2. Accuracy on batch 1037/3013  on Training is 84.51047687861272\n",
            "Epoch #2. Accuracy on batch 1038/3013  on Training is 84.51636188642927\n",
            "Epoch #2. Accuracy on batch 1039/3013  on Training is 84.52223557692308\n",
            "Batch Id 1040 is having training loss of 0.5558122396469116\n",
            "0.8528069853782654\n",
            "Epoch #2. Accuracy on batch 1040/3013  on Training is 84.513088376561\n",
            "Epoch #2. Accuracy on batch 1041/3013  on Training is 84.51895393474088\n",
            "Epoch #2. Accuracy on batch 1042/3013  on Training is 84.52181208053692\n",
            "Epoch #2. Accuracy on batch 1043/3013  on Training is 84.5216714559387\n",
            "Epoch #2. Accuracy on batch 1044/3013  on Training is 84.52153110047847\n",
            "Epoch #2. Accuracy on batch 1045/3013  on Training is 84.52139101338432\n",
            "Epoch #2. Accuracy on batch 1046/3013  on Training is 84.5212511938873\n",
            "Epoch #2. Accuracy on batch 1047/3013  on Training is 84.51812977099236\n",
            "Epoch #2. Accuracy on batch 1048/3013  on Training is 84.50905624404194\n",
            "Epoch #2. Accuracy on batch 1049/3013  on Training is 84.50297619047619\n",
            "Epoch #2. Accuracy on batch 1050/3013  on Training is 84.50880114176974\n",
            "Epoch #2. Accuracy on batch 1051/3013  on Training is 84.50273288973384\n",
            "Epoch #2. Accuracy on batch 1052/3013  on Training is 84.49667616334283\n",
            "Epoch #2. Accuracy on batch 1053/3013  on Training is 84.48470113851992\n",
            "Epoch #2. Accuracy on batch 1054/3013  on Training is 84.48163507109005\n",
            "Epoch #2. Accuracy on batch 1055/3013  on Training is 84.48745265151516\n",
            "Epoch #2. Accuracy on batch 1056/3013  on Training is 84.49325922421949\n",
            "Epoch #2. Accuracy on batch 1057/3013  on Training is 84.49019376181475\n",
            "Epoch #2. Accuracy on batch 1058/3013  on Training is 84.4900849858357\n",
            "Epoch #2. Accuracy on batch 1059/3013  on Training is 84.49292452830188\n",
            "Batch Id 1060 is having training loss of 0.5558186173439026\n",
            "0.3302065134048462\n",
            "Epoch #2. Accuracy on batch 1060/3013  on Training is 84.4987040527804\n",
            "Epoch #2. Accuracy on batch 1061/3013  on Training is 84.4956450094162\n",
            "Epoch #2. Accuracy on batch 1062/3013  on Training is 84.50141110065852\n",
            "Epoch #2. Accuracy on batch 1063/3013  on Training is 84.50129229323308\n",
            "Epoch #2. Accuracy on batch 1064/3013  on Training is 84.49823943661971\n",
            "Epoch #2. Accuracy on batch 1065/3013  on Training is 84.49226078799249\n",
            "Epoch #2. Accuracy on batch 1066/3013  on Training is 84.50386597938144\n",
            "Epoch #2. Accuracy on batch 1067/3013  on Training is 84.50081928838951\n",
            "Epoch #2. Accuracy on batch 1068/3013  on Training is 84.49193171188026\n",
            "Epoch #2. Accuracy on batch 1069/3013  on Training is 84.4947429906542\n",
            "Epoch #2. Accuracy on batch 1070/3013  on Training is 84.49463118580766\n",
            "Epoch #2. Accuracy on batch 1071/3013  on Training is 84.50034981343283\n",
            "Epoch #2. Accuracy on batch 1072/3013  on Training is 84.50605778191985\n",
            "Epoch #2. Accuracy on batch 1073/3013  on Training is 84.51175512104282\n",
            "Epoch #2. Accuracy on batch 1074/3013  on Training is 84.50872093023256\n",
            "Epoch #2. Accuracy on batch 1075/3013  on Training is 84.5085966542751\n",
            "Epoch #2. Accuracy on batch 1076/3013  on Training is 84.50847260909936\n",
            "Epoch #2. Accuracy on batch 1077/3013  on Training is 84.51994434137292\n",
            "Epoch #2. Accuracy on batch 1078/3013  on Training is 84.52560240963855\n",
            "Epoch #2. Accuracy on batch 1079/3013  on Training is 84.53125\n",
            "Batch Id 1080 is having training loss of 0.555509626865387\n",
            "0.45118895173072815\n",
            "Epoch #2. Accuracy on batch 1080/3013  on Training is 84.52821461609621\n",
            "Epoch #2. Accuracy on batch 1081/3013  on Training is 84.52518484288355\n",
            "Epoch #2. Accuracy on batch 1082/3013  on Training is 84.52793167128347\n",
            "Epoch #2. Accuracy on batch 1083/3013  on Training is 84.52202490774907\n",
            "Epoch #2. Accuracy on batch 1084/3013  on Training is 84.52188940092167\n",
            "Epoch #2. Accuracy on batch 1085/3013  on Training is 84.49873388581952\n",
            "Epoch #2. Accuracy on batch 1086/3013  on Training is 84.49574517019319\n",
            "Epoch #2. Accuracy on batch 1087/3013  on Training is 84.4927619485294\n",
            "Epoch #2. Accuracy on batch 1088/3013  on Training is 84.50126262626263\n",
            "Epoch #2. Accuracy on batch 1089/3013  on Training is 84.49827981651376\n",
            "Epoch #2. Accuracy on batch 1090/3013  on Training is 84.50103116406966\n",
            "Epoch #2. Accuracy on batch 1091/3013  on Training is 84.50091575091575\n",
            "Epoch #2. Accuracy on batch 1092/3013  on Training is 84.49794144556267\n",
            "Epoch #2. Accuracy on batch 1093/3013  on Training is 84.49497257769653\n",
            "Epoch #2. Accuracy on batch 1094/3013  on Training is 84.50342465753425\n",
            "Epoch #2. Accuracy on batch 1095/3013  on Training is 84.4976049270073\n",
            "Epoch #2. Accuracy on batch 1096/3013  on Training is 84.49179580674567\n",
            "Epoch #2. Accuracy on batch 1097/3013  on Training is 84.48315118397086\n",
            "Epoch #2. Accuracy on batch 1098/3013  on Training is 84.48305277525023\n",
            "Epoch #2. Accuracy on batch 1099/3013  on Training is 84.47727272727273\n",
            "Batch Id 1100 is having training loss of 0.5569757223129272\n",
            "0.4842161536216736\n",
            "Epoch #2. Accuracy on batch 1100/3013  on Training is 84.47717983651226\n",
            "Epoch #2. Accuracy on batch 1101/3013  on Training is 84.47425136116152\n",
            "Epoch #2. Accuracy on batch 1102/3013  on Training is 84.4798277425204\n",
            "Epoch #2. Accuracy on batch 1103/3013  on Training is 84.47407155797102\n",
            "Epoch #2. Accuracy on batch 1104/3013  on Training is 84.46266968325791\n",
            "Epoch #2. Accuracy on batch 1105/3013  on Training is 84.4625904159132\n",
            "Epoch #2. Accuracy on batch 1106/3013  on Training is 84.4653342366757\n",
            "Epoch #2. Accuracy on batch 1107/3013  on Training is 84.4596119133574\n",
            "Epoch #2. Accuracy on batch 1108/3013  on Training is 84.46235347159603\n",
            "Epoch #2. Accuracy on batch 1109/3013  on Training is 84.45945945945945\n",
            "Epoch #2. Accuracy on batch 1110/3013  on Training is 84.4650090009001\n",
            "Epoch #2. Accuracy on batch 1111/3013  on Training is 84.46492805755396\n",
            "Epoch #2. Accuracy on batch 1112/3013  on Training is 84.45923180592992\n",
            "Epoch #2. Accuracy on batch 1113/3013  on Training is 84.45915619389586\n",
            "Epoch #2. Accuracy on batch 1114/3013  on Training is 84.45347533632287\n",
            "Epoch #2. Accuracy on batch 1115/3013  on Training is 84.44500448028674\n",
            "Epoch #2. Accuracy on batch 1116/3013  on Training is 84.43654879140556\n",
            "Epoch #2. Accuracy on batch 1117/3013  on Training is 84.44208407871199\n",
            "Epoch #2. Accuracy on batch 1118/3013  on Training is 84.43923145665774\n",
            "Epoch #2. Accuracy on batch 1119/3013  on Training is 84.43080357142857\n",
            "Batch Id 1120 is having training loss of 0.5580075979232788\n",
            "0.27485162019729614\n",
            "Epoch #2. Accuracy on batch 1120/3013  on Training is 84.43632917038359\n",
            "Epoch #2. Accuracy on batch 1121/3013  on Training is 84.43905971479501\n",
            "Epoch #2. Accuracy on batch 1122/3013  on Training is 84.43621994657168\n",
            "Epoch #2. Accuracy on batch 1123/3013  on Training is 84.43616548042705\n",
            "Epoch #2. Accuracy on batch 1124/3013  on Training is 84.44166666666666\n",
            "Epoch #2. Accuracy on batch 1125/3013  on Training is 84.44438277087033\n",
            "Epoch #2. Accuracy on batch 1126/3013  on Training is 84.44154835847382\n",
            "Epoch #2. Accuracy on batch 1127/3013  on Training is 84.43594858156028\n",
            "Epoch #2. Accuracy on batch 1128/3013  on Training is 84.43866253321524\n",
            "Epoch #2. Accuracy on batch 1129/3013  on Training is 84.44137168141593\n",
            "Epoch #2. Accuracy on batch 1130/3013  on Training is 84.44960212201592\n",
            "Epoch #2. Accuracy on batch 1131/3013  on Training is 84.45781802120142\n",
            "Epoch #2. Accuracy on batch 1132/3013  on Training is 84.4632612533098\n",
            "Epoch #2. Accuracy on batch 1133/3013  on Training is 84.46318342151676\n",
            "Epoch #2. Accuracy on batch 1134/3013  on Training is 84.46585903083701\n",
            "Epoch #2. Accuracy on batch 1135/3013  on Training is 84.46302816901408\n",
            "Epoch #2. Accuracy on batch 1136/3013  on Training is 84.46020228671944\n",
            "Epoch #2. Accuracy on batch 1137/3013  on Training is 84.46012741652021\n",
            "Epoch #2. Accuracy on batch 1138/3013  on Training is 84.45456540825285\n",
            "Epoch #2. Accuracy on batch 1139/3013  on Training is 84.4654605263158\n",
            "Batch Id 1140 is having training loss of 0.5574263334274292\n",
            "0.5587297081947327\n",
            "Epoch #2. Accuracy on batch 1140/3013  on Training is 84.46264241893076\n",
            "Epoch #2. Accuracy on batch 1141/3013  on Training is 84.45709281961472\n",
            "Epoch #2. Accuracy on batch 1142/3013  on Training is 84.46248906386701\n",
            "Epoch #2. Accuracy on batch 1143/3013  on Training is 84.4569493006993\n",
            "Epoch #2. Accuracy on batch 1144/3013  on Training is 84.45414847161572\n",
            "Epoch #2. Accuracy on batch 1145/3013  on Training is 84.45407940663176\n",
            "Epoch #2. Accuracy on batch 1146/3013  on Training is 84.45673496076722\n",
            "Epoch #2. Accuracy on batch 1147/3013  on Training is 84.45394163763066\n",
            "Epoch #2. Accuracy on batch 1148/3013  on Training is 84.4538729329852\n",
            "Epoch #2. Accuracy on batch 1149/3013  on Training is 84.46195652173913\n",
            "Epoch #2. Accuracy on batch 1150/3013  on Training is 84.4618809730669\n",
            "Epoch #2. Accuracy on batch 1151/3013  on Training is 84.46180555555556\n",
            "Epoch #2. Accuracy on batch 1152/3013  on Training is 84.46715091066783\n",
            "Epoch #2. Accuracy on batch 1153/3013  on Training is 84.45894714038128\n",
            "Epoch #2. Accuracy on batch 1154/3013  on Training is 84.46428571428571\n",
            "Epoch #2. Accuracy on batch 1155/3013  on Training is 84.46691176470588\n",
            "Epoch #2. Accuracy on batch 1156/3013  on Training is 84.46953327571305\n",
            "Epoch #2. Accuracy on batch 1157/3013  on Training is 84.46135578583765\n",
            "Epoch #2. Accuracy on batch 1158/3013  on Training is 84.4585849870578\n",
            "Epoch #2. Accuracy on batch 1159/3013  on Training is 84.45851293103448\n",
            "Batch Id 1160 is having training loss of 0.5576575398445129\n",
            "0.9321030378341675\n",
            "Epoch #2. Accuracy on batch 1160/3013  on Training is 84.44767441860465\n",
            "Epoch #2. Accuracy on batch 1161/3013  on Training is 84.44223321858864\n",
            "Epoch #2. Accuracy on batch 1162/3013  on Training is 84.4475494411006\n",
            "Epoch #2. Accuracy on batch 1163/3013  on Training is 84.45285652920963\n",
            "Epoch #2. Accuracy on batch 1164/3013  on Training is 84.4554721030043\n",
            "Epoch #2. Accuracy on batch 1165/3013  on Training is 84.45808319039452\n",
            "Epoch #2. Accuracy on batch 1166/3013  on Training is 84.46068980291345\n",
            "Epoch #2. Accuracy on batch 1167/3013  on Training is 84.45258989726027\n",
            "Epoch #2. Accuracy on batch 1168/3013  on Training is 84.44183062446535\n",
            "Epoch #2. Accuracy on batch 1169/3013  on Training is 84.44711538461539\n",
            "Epoch #2. Accuracy on batch 1170/3013  on Training is 84.44972245943637\n",
            "Epoch #2. Accuracy on batch 1171/3013  on Training is 84.44432593856655\n",
            "Epoch #2. Accuracy on batch 1172/3013  on Training is 84.44693094629156\n",
            "Epoch #2. Accuracy on batch 1173/3013  on Training is 84.44953151618398\n",
            "Epoch #2. Accuracy on batch 1174/3013  on Training is 84.44946808510639\n",
            "Epoch #2. Accuracy on batch 1175/3013  on Training is 84.4467474489796\n",
            "Epoch #2. Accuracy on batch 1176/3013  on Training is 84.44403143585387\n",
            "Epoch #2. Accuracy on batch 1177/3013  on Training is 84.4519312393888\n",
            "Epoch #2. Accuracy on batch 1178/3013  on Training is 84.45716709075488\n",
            "Epoch #2. Accuracy on batch 1179/3013  on Training is 84.45444915254237\n",
            "Batch Id 1180 is having training loss of 0.5574082732200623\n",
            "0.8422614336013794\n",
            "Epoch #2. Accuracy on batch 1180/3013  on Training is 84.45173581710415\n",
            "Epoch #2. Accuracy on batch 1181/3013  on Training is 84.44902707275804\n",
            "Epoch #2. Accuracy on batch 1182/3013  on Training is 84.45160608622147\n",
            "Epoch #2. Accuracy on batch 1183/3013  on Training is 84.45418074324324\n",
            "Epoch #2. Accuracy on batch 1184/3013  on Training is 84.45675105485232\n",
            "Epoch #2. Accuracy on batch 1185/3013  on Training is 84.45404721753795\n",
            "Epoch #2. Accuracy on batch 1186/3013  on Training is 84.45134793597305\n",
            "Epoch #2. Accuracy on batch 1187/3013  on Training is 84.4486531986532\n",
            "Epoch #2. Accuracy on batch 1188/3013  on Training is 84.4459629941127\n",
            "Epoch #2. Accuracy on batch 1189/3013  on Training is 84.44852941176471\n",
            "Epoch #2. Accuracy on batch 1190/3013  on Training is 84.45633921074727\n",
            "Epoch #2. Accuracy on batch 1191/3013  on Training is 84.46413590604027\n",
            "Epoch #2. Accuracy on batch 1192/3013  on Training is 84.46144174350377\n",
            "Epoch #2. Accuracy on batch 1193/3013  on Training is 84.46660385259632\n",
            "Epoch #2. Accuracy on batch 1194/3013  on Training is 84.46391213389121\n",
            "Epoch #2. Accuracy on batch 1195/3013  on Training is 84.4690635451505\n",
            "Epoch #2. Accuracy on batch 1196/3013  on Training is 84.47420634920636\n",
            "Epoch #2. Accuracy on batch 1197/3013  on Training is 84.48194908180301\n",
            "Epoch #2. Accuracy on batch 1198/3013  on Training is 84.48446622185155\n",
            "Epoch #2. Accuracy on batch 1199/3013  on Training is 84.484375\n",
            "Batch Id 1200 is having training loss of 0.5564612150192261\n",
            "0.4575549066066742\n",
            "Epoch #2. Accuracy on batch 1200/3013  on Training is 84.48428393005828\n",
            "Epoch #2. Accuracy on batch 1201/3013  on Training is 84.47899334442596\n",
            "Epoch #2. Accuracy on batch 1202/3013  on Training is 84.48669991687449\n",
            "Epoch #2. Accuracy on batch 1203/3013  on Training is 84.48401162790698\n",
            "Epoch #2. Accuracy on batch 1204/3013  on Training is 84.48910788381743\n",
            "Epoch #2. Accuracy on batch 1205/3013  on Training is 84.48642205638474\n",
            "Epoch #2. Accuracy on batch 1206/3013  on Training is 84.48632974316487\n",
            "Epoch #2. Accuracy on batch 1207/3013  on Training is 84.48106374172185\n",
            "Epoch #2. Accuracy on batch 1208/3013  on Training is 84.47839123242349\n",
            "Epoch #2. Accuracy on batch 1209/3013  on Training is 84.47314049586777\n",
            "Epoch #2. Accuracy on batch 1210/3013  on Training is 84.48080099091659\n",
            "Epoch #2. Accuracy on batch 1211/3013  on Training is 84.47555693069307\n",
            "Epoch #2. Accuracy on batch 1212/3013  on Training is 84.48062654575433\n",
            "Epoch #2. Accuracy on batch 1213/3013  on Training is 84.47281713344316\n",
            "Epoch #2. Accuracy on batch 1214/3013  on Training is 84.47788065843622\n",
            "Epoch #2. Accuracy on batch 1215/3013  on Training is 84.47779605263158\n",
            "Epoch #2. Accuracy on batch 1216/3013  on Training is 84.4854149548069\n",
            "Epoch #2. Accuracy on batch 1217/3013  on Training is 84.49302134646962\n",
            "Epoch #2. Accuracy on batch 1218/3013  on Training is 84.50317883511075\n",
            "Epoch #2. Accuracy on batch 1219/3013  on Training is 84.51075819672131\n",
            "Batch Id 1220 is having training loss of 0.5553606152534485\n",
            "0.6564511656761169\n",
            "Epoch #2. Accuracy on batch 1220/3013  on Training is 84.50296887796888\n",
            "Epoch #2. Accuracy on batch 1221/3013  on Training is 84.50542144026187\n",
            "Epoch #2. Accuracy on batch 1222/3013  on Training is 84.51042518397384\n",
            "Epoch #2. Accuracy on batch 1223/3013  on Training is 84.51797385620915\n",
            "Epoch #2. Accuracy on batch 1224/3013  on Training is 84.50510204081633\n",
            "Epoch #2. Accuracy on batch 1225/3013  on Training is 84.5100938009788\n",
            "Epoch #2. Accuracy on batch 1226/3013  on Training is 84.50488997555013\n",
            "Epoch #2. Accuracy on batch 1227/3013  on Training is 84.50732899022802\n",
            "Epoch #2. Accuracy on batch 1228/3013  on Training is 84.50722131814483\n",
            "Epoch #2. Accuracy on batch 1229/3013  on Training is 84.4969512195122\n",
            "Epoch #2. Accuracy on batch 1230/3013  on Training is 84.49939073923639\n",
            "Epoch #2. Accuracy on batch 1231/3013  on Training is 84.4916801948052\n",
            "Epoch #2. Accuracy on batch 1232/3013  on Training is 84.49918896999189\n",
            "Epoch #2. Accuracy on batch 1233/3013  on Training is 84.49402350081037\n",
            "Epoch #2. Accuracy on batch 1234/3013  on Training is 84.50404858299595\n",
            "Epoch #2. Accuracy on batch 1235/3013  on Training is 84.49635922330097\n",
            "Epoch #2. Accuracy on batch 1236/3013  on Training is 84.5038399353274\n",
            "Epoch #2. Accuracy on batch 1237/3013  on Training is 84.50626009693053\n",
            "Epoch #2. Accuracy on batch 1238/3013  on Training is 84.50615415657789\n",
            "Epoch #2. Accuracy on batch 1239/3013  on Training is 84.5085685483871\n",
            "Batch Id 1240 is having training loss of 0.5547019839286804\n",
            "0.3096371293067932\n",
            "Epoch #2. Accuracy on batch 1240/3013  on Training is 84.51601531023368\n",
            "Epoch #2. Accuracy on batch 1241/3013  on Training is 84.51590177133656\n",
            "Epoch #2. Accuracy on batch 1242/3013  on Training is 84.51076025744167\n",
            "Epoch #2. Accuracy on batch 1243/3013  on Training is 84.51818729903538\n",
            "Epoch #2. Accuracy on batch 1244/3013  on Training is 84.51807228915662\n",
            "Epoch #2. Accuracy on batch 1245/3013  on Training is 84.52548154093098\n",
            "Epoch #2. Accuracy on batch 1246/3013  on Training is 84.53287890938252\n",
            "Epoch #2. Accuracy on batch 1247/3013  on Training is 84.54026442307692\n",
            "Epoch #2. Accuracy on batch 1248/3013  on Training is 84.5326261008807\n",
            "Epoch #2. Accuracy on batch 1249/3013  on Training is 84.5375\n",
            "Epoch #2. Accuracy on batch 1250/3013  on Training is 84.53737010391687\n",
            "Epoch #2. Accuracy on batch 1251/3013  on Training is 84.54223242811501\n",
            "Epoch #2. Accuracy on batch 1252/3013  on Training is 84.54209896249003\n",
            "Epoch #2. Accuracy on batch 1253/3013  on Training is 84.53698165869218\n",
            "Epoch #2. Accuracy on batch 1254/3013  on Training is 84.53685258964144\n",
            "Epoch #2. Accuracy on batch 1255/3013  on Training is 84.5342356687898\n",
            "Epoch #2. Accuracy on batch 1256/3013  on Training is 84.53162291169451\n",
            "Epoch #2. Accuracy on batch 1257/3013  on Training is 84.54143481717011\n",
            "Epoch #2. Accuracy on batch 1258/3013  on Training is 84.54130262112788\n",
            "Epoch #2. Accuracy on batch 1259/3013  on Training is 84.5436507936508\n",
            "Batch Id 1260 is having training loss of 0.5535111427307129\n",
            "0.3490663766860962\n",
            "Epoch #2. Accuracy on batch 1260/3013  on Training is 84.54847343378272\n",
            "Epoch #2. Accuracy on batch 1261/3013  on Training is 84.54090729001585\n",
            "Epoch #2. Accuracy on batch 1262/3013  on Training is 84.5457244655582\n",
            "Epoch #2. Accuracy on batch 1263/3013  on Training is 84.54064477848101\n",
            "Epoch #2. Accuracy on batch 1264/3013  on Training is 84.53804347826087\n",
            "Epoch #2. Accuracy on batch 1265/3013  on Training is 84.54038309636651\n",
            "Epoch #2. Accuracy on batch 1266/3013  on Training is 84.54271902131018\n",
            "Epoch #2. Accuracy on batch 1267/3013  on Training is 84.54998028391167\n",
            "Epoch #2. Accuracy on batch 1268/3013  on Training is 84.5596926713948\n",
            "Epoch #2. Accuracy on batch 1269/3013  on Training is 84.55954724409449\n",
            "Epoch #2. Accuracy on batch 1270/3013  on Training is 84.55940204563336\n",
            "Epoch #2. Accuracy on batch 1271/3013  on Training is 84.55434355345912\n",
            "Epoch #2. Accuracy on batch 1272/3013  on Training is 84.55174783974863\n",
            "Epoch #2. Accuracy on batch 1273/3013  on Training is 84.54915620094191\n",
            "Epoch #2. Accuracy on batch 1274/3013  on Training is 84.54411764705883\n",
            "Epoch #2. Accuracy on batch 1275/3013  on Training is 84.54153605015674\n",
            "Epoch #2. Accuracy on batch 1276/3013  on Training is 84.54140563821457\n",
            "Epoch #2. Accuracy on batch 1277/3013  on Training is 84.5314945226917\n",
            "Epoch #2. Accuracy on batch 1278/3013  on Training is 84.53137216575449\n",
            "Epoch #2. Accuracy on batch 1279/3013  on Training is 84.53857421875\n",
            "Batch Id 1280 is having training loss of 0.5542130470275879\n",
            "0.8230451345443726\n",
            "Epoch #2. Accuracy on batch 1280/3013  on Training is 84.52868852459017\n",
            "Epoch #2. Accuracy on batch 1281/3013  on Training is 84.53100624024961\n",
            "Epoch #2. Accuracy on batch 1282/3013  on Training is 84.53575604053\n",
            "Epoch #2. Accuracy on batch 1283/3013  on Training is 84.53076323987538\n",
            "Epoch #2. Accuracy on batch 1284/3013  on Training is 84.52334630350195\n",
            "Epoch #2. Accuracy on batch 1285/3013  on Training is 84.51837091757388\n",
            "Epoch #2. Accuracy on batch 1286/3013  on Training is 84.51825951825951\n",
            "Epoch #2. Accuracy on batch 1287/3013  on Training is 84.5205745341615\n",
            "Epoch #2. Accuracy on batch 1288/3013  on Training is 84.51803723816913\n",
            "Epoch #2. Accuracy on batch 1289/3013  on Training is 84.5203488372093\n",
            "Epoch #2. Accuracy on batch 1290/3013  on Training is 84.51297443841983\n",
            "Epoch #2. Accuracy on batch 1291/3013  on Training is 84.52254256965944\n",
            "Epoch #2. Accuracy on batch 1292/3013  on Training is 84.52484532095902\n",
            "Epoch #2. Accuracy on batch 1293/3013  on Training is 84.5126545595054\n",
            "Epoch #2. Accuracy on batch 1294/3013  on Training is 84.50772200772201\n",
            "Epoch #2. Accuracy on batch 1295/3013  on Training is 84.50038580246914\n",
            "Epoch #2. Accuracy on batch 1296/3013  on Training is 84.50510794140324\n",
            "Epoch #2. Accuracy on batch 1297/3013  on Training is 84.50982280431433\n",
            "Epoch #2. Accuracy on batch 1298/3013  on Training is 84.51453040800615\n",
            "Epoch #2. Accuracy on batch 1299/3013  on Training is 84.51201923076923\n",
            "Batch Id 1300 is having training loss of 0.554652214050293\n",
            "0.47289618849754333\n",
            "Epoch #2. Accuracy on batch 1300/3013  on Training is 84.51431591083782\n",
            "Epoch #2. Accuracy on batch 1301/3013  on Training is 84.51900921658986\n",
            "Epoch #2. Accuracy on batch 1302/3013  on Training is 84.5188986953185\n",
            "Epoch #2. Accuracy on batch 1303/3013  on Training is 84.52118481595092\n",
            "Epoch #2. Accuracy on batch 1304/3013  on Training is 84.51867816091954\n",
            "Epoch #2. Accuracy on batch 1305/3013  on Training is 84.52574655436447\n",
            "Epoch #2. Accuracy on batch 1306/3013  on Training is 84.52563121652639\n",
            "Epoch #2. Accuracy on batch 1307/3013  on Training is 84.52551605504587\n",
            "Epoch #2. Accuracy on batch 1308/3013  on Training is 84.5277883880825\n",
            "Epoch #2. Accuracy on batch 1309/3013  on Training is 84.5300572519084\n",
            "Epoch #2. Accuracy on batch 1310/3013  on Training is 84.53232265446225\n",
            "Epoch #2. Accuracy on batch 1311/3013  on Training is 84.53220274390245\n",
            "Epoch #2. Accuracy on batch 1312/3013  on Training is 84.52970297029702\n",
            "Epoch #2. Accuracy on batch 1313/3013  on Training is 84.52007229832573\n",
            "Epoch #2. Accuracy on batch 1314/3013  on Training is 84.5175855513308\n",
            "Epoch #2. Accuracy on batch 1315/3013  on Training is 84.51985182370821\n",
            "Epoch #2. Accuracy on batch 1316/3013  on Training is 84.52211465451785\n",
            "Epoch #2. Accuracy on batch 1317/3013  on Training is 84.51488998482549\n",
            "Epoch #2. Accuracy on batch 1318/3013  on Training is 84.51004548900683\n",
            "Epoch #2. Accuracy on batch 1319/3013  on Training is 84.50994318181819\n",
            "Batch Id 1320 is having training loss of 0.554104745388031\n",
            "0.3735535740852356\n",
            "Epoch #2. Accuracy on batch 1320/3013  on Training is 84.51220666161998\n",
            "Epoch #2. Accuracy on batch 1321/3013  on Training is 84.5073751891074\n",
            "Epoch #2. Accuracy on batch 1322/3013  on Training is 84.51908541194256\n",
            "Epoch #2. Accuracy on batch 1323/3013  on Training is 84.5166163141994\n",
            "Epoch #2. Accuracy on batch 1324/3013  on Training is 84.51650943396227\n",
            "Epoch #2. Accuracy on batch 1325/3013  on Training is 84.51640271493213\n",
            "Epoch #2. Accuracy on batch 1326/3013  on Training is 84.5139412207988\n",
            "Epoch #2. Accuracy on batch 1327/3013  on Training is 84.51854292168674\n",
            "Epoch #2. Accuracy on batch 1328/3013  on Training is 84.51843491346877\n",
            "Epoch #2. Accuracy on batch 1329/3013  on Training is 84.51127819548873\n",
            "Epoch #2. Accuracy on batch 1330/3013  on Training is 84.51821938392186\n",
            "Epoch #2. Accuracy on batch 1331/3013  on Training is 84.51811186186187\n",
            "Epoch #2. Accuracy on batch 1332/3013  on Training is 84.51331582895725\n",
            "Epoch #2. Accuracy on batch 1333/3013  on Training is 84.51086956521739\n",
            "Epoch #2. Accuracy on batch 1334/3013  on Training is 84.50140449438203\n",
            "Epoch #2. Accuracy on batch 1335/3013  on Training is 84.50130988023952\n",
            "Epoch #2. Accuracy on batch 1336/3013  on Training is 84.50589005235602\n",
            "Epoch #2. Accuracy on batch 1337/3013  on Training is 84.50112107623319\n",
            "Epoch #2. Accuracy on batch 1338/3013  on Training is 84.50336071695295\n",
            "Epoch #2. Accuracy on batch 1339/3013  on Training is 84.50559701492537\n",
            "Batch Id 1340 is having training loss of 0.5538620948791504\n",
            "0.5238975882530212\n",
            "Epoch #2. Accuracy on batch 1340/3013  on Training is 84.51016032811334\n",
            "Epoch #2. Accuracy on batch 1341/3013  on Training is 84.51005961251863\n",
            "Epoch #2. Accuracy on batch 1342/3013  on Training is 84.51228592702904\n",
            "Epoch #2. Accuracy on batch 1343/3013  on Training is 84.50753348214286\n",
            "Epoch #2. Accuracy on batch 1344/3013  on Training is 84.51208178438662\n",
            "Epoch #2. Accuracy on batch 1345/3013  on Training is 84.51430163447252\n",
            "Epoch #2. Accuracy on batch 1346/3013  on Training is 84.51883815887156\n",
            "Epoch #2. Accuracy on batch 1347/3013  on Training is 84.51409495548961\n",
            "Epoch #2. Accuracy on batch 1348/3013  on Training is 84.51862490733878\n",
            "Epoch #2. Accuracy on batch 1349/3013  on Training is 84.51851851851852\n",
            "Epoch #2. Accuracy on batch 1350/3013  on Training is 84.5160991857883\n",
            "Epoch #2. Accuracy on batch 1351/3013  on Training is 84.51599482248521\n",
            "Epoch #2. Accuracy on batch 1352/3013  on Training is 84.51358093126386\n",
            "Epoch #2. Accuracy on batch 1353/3013  on Training is 84.50886262924668\n",
            "Epoch #2. Accuracy on batch 1354/3013  on Training is 84.50876383763837\n",
            "Epoch #2. Accuracy on batch 1355/3013  on Training is 84.50866519174042\n",
            "Epoch #2. Accuracy on batch 1356/3013  on Training is 84.50626381724392\n",
            "Epoch #2. Accuracy on batch 1357/3013  on Training is 84.5015648011782\n",
            "Epoch #2. Accuracy on batch 1358/3013  on Training is 84.49917218543047\n",
            "Epoch #2. Accuracy on batch 1359/3013  on Training is 84.49908088235294\n",
            "Batch Id 1360 is having training loss of 0.5539273023605347\n",
            "0.8549728989601135\n",
            "Epoch #2. Accuracy on batch 1360/3013  on Training is 84.48750918442322\n",
            "Epoch #2. Accuracy on batch 1361/3013  on Training is 84.48283773861968\n",
            "Epoch #2. Accuracy on batch 1362/3013  on Training is 84.48275862068965\n",
            "Epoch #2. Accuracy on batch 1363/3013  on Training is 84.48726173020528\n",
            "Epoch #2. Accuracy on batch 1364/3013  on Training is 84.48489010989012\n",
            "Epoch #2. Accuracy on batch 1365/3013  on Training is 84.4756588579795\n",
            "Epoch #2. Accuracy on batch 1366/3013  on Training is 84.47329919531822\n",
            "Epoch #2. Accuracy on batch 1367/3013  on Training is 84.47779605263158\n",
            "Epoch #2. Accuracy on batch 1368/3013  on Training is 84.47772096420745\n",
            "Epoch #2. Accuracy on batch 1369/3013  on Training is 84.47764598540147\n",
            "Epoch #2. Accuracy on batch 1370/3013  on Training is 84.48440919037199\n",
            "Epoch #2. Accuracy on batch 1371/3013  on Training is 84.48888483965014\n",
            "Epoch #2. Accuracy on batch 1372/3013  on Training is 84.49335396941005\n",
            "Epoch #2. Accuracy on batch 1373/3013  on Training is 84.50009097525474\n",
            "Epoch #2. Accuracy on batch 1374/3013  on Training is 84.50227272727273\n",
            "Epoch #2. Accuracy on batch 1375/3013  on Training is 84.50899345930233\n",
            "Epoch #2. Accuracy on batch 1376/3013  on Training is 84.50889615105301\n",
            "Epoch #2. Accuracy on batch 1377/3013  on Training is 84.504263425254\n",
            "Epoch #2. Accuracy on batch 1378/3013  on Training is 84.50870195794053\n",
            "Epoch #2. Accuracy on batch 1379/3013  on Training is 84.51086956521739\n",
            "Batch Id 1380 is having training loss of 0.5530766844749451\n",
            "0.4416472315788269\n",
            "Epoch #2. Accuracy on batch 1380/3013  on Training is 84.51529688631426\n",
            "Epoch #2. Accuracy on batch 1381/3013  on Training is 84.5151953690304\n",
            "Epoch #2. Accuracy on batch 1382/3013  on Training is 84.5105748373102\n",
            "Epoch #2. Accuracy on batch 1383/3013  on Training is 84.50596098265896\n",
            "Epoch #2. Accuracy on batch 1384/3013  on Training is 84.50586642599278\n",
            "Epoch #2. Accuracy on batch 1385/3013  on Training is 84.50351731601732\n",
            "Epoch #2. Accuracy on batch 1386/3013  on Training is 84.50793078586878\n",
            "Epoch #2. Accuracy on batch 1387/3013  on Training is 84.51684077809799\n",
            "Epoch #2. Accuracy on batch 1388/3013  on Training is 84.51673866090712\n",
            "Epoch #2. Accuracy on batch 1389/3013  on Training is 84.52338129496403\n",
            "Epoch #2. Accuracy on batch 1390/3013  on Training is 84.51878145219267\n",
            "Epoch #2. Accuracy on batch 1391/3013  on Training is 84.52316810344827\n",
            "Epoch #2. Accuracy on batch 1392/3013  on Training is 84.51857501794687\n",
            "Epoch #2. Accuracy on batch 1393/3013  on Training is 84.51847202295552\n",
            "Epoch #2. Accuracy on batch 1394/3013  on Training is 84.51612903225806\n",
            "Epoch #2. Accuracy on batch 1395/3013  on Training is 84.52050501432664\n",
            "Epoch #2. Accuracy on batch 1396/3013  on Training is 84.52040085898354\n",
            "Epoch #2. Accuracy on batch 1397/3013  on Training is 84.5158261802575\n",
            "Epoch #2. Accuracy on batch 1398/3013  on Training is 84.50902430307363\n",
            "Epoch #2. Accuracy on batch 1399/3013  on Training is 84.50892857142857\n",
            "Batch Id 1400 is having training loss of 0.5535022616386414\n",
            "0.41338181495666504\n",
            "Epoch #2. Accuracy on batch 1400/3013  on Training is 84.50883297644539\n",
            "Epoch #2. Accuracy on batch 1401/3013  on Training is 84.50427960057061\n",
            "Epoch #2. Accuracy on batch 1402/3013  on Training is 84.5041874554526\n",
            "Epoch #2. Accuracy on batch 1403/3013  on Training is 84.50854700854701\n",
            "Epoch #2. Accuracy on batch 1404/3013  on Training is 84.51067615658363\n",
            "Epoch #2. Accuracy on batch 1405/3013  on Training is 84.51057965860598\n",
            "Epoch #2. Accuracy on batch 1406/3013  on Training is 84.50604122245913\n",
            "Epoch #2. Accuracy on batch 1407/3013  on Training is 84.5059481534091\n",
            "Epoch #2. Accuracy on batch 1408/3013  on Training is 84.49698367636621\n",
            "Epoch #2. Accuracy on batch 1409/3013  on Training is 84.49024822695036\n",
            "Epoch #2. Accuracy on batch 1410/3013  on Training is 84.48795180722891\n",
            "Epoch #2. Accuracy on batch 1411/3013  on Training is 84.49229815864022\n",
            "Epoch #2. Accuracy on batch 1412/3013  on Training is 84.49442675159236\n",
            "Epoch #2. Accuracy on batch 1413/3013  on Training is 84.49434229137199\n",
            "Epoch #2. Accuracy on batch 1414/3013  on Training is 84.49646643109541\n",
            "Epoch #2. Accuracy on batch 1415/3013  on Training is 84.50520833333333\n",
            "Epoch #2. Accuracy on batch 1416/3013  on Training is 84.50732180663373\n",
            "Epoch #2. Accuracy on batch 1417/3013  on Training is 84.50943229901269\n",
            "Epoch #2. Accuracy on batch 1418/3013  on Training is 84.50493305144468\n",
            "Epoch #2. Accuracy on batch 1419/3013  on Training is 84.50484154929578\n",
            "Batch Id 1420 is having training loss of 0.5534780621528625\n",
            "0.6153032779693604\n",
            "Epoch #2. Accuracy on batch 1420/3013  on Training is 84.50255102040816\n",
            "Epoch #2. Accuracy on batch 1421/3013  on Training is 84.49367088607595\n",
            "Epoch #2. Accuracy on batch 1422/3013  on Training is 84.49358749121573\n",
            "Epoch #2. Accuracy on batch 1423/3013  on Training is 84.49350421348315\n",
            "Epoch #2. Accuracy on batch 1424/3013  on Training is 84.49561403508773\n",
            "Epoch #2. Accuracy on batch 1425/3013  on Training is 84.50210378681626\n",
            "Epoch #2. Accuracy on batch 1426/3013  on Training is 84.50639453398739\n",
            "Epoch #2. Accuracy on batch 1427/3013  on Training is 84.50849089635854\n",
            "Epoch #2. Accuracy on batch 1428/3013  on Training is 84.50839748075578\n",
            "Epoch #2. Accuracy on batch 1429/3013  on Training is 84.51267482517483\n",
            "Epoch #2. Accuracy on batch 1430/3013  on Training is 84.50821104122991\n",
            "Epoch #2. Accuracy on batch 1431/3013  on Training is 84.50375349162012\n",
            "Epoch #2. Accuracy on batch 1432/3013  on Training is 84.50584438241451\n",
            "Epoch #2. Accuracy on batch 1433/3013  on Training is 84.51011157601116\n",
            "Epoch #2. Accuracy on batch 1434/3013  on Training is 84.51219512195122\n",
            "Epoch #2. Accuracy on batch 1435/3013  on Training is 84.50774721448468\n",
            "Epoch #2. Accuracy on batch 1436/3013  on Training is 84.50330549756437\n",
            "Epoch #2. Accuracy on batch 1437/3013  on Training is 84.50538942976355\n",
            "Epoch #2. Accuracy on batch 1438/3013  on Training is 84.50529881862404\n",
            "Epoch #2. Accuracy on batch 1439/3013  on Training is 84.50303819444444\n",
            "Batch Id 1440 is having training loss of 0.5535316467285156\n",
            "0.7073639631271362\n",
            "Epoch #2. Accuracy on batch 1440/3013  on Training is 84.49861207494796\n",
            "Epoch #2. Accuracy on batch 1441/3013  on Training is 84.49635922330097\n",
            "Epoch #2. Accuracy on batch 1442/3013  on Training is 84.48977823977825\n",
            "Epoch #2. Accuracy on batch 1443/3013  on Training is 84.49402700831025\n",
            "Epoch #2. Accuracy on batch 1444/3013  on Training is 84.49610726643598\n",
            "Epoch #2. Accuracy on batch 1445/3013  on Training is 84.50250691562933\n",
            "Epoch #2. Accuracy on batch 1446/3013  on Training is 84.50457843814789\n",
            "Epoch #2. Accuracy on batch 1447/3013  on Training is 84.50233080110497\n",
            "Epoch #2. Accuracy on batch 1448/3013  on Training is 84.49792960662526\n",
            "Epoch #2. Accuracy on batch 1449/3013  on Training is 84.5\n",
            "Epoch #2. Accuracy on batch 1450/3013  on Training is 84.50206753962784\n",
            "Epoch #2. Accuracy on batch 1451/3013  on Training is 84.50413223140495\n",
            "Epoch #2. Accuracy on batch 1452/3013  on Training is 84.49544046799724\n",
            "Epoch #2. Accuracy on batch 1453/3013  on Training is 84.4910591471802\n",
            "Epoch #2. Accuracy on batch 1454/3013  on Training is 84.49312714776632\n",
            "Epoch #2. Accuracy on batch 1455/3013  on Training is 84.49089972527473\n",
            "Epoch #2. Accuracy on batch 1456/3013  on Training is 84.49296499656829\n",
            "Epoch #2. Accuracy on batch 1457/3013  on Training is 84.4928840877915\n",
            "Epoch #2. Accuracy on batch 1458/3013  on Training is 84.49066141192597\n",
            "Epoch #2. Accuracy on batch 1459/3013  on Training is 84.48630136986301\n",
            "Batch Id 1460 is having training loss of 0.5536922216415405\n",
            "0.42501339316368103\n",
            "Epoch #2. Accuracy on batch 1460/3013  on Training is 84.4883641341547\n",
            "Epoch #2. Accuracy on batch 1461/3013  on Training is 84.48614911080712\n",
            "Epoch #2. Accuracy on batch 1462/3013  on Training is 84.4818010936432\n",
            "Epoch #2. Accuracy on batch 1463/3013  on Training is 84.48386270491804\n",
            "Epoch #2. Accuracy on batch 1464/3013  on Training is 84.48378839590444\n",
            "Epoch #2. Accuracy on batch 1465/3013  on Training is 84.48158253751706\n",
            "Epoch #2. Accuracy on batch 1466/3013  on Training is 84.48364008179959\n",
            "Epoch #2. Accuracy on batch 1467/3013  on Training is 84.48782356948229\n",
            "Epoch #2. Accuracy on batch 1468/3013  on Training is 84.4898740639891\n",
            "Epoch #2. Accuracy on batch 1469/3013  on Training is 84.49404761904762\n",
            "Epoch #2. Accuracy on batch 1470/3013  on Training is 84.48971787899389\n",
            "Epoch #2. Accuracy on batch 1471/3013  on Training is 84.48539402173913\n",
            "Epoch #2. Accuracy on batch 1472/3013  on Training is 84.48531907671419\n",
            "Epoch #2. Accuracy on batch 1473/3013  on Training is 84.47888398914519\n",
            "Epoch #2. Accuracy on batch 1474/3013  on Training is 84.47669491525424\n",
            "Epoch #2. Accuracy on batch 1475/3013  on Training is 84.4702743902439\n",
            "Epoch #2. Accuracy on batch 1476/3013  on Training is 84.47444143534192\n",
            "Epoch #2. Accuracy on batch 1477/3013  on Training is 84.4722598105548\n",
            "Epoch #2. Accuracy on batch 1478/3013  on Training is 84.4721940500338\n",
            "Epoch #2. Accuracy on batch 1479/3013  on Training is 84.47212837837837\n",
            "Batch Id 1480 is having training loss of 0.5545244812965393\n",
            "0.7326145172119141\n",
            "Epoch #2. Accuracy on batch 1480/3013  on Training is 84.46995273463875\n",
            "Epoch #2. Accuracy on batch 1481/3013  on Training is 84.46988866396761\n",
            "Epoch #2. Accuracy on batch 1482/3013  on Training is 84.46561024949426\n",
            "Epoch #2. Accuracy on batch 1483/3013  on Training is 84.46554919137466\n",
            "Epoch #2. Accuracy on batch 1484/3013  on Training is 84.47180134680134\n",
            "Epoch #2. Accuracy on batch 1485/3013  on Training is 84.47173620457605\n",
            "Epoch #2. Accuracy on batch 1486/3013  on Training is 84.47167114996637\n",
            "Epoch #2. Accuracy on batch 1487/3013  on Training is 84.4695060483871\n",
            "Epoch #2. Accuracy on batch 1488/3013  on Training is 84.47364002686366\n",
            "Epoch #2. Accuracy on batch 1489/3013  on Training is 84.4756711409396\n",
            "Epoch #2. Accuracy on batch 1490/3013  on Training is 84.48189134808852\n",
            "Epoch #2. Accuracy on batch 1491/3013  on Training is 84.47972520107238\n",
            "Epoch #2. Accuracy on batch 1492/3013  on Training is 84.47965505693234\n",
            "Epoch #2. Accuracy on batch 1493/3013  on Training is 84.48376840696118\n",
            "Epoch #2. Accuracy on batch 1494/3013  on Training is 84.47951505016722\n",
            "Epoch #2. Accuracy on batch 1495/3013  on Training is 84.47944518716578\n",
            "Epoch #2. Accuracy on batch 1496/3013  on Training is 84.48563794255178\n",
            "Epoch #2. Accuracy on batch 1497/3013  on Training is 84.48556408544727\n",
            "Epoch #2. Accuracy on batch 1498/3013  on Training is 84.48549032688459\n",
            "Epoch #2. Accuracy on batch 1499/3013  on Training is 84.48125\n",
            "Batch Id 1500 is having training loss of 0.5540768504142761\n",
            "0.45870059728622437\n",
            "Epoch #2. Accuracy on batch 1500/3013  on Training is 84.48534310459694\n",
            "Epoch #2. Accuracy on batch 1501/3013  on Training is 84.47694740346205\n",
            "Epoch #2. Accuracy on batch 1502/3013  on Training is 84.47687957418496\n",
            "Epoch #2. Accuracy on batch 1503/3013  on Training is 84.47681183510639\n",
            "Epoch #2. Accuracy on batch 1504/3013  on Training is 84.47466777408638\n",
            "Epoch #2. Accuracy on batch 1505/3013  on Training is 84.4683764940239\n",
            "Epoch #2. Accuracy on batch 1506/3013  on Training is 84.4662408759124\n",
            "Epoch #2. Accuracy on batch 1507/3013  on Training is 84.46618037135279\n",
            "Epoch #2. Accuracy on batch 1508/3013  on Training is 84.46404903909874\n",
            "Epoch #2. Accuracy on batch 1509/3013  on Training is 84.46605960264901\n",
            "Epoch #2. Accuracy on batch 1510/3013  on Training is 84.4680675049636\n",
            "Epoch #2. Accuracy on batch 1511/3013  on Training is 84.46800595238095\n",
            "Epoch #2. Accuracy on batch 1512/3013  on Training is 84.47000991407799\n",
            "Epoch #2. Accuracy on batch 1513/3013  on Training is 84.47820343461031\n",
            "Epoch #2. Accuracy on batch 1514/3013  on Training is 84.47813531353135\n",
            "Epoch #2. Accuracy on batch 1515/3013  on Training is 84.47394459102902\n",
            "Epoch #2. Accuracy on batch 1516/3013  on Training is 84.47181938035597\n",
            "Epoch #2. Accuracy on batch 1517/3013  on Training is 84.47381422924902\n",
            "Epoch #2. Accuracy on batch 1518/3013  on Training is 84.46963462804477\n",
            "Epoch #2. Accuracy on batch 1519/3013  on Training is 84.47574013157895\n",
            "Batch Id 1520 is having training loss of 0.5544052124023438\n",
            "0.3537905514240265\n",
            "Epoch #2. Accuracy on batch 1520/3013  on Training is 84.47772846811309\n",
            "Epoch #2. Accuracy on batch 1521/3013  on Training is 84.47355453350855\n",
            "Epoch #2. Accuracy on batch 1522/3013  on Training is 84.46733420879842\n",
            "Epoch #2. Accuracy on batch 1523/3013  on Training is 84.46522309711285\n",
            "Epoch #2. Accuracy on batch 1524/3013  on Training is 84.4672131147541\n",
            "Epoch #2. Accuracy on batch 1525/3013  on Training is 84.47124836173002\n",
            "Epoch #2. Accuracy on batch 1526/3013  on Training is 84.46913883431566\n",
            "Epoch #2. Accuracy on batch 1527/3013  on Training is 84.46089659685863\n",
            "Epoch #2. Accuracy on batch 1528/3013  on Training is 84.46288423806409\n",
            "Epoch #2. Accuracy on batch 1529/3013  on Training is 84.45874183006536\n",
            "Epoch #2. Accuracy on batch 1530/3013  on Training is 84.45664598301764\n",
            "Epoch #2. Accuracy on batch 1531/3013  on Training is 84.45455287206266\n",
            "Epoch #2. Accuracy on batch 1532/3013  on Training is 84.4565394651011\n",
            "Epoch #2. Accuracy on batch 1533/3013  on Training is 84.45648631029987\n",
            "Epoch #2. Accuracy on batch 1534/3013  on Training is 84.4584690553746\n",
            "Epoch #2. Accuracy on batch 1535/3013  on Training is 84.45638020833333\n",
            "Epoch #2. Accuracy on batch 1536/3013  on Training is 84.46242680546518\n",
            "Epoch #2. Accuracy on batch 1537/3013  on Training is 84.46440182054616\n",
            "Epoch #2. Accuracy on batch 1538/3013  on Training is 84.46231319038337\n",
            "Epoch #2. Accuracy on batch 1539/3013  on Training is 84.46022727272727\n",
            "Batch Id 1540 is having training loss of 0.5549443364143372\n",
            "0.7787488698959351\n",
            "Epoch #2. Accuracy on batch 1540/3013  on Training is 84.45814406229721\n",
            "Epoch #2. Accuracy on batch 1541/3013  on Training is 84.45809014267185\n",
            "Epoch #2. Accuracy on batch 1542/3013  on Training is 84.46411211924821\n",
            "Epoch #2. Accuracy on batch 1543/3013  on Training is 84.46203044041451\n",
            "Epoch #2. Accuracy on batch 1544/3013  on Training is 84.457928802589\n",
            "Epoch #2. Accuracy on batch 1545/3013  on Training is 84.45787516170763\n",
            "Epoch #2. Accuracy on batch 1546/3013  on Training is 84.44166127989658\n",
            "Epoch #2. Accuracy on batch 1547/3013  on Training is 84.43556201550388\n",
            "Epoch #2. Accuracy on batch 1548/3013  on Training is 84.43148805681085\n",
            "Epoch #2. Accuracy on batch 1549/3013  on Training is 84.42943548387096\n",
            "Epoch #2. Accuracy on batch 1550/3013  on Training is 84.42940038684719\n",
            "Epoch #2. Accuracy on batch 1551/3013  on Training is 84.42936533505154\n",
            "Epoch #2. Accuracy on batch 1552/3013  on Training is 84.43134256278171\n",
            "Epoch #2. Accuracy on batch 1553/3013  on Training is 84.43532818532819\n",
            "Epoch #2. Accuracy on batch 1554/3013  on Training is 84.43729903536978\n",
            "Epoch #2. Accuracy on batch 1555/3013  on Training is 84.44529241645245\n",
            "Epoch #2. Accuracy on batch 1556/3013  on Training is 84.44524727039177\n",
            "Epoch #2. Accuracy on batch 1557/3013  on Training is 84.43717907573813\n",
            "Epoch #2. Accuracy on batch 1558/3013  on Training is 84.44114817190507\n",
            "Epoch #2. Accuracy on batch 1559/3013  on Training is 84.44110576923077\n",
            "Batch Id 1560 is having training loss of 0.5557499527931213\n",
            "0.4701800048351288\n",
            "Epoch #2. Accuracy on batch 1560/3013  on Training is 84.44306534272901\n",
            "Epoch #2. Accuracy on batch 1561/3013  on Training is 84.44302176696543\n",
            "Epoch #2. Accuracy on batch 1562/3013  on Training is 84.44297824696098\n",
            "Epoch #2. Accuracy on batch 1563/3013  on Training is 84.4429347826087\n",
            "Epoch #2. Accuracy on batch 1564/3013  on Training is 84.44289137380191\n",
            "Epoch #2. Accuracy on batch 1565/3013  on Training is 84.43885696040869\n",
            "Epoch #2. Accuracy on batch 1566/3013  on Training is 84.43482769623485\n",
            "Epoch #2. Accuracy on batch 1567/3013  on Training is 84.43080357142857\n",
            "Epoch #2. Accuracy on batch 1568/3013  on Training is 84.43475143403441\n",
            "Epoch #2. Accuracy on batch 1569/3013  on Training is 84.42874203821655\n",
            "Epoch #2. Accuracy on batch 1570/3013  on Training is 84.42671865054106\n",
            "Epoch #2. Accuracy on batch 1571/3013  on Training is 84.43066157760815\n",
            "Epoch #2. Accuracy on batch 1572/3013  on Training is 84.43459949141767\n",
            "Epoch #2. Accuracy on batch 1573/3013  on Training is 84.43456162642948\n",
            "Epoch #2. Accuracy on batch 1574/3013  on Training is 84.43452380952381\n",
            "Epoch #2. Accuracy on batch 1575/3013  on Training is 84.42655456852792\n",
            "Epoch #2. Accuracy on batch 1576/3013  on Training is 84.42652187698161\n",
            "Epoch #2. Accuracy on batch 1577/3013  on Training is 84.42846958174906\n",
            "Epoch #2. Accuracy on batch 1578/3013  on Training is 84.4343730208993\n",
            "Epoch #2. Accuracy on batch 1579/3013  on Training is 84.43631329113924\n",
            "Batch Id 1580 is having training loss of 0.5558081865310669\n",
            "0.6850965619087219\n",
            "Epoch #2. Accuracy on batch 1580/3013  on Training is 84.43627450980392\n",
            "Epoch #2. Accuracy on batch 1581/3013  on Training is 84.43623577749683\n",
            "Epoch #2. Accuracy on batch 1582/3013  on Training is 84.43817119393556\n",
            "Epoch #2. Accuracy on batch 1583/3013  on Training is 84.44010416666667\n",
            "Epoch #2. Accuracy on batch 1584/3013  on Training is 84.44597791798107\n",
            "Epoch #2. Accuracy on batch 1585/3013  on Training is 84.44593316519546\n",
            "Epoch #2. Accuracy on batch 1586/3013  on Training is 84.44391934467549\n",
            "Epoch #2. Accuracy on batch 1587/3013  on Training is 84.4419080604534\n",
            "Epoch #2. Accuracy on batch 1588/3013  on Training is 84.43989930774072\n",
            "Epoch #2. Accuracy on batch 1589/3013  on Training is 84.43985849056604\n",
            "Epoch #2. Accuracy on batch 1590/3013  on Training is 84.44571024512885\n",
            "Epoch #2. Accuracy on batch 1591/3013  on Training is 84.44370288944724\n",
            "Epoch #2. Accuracy on batch 1592/3013  on Training is 84.43777463904583\n",
            "Epoch #2. Accuracy on batch 1593/3013  on Training is 84.44165621079047\n",
            "Epoch #2. Accuracy on batch 1594/3013  on Training is 84.44161442006269\n",
            "Epoch #2. Accuracy on batch 1595/3013  on Training is 84.43961466165413\n",
            "Epoch #2. Accuracy on batch 1596/3013  on Training is 84.43957420162805\n",
            "Epoch #2. Accuracy on batch 1597/3013  on Training is 84.43562265331664\n",
            "Epoch #2. Accuracy on batch 1598/3013  on Training is 84.43753908692933\n",
            "Epoch #2. Accuracy on batch 1599/3013  on Training is 84.431640625\n",
            "Batch Id 1600 is having training loss of 0.5556327700614929\n",
            "0.4333827793598175\n",
            "Epoch #2. Accuracy on batch 1600/3013  on Training is 84.43550905683948\n",
            "Epoch #2. Accuracy on batch 1601/3013  on Training is 84.43742197253434\n",
            "Epoch #2. Accuracy on batch 1602/3013  on Training is 84.44128197130381\n",
            "Epoch #2. Accuracy on batch 1603/3013  on Training is 84.44318890274315\n",
            "Epoch #2. Accuracy on batch 1604/3013  on Training is 84.44119937694704\n",
            "Epoch #2. Accuracy on batch 1605/3013  on Training is 84.44699564134496\n",
            "Epoch #2. Accuracy on batch 1606/3013  on Training is 84.44695084007468\n",
            "Epoch #2. Accuracy on batch 1607/3013  on Training is 84.44496268656717\n",
            "Epoch #2. Accuracy on batch 1608/3013  on Training is 84.44880360472344\n",
            "Epoch #2. Accuracy on batch 1609/3013  on Training is 84.44099378881988\n",
            "Epoch #2. Accuracy on batch 1610/3013  on Training is 84.44095282433271\n",
            "Epoch #2. Accuracy on batch 1611/3013  on Training is 84.43509615384616\n",
            "Epoch #2. Accuracy on batch 1612/3013  on Training is 84.43312151270923\n",
            "Epoch #2. Accuracy on batch 1613/3013  on Training is 84.42921313506815\n",
            "Epoch #2. Accuracy on batch 1614/3013  on Training is 84.4311145510836\n",
            "Epoch #2. Accuracy on batch 1615/3013  on Training is 84.43301361386139\n",
            "Epoch #2. Accuracy on batch 1616/3013  on Training is 84.43297773654916\n",
            "Epoch #2. Accuracy on batch 1617/3013  on Training is 84.43294190358468\n",
            "Epoch #2. Accuracy on batch 1618/3013  on Training is 84.43290611488572\n",
            "Epoch #2. Accuracy on batch 1619/3013  on Training is 84.42901234567901\n",
            "Batch Id 1620 is having training loss of 0.5553781390190125\n",
            "0.534670889377594\n",
            "Epoch #2. Accuracy on batch 1620/3013  on Training is 84.42897902529303\n",
            "Epoch #2. Accuracy on batch 1621/3013  on Training is 84.4289457459926\n",
            "Epoch #2. Accuracy on batch 1622/3013  on Training is 84.42891250770178\n",
            "Epoch #2. Accuracy on batch 1623/3013  on Training is 84.42118226600985\n",
            "Epoch #2. Accuracy on batch 1624/3013  on Training is 84.41346153846153\n",
            "Epoch #2. Accuracy on batch 1625/3013  on Training is 84.41728167281673\n",
            "Epoch #2. Accuracy on batch 1626/3013  on Training is 84.4172556853104\n",
            "Epoch #2. Accuracy on batch 1627/3013  on Training is 84.4210687960688\n",
            "Epoch #2. Accuracy on batch 1628/3013  on Training is 84.42104051565377\n",
            "Epoch #2. Accuracy on batch 1629/3013  on Training is 84.42292944785277\n",
            "Epoch #2. Accuracy on batch 1630/3013  on Training is 84.42290006131208\n",
            "Epoch #2. Accuracy on batch 1631/3013  on Training is 84.42478553921569\n",
            "Epoch #2. Accuracy on batch 1632/3013  on Training is 84.41901408450704\n",
            "Epoch #2. Accuracy on batch 1633/3013  on Training is 84.41898714810281\n",
            "Epoch #2. Accuracy on batch 1634/3013  on Training is 84.4151376146789\n",
            "Epoch #2. Accuracy on batch 1635/3013  on Training is 84.41320293398533\n",
            "Epoch #2. Accuracy on batch 1636/3013  on Training is 84.40745265729994\n",
            "Epoch #2. Accuracy on batch 1637/3013  on Training is 84.41124847374847\n",
            "Epoch #2. Accuracy on batch 1638/3013  on Training is 84.40741305674192\n",
            "Epoch #2. Accuracy on batch 1639/3013  on Training is 84.40358231707317\n",
            "Batch Id 1640 is having training loss of 0.5558480620384216\n",
            "0.6373599767684937\n",
            "Epoch #2. Accuracy on batch 1640/3013  on Training is 84.39785191956125\n",
            "Epoch #2. Accuracy on batch 1641/3013  on Training is 84.39593483556638\n",
            "Epoch #2. Accuracy on batch 1642/3013  on Training is 84.39972611077297\n",
            "Epoch #2. Accuracy on batch 1643/3013  on Training is 84.3997110705596\n",
            "Epoch #2. Accuracy on batch 1644/3013  on Training is 84.40349544072949\n",
            "Epoch #2. Accuracy on batch 1645/3013  on Training is 84.40537667071689\n",
            "Epoch #2. Accuracy on batch 1646/3013  on Training is 84.40346083788707\n",
            "Epoch #2. Accuracy on batch 1647/3013  on Training is 84.40154733009709\n",
            "Epoch #2. Accuracy on batch 1648/3013  on Training is 84.4034263189812\n",
            "Epoch #2. Accuracy on batch 1649/3013  on Training is 84.39962121212122\n",
            "Epoch #2. Accuracy on batch 1650/3013  on Training is 84.39014233797698\n",
            "Epoch #2. Accuracy on batch 1651/3013  on Training is 84.39202481840194\n",
            "Epoch #2. Accuracy on batch 1652/3013  on Training is 84.39390502117362\n",
            "Epoch #2. Accuracy on batch 1653/3013  on Training is 84.3976723095526\n",
            "Epoch #2. Accuracy on batch 1654/3013  on Training is 84.39577039274924\n",
            "Epoch #2. Accuracy on batch 1655/3013  on Training is 84.39953200483092\n",
            "Epoch #2. Accuracy on batch 1656/3013  on Training is 84.40140313820157\n",
            "Epoch #2. Accuracy on batch 1657/3013  on Training is 84.38819360675512\n",
            "Epoch #2. Accuracy on batch 1658/3013  on Training is 84.38818565400844\n",
            "Epoch #2. Accuracy on batch 1659/3013  on Training is 84.38817771084338\n",
            "Batch Id 1660 is having training loss of 0.5565251111984253\n",
            "0.9499021768569946\n",
            "Epoch #2. Accuracy on batch 1660/3013  on Training is 84.38440698374473\n",
            "Epoch #2. Accuracy on batch 1661/3013  on Training is 84.38440132370638\n",
            "Epoch #2. Accuracy on batch 1662/3013  on Training is 84.39003307276008\n",
            "Epoch #2. Accuracy on batch 1663/3013  on Training is 84.38626802884616\n",
            "Epoch #2. Accuracy on batch 1664/3013  on Training is 84.38626126126127\n",
            "Epoch #2. Accuracy on batch 1665/3013  on Training is 84.39000600240097\n",
            "Epoch #2. Accuracy on batch 1666/3013  on Training is 84.38999700059988\n",
            "Epoch #2. Accuracy on batch 1667/3013  on Training is 84.38998800959233\n",
            "Epoch #2. Accuracy on batch 1668/3013  on Training is 84.39185140802876\n",
            "Epoch #2. Accuracy on batch 1669/3013  on Training is 84.39558383233533\n",
            "Epoch #2. Accuracy on batch 1670/3013  on Training is 84.39744165170556\n",
            "Epoch #2. Accuracy on batch 1671/3013  on Training is 84.40116626794259\n",
            "Epoch #2. Accuracy on batch 1672/3013  on Training is 84.40488643156007\n",
            "Epoch #2. Accuracy on batch 1673/3013  on Training is 84.41233572281959\n",
            "Epoch #2. Accuracy on batch 1674/3013  on Training is 84.4160447761194\n",
            "Epoch #2. Accuracy on batch 1675/3013  on Training is 84.40856205250597\n",
            "Epoch #2. Accuracy on batch 1676/3013  on Training is 84.40854203935599\n",
            "Epoch #2. Accuracy on batch 1677/3013  on Training is 84.41038438617402\n",
            "Epoch #2. Accuracy on batch 1678/3013  on Training is 84.41222453841573\n",
            "Epoch #2. Accuracy on batch 1679/3013  on Training is 84.4140625\n",
            "Batch Id 1680 is having training loss of 0.5556039214134216\n",
            "0.37692171335220337\n",
            "Epoch #2. Accuracy on batch 1680/3013  on Training is 84.41775728732897\n",
            "Epoch #2. Accuracy on batch 1681/3013  on Training is 84.41958977407847\n",
            "Epoch #2. Accuracy on batch 1682/3013  on Training is 84.41770647653\n",
            "Epoch #2. Accuracy on batch 1683/3013  on Training is 84.41768111638955\n",
            "Epoch #2. Accuracy on batch 1684/3013  on Training is 84.42136498516321\n",
            "Epoch #2. Accuracy on batch 1685/3013  on Training is 84.421337485172\n",
            "Epoch #2. Accuracy on batch 1686/3013  on Training is 84.41390041493776\n",
            "Epoch #2. Accuracy on batch 1687/3013  on Training is 84.41572867298578\n",
            "Epoch #2. Accuracy on batch 1688/3013  on Training is 84.41385435168739\n",
            "Epoch #2. Accuracy on batch 1689/3013  on Training is 84.41752958579882\n",
            "Epoch #2. Accuracy on batch 1690/3013  on Training is 84.40641632170313\n",
            "Epoch #2. Accuracy on batch 1691/3013  on Training is 84.39531619385343\n",
            "Epoch #2. Accuracy on batch 1692/3013  on Training is 84.39715002953338\n",
            "Epoch #2. Accuracy on batch 1693/3013  on Training is 84.39529220779221\n",
            "Epoch #2. Accuracy on batch 1694/3013  on Training is 84.3952802359882\n",
            "Epoch #2. Accuracy on batch 1695/3013  on Training is 84.39895341981132\n",
            "Epoch #2. Accuracy on batch 1696/3013  on Training is 84.39709781968179\n",
            "Epoch #2. Accuracy on batch 1697/3013  on Training is 84.3970848056537\n",
            "Epoch #2. Accuracy on batch 1698/3013  on Training is 84.40075044143614\n",
            "Epoch #2. Accuracy on batch 1699/3013  on Training is 84.40441176470588\n",
            "Batch Id 1700 is having training loss of 0.5557898879051208\n",
            "0.37157145142555237\n",
            "Epoch #2. Accuracy on batch 1700/3013  on Training is 84.40806878306879\n",
            "Epoch #2. Accuracy on batch 1701/3013  on Training is 84.40621327849588\n",
            "Epoch #2. Accuracy on batch 1702/3013  on Training is 84.4098649442161\n",
            "Epoch #2. Accuracy on batch 1703/3013  on Training is 84.40801056338029\n",
            "Epoch #2. Accuracy on batch 1704/3013  on Training is 84.40432551319648\n",
            "Epoch #2. Accuracy on batch 1705/3013  on Training is 84.40247655334115\n",
            "Epoch #2. Accuracy on batch 1706/3013  on Training is 84.39879906268307\n",
            "Epoch #2. Accuracy on batch 1707/3013  on Training is 84.4024443793911\n",
            "Epoch #2. Accuracy on batch 1708/3013  on Training is 84.400599765945\n",
            "Epoch #2. Accuracy on batch 1709/3013  on Training is 84.40058479532163\n",
            "Epoch #2. Accuracy on batch 1710/3013  on Training is 84.40422267679719\n",
            "Epoch #2. Accuracy on batch 1711/3013  on Training is 84.40420560747664\n",
            "Epoch #2. Accuracy on batch 1712/3013  on Training is 84.3950671336836\n",
            "Epoch #2. Accuracy on batch 1713/3013  on Training is 84.39687864644107\n",
            "Epoch #2. Accuracy on batch 1714/3013  on Training is 84.39686588921283\n",
            "Epoch #2. Accuracy on batch 1715/3013  on Training is 84.39867424242425\n",
            "Epoch #2. Accuracy on batch 1716/3013  on Training is 84.39866045428072\n",
            "Epoch #2. Accuracy on batch 1717/3013  on Training is 84.39137077997671\n",
            "Epoch #2. Accuracy on batch 1718/3013  on Training is 84.38408958696917\n",
            "Epoch #2. Accuracy on batch 1719/3013  on Training is 84.38771802325581\n",
            "Batch Id 1720 is having training loss of 0.5569221377372742\n",
            "0.8660058975219727\n",
            "Epoch #2. Accuracy on batch 1720/3013  on Training is 84.38407902382336\n",
            "Epoch #2. Accuracy on batch 1721/3013  on Training is 84.38588850174216\n",
            "Epoch #2. Accuracy on batch 1722/3013  on Training is 84.38769587928033\n",
            "Epoch #2. Accuracy on batch 1723/3013  on Training is 84.38587587006961\n",
            "Epoch #2. Accuracy on batch 1724/3013  on Training is 84.38949275362319\n",
            "Epoch #2. Accuracy on batch 1725/3013  on Training is 84.3931054461182\n",
            "Epoch #2. Accuracy on batch 1726/3013  on Training is 84.39128546612623\n",
            "Epoch #2. Accuracy on batch 1727/3013  on Training is 84.39127604166667\n",
            "Epoch #2. Accuracy on batch 1728/3013  on Training is 84.39488143435511\n",
            "Epoch #2. Accuracy on batch 1729/3013  on Training is 84.39667630057804\n",
            "Epoch #2. Accuracy on batch 1730/3013  on Training is 84.39666377816292\n",
            "Epoch #2. Accuracy on batch 1731/3013  on Training is 84.39845554272517\n",
            "Epoch #2. Accuracy on batch 1732/3013  on Training is 84.40385170225044\n",
            "Epoch #2. Accuracy on batch 1733/3013  on Training is 84.40203287197232\n",
            "Epoch #2. Accuracy on batch 1734/3013  on Training is 84.39841498559078\n",
            "Epoch #2. Accuracy on batch 1735/3013  on Training is 84.4020017281106\n",
            "Epoch #2. Accuracy on batch 1736/3013  on Training is 84.40198618307427\n",
            "Epoch #2. Accuracy on batch 1737/3013  on Training is 84.40376869965478\n",
            "Epoch #2. Accuracy on batch 1738/3013  on Training is 84.401955146636\n",
            "Epoch #2. Accuracy on batch 1739/3013  on Training is 84.40014367816092\n",
            "Batch Id 1740 is having training loss of 0.5565032958984375\n",
            "0.8395498394966125\n",
            "Epoch #2. Accuracy on batch 1740/3013  on Training is 84.3965393452039\n",
            "Epoch #2. Accuracy on batch 1741/3013  on Training is 84.40011481056257\n",
            "Epoch #2. Accuracy on batch 1742/3013  on Training is 84.40010040160642\n",
            "Epoch #2. Accuracy on batch 1743/3013  on Training is 84.39829415137615\n",
            "Epoch #2. Accuracy on batch 1744/3013  on Training is 84.40186246418338\n",
            "Epoch #2. Accuracy on batch 1745/3013  on Training is 84.40542668957617\n",
            "Epoch #2. Accuracy on batch 1746/3013  on Training is 84.41077561534058\n",
            "Epoch #2. Accuracy on batch 1747/3013  on Training is 84.40896739130434\n",
            "Epoch #2. Accuracy on batch 1748/3013  on Training is 84.40358776443682\n",
            "Epoch #2. Accuracy on batch 1749/3013  on Training is 84.40357142857142\n",
            "Epoch #2. Accuracy on batch 1750/3013  on Training is 84.40712450028555\n",
            "Epoch #2. Accuracy on batch 1751/3013  on Training is 84.40710616438356\n",
            "Epoch #2. Accuracy on batch 1752/3013  on Training is 84.40708784940102\n",
            "Epoch #2. Accuracy on batch 1753/3013  on Training is 84.39994298745724\n",
            "Epoch #2. Accuracy on batch 1754/3013  on Training is 84.39992877492878\n",
            "Epoch #2. Accuracy on batch 1755/3013  on Training is 84.39635535307517\n",
            "Epoch #2. Accuracy on batch 1756/3013  on Training is 84.40167899829254\n",
            "Epoch #2. Accuracy on batch 1757/3013  on Training is 84.40166382252559\n",
            "Epoch #2. Accuracy on batch 1758/3013  on Training is 84.40342524161456\n",
            "Epoch #2. Accuracy on batch 1759/3013  on Training is 84.39808238636364\n",
            "Batch Id 1760 is having training loss of 0.5567270517349243\n",
            "0.7073690891265869\n",
            "Epoch #2. Accuracy on batch 1760/3013  on Training is 84.39629471890972\n",
            "Epoch #2. Accuracy on batch 1761/3013  on Training is 84.39628263337117\n",
            "Epoch #2. Accuracy on batch 1762/3013  on Training is 84.39627056154282\n",
            "Epoch #2. Accuracy on batch 1763/3013  on Training is 84.39803004535148\n",
            "Epoch #2. Accuracy on batch 1764/3013  on Training is 84.39801699716713\n",
            "Epoch #2. Accuracy on batch 1765/3013  on Training is 84.39269535673839\n",
            "Epoch #2. Accuracy on batch 1766/3013  on Training is 84.3909168081494\n",
            "Epoch #2. Accuracy on batch 1767/3013  on Training is 84.38914027149322\n",
            "Epoch #2. Accuracy on batch 1768/3013  on Training is 84.39266534765405\n",
            "Epoch #2. Accuracy on batch 1769/3013  on Training is 84.3944209039548\n",
            "Epoch #2. Accuracy on batch 1770/3013  on Training is 84.39617447769622\n",
            "Epoch #2. Accuracy on batch 1771/3013  on Training is 84.39968961625283\n",
            "Epoch #2. Accuracy on batch 1772/3013  on Training is 84.39615059221659\n",
            "Epoch #2. Accuracy on batch 1773/3013  on Training is 84.39613866967305\n",
            "Epoch #2. Accuracy on batch 1774/3013  on Training is 84.39612676056338\n",
            "Epoch #2. Accuracy on batch 1775/3013  on Training is 84.40139358108108\n",
            "Epoch #2. Accuracy on batch 1776/3013  on Training is 84.40313731007316\n",
            "Epoch #2. Accuracy on batch 1777/3013  on Training is 84.4066366704162\n",
            "Epoch #2. Accuracy on batch 1778/3013  on Training is 84.41364530635188\n",
            "Epoch #2. Accuracy on batch 1779/3013  on Training is 84.41889044943821\n",
            "Batch Id 1780 is having training loss of 0.5557220578193665\n",
            "0.45685064792633057\n",
            "Epoch #2. Accuracy on batch 1780/3013  on Training is 84.41886580572712\n",
            "Epoch #2. Accuracy on batch 1781/3013  on Training is 84.41708754208754\n",
            "Epoch #2. Accuracy on batch 1782/3013  on Training is 84.41531127313516\n",
            "Epoch #2. Accuracy on batch 1783/3013  on Training is 84.4170403587444\n",
            "Epoch #2. Accuracy on batch 1784/3013  on Training is 84.41701680672269\n",
            "Epoch #2. Accuracy on batch 1785/3013  on Training is 84.41874300111982\n",
            "Epoch #2. Accuracy on batch 1786/3013  on Training is 84.42221600447678\n",
            "Epoch #2. Accuracy on batch 1787/3013  on Training is 84.41694630872483\n",
            "Epoch #2. Accuracy on batch 1788/3013  on Training is 84.4221632196758\n",
            "Epoch #2. Accuracy on batch 1789/3013  on Training is 84.42562849162012\n",
            "Epoch #2. Accuracy on batch 1790/3013  on Training is 84.42734505862647\n",
            "Epoch #2. Accuracy on batch 1791/3013  on Training is 84.42731584821429\n",
            "Epoch #2. Accuracy on batch 1792/3013  on Training is 84.42728667038483\n",
            "Epoch #2. Accuracy on batch 1793/3013  on Training is 84.43074136008919\n",
            "Epoch #2. Accuracy on batch 1794/3013  on Training is 84.43071030640668\n",
            "Epoch #2. Accuracy on batch 1795/3013  on Training is 84.4324192650334\n",
            "Epoch #2. Accuracy on batch 1796/3013  on Training is 84.43760434056762\n",
            "Epoch #2. Accuracy on batch 1797/3013  on Training is 84.42714126807564\n",
            "Epoch #2. Accuracy on batch 1798/3013  on Training is 84.42884936075598\n",
            "Epoch #2. Accuracy on batch 1799/3013  on Training is 84.42881944444444\n",
            "Batch Id 1800 is having training loss of 0.5554397106170654\n",
            "0.7664951086044312\n",
            "Epoch #2. Accuracy on batch 1800/3013  on Training is 84.42011382565242\n",
            "Epoch #2. Accuracy on batch 1801/3013  on Training is 84.42008879023308\n",
            "Epoch #2. Accuracy on batch 1802/3013  on Training is 84.42179700499167\n",
            "Epoch #2. Accuracy on batch 1803/3013  on Training is 84.41657427937916\n",
            "Epoch #2. Accuracy on batch 1804/3013  on Training is 84.42001385041551\n",
            "Epoch #2. Accuracy on batch 1805/3013  on Training is 84.421719269103\n",
            "Epoch #2. Accuracy on batch 1806/3013  on Training is 84.42169341449917\n",
            "Epoch #2. Accuracy on batch 1807/3013  on Training is 84.41648230088495\n",
            "Epoch #2. Accuracy on batch 1808/3013  on Training is 84.41645936981757\n",
            "Epoch #2. Accuracy on batch 1809/3013  on Training is 84.41816298342542\n",
            "Epoch #2. Accuracy on batch 1810/3013  on Training is 84.41813914964108\n",
            "Epoch #2. Accuracy on batch 1811/3013  on Training is 84.41811534216336\n",
            "Epoch #2. Accuracy on batch 1812/3013  on Training is 84.41809156094871\n",
            "Epoch #2. Accuracy on batch 1813/3013  on Training is 84.4180678059537\n",
            "Epoch #2. Accuracy on batch 1814/3013  on Training is 84.41632231404958\n",
            "Epoch #2. Accuracy on batch 1815/3013  on Training is 84.4145787444934\n",
            "Epoch #2. Accuracy on batch 1816/3013  on Training is 84.40767749036874\n",
            "Epoch #2. Accuracy on batch 1817/3013  on Training is 84.40937843784378\n",
            "Epoch #2. Accuracy on batch 1818/3013  on Training is 84.4110775151182\n",
            "Epoch #2. Accuracy on batch 1819/3013  on Training is 84.40418956043956\n",
            "Batch Id 1820 is having training loss of 0.555814802646637\n",
            "0.5866557955741882\n",
            "Epoch #2. Accuracy on batch 1820/3013  on Training is 84.40588962108731\n",
            "Epoch #2. Accuracy on batch 1821/3013  on Training is 84.40587266739847\n",
            "Epoch #2. Accuracy on batch 1822/3013  on Training is 84.40585573230938\n",
            "Epoch #2. Accuracy on batch 1823/3013  on Training is 84.40069901315789\n",
            "Epoch #2. Accuracy on batch 1824/3013  on Training is 84.4041095890411\n",
            "Epoch #2. Accuracy on batch 1825/3013  on Training is 84.4006708652793\n",
            "Epoch #2. Accuracy on batch 1826/3013  on Training is 84.39894636015326\n",
            "Epoch #2. Accuracy on batch 1827/3013  on Training is 84.39893326039387\n",
            "Epoch #2. Accuracy on batch 1828/3013  on Training is 84.39721159103335\n",
            "Epoch #2. Accuracy on batch 1829/3013  on Training is 84.39890710382514\n",
            "Epoch #2. Accuracy on batch 1830/3013  on Training is 84.4057209175314\n",
            "Epoch #2. Accuracy on batch 1831/3013  on Training is 84.39546943231441\n",
            "Epoch #2. Accuracy on batch 1832/3013  on Training is 84.39375340971085\n",
            "Epoch #2. Accuracy on batch 1833/3013  on Training is 84.39203925845148\n",
            "Epoch #2. Accuracy on batch 1834/3013  on Training is 84.39543596730245\n",
            "Epoch #2. Accuracy on batch 1835/3013  on Training is 84.39882897603486\n",
            "Epoch #2. Accuracy on batch 1836/3013  on Training is 84.40221829069135\n",
            "Epoch #2. Accuracy on batch 1837/3013  on Training is 84.40050326441785\n",
            "Epoch #2. Accuracy on batch 1838/3013  on Training is 84.40388798259924\n",
            "Epoch #2. Accuracy on batch 1839/3013  on Training is 84.40217391304348\n",
            "Batch Id 1840 is having training loss of 0.5558678507804871\n",
            "0.506036639213562\n",
            "Epoch #2. Accuracy on batch 1840/3013  on Training is 84.40046170559478\n",
            "Epoch #2. Accuracy on batch 1841/3013  on Training is 84.4021444082519\n",
            "Epoch #2. Accuracy on batch 1842/3013  on Training is 84.40382528486164\n",
            "Epoch #2. Accuracy on batch 1843/3013  on Training is 84.40042028199566\n",
            "Epoch #2. Accuracy on batch 1844/3013  on Training is 84.40210027100271\n",
            "Epoch #2. Accuracy on batch 1845/3013  on Training is 84.40716413867823\n",
            "Epoch #2. Accuracy on batch 1846/3013  on Training is 84.40883865728208\n",
            "Epoch #2. Accuracy on batch 1847/3013  on Training is 84.40543831168831\n",
            "Epoch #2. Accuracy on batch 1848/3013  on Training is 84.41218226068145\n",
            "Epoch #2. Accuracy on batch 1849/3013  on Training is 84.41554054054055\n",
            "Epoch #2. Accuracy on batch 1850/3013  on Training is 84.42058346839546\n",
            "Epoch #2. Accuracy on batch 1851/3013  on Training is 84.42055885529157\n",
            "Epoch #2. Accuracy on batch 1852/3013  on Training is 84.42390717754992\n",
            "Epoch #2. Accuracy on batch 1853/3013  on Training is 84.42219525350593\n",
            "Epoch #2. Accuracy on batch 1854/3013  on Training is 84.40869272237197\n",
            "Epoch #2. Accuracy on batch 1855/3013  on Training is 84.40362338362068\n",
            "Epoch #2. Accuracy on batch 1856/3013  on Training is 84.40529079159936\n",
            "Epoch #2. Accuracy on batch 1857/3013  on Training is 84.40527448869753\n",
            "Epoch #2. Accuracy on batch 1858/3013  on Training is 84.40525820333512\n",
            "Epoch #2. Accuracy on batch 1859/3013  on Training is 84.40860215053763\n",
            "Batch Id 1860 is having training loss of 0.5561019778251648\n",
            "0.4902457594871521\n",
            "Epoch #2. Accuracy on batch 1860/3013  on Training is 84.41026329930145\n",
            "Epoch #2. Accuracy on batch 1861/3013  on Training is 84.40688775510205\n",
            "Epoch #2. Accuracy on batch 1862/3013  on Training is 84.40183843263553\n",
            "Epoch #2. Accuracy on batch 1863/3013  on Training is 84.4051770386266\n",
            "Epoch #2. Accuracy on batch 1864/3013  on Training is 84.406836461126\n",
            "Epoch #2. Accuracy on batch 1865/3013  on Training is 84.40681939978563\n",
            "Epoch #2. Accuracy on batch 1866/3013  on Training is 84.40847616497054\n",
            "Epoch #2. Accuracy on batch 1867/3013  on Training is 84.41013115631692\n",
            "Epoch #2. Accuracy on batch 1868/3013  on Training is 84.4050963081862\n",
            "Epoch #2. Accuracy on batch 1869/3013  on Training is 84.40006684491979\n",
            "Epoch #2. Accuracy on batch 1870/3013  on Training is 84.39838321753074\n",
            "Epoch #2. Accuracy on batch 1871/3013  on Training is 84.4017094017094\n",
            "Epoch #2. Accuracy on batch 1872/3013  on Training is 84.39668980245595\n",
            "Epoch #2. Accuracy on batch 1873/3013  on Training is 84.39167556029882\n",
            "Epoch #2. Accuracy on batch 1874/3013  on Training is 84.39\n",
            "Epoch #2. Accuracy on batch 1875/3013  on Training is 84.3849946695096\n",
            "Epoch #2. Accuracy on batch 1876/3013  on Training is 84.38165956313266\n",
            "Epoch #2. Accuracy on batch 1877/3013  on Training is 84.37999201277955\n",
            "Epoch #2. Accuracy on batch 1878/3013  on Training is 84.3783262373603\n",
            "Epoch #2. Accuracy on batch 1879/3013  on Training is 84.37998670212765\n",
            "Batch Id 1880 is having training loss of 0.5565575361251831\n",
            "0.873043417930603\n",
            "Epoch #2. Accuracy on batch 1880/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 1881/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 1882/3013  on Training is 84.3766595857674\n",
            "Epoch #2. Accuracy on batch 1883/3013  on Training is 84.37334129511677\n",
            "Epoch #2. Accuracy on batch 1884/3013  on Training is 84.37831564986737\n",
            "Epoch #2. Accuracy on batch 1885/3013  on Training is 84.37997083775186\n",
            "Epoch #2. Accuracy on batch 1886/3013  on Training is 84.37831213566508\n",
            "Epoch #2. Accuracy on batch 1887/3013  on Training is 84.37168961864407\n",
            "Epoch #2. Accuracy on batch 1888/3013  on Training is 84.36507411328745\n",
            "Epoch #2. Accuracy on batch 1889/3013  on Training is 84.37003968253968\n",
            "Epoch #2. Accuracy on batch 1890/3013  on Training is 84.36838974087784\n",
            "Epoch #2. Accuracy on batch 1891/3013  on Training is 84.36013477801268\n",
            "Epoch #2. Accuracy on batch 1892/3013  on Training is 84.36014263074485\n",
            "Epoch #2. Accuracy on batch 1893/3013  on Training is 84.36180042238648\n",
            "Epoch #2. Accuracy on batch 1894/3013  on Training is 84.36015831134564\n",
            "Epoch #2. Accuracy on batch 1895/3013  on Training is 84.36181434599156\n",
            "Epoch #2. Accuracy on batch 1896/3013  on Training is 84.36346863468634\n",
            "Epoch #2. Accuracy on batch 1897/3013  on Training is 84.35688883034773\n",
            "Epoch #2. Accuracy on batch 1898/3013  on Training is 84.35525276461296\n",
            "Epoch #2. Accuracy on batch 1899/3013  on Training is 84.35197368421052\n",
            "Batch Id 1900 is having training loss of 0.5570846199989319\n",
            "0.6156889796257019\n",
            "Epoch #2. Accuracy on batch 1900/3013  on Training is 84.35362966859547\n",
            "Epoch #2. Accuracy on batch 1901/3013  on Training is 84.35528391167192\n",
            "Epoch #2. Accuracy on batch 1902/3013  on Training is 84.35036784025223\n",
            "Epoch #2. Accuracy on batch 1903/3013  on Training is 84.35202205882354\n",
            "Epoch #2. Accuracy on batch 1904/3013  on Training is 84.35039370078741\n",
            "Epoch #2. Accuracy on batch 1905/3013  on Training is 84.34548793284365\n",
            "Epoch #2. Accuracy on batch 1906/3013  on Training is 84.34878080755112\n",
            "Epoch #2. Accuracy on batch 1907/3013  on Training is 84.34551886792453\n",
            "Epoch #2. Accuracy on batch 1908/3013  on Training is 84.34062336301729\n",
            "Epoch #2. Accuracy on batch 1909/3013  on Training is 84.33736910994764\n",
            "Epoch #2. Accuracy on batch 1910/3013  on Training is 84.33411826268969\n",
            "Epoch #2. Accuracy on batch 1911/3013  on Training is 84.33413964435147\n",
            "Epoch #2. Accuracy on batch 1912/3013  on Training is 84.33252744380555\n",
            "Epoch #2. Accuracy on batch 1913/3013  on Training is 84.33581504702194\n",
            "Epoch #2. Accuracy on batch 1914/3013  on Training is 84.33583550913838\n",
            "Epoch #2. Accuracy on batch 1915/3013  on Training is 84.33911795407099\n",
            "Epoch #2. Accuracy on batch 1916/3013  on Training is 84.34076682316119\n",
            "Epoch #2. Accuracy on batch 1917/3013  on Training is 84.344043274244\n",
            "Epoch #2. Accuracy on batch 1918/3013  on Training is 84.34568785825951\n",
            "Epoch #2. Accuracy on batch 1919/3013  on Training is 84.3505859375\n",
            "Batch Id 1920 is having training loss of 0.5571296811103821\n",
            "0.4129122495651245\n",
            "Epoch #2. Accuracy on batch 1920/3013  on Training is 84.35222540343571\n",
            "Epoch #2. Accuracy on batch 1921/3013  on Training is 84.3522372528616\n",
            "Epoch #2. Accuracy on batch 1922/3013  on Training is 84.35224908996359\n",
            "Epoch #2. Accuracy on batch 1923/3013  on Training is 84.35713357588358\n",
            "Epoch #2. Accuracy on batch 1924/3013  on Training is 84.3603896103896\n",
            "Epoch #2. Accuracy on batch 1925/3013  on Training is 84.36364226375909\n",
            "Epoch #2. Accuracy on batch 1926/3013  on Training is 84.36364815775818\n",
            "Epoch #2. Accuracy on batch 1927/3013  on Training is 84.36527489626556\n",
            "Epoch #2. Accuracy on batch 1928/3013  on Training is 84.36365992742354\n",
            "Epoch #2. Accuracy on batch 1929/3013  on Training is 84.3636658031088\n",
            "Epoch #2. Accuracy on batch 1930/3013  on Training is 84.37014500258933\n",
            "Epoch #2. Accuracy on batch 1931/3013  on Training is 84.36853002070393\n",
            "Epoch #2. Accuracy on batch 1932/3013  on Training is 84.37176668391102\n",
            "Epoch #2. Accuracy on batch 1933/3013  on Training is 84.3733841778697\n",
            "Epoch #2. Accuracy on batch 1934/3013  on Training is 84.3733850129199\n",
            "Epoch #2. Accuracy on batch 1935/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 1936/3013  on Training is 84.37338668043365\n",
            "Epoch #2. Accuracy on batch 1937/3013  on Training is 84.3766124871001\n",
            "Epoch #2. Accuracy on batch 1938/3013  on Training is 84.37983496647756\n",
            "Epoch #2. Accuracy on batch 1939/3013  on Training is 84.38144329896907\n",
            "Batch Id 1940 is having training loss of 0.556298017501831\n",
            "0.34368571639060974\n",
            "Epoch #2. Accuracy on batch 1940/3013  on Training is 84.38626996393612\n",
            "Epoch #2. Accuracy on batch 1941/3013  on Training is 84.38304582904223\n",
            "Epoch #2. Accuracy on batch 1942/3013  on Training is 84.37821667524447\n",
            "Epoch #2. Accuracy on batch 1943/3013  on Training is 84.38143004115226\n",
            "Epoch #2. Accuracy on batch 1944/3013  on Training is 84.38464010282776\n",
            "Epoch #2. Accuracy on batch 1945/3013  on Training is 84.38784686536485\n",
            "Epoch #2. Accuracy on batch 1946/3013  on Training is 84.39105033384695\n",
            "Epoch #2. Accuracy on batch 1947/3013  on Training is 84.3958547227926\n",
            "Epoch #2. Accuracy on batch 1948/3013  on Training is 84.39905079527963\n",
            "Epoch #2. Accuracy on batch 1949/3013  on Training is 84.3974358974359\n",
            "Epoch #2. Accuracy on batch 1950/3013  on Training is 84.3990261404408\n",
            "Epoch #2. Accuracy on batch 1951/3013  on Training is 84.40061475409836\n",
            "Epoch #2. Accuracy on batch 1952/3013  on Training is 84.40060163850487\n",
            "Epoch #2. Accuracy on batch 1953/3013  on Training is 84.40058853633572\n",
            "Epoch #2. Accuracy on batch 1954/3013  on Training is 84.40377237851662\n",
            "Epoch #2. Accuracy on batch 1955/3013  on Training is 84.39896472392638\n",
            "Epoch #2. Accuracy on batch 1956/3013  on Training is 84.38937148696985\n",
            "Epoch #2. Accuracy on batch 1957/3013  on Training is 84.38936414708887\n",
            "Epoch #2. Accuracy on batch 1958/3013  on Training is 84.39254721796836\n",
            "Epoch #2. Accuracy on batch 1959/3013  on Training is 84.39253826530613\n",
            "Batch Id 1960 is having training loss of 0.5558274984359741\n",
            "0.8105340600013733\n",
            "Epoch #2. Accuracy on batch 1960/3013  on Training is 84.39093574706783\n",
            "Epoch #2. Accuracy on batch 1961/3013  on Training is 84.38774209989806\n",
            "Epoch #2. Accuracy on batch 1962/3013  on Training is 84.39091951095263\n",
            "Epoch #2. Accuracy on batch 1963/3013  on Training is 84.39091140529531\n",
            "Epoch #2. Accuracy on batch 1964/3013  on Training is 84.38931297709924\n",
            "Epoch #2. Accuracy on batch 1965/3013  on Training is 84.39407426246186\n",
            "Epoch #2. Accuracy on batch 1966/3013  on Training is 84.39088713777326\n",
            "Epoch #2. Accuracy on batch 1967/3013  on Training is 84.38611534552845\n",
            "Epoch #2. Accuracy on batch 1968/3013  on Training is 84.38928390045709\n",
            "Epoch #2. Accuracy on batch 1969/3013  on Training is 84.3892766497462\n",
            "Epoch #2. Accuracy on batch 1970/3013  on Training is 84.3876839167935\n",
            "Epoch #2. Accuracy on batch 1971/3013  on Training is 84.39243154158216\n",
            "Epoch #2. Accuracy on batch 1972/3013  on Training is 84.3908388241257\n",
            "Epoch #2. Accuracy on batch 1973/3013  on Training is 84.38924772036474\n",
            "Epoch #2. Accuracy on batch 1974/3013  on Training is 84.3876582278481\n",
            "Epoch #2. Accuracy on batch 1975/3013  on Training is 84.39081477732793\n",
            "Epoch #2. Accuracy on batch 1976/3013  on Training is 84.39080677794638\n",
            "Epoch #2. Accuracy on batch 1977/3013  on Training is 84.38605915065723\n",
            "Epoch #2. Accuracy on batch 1978/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 1979/3013  on Training is 84.37657828282828\n",
            "Batch Id 1980 is having training loss of 0.5564929246902466\n",
            "0.3162985146045685\n",
            "Epoch #2. Accuracy on batch 1980/3013  on Training is 84.37973245835437\n",
            "Epoch #2. Accuracy on batch 1981/3013  on Training is 84.38288345105954\n",
            "Epoch #2. Accuracy on batch 1982/3013  on Training is 84.38287947554211\n",
            "Epoch #2. Accuracy on batch 1983/3013  on Training is 84.37972530241936\n",
            "Epoch #2. Accuracy on batch 1984/3013  on Training is 84.38129722921914\n",
            "Epoch #2. Accuracy on batch 1985/3013  on Training is 84.38129405840886\n",
            "Epoch #2. Accuracy on batch 1986/3013  on Training is 84.38286361348767\n",
            "Epoch #2. Accuracy on batch 1987/3013  on Training is 84.37814386317908\n",
            "Epoch #2. Accuracy on batch 1988/3013  on Training is 84.38442684766214\n",
            "Epoch #2. Accuracy on batch 1989/3013  on Training is 84.38128140703517\n",
            "Epoch #2. Accuracy on batch 1990/3013  on Training is 84.38284781516826\n",
            "Epoch #2. Accuracy on batch 1991/3013  on Training is 84.3797063253012\n",
            "Epoch #2. Accuracy on batch 1992/3013  on Training is 84.38127195183141\n",
            "Epoch #2. Accuracy on batch 1993/3013  on Training is 84.38440320962889\n",
            "Epoch #2. Accuracy on batch 1994/3013  on Training is 84.3828320802005\n",
            "Epoch #2. Accuracy on batch 1995/3013  on Training is 84.38595941883767\n",
            "Epoch #2. Accuracy on batch 1996/3013  on Training is 84.38751877816725\n",
            "Epoch #2. Accuracy on batch 1997/3013  on Training is 84.39064064064064\n",
            "Epoch #2. Accuracy on batch 1998/3013  on Training is 84.38750625312656\n",
            "Epoch #2. Accuracy on batch 1999/3013  on Training is 84.390625\n",
            "Batch Id 2000 is having training loss of 0.556290328502655\n",
            "0.7665855884552002\n",
            "Epoch #2. Accuracy on batch 2000/3013  on Training is 84.38749375312344\n",
            "Epoch #2. Accuracy on batch 2001/3013  on Training is 84.38748751248751\n",
            "Epoch #2. Accuracy on batch 2002/3013  on Training is 84.38904143784323\n",
            "Epoch #2. Accuracy on batch 2003/3013  on Training is 84.38591566866268\n",
            "Epoch #2. Accuracy on batch 2004/3013  on Training is 84.38279301745636\n",
            "Epoch #2. Accuracy on batch 2005/3013  on Training is 84.3827891326022\n",
            "Epoch #2. Accuracy on batch 2006/3013  on Training is 84.38122820129547\n",
            "Epoch #2. Accuracy on batch 2007/3013  on Training is 84.38278137450199\n",
            "Epoch #2. Accuracy on batch 2008/3013  on Training is 84.37966650074664\n",
            "Epoch #2. Accuracy on batch 2009/3013  on Training is 84.37655472636816\n",
            "Epoch #2. Accuracy on batch 2010/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 2011/3013  on Training is 84.37810636182903\n",
            "Epoch #2. Accuracy on batch 2012/3013  on Training is 84.3734475906607\n",
            "Epoch #2. Accuracy on batch 2013/3013  on Training is 84.37189672293943\n",
            "Epoch #2. Accuracy on batch 2014/3013  on Training is 84.37344913151365\n",
            "Epoch #2. Accuracy on batch 2015/3013  on Training is 84.3718998015873\n",
            "Epoch #2. Accuracy on batch 2016/3013  on Training is 84.37190133862171\n",
            "Epoch #2. Accuracy on batch 2017/3013  on Training is 84.37345143706641\n",
            "Epoch #2. Accuracy on batch 2018/3013  on Training is 84.37345220406142\n",
            "Epoch #2. Accuracy on batch 2019/3013  on Training is 84.37190594059406\n",
            "Batch Id 2020 is having training loss of 0.556972861289978\n",
            "0.8428544998168945\n",
            "Epoch #2. Accuracy on batch 2020/3013  on Training is 84.36417615042059\n",
            "Epoch #2. Accuracy on batch 2021/3013  on Training is 84.36572700296736\n",
            "Epoch #2. Accuracy on batch 2022/3013  on Training is 84.37036579337618\n",
            "Epoch #2. Accuracy on batch 2023/3013  on Training is 84.37036808300395\n",
            "Epoch #2. Accuracy on batch 2024/3013  on Training is 84.36728395061728\n",
            "Epoch #2. Accuracy on batch 2025/3013  on Training is 84.36883020730504\n",
            "Epoch #2. Accuracy on batch 2026/3013  on Training is 84.36574987666502\n",
            "Epoch #2. Accuracy on batch 2027/3013  on Training is 84.35959072978304\n",
            "Epoch #2. Accuracy on batch 2028/3013  on Training is 84.36113849186792\n",
            "Epoch #2. Accuracy on batch 2029/3013  on Training is 84.36576354679804\n",
            "Epoch #2. Accuracy on batch 2030/3013  on Training is 84.36884539635648\n",
            "Epoch #2. Accuracy on batch 2031/3013  on Training is 84.36577263779527\n",
            "Epoch #2. Accuracy on batch 2032/3013  on Training is 84.36731431382194\n",
            "Epoch #2. Accuracy on batch 2033/3013  on Training is 84.36578171091445\n",
            "Epoch #2. Accuracy on batch 2034/3013  on Training is 84.36425061425061\n",
            "Epoch #2. Accuracy on batch 2035/3013  on Training is 84.36732563850687\n",
            "Epoch #2. Accuracy on batch 2036/3013  on Training is 84.36886352479137\n",
            "Epoch #2. Accuracy on batch 2037/3013  on Training is 84.37193326790971\n",
            "Epoch #2. Accuracy on batch 2038/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 2039/3013  on Training is 84.375\n",
            "Batch Id 2040 is having training loss of 0.5570185780525208\n",
            "0.7708826661109924\n",
            "Epoch #2. Accuracy on batch 2040/3013  on Training is 84.36887555120039\n",
            "Epoch #2. Accuracy on batch 2041/3013  on Training is 84.37040891283056\n",
            "Epoch #2. Accuracy on batch 2042/3013  on Training is 84.37347038668625\n",
            "Epoch #2. Accuracy on batch 2043/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 2044/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 2045/3013  on Training is 84.37805474095796\n",
            "Epoch #2. Accuracy on batch 2046/3013  on Training is 84.38110649731314\n",
            "Epoch #2. Accuracy on batch 2047/3013  on Training is 84.3780517578125\n",
            "Epoch #2. Accuracy on batch 2048/3013  on Training is 84.38262567105906\n",
            "Epoch #2. Accuracy on batch 2049/3013  on Training is 84.38719512195122\n",
            "Epoch #2. Accuracy on batch 2050/3013  on Training is 84.3871891760117\n",
            "Epoch #2. Accuracy on batch 2051/3013  on Training is 84.38413742690058\n",
            "Epoch #2. Accuracy on batch 2052/3013  on Training is 84.38869946419874\n",
            "Epoch #2. Accuracy on batch 2053/3013  on Training is 84.3932570593963\n",
            "Epoch #2. Accuracy on batch 2054/3013  on Training is 84.39020681265207\n",
            "Epoch #2. Accuracy on batch 2055/3013  on Training is 84.3932392996109\n",
            "Epoch #2. Accuracy on batch 2056/3013  on Training is 84.3886728245017\n",
            "Epoch #2. Accuracy on batch 2057/3013  on Training is 84.38714771622935\n",
            "Epoch #2. Accuracy on batch 2058/3013  on Training is 84.38714181641573\n",
            "Epoch #2. Accuracy on batch 2059/3013  on Training is 84.39168689320388\n",
            "Batch Id 2060 is having training loss of 0.5562931299209595\n",
            "0.2105226218700409\n",
            "Epoch #2. Accuracy on batch 2060/3013  on Training is 84.3992600679282\n",
            "Epoch #2. Accuracy on batch 2061/3013  on Training is 84.40531037827353\n",
            "Epoch #2. Accuracy on batch 2062/3013  on Training is 84.40984003877848\n",
            "Epoch #2. Accuracy on batch 2063/3013  on Training is 84.41133720930233\n",
            "Epoch #2. Accuracy on batch 2064/3013  on Training is 84.41283292978208\n",
            "Epoch #2. Accuracy on batch 2065/3013  on Training is 84.4128146176186\n",
            "Epoch #2. Accuracy on batch 2066/3013  on Training is 84.40826076439284\n",
            "Epoch #2. Accuracy on batch 2067/3013  on Training is 84.40975580270793\n",
            "Epoch #2. Accuracy on batch 2068/3013  on Training is 84.40822861285645\n",
            "Epoch #2. Accuracy on batch 2069/3013  on Training is 84.40972222222223\n",
            "Epoch #2. Accuracy on batch 2070/3013  on Training is 84.40819652341864\n",
            "Epoch #2. Accuracy on batch 2071/3013  on Training is 84.4081805019305\n",
            "Epoch #2. Accuracy on batch 2072/3013  on Training is 84.41117945007235\n",
            "Epoch #2. Accuracy on batch 2073/3013  on Training is 84.41568225650916\n",
            "Epoch #2. Accuracy on batch 2074/3013  on Training is 84.41265060240964\n",
            "Epoch #2. Accuracy on batch 2075/3013  on Training is 84.41263246628131\n",
            "Epoch #2. Accuracy on batch 2076/3013  on Training is 84.41411892152142\n",
            "Epoch #2. Accuracy on batch 2077/3013  on Training is 84.41560394610202\n",
            "Epoch #2. Accuracy on batch 2078/3013  on Training is 84.41558441558442\n",
            "Epoch #2. Accuracy on batch 2079/3013  on Training is 84.4170673076923\n",
            "Batch Id 2080 is having training loss of 0.5558735728263855\n",
            "0.8089004755020142\n",
            "Epoch #2. Accuracy on batch 2080/3013  on Training is 84.41254204709274\n",
            "Epoch #2. Accuracy on batch 2081/3013  on Training is 84.41252401536984\n",
            "Epoch #2. Accuracy on batch 2082/3013  on Training is 84.40950552088334\n",
            "Epoch #2. Accuracy on batch 2083/3013  on Training is 84.40948896353167\n",
            "Epoch #2. Accuracy on batch 2084/3013  on Training is 84.40947242206235\n",
            "Epoch #2. Accuracy on batch 2085/3013  on Training is 84.41245206136146\n",
            "Epoch #2. Accuracy on batch 2086/3013  on Training is 84.41542884523238\n",
            "Epoch #2. Accuracy on batch 2087/3013  on Training is 84.41540948275862\n",
            "Epoch #2. Accuracy on batch 2088/3013  on Training is 84.4183820009574\n",
            "Epoch #2. Accuracy on batch 2089/3013  on Training is 84.41686602870813\n",
            "Epoch #2. Accuracy on batch 2090/3013  on Training is 84.41535150645625\n",
            "Epoch #2. Accuracy on batch 2091/3013  on Training is 84.41533221797323\n",
            "Epoch #2. Accuracy on batch 2092/3013  on Training is 84.41829909221214\n",
            "Epoch #2. Accuracy on batch 2093/3013  on Training is 84.41529369627507\n",
            "Epoch #2. Accuracy on batch 2094/3013  on Training is 84.41527446300717\n",
            "Epoch #2. Accuracy on batch 2095/3013  on Training is 84.4137643129771\n",
            "Epoch #2. Accuracy on batch 2096/3013  on Training is 84.41225560324273\n",
            "Epoch #2. Accuracy on batch 2097/3013  on Training is 84.4122378455672\n",
            "Epoch #2. Accuracy on batch 2098/3013  on Training is 84.40924249642687\n",
            "Epoch #2. Accuracy on batch 2099/3013  on Training is 84.4077380952381\n",
            "Batch Id 2100 is having training loss of 0.5555381178855896\n",
            "0.3986341655254364\n",
            "Epoch #2. Accuracy on batch 2100/3013  on Training is 84.407722513089\n",
            "Epoch #2. Accuracy on batch 2101/3013  on Training is 84.40919362511893\n",
            "Epoch #2. Accuracy on batch 2102/3013  on Training is 84.41066333808844\n",
            "Epoch #2. Accuracy on batch 2103/3013  on Training is 84.4106463878327\n",
            "Epoch #2. Accuracy on batch 2104/3013  on Training is 84.40914489311164\n",
            "Epoch #2. Accuracy on batch 2105/3013  on Training is 84.41358024691358\n",
            "Epoch #2. Accuracy on batch 2106/3013  on Training is 84.41652823920266\n",
            "Epoch #2. Accuracy on batch 2107/3013  on Training is 84.4150260910816\n",
            "Epoch #2. Accuracy on batch 2108/3013  on Training is 84.41500711237553\n",
            "Epoch #2. Accuracy on batch 2109/3013  on Training is 84.41350710900474\n",
            "Epoch #2. Accuracy on batch 2110/3013  on Training is 84.42089057318806\n",
            "Epoch #2. Accuracy on batch 2111/3013  on Training is 84.4149502840909\n",
            "Epoch #2. Accuracy on batch 2112/3013  on Training is 84.41936819687648\n",
            "Epoch #2. Accuracy on batch 2113/3013  on Training is 84.41786896877956\n",
            "Epoch #2. Accuracy on batch 2114/3013  on Training is 84.4178486997636\n",
            "Epoch #2. Accuracy on batch 2115/3013  on Training is 84.42225897920605\n",
            "Epoch #2. Accuracy on batch 2116/3013  on Training is 84.42223665564478\n",
            "Epoch #2. Accuracy on batch 2117/3013  on Training is 84.420738904627\n",
            "Epoch #2. Accuracy on batch 2118/3013  on Training is 84.42366682397358\n",
            "Epoch #2. Accuracy on batch 2119/3013  on Training is 84.42659198113208\n",
            "Batch Id 2120 is having training loss of 0.5549222230911255\n",
            "0.2786727249622345\n",
            "Epoch #2. Accuracy on batch 2120/3013  on Training is 84.43098774163131\n",
            "Epoch #2. Accuracy on batch 2121/3013  on Training is 84.43243402450518\n",
            "Epoch #2. Accuracy on batch 2122/3013  on Training is 84.43093499764484\n",
            "Epoch #2. Accuracy on batch 2123/3013  on Training is 84.42796610169492\n",
            "Epoch #2. Accuracy on batch 2124/3013  on Training is 84.42205882352941\n",
            "Epoch #2. Accuracy on batch 2125/3013  on Training is 84.41762699905927\n",
            "Epoch #2. Accuracy on batch 2126/3013  on Training is 84.42054536906441\n",
            "Epoch #2. Accuracy on batch 2127/3013  on Training is 84.42052396616542\n",
            "Epoch #2. Accuracy on batch 2128/3013  on Training is 84.41756693283232\n",
            "Epoch #2. Accuracy on batch 2129/3013  on Training is 84.4219483568075\n",
            "Epoch #2. Accuracy on batch 2130/3013  on Training is 84.42192632566871\n",
            "Epoch #2. Accuracy on batch 2131/3013  on Training is 84.421904315197\n",
            "Epoch #2. Accuracy on batch 2132/3013  on Training is 84.42041725269573\n",
            "Epoch #2. Accuracy on batch 2133/3013  on Training is 84.4130740393627\n",
            "Epoch #2. Accuracy on batch 2134/3013  on Training is 84.413056206089\n",
            "Epoch #2. Accuracy on batch 2135/3013  on Training is 84.41450140449439\n",
            "Epoch #2. Accuracy on batch 2136/3013  on Training is 84.41448291998128\n",
            "Epoch #2. Accuracy on batch 2137/3013  on Training is 84.41592609915809\n",
            "Epoch #2. Accuracy on batch 2138/3013  on Training is 84.4159069658719\n",
            "Epoch #2. Accuracy on batch 2139/3013  on Training is 84.42172897196262\n",
            "Batch Id 2140 is having training loss of 0.5547551512718201\n",
            "0.7105422616004944\n",
            "Epoch #2. Accuracy on batch 2140/3013  on Training is 84.41878794955628\n",
            "Epoch #2. Accuracy on batch 2141/3013  on Training is 84.42460317460318\n",
            "Epoch #2. Accuracy on batch 2142/3013  on Training is 84.4289547363509\n",
            "Epoch #2. Accuracy on batch 2143/3013  on Training is 84.43038712686567\n",
            "Epoch #2. Accuracy on batch 2144/3013  on Training is 84.42599067599068\n",
            "Epoch #2. Accuracy on batch 2145/3013  on Training is 84.42887931034483\n",
            "Epoch #2. Accuracy on batch 2146/3013  on Training is 84.42885421518397\n",
            "Epoch #2. Accuracy on batch 2147/3013  on Training is 84.4288291433892\n",
            "Epoch #2. Accuracy on batch 2148/3013  on Training is 84.4273499302001\n",
            "Epoch #2. Accuracy on batch 2149/3013  on Training is 84.42732558139535\n",
            "Epoch #2. Accuracy on batch 2150/3013  on Training is 84.42584844258485\n",
            "Epoch #2. Accuracy on batch 2151/3013  on Training is 84.4301812267658\n",
            "Epoch #2. Accuracy on batch 2152/3013  on Training is 84.42870413376684\n",
            "Epoch #2. Accuracy on batch 2153/3013  on Training is 84.43448235840297\n",
            "Epoch #2. Accuracy on batch 2154/3013  on Training is 84.43300464037122\n",
            "Epoch #2. Accuracy on batch 2155/3013  on Training is 84.4344271799629\n",
            "Epoch #2. Accuracy on batch 2156/3013  on Training is 84.43729717199814\n",
            "Epoch #2. Accuracy on batch 2157/3013  on Training is 84.43871640407785\n",
            "Epoch #2. Accuracy on batch 2158/3013  on Training is 84.44302918017601\n",
            "Epoch #2. Accuracy on batch 2159/3013  on Training is 84.44589120370371\n",
            "Batch Id 2160 is having training loss of 0.5539227724075317\n",
            "0.44383445382118225\n",
            "Epoch #2. Accuracy on batch 2160/3013  on Training is 84.4487505784359\n",
            "Epoch #2. Accuracy on batch 2161/3013  on Training is 84.45305272895467\n",
            "Epoch #2. Accuracy on batch 2162/3013  on Training is 84.45446139620897\n",
            "Epoch #2. Accuracy on batch 2163/3013  on Training is 84.45442467652495\n",
            "Epoch #2. Accuracy on batch 2164/3013  on Training is 84.45005773672055\n",
            "Epoch #2. Accuracy on batch 2165/3013  on Training is 84.45002308402586\n",
            "Epoch #2. Accuracy on batch 2166/3013  on Training is 84.44422011998154\n",
            "Epoch #2. Accuracy on batch 2167/3013  on Training is 84.44707103321034\n",
            "Epoch #2. Accuracy on batch 2168/3013  on Training is 84.44559704933148\n",
            "Epoch #2. Accuracy on batch 2169/3013  on Training is 84.44700460829493\n",
            "Epoch #2. Accuracy on batch 2170/3013  on Training is 84.44985029940119\n",
            "Epoch #2. Accuracy on batch 2171/3013  on Training is 84.45125460405157\n",
            "Epoch #2. Accuracy on batch 2172/3013  on Training is 84.44978140819144\n",
            "Epoch #2. Accuracy on batch 2173/3013  on Training is 84.446872125115\n",
            "Epoch #2. Accuracy on batch 2174/3013  on Training is 84.44971264367815\n",
            "Epoch #2. Accuracy on batch 2175/3013  on Training is 84.44536994485294\n",
            "Epoch #2. Accuracy on batch 2176/3013  on Training is 84.44533762057878\n",
            "Epoch #2. Accuracy on batch 2177/3013  on Training is 84.44530532598715\n",
            "Epoch #2. Accuracy on batch 2178/3013  on Training is 84.44383891693437\n",
            "Epoch #2. Accuracy on batch 2179/3013  on Training is 84.44237385321101\n",
            "Batch Id 2180 is having training loss of 0.5541853904724121\n",
            "0.6308618783950806\n",
            "Epoch #2. Accuracy on batch 2180/3013  on Training is 84.44234296194406\n",
            "Epoch #2. Accuracy on batch 2181/3013  on Training is 84.44231209899175\n",
            "Epoch #2. Accuracy on batch 2182/3013  on Training is 84.44371278057719\n",
            "Epoch #2. Accuracy on batch 2183/3013  on Training is 84.44511217948718\n",
            "Epoch #2. Accuracy on batch 2184/3013  on Training is 84.4407894736842\n",
            "Epoch #2. Accuracy on batch 2185/3013  on Training is 84.44075937785911\n",
            "Epoch #2. Accuracy on batch 2186/3013  on Training is 84.4378715134888\n",
            "Epoch #2. Accuracy on batch 2187/3013  on Training is 84.43498628884826\n",
            "Epoch #2. Accuracy on batch 2188/3013  on Training is 84.43638647784377\n",
            "Epoch #2. Accuracy on batch 2189/3013  on Training is 84.43635844748859\n",
            "Epoch #2. Accuracy on batch 2190/3013  on Training is 84.4377567320858\n",
            "Epoch #2. Accuracy on batch 2191/3013  on Training is 84.44057937956204\n",
            "Epoch #2. Accuracy on batch 2192/3013  on Training is 84.43912448700411\n",
            "Epoch #2. Accuracy on batch 2193/3013  on Training is 84.44336827711942\n",
            "Epoch #2. Accuracy on batch 2194/3013  on Training is 84.44048974943053\n",
            "Epoch #2. Accuracy on batch 2195/3013  on Training is 84.4361908014572\n",
            "Epoch #2. Accuracy on batch 2196/3013  on Training is 84.43331816112881\n",
            "Epoch #2. Accuracy on batch 2197/3013  on Training is 84.43755686988172\n",
            "Epoch #2. Accuracy on batch 2198/3013  on Training is 84.43468622100956\n",
            "Epoch #2. Accuracy on batch 2199/3013  on Training is 84.43323863636364\n",
            "Batch Id 2200 is having training loss of 0.5545454621315002\n",
            "0.7270833253860474\n",
            "Epoch #2. Accuracy on batch 2200/3013  on Training is 84.43037255792821\n",
            "Epoch #2. Accuracy on batch 2201/3013  on Training is 84.42608991825612\n",
            "Epoch #2. Accuracy on batch 2202/3013  on Training is 84.42748524738992\n",
            "Epoch #2. Accuracy on batch 2203/3013  on Training is 84.42887931034483\n",
            "Epoch #2. Accuracy on batch 2204/3013  on Training is 84.42602040816327\n",
            "Epoch #2. Accuracy on batch 2205/3013  on Training is 84.43024705349048\n",
            "Epoch #2. Accuracy on batch 2206/3013  on Training is 84.42739012233801\n",
            "Epoch #2. Accuracy on batch 2207/3013  on Training is 84.42170516304348\n",
            "Epoch #2. Accuracy on batch 2208/3013  on Training is 84.42309868718877\n",
            "Epoch #2. Accuracy on batch 2209/3013  on Training is 84.42024886877829\n",
            "Epoch #2. Accuracy on batch 2210/3013  on Training is 84.41881501582994\n",
            "Epoch #2. Accuracy on batch 2211/3013  on Training is 84.4187952079566\n",
            "Epoch #2. Accuracy on batch 2212/3013  on Training is 84.41736330772707\n",
            "Epoch #2. Accuracy on batch 2213/3013  on Training is 84.41310975609755\n",
            "Epoch #2. Accuracy on batch 2214/3013  on Training is 84.41591422121896\n",
            "Epoch #2. Accuracy on batch 2215/3013  on Training is 84.4173059566787\n",
            "Epoch #2. Accuracy on batch 2216/3013  on Training is 84.42151556156969\n",
            "Epoch #2. Accuracy on batch 2217/3013  on Training is 84.4229035166817\n",
            "Epoch #2. Accuracy on batch 2218/3013  on Training is 84.42569851284362\n",
            "Epoch #2. Accuracy on batch 2219/3013  on Training is 84.42426801801801\n",
            "Batch Id 2220 is having training loss of 0.5545474886894226\n",
            "0.6344211101531982\n",
            "Epoch #2. Accuracy on batch 2220/3013  on Training is 84.42424583520936\n",
            "Epoch #2. Accuracy on batch 2221/3013  on Training is 84.42141089108911\n",
            "Epoch #2. Accuracy on batch 2222/3013  on Training is 84.42139001349528\n",
            "Epoch #2. Accuracy on batch 2223/3013  on Training is 84.42136915467626\n",
            "Epoch #2. Accuracy on batch 2224/3013  on Training is 84.42134831460675\n",
            "Epoch #2. Accuracy on batch 2225/3013  on Training is 84.41851976639713\n",
            "Epoch #2. Accuracy on batch 2226/3013  on Training is 84.42130669061518\n",
            "Epoch #2. Accuracy on batch 2227/3013  on Training is 84.41848070017953\n",
            "Epoch #2. Accuracy on batch 2228/3013  on Training is 84.42126514131898\n",
            "Epoch #2. Accuracy on batch 2229/3013  on Training is 84.41844170403587\n",
            "Epoch #2. Accuracy on batch 2230/3013  on Training is 84.41702151501569\n",
            "Epoch #2. Accuracy on batch 2231/3013  on Training is 84.41000224014337\n",
            "Epoch #2. Accuracy on batch 2232/3013  on Training is 84.40858710255262\n",
            "Epoch #2. Accuracy on batch 2233/3013  on Training is 84.4099709042077\n",
            "Epoch #2. Accuracy on batch 2234/3013  on Training is 84.40855704697987\n",
            "Epoch #2. Accuracy on batch 2235/3013  on Training is 84.41133720930233\n",
            "Epoch #2. Accuracy on batch 2236/3013  on Training is 84.4113209655789\n",
            "Epoch #2. Accuracy on batch 2237/3013  on Training is 84.41270107238606\n",
            "Epoch #2. Accuracy on batch 2238/3013  on Training is 84.41547565877624\n",
            "Epoch #2. Accuracy on batch 2239/3013  on Training is 84.4140625\n",
            "Batch Id 2240 is having training loss of 0.5548499226570129\n",
            "0.7740037441253662\n",
            "Epoch #2. Accuracy on batch 2240/3013  on Training is 84.41404506916555\n",
            "Epoch #2. Accuracy on batch 2241/3013  on Training is 84.41681534344336\n",
            "Epoch #2. Accuracy on batch 2242/3013  on Training is 84.42097637093178\n",
            "Epoch #2. Accuracy on batch 2243/3013  on Training is 84.42234848484848\n",
            "Epoch #2. Accuracy on batch 2244/3013  on Training is 84.42650334075724\n",
            "Epoch #2. Accuracy on batch 2245/3013  on Training is 84.42091495992877\n",
            "Epoch #2. Accuracy on batch 2246/3013  on Training is 84.42089452603471\n",
            "Epoch #2. Accuracy on batch 2247/3013  on Training is 84.41948398576513\n",
            "Epoch #2. Accuracy on batch 2248/3013  on Training is 84.42224321920854\n",
            "Epoch #2. Accuracy on batch 2249/3013  on Training is 84.42361111111111\n",
            "Epoch #2. Accuracy on batch 2250/3013  on Training is 84.4222012438916\n",
            "Epoch #2. Accuracy on batch 2251/3013  on Training is 84.42495559502665\n",
            "Epoch #2. Accuracy on batch 2252/3013  on Training is 84.41938526409233\n",
            "Epoch #2. Accuracy on batch 2253/3013  on Training is 84.41797914818102\n",
            "Epoch #2. Accuracy on batch 2254/3013  on Training is 84.42073170731707\n",
            "Epoch #2. Accuracy on batch 2255/3013  on Training is 84.41932624113475\n",
            "Epoch #2. Accuracy on batch 2256/3013  on Training is 84.42069118298626\n",
            "Epoch #2. Accuracy on batch 2257/3013  on Training is 84.41790301151461\n",
            "Epoch #2. Accuracy on batch 2258/3013  on Training is 84.41788401947764\n",
            "Epoch #2. Accuracy on batch 2259/3013  on Training is 84.41371681415929\n",
            "Batch Id 2260 is having training loss of 0.5551170706748962\n",
            "0.847133219242096\n",
            "Epoch #2. Accuracy on batch 2260/3013  on Training is 84.40955329500221\n",
            "Epoch #2. Accuracy on batch 2261/3013  on Training is 84.41091954022988\n",
            "Epoch #2. Accuracy on batch 2262/3013  on Training is 84.41504639858594\n",
            "Epoch #2. Accuracy on batch 2263/3013  on Training is 84.41916961130742\n",
            "Epoch #2. Accuracy on batch 2264/3013  on Training is 84.41777041942605\n",
            "Epoch #2. Accuracy on batch 2265/3013  on Training is 84.42050970873787\n",
            "Epoch #2. Accuracy on batch 2266/3013  on Training is 84.42186810763123\n",
            "Epoch #2. Accuracy on batch 2267/3013  on Training is 84.42460317460318\n",
            "Epoch #2. Accuracy on batch 2268/3013  on Training is 84.42182679594535\n",
            "Epoch #2. Accuracy on batch 2269/3013  on Training is 84.42180616740089\n",
            "Epoch #2. Accuracy on batch 2270/3013  on Training is 84.42728974020255\n",
            "Epoch #2. Accuracy on batch 2271/3013  on Training is 84.42726672535211\n",
            "Epoch #2. Accuracy on batch 2272/3013  on Training is 84.42311922569291\n",
            "Epoch #2. Accuracy on batch 2273/3013  on Training is 84.42584652594547\n",
            "Epoch #2. Accuracy on batch 2274/3013  on Training is 84.42445054945055\n",
            "Epoch #2. Accuracy on batch 2275/3013  on Training is 84.4203097539543\n",
            "Epoch #2. Accuracy on batch 2276/3013  on Training is 84.42028985507247\n",
            "Epoch #2. Accuracy on batch 2277/3013  on Training is 84.4202699736611\n",
            "Epoch #2. Accuracy on batch 2278/3013  on Training is 84.42162132514261\n",
            "Epoch #2. Accuracy on batch 2279/3013  on Training is 84.41611842105263\n",
            "Batch Id 2280 is having training loss of 0.5550075769424438\n",
            "0.48554661870002747\n",
            "Epoch #2. Accuracy on batch 2280/3013  on Training is 84.41884042086804\n",
            "Epoch #2. Accuracy on batch 2281/3013  on Training is 84.42019062226117\n",
            "Epoch #2. Accuracy on batch 2282/3013  on Training is 84.41880201489269\n",
            "Epoch #2. Accuracy on batch 2283/3013  on Training is 84.42151926444834\n",
            "Epoch #2. Accuracy on batch 2284/3013  on Training is 84.42013129102844\n",
            "Epoch #2. Accuracy on batch 2285/3013  on Training is 84.42011154855643\n",
            "Epoch #2. Accuracy on batch 2286/3013  on Training is 84.42145824223874\n",
            "Epoch #2. Accuracy on batch 2287/3013  on Training is 84.42007211538461\n",
            "Epoch #2. Accuracy on batch 2288/3013  on Training is 84.42278287461774\n",
            "Epoch #2. Accuracy on batch 2289/3013  on Training is 84.42276200873363\n",
            "Epoch #2. Accuracy on batch 2290/3013  on Training is 84.42137712789174\n",
            "Epoch #2. Accuracy on batch 2291/3013  on Training is 84.42135689354276\n",
            "Epoch #2. Accuracy on batch 2292/3013  on Training is 84.42678805058875\n",
            "Epoch #2. Accuracy on batch 2293/3013  on Training is 84.42131647776809\n",
            "Epoch #2. Accuracy on batch 2294/3013  on Training is 84.41993464052288\n",
            "Epoch #2. Accuracy on batch 2295/3013  on Training is 84.42127613240419\n",
            "Epoch #2. Accuracy on batch 2296/3013  on Training is 84.41989551589029\n",
            "Epoch #2. Accuracy on batch 2297/3013  on Training is 84.42123585726719\n",
            "Epoch #2. Accuracy on batch 2298/3013  on Training is 84.41849717268377\n",
            "Epoch #2. Accuracy on batch 2299/3013  on Training is 84.41711956521739\n",
            "Batch Id 2300 is having training loss of 0.5548333525657654\n",
            "0.5717428922653198\n",
            "Epoch #2. Accuracy on batch 2300/3013  on Training is 84.41845936549326\n",
            "Epoch #2. Accuracy on batch 2301/3013  on Training is 84.4211555169418\n",
            "Epoch #2. Accuracy on batch 2302/3013  on Training is 84.41977854971776\n",
            "Epoch #2. Accuracy on batch 2303/3013  on Training is 84.41975911458333\n",
            "Epoch #2. Accuracy on batch 2304/3013  on Training is 84.41973969631236\n",
            "Epoch #2. Accuracy on batch 2305/3013  on Training is 84.4237857762359\n",
            "Epoch #2. Accuracy on batch 2306/3013  on Training is 84.42647377546598\n",
            "Epoch #2. Accuracy on batch 2307/3013  on Training is 84.42915944540728\n",
            "Epoch #2. Accuracy on batch 2308/3013  on Training is 84.4291359896059\n",
            "Epoch #2. Accuracy on batch 2309/3013  on Training is 84.43181818181819\n",
            "Epoch #2. Accuracy on batch 2310/3013  on Training is 84.434498052791\n",
            "Epoch #2. Accuracy on batch 2311/3013  on Training is 84.43582396193771\n",
            "Epoch #2. Accuracy on batch 2312/3013  on Training is 84.43579766536965\n",
            "Epoch #2. Accuracy on batch 2313/3013  on Training is 84.4398228176318\n",
            "Epoch #2. Accuracy on batch 2314/3013  on Training is 84.44249460043197\n",
            "Epoch #2. Accuracy on batch 2315/3013  on Training is 84.43976683937824\n",
            "Epoch #2. Accuracy on batch 2316/3013  on Training is 84.44378506689685\n",
            "Epoch #2. Accuracy on batch 2317/3013  on Training is 84.44105910267471\n",
            "Epoch #2. Accuracy on batch 2318/3013  on Training is 84.4423781802501\n",
            "Epoch #2. Accuracy on batch 2319/3013  on Training is 84.44100215517241\n",
            "Batch Id 2320 is having training loss of 0.5541063547134399\n",
            "0.5100720524787903\n",
            "Epoch #2. Accuracy on batch 2320/3013  on Training is 84.4409737182249\n",
            "Epoch #2. Accuracy on batch 2321/3013  on Training is 84.44363695090439\n",
            "Epoch #2. Accuracy on batch 2322/3013  on Training is 84.44495264743865\n",
            "Epoch #2. Accuracy on batch 2323/3013  on Training is 84.44761187607573\n",
            "Epoch #2. Accuracy on batch 2324/3013  on Training is 84.4489247311828\n",
            "Epoch #2. Accuracy on batch 2325/3013  on Training is 84.44620593293207\n",
            "Epoch #2. Accuracy on batch 2326/3013  on Training is 84.44483240223464\n",
            "Epoch #2. Accuracy on batch 2327/3013  on Training is 84.43809063573883\n",
            "Epoch #2. Accuracy on batch 2328/3013  on Training is 84.44074710176041\n",
            "Epoch #2. Accuracy on batch 2329/3013  on Training is 84.43803648068669\n",
            "Epoch #2. Accuracy on batch 2330/3013  on Training is 84.43935006435007\n",
            "Epoch #2. Accuracy on batch 2331/3013  on Training is 84.43798241852487\n",
            "Epoch #2. Accuracy on batch 2332/3013  on Training is 84.44063437633947\n",
            "Epoch #2. Accuracy on batch 2333/3013  on Training is 84.43792844901456\n",
            "Epoch #2. Accuracy on batch 2334/3013  on Training is 84.43522483940043\n",
            "Epoch #2. Accuracy on batch 2335/3013  on Training is 84.4365368150685\n",
            "Epoch #2. Accuracy on batch 2336/3013  on Training is 84.43918485237484\n",
            "Epoch #2. Accuracy on batch 2337/3013  on Training is 84.43915739948675\n",
            "Epoch #2. Accuracy on batch 2338/3013  on Training is 84.44046601111586\n",
            "Epoch #2. Accuracy on batch 2339/3013  on Training is 84.43776709401709\n",
            "Batch Id 2340 is having training loss of 0.5542343258857727\n",
            "0.4846362769603729\n",
            "Epoch #2. Accuracy on batch 2340/3013  on Training is 84.43907518154634\n",
            "Epoch #2. Accuracy on batch 2341/3013  on Training is 84.43504483347566\n",
            "Epoch #2. Accuracy on batch 2342/3013  on Training is 84.43368544600939\n",
            "Epoch #2. Accuracy on batch 2343/3013  on Training is 84.43765998293516\n",
            "Epoch #2. Accuracy on batch 2344/3013  on Training is 84.44163113006397\n",
            "Epoch #2. Accuracy on batch 2345/3013  on Training is 84.44160272804774\n",
            "Epoch #2. Accuracy on batch 2346/3013  on Training is 84.44690029825308\n",
            "Epoch #2. Accuracy on batch 2347/3013  on Training is 84.44553875638842\n",
            "Epoch #2. Accuracy on batch 2348/3013  on Training is 84.44683908045977\n",
            "Epoch #2. Accuracy on batch 2349/3013  on Training is 84.44813829787235\n",
            "Epoch #2. Accuracy on batch 2350/3013  on Training is 84.44943641003829\n",
            "Epoch #2. Accuracy on batch 2351/3013  on Training is 84.45339073129252\n",
            "Epoch #2. Accuracy on batch 2352/3013  on Training is 84.45070123246919\n",
            "Epoch #2. Accuracy on batch 2353/3013  on Training is 84.45332412914189\n",
            "Epoch #2. Accuracy on batch 2354/3013  on Training is 84.45727176220807\n",
            "Epoch #2. Accuracy on batch 2355/3013  on Training is 84.45723684210526\n",
            "Epoch #2. Accuracy on batch 2356/3013  on Training is 84.45985362749258\n",
            "Epoch #2. Accuracy on batch 2357/3013  on Training is 84.46114291772689\n",
            "Epoch #2. Accuracy on batch 2358/3013  on Training is 84.46375582874099\n",
            "Epoch #2. Accuracy on batch 2359/3013  on Training is 84.46106991525424\n",
            "Batch Id 2360 is having training loss of 0.5538783073425293\n",
            "0.5116795301437378\n",
            "Epoch #2. Accuracy on batch 2360/3013  on Training is 84.45838627700127\n",
            "Epoch #2. Accuracy on batch 2361/3013  on Training is 84.46099703640982\n",
            "Epoch #2. Accuracy on batch 2362/3013  on Training is 84.46228311468472\n",
            "Epoch #2. Accuracy on batch 2363/3013  on Training is 84.46356810490694\n",
            "Epoch #2. Accuracy on batch 2364/3013  on Training is 84.45692389006342\n",
            "Epoch #2. Accuracy on batch 2365/3013  on Training is 84.45688926458158\n",
            "Epoch #2. Accuracy on batch 2366/3013  on Training is 84.45949514152936\n",
            "Epoch #2. Accuracy on batch 2367/3013  on Training is 84.46077913851352\n",
            "Epoch #2. Accuracy on batch 2368/3013  on Training is 84.45678556352891\n",
            "Epoch #2. Accuracy on batch 2369/3013  on Training is 84.4620253164557\n",
            "Epoch #2. Accuracy on batch 2370/3013  on Training is 84.46198861239984\n",
            "Epoch #2. Accuracy on batch 2371/3013  on Training is 84.46326939291737\n",
            "Epoch #2. Accuracy on batch 2372/3013  on Training is 84.46586599241466\n",
            "Epoch #2. Accuracy on batch 2373/3013  on Training is 84.46187868576243\n",
            "Epoch #2. Accuracy on batch 2374/3013  on Training is 84.45921052631579\n",
            "Epoch #2. Accuracy on batch 2375/3013  on Training is 84.45654461279462\n",
            "Epoch #2. Accuracy on batch 2376/3013  on Training is 84.44862221287337\n",
            "Epoch #2. Accuracy on batch 2377/3013  on Training is 84.45384777123633\n",
            "Epoch #2. Accuracy on batch 2378/3013  on Training is 84.45118747372845\n",
            "Epoch #2. Accuracy on batch 2379/3013  on Training is 84.44852941176471\n",
            "Batch Id 2380 is having training loss of 0.553997814655304\n",
            "0.45801806449890137\n",
            "Epoch #2. Accuracy on batch 2380/3013  on Training is 84.44718605627888\n",
            "Epoch #2. Accuracy on batch 2381/3013  on Training is 84.44846767422334\n",
            "Epoch #2. Accuracy on batch 2382/3013  on Training is 84.447125472094\n",
            "Epoch #2. Accuracy on batch 2383/3013  on Training is 84.44578439597315\n",
            "Epoch #2. Accuracy on batch 2384/3013  on Training is 84.44706498951781\n",
            "Epoch #2. Accuracy on batch 2385/3013  on Training is 84.44834450963957\n",
            "Epoch #2. Accuracy on batch 2386/3013  on Training is 84.44700460829493\n",
            "Epoch #2. Accuracy on batch 2387/3013  on Training is 84.44304857621441\n",
            "Epoch #2. Accuracy on batch 2388/3013  on Training is 84.44302009208874\n",
            "Epoch #2. Accuracy on batch 2389/3013  on Training is 84.44299163179916\n",
            "Epoch #2. Accuracy on batch 2390/3013  on Training is 84.44557716436637\n",
            "Epoch #2. Accuracy on batch 2391/3013  on Training is 84.4429347826087\n",
            "Epoch #2. Accuracy on batch 2392/3013  on Training is 84.44290639364814\n",
            "Epoch #2. Accuracy on batch 2393/3013  on Training is 84.44418337510443\n",
            "Epoch #2. Accuracy on batch 2394/3013  on Training is 84.4428496868476\n",
            "Epoch #2. Accuracy on batch 2395/3013  on Training is 84.44542988313856\n",
            "Epoch #2. Accuracy on batch 2396/3013  on Training is 84.44670421360033\n",
            "Epoch #2. Accuracy on batch 2397/3013  on Training is 84.44406797331109\n",
            "Epoch #2. Accuracy on batch 2398/3013  on Training is 84.44534180908713\n",
            "Epoch #2. Accuracy on batch 2399/3013  on Training is 84.44270833333333\n",
            "Batch Id 2400 is having training loss of 0.5537804961204529\n",
            "0.5185048580169678\n",
            "Epoch #2. Accuracy on batch 2400/3013  on Training is 84.44398167430238\n",
            "Epoch #2. Accuracy on batch 2401/3013  on Training is 84.44525395503747\n",
            "Epoch #2. Accuracy on batch 2402/3013  on Training is 84.44262380357885\n",
            "Epoch #2. Accuracy on batch 2403/3013  on Training is 84.43999584026622\n",
            "Epoch #2. Accuracy on batch 2404/3013  on Training is 84.4412681912682\n",
            "Epoch #2. Accuracy on batch 2405/3013  on Training is 84.43604530340815\n",
            "Epoch #2. Accuracy on batch 2406/3013  on Training is 84.44121312837557\n",
            "Epoch #2. Accuracy on batch 2407/3013  on Training is 84.43729235880399\n",
            "Epoch #2. Accuracy on batch 2408/3013  on Training is 84.43986093814861\n",
            "Epoch #2. Accuracy on batch 2409/3013  on Training is 84.43724066390041\n",
            "Epoch #2. Accuracy on batch 2410/3013  on Training is 84.43851099128992\n",
            "Epoch #2. Accuracy on batch 2411/3013  on Training is 84.43200663349917\n",
            "Epoch #2. Accuracy on batch 2412/3013  on Training is 84.43327807708248\n",
            "Epoch #2. Accuracy on batch 2413/3013  on Training is 84.4358429991715\n",
            "Epoch #2. Accuracy on batch 2414/3013  on Training is 84.43711180124224\n",
            "Epoch #2. Accuracy on batch 2415/3013  on Training is 84.43708609271523\n",
            "Epoch #2. Accuracy on batch 2416/3013  on Training is 84.43706040546131\n",
            "Epoch #2. Accuracy on batch 2417/3013  on Training is 84.43832712985939\n",
            "Epoch #2. Accuracy on batch 2418/3013  on Training is 84.43442538238942\n",
            "Epoch #2. Accuracy on batch 2419/3013  on Training is 84.43052685950413\n",
            "Batch Id 2420 is having training loss of 0.5538883805274963\n",
            "0.398860365152359\n",
            "Epoch #2. Accuracy on batch 2420/3013  on Training is 84.42921313506815\n",
            "Epoch #2. Accuracy on batch 2421/3013  on Training is 84.43048100743188\n",
            "Epoch #2. Accuracy on batch 2422/3013  on Training is 84.42658893933141\n",
            "Epoch #2. Accuracy on batch 2423/3013  on Training is 84.42914603960396\n",
            "Epoch #2. Accuracy on batch 2424/3013  on Training is 84.42654639175258\n",
            "Epoch #2. Accuracy on batch 2425/3013  on Training is 84.42781327287716\n",
            "Epoch #2. Accuracy on batch 2426/3013  on Training is 84.42779151215493\n",
            "Epoch #2. Accuracy on batch 2427/3013  on Training is 84.4290568369028\n",
            "Epoch #2. Accuracy on batch 2428/3013  on Training is 84.43289419514204\n",
            "Epoch #2. Accuracy on batch 2429/3013  on Training is 84.43544238683127\n",
            "Epoch #2. Accuracy on batch 2430/3013  on Training is 84.43927396133279\n",
            "Epoch #2. Accuracy on batch 2431/3013  on Training is 84.44181743421052\n",
            "Epoch #2. Accuracy on batch 2432/3013  on Training is 84.44564323879983\n",
            "Epoch #2. Accuracy on batch 2433/3013  on Training is 84.44176253081348\n",
            "Epoch #2. Accuracy on batch 2434/3013  on Training is 84.43788501026694\n",
            "Epoch #2. Accuracy on batch 2435/3013  on Training is 84.43914203612479\n",
            "Epoch #2. Accuracy on batch 2436/3013  on Training is 84.43526877308166\n",
            "Epoch #2. Accuracy on batch 2437/3013  on Training is 84.43396226415095\n",
            "Epoch #2. Accuracy on batch 2438/3013  on Training is 84.43265682656826\n",
            "Epoch #2. Accuracy on batch 2439/3013  on Training is 84.43519467213115\n",
            "Batch Id 2440 is having training loss of 0.5536897778511047\n",
            "0.8451074957847595\n",
            "Epoch #2. Accuracy on batch 2440/3013  on Training is 84.4313293732077\n",
            "Epoch #2. Accuracy on batch 2441/3013  on Training is 84.43386568386569\n",
            "Epoch #2. Accuracy on batch 2442/3013  on Training is 84.43639991813345\n",
            "Epoch #2. Accuracy on batch 2443/3013  on Training is 84.43765343698854\n",
            "Epoch #2. Accuracy on batch 2444/3013  on Training is 84.43762781186093\n",
            "Epoch #2. Accuracy on batch 2445/3013  on Training is 84.4363246116108\n",
            "Epoch #2. Accuracy on batch 2446/3013  on Training is 84.4375766244381\n",
            "Epoch #2. Accuracy on batch 2447/3013  on Training is 84.43372140522875\n",
            "Epoch #2. Accuracy on batch 2448/3013  on Training is 84.43497345855451\n",
            "Epoch #2. Accuracy on batch 2449/3013  on Training is 84.43367346938776\n",
            "Epoch #2. Accuracy on batch 2450/3013  on Training is 84.42854957160343\n",
            "Epoch #2. Accuracy on batch 2451/3013  on Training is 84.43362561174551\n",
            "Epoch #2. Accuracy on batch 2452/3013  on Training is 84.42977986139421\n",
            "Epoch #2. Accuracy on batch 2453/3013  on Training is 84.42975753871231\n",
            "Epoch #2. Accuracy on batch 2454/3013  on Training is 84.43228105906314\n",
            "Epoch #2. Accuracy on batch 2455/3013  on Training is 84.43607491856677\n",
            "Epoch #2. Accuracy on batch 2456/3013  on Training is 84.43859381359381\n",
            "Epoch #2. Accuracy on batch 2457/3013  on Training is 84.43856794141578\n",
            "Epoch #2. Accuracy on batch 2458/3013  on Training is 84.4385420902806\n",
            "Epoch #2. Accuracy on batch 2459/3013  on Training is 84.4410569105691\n",
            "Batch Id 2460 is having training loss of 0.5533357262611389\n",
            "0.5847184658050537\n",
            "Epoch #2. Accuracy on batch 2460/3013  on Training is 84.43976026005689\n",
            "Epoch #2. Accuracy on batch 2461/3013  on Training is 84.43846466287572\n",
            "Epoch #2. Accuracy on batch 2462/3013  on Training is 84.43336378400325\n",
            "Epoch #2. Accuracy on batch 2463/3013  on Training is 84.43334009740259\n",
            "Epoch #2. Accuracy on batch 2464/3013  on Training is 84.43585192697769\n",
            "Epoch #2. Accuracy on batch 2465/3013  on Training is 84.43329278183293\n",
            "Epoch #2. Accuracy on batch 2466/3013  on Training is 84.42946899067694\n",
            "Epoch #2. Accuracy on batch 2467/3013  on Training is 84.42438209076175\n",
            "Epoch #2. Accuracy on batch 2468/3013  on Training is 84.41929931146213\n",
            "Epoch #2. Accuracy on batch 2469/3013  on Training is 84.42054655870446\n",
            "Epoch #2. Accuracy on batch 2470/3013  on Training is 84.42052812626467\n",
            "Epoch #2. Accuracy on batch 2471/3013  on Training is 84.41924555016182\n",
            "Epoch #2. Accuracy on batch 2472/3013  on Training is 84.4192276587141\n",
            "Epoch #2. Accuracy on batch 2473/3013  on Training is 84.41794664510914\n",
            "Epoch #2. Accuracy on batch 2474/3013  on Training is 84.41540404040404\n",
            "Epoch #2. Accuracy on batch 2475/3013  on Training is 84.41286348949919\n",
            "Epoch #2. Accuracy on batch 2476/3013  on Training is 84.41032498990715\n",
            "Epoch #2. Accuracy on batch 2477/3013  on Training is 84.40652744148507\n",
            "Epoch #2. Accuracy on batch 2478/3013  on Training is 84.40525413473175\n",
            "Epoch #2. Accuracy on batch 2479/3013  on Training is 84.40776209677419\n",
            "Batch Id 2480 is having training loss of 0.5540563464164734\n",
            "0.6519260406494141\n",
            "Epoch #2. Accuracy on batch 2480/3013  on Training is 84.40774889157598\n",
            "Epoch #2. Accuracy on batch 2481/3013  on Training is 84.40773569701854\n",
            "Epoch #2. Accuracy on batch 2482/3013  on Training is 84.40646395489327\n",
            "Epoch #2. Accuracy on batch 2483/3013  on Training is 84.40519323671498\n",
            "Epoch #2. Accuracy on batch 2484/3013  on Training is 84.40643863179075\n",
            "Epoch #2. Accuracy on batch 2485/3013  on Training is 84.40894006436042\n",
            "Epoch #2. Accuracy on batch 2486/3013  on Training is 84.4051568154403\n",
            "Epoch #2. Accuracy on batch 2487/3013  on Training is 84.40263263665595\n",
            "Epoch #2. Accuracy on batch 2488/3013  on Training is 84.40136601044597\n",
            "Epoch #2. Accuracy on batch 2489/3013  on Training is 84.3988453815261\n",
            "Epoch #2. Accuracy on batch 2490/3013  on Training is 84.39758129265356\n",
            "Epoch #2. Accuracy on batch 2491/3013  on Training is 84.39631821829856\n",
            "Epoch #2. Accuracy on batch 2492/3013  on Training is 84.39881668672282\n",
            "Epoch #2. Accuracy on batch 2493/3013  on Training is 84.39880713712911\n",
            "Epoch #2. Accuracy on batch 2494/3013  on Training is 84.39879759519039\n",
            "Epoch #2. Accuracy on batch 2495/3013  on Training is 84.39878806089743\n",
            "Epoch #2. Accuracy on batch 2496/3013  on Training is 84.40128153784542\n",
            "Epoch #2. Accuracy on batch 2497/3013  on Training is 84.40002001601282\n",
            "Epoch #2. Accuracy on batch 2498/3013  on Training is 84.39875950380151\n",
            "Epoch #2. Accuracy on batch 2499/3013  on Training is 84.39625\n",
            "Batch Id 2500 is having training loss of 0.5542725920677185\n",
            "0.5551303029060364\n",
            "Epoch #2. Accuracy on batch 2500/3013  on Training is 84.39624150339864\n",
            "Epoch #2. Accuracy on batch 2501/3013  on Training is 84.39623301358912\n",
            "Epoch #2. Accuracy on batch 2502/3013  on Training is 84.39497602876548\n",
            "Epoch #2. Accuracy on batch 2503/3013  on Training is 84.39496805111821\n",
            "Epoch #2. Accuracy on batch 2504/3013  on Training is 84.39496007984032\n",
            "Epoch #2. Accuracy on batch 2505/3013  on Training is 84.39619912210695\n",
            "Epoch #2. Accuracy on batch 2506/3013  on Training is 84.38995811727163\n",
            "Epoch #2. Accuracy on batch 2507/3013  on Training is 84.38995215311004\n",
            "Epoch #2. Accuracy on batch 2508/3013  on Training is 84.38496412913511\n",
            "Epoch #2. Accuracy on batch 2509/3013  on Training is 84.38247011952191\n",
            "Epoch #2. Accuracy on batch 2510/3013  on Training is 84.38371166865791\n",
            "Epoch #2. Accuracy on batch 2511/3013  on Training is 84.3812201433121\n",
            "Epoch #2. Accuracy on batch 2512/3013  on Training is 84.3799741345006\n",
            "Epoch #2. Accuracy on batch 2513/3013  on Training is 84.37872911694511\n",
            "Epoch #2. Accuracy on batch 2514/3013  on Training is 84.37748508946322\n",
            "Epoch #2. Accuracy on batch 2515/3013  on Training is 84.37996820349761\n",
            "Epoch #2. Accuracy on batch 2516/3013  on Training is 84.37996622963846\n",
            "Epoch #2. Accuracy on batch 2517/3013  on Training is 84.38244638602065\n",
            "Epoch #2. Accuracy on batch 2518/3013  on Training is 84.37996228662168\n",
            "Epoch #2. Accuracy on batch 2519/3013  on Training is 84.37996031746032\n",
            "Batch Id 2520 is having training loss of 0.5549671649932861\n",
            "0.8476331233978271\n",
            "Epoch #2. Accuracy on batch 2520/3013  on Training is 84.37747917493058\n",
            "Epoch #2. Accuracy on batch 2521/3013  on Training is 84.37747819191118\n",
            "Epoch #2. Accuracy on batch 2522/3013  on Training is 84.3762386048355\n",
            "Epoch #2. Accuracy on batch 2523/3013  on Training is 84.37871434231378\n",
            "Epoch #2. Accuracy on batch 2524/3013  on Training is 84.38118811881188\n",
            "Epoch #2. Accuracy on batch 2525/3013  on Training is 84.37871140142518\n",
            "Epoch #2. Accuracy on batch 2526/3013  on Training is 84.37994657696873\n",
            "Epoch #2. Accuracy on batch 2527/3013  on Training is 84.38118077531645\n",
            "Epoch #2. Accuracy on batch 2528/3013  on Training is 84.37870699881375\n",
            "Epoch #2. Accuracy on batch 2529/3013  on Training is 84.37747035573122\n",
            "Epoch #2. Accuracy on batch 2530/3013  on Training is 84.37623468984592\n",
            "Epoch #2. Accuracy on batch 2531/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 2532/3013  on Training is 84.37253257007501\n",
            "Epoch #2. Accuracy on batch 2533/3013  on Training is 84.37130031570639\n",
            "Epoch #2. Accuracy on batch 2534/3013  on Training is 84.37253451676528\n",
            "Epoch #2. Accuracy on batch 2535/3013  on Training is 84.37130323343848\n",
            "Epoch #2. Accuracy on batch 2536/3013  on Training is 84.37253646038629\n",
            "Epoch #2. Accuracy on batch 2537/3013  on Training is 84.36884357762017\n",
            "Epoch #2. Accuracy on batch 2538/3013  on Training is 84.36761520283576\n",
            "Epoch #2. Accuracy on batch 2539/3013  on Training is 84.36392716535433\n",
            "Batch Id 2540 is having training loss of 0.5553520917892456\n",
            "0.7275775671005249\n",
            "Epoch #2. Accuracy on batch 2540/3013  on Training is 84.36147186147186\n",
            "Epoch #2. Accuracy on batch 2541/3013  on Training is 84.35655979543667\n",
            "Epoch #2. Accuracy on batch 2542/3013  on Training is 84.35779591034212\n",
            "Epoch #2. Accuracy on batch 2543/3013  on Training is 84.35534591194968\n",
            "Epoch #2. Accuracy on batch 2544/3013  on Training is 84.35412573673871\n",
            "Epoch #2. Accuracy on batch 2545/3013  on Training is 84.35167910447761\n",
            "Epoch #2. Accuracy on batch 2546/3013  on Training is 84.35414212799371\n",
            "Epoch #2. Accuracy on batch 2547/3013  on Training is 84.35292386185243\n",
            "Epoch #2. Accuracy on batch 2548/3013  on Training is 84.35048058061984\n",
            "Epoch #2. Accuracy on batch 2549/3013  on Training is 84.35171568627452\n",
            "Epoch #2. Accuracy on batch 2550/3013  on Training is 84.35172481379851\n",
            "Epoch #2. Accuracy on batch 2551/3013  on Training is 84.35050940438872\n",
            "Epoch #2. Accuracy on batch 2552/3013  on Training is 84.34929494712104\n",
            "Epoch #2. Accuracy on batch 2553/3013  on Training is 84.35052858261551\n",
            "Epoch #2. Accuracy on batch 2554/3013  on Training is 84.35053816046967\n",
            "Epoch #2. Accuracy on batch 2555/3013  on Training is 84.35543818466354\n",
            "Epoch #2. Accuracy on batch 2556/3013  on Training is 84.35544583496285\n",
            "Epoch #2. Accuracy on batch 2557/3013  on Training is 84.35545347928068\n",
            "Epoch #2. Accuracy on batch 2558/3013  on Training is 84.35790347792106\n",
            "Epoch #2. Accuracy on batch 2559/3013  on Training is 84.35546875\n",
            "Batch Id 2560 is having training loss of 0.5554665327072144\n",
            "0.6981554627418518\n",
            "Epoch #2. Accuracy on batch 2560/3013  on Training is 84.35181569699336\n",
            "Epoch #2. Accuracy on batch 2561/3013  on Training is 84.3506049960968\n",
            "Epoch #2. Accuracy on batch 2562/3013  on Training is 84.35427233710496\n",
            "Epoch #2. Accuracy on batch 2563/3013  on Training is 84.35428042121684\n",
            "Epoch #2. Accuracy on batch 2564/3013  on Training is 84.3530701754386\n",
            "Epoch #2. Accuracy on batch 2565/3013  on Training is 84.35064302416212\n",
            "Epoch #2. Accuracy on batch 2566/3013  on Training is 84.35065251266069\n",
            "Epoch #2. Accuracy on batch 2567/3013  on Training is 84.35552959501558\n",
            "Epoch #2. Accuracy on batch 2568/3013  on Training is 84.35675360062281\n",
            "Epoch #2. Accuracy on batch 2569/3013  on Training is 84.36162451361868\n",
            "Epoch #2. Accuracy on batch 2570/3013  on Training is 84.36406067677946\n",
            "Epoch #2. Accuracy on batch 2571/3013  on Training is 84.36649494556765\n",
            "Epoch #2. Accuracy on batch 2572/3013  on Training is 84.36528371550719\n",
            "Epoch #2. Accuracy on batch 2573/3013  on Training is 84.37014374514375\n",
            "Epoch #2. Accuracy on batch 2574/3013  on Training is 84.36771844660194\n",
            "Epoch #2. Accuracy on batch 2575/3013  on Training is 84.36772127329192\n",
            "Epoch #2. Accuracy on batch 2576/3013  on Training is 84.36893674815677\n",
            "Epoch #2. Accuracy on batch 2577/3013  on Training is 84.36772692009309\n",
            "Epoch #2. Accuracy on batch 2578/3013  on Training is 84.36772974020938\n",
            "Epoch #2. Accuracy on batch 2579/3013  on Training is 84.36531007751938\n",
            "Batch Id 2580 is having training loss of 0.555213212966919\n",
            "0.5100809335708618\n",
            "Epoch #2. Accuracy on batch 2580/3013  on Training is 84.36410306082914\n",
            "Epoch #2. Accuracy on batch 2581/3013  on Training is 84.36652788536018\n",
            "Epoch #2. Accuracy on batch 2582/3013  on Training is 84.36411149825784\n",
            "Epoch #2. Accuracy on batch 2583/3013  on Training is 84.359278250774\n",
            "Epoch #2. Accuracy on batch 2584/3013  on Training is 84.36170212765957\n",
            "Epoch #2. Accuracy on batch 2585/3013  on Training is 84.35808197989172\n",
            "Epoch #2. Accuracy on batch 2586/3013  on Training is 84.35808851952068\n",
            "Epoch #2. Accuracy on batch 2587/3013  on Training is 84.35205757341576\n",
            "Epoch #2. Accuracy on batch 2588/3013  on Training is 84.34965237543453\n",
            "Epoch #2. Accuracy on batch 2589/3013  on Training is 84.3484555984556\n",
            "Epoch #2. Accuracy on batch 2590/3013  on Training is 84.3472597452721\n",
            "Epoch #2. Accuracy on batch 2591/3013  on Training is 84.34485918209876\n",
            "Epoch #2. Accuracy on batch 2592/3013  on Training is 84.33763979946008\n",
            "Epoch #2. Accuracy on batch 2593/3013  on Training is 84.33765420200463\n",
            "Epoch #2. Accuracy on batch 2594/3013  on Training is 84.34007707129095\n",
            "Epoch #2. Accuracy on batch 2595/3013  on Training is 84.34249807395994\n",
            "Epoch #2. Accuracy on batch 2596/3013  on Training is 84.34491721216789\n",
            "Epoch #2. Accuracy on batch 2597/3013  on Training is 84.34252309468822\n",
            "Epoch #2. Accuracy on batch 2598/3013  on Training is 84.34494036167757\n",
            "Epoch #2. Accuracy on batch 2599/3013  on Training is 84.3485576923077\n",
            "Batch Id 2600 is having training loss of 0.5557342171669006\n",
            "0.423261821269989\n",
            "Epoch #2. Accuracy on batch 2600/3013  on Training is 84.34856785851595\n",
            "Epoch #2. Accuracy on batch 2601/3013  on Training is 84.34857801691007\n",
            "Epoch #2. Accuracy on batch 2602/3013  on Training is 84.35098924318095\n",
            "Epoch #2. Accuracy on batch 2603/3013  on Training is 84.35219854070661\n",
            "Epoch #2. Accuracy on batch 2604/3013  on Training is 84.35700575815738\n",
            "Epoch #2. Accuracy on batch 2605/3013  on Training is 84.35821181887951\n",
            "Epoch #2. Accuracy on batch 2606/3013  on Training is 84.36061565017262\n",
            "Epoch #2. Accuracy on batch 2607/3013  on Training is 84.36301763803681\n",
            "Epoch #2. Accuracy on batch 2608/3013  on Training is 84.36302223073974\n",
            "Epoch #2. Accuracy on batch 2609/3013  on Training is 84.36063218390805\n",
            "Epoch #2. Accuracy on batch 2610/3013  on Training is 84.36063768671008\n",
            "Epoch #2. Accuracy on batch 2611/3013  on Training is 84.36183958652374\n",
            "Epoch #2. Accuracy on batch 2612/3013  on Training is 84.36543245311903\n",
            "Epoch #2. Accuracy on batch 2613/3013  on Training is 84.36065416985463\n",
            "Epoch #2. Accuracy on batch 2614/3013  on Training is 84.36065965583174\n",
            "Epoch #2. Accuracy on batch 2615/3013  on Training is 84.36424885321101\n",
            "Epoch #2. Accuracy on batch 2616/3013  on Training is 84.36186473060756\n",
            "Epoch #2. Accuracy on batch 2617/3013  on Training is 84.36545072574485\n",
            "Epoch #2. Accuracy on batch 2618/3013  on Training is 84.36664757541047\n",
            "Epoch #2. Accuracy on batch 2619/3013  on Training is 84.36665076335878\n",
            "Batch Id 2620 is having training loss of 0.5556264519691467\n",
            "0.9398366212844849\n",
            "Epoch #2. Accuracy on batch 2620/3013  on Training is 84.36188477680275\n",
            "Epoch #2. Accuracy on batch 2621/3013  on Training is 84.36069794050343\n",
            "Epoch #2. Accuracy on batch 2622/3013  on Training is 84.36308616088448\n",
            "Epoch #2. Accuracy on batch 2623/3013  on Training is 84.36666349085365\n",
            "Epoch #2. Accuracy on batch 2624/3013  on Training is 84.36904761904762\n",
            "Epoch #2. Accuracy on batch 2625/3013  on Training is 84.3690498857578\n",
            "Epoch #2. Accuracy on batch 2626/3013  on Training is 84.36786258089074\n",
            "Epoch #2. Accuracy on batch 2627/3013  on Training is 84.36667617960426\n",
            "Epoch #2. Accuracy on batch 2628/3013  on Training is 84.36786801065044\n",
            "Epoch #2. Accuracy on batch 2629/3013  on Training is 84.36787072243347\n",
            "Epoch #2. Accuracy on batch 2630/3013  on Training is 84.36906119346256\n",
            "Epoch #2. Accuracy on batch 2631/3013  on Training is 84.37025075987842\n",
            "Epoch #2. Accuracy on batch 2632/3013  on Training is 84.37262628180783\n",
            "Epoch #2. Accuracy on batch 2633/3013  on Training is 84.37381359149582\n",
            "Epoch #2. Accuracy on batch 2634/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 2635/3013  on Training is 84.37618550834598\n",
            "Epoch #2. Accuracy on batch 2636/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 2637/3013  on Training is 84.3738153904473\n",
            "Epoch #2. Accuracy on batch 2638/3013  on Training is 84.37263167866617\n",
            "Epoch #2. Accuracy on batch 2639/3013  on Training is 84.37618371212122\n",
            "Batch Id 2640 is having training loss of 0.5553060173988342\n",
            "0.3475196659564972\n",
            "Epoch #2. Accuracy on batch 2640/3013  on Training is 84.37618326391518\n",
            "Epoch #2. Accuracy on batch 2641/3013  on Training is 84.37381718395156\n",
            "Epoch #2. Accuracy on batch 2642/3013  on Training is 84.37618236852062\n",
            "Epoch #2. Accuracy on batch 2643/3013  on Training is 84.37854576399396\n",
            "Epoch #2. Accuracy on batch 2644/3013  on Training is 84.3773629489603\n",
            "Epoch #2. Accuracy on batch 2645/3013  on Training is 84.38090513983371\n",
            "Epoch #2. Accuracy on batch 2646/3013  on Training is 84.38090290895353\n",
            "Epoch #2. Accuracy on batch 2647/3013  on Training is 84.37736027190333\n",
            "Epoch #2. Accuracy on batch 2648/3013  on Training is 84.37735938089845\n",
            "Epoch #2. Accuracy on batch 2649/3013  on Training is 84.37382075471699\n",
            "Epoch #2. Accuracy on batch 2650/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 2651/3013  on Training is 84.3785350678733\n",
            "Epoch #2. Accuracy on batch 2652/3013  on Training is 84.37735582359593\n",
            "Epoch #2. Accuracy on batch 2653/3013  on Training is 84.37382253202713\n",
            "Epoch #2. Accuracy on batch 2654/3013  on Training is 84.36793785310735\n",
            "Epoch #2. Accuracy on batch 2655/3013  on Training is 84.36441076807229\n",
            "Epoch #2. Accuracy on batch 2656/3013  on Training is 84.3667670304855\n",
            "Epoch #2. Accuracy on batch 2657/3013  on Training is 84.36559443190369\n",
            "Epoch #2. Accuracy on batch 2658/3013  on Training is 84.36559796916134\n",
            "Epoch #2. Accuracy on batch 2659/3013  on Training is 84.36677631578948\n",
            "Batch Id 2660 is having training loss of 0.555677056312561\n",
            "0.4112592339515686\n",
            "Epoch #2. Accuracy on batch 2660/3013  on Training is 84.36677940623825\n",
            "Epoch #2. Accuracy on batch 2661/3013  on Training is 84.36443463561233\n",
            "Epoch #2. Accuracy on batch 2662/3013  on Training is 84.36326511453248\n",
            "Epoch #2. Accuracy on batch 2663/3013  on Training is 84.36209647147147\n",
            "Epoch #2. Accuracy on batch 2664/3013  on Training is 84.35975609756098\n",
            "Epoch #2. Accuracy on batch 2665/3013  on Training is 84.36327831957989\n",
            "Epoch #2. Accuracy on batch 2666/3013  on Training is 84.35976752905887\n",
            "Epoch #2. Accuracy on batch 2667/3013  on Training is 84.3644583958021\n",
            "Epoch #2. Accuracy on batch 2668/3013  on Training is 84.36329149494192\n",
            "Epoch #2. Accuracy on batch 2669/3013  on Training is 84.36680711610487\n",
            "Epoch #2. Accuracy on batch 2670/3013  on Training is 84.36681018345189\n",
            "Epoch #2. Accuracy on batch 2671/3013  on Training is 84.36798278443113\n",
            "Epoch #2. Accuracy on batch 2672/3013  on Training is 84.36798540965208\n",
            "Epoch #2. Accuracy on batch 2673/3013  on Training is 84.37149401645475\n",
            "Epoch #2. Accuracy on batch 2674/3013  on Training is 84.3714953271028\n",
            "Epoch #2. Accuracy on batch 2675/3013  on Training is 84.3703288490284\n",
            "Epoch #2. Accuracy on batch 2676/3013  on Training is 84.37033059394845\n",
            "Epoch #2. Accuracy on batch 2677/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 2678/3013  on Training is 84.37616648002987\n",
            "Epoch #2. Accuracy on batch 2679/3013  on Training is 84.37616604477611\n",
            "Batch Id 2680 is having training loss of 0.5556237101554871\n",
            "0.5057364106178284\n",
            "Epoch #2. Accuracy on batch 2680/3013  on Training is 84.37733121969414\n",
            "Epoch #2. Accuracy on batch 2681/3013  on Training is 84.37849552572708\n",
            "Epoch #2. Accuracy on batch 2682/3013  on Training is 84.38082370480805\n",
            "Epoch #2. Accuracy on batch 2683/3013  on Training is 84.38082153502235\n",
            "Epoch #2. Accuracy on batch 2684/3013  on Training is 84.38314711359403\n",
            "Epoch #2. Accuracy on batch 2685/3013  on Training is 84.38430752047654\n",
            "Epoch #2. Accuracy on batch 2686/3013  on Training is 84.38663007071084\n",
            "Epoch #2. Accuracy on batch 2687/3013  on Training is 84.38662574404762\n",
            "Epoch #2. Accuracy on batch 2688/3013  on Training is 84.38313499442172\n",
            "Epoch #2. Accuracy on batch 2689/3013  on Training is 84.38080855018588\n",
            "Epoch #2. Accuracy on batch 2690/3013  on Training is 84.38080639167596\n",
            "Epoch #2. Accuracy on batch 2691/3013  on Training is 84.37964338781575\n",
            "Epoch #2. Accuracy on batch 2692/3013  on Training is 84.37964166357223\n",
            "Epoch #2. Accuracy on batch 2693/3013  on Training is 84.37847995545657\n",
            "Epoch #2. Accuracy on batch 2694/3013  on Training is 84.37731910946196\n",
            "Epoch #2. Accuracy on batch 2695/3013  on Training is 84.3807956231454\n",
            "Epoch #2. Accuracy on batch 2696/3013  on Training is 84.3796347793845\n",
            "Epoch #2. Accuracy on batch 2697/3013  on Training is 84.38079132690882\n",
            "Epoch #2. Accuracy on batch 2698/3013  on Training is 84.37963134494257\n",
            "Epoch #2. Accuracy on batch 2699/3013  on Training is 84.37962962962963\n",
            "Batch Id 2700 is having training loss of 0.5555686950683594\n",
            "0.648792564868927\n",
            "Epoch #2. Accuracy on batch 2700/3013  on Training is 84.37847093669012\n",
            "Epoch #2. Accuracy on batch 2701/3013  on Training is 84.38425240562546\n",
            "Epoch #2. Accuracy on batch 2702/3013  on Training is 84.38193673695893\n",
            "Epoch #2. Accuracy on batch 2703/3013  on Training is 84.38077847633136\n",
            "Epoch #2. Accuracy on batch 2704/3013  on Training is 84.37846580406655\n",
            "Epoch #2. Accuracy on batch 2705/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 2706/3013  on Training is 84.37730882896194\n",
            "Epoch #2. Accuracy on batch 2707/3013  on Training is 84.37961595273265\n",
            "Epoch #2. Accuracy on batch 2708/3013  on Training is 84.37730712440015\n",
            "Epoch #2. Accuracy on batch 2709/3013  on Training is 84.37384686346863\n",
            "Epoch #2. Accuracy on batch 2710/3013  on Training is 84.37384728882331\n",
            "Epoch #2. Accuracy on batch 2711/3013  on Training is 84.37384771386431\n",
            "Epoch #2. Accuracy on batch 2712/3013  on Training is 84.37039255436785\n",
            "Epoch #2. Accuracy on batch 2713/3013  on Training is 84.3715456890199\n",
            "Epoch #2. Accuracy on batch 2714/3013  on Training is 84.37269797421732\n",
            "Epoch #2. Accuracy on batch 2715/3013  on Training is 84.37154823269513\n",
            "Epoch #2. Accuracy on batch 2716/3013  on Training is 84.36924917188075\n",
            "Epoch #2. Accuracy on batch 2717/3013  on Training is 84.37040103016925\n",
            "Epoch #2. Accuracy on batch 2718/3013  on Training is 84.37040272158882\n",
            "Epoch #2. Accuracy on batch 2719/3013  on Training is 84.37040441176471\n",
            "Batch Id 2720 is having training loss of 0.5560204386711121\n",
            "0.44349589943885803\n",
            "Epoch #2. Accuracy on batch 2720/3013  on Training is 84.37385152517457\n",
            "Epoch #2. Accuracy on batch 2721/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 2722/3013  on Training is 84.37844289386706\n",
            "Epoch #2. Accuracy on batch 2723/3013  on Training is 84.38073604992658\n",
            "Epoch #2. Accuracy on batch 2724/3013  on Training is 84.38073394495413\n",
            "Epoch #2. Accuracy on batch 2725/3013  on Training is 84.38187820983126\n",
            "Epoch #2. Accuracy on batch 2726/3013  on Training is 84.38072973964063\n",
            "Epoch #2. Accuracy on batch 2727/3013  on Training is 84.37843658357771\n",
            "Epoch #2. Accuracy on batch 2728/3013  on Training is 84.37843532429461\n",
            "Epoch #2. Accuracy on batch 2729/3013  on Training is 84.37843406593407\n",
            "Epoch #2. Accuracy on batch 2730/3013  on Training is 84.37728853899671\n",
            "Epoch #2. Accuracy on batch 2731/3013  on Training is 84.37843155197658\n",
            "Epoch #2. Accuracy on batch 2732/3013  on Training is 84.37385656787413\n",
            "Epoch #2. Accuracy on batch 2733/3013  on Training is 84.36928493050476\n",
            "Epoch #2. Accuracy on batch 2734/3013  on Training is 84.37157221206581\n",
            "Epoch #2. Accuracy on batch 2735/3013  on Training is 84.37271564327486\n",
            "Epoch #2. Accuracy on batch 2736/3013  on Training is 84.37157471684326\n",
            "Epoch #2. Accuracy on batch 2737/3013  on Training is 84.37157596785975\n",
            "Epoch #2. Accuracy on batch 2738/3013  on Training is 84.37614092734574\n",
            "Epoch #2. Accuracy on batch 2739/3013  on Training is 84.375\n",
            "Batch Id 2740 is having training loss of 0.5557831525802612\n",
            "0.2658422589302063\n",
            "Epoch #2. Accuracy on batch 2740/3013  on Training is 84.37728018971178\n",
            "Epoch #2. Accuracy on batch 2741/3013  on Training is 84.37386032093363\n",
            "Epoch #2. Accuracy on batch 2742/3013  on Training is 84.37841779074006\n",
            "Epoch #2. Accuracy on batch 2743/3013  on Training is 84.37841654518951\n",
            "Epoch #2. Accuracy on batch 2744/3013  on Training is 84.38069216757741\n",
            "Epoch #2. Accuracy on batch 2745/3013  on Training is 84.3784140568099\n",
            "Epoch #2. Accuracy on batch 2746/3013  on Training is 84.38068802329815\n",
            "Epoch #2. Accuracy on batch 2747/3013  on Training is 84.38296033478893\n",
            "Epoch #2. Accuracy on batch 2748/3013  on Training is 84.38295743906875\n",
            "Epoch #2. Accuracy on batch 2749/3013  on Training is 84.38522727272728\n",
            "Epoch #2. Accuracy on batch 2750/3013  on Training is 84.38749545619774\n",
            "Epoch #2. Accuracy on batch 2751/3013  on Training is 84.38749091569767\n",
            "Epoch #2. Accuracy on batch 2752/3013  on Training is 84.3908917544497\n",
            "Epoch #2. Accuracy on batch 2753/3013  on Training is 84.38975127087872\n",
            "Epoch #2. Accuracy on batch 2754/3013  on Training is 84.38747731397459\n",
            "Epoch #2. Accuracy on batch 2755/3013  on Training is 84.38747278664731\n",
            "Epoch #2. Accuracy on batch 2756/3013  on Training is 84.3863347841857\n",
            "Epoch #2. Accuracy on batch 2757/3013  on Training is 84.38519760696157\n",
            "Epoch #2. Accuracy on batch 2758/3013  on Training is 84.39085719463574\n",
            "Epoch #2. Accuracy on batch 2759/3013  on Training is 84.39198369565217\n",
            "Batch Id 2760 is having training loss of 0.5554416179656982\n",
            "0.45155489444732666\n",
            "Epoch #2. Accuracy on batch 2760/3013  on Training is 84.39424121695038\n",
            "Epoch #2. Accuracy on batch 2761/3013  on Training is 84.39649710354816\n",
            "Epoch #2. Accuracy on batch 2762/3013  on Training is 84.39309627216794\n",
            "Epoch #2. Accuracy on batch 2763/3013  on Training is 84.39308972503618\n",
            "Epoch #2. Accuracy on batch 2764/3013  on Training is 84.39308318264014\n",
            "Epoch #2. Accuracy on batch 2765/3013  on Training is 84.39759580621836\n",
            "Epoch #2. Accuracy on batch 2766/3013  on Training is 84.39871702204553\n",
            "Epoch #2. Accuracy on batch 2767/3013  on Training is 84.39757947976878\n",
            "Epoch #2. Accuracy on batch 2768/3013  on Training is 84.39869989165764\n",
            "Epoch #2. Accuracy on batch 2769/3013  on Training is 84.39643501805054\n",
            "Epoch #2. Accuracy on batch 2770/3013  on Training is 84.39642728256948\n",
            "Epoch #2. Accuracy on batch 2771/3013  on Training is 84.39641955266956\n",
            "Epoch #2. Accuracy on batch 2772/3013  on Training is 84.3975387666787\n",
            "Epoch #2. Accuracy on batch 2773/3013  on Training is 84.39753064167267\n",
            "Epoch #2. Accuracy on batch 2774/3013  on Training is 84.39864864864865\n",
            "Epoch #2. Accuracy on batch 2775/3013  on Training is 84.39976585014409\n",
            "Epoch #2. Accuracy on batch 2776/3013  on Training is 84.39525567158805\n",
            "Epoch #2. Accuracy on batch 2777/3013  on Training is 84.39524838012959\n",
            "Epoch #2. Accuracy on batch 2778/3013  on Training is 84.39074307304786\n",
            "Epoch #2. Accuracy on batch 2779/3013  on Training is 84.38961330935251\n",
            "Batch Id 2780 is having training loss of 0.555679202079773\n",
            "0.3497142791748047\n",
            "Epoch #2. Accuracy on batch 2780/3013  on Training is 84.3918554476807\n",
            "Epoch #2. Accuracy on batch 2781/3013  on Training is 84.39297268152409\n",
            "Epoch #2. Accuracy on batch 2782/3013  on Training is 84.3952120014373\n",
            "Epoch #2. Accuracy on batch 2783/3013  on Training is 84.3963272270115\n",
            "Epoch #2. Accuracy on batch 2784/3013  on Training is 84.39519748653501\n",
            "Epoch #2. Accuracy on batch 2785/3013  on Training is 84.39294687724336\n",
            "Epoch #2. Accuracy on batch 2786/3013  on Training is 84.39518299246501\n",
            "Epoch #2. Accuracy on batch 2787/3013  on Training is 84.39293400286944\n",
            "Epoch #2. Accuracy on batch 2788/3013  on Training is 84.39292757260667\n",
            "Epoch #2. Accuracy on batch 2789/3013  on Training is 84.39628136200717\n",
            "Epoch #2. Accuracy on batch 2790/3013  on Training is 84.39515406664277\n",
            "Epoch #2. Accuracy on batch 2791/3013  on Training is 84.39514684813754\n",
            "Epoch #2. Accuracy on batch 2792/3013  on Training is 84.3984962406015\n",
            "Epoch #2. Accuracy on batch 2793/3013  on Training is 84.39736936292054\n",
            "Epoch #2. Accuracy on batch 2794/3013  on Training is 84.39959749552773\n",
            "Epoch #2. Accuracy on batch 2795/3013  on Training is 84.40182403433477\n",
            "Epoch #2. Accuracy on batch 2796/3013  on Training is 84.39846263854129\n",
            "Epoch #2. Accuracy on batch 2797/3013  on Training is 84.39845425303788\n",
            "Epoch #2. Accuracy on batch 2798/3013  on Training is 84.39844587352626\n",
            "Epoch #2. Accuracy on batch 2799/3013  on Training is 84.39732142857143\n",
            "Batch Id 2800 is having training loss of 0.555593729019165\n",
            "0.5697689056396484\n",
            "Epoch #2. Accuracy on batch 2800/3013  on Training is 84.39396644055694\n",
            "Epoch #2. Accuracy on batch 2801/3013  on Training is 84.39172912205568\n",
            "Epoch #2. Accuracy on batch 2802/3013  on Training is 84.39060827684624\n",
            "Epoch #2. Accuracy on batch 2803/3013  on Training is 84.38948823109843\n",
            "Epoch #2. Accuracy on batch 2804/3013  on Training is 84.38614081996435\n",
            "Epoch #2. Accuracy on batch 2805/3013  on Training is 84.3816821097648\n",
            "Epoch #2. Accuracy on batch 2806/3013  on Training is 84.3772265764161\n",
            "Epoch #2. Accuracy on batch 2807/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 2808/3013  on Training is 84.37722499110004\n",
            "Epoch #2. Accuracy on batch 2809/3013  on Training is 84.37722419928825\n",
            "Epoch #2. Accuracy on batch 2810/3013  on Training is 84.37944681607969\n",
            "Epoch #2. Accuracy on batch 2811/3013  on Training is 84.37833392603129\n",
            "Epoch #2. Accuracy on batch 2812/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 2813/3013  on Training is 84.3738894811656\n",
            "Epoch #2. Accuracy on batch 2814/3013  on Training is 84.37055950266429\n",
            "Epoch #2. Accuracy on batch 2815/3013  on Training is 84.3716708096591\n",
            "Epoch #2. Accuracy on batch 2816/3013  on Training is 84.37056265530707\n",
            "Epoch #2. Accuracy on batch 2817/3013  on Training is 84.37167317246274\n",
            "Epoch #2. Accuracy on batch 2818/3013  on Training is 84.3727829017382\n",
            "Epoch #2. Accuracy on batch 2819/3013  on Training is 84.37278368794327\n",
            "Batch Id 2820 is having training loss of 0.556275486946106\n",
            "0.6067545413970947\n",
            "Epoch #2. Accuracy on batch 2820/3013  on Training is 84.37389223679546\n",
            "Epoch #2. Accuracy on batch 2821/3013  on Training is 84.375\n",
            "Epoch #2. Accuracy on batch 2822/3013  on Training is 84.37610697839177\n",
            "Epoch #2. Accuracy on batch 2823/3013  on Training is 84.37610658640227\n",
            "Epoch #2. Accuracy on batch 2824/3013  on Training is 84.37610619469027\n",
            "Epoch #2. Accuracy on batch 2825/3013  on Training is 84.37389419674452\n",
            "Epoch #2. Accuracy on batch 2826/3013  on Training is 84.37168376370711\n",
            "Epoch #2. Accuracy on batch 2827/3013  on Training is 84.37057991513437\n",
            "Epoch #2. Accuracy on batch 2828/3013  on Training is 84.36837221633085\n",
            "Epoch #2. Accuracy on batch 2829/3013  on Training is 84.36837455830388\n",
            "Epoch #2. Accuracy on batch 2830/3013  on Training is 84.369480748852\n",
            "Epoch #2. Accuracy on batch 2831/3013  on Training is 84.37279307909604\n",
            "Epoch #2. Accuracy on batch 2832/3013  on Training is 84.37058771620191\n",
            "Epoch #2. Accuracy on batch 2833/3013  on Training is 84.3705892731122\n",
            "Epoch #2. Accuracy on batch 2834/3013  on Training is 84.37389770723104\n",
            "Epoch #2. Accuracy on batch 2835/3013  on Training is 84.37720380818054\n",
            "Epoch #2. Accuracy on batch 2836/3013  on Training is 84.37610151568558\n",
            "Epoch #2. Accuracy on batch 2837/3013  on Training is 84.37389887244538\n",
            "Epoch #2. Accuracy on batch 2838/3013  on Training is 84.37279852060584\n",
            "Epoch #2. Accuracy on batch 2839/3013  on Training is 84.36289612676056\n",
            "Batch Id 2840 is having training loss of 0.5562288165092468\n",
            "0.25081199407577515\n",
            "Epoch #2. Accuracy on batch 2840/3013  on Training is 84.36510031678986\n",
            "Epoch #2. Accuracy on batch 2841/3013  on Training is 84.36290464461646\n",
            "Epoch #2. Accuracy on batch 2842/3013  on Training is 84.36620647203658\n",
            "Epoch #2. Accuracy on batch 2843/3013  on Training is 84.36291315049226\n",
            "Epoch #2. Accuracy on batch 2844/3013  on Training is 84.36291739894551\n",
            "Epoch #2. Accuracy on batch 2845/3013  on Training is 84.3629216444132\n",
            "Epoch #2. Accuracy on batch 2846/3013  on Training is 84.36512118018967\n",
            "Epoch #2. Accuracy on batch 2847/3013  on Training is 84.3651246488764\n",
            "Epoch #2. Accuracy on batch 2848/3013  on Training is 84.36183748683749\n",
            "Epoch #2. Accuracy on batch 2849/3013  on Training is 84.36184210526316\n",
            "Epoch #2. Accuracy on batch 2850/3013  on Training is 84.36403893370748\n",
            "Epoch #2. Accuracy on batch 2851/3013  on Training is 84.36623422159887\n",
            "Epoch #2. Accuracy on batch 2852/3013  on Training is 84.36076060287417\n",
            "Epoch #2. Accuracy on batch 2853/3013  on Training is 84.35857568325157\n",
            "Epoch #2. Accuracy on batch 2854/3013  on Training is 84.35639229422067\n",
            "Epoch #2. Accuracy on batch 2855/3013  on Training is 84.35530462184875\n",
            "Epoch #2. Accuracy on batch 2856/3013  on Training is 84.35421771088555\n",
            "Epoch #2. Accuracy on batch 2857/3013  on Training is 84.35641182645206\n",
            "Epoch #2. Accuracy on batch 2858/3013  on Training is 84.35641832808675\n",
            "Epoch #2. Accuracy on batch 2859/3013  on Training is 84.35861013986013\n",
            "Batch Id 2860 is having training loss of 0.5563830733299255\n",
            "0.49232217669487\n",
            "Epoch #2. Accuracy on batch 2860/3013  on Training is 84.36080041943376\n",
            "Epoch #2. Accuracy on batch 2861/3013  on Training is 84.36189727463312\n",
            "Epoch #2. Accuracy on batch 2862/3013  on Training is 84.36081033880545\n",
            "Epoch #2. Accuracy on batch 2863/3013  on Training is 84.36081529329608\n",
            "Epoch #2. Accuracy on batch 2864/3013  on Training is 84.3608202443281\n",
            "Epoch #2. Accuracy on batch 2865/3013  on Training is 84.36300593161201\n",
            "Epoch #2. Accuracy on batch 2866/3013  on Training is 84.364100104639\n",
            "Epoch #2. Accuracy on batch 2867/3013  on Training is 84.36628312412832\n",
            "Epoch #2. Accuracy on batch 2868/3013  on Training is 84.36410770303242\n",
            "Epoch #2. Accuracy on batch 2869/3013  on Training is 84.36411149825784\n",
            "Epoch #2. Accuracy on batch 2870/3013  on Training is 84.36411529083942\n",
            "Epoch #2. Accuracy on batch 2871/3013  on Training is 84.36520717270194\n",
            "Epoch #2. Accuracy on batch 2872/3013  on Training is 84.36521058127393\n",
            "Epoch #2. Accuracy on batch 2873/3013  on Training is 84.3597773138483\n",
            "Epoch #2. Accuracy on batch 2874/3013  on Training is 84.36195652173913\n",
            "Epoch #2. Accuracy on batch 2875/3013  on Training is 84.36196105702365\n",
            "Epoch #2. Accuracy on batch 2876/3013  on Training is 84.36087938825165\n",
            "Epoch #2. Accuracy on batch 2877/3013  on Training is 84.35979847116053\n",
            "Epoch #2. Accuracy on batch 2878/3013  on Training is 84.3554619659604\n",
            "Epoch #2. Accuracy on batch 2879/3013  on Training is 84.35763888888889\n",
            "Batch Id 2880 is having training loss of 0.5561432838439941\n",
            "0.33070915937423706\n",
            "Epoch #2. Accuracy on batch 2880/3013  on Training is 84.35656022214509\n",
            "Epoch #2. Accuracy on batch 2881/3013  on Training is 84.35765093684941\n",
            "Epoch #2. Accuracy on batch 2882/3013  on Training is 84.360908775581\n",
            "Epoch #2. Accuracy on batch 2883/3013  on Training is 84.36091366158114\n",
            "Epoch #2. Accuracy on batch 2884/3013  on Training is 84.35550259965338\n",
            "Epoch #2. Accuracy on batch 2885/3013  on Training is 84.35550935550935\n",
            "Epoch #2. Accuracy on batch 2886/3013  on Training is 84.35551610668514\n",
            "Epoch #2. Accuracy on batch 2887/3013  on Training is 84.35768698060942\n",
            "Epoch #2. Accuracy on batch 2888/3013  on Training is 84.36093804084459\n",
            "Epoch #2. Accuracy on batch 2889/3013  on Training is 84.36310553633218\n",
            "Epoch #2. Accuracy on batch 2890/3013  on Training is 84.35986682808716\n",
            "Epoch #2. Accuracy on batch 2891/3013  on Training is 84.36095262793914\n",
            "Epoch #2. Accuracy on batch 2892/3013  on Training is 84.3566367092983\n",
            "Epoch #2. Accuracy on batch 2893/3013  on Training is 84.35988251554942\n",
            "Epoch #2. Accuracy on batch 2894/3013  on Training is 84.36204663212435\n",
            "Epoch #2. Accuracy on batch 2895/3013  on Training is 84.35881388121547\n",
            "Epoch #2. Accuracy on batch 2896/3013  on Training is 84.35774076630997\n",
            "Epoch #2. Accuracy on batch 2897/3013  on Training is 84.35774672187716\n",
            "Epoch #2. Accuracy on batch 2898/3013  on Training is 84.35775267333564\n",
            "Epoch #2. Accuracy on batch 2899/3013  on Training is 84.35775862068965\n",
            "Batch Id 2900 is having training loss of 0.5561655759811401\n",
            "0.8860384821891785\n",
            "Epoch #2. Accuracy on batch 2900/3013  on Training is 84.35668734918994\n",
            "Epoch #2. Accuracy on batch 2901/3013  on Training is 84.36100103376981\n",
            "Epoch #2. Accuracy on batch 2902/3013  on Training is 84.36208232862556\n",
            "Epoch #2. Accuracy on batch 2903/3013  on Training is 84.36423898071625\n",
            "Epoch #2. Accuracy on batch 2904/3013  on Training is 84.36746987951807\n",
            "Epoch #2. Accuracy on batch 2905/3013  on Training is 84.36639710942877\n",
            "Epoch #2. Accuracy on batch 2906/3013  on Training is 84.36747506019952\n",
            "Epoch #2. Accuracy on batch 2907/3013  on Training is 84.36747764786796\n",
            "Epoch #2. Accuracy on batch 2908/3013  on Training is 84.3674802337573\n",
            "Epoch #2. Accuracy on batch 2909/3013  on Training is 84.3664089347079\n",
            "Epoch #2. Accuracy on batch 2910/3013  on Training is 84.36748540020612\n",
            "Epoch #2. Accuracy on batch 2911/3013  on Training is 84.36319539835165\n",
            "Epoch #2. Accuracy on batch 2912/3013  on Training is 84.3642722279437\n",
            "Epoch #2. Accuracy on batch 2913/3013  on Training is 84.36642072752231\n",
            "Epoch #2. Accuracy on batch 2914/3013  on Training is 84.36642367066895\n",
            "Epoch #2. Accuracy on batch 2915/3013  on Training is 84.36856995884774\n",
            "Epoch #2. Accuracy on batch 2916/3013  on Training is 84.3675008570449\n",
            "Epoch #2. Accuracy on batch 2917/3013  on Training is 84.36750342700479\n",
            "Epoch #2. Accuracy on batch 2918/3013  on Training is 84.36857656731758\n",
            "Epoch #2. Accuracy on batch 2919/3013  on Training is 84.36857876712328\n",
            "Batch Id 2920 is having training loss of 0.5556134581565857\n",
            "0.3065699636936188\n",
            "Epoch #2. Accuracy on batch 2920/3013  on Training is 84.3707206436152\n",
            "Epoch #2. Accuracy on batch 2921/3013  on Training is 84.36858316221766\n",
            "Epoch #2. Accuracy on batch 2922/3013  on Training is 84.37072357167294\n",
            "Epoch #2. Accuracy on batch 2923/3013  on Training is 84.36965629274965\n",
            "Epoch #2. Accuracy on batch 2924/3013  on Training is 84.37179487179488\n",
            "Epoch #2. Accuracy on batch 2925/3013  on Training is 84.3717959671907\n",
            "Epoch #2. Accuracy on batch 2926/3013  on Training is 84.37072941578408\n",
            "Epoch #2. Accuracy on batch 2927/3013  on Training is 84.36966359289617\n",
            "Epoch #2. Accuracy on batch 2928/3013  on Training is 84.37073233185387\n",
            "Epoch #2. Accuracy on batch 2929/3013  on Training is 84.36966723549489\n",
            "Epoch #2. Accuracy on batch 2930/3013  on Training is 84.36966905493006\n",
            "Epoch #2. Accuracy on batch 2931/3013  on Training is 84.37073669849931\n",
            "Epoch #2. Accuracy on batch 2932/3013  on Training is 84.37180361404705\n",
            "Epoch #2. Accuracy on batch 2933/3013  on Training is 84.36860940695297\n",
            "Epoch #2. Accuracy on batch 2934/3013  on Training is 84.37074105621805\n",
            "Epoch #2. Accuracy on batch 2935/3013  on Training is 84.36967813351498\n",
            "Epoch #2. Accuracy on batch 2936/3013  on Training is 84.36967994552265\n",
            "Epoch #2. Accuracy on batch 2937/3013  on Training is 84.3696817562968\n",
            "Epoch #2. Accuracy on batch 2938/3013  on Training is 84.36862027900646\n",
            "Epoch #2. Accuracy on batch 2939/3013  on Training is 84.36755952380952\n",
            "Batch Id 2940 is having training loss of 0.5556305050849915\n",
            "0.2711259424686432\n",
            "Epoch #2. Accuracy on batch 2940/3013  on Training is 84.37074974498469\n",
            "Epoch #2. Accuracy on batch 2941/3013  on Training is 84.37075118966689\n",
            "Epoch #2. Accuracy on batch 2942/3013  on Training is 84.37181447502549\n",
            "Epoch #2. Accuracy on batch 2943/3013  on Training is 84.37075407608695\n",
            "Epoch #2. Accuracy on batch 2944/3013  on Training is 84.37287775891342\n",
            "Epoch #2. Accuracy on batch 2945/3013  on Training is 84.37287847929396\n",
            "Epoch #2. Accuracy on batch 2946/3013  on Training is 84.36757719714964\n",
            "Epoch #2. Accuracy on batch 2947/3013  on Training is 84.36545963364993\n",
            "Epoch #2. Accuracy on batch 2948/3013  on Training is 84.36758223126483\n",
            "Epoch #2. Accuracy on batch 2949/3013  on Training is 84.36546610169492\n",
            "Epoch #2. Accuracy on batch 2950/3013  on Training is 84.36758725855643\n",
            "Epoch #2. Accuracy on batch 2951/3013  on Training is 84.36970697831978\n",
            "Epoch #2. Accuracy on batch 2952/3013  on Training is 84.37076701659329\n",
            "Epoch #2. Accuracy on batch 2953/3013  on Training is 84.3697105619499\n",
            "Epoch #2. Accuracy on batch 2954/3013  on Training is 84.36548223350253\n",
            "Epoch #2. Accuracy on batch 2955/3013  on Training is 84.36337110960758\n",
            "Epoch #2. Accuracy on batch 2956/3013  on Training is 84.35914778491714\n",
            "Epoch #2. Accuracy on batch 2957/3013  on Training is 84.35598377281947\n",
            "Epoch #2. Accuracy on batch 2958/3013  on Training is 84.35493409935789\n",
            "Epoch #2. Accuracy on batch 2959/3013  on Training is 84.35599662162163\n",
            "Batch Id 2960 is having training loss of 0.5557939410209656\n",
            "0.3284882605075836\n",
            "Epoch #2. Accuracy on batch 2960/3013  on Training is 84.35916919959473\n",
            "Epoch #2. Accuracy on batch 2961/3013  on Training is 84.35917454422687\n",
            "Epoch #2. Accuracy on batch 2962/3013  on Training is 84.35917988525144\n",
            "Epoch #2. Accuracy on batch 2963/3013  on Training is 84.35918522267207\n",
            "Epoch #2. Accuracy on batch 2964/3013  on Training is 84.3570826306914\n",
            "Epoch #2. Accuracy on batch 2965/3013  on Training is 84.35708867161159\n",
            "Epoch #2. Accuracy on batch 2966/3013  on Training is 84.35498820357263\n",
            "Epoch #2. Accuracy on batch 2967/3013  on Training is 84.35604784366576\n",
            "Epoch #2. Accuracy on batch 2968/3013  on Training is 84.35815931289997\n",
            "Epoch #2. Accuracy on batch 2969/3013  on Training is 84.35606060606061\n",
            "Epoch #2. Accuracy on batch 2970/3013  on Training is 84.35606698081455\n",
            "Epoch #2. Accuracy on batch 2971/3013  on Training is 84.3560733512786\n",
            "Epoch #2. Accuracy on batch 2972/3013  on Training is 84.35923309788093\n",
            "Epoch #2. Accuracy on batch 2973/3013  on Training is 84.3581876260928\n",
            "Epoch #2. Accuracy on batch 2974/3013  on Training is 84.36029411764706\n",
            "Epoch #2. Accuracy on batch 2975/3013  on Training is 84.36134912634408\n",
            "Epoch #2. Accuracy on batch 2976/3013  on Training is 84.36030399731273\n",
            "Epoch #2. Accuracy on batch 2977/3013  on Training is 84.36240765614507\n",
            "Epoch #2. Accuracy on batch 2978/3013  on Training is 84.3645099026519\n",
            "Epoch #2. Accuracy on batch 2979/3013  on Training is 84.36661073825503\n",
            "Batch Id 2980 is having training loss of 0.555829644203186\n",
            "0.6863521933555603\n",
            "Epoch #2. Accuracy on batch 2980/3013  on Training is 84.36661355249916\n",
            "Epoch #2. Accuracy on batch 2981/3013  on Training is 84.36766431924883\n",
            "Epoch #2. Accuracy on batch 2982/3013  on Training is 84.36347636607442\n",
            "Epoch #2. Accuracy on batch 2983/3013  on Training is 84.36557473190348\n",
            "Epoch #2. Accuracy on batch 2984/3013  on Training is 84.36557788944724\n",
            "Epoch #2. Accuracy on batch 2985/3013  on Training is 84.3613948425988\n",
            "Epoch #2. Accuracy on batch 2986/3013  on Training is 84.36244559758956\n",
            "Epoch #2. Accuracy on batch 2987/3013  on Training is 84.36454149933066\n",
            "Epoch #2. Accuracy on batch 2988/3013  on Training is 84.3645449983272\n",
            "Epoch #2. Accuracy on batch 2989/3013  on Training is 84.36559364548495\n",
            "Epoch #2. Accuracy on batch 2990/3013  on Training is 84.36559679037111\n",
            "Epoch #2. Accuracy on batch 2991/3013  on Training is 84.36455548128342\n",
            "Epoch #2. Accuracy on batch 2992/3013  on Training is 84.36560307383895\n",
            "Epoch #2. Accuracy on batch 2993/3013  on Training is 84.36351870407482\n",
            "Epoch #2. Accuracy on batch 2994/3013  on Training is 84.3593489148581\n",
            "Epoch #2. Accuracy on batch 2995/3013  on Training is 84.35831108144193\n",
            "Epoch #2. Accuracy on batch 2996/3013  on Training is 84.35831664998332\n",
            "Epoch #2. Accuracy on batch 2997/3013  on Training is 84.36040693795864\n",
            "Epoch #2. Accuracy on batch 2998/3013  on Training is 84.36249583194399\n",
            "Epoch #2. Accuracy on batch 2999/3013  on Training is 84.36458333333333\n",
            "Batch Id 3000 is having training loss of 0.5559428930282593\n",
            "0.7522794008255005\n",
            "Epoch #2. Accuracy on batch 3000/3013  on Training is 84.3614628457181\n",
            "Epoch #2. Accuracy on batch 3001/3013  on Training is 84.36042638241173\n",
            "Epoch #2. Accuracy on batch 3002/3013  on Training is 84.35522810522811\n",
            "Epoch #2. Accuracy on batch 3003/3013  on Training is 84.35835552596538\n",
            "Epoch #2. Accuracy on batch 3004/3013  on Training is 84.35836106489185\n",
            "Epoch #2. Accuracy on batch 3005/3013  on Training is 84.35940618762476\n",
            "Epoch #2. Accuracy on batch 3006/3013  on Training is 84.36045061523113\n",
            "Epoch #2. Accuracy on batch 3007/3013  on Training is 84.35837765957447\n",
            "Epoch #2. Accuracy on batch 3008/3013  on Training is 84.35734463276836\n",
            "Epoch #2. Accuracy on batch 3009/3013  on Training is 84.359426910299\n",
            "Epoch #2. Accuracy on batch 3010/3013  on Training is 84.36150780471604\n",
            "Epoch #2. Accuracy on batch 3011/3013  on Training is 84.36254980079681\n",
            "Epoch #2. Accuracy on batch 3012/3013  on Training is 84.36313463493579\n",
            "Epoch #2. Batch Id 0/278  is having validation loss of 1.05425226688385\n",
            "1.05425226688385\n",
            "Epoch #2. Batch Id 0/278  is having validation accuracy of 71.875\n",
            "Epoch #2. Batch Id 1/278  is having validation loss of 0.808199405670166\n",
            "0.5621465444564819\n",
            "Epoch #2. Batch Id 1/278  is having validation accuracy of 78.125\n",
            "Epoch #2. Batch Id 2/278  is having validation loss of 0.6693885326385498\n",
            "0.39176684617996216\n",
            "Epoch #2. Batch Id 2/278  is having validation accuracy of 82.29166666666667\n",
            "Epoch #2. Batch Id 3/278  is having validation loss of 0.6164811253547668\n",
            "0.4577588737010956\n",
            "Epoch #2. Batch Id 3/278  is having validation accuracy of 82.8125\n",
            "Epoch #2. Batch Id 4/278  is having validation loss of 0.6824828386306763\n",
            "0.9464898109436035\n",
            "Epoch #2. Batch Id 4/278  is having validation accuracy of 81.875\n",
            "Epoch #2. Batch Id 5/278  is having validation loss of 0.6801363825798035\n",
            "0.6684040427207947\n",
            "Epoch #2. Batch Id 5/278  is having validation accuracy of 82.29166666666667\n",
            "Epoch #2. Batch Id 6/278  is having validation loss of 0.7583852410316467\n",
            "1.227878451347351\n",
            "Epoch #2. Batch Id 6/278  is having validation accuracy of 79.91071428571429\n",
            "Epoch #2. Batch Id 7/278  is having validation loss of 0.687903881072998\n",
            "0.19453443586826324\n",
            "Epoch #2. Batch Id 7/278  is having validation accuracy of 81.640625\n",
            "Epoch #2. Batch Id 8/278  is having validation loss of 0.6472121477127075\n",
            "0.3216782510280609\n",
            "Epoch #2. Batch Id 8/278  is having validation accuracy of 82.63888888888889\n",
            "Epoch #2. Batch Id 9/278  is having validation loss of 0.6228272914886475\n",
            "0.40336349606513977\n",
            "Epoch #2. Batch Id 9/278  is having validation accuracy of 83.4375\n",
            "Epoch #2. Batch Id 10/278  is having validation loss of 0.6146066784858704\n",
            "0.5324003100395203\n",
            "Epoch #2. Batch Id 10/278  is having validation accuracy of 83.52272727272727\n",
            "Epoch #2. Batch Id 11/278  is having validation loss of 0.6253122687339783\n",
            "0.7430740594863892\n",
            "Epoch #2. Batch Id 11/278  is having validation accuracy of 83.33333333333333\n",
            "Epoch #2. Batch Id 12/278  is having validation loss of 0.6323484778404236\n",
            "0.716782808303833\n",
            "Epoch #2. Batch Id 12/278  is having validation accuracy of 83.17307692307692\n",
            "Epoch #2. Batch Id 13/278  is having validation loss of 0.6346518993377686\n",
            "0.6645967960357666\n",
            "Epoch #2. Batch Id 13/278  is having validation accuracy of 82.36607142857143\n",
            "Epoch #2. Batch Id 14/278  is having validation loss of 0.6409165859222412\n",
            "0.7286224365234375\n",
            "Epoch #2. Batch Id 14/278  is having validation accuracy of 82.08333333333333\n",
            "Epoch #2. Batch Id 15/278  is having validation loss of 0.6447251439094543\n",
            "0.7018536925315857\n",
            "Epoch #2. Batch Id 15/278  is having validation accuracy of 82.2265625\n",
            "Epoch #2. Batch Id 16/278  is having validation loss of 0.6657208800315857\n",
            "1.0016528367996216\n",
            "Epoch #2. Batch Id 16/278  is having validation accuracy of 82.16911764705883\n",
            "Epoch #2. Batch Id 17/278  is having validation loss of 0.6563108563423157\n",
            "0.496340274810791\n",
            "Epoch #2. Batch Id 17/278  is having validation accuracy of 82.11805555555556\n",
            "Epoch #2. Batch Id 18/278  is having validation loss of 0.6428571939468384\n",
            "0.40069130063056946\n",
            "Epoch #2. Batch Id 18/278  is having validation accuracy of 82.40131578947368\n",
            "Epoch #2. Batch Id 19/278  is having validation loss of 0.6313404440879822\n",
            "0.4125220775604248\n",
            "Epoch #2. Batch Id 19/278  is having validation accuracy of 82.5\n",
            "Epoch #2. Batch Id 20/278  is having validation loss of 0.6212108135223389\n",
            "0.41861844062805176\n",
            "Epoch #2. Batch Id 20/278  is having validation accuracy of 82.88690476190476\n",
            "Epoch #2. Batch Id 21/278  is having validation loss of 0.6156904101371765\n",
            "0.4997617304325104\n",
            "Epoch #2. Batch Id 21/278  is having validation accuracy of 82.95454545454545\n",
            "Epoch #2. Batch Id 22/278  is having validation loss of 0.6038541793823242\n",
            "0.3434571623802185\n",
            "Epoch #2. Batch Id 22/278  is having validation accuracy of 82.8804347826087\n",
            "Epoch #2. Batch Id 23/278  is having validation loss of 0.6063059568405151\n",
            "0.6626973152160645\n",
            "Epoch #2. Batch Id 23/278  is having validation accuracy of 82.8125\n",
            "Epoch #2. Batch Id 24/278  is having validation loss of 0.5966829061508179\n",
            "0.3657296597957611\n",
            "Epoch #2. Batch Id 24/278  is having validation accuracy of 83.125\n",
            "Epoch #2. Batch Id 25/278  is having validation loss of 0.5966882109642029\n",
            "0.5968207716941833\n",
            "Epoch #2. Batch Id 25/278  is having validation accuracy of 83.29326923076923\n",
            "Epoch #2. Batch Id 26/278  is having validation loss of 0.6008851528167725\n",
            "0.7100062370300293\n",
            "Epoch #2. Batch Id 26/278  is having validation accuracy of 83.2175925925926\n",
            "Epoch #2. Batch Id 27/278  is having validation loss of 0.603632926940918\n",
            "0.6778233647346497\n",
            "Epoch #2. Batch Id 27/278  is having validation accuracy of 83.03571428571429\n",
            "Epoch #2. Batch Id 28/278  is having validation loss of 0.6114793419837952\n",
            "0.8311782479286194\n",
            "Epoch #2. Batch Id 28/278  is having validation accuracy of 82.86637931034483\n",
            "Epoch #2. Batch Id 29/278  is having validation loss of 0.598736047744751\n",
            "0.2291802167892456\n",
            "Epoch #2. Batch Id 29/278  is having validation accuracy of 83.33333333333333\n",
            "Epoch #2. Batch Id 30/278  is having validation loss of 0.5921854376792908\n",
            "0.39566677808761597\n",
            "Epoch #2. Batch Id 30/278  is having validation accuracy of 83.46774193548387\n",
            "Epoch #2. Batch Id 31/278  is having validation loss of 0.5876423716545105\n",
            "0.446807324886322\n",
            "Epoch #2. Batch Id 31/278  is having validation accuracy of 83.69140625\n",
            "Epoch #2. Batch Id 32/278  is having validation loss of 0.583419144153595\n",
            "0.4482767879962921\n",
            "Epoch #2. Batch Id 32/278  is having validation accuracy of 83.90151515151516\n",
            "Epoch #2. Batch Id 33/278  is having validation loss of 0.5812327265739441\n",
            "0.5090813040733337\n",
            "Epoch #2. Batch Id 33/278  is having validation accuracy of 83.82352941176471\n",
            "Epoch #2. Batch Id 34/278  is having validation loss of 0.5908495783805847\n",
            "0.9178224205970764\n",
            "Epoch #2. Batch Id 34/278  is having validation accuracy of 83.39285714285714\n",
            "Epoch #2. Batch Id 35/278  is having validation loss of 0.5879826545715332\n",
            "0.48763978481292725\n",
            "Epoch #2. Batch Id 35/278  is having validation accuracy of 83.33333333333333\n",
            "Epoch #2. Batch Id 36/278  is having validation loss of 0.585792601108551\n",
            "0.5069506168365479\n",
            "Epoch #2. Batch Id 36/278  is having validation accuracy of 83.36148648648648\n",
            "Epoch #2. Batch Id 37/278  is having validation loss of 0.5854434370994568\n",
            "0.5725249648094177\n",
            "Epoch #2. Batch Id 37/278  is having validation accuracy of 83.47039473684211\n",
            "Epoch #2. Batch Id 38/278  is having validation loss of 0.5887397527694702\n",
            "0.7140005826950073\n",
            "Epoch #2. Batch Id 38/278  is having validation accuracy of 83.57371794871794\n",
            "Epoch #2. Batch Id 39/278  is having validation loss of 0.5880169868469238\n",
            "0.5598292946815491\n",
            "Epoch #2. Batch Id 39/278  is having validation accuracy of 83.515625\n",
            "Epoch #2. Batch Id 40/278  is having validation loss of 0.5800682902336121\n",
            "0.2621214687824249\n",
            "Epoch #2. Batch Id 40/278  is having validation accuracy of 83.84146341463415\n",
            "Epoch #2. Batch Id 41/278  is having validation loss of 0.581427276134491\n",
            "0.6371461749076843\n",
            "Epoch #2. Batch Id 41/278  is having validation accuracy of 83.7797619047619\n",
            "Epoch #2. Batch Id 42/278  is having validation loss of 0.5819514393806458\n",
            "0.6039658784866333\n",
            "Epoch #2. Batch Id 42/278  is having validation accuracy of 83.72093023255815\n",
            "Epoch #2. Batch Id 43/278  is having validation loss of 0.5792452692985535\n",
            "0.46287962794303894\n",
            "Epoch #2. Batch Id 43/278  is having validation accuracy of 83.80681818181819\n",
            "Epoch #2. Batch Id 44/278  is having validation loss of 0.585256814956665\n",
            "0.8497651815414429\n",
            "Epoch #2. Batch Id 44/278  is having validation accuracy of 83.47222222222223\n",
            "Epoch #2. Batch Id 45/278  is having validation loss of 0.5850935578346252\n",
            "0.5777456760406494\n",
            "Epoch #2. Batch Id 45/278  is having validation accuracy of 83.49184782608695\n",
            "Epoch #2. Batch Id 46/278  is having validation loss of 0.5824896097183228\n",
            "0.46270686388015747\n",
            "Epoch #2. Batch Id 46/278  is having validation accuracy of 83.57712765957447\n",
            "Epoch #2. Batch Id 47/278  is having validation loss of 0.5861799120903015\n",
            "0.7596246004104614\n",
            "Epoch #2. Batch Id 47/278  is having validation accuracy of 83.46354166666667\n",
            "Epoch #2. Batch Id 48/278  is having validation loss of 0.5827792882919312\n",
            "0.4195490777492523\n",
            "Epoch #2. Batch Id 48/278  is having validation accuracy of 83.60969387755102\n",
            "Epoch #2. Batch Id 49/278  is having validation loss of 0.5845116376876831\n",
            "0.669395387172699\n",
            "Epoch #2. Batch Id 49/278  is having validation accuracy of 83.5625\n",
            "Epoch #2. Batch Id 50/278  is having validation loss of 0.5793915390968323\n",
            "0.3233851492404938\n",
            "Epoch #2. Batch Id 50/278  is having validation accuracy of 83.63970588235294\n",
            "Epoch #2. Batch Id 51/278  is having validation loss of 0.5742392539978027\n",
            "0.3114742338657379\n",
            "Epoch #2. Batch Id 51/278  is having validation accuracy of 83.7139423076923\n",
            "Epoch #2. Batch Id 52/278  is having validation loss of 0.5741846561431885\n",
            "0.5713463425636292\n",
            "Epoch #2. Batch Id 52/278  is having validation accuracy of 83.72641509433963\n",
            "Epoch #2. Batch Id 53/278  is having validation loss of 0.5808292627334595\n",
            "0.9329934120178223\n",
            "Epoch #2. Batch Id 53/278  is having validation accuracy of 83.56481481481481\n",
            "Epoch #2. Batch Id 54/278  is having validation loss of 0.5775108337402344\n",
            "0.3983150124549866\n",
            "Epoch #2. Batch Id 54/278  is having validation accuracy of 83.69318181818181\n",
            "Epoch #2. Batch Id 55/278  is having validation loss of 0.5734285116195679\n",
            "0.34890103340148926\n",
            "Epoch #2. Batch Id 55/278  is having validation accuracy of 83.87276785714286\n",
            "Epoch #2. Batch Id 56/278  is having validation loss of 0.5779723525047302\n",
            "0.8324280977249146\n",
            "Epoch #2. Batch Id 56/278  is having validation accuracy of 83.71710526315789\n",
            "Epoch #2. Batch Id 57/278  is having validation loss of 0.5800985097885132\n",
            "0.7012891173362732\n",
            "Epoch #2. Batch Id 57/278  is having validation accuracy of 83.78232758620689\n",
            "Epoch #2. Batch Id 58/278  is having validation loss of 0.57598876953125\n",
            "0.33762502670288086\n",
            "Epoch #2. Batch Id 58/278  is having validation accuracy of 83.84533898305085\n",
            "Epoch #2. Batch Id 59/278  is having validation loss of 0.5743411779403687\n",
            "0.4771336615085602\n",
            "Epoch #2. Batch Id 59/278  is having validation accuracy of 83.90625\n",
            "Epoch #2. Batch Id 60/278  is having validation loss of 0.5727003812789917\n",
            "0.47425389289855957\n",
            "Epoch #2. Batch Id 60/278  is having validation accuracy of 83.96516393442623\n",
            "Epoch #2. Batch Id 61/278  is having validation loss of 0.5702560544013977\n",
            "0.4211539328098297\n",
            "Epoch #2. Batch Id 61/278  is having validation accuracy of 83.92137096774194\n",
            "Epoch #2. Batch Id 62/278  is having validation loss of 0.5668033957481384\n",
            "0.35274040699005127\n",
            "Epoch #2. Batch Id 62/278  is having validation accuracy of 84.02777777777777\n",
            "Epoch #2. Batch Id 63/278  is having validation loss of 0.5688270926475525\n",
            "0.6963205933570862\n",
            "Epoch #2. Batch Id 63/278  is having validation accuracy of 83.984375\n",
            "Epoch #2. Batch Id 64/278  is having validation loss of 0.5683451890945435\n",
            "0.5375043749809265\n",
            "Epoch #2. Batch Id 64/278  is having validation accuracy of 83.84615384615384\n",
            "Epoch #2. Batch Id 65/278  is having validation loss of 0.5629534721374512\n",
            "0.2124926596879959\n",
            "Epoch #2. Batch Id 65/278  is having validation accuracy of 84.04356060606061\n",
            "Epoch #2. Batch Id 66/278  is having validation loss of 0.5602813959121704\n",
            "0.38392579555511475\n",
            "Epoch #2. Batch Id 66/278  is having validation accuracy of 84.09514925373135\n",
            "Epoch #2. Batch Id 67/278  is having validation loss of 0.5599724650382996\n",
            "0.5392739772796631\n",
            "Epoch #2. Batch Id 67/278  is having validation accuracy of 84.14522058823529\n",
            "Epoch #2. Batch Id 68/278  is having validation loss of 0.5567736625671387\n",
            "0.3392532467842102\n",
            "Epoch #2. Batch Id 68/278  is having validation accuracy of 84.19384057971014\n",
            "Epoch #2. Batch Id 69/278  is having validation loss of 0.5551559329032898\n",
            "0.4435312747955322\n",
            "Epoch #2. Batch Id 69/278  is having validation accuracy of 84.24107142857143\n",
            "Epoch #2. Batch Id 70/278  is having validation loss of 0.5575931072235107\n",
            "0.7281966805458069\n",
            "Epoch #2. Batch Id 70/278  is having validation accuracy of 84.28697183098592\n",
            "Epoch #2. Batch Id 71/278  is having validation loss of 0.5536692142486572\n",
            "0.2750720977783203\n",
            "Epoch #2. Batch Id 71/278  is having validation accuracy of 84.33159722222223\n",
            "Epoch #2. Batch Id 72/278  is having validation loss of 0.5517048239707947\n",
            "0.4102676212787628\n",
            "Epoch #2. Batch Id 72/278  is having validation accuracy of 84.41780821917808\n",
            "Epoch #2. Batch Id 73/278  is having validation loss of 0.5503140687942505\n",
            "0.44878697395324707\n",
            "Epoch #2. Batch Id 73/278  is having validation accuracy of 84.41722972972973\n",
            "Epoch #2. Batch Id 74/278  is having validation loss of 0.5538550019264221\n",
            "0.8158826231956482\n",
            "Epoch #2. Batch Id 74/278  is having validation accuracy of 84.375\n",
            "Epoch #2. Batch Id 75/278  is having validation loss of 0.56145179271698\n",
            "1.1312133073806763\n",
            "Epoch #2. Batch Id 75/278  is having validation accuracy of 84.1282894736842\n",
            "Epoch #2. Batch Id 76/278  is having validation loss of 0.5600130558013916\n",
            "0.45066899061203003\n",
            "Epoch #2. Batch Id 76/278  is having validation accuracy of 84.21266233766234\n",
            "Epoch #2. Batch Id 77/278  is having validation loss of 0.5594229102134705\n",
            "0.5139812231063843\n",
            "Epoch #2. Batch Id 77/278  is having validation accuracy of 84.17467948717949\n",
            "Epoch #2. Batch Id 78/278  is having validation loss of 0.5585882067680359\n",
            "0.4934825003147125\n",
            "Epoch #2. Batch Id 78/278  is having validation accuracy of 84.21677215189874\n",
            "Epoch #2. Batch Id 79/278  is having validation loss of 0.5546591877937317\n",
            "0.2442655712366104\n",
            "Epoch #2. Batch Id 79/278  is having validation accuracy of 84.375\n",
            "Epoch #2. Batch Id 80/278  is having validation loss of 0.554250180721283\n",
            "0.5215292572975159\n",
            "Epoch #2. Batch Id 80/278  is having validation accuracy of 84.33641975308642\n",
            "Epoch #2. Batch Id 81/278  is having validation loss of 0.557287871837616\n",
            "0.8033408522605896\n",
            "Epoch #2. Batch Id 81/278  is having validation accuracy of 84.29878048780488\n",
            "Epoch #2. Batch Id 82/278  is having validation loss of 0.559523344039917\n",
            "0.7428340911865234\n",
            "Epoch #2. Batch Id 82/278  is having validation accuracy of 84.22439759036145\n",
            "Epoch #2. Batch Id 83/278  is having validation loss of 0.5575475096702576\n",
            "0.3935508728027344\n",
            "Epoch #2. Batch Id 83/278  is having validation accuracy of 84.26339285714286\n",
            "Epoch #2. Batch Id 84/278  is having validation loss of 0.5583111643791199\n",
            "0.6224580407142639\n",
            "Epoch #2. Batch Id 84/278  is having validation accuracy of 84.26470588235294\n",
            "Epoch #2. Batch Id 85/278  is having validation loss of 0.5581880807876587\n",
            "0.5477278828620911\n",
            "Epoch #2. Batch Id 85/278  is having validation accuracy of 84.2296511627907\n",
            "Epoch #2. Batch Id 86/278  is having validation loss of 0.5570868253707886\n",
            "0.4623810052871704\n",
            "Epoch #2. Batch Id 86/278  is having validation accuracy of 84.15948275862068\n",
            "Epoch #2. Batch Id 87/278  is having validation loss of 0.5572118759155273\n",
            "0.5680890679359436\n",
            "Epoch #2. Batch Id 87/278  is having validation accuracy of 84.16193181818181\n",
            "Epoch #2. Batch Id 88/278  is having validation loss of 0.5584132075309753\n",
            "0.6641287207603455\n",
            "Epoch #2. Batch Id 88/278  is having validation accuracy of 84.12921348314607\n",
            "Epoch #2. Batch Id 89/278  is having validation loss of 0.555424153804779\n",
            "0.2893962562084198\n",
            "Epoch #2. Batch Id 89/278  is having validation accuracy of 84.20138888888889\n",
            "Epoch #2. Batch Id 90/278  is having validation loss of 0.5528711080551147\n",
            "0.32309484481811523\n",
            "Epoch #2. Batch Id 90/278  is having validation accuracy of 84.23763736263736\n",
            "Epoch #2. Batch Id 91/278  is having validation loss of 0.5520147085189819\n",
            "0.4740842580795288\n",
            "Epoch #2. Batch Id 91/278  is having validation accuracy of 84.3070652173913\n",
            "Epoch #2. Batch Id 92/278  is having validation loss of 0.5494266748428345\n",
            "0.31132784485816956\n",
            "Epoch #2. Batch Id 92/278  is having validation accuracy of 84.40860215053763\n",
            "Epoch #2. Batch Id 93/278  is having validation loss of 0.5485863089561462\n",
            "0.4704331159591675\n",
            "Epoch #2. Batch Id 93/278  is having validation accuracy of 84.50797872340425\n",
            "Epoch #2. Batch Id 94/278  is having validation loss of 0.547904908657074\n",
            "0.4838547110557556\n",
            "Epoch #2. Batch Id 94/278  is having validation accuracy of 84.53947368421052\n",
            "Epoch #2. Batch Id 95/278  is having validation loss of 0.5492876172065735\n",
            "0.6806427240371704\n",
            "Epoch #2. Batch Id 95/278  is having validation accuracy of 84.50520833333333\n",
            "Epoch #2. Batch Id 96/278  is having validation loss of 0.5498262047767639\n",
            "0.6015309691429138\n",
            "Epoch #2. Batch Id 96/278  is having validation accuracy of 84.47164948453609\n",
            "Epoch #2. Batch Id 97/278  is having validation loss of 0.5522972345352173\n",
            "0.7919880747795105\n",
            "Epoch #2. Batch Id 97/278  is having validation accuracy of 84.47066326530613\n",
            "Epoch #2. Batch Id 98/278  is having validation loss of 0.5500829219818115\n",
            "0.33308297395706177\n",
            "Epoch #2. Batch Id 98/278  is having validation accuracy of 84.56439393939394\n",
            "Epoch #2. Batch Id 99/278  is having validation loss of 0.5534945130348206\n",
            "0.8912445306777954\n",
            "Epoch #2. Batch Id 99/278  is having validation accuracy of 84.4375\n",
            "Epoch #2. Batch Id 100/278  is having validation loss of 0.5523784160614014\n",
            "0.44076842069625854\n",
            "Epoch #2. Batch Id 100/278  is having validation accuracy of 84.43688118811882\n",
            "Epoch #2. Batch Id 101/278  is having validation loss of 0.5522856116294861\n",
            "0.5429098606109619\n",
            "Epoch #2. Batch Id 101/278  is having validation accuracy of 84.40563725490196\n",
            "Epoch #2. Batch Id 102/278  is having validation loss of 0.5536748766899109\n",
            "0.6953780651092529\n",
            "Epoch #2. Batch Id 102/278  is having validation accuracy of 84.375\n",
            "Epoch #2. Batch Id 103/278  is having validation loss of 0.5527245998382568\n",
            "0.4548470079898834\n",
            "Epoch #2. Batch Id 103/278  is having validation accuracy of 84.43509615384616\n",
            "Epoch #2. Batch Id 104/278  is having validation loss of 0.550950288772583\n",
            "0.36642172932624817\n",
            "Epoch #2. Batch Id 104/278  is having validation accuracy of 84.49404761904762\n",
            "Epoch #2. Batch Id 105/278  is having validation loss of 0.5514764785766602\n",
            "0.6067283749580383\n",
            "Epoch #2. Batch Id 105/278  is having validation accuracy of 84.49292452830188\n",
            "Epoch #2. Batch Id 106/278  is having validation loss of 0.5493236184120178\n",
            "0.321118026971817\n",
            "Epoch #2. Batch Id 106/278  is having validation accuracy of 84.55023364485982\n",
            "Epoch #2. Batch Id 107/278  is having validation loss of 0.5486367344856262\n",
            "0.475141316652298\n",
            "Epoch #2. Batch Id 107/278  is having validation accuracy of 84.49074074074075\n",
            "Epoch #2. Batch Id 108/278  is having validation loss of 0.5483015179634094\n",
            "0.5121006965637207\n",
            "Epoch #2. Batch Id 108/278  is having validation accuracy of 84.46100917431193\n",
            "Epoch #2. Batch Id 109/278  is having validation loss of 0.5497564673423767\n",
            "0.708348274230957\n",
            "Epoch #2. Batch Id 109/278  is having validation accuracy of 84.375\n",
            "Epoch #2. Batch Id 110/278  is having validation loss of 0.5503538846969604\n",
            "0.6160686016082764\n",
            "Epoch #2. Batch Id 110/278  is having validation accuracy of 84.375\n",
            "Epoch #2. Batch Id 111/278  is having validation loss of 0.549757182598114\n",
            "0.4835255742073059\n",
            "Epoch #2. Batch Id 111/278  is having validation accuracy of 84.34709821428571\n",
            "Epoch #2. Batch Id 112/278  is having validation loss of 0.5540046095848083\n",
            "1.0297152996063232\n",
            "Epoch #2. Batch Id 112/278  is having validation accuracy of 84.20907079646018\n",
            "Epoch #2. Batch Id 113/278  is having validation loss of 0.5532354712486267\n",
            "0.46632227301597595\n",
            "Epoch #2. Batch Id 113/278  is having validation accuracy of 84.23793859649123\n",
            "Epoch #2. Batch Id 114/278  is having validation loss of 0.5533478260040283\n",
            "0.5661572813987732\n",
            "Epoch #2. Batch Id 114/278  is having validation accuracy of 84.18478260869566\n",
            "Epoch #2. Batch Id 115/278  is having validation loss of 0.5529412627220154\n",
            "0.5061848759651184\n",
            "Epoch #2. Batch Id 115/278  is having validation accuracy of 84.24030172413794\n",
            "Epoch #2. Batch Id 116/278  is having validation loss of 0.5535982847213745\n",
            "0.6298116445541382\n",
            "Epoch #2. Batch Id 116/278  is having validation accuracy of 84.21474358974359\n",
            "Epoch #2. Batch Id 117/278  is having validation loss of 0.5523343682289124\n",
            "0.4044533371925354\n",
            "Epoch #2. Batch Id 117/278  is having validation accuracy of 84.26906779661017\n",
            "Epoch #2. Batch Id 118/278  is having validation loss of 0.553668200969696\n",
            "0.7110608816146851\n",
            "Epoch #2. Batch Id 118/278  is having validation accuracy of 84.29621848739495\n",
            "Epoch #2. Batch Id 119/278  is having validation loss of 0.5541433095932007\n",
            "0.6106839776039124\n",
            "Epoch #2. Batch Id 119/278  is having validation accuracy of 84.32291666666667\n",
            "Epoch #2. Batch Id 120/278  is having validation loss of 0.5537017583847046\n",
            "0.5007176995277405\n",
            "Epoch #2. Batch Id 120/278  is having validation accuracy of 84.375\n",
            "Epoch #2. Batch Id 121/278  is having validation loss of 0.5570210218429565\n",
            "0.9586526155471802\n",
            "Epoch #2. Batch Id 121/278  is having validation accuracy of 84.29815573770492\n",
            "Epoch #2. Batch Id 122/278  is having validation loss of 0.5579994916915894\n",
            "0.6773754358291626\n",
            "Epoch #2. Batch Id 122/278  is having validation accuracy of 84.2479674796748\n",
            "Epoch #2. Batch Id 123/278  is having validation loss of 0.557972252368927\n",
            "0.5546201467514038\n",
            "Epoch #2. Batch Id 123/278  is having validation accuracy of 84.2741935483871\n",
            "Epoch #2. Batch Id 124/278  is having validation loss of 0.5590145587921143\n",
            "0.6882574558258057\n",
            "Epoch #2. Batch Id 124/278  is having validation accuracy of 84.3\n",
            "Epoch #2. Batch Id 125/278  is having validation loss of 0.5601193904876709\n",
            "0.698223888874054\n",
            "Epoch #2. Batch Id 125/278  is having validation accuracy of 84.27579365079364\n",
            "Epoch #2. Batch Id 126/278  is having validation loss of 0.5599978566169739\n",
            "0.5446863770484924\n",
            "Epoch #2. Batch Id 126/278  is having validation accuracy of 84.30118110236221\n",
            "Epoch #2. Batch Id 127/278  is having validation loss of 0.5598447322845459\n",
            "0.5403997302055359\n",
            "Epoch #2. Batch Id 127/278  is having validation accuracy of 84.3017578125\n",
            "Epoch #2. Batch Id 128/278  is having validation loss of 0.55837082862854\n",
            "0.36970868706703186\n",
            "Epoch #2. Batch Id 128/278  is having validation accuracy of 84.35077519379846\n",
            "Epoch #2. Batch Id 129/278  is having validation loss of 0.5600122809410095\n",
            "0.7717582583427429\n",
            "Epoch #2. Batch Id 129/278  is having validation accuracy of 84.30288461538461\n",
            "Epoch #2. Batch Id 130/278  is having validation loss of 0.558513343334198\n",
            "0.3636535108089447\n",
            "Epoch #2. Batch Id 130/278  is having validation accuracy of 84.32729007633588\n",
            "Epoch #2. Batch Id 131/278  is having validation loss of 0.5584862232208252\n",
            "0.5549367666244507\n",
            "Epoch #2. Batch Id 131/278  is having validation accuracy of 84.30397727272727\n",
            "Epoch #2. Batch Id 132/278  is having validation loss of 0.5574808120727539\n",
            "0.4247669577598572\n",
            "Epoch #2. Batch Id 132/278  is having validation accuracy of 84.328007518797\n",
            "Epoch #2. Batch Id 133/278  is having validation loss of 0.5561861991882324\n",
            "0.3839995563030243\n",
            "Epoch #2. Batch Id 133/278  is having validation accuracy of 84.375\n",
            "Epoch #2. Batch Id 134/278  is having validation loss of 0.5575230717658997\n",
            "0.7366621494293213\n",
            "Epoch #2. Batch Id 134/278  is having validation accuracy of 84.35185185185185\n",
            "Epoch #2. Batch Id 135/278  is having validation loss of 0.5599262714385986\n",
            "0.8843570351600647\n",
            "Epoch #2. Batch Id 135/278  is having validation accuracy of 84.32904411764706\n",
            "Epoch #2. Batch Id 136/278  is having validation loss of 0.5606502890586853\n",
            "0.6591181755065918\n",
            "Epoch #2. Batch Id 136/278  is having validation accuracy of 84.2837591240876\n",
            "Epoch #2. Batch Id 137/278  is having validation loss of 0.5627159476280212\n",
            "0.8457112312316895\n",
            "Epoch #2. Batch Id 137/278  is having validation accuracy of 84.23913043478261\n",
            "Epoch #2. Batch Id 138/278  is having validation loss of 0.5617104172706604\n",
            "0.42294842004776\n",
            "Epoch #2. Batch Id 138/278  is having validation accuracy of 84.24010791366906\n",
            "Epoch #2. Batch Id 139/278  is having validation loss of 0.5611945986747742\n",
            "0.48949283361434937\n",
            "Epoch #2. Batch Id 139/278  is having validation accuracy of 84.28571428571429\n",
            "Epoch #2. Batch Id 140/278  is having validation loss of 0.5620675086975098\n",
            "0.6842732429504395\n",
            "Epoch #2. Batch Id 140/278  is having validation accuracy of 84.28634751773049\n",
            "Epoch #2. Batch Id 141/278  is having validation loss of 0.5610960721969604\n",
            "0.4241277575492859\n",
            "Epoch #2. Batch Id 141/278  is having validation accuracy of 84.30897887323944\n",
            "Epoch #2. Batch Id 142/278  is having validation loss of 0.5626946091651917\n",
            "0.7896845936775208\n",
            "Epoch #2. Batch Id 142/278  is having validation accuracy of 84.26573426573427\n",
            "Epoch #2. Batch Id 143/278  is having validation loss of 0.563707709312439\n",
            "0.7085846066474915\n",
            "Epoch #2. Batch Id 143/278  is having validation accuracy of 84.22309027777777\n",
            "Epoch #2. Batch Id 144/278  is having validation loss of 0.5613276958465576\n",
            "0.21860632300376892\n",
            "Epoch #2. Batch Id 144/278  is having validation accuracy of 84.26724137931035\n",
            "Epoch #2. Batch Id 145/278  is having validation loss of 0.5619808435440063\n",
            "0.6566912531852722\n",
            "Epoch #2. Batch Id 145/278  is having validation accuracy of 84.26797945205479\n",
            "Epoch #2. Batch Id 146/278  is having validation loss of 0.5637182593345642\n",
            "0.8173841238021851\n",
            "Epoch #2. Batch Id 146/278  is having validation accuracy of 84.24744897959184\n",
            "Epoch #2. Batch Id 147/278  is having validation loss of 0.5657762885093689\n",
            "0.868305504322052\n",
            "Epoch #2. Batch Id 147/278  is having validation accuracy of 84.2483108108108\n",
            "Epoch #2. Batch Id 148/278  is having validation loss of 0.5653327703475952\n",
            "0.49969103932380676\n",
            "Epoch #2. Batch Id 148/278  is having validation accuracy of 84.2491610738255\n",
            "Epoch #2. Batch Id 149/278  is having validation loss of 0.5631395578384399\n",
            "0.23635099828243256\n",
            "Epoch #2. Batch Id 149/278  is having validation accuracy of 84.29166666666667\n",
            "Epoch #2. Batch Id 150/278  is having validation loss of 0.5653113722801208\n",
            "0.8910846710205078\n",
            "Epoch #2. Batch Id 150/278  is having validation accuracy of 84.25082781456953\n",
            "Epoch #2. Batch Id 151/278  is having validation loss of 0.5653573870658875\n",
            "0.5723053812980652\n",
            "Epoch #2. Batch Id 151/278  is having validation accuracy of 84.25164473684211\n",
            "Epoch #2. Batch Id 152/278  is having validation loss of 0.5667172074317932\n",
            "0.7734139561653137\n",
            "Epoch #2. Batch Id 152/278  is having validation accuracy of 84.21160130718954\n",
            "Epoch #2. Batch Id 153/278  is having validation loss of 0.5659866333007812\n",
            "0.4542117416858673\n",
            "Epoch #2. Batch Id 153/278  is having validation accuracy of 84.23295454545455\n",
            "Epoch #2. Batch Id 154/278  is having validation loss of 0.5662429332733154\n",
            "0.6057093143463135\n",
            "Epoch #2. Batch Id 154/278  is having validation accuracy of 84.23387096774194\n",
            "Epoch #2. Batch Id 155/278  is having validation loss of 0.5645551085472107\n",
            "0.30294108390808105\n",
            "Epoch #2. Batch Id 155/278  is having validation accuracy of 84.2548076923077\n",
            "Epoch #2. Batch Id 156/278  is having validation loss of 0.5680885314941406\n",
            "1.119306206703186\n",
            "Epoch #2. Batch Id 156/278  is having validation accuracy of 84.11624203821655\n",
            "Epoch #2. Batch Id 157/278  is having validation loss of 0.5691283941268921\n",
            "0.7323846220970154\n",
            "Epoch #2. Batch Id 157/278  is having validation accuracy of 84.09810126582279\n",
            "Epoch #2. Batch Id 158/278  is having validation loss of 0.5669094920158386\n",
            "0.21632426977157593\n",
            "Epoch #2. Batch Id 158/278  is having validation accuracy of 84.15880503144655\n",
            "Epoch #2. Batch Id 159/278  is having validation loss of 0.567729115486145\n",
            "0.6980451345443726\n",
            "Epoch #2. Batch Id 159/278  is having validation accuracy of 84.16015625\n",
            "Epoch #2. Batch Id 160/278  is having validation loss of 0.5710107684135437\n",
            "1.0960760116577148\n",
            "Epoch #2. Batch Id 160/278  is having validation accuracy of 84.10326086956522\n",
            "Epoch #2. Batch Id 161/278  is having validation loss of 0.570442259311676\n",
            "0.478911817073822\n",
            "Epoch #2. Batch Id 161/278  is having validation accuracy of 84.08564814814815\n",
            "Epoch #2. Batch Id 162/278  is having validation loss of 0.5699458718299866\n",
            "0.48953181505203247\n",
            "Epoch #2. Batch Id 162/278  is having validation accuracy of 84.10659509202453\n",
            "Epoch #2. Batch Id 163/278  is having validation loss of 0.5689910650253296\n",
            "0.41335371136665344\n",
            "Epoch #2. Batch Id 163/278  is having validation accuracy of 84.12728658536585\n",
            "Epoch #2. Batch Id 164/278  is having validation loss of 0.5694522857666016\n",
            "0.6450962424278259\n",
            "Epoch #2. Batch Id 164/278  is having validation accuracy of 84.12878787878788\n",
            "Epoch #2. Batch Id 165/278  is having validation loss of 0.5690754055976868\n",
            "0.5068910121917725\n",
            "Epoch #2. Batch Id 165/278  is having validation accuracy of 84.11144578313252\n",
            "Epoch #2. Batch Id 166/278  is having validation loss of 0.5680309534072876\n",
            "0.39465320110321045\n",
            "Epoch #2. Batch Id 166/278  is having validation accuracy of 84.13173652694611\n",
            "Epoch #2. Batch Id 167/278  is having validation loss of 0.5683793425559998\n",
            "0.6265592575073242\n",
            "Epoch #2. Batch Id 167/278  is having validation accuracy of 84.15178571428571\n",
            "Epoch #2. Batch Id 168/278  is having validation loss of 0.5658884644508362\n",
            "0.14741943776607513\n",
            "Epoch #2. Batch Id 168/278  is having validation accuracy of 84.22707100591715\n",
            "Epoch #2. Batch Id 169/278  is having validation loss of 0.5645606517791748\n",
            "0.3401605486869812\n",
            "Epoch #2. Batch Id 169/278  is having validation accuracy of 84.28308823529412\n",
            "Epoch #2. Batch Id 170/278  is having validation loss of 0.5642390847206116\n",
            "0.5095723271369934\n",
            "Epoch #2. Batch Id 170/278  is having validation accuracy of 84.28362573099415\n",
            "Epoch #2. Batch Id 171/278  is having validation loss of 0.5641694664955139\n",
            "0.5522668361663818\n",
            "Epoch #2. Batch Id 171/278  is having validation accuracy of 84.24781976744185\n",
            "Epoch #2. Batch Id 172/278  is having validation loss of 0.5628301501274109\n",
            "0.33246272802352905\n",
            "Epoch #2. Batch Id 172/278  is having validation accuracy of 84.26661849710983\n",
            "Epoch #2. Batch Id 173/278  is having validation loss of 0.56305330991745\n",
            "0.6016616821289062\n",
            "Epoch #2. Batch Id 173/278  is having validation accuracy of 84.26724137931035\n",
            "Epoch #2. Batch Id 174/278  is having validation loss of 0.5631073713302612\n",
            "0.5725144743919373\n",
            "Epoch #2. Batch Id 174/278  is having validation accuracy of 84.25\n",
            "Epoch #2. Batch Id 175/278  is having validation loss of 0.5639644265174866\n",
            "0.7139460444450378\n",
            "Epoch #2. Batch Id 175/278  is having validation accuracy of 84.25071022727273\n",
            "Epoch #2. Batch Id 176/278  is having validation loss of 0.5629215836524963\n",
            "0.37938645482063293\n",
            "Epoch #2. Batch Id 176/278  is having validation accuracy of 84.28672316384181\n",
            "Epoch #2. Batch Id 177/278  is having validation loss of 0.5614508390426636\n",
            "0.3011326491832733\n",
            "Epoch #2. Batch Id 177/278  is having validation accuracy of 84.32233146067416\n",
            "Epoch #2. Batch Id 178/278  is having validation loss of 0.5618271827697754\n",
            "0.6288158297538757\n",
            "Epoch #2. Batch Id 178/278  is having validation accuracy of 84.32262569832402\n",
            "Epoch #2. Batch Id 179/278  is having validation loss of 0.5632883906364441\n",
            "0.8248440027236938\n",
            "Epoch #2. Batch Id 179/278  is having validation accuracy of 84.25347222222223\n",
            "Epoch #2. Batch Id 180/278  is having validation loss of 0.565093457698822\n",
            "0.8900030255317688\n",
            "Epoch #2. Batch Id 180/278  is having validation accuracy of 84.16781767955801\n",
            "Epoch #2. Batch Id 181/278  is having validation loss of 0.5639750361442566\n",
            "0.36153820157051086\n",
            "Epoch #2. Batch Id 181/278  is having validation accuracy of 84.18612637362638\n",
            "Epoch #2. Batch Id 182/278  is having validation loss of 0.5646612644195557\n",
            "0.6895589828491211\n",
            "Epoch #2. Batch Id 182/278  is having validation accuracy of 84.15300546448087\n",
            "Epoch #2. Batch Id 183/278  is having validation loss of 0.5644471049308777\n",
            "0.5252573490142822\n",
            "Epoch #2. Batch Id 183/278  is having validation accuracy of 84.1881793478261\n",
            "Epoch #2. Batch Id 184/278  is having validation loss of 0.5634776949882507\n",
            "0.38510552048683167\n",
            "Epoch #2. Batch Id 184/278  is having validation accuracy of 84.22297297297297\n",
            "Epoch #2. Batch Id 185/278  is having validation loss of 0.5624870657920837\n",
            "0.37922245264053345\n",
            "Epoch #2. Batch Id 185/278  is having validation accuracy of 84.25739247311827\n",
            "Epoch #2. Batch Id 186/278  is having validation loss of 0.5626920461654663\n",
            "0.600822389125824\n",
            "Epoch #2. Batch Id 186/278  is having validation accuracy of 84.25802139037434\n",
            "Epoch #2. Batch Id 187/278  is having validation loss of 0.562389612197876\n",
            "0.5058339834213257\n",
            "Epoch #2. Batch Id 187/278  is having validation accuracy of 84.2752659574468\n",
            "Epoch #2. Batch Id 188/278  is having validation loss of 0.5641773343086243\n",
            "0.9002731442451477\n",
            "Epoch #2. Batch Id 188/278  is having validation accuracy of 84.24272486772487\n",
            "Epoch #2. Batch Id 189/278  is having validation loss of 0.5650948286056519\n",
            "0.7384999990463257\n",
            "Epoch #2. Batch Id 189/278  is having validation accuracy of 84.24342105263158\n",
            "Epoch #2. Batch Id 190/278  is having validation loss of 0.5637673139572144\n",
            "0.31153497099876404\n",
            "Epoch #2. Batch Id 190/278  is having validation accuracy of 84.27683246073299\n",
            "Epoch #2. Batch Id 191/278  is having validation loss of 0.5665735602378845\n",
            "1.1025645732879639\n",
            "Epoch #2. Batch Id 191/278  is having validation accuracy of 84.228515625\n",
            "Epoch #2. Batch Id 192/278  is having validation loss of 0.5659844279289246\n",
            "0.4528658390045166\n",
            "Epoch #2. Batch Id 192/278  is having validation accuracy of 84.26165803108809\n",
            "Epoch #2. Batch Id 193/278  is having validation loss of 0.5669589042663574\n",
            "0.7550331950187683\n",
            "Epoch #2. Batch Id 193/278  is having validation accuracy of 84.24613402061856\n",
            "Epoch #2. Batch Id 194/278  is having validation loss of 0.5663691163063049\n",
            "0.4519452452659607\n",
            "Epoch #2. Batch Id 194/278  is having validation accuracy of 84.26282051282051\n",
            "Epoch #2. Batch Id 195/278  is having validation loss of 0.567043125629425\n",
            "0.6984707117080688\n",
            "Epoch #2. Batch Id 195/278  is having validation accuracy of 84.23150510204081\n",
            "Epoch #2. Batch Id 196/278  is having validation loss of 0.567500650882721\n",
            "0.6571812629699707\n",
            "Epoch #2. Batch Id 196/278  is having validation accuracy of 84.18464467005076\n",
            "Epoch #2. Batch Id 197/278  is having validation loss of 0.5676618218421936\n",
            "0.5994139313697815\n",
            "Epoch #2. Batch Id 197/278  is having validation accuracy of 84.18560606060606\n",
            "Epoch #2. Batch Id 198/278  is having validation loss of 0.5697378516197205\n",
            "0.980787992477417\n",
            "Epoch #2. Batch Id 198/278  is having validation accuracy of 84.12374371859296\n",
            "Epoch #2. Batch Id 199/278  is having validation loss of 0.5690110921859741\n",
            "0.4243869185447693\n",
            "Epoch #2. Batch Id 199/278  is having validation accuracy of 84.15625\n",
            "Epoch #2. Batch Id 200/278  is having validation loss of 0.5689267516136169\n",
            "0.5520569682121277\n",
            "Epoch #2. Batch Id 200/278  is having validation accuracy of 84.15733830845771\n",
            "Epoch #2. Batch Id 201/278  is having validation loss of 0.5700358152389526\n",
            "0.7929537296295166\n",
            "Epoch #2. Batch Id 201/278  is having validation accuracy of 84.12747524752476\n",
            "Epoch #2. Batch Id 202/278  is having validation loss of 0.5692799687385559\n",
            "0.416604608297348\n",
            "Epoch #2. Batch Id 202/278  is having validation accuracy of 84.11330049261083\n",
            "Epoch #2. Batch Id 203/278  is having validation loss of 0.5698556303977966\n",
            "0.6867100596427917\n",
            "Epoch #2. Batch Id 203/278  is having validation accuracy of 84.08394607843137\n",
            "Epoch #2. Batch Id 204/278  is having validation loss of 0.570121169090271\n",
            "0.6242967844009399\n",
            "Epoch #2. Batch Id 204/278  is having validation accuracy of 84.08536585365853\n",
            "Epoch #2. Batch Id 205/278  is having validation loss of 0.5699262022972107\n",
            "0.5299577713012695\n",
            "Epoch #2. Batch Id 205/278  is having validation accuracy of 84.10194174757281\n",
            "Epoch #2. Batch Id 206/278  is having validation loss of 0.5689208507537842\n",
            "0.3618161380290985\n",
            "Epoch #2. Batch Id 206/278  is having validation accuracy of 84.10326086956522\n",
            "Epoch #2. Batch Id 207/278  is having validation loss of 0.5680546164512634\n",
            "0.3887380063533783\n",
            "Epoch #2. Batch Id 207/278  is having validation accuracy of 84.13461538461539\n",
            "Epoch #2. Batch Id 208/278  is having validation loss of 0.5684413909912109\n",
            "0.6488960385322571\n",
            "Epoch #2. Batch Id 208/278  is having validation accuracy of 84.12081339712918\n",
            "Epoch #2. Batch Id 209/278  is having validation loss of 0.5670716762542725\n",
            "0.280799001455307\n",
            "Epoch #2. Batch Id 209/278  is having validation accuracy of 84.16666666666667\n",
            "Epoch #2. Batch Id 210/278  is having validation loss of 0.5698919296264648\n",
            "1.1621426343917847\n",
            "Epoch #2. Batch Id 210/278  is having validation accuracy of 84.07879146919431\n",
            "Epoch #2. Batch Id 211/278  is having validation loss of 0.5700826048851013\n",
            "0.6103208065032959\n",
            "Epoch #2. Batch Id 211/278  is having validation accuracy of 84.08018867924528\n",
            "Epoch #2. Batch Id 212/278  is having validation loss of 0.5720155835151672\n",
            "0.9818063974380493\n",
            "Epoch #2. Batch Id 212/278  is having validation accuracy of 84.05223004694835\n",
            "Epoch #2. Batch Id 213/278  is having validation loss of 0.5728231072425842\n",
            "0.744827151298523\n",
            "Epoch #2. Batch Id 213/278  is having validation accuracy of 83.99532710280374\n",
            "Epoch #2. Batch Id 214/278  is having validation loss of 0.5730384588241577\n",
            "0.619121789932251\n",
            "Epoch #2. Batch Id 214/278  is having validation accuracy of 84.01162790697674\n",
            "Epoch #2. Batch Id 215/278  is having validation loss of 0.572995662689209\n",
            "0.5637970566749573\n",
            "Epoch #2. Batch Id 215/278  is having validation accuracy of 84.01331018518519\n",
            "Epoch #2. Batch Id 216/278  is having validation loss of 0.572842001914978\n",
            "0.5396504998207092\n",
            "Epoch #2. Batch Id 216/278  is having validation accuracy of 84.04377880184332\n",
            "Epoch #2. Batch Id 217/278  is having validation loss of 0.5739625096321106\n",
            "0.817107081413269\n",
            "Epoch #2. Batch Id 217/278  is having validation accuracy of 84.01662844036697\n",
            "Epoch #2. Batch Id 218/278  is having validation loss of 0.5739251375198364\n",
            "0.5657771229743958\n",
            "Epoch #2. Batch Id 218/278  is having validation accuracy of 83.98972602739725\n",
            "Epoch #2. Batch Id 219/278  is having validation loss of 0.574781060218811\n",
            "0.762234628200531\n",
            "Epoch #2. Batch Id 219/278  is having validation accuracy of 83.97727272727273\n",
            "Epoch #2. Batch Id 220/278  is having validation loss of 0.5741967558860779\n",
            "0.44564980268478394\n",
            "Epoch #2. Batch Id 220/278  is having validation accuracy of 84.00735294117646\n",
            "Epoch #2. Batch Id 221/278  is having validation loss of 0.5740233659744263\n",
            "0.5356998443603516\n",
            "Epoch #2. Batch Id 221/278  is having validation accuracy of 84.02308558558559\n",
            "Epoch #2. Batch Id 222/278  is having validation loss of 0.5750113725662231\n",
            "0.7943487763404846\n",
            "Epoch #2. Batch Id 222/278  is having validation accuracy of 83.98262331838565\n",
            "Epoch #2. Batch Id 223/278  is having validation loss of 0.5745546817779541\n",
            "0.47270679473876953\n",
            "Epoch #2. Batch Id 223/278  is having validation accuracy of 83.99832589285714\n",
            "Epoch #2. Batch Id 224/278  is having validation loss of 0.5751355290412903\n",
            "0.705250084400177\n",
            "Epoch #2. Batch Id 224/278  is having validation accuracy of 83.95833333333333\n",
            "Epoch #2. Batch Id 225/278  is having validation loss of 0.5743409991264343\n",
            "0.39556702971458435\n",
            "Epoch #2. Batch Id 225/278  is having validation accuracy of 84.01548672566372\n",
            "Epoch #2. Batch Id 226/278  is having validation loss of 0.5733511447906494\n",
            "0.34963858127593994\n",
            "Epoch #2. Batch Id 226/278  is having validation accuracy of 84.0033039647577\n",
            "Epoch #2. Batch Id 227/278  is having validation loss of 0.5741786360740662\n",
            "0.7620214223861694\n",
            "Epoch #2. Batch Id 227/278  is having validation accuracy of 83.96381578947368\n",
            "Epoch #2. Batch Id 228/278  is having validation loss of 0.5743601322174072\n",
            "0.6157472729682922\n",
            "Epoch #2. Batch Id 228/278  is having validation accuracy of 83.93831877729258\n",
            "Epoch #2. Batch Id 229/278  is having validation loss of 0.5765501260757446\n",
            "1.0780638456344604\n",
            "Epoch #2. Batch Id 229/278  is having validation accuracy of 83.89945652173913\n",
            "Epoch #2. Batch Id 230/278  is having validation loss of 0.5764079093933105\n",
            "0.5436919331550598\n",
            "Epoch #2. Batch Id 230/278  is having validation accuracy of 83.88798701298701\n",
            "Epoch #2. Batch Id 231/278  is having validation loss of 0.5757104158401489\n",
            "0.4145851135253906\n",
            "Epoch #2. Batch Id 231/278  is having validation accuracy of 83.90355603448276\n",
            "Epoch #2. Batch Id 232/278  is having validation loss of 0.5752125382423401\n",
            "0.45970988273620605\n",
            "Epoch #2. Batch Id 232/278  is having validation accuracy of 83.9324034334764\n",
            "Epoch #2. Batch Id 233/278  is having validation loss of 0.5747866630554199\n",
            "0.47555410861968994\n",
            "Epoch #2. Batch Id 233/278  is having validation accuracy of 83.94764957264957\n",
            "Epoch #2. Batch Id 234/278  is having validation loss of 0.5740295648574829\n",
            "0.39686715602874756\n",
            "Epoch #2. Batch Id 234/278  is having validation accuracy of 83.9627659574468\n",
            "Epoch #2. Batch Id 235/278  is having validation loss of 0.5735886096954346\n",
            "0.4699588418006897\n",
            "Epoch #2. Batch Id 235/278  is having validation accuracy of 83.9645127118644\n",
            "Epoch #2. Batch Id 236/278  is having validation loss of 0.5735110640525818\n",
            "0.5552084445953369\n",
            "Epoch #2. Batch Id 236/278  is having validation accuracy of 83.92668776371308\n",
            "Epoch #2. Batch Id 237/278  is having validation loss of 0.5727664828300476\n",
            "0.3962957262992859\n",
            "Epoch #2. Batch Id 237/278  is having validation accuracy of 83.9548319327731\n",
            "Epoch #2. Batch Id 238/278  is having validation loss of 0.5745131373405457\n",
            "0.9902203679084778\n",
            "Epoch #2. Batch Id 238/278  is having validation accuracy of 83.90428870292887\n",
            "Epoch #2. Batch Id 239/278  is having validation loss of 0.5727221369743347\n",
            "0.1446722000837326\n",
            "Epoch #2. Batch Id 239/278  is having validation accuracy of 83.97135416666667\n",
            "Epoch #2. Batch Id 240/278  is having validation loss of 0.5732415318489075\n",
            "0.6978902220726013\n",
            "Epoch #2. Batch Id 240/278  is having validation accuracy of 83.94709543568464\n",
            "Epoch #2. Batch Id 241/278  is having validation loss of 0.5736104249954224\n",
            "0.6625188589096069\n",
            "Epoch #2. Batch Id 241/278  is having validation accuracy of 83.93595041322314\n",
            "Epoch #2. Batch Id 242/278  is having validation loss of 0.5728573799133301\n",
            "0.39062511920928955\n",
            "Epoch #2. Batch Id 242/278  is having validation accuracy of 83.96347736625515\n",
            "Epoch #2. Batch Id 243/278  is having validation loss of 0.5719497203826904\n",
            "0.35138440132141113\n",
            "Epoch #2. Batch Id 243/278  is having validation accuracy of 83.99077868852459\n",
            "Epoch #2. Batch Id 244/278  is having validation loss of 0.5726186037063599\n",
            "0.7358260154724121\n",
            "Epoch #2. Batch Id 244/278  is having validation accuracy of 83.94132653061224\n",
            "Epoch #2. Batch Id 245/278  is having validation loss of 0.5743178129196167\n",
            "0.990628182888031\n",
            "Epoch #2. Batch Id 245/278  is having validation accuracy of 83.90497967479675\n",
            "Epoch #2. Batch Id 246/278  is having validation loss of 0.5764792561531067\n",
            "1.1081913709640503\n",
            "Epoch #2. Batch Id 246/278  is having validation accuracy of 83.88157894736842\n",
            "Epoch #2. Batch Id 247/278  is having validation loss of 0.5761081576347351\n",
            "0.4844433665275574\n",
            "Epoch #2. Batch Id 247/278  is having validation accuracy of 83.8835685483871\n",
            "Epoch #2. Batch Id 248/278  is having validation loss of 0.5767387747764587\n",
            "0.7331260442733765\n",
            "Epoch #2. Batch Id 248/278  is having validation accuracy of 83.8855421686747\n",
            "Epoch #2. Batch Id 249/278  is having validation loss of 0.5758448839187622\n",
            "0.3532717823982239\n",
            "Epoch #2. Batch Id 249/278  is having validation accuracy of 83.9125\n",
            "Epoch #2. Batch Id 250/278  is having validation loss of 0.5760522484779358\n",
            "0.6278908252716064\n",
            "Epoch #2. Batch Id 250/278  is having validation accuracy of 83.92679282868527\n",
            "Epoch #2. Batch Id 251/278  is having validation loss of 0.5770441293716431\n",
            "0.8260013461112976\n",
            "Epoch #2. Batch Id 251/278  is having validation accuracy of 83.91617063492063\n",
            "Epoch #2. Batch Id 252/278  is having validation loss of 0.5763533711433411\n",
            "0.40227803587913513\n",
            "Epoch #2. Batch Id 252/278  is having validation accuracy of 83.9550395256917\n",
            "Epoch #2. Batch Id 253/278  is having validation loss of 0.5780782103538513\n",
            "1.0144699811935425\n",
            "Epoch #2. Batch Id 253/278  is having validation accuracy of 83.89517716535433\n",
            "Epoch #2. Batch Id 254/278  is having validation loss of 0.5779885053634644\n",
            "0.5552002787590027\n",
            "Epoch #2. Batch Id 254/278  is having validation accuracy of 83.9093137254902\n",
            "Epoch #2. Batch Id 255/278  is having validation loss of 0.5768797397613525\n",
            "0.2941432297229767\n",
            "Epoch #2. Batch Id 255/278  is having validation accuracy of 83.94775390625\n",
            "Epoch #2. Batch Id 256/278  is having validation loss of 0.5758628845214844\n",
            "0.31554555892944336\n",
            "Epoch #2. Batch Id 256/278  is having validation accuracy of 83.97373540856032\n",
            "Epoch #2. Batch Id 257/278  is having validation loss of 0.5746712684631348\n",
            "0.26842397451400757\n",
            "Epoch #2. Batch Id 257/278  is having validation accuracy of 84.01162790697674\n",
            "Epoch #2. Batch Id 258/278  is having validation loss of 0.5740430951118469\n",
            "0.4119679927825928\n",
            "Epoch #2. Batch Id 258/278  is having validation accuracy of 84.0492277992278\n",
            "Epoch #2. Batch Id 259/278  is having validation loss of 0.5733010768890381\n",
            "0.3811141848564148\n",
            "Epoch #2. Batch Id 259/278  is having validation accuracy of 84.08653846153847\n",
            "Epoch #2. Batch Id 260/278  is having validation loss of 0.5724833011627197\n",
            "0.35986676812171936\n",
            "Epoch #2. Batch Id 260/278  is having validation accuracy of 84.08764367816092\n",
            "Epoch #2. Batch Id 261/278  is having validation loss of 0.5721558928489685\n",
            "0.4867003560066223\n",
            "Epoch #2. Batch Id 261/278  is having validation accuracy of 84.1006679389313\n",
            "Epoch #2. Batch Id 262/278  is having validation loss of 0.5722237825393677\n",
            "0.5900091528892517\n",
            "Epoch #2. Batch Id 262/278  is having validation accuracy of 84.0898288973384\n",
            "Epoch #2. Batch Id 263/278  is having validation loss of 0.5727117657661438\n",
            "0.7010572552680969\n",
            "Epoch #2. Batch Id 263/278  is having validation accuracy of 84.05539772727273\n",
            "Epoch #2. Batch Id 264/278  is having validation loss of 0.5716274976730347\n",
            "0.28538697957992554\n",
            "Epoch #2. Batch Id 264/278  is having validation accuracy of 84.09198113207547\n",
            "Epoch #2. Batch Id 265/278  is having validation loss of 0.5726022124290466\n",
            "0.8309048414230347\n",
            "Epoch #2. Batch Id 265/278  is having validation accuracy of 84.06954887218045\n",
            "Epoch #2. Batch Id 266/278  is having validation loss of 0.5730936527252197\n",
            "0.7038186192512512\n",
            "Epoch #2. Batch Id 266/278  is having validation accuracy of 84.07069288389513\n",
            "Epoch #2. Batch Id 267/278  is having validation loss of 0.5722028017044067\n",
            "0.33433976769447327\n",
            "Epoch #2. Batch Id 267/278  is having validation accuracy of 84.09514925373135\n",
            "Epoch #2. Batch Id 268/278  is having validation loss of 0.5716755390167236\n",
            "0.430370032787323\n",
            "Epoch #2. Batch Id 268/278  is having validation accuracy of 84.10780669144981\n",
            "Epoch #2. Batch Id 269/278  is having validation loss of 0.5706431269645691\n",
            "0.29293185472488403\n",
            "Epoch #2. Batch Id 269/278  is having validation accuracy of 84.12037037037037\n",
            "Epoch #2. Batch Id 270/278  is having validation loss of 0.5706635117530823\n",
            "0.5761598348617554\n",
            "Epoch #2. Batch Id 270/278  is having validation accuracy of 84.13284132841328\n",
            "Epoch #2. Batch Id 271/278  is having validation loss of 0.5709971189498901\n",
            "0.6614058017730713\n",
            "Epoch #2. Batch Id 271/278  is having validation accuracy of 84.12224264705883\n",
            "Epoch #2. Batch Id 272/278  is having validation loss of 0.5719841122627258\n",
            "0.8404428362846375\n",
            "Epoch #2. Batch Id 272/278  is having validation accuracy of 84.07738095238095\n",
            "Epoch #2. Batch Id 273/278  is having validation loss of 0.5729517340660095\n",
            "0.8371164202690125\n",
            "Epoch #2. Batch Id 273/278  is having validation accuracy of 84.06706204379562\n",
            "Epoch #2. Batch Id 274/278  is having validation loss of 0.5728450417518616\n",
            "0.5436088442802429\n",
            "Epoch #2. Batch Id 274/278  is having validation accuracy of 84.05681818181819\n",
            "Epoch #2. Batch Id 275/278  is having validation loss of 0.5734838843345642\n",
            "0.7491624355316162\n",
            "Epoch #2. Batch Id 275/278  is having validation accuracy of 84.04664855072464\n",
            "Epoch #2. Batch Id 276/278  is having validation loss of 0.573552668094635\n",
            "0.5925342440605164\n",
            "Epoch #2. Batch Id 276/278  is having validation accuracy of 84.04783393501805\n",
            "Epoch #2. Batch Id 277/278  is having validation loss of 0.5715509653091431\n",
            "0.017085062339901924\n",
            "Epoch #2. Batch Id 277/278  is having validation accuracy of 84.05502931889941\n",
            "Эпоха #2 train_loss: 5.765807145508006e-06, val_loss: 6.445094186346978e-05\n",
            "Потрачено 8.8 минут на 2 эпоху\n",
            "Batch Id 0 is having training loss of 0.4348130226135254\n",
            "0.4348130226135254\n",
            "Epoch #3. Accuracy on batch 0/3013  on Training is 90.625\n",
            "Epoch #3. Accuracy on batch 1/3013  on Training is 84.375\n",
            "Epoch #3. Accuracy on batch 2/3013  on Training is 84.375\n",
            "Epoch #3. Accuracy on batch 3/3013  on Training is 85.15625\n",
            "Epoch #3. Accuracy on batch 4/3013  on Training is 86.25\n",
            "Epoch #3. Accuracy on batch 5/3013  on Training is 88.02083333333333\n",
            "Epoch #3. Accuracy on batch 6/3013  on Training is 87.05357142857143\n",
            "Epoch #3. Accuracy on batch 7/3013  on Training is 87.109375\n",
            "Epoch #3. Accuracy on batch 8/3013  on Training is 86.80555555555556\n",
            "Epoch #3. Accuracy on batch 9/3013  on Training is 86.5625\n",
            "Epoch #3. Accuracy on batch 10/3013  on Training is 86.07954545454545\n",
            "Epoch #3. Accuracy on batch 11/3013  on Training is 86.97916666666667\n",
            "Epoch #3. Accuracy on batch 12/3013  on Training is 86.53846153846153\n",
            "Epoch #3. Accuracy on batch 13/3013  on Training is 86.38392857142857\n",
            "Epoch #3. Accuracy on batch 14/3013  on Training is 86.875\n",
            "Epoch #3. Accuracy on batch 15/3013  on Training is 86.9140625\n",
            "Epoch #3. Accuracy on batch 16/3013  on Training is 86.76470588235294\n",
            "Epoch #3. Accuracy on batch 17/3013  on Training is 87.15277777777777\n",
            "Epoch #3. Accuracy on batch 18/3013  on Training is 87.00657894736842\n",
            "Epoch #3. Accuracy on batch 19/3013  on Training is 86.5625\n",
            "Batch Id 20 is having training loss of 0.4911290109157562\n",
            "0.37309548258781433\n",
            "Epoch #3. Accuracy on batch 20/3013  on Training is 86.60714285714286\n",
            "Epoch #3. Accuracy on batch 21/3013  on Training is 86.78977272727273\n",
            "Epoch #3. Accuracy on batch 22/3013  on Training is 86.95652173913044\n",
            "Epoch #3. Accuracy on batch 23/3013  on Training is 87.23958333333333\n",
            "Epoch #3. Accuracy on batch 24/3013  on Training is 86.875\n",
            "Epoch #3. Accuracy on batch 25/3013  on Training is 87.01923076923077\n",
            "Epoch #3. Accuracy on batch 26/3013  on Training is 87.03703703703704\n",
            "Epoch #3. Accuracy on batch 27/3013  on Training is 87.27678571428571\n",
            "Epoch #3. Accuracy on batch 28/3013  on Training is 87.28448275862068\n",
            "Epoch #3. Accuracy on batch 29/3013  on Training is 87.5\n",
            "Epoch #3. Accuracy on batch 30/3013  on Training is 87.5\n",
            "Epoch #3. Accuracy on batch 31/3013  on Training is 87.79296875\n",
            "Epoch #3. Accuracy on batch 32/3013  on Training is 88.06818181818181\n",
            "Epoch #3. Accuracy on batch 33/3013  on Training is 88.05147058823529\n",
            "Epoch #3. Accuracy on batch 34/3013  on Training is 88.21428571428571\n",
            "Epoch #3. Accuracy on batch 35/3013  on Training is 87.93402777777777\n",
            "Epoch #3. Accuracy on batch 36/3013  on Training is 87.75337837837837\n",
            "Epoch #3. Accuracy on batch 37/3013  on Training is 87.82894736842105\n",
            "Epoch #3. Accuracy on batch 38/3013  on Training is 87.90064102564102\n",
            "Epoch #3. Accuracy on batch 39/3013  on Training is 87.65625\n",
            "Batch Id 40 is having training loss of 0.4381623864173889\n",
            "0.6340330839157104\n",
            "Epoch #3. Accuracy on batch 40/3013  on Training is 87.57621951219512\n",
            "Epoch #3. Accuracy on batch 41/3013  on Training is 87.27678571428571\n",
            "Epoch #3. Accuracy on batch 42/3013  on Training is 87.5\n",
            "Epoch #3. Accuracy on batch 43/3013  on Training is 87.42897727272727\n",
            "Epoch #3. Accuracy on batch 44/3013  on Training is 87.22222222222223\n",
            "Epoch #3. Accuracy on batch 45/3013  on Training is 87.22826086956522\n",
            "Epoch #3. Accuracy on batch 46/3013  on Training is 87.10106382978724\n",
            "Epoch #3. Accuracy on batch 47/3013  on Training is 87.04427083333333\n",
            "Epoch #3. Accuracy on batch 48/3013  on Training is 87.24489795918367\n",
            "Epoch #3. Accuracy on batch 49/3013  on Training is 87.1875\n",
            "Epoch #3. Accuracy on batch 50/3013  on Training is 87.13235294117646\n",
            "Epoch #3. Accuracy on batch 51/3013  on Training is 87.01923076923077\n",
            "Epoch #3. Accuracy on batch 52/3013  on Training is 86.79245283018868\n",
            "Epoch #3. Accuracy on batch 53/3013  on Training is 86.68981481481481\n",
            "Epoch #3. Accuracy on batch 54/3013  on Training is 86.64772727272727\n",
            "Epoch #3. Accuracy on batch 55/3013  on Training is 86.66294642857143\n",
            "Epoch #3. Accuracy on batch 56/3013  on Training is 86.67763157894737\n",
            "Epoch #3. Accuracy on batch 57/3013  on Training is 86.74568965517241\n",
            "Epoch #3. Accuracy on batch 58/3013  on Training is 86.75847457627118\n",
            "Epoch #3. Accuracy on batch 59/3013  on Training is 86.82291666666667\n",
            "Batch Id 60 is having training loss of 0.4598672389984131\n",
            "0.30154550075531006\n",
            "Epoch #3. Accuracy on batch 60/3013  on Training is 86.93647540983606\n",
            "Epoch #3. Accuracy on batch 61/3013  on Training is 86.84475806451613\n",
            "Epoch #3. Accuracy on batch 62/3013  on Training is 86.80555555555556\n",
            "Epoch #3. Accuracy on batch 63/3013  on Training is 86.865234375\n",
            "Epoch #3. Accuracy on batch 64/3013  on Training is 86.82692307692308\n",
            "Epoch #3. Accuracy on batch 65/3013  on Training is 86.83712121212122\n",
            "Epoch #3. Accuracy on batch 66/3013  on Training is 86.84701492537313\n",
            "Epoch #3. Accuracy on batch 67/3013  on Training is 86.90257352941177\n",
            "Epoch #3. Accuracy on batch 68/3013  on Training is 86.8659420289855\n",
            "Epoch #3. Accuracy on batch 69/3013  on Training is 86.96428571428571\n",
            "Epoch #3. Accuracy on batch 70/3013  on Training is 86.97183098591549\n",
            "Epoch #3. Accuracy on batch 71/3013  on Training is 87.06597222222223\n",
            "Epoch #3. Accuracy on batch 72/3013  on Training is 86.98630136986301\n",
            "Epoch #3. Accuracy on batch 73/3013  on Training is 86.86655405405405\n",
            "Epoch #3. Accuracy on batch 74/3013  on Training is 87.0\n",
            "Epoch #3. Accuracy on batch 75/3013  on Training is 86.9654605263158\n",
            "Epoch #3. Accuracy on batch 76/3013  on Training is 86.93181818181819\n",
            "Epoch #3. Accuracy on batch 77/3013  on Training is 86.81891025641026\n",
            "Epoch #3. Accuracy on batch 78/3013  on Training is 86.66930379746836\n",
            "Epoch #3. Accuracy on batch 79/3013  on Training is 86.71875\n",
            "Batch Id 80 is having training loss of 0.46821528673171997\n",
            "0.567108690738678\n",
            "Epoch #3. Accuracy on batch 80/3013  on Training is 86.61265432098766\n",
            "Epoch #3. Accuracy on batch 81/3013  on Training is 86.69969512195122\n",
            "Epoch #3. Accuracy on batch 82/3013  on Training is 86.82228915662651\n",
            "Epoch #3. Accuracy on batch 83/3013  on Training is 86.68154761904762\n",
            "Epoch #3. Accuracy on batch 84/3013  on Training is 86.69117647058823\n",
            "Epoch #3. Accuracy on batch 85/3013  on Training is 86.62790697674419\n",
            "Epoch #3. Accuracy on batch 86/3013  on Training is 86.60201149425288\n",
            "Epoch #3. Accuracy on batch 87/3013  on Training is 86.39914772727273\n",
            "Epoch #3. Accuracy on batch 88/3013  on Training is 86.3061797752809\n",
            "Epoch #3. Accuracy on batch 89/3013  on Training is 86.35416666666667\n",
            "Epoch #3. Accuracy on batch 90/3013  on Training is 86.46978021978022\n",
            "Epoch #3. Accuracy on batch 91/3013  on Training is 86.5149456521739\n",
            "Epoch #3. Accuracy on batch 92/3013  on Training is 86.49193548387096\n",
            "Epoch #3. Accuracy on batch 93/3013  on Training is 86.56914893617021\n",
            "Epoch #3. Accuracy on batch 94/3013  on Training is 86.54605263157895\n",
            "Epoch #3. Accuracy on batch 95/3013  on Training is 86.55598958333333\n",
            "Epoch #3. Accuracy on batch 96/3013  on Training is 86.53350515463917\n",
            "Epoch #3. Accuracy on batch 97/3013  on Training is 86.54336734693878\n",
            "Epoch #3. Accuracy on batch 98/3013  on Training is 86.58459595959596\n",
            "Epoch #3. Accuracy on batch 99/3013  on Training is 86.4375\n",
            "Batch Id 100 is having training loss of 0.47939348220825195\n",
            "0.41097480058670044\n",
            "Epoch #3. Accuracy on batch 100/3013  on Training is 86.4480198019802\n",
            "Epoch #3. Accuracy on batch 101/3013  on Training is 86.42769607843137\n",
            "Epoch #3. Accuracy on batch 102/3013  on Training is 86.4381067961165\n",
            "Epoch #3. Accuracy on batch 103/3013  on Training is 86.41826923076923\n",
            "Epoch #3. Accuracy on batch 104/3013  on Training is 86.42857142857143\n",
            "Epoch #3. Accuracy on batch 105/3013  on Training is 86.46816037735849\n",
            "Epoch #3. Accuracy on batch 106/3013  on Training is 86.53621495327103\n",
            "Epoch #3. Accuracy on batch 107/3013  on Training is 86.54513888888889\n",
            "Epoch #3. Accuracy on batch 108/3013  on Training is 86.63990825688073\n",
            "Epoch #3. Accuracy on batch 109/3013  on Training is 86.61931818181819\n",
            "Epoch #3. Accuracy on batch 110/3013  on Training is 86.6554054054054\n",
            "Epoch #3. Accuracy on batch 111/3013  on Training is 86.71875\n",
            "Epoch #3. Accuracy on batch 112/3013  on Training is 86.72566371681415\n",
            "Epoch #3. Accuracy on batch 113/3013  on Training is 86.67763157894737\n",
            "Epoch #3. Accuracy on batch 114/3013  on Training is 86.71195652173913\n",
            "Epoch #3. Accuracy on batch 115/3013  on Training is 86.66487068965517\n",
            "Epoch #3. Accuracy on batch 116/3013  on Training is 86.72542735042735\n",
            "Epoch #3. Accuracy on batch 117/3013  on Training is 86.75847457627118\n",
            "Epoch #3. Accuracy on batch 118/3013  on Training is 86.76470588235294\n",
            "Epoch #3. Accuracy on batch 119/3013  on Training is 86.74479166666667\n",
            "Batch Id 120 is having training loss of 0.4734289050102234\n",
            "0.39575883746147156\n",
            "Epoch #3. Accuracy on batch 120/3013  on Training is 86.75103305785125\n",
            "Epoch #3. Accuracy on batch 121/3013  on Training is 86.7827868852459\n",
            "Epoch #3. Accuracy on batch 122/3013  on Training is 86.76321138211382\n",
            "Epoch #3. Accuracy on batch 123/3013  on Training is 86.69354838709677\n",
            "Epoch #3. Accuracy on batch 124/3013  on Training is 86.725\n",
            "Epoch #3. Accuracy on batch 125/3013  on Training is 86.65674603174604\n",
            "Epoch #3. Accuracy on batch 126/3013  on Training is 86.63877952755905\n",
            "Epoch #3. Accuracy on batch 127/3013  on Training is 86.5966796875\n",
            "Epoch #3. Accuracy on batch 128/3013  on Training is 86.57945736434108\n",
            "Epoch #3. Accuracy on batch 129/3013  on Training is 86.58653846153847\n",
            "Epoch #3. Accuracy on batch 130/3013  on Training is 86.6412213740458\n",
            "Epoch #3. Accuracy on batch 131/3013  on Training is 86.64772727272727\n",
            "Epoch #3. Accuracy on batch 132/3013  on Training is 86.70112781954887\n",
            "Epoch #3. Accuracy on batch 133/3013  on Training is 86.73041044776119\n",
            "Epoch #3. Accuracy on batch 134/3013  on Training is 86.71296296296296\n",
            "Epoch #3. Accuracy on batch 135/3013  on Training is 86.6498161764706\n",
            "Epoch #3. Accuracy on batch 136/3013  on Training is 86.61040145985402\n",
            "Epoch #3. Accuracy on batch 137/3013  on Training is 86.63949275362319\n",
            "Epoch #3. Accuracy on batch 138/3013  on Training is 86.64568345323741\n",
            "Epoch #3. Accuracy on batch 139/3013  on Training is 86.71875\n",
            "Batch Id 140 is having training loss of 0.47192835807800293\n",
            "0.4214678406715393\n",
            "Epoch #3. Accuracy on batch 140/3013  on Training is 86.70212765957447\n",
            "Epoch #3. Accuracy on batch 141/3013  on Training is 86.75176056338029\n",
            "Epoch #3. Accuracy on batch 142/3013  on Training is 86.7132867132867\n",
            "Epoch #3. Accuracy on batch 143/3013  on Training is 86.69704861111111\n",
            "Epoch #3. Accuracy on batch 144/3013  on Training is 86.68103448275862\n",
            "Epoch #3. Accuracy on batch 145/3013  on Training is 86.6652397260274\n",
            "Epoch #3. Accuracy on batch 146/3013  on Training is 86.6921768707483\n",
            "Epoch #3. Accuracy on batch 147/3013  on Training is 86.71875\n",
            "Epoch #3. Accuracy on batch 148/3013  on Training is 86.70302013422818\n",
            "Epoch #3. Accuracy on batch 149/3013  on Training is 86.75\n",
            "Epoch #3. Accuracy on batch 150/3013  on Training is 86.75496688741723\n",
            "Epoch #3. Accuracy on batch 151/3013  on Training is 86.75986842105263\n",
            "Epoch #3. Accuracy on batch 152/3013  on Training is 86.82598039215686\n",
            "Epoch #3. Accuracy on batch 153/3013  on Training is 86.85064935064935\n",
            "Epoch #3. Accuracy on batch 154/3013  on Training is 86.83467741935483\n",
            "Epoch #3. Accuracy on batch 155/3013  on Training is 86.85897435897436\n",
            "Epoch #3. Accuracy on batch 156/3013  on Training is 86.76353503184713\n",
            "Epoch #3. Accuracy on batch 157/3013  on Training is 86.7879746835443\n",
            "Epoch #3. Accuracy on batch 158/3013  on Training is 86.79245283018868\n",
            "Epoch #3. Accuracy on batch 159/3013  on Training is 86.71875\n",
            "Batch Id 160 is having training loss of 0.47503525018692017\n",
            "0.7055162191390991\n",
            "Epoch #3. Accuracy on batch 160/3013  on Training is 86.62655279503106\n",
            "Epoch #3. Accuracy on batch 161/3013  on Training is 86.61265432098766\n",
            "Epoch #3. Accuracy on batch 162/3013  on Training is 86.65644171779141\n",
            "Epoch #3. Accuracy on batch 163/3013  on Training is 86.66158536585365\n",
            "Epoch #3. Accuracy on batch 164/3013  on Training is 86.68560606060606\n",
            "Epoch #3. Accuracy on batch 165/3013  on Training is 86.67168674698796\n",
            "Epoch #3. Accuracy on batch 166/3013  on Training is 86.71407185628742\n",
            "Epoch #3. Accuracy on batch 167/3013  on Training is 86.68154761904762\n",
            "Epoch #3. Accuracy on batch 168/3013  on Training is 86.66789940828403\n",
            "Epoch #3. Accuracy on batch 169/3013  on Training is 86.65441176470588\n",
            "Epoch #3. Accuracy on batch 170/3013  on Training is 86.64108187134502\n",
            "Epoch #3. Accuracy on batch 171/3013  on Training is 86.60973837209302\n",
            "Epoch #3. Accuracy on batch 172/3013  on Training is 86.63294797687861\n",
            "Epoch #3. Accuracy on batch 173/3013  on Training is 86.6558908045977\n",
            "Epoch #3. Accuracy on batch 174/3013  on Training is 86.69642857142857\n",
            "Epoch #3. Accuracy on batch 175/3013  on Training is 86.59446022727273\n",
            "Epoch #3. Accuracy on batch 176/3013  on Training is 86.5819209039548\n",
            "Epoch #3. Accuracy on batch 177/3013  on Training is 86.51685393258427\n",
            "Epoch #3. Accuracy on batch 178/3013  on Training is 86.52234636871508\n",
            "Epoch #3. Accuracy on batch 179/3013  on Training is 86.54513888888889\n",
            "Batch Id 180 is having training loss of 0.4765828251838684\n",
            "0.4452407658100128\n",
            "Epoch #3. Accuracy on batch 180/3013  on Training is 86.55041436464089\n",
            "Epoch #3. Accuracy on batch 181/3013  on Training is 86.52129120879121\n",
            "Epoch #3. Accuracy on batch 182/3013  on Training is 86.50956284153006\n",
            "Epoch #3. Accuracy on batch 183/3013  on Training is 86.46399456521739\n",
            "Epoch #3. Accuracy on batch 184/3013  on Training is 86.4695945945946\n",
            "Epoch #3. Accuracy on batch 185/3013  on Training is 86.52553763440861\n",
            "Epoch #3. Accuracy on batch 186/3013  on Training is 86.46390374331551\n",
            "Epoch #3. Accuracy on batch 187/3013  on Training is 86.40292553191489\n",
            "Epoch #3. Accuracy on batch 188/3013  on Training is 86.30952380952381\n",
            "Epoch #3. Accuracy on batch 189/3013  on Training is 86.28289473684211\n",
            "Epoch #3. Accuracy on batch 190/3013  on Training is 86.2729057591623\n",
            "Epoch #3. Accuracy on batch 191/3013  on Training is 86.31184895833333\n",
            "Epoch #3. Accuracy on batch 192/3013  on Training is 86.38277202072538\n",
            "Epoch #3. Accuracy on batch 193/3013  on Training is 86.38853092783505\n",
            "Epoch #3. Accuracy on batch 194/3013  on Training is 86.39423076923077\n",
            "Epoch #3. Accuracy on batch 195/3013  on Training is 86.3998724489796\n",
            "Epoch #3. Accuracy on batch 196/3013  on Training is 86.45304568527919\n",
            "Epoch #3. Accuracy on batch 197/3013  on Training is 86.41098484848484\n",
            "Epoch #3. Accuracy on batch 198/3013  on Training is 86.44786432160804\n",
            "Epoch #3. Accuracy on batch 199/3013  on Training is 86.484375\n",
            "Batch Id 200 is having training loss of 0.4797498881816864\n",
            "0.48904287815093994\n",
            "Epoch #3. Accuracy on batch 200/3013  on Training is 86.44278606965175\n",
            "Epoch #3. Accuracy on batch 201/3013  on Training is 86.4480198019802\n",
            "Epoch #3. Accuracy on batch 202/3013  on Training is 86.45320197044335\n",
            "Epoch #3. Accuracy on batch 203/3013  on Training is 86.44301470588235\n",
            "Epoch #3. Accuracy on batch 204/3013  on Training is 86.46341463414635\n",
            "Epoch #3. Accuracy on batch 205/3013  on Training is 86.45327669902913\n",
            "Epoch #3. Accuracy on batch 206/3013  on Training is 86.45833333333333\n",
            "Epoch #3. Accuracy on batch 207/3013  on Training is 86.49338942307692\n",
            "Epoch #3. Accuracy on batch 208/3013  on Training is 86.48325358851675\n",
            "Epoch #3. Accuracy on batch 209/3013  on Training is 86.45833333333333\n",
            "Epoch #3. Accuracy on batch 210/3013  on Training is 86.44845971563981\n",
            "Epoch #3. Accuracy on batch 211/3013  on Training is 86.43867924528301\n",
            "Epoch #3. Accuracy on batch 212/3013  on Training is 86.45833333333333\n",
            "Epoch #3. Accuracy on batch 213/3013  on Training is 86.47780373831776\n",
            "Epoch #3. Accuracy on batch 214/3013  on Training is 86.49709302325581\n",
            "Epoch #3. Accuracy on batch 215/3013  on Training is 86.47280092592592\n",
            "Epoch #3. Accuracy on batch 216/3013  on Training is 86.463133640553\n",
            "Epoch #3. Accuracy on batch 217/3013  on Training is 86.4822247706422\n",
            "Epoch #3. Accuracy on batch 218/3013  on Training is 86.48687214611873\n",
            "Epoch #3. Accuracy on batch 219/3013  on Training is 86.47727272727273\n",
            "Batch Id 220 is having training loss of 0.47729286551475525\n",
            "0.42109835147857666\n",
            "Epoch #3. Accuracy on batch 220/3013  on Training is 86.48190045248869\n",
            "Epoch #3. Accuracy on batch 221/3013  on Training is 86.51463963963964\n",
            "Epoch #3. Accuracy on batch 222/3013  on Training is 86.46300448430493\n",
            "Epoch #3. Accuracy on batch 223/3013  on Training is 86.45368303571429\n",
            "Epoch #3. Accuracy on batch 224/3013  on Training is 86.47222222222223\n",
            "Epoch #3. Accuracy on batch 225/3013  on Training is 86.50442477876106\n",
            "Epoch #3. Accuracy on batch 226/3013  on Training is 86.49504405286343\n",
            "Epoch #3. Accuracy on batch 227/3013  on Training is 86.48574561403508\n",
            "Epoch #3. Accuracy on batch 228/3013  on Training is 86.5174672489083\n",
            "Epoch #3. Accuracy on batch 229/3013  on Training is 86.54891304347827\n",
            "Epoch #3. Accuracy on batch 230/3013  on Training is 86.49891774891775\n",
            "Epoch #3. Accuracy on batch 231/3013  on Training is 86.50323275862068\n",
            "Epoch #3. Accuracy on batch 232/3013  on Training is 86.50751072961373\n",
            "Epoch #3. Accuracy on batch 233/3013  on Training is 86.51175213675214\n",
            "Epoch #3. Accuracy on batch 234/3013  on Training is 86.48936170212765\n",
            "Epoch #3. Accuracy on batch 235/3013  on Training is 86.46716101694915\n",
            "Epoch #3. Accuracy on batch 236/3013  on Training is 86.44514767932489\n",
            "Epoch #3. Accuracy on batch 237/3013  on Training is 86.44957983193277\n",
            "Epoch #3. Accuracy on batch 238/3013  on Training is 86.38859832635983\n",
            "Epoch #3. Accuracy on batch 239/3013  on Training is 86.3671875\n",
            "Batch Id 240 is having training loss of 0.47803252935409546\n",
            "0.479579359292984\n",
            "Epoch #3. Accuracy on batch 240/3013  on Training is 86.35892116182572\n",
            "Epoch #3. Accuracy on batch 241/3013  on Training is 86.33780991735537\n",
            "Epoch #3. Accuracy on batch 242/3013  on Training is 86.3425925925926\n",
            "Epoch #3. Accuracy on batch 243/3013  on Training is 86.37295081967213\n",
            "Epoch #3. Accuracy on batch 244/3013  on Training is 86.37755102040816\n",
            "Epoch #3. Accuracy on batch 245/3013  on Training is 86.3185975609756\n",
            "Epoch #3. Accuracy on batch 246/3013  on Training is 86.29807692307692\n",
            "Epoch #3. Accuracy on batch 247/3013  on Training is 86.31552419354838\n",
            "Epoch #3. Accuracy on batch 248/3013  on Training is 86.30773092369478\n",
            "Epoch #3. Accuracy on batch 249/3013  on Training is 86.325\n",
            "Epoch #3. Accuracy on batch 250/3013  on Training is 86.29233067729083\n",
            "Epoch #3. Accuracy on batch 251/3013  on Training is 86.29712301587301\n",
            "Epoch #3. Accuracy on batch 252/3013  on Training is 86.27717391304348\n",
            "Epoch #3. Accuracy on batch 253/3013  on Training is 86.28198818897638\n",
            "Epoch #3. Accuracy on batch 254/3013  on Training is 86.28676470588235\n",
            "Epoch #3. Accuracy on batch 255/3013  on Training is 86.34033203125\n",
            "Epoch #3. Accuracy on batch 256/3013  on Training is 86.35700389105058\n",
            "Epoch #3. Accuracy on batch 257/3013  on Training is 86.33720930232558\n",
            "Epoch #3. Accuracy on batch 258/3013  on Training is 86.32963320463321\n",
            "Epoch #3. Accuracy on batch 259/3013  on Training is 86.35817307692308\n",
            "Batch Id 260 is having training loss of 0.47787728905677795\n",
            "0.6419360637664795\n",
            "Epoch #3. Accuracy on batch 260/3013  on Training is 86.32662835249042\n",
            "Epoch #3. Accuracy on batch 261/3013  on Training is 86.31917938931298\n",
            "Epoch #3. Accuracy on batch 262/3013  on Training is 86.29990494296578\n",
            "Epoch #3. Accuracy on batch 263/3013  on Training is 86.31628787878788\n",
            "Epoch #3. Accuracy on batch 264/3013  on Training is 86.35613207547169\n",
            "Epoch #3. Accuracy on batch 265/3013  on Training is 86.34868421052632\n",
            "Epoch #3. Accuracy on batch 266/3013  on Training is 86.36470037453184\n",
            "Epoch #3. Accuracy on batch 267/3013  on Training is 86.40391791044776\n",
            "Epoch #3. Accuracy on batch 268/3013  on Training is 86.39637546468401\n",
            "Epoch #3. Accuracy on batch 269/3013  on Training is 86.44675925925925\n",
            "Epoch #3. Accuracy on batch 270/3013  on Training is 86.40452029520296\n",
            "Epoch #3. Accuracy on batch 271/3013  on Training is 86.38556985294117\n",
            "Epoch #3. Accuracy on batch 272/3013  on Training is 86.38965201465201\n",
            "Epoch #3. Accuracy on batch 273/3013  on Training is 86.4051094890511\n",
            "Epoch #3. Accuracy on batch 274/3013  on Training is 86.4090909090909\n",
            "Epoch #3. Accuracy on batch 275/3013  on Training is 86.42436594202898\n",
            "Epoch #3. Accuracy on batch 276/3013  on Training is 86.43953068592057\n",
            "Epoch #3. Accuracy on batch 277/3013  on Training is 86.43210431654676\n",
            "Epoch #3. Accuracy on batch 278/3013  on Training is 86.48073476702508\n",
            "Epoch #3. Accuracy on batch 279/3013  on Training is 86.49553571428571\n",
            "Batch Id 280 is having training loss of 0.47551774978637695\n",
            "0.47750377655029297\n",
            "Epoch #3. Accuracy on batch 280/3013  on Training is 86.52135231316726\n",
            "Epoch #3. Accuracy on batch 281/3013  on Training is 86.52482269503547\n",
            "Epoch #3. Accuracy on batch 282/3013  on Training is 86.51722614840989\n",
            "Epoch #3. Accuracy on batch 283/3013  on Training is 86.54269366197182\n",
            "Epoch #3. Accuracy on batch 284/3013  on Training is 86.54605263157895\n",
            "Epoch #3. Accuracy on batch 285/3013  on Training is 86.57124125874125\n",
            "Epoch #3. Accuracy on batch 286/3013  on Training is 86.5962543554007\n",
            "Epoch #3. Accuracy on batch 287/3013  on Training is 86.61024305555556\n",
            "Epoch #3. Accuracy on batch 288/3013  on Training is 86.61332179930795\n",
            "Epoch #3. Accuracy on batch 289/3013  on Training is 86.63793103448276\n",
            "Epoch #3. Accuracy on batch 290/3013  on Training is 86.6516323024055\n",
            "Epoch #3. Accuracy on batch 291/3013  on Training is 86.64383561643835\n",
            "Epoch #3. Accuracy on batch 292/3013  on Training is 86.65742320819113\n",
            "Epoch #3. Accuracy on batch 293/3013  on Training is 86.66028911564626\n",
            "Epoch #3. Accuracy on batch 294/3013  on Training is 86.64194915254237\n",
            "Epoch #3. Accuracy on batch 295/3013  on Training is 86.63429054054055\n",
            "Epoch #3. Accuracy on batch 296/3013  on Training is 86.63720538720538\n",
            "Epoch #3. Accuracy on batch 297/3013  on Training is 86.64010067114094\n",
            "Epoch #3. Accuracy on batch 298/3013  on Training is 86.6638795986622\n",
            "Epoch #3. Accuracy on batch 299/3013  on Training is 86.63541666666667\n",
            "Batch Id 300 is having training loss of 0.47129812836647034\n",
            "0.20843376219272614\n",
            "Epoch #3. Accuracy on batch 300/3013  on Training is 86.65905315614619\n",
            "Epoch #3. Accuracy on batch 301/3013  on Training is 86.65149006622516\n",
            "Epoch #3. Accuracy on batch 302/3013  on Training is 86.61303630363037\n",
            "Epoch #3. Accuracy on batch 303/3013  on Training is 86.59539473684211\n",
            "Epoch #3. Accuracy on batch 304/3013  on Training is 86.6188524590164\n",
            "Epoch #3. Accuracy on batch 305/3013  on Training is 86.59109477124183\n",
            "Epoch #3. Accuracy on batch 306/3013  on Training is 86.58387622149837\n",
            "Epoch #3. Accuracy on batch 307/3013  on Training is 86.59699675324676\n",
            "Epoch #3. Accuracy on batch 308/3013  on Training is 86.59991909385113\n",
            "Epoch #3. Accuracy on batch 309/3013  on Training is 86.58266129032258\n",
            "Epoch #3. Accuracy on batch 310/3013  on Training is 86.57556270096462\n",
            "Epoch #3. Accuracy on batch 311/3013  on Training is 86.57852564102564\n",
            "Epoch #3. Accuracy on batch 312/3013  on Training is 86.5814696485623\n",
            "Epoch #3. Accuracy on batch 313/3013  on Training is 86.60429936305732\n",
            "Epoch #3. Accuracy on batch 314/3013  on Training is 86.6170634920635\n",
            "Epoch #3. Accuracy on batch 315/3013  on Training is 86.60996835443038\n",
            "Epoch #3. Accuracy on batch 316/3013  on Training is 86.62263406940063\n",
            "Epoch #3. Accuracy on batch 317/3013  on Training is 86.61556603773585\n",
            "Epoch #3. Accuracy on batch 318/3013  on Training is 86.62813479623824\n",
            "Epoch #3. Accuracy on batch 319/3013  on Training is 86.630859375\n",
            "Batch Id 320 is having training loss of 0.4709438681602478\n",
            "0.47331297397613525\n",
            "Epoch #3. Accuracy on batch 320/3013  on Training is 86.60436137071652\n",
            "Epoch #3. Accuracy on batch 321/3013  on Training is 86.60714285714286\n",
            "Epoch #3. Accuracy on batch 322/3013  on Training is 86.58088235294117\n",
            "Epoch #3. Accuracy on batch 323/3013  on Training is 86.59336419753086\n",
            "Epoch #3. Accuracy on batch 324/3013  on Training is 86.59615384615384\n",
            "Epoch #3. Accuracy on batch 325/3013  on Training is 86.57016871165644\n",
            "Epoch #3. Accuracy on batch 326/3013  on Training is 86.51567278287462\n",
            "Epoch #3. Accuracy on batch 327/3013  on Training is 86.50914634146342\n",
            "Epoch #3. Accuracy on batch 328/3013  on Training is 86.54065349544074\n",
            "Epoch #3. Accuracy on batch 329/3013  on Training is 86.54356060606061\n",
            "Epoch #3. Accuracy on batch 330/3013  on Training is 86.5464501510574\n",
            "Epoch #3. Accuracy on batch 331/3013  on Training is 86.58697289156626\n",
            "Epoch #3. Accuracy on batch 332/3013  on Training is 86.57094594594595\n",
            "Epoch #3. Accuracy on batch 333/3013  on Training is 86.56437125748504\n",
            "Epoch #3. Accuracy on batch 334/3013  on Training is 86.57649253731343\n",
            "Epoch #3. Accuracy on batch 335/3013  on Training is 86.59784226190476\n",
            "Epoch #3. Accuracy on batch 336/3013  on Training is 86.59124629080118\n",
            "Epoch #3. Accuracy on batch 337/3013  on Training is 86.60318047337279\n",
            "Epoch #3. Accuracy on batch 338/3013  on Training is 86.6334808259587\n",
            "Epoch #3. Accuracy on batch 339/3013  on Training is 86.60845588235294\n",
            "Batch Id 340 is having training loss of 0.4718219041824341\n",
            "0.2981269657611847\n",
            "Epoch #3. Accuracy on batch 340/3013  on Training is 86.62939882697947\n",
            "Epoch #3. Accuracy on batch 341/3013  on Training is 86.64108187134502\n",
            "Epoch #3. Accuracy on batch 342/3013  on Training is 86.62536443148689\n",
            "Epoch #3. Accuracy on batch 343/3013  on Training is 86.62790697674419\n",
            "Epoch #3. Accuracy on batch 344/3013  on Training is 86.6213768115942\n",
            "Epoch #3. Accuracy on batch 345/3013  on Training is 86.61488439306359\n",
            "Epoch #3. Accuracy on batch 346/3013  on Training is 86.59041786743516\n",
            "Epoch #3. Accuracy on batch 347/3013  on Training is 86.5930316091954\n",
            "Epoch #3. Accuracy on batch 348/3013  on Training is 86.60458452722062\n",
            "Epoch #3. Accuracy on batch 349/3013  on Training is 86.57142857142857\n",
            "Epoch #3. Accuracy on batch 350/3013  on Training is 86.56517094017094\n",
            "Epoch #3. Accuracy on batch 351/3013  on Training is 86.57670454545455\n",
            "Epoch #3. Accuracy on batch 352/3013  on Training is 86.54390934844193\n",
            "Epoch #3. Accuracy on batch 353/3013  on Training is 86.55543785310735\n",
            "Epoch #3. Accuracy on batch 354/3013  on Training is 86.5580985915493\n",
            "Epoch #3. Accuracy on batch 355/3013  on Training is 86.57830056179775\n",
            "Epoch #3. Accuracy on batch 356/3013  on Training is 86.5546218487395\n",
            "Epoch #3. Accuracy on batch 357/3013  on Training is 86.53980446927375\n",
            "Epoch #3. Accuracy on batch 358/3013  on Training is 86.525069637883\n",
            "Epoch #3. Accuracy on batch 359/3013  on Training is 86.51041666666667\n",
            "Batch Id 360 is having training loss of 0.473825603723526\n",
            "0.3128223717212677\n",
            "Epoch #3. Accuracy on batch 360/3013  on Training is 86.52181440443213\n",
            "Epoch #3. Accuracy on batch 361/3013  on Training is 86.53314917127072\n",
            "Epoch #3. Accuracy on batch 362/3013  on Training is 86.52720385674931\n",
            "Epoch #3. Accuracy on batch 363/3013  on Training is 86.50412087912088\n",
            "Epoch #3. Accuracy on batch 364/3013  on Training is 86.51541095890411\n",
            "Epoch #3. Accuracy on batch 365/3013  on Training is 86.52663934426229\n",
            "Epoch #3. Accuracy on batch 366/3013  on Training is 86.52077656675749\n",
            "Epoch #3. Accuracy on batch 367/3013  on Training is 86.5149456521739\n",
            "Epoch #3. Accuracy on batch 368/3013  on Training is 86.49220867208672\n",
            "Epoch #3. Accuracy on batch 369/3013  on Training is 86.50337837837837\n",
            "Epoch #3. Accuracy on batch 370/3013  on Training is 86.51448787061994\n",
            "Epoch #3. Accuracy on batch 371/3013  on Training is 86.53393817204301\n",
            "Epoch #3. Accuracy on batch 372/3013  on Training is 86.51139410187668\n",
            "Epoch #3. Accuracy on batch 373/3013  on Training is 86.5307486631016\n",
            "Epoch #3. Accuracy on batch 374/3013  on Training is 86.50833333333334\n",
            "Epoch #3. Accuracy on batch 375/3013  on Training is 86.53590425531915\n",
            "Epoch #3. Accuracy on batch 376/3013  on Training is 86.52188328912467\n",
            "Epoch #3. Accuracy on batch 377/3013  on Training is 86.5327380952381\n",
            "Epoch #3. Accuracy on batch 378/3013  on Training is 86.54353562005277\n",
            "Epoch #3. Accuracy on batch 379/3013  on Training is 86.55427631578948\n",
            "Batch Id 380 is having training loss of 0.47434183955192566\n",
            "0.5518324971199036\n",
            "Epoch #3. Accuracy on batch 380/3013  on Training is 86.54035433070867\n",
            "Epoch #3. Accuracy on batch 381/3013  on Training is 86.51832460732984\n",
            "Epoch #3. Accuracy on batch 382/3013  on Training is 86.52088772845953\n",
            "Epoch #3. Accuracy on batch 383/3013  on Training is 86.51529947916667\n",
            "Epoch #3. Accuracy on batch 384/3013  on Training is 86.51785714285714\n",
            "Epoch #3. Accuracy on batch 385/3013  on Training is 86.51230569948187\n",
            "Epoch #3. Accuracy on batch 386/3013  on Training is 86.54715762273902\n",
            "Epoch #3. Accuracy on batch 387/3013  on Training is 86.53350515463917\n",
            "Epoch #3. Accuracy on batch 388/3013  on Training is 86.52795629820051\n",
            "Epoch #3. Accuracy on batch 389/3013  on Training is 86.53846153846153\n",
            "Epoch #3. Accuracy on batch 390/3013  on Training is 86.54891304347827\n",
            "Epoch #3. Accuracy on batch 391/3013  on Training is 86.55133928571429\n",
            "Epoch #3. Accuracy on batch 392/3013  on Training is 86.55375318066157\n",
            "Epoch #3. Accuracy on batch 393/3013  on Training is 86.53236040609137\n",
            "Epoch #3. Accuracy on batch 394/3013  on Training is 86.54272151898734\n",
            "Epoch #3. Accuracy on batch 395/3013  on Training is 86.52935606060606\n",
            "Epoch #3. Accuracy on batch 396/3013  on Training is 86.51605793450882\n",
            "Epoch #3. Accuracy on batch 397/3013  on Training is 86.51853015075378\n",
            "Epoch #3. Accuracy on batch 398/3013  on Training is 86.52882205513785\n",
            "Epoch #3. Accuracy on batch 399/3013  on Training is 86.5390625\n",
            "Batch Id 400 is having training loss of 0.4735476076602936\n",
            "0.39745283126831055\n",
            "Epoch #3. Accuracy on batch 400/3013  on Training is 86.54925187032418\n",
            "Epoch #3. Accuracy on batch 401/3013  on Training is 86.55939054726367\n",
            "Epoch #3. Accuracy on batch 402/3013  on Training is 86.56172456575682\n",
            "Epoch #3. Accuracy on batch 403/3013  on Training is 86.54084158415841\n",
            "Epoch #3. Accuracy on batch 404/3013  on Training is 86.5354938271605\n",
            "Epoch #3. Accuracy on batch 405/3013  on Training is 86.54556650246306\n",
            "Epoch #3. Accuracy on batch 406/3013  on Training is 86.54023341523342\n",
            "Epoch #3. Accuracy on batch 407/3013  on Training is 86.52726715686275\n",
            "Epoch #3. Accuracy on batch 408/3013  on Training is 86.50672371638142\n",
            "Epoch #3. Accuracy on batch 409/3013  on Training is 86.51676829268293\n",
            "Epoch #3. Accuracy on batch 410/3013  on Training is 86.53436739659368\n",
            "Epoch #3. Accuracy on batch 411/3013  on Training is 86.52912621359224\n",
            "Epoch #3. Accuracy on batch 412/3013  on Training is 86.5390435835351\n",
            "Epoch #3. Accuracy on batch 413/3013  on Training is 86.56400966183575\n",
            "Epoch #3. Accuracy on batch 414/3013  on Training is 86.5512048192771\n",
            "Epoch #3. Accuracy on batch 415/3013  on Training is 86.5459735576923\n",
            "Epoch #3. Accuracy on batch 416/3013  on Training is 86.55575539568345\n",
            "Epoch #3. Accuracy on batch 417/3013  on Training is 86.54306220095694\n",
            "Epoch #3. Accuracy on batch 418/3013  on Training is 86.52297136038186\n",
            "Epoch #3. Accuracy on batch 419/3013  on Training is 86.51041666666667\n",
            "Batch Id 420 is having training loss of 0.47473621368408203\n",
            "0.36690855026245117\n",
            "Epoch #3. Accuracy on batch 420/3013  on Training is 86.50534441805226\n",
            "Epoch #3. Accuracy on batch 421/3013  on Training is 86.51510663507109\n",
            "Epoch #3. Accuracy on batch 422/3013  on Training is 86.52482269503547\n",
            "Epoch #3. Accuracy on batch 423/3013  on Training is 86.52712264150944\n",
            "Epoch #3. Accuracy on batch 424/3013  on Training is 86.53676470588235\n",
            "Epoch #3. Accuracy on batch 425/3013  on Training is 86.51701877934272\n",
            "Epoch #3. Accuracy on batch 426/3013  on Training is 86.51200234192038\n",
            "Epoch #3. Accuracy on batch 427/3013  on Training is 86.50700934579439\n",
            "Epoch #3. Accuracy on batch 428/3013  on Training is 86.49475524475524\n",
            "Epoch #3. Accuracy on batch 429/3013  on Training is 86.49709302325581\n",
            "Epoch #3. Accuracy on batch 430/3013  on Training is 86.49941995359629\n",
            "Epoch #3. Accuracy on batch 431/3013  on Training is 86.48726851851852\n",
            "Epoch #3. Accuracy on batch 432/3013  on Training is 86.49682448036951\n",
            "Epoch #3. Accuracy on batch 433/3013  on Training is 86.47753456221199\n",
            "Epoch #3. Accuracy on batch 434/3013  on Training is 86.47988505747126\n",
            "Epoch #3. Accuracy on batch 435/3013  on Training is 86.47505733944953\n",
            "Epoch #3. Accuracy on batch 436/3013  on Training is 86.46310068649886\n",
            "Epoch #3. Accuracy on batch 437/3013  on Training is 86.45833333333333\n",
            "Epoch #3. Accuracy on batch 438/3013  on Training is 86.46782460136674\n",
            "Epoch #3. Accuracy on batch 439/3013  on Training is 86.46306818181819\n",
            "Batch Id 440 is having training loss of 0.4734232425689697\n",
            "0.38550037145614624\n",
            "Epoch #3. Accuracy on batch 440/3013  on Training is 86.47250566893425\n",
            "Epoch #3. Accuracy on batch 441/3013  on Training is 86.48897058823529\n",
            "Epoch #3. Accuracy on batch 442/3013  on Training is 86.49830699774266\n",
            "Epoch #3. Accuracy on batch 443/3013  on Training is 86.51463963963964\n",
            "Epoch #3. Accuracy on batch 444/3013  on Training is 86.50983146067416\n",
            "Epoch #3. Accuracy on batch 445/3013  on Training is 86.51905829596413\n",
            "Epoch #3. Accuracy on batch 446/3013  on Training is 86.50027964205816\n",
            "Epoch #3. Accuracy on batch 447/3013  on Training is 86.50251116071429\n",
            "Epoch #3. Accuracy on batch 448/3013  on Training is 86.51865256124722\n",
            "Epoch #3. Accuracy on batch 449/3013  on Training is 86.51388888888889\n",
            "Epoch #3. Accuracy on batch 450/3013  on Training is 86.51607538802661\n",
            "Epoch #3. Accuracy on batch 451/3013  on Training is 86.51825221238938\n",
            "Epoch #3. Accuracy on batch 452/3013  on Training is 86.53421633554083\n",
            "Epoch #3. Accuracy on batch 453/3013  on Training is 86.5363436123348\n",
            "Epoch #3. Accuracy on batch 454/3013  on Training is 86.53846153846153\n",
            "Epoch #3. Accuracy on batch 455/3013  on Training is 86.53371710526316\n",
            "Epoch #3. Accuracy on batch 456/3013  on Training is 86.52899343544858\n",
            "Epoch #3. Accuracy on batch 457/3013  on Training is 86.54475982532752\n",
            "Epoch #3. Accuracy on batch 458/3013  on Training is 86.52641612200436\n",
            "Epoch #3. Accuracy on batch 459/3013  on Training is 86.52173913043478\n",
            "Batch Id 460 is having training loss of 0.47122180461883545\n",
            "0.5921708941459656\n",
            "Epoch #3. Accuracy on batch 460/3013  on Training is 86.52386117136659\n",
            "Epoch #3. Accuracy on batch 461/3013  on Training is 86.5327380952381\n",
            "Epoch #3. Accuracy on batch 462/3013  on Training is 86.54157667386609\n",
            "Epoch #3. Accuracy on batch 463/3013  on Training is 86.55037715517241\n",
            "Epoch #3. Accuracy on batch 464/3013  on Training is 86.51881720430107\n",
            "Epoch #3. Accuracy on batch 465/3013  on Training is 86.51421673819742\n",
            "Epoch #3. Accuracy on batch 466/3013  on Training is 86.50294432548179\n",
            "Epoch #3. Accuracy on batch 467/3013  on Training is 86.50507478632478\n",
            "Epoch #3. Accuracy on batch 468/3013  on Training is 86.50053304904051\n",
            "Epoch #3. Accuracy on batch 469/3013  on Training is 86.48271276595744\n",
            "Epoch #3. Accuracy on batch 470/3013  on Training is 86.47160297239915\n",
            "Epoch #3. Accuracy on batch 471/3013  on Training is 86.45391949152543\n",
            "Epoch #3. Accuracy on batch 472/3013  on Training is 86.4561310782241\n",
            "Epoch #3. Accuracy on batch 473/3013  on Training is 86.45833333333333\n",
            "Epoch #3. Accuracy on batch 474/3013  on Training is 86.46052631578948\n",
            "Epoch #3. Accuracy on batch 475/3013  on Training is 86.43644957983193\n",
            "Epoch #3. Accuracy on batch 476/3013  on Training is 86.45833333333333\n",
            "Epoch #3. Accuracy on batch 477/3013  on Training is 86.4539748953975\n",
            "Epoch #3. Accuracy on batch 478/3013  on Training is 86.44963465553236\n",
            "Epoch #3. Accuracy on batch 479/3013  on Training is 86.42578125\n",
            "Batch Id 480 is having training loss of 0.4736785292625427\n",
            "0.05686727538704872\n",
            "Epoch #3. Accuracy on batch 480/3013  on Training is 86.45400207900208\n",
            "Epoch #3. Accuracy on batch 481/3013  on Training is 86.46265560165975\n",
            "Epoch #3. Accuracy on batch 482/3013  on Training is 86.4453933747412\n",
            "Epoch #3. Accuracy on batch 483/3013  on Training is 86.4088326446281\n",
            "Epoch #3. Accuracy on batch 484/3013  on Training is 86.39819587628865\n",
            "Epoch #3. Accuracy on batch 485/3013  on Training is 86.41975308641975\n",
            "Epoch #3. Accuracy on batch 486/3013  on Training is 86.39630390143738\n",
            "Epoch #3. Accuracy on batch 487/3013  on Training is 86.3985655737705\n",
            "Epoch #3. Accuracy on batch 488/3013  on Training is 86.41359918200409\n",
            "Epoch #3. Accuracy on batch 489/3013  on Training is 86.41581632653062\n",
            "Epoch #3. Accuracy on batch 490/3013  on Training is 86.4116598778004\n",
            "Epoch #3. Accuracy on batch 491/3013  on Training is 86.401168699187\n",
            "Epoch #3. Accuracy on batch 492/3013  on Training is 86.41607505070994\n",
            "Epoch #3. Accuracy on batch 493/3013  on Training is 86.41194331983806\n",
            "Epoch #3. Accuracy on batch 494/3013  on Training is 86.39520202020202\n",
            "Epoch #3. Accuracy on batch 495/3013  on Training is 86.37852822580645\n",
            "Epoch #3. Accuracy on batch 496/3013  on Training is 86.3933601609658\n",
            "Epoch #3. Accuracy on batch 497/3013  on Training is 86.38303212851406\n",
            "Epoch #3. Accuracy on batch 498/3013  on Training is 86.39153306613227\n",
            "Epoch #3. Accuracy on batch 499/3013  on Training is 86.39375\n",
            "Batch Id 500 is having training loss of 0.4756714105606079\n",
            "0.39710062742233276\n",
            "Epoch #3. Accuracy on batch 500/3013  on Training is 86.38972055888223\n",
            "Epoch #3. Accuracy on batch 501/3013  on Training is 86.41683266932272\n",
            "Epoch #3. Accuracy on batch 502/3013  on Training is 86.4065606361829\n",
            "Epoch #3. Accuracy on batch 503/3013  on Training is 86.41493055555556\n",
            "Epoch #3. Accuracy on batch 504/3013  on Training is 86.41707920792079\n",
            "Epoch #3. Accuracy on batch 505/3013  on Training is 86.41304347826087\n",
            "Epoch #3. Accuracy on batch 506/3013  on Training is 86.41518737672584\n",
            "Epoch #3. Accuracy on batch 507/3013  on Training is 86.41117125984252\n",
            "Epoch #3. Accuracy on batch 508/3013  on Training is 86.40103143418467\n",
            "Epoch #3. Accuracy on batch 509/3013  on Training is 86.3970588235294\n",
            "Epoch #3. Accuracy on batch 510/3013  on Training is 86.39310176125245\n",
            "Epoch #3. Accuracy on batch 511/3013  on Training is 86.4013671875\n",
            "Epoch #3. Accuracy on batch 512/3013  on Training is 86.421783625731\n",
            "Epoch #3. Accuracy on batch 513/3013  on Training is 86.4238813229572\n",
            "Epoch #3. Accuracy on batch 514/3013  on Training is 86.42597087378641\n",
            "Epoch #3. Accuracy on batch 515/3013  on Training is 86.42805232558139\n",
            "Epoch #3. Accuracy on batch 516/3013  on Training is 86.43617021276596\n",
            "Epoch #3. Accuracy on batch 517/3013  on Training is 86.44425675675676\n",
            "Epoch #3. Accuracy on batch 518/3013  on Training is 86.44026974951831\n",
            "Epoch #3. Accuracy on batch 519/3013  on Training is 86.4483173076923\n",
            "Batch Id 520 is having training loss of 0.4741238057613373\n",
            "0.3879871666431427\n",
            "Epoch #3. Accuracy on batch 520/3013  on Training is 86.45033589251439\n",
            "Epoch #3. Accuracy on batch 521/3013  on Training is 86.43438697318008\n",
            "Epoch #3. Accuracy on batch 522/3013  on Training is 86.4543499043977\n",
            "Epoch #3. Accuracy on batch 523/3013  on Training is 86.43249045801527\n",
            "Epoch #3. Accuracy on batch 524/3013  on Training is 86.43452380952381\n",
            "Epoch #3. Accuracy on batch 525/3013  on Training is 86.44843155893535\n",
            "Epoch #3. Accuracy on batch 526/3013  on Training is 86.44449715370018\n",
            "Epoch #3. Accuracy on batch 527/3013  on Training is 86.45833333333333\n",
            "Epoch #3. Accuracy on batch 528/3013  on Training is 86.46030245746692\n",
            "Epoch #3. Accuracy on batch 529/3013  on Training is 86.47995283018868\n",
            "Epoch #3. Accuracy on batch 530/3013  on Training is 86.45833333333333\n",
            "Epoch #3. Accuracy on batch 531/3013  on Training is 86.46616541353383\n",
            "Epoch #3. Accuracy on batch 532/3013  on Training is 86.46224202626642\n",
            "Epoch #3. Accuracy on batch 533/3013  on Training is 86.45833333333333\n",
            "Epoch #3. Accuracy on batch 534/3013  on Training is 86.45443925233644\n",
            "Epoch #3. Accuracy on batch 535/3013  on Training is 86.45055970149254\n",
            "Epoch #3. Accuracy on batch 536/3013  on Training is 86.45833333333333\n",
            "Epoch #3. Accuracy on batch 537/3013  on Training is 86.45446096654275\n",
            "Epoch #3. Accuracy on batch 538/3013  on Training is 86.45640074211502\n",
            "Epoch #3. Accuracy on batch 539/3013  on Training is 86.43518518518519\n",
            "Batch Id 540 is having training loss of 0.4751095473766327\n",
            "1.2013128995895386\n",
            "Epoch #3. Accuracy on batch 540/3013  on Training is 86.3909426987061\n",
            "Epoch #3. Accuracy on batch 541/3013  on Training is 86.3929889298893\n",
            "Epoch #3. Accuracy on batch 542/3013  on Training is 86.3720073664825\n",
            "Epoch #3. Accuracy on batch 543/3013  on Training is 86.36259191176471\n",
            "Epoch #3. Accuracy on batch 544/3013  on Training is 86.35321100917432\n",
            "Epoch #3. Accuracy on batch 545/3013  on Training is 86.33241758241758\n",
            "Epoch #3. Accuracy on batch 546/3013  on Training is 86.32312614259598\n",
            "Epoch #3. Accuracy on batch 547/3013  on Training is 86.31957116788321\n",
            "Epoch #3. Accuracy on batch 548/3013  on Training is 86.33879781420765\n",
            "Epoch #3. Accuracy on batch 549/3013  on Training is 86.3409090909091\n",
            "Epoch #3. Accuracy on batch 550/3013  on Training is 86.33734119782214\n",
            "Epoch #3. Accuracy on batch 551/3013  on Training is 86.34510869565217\n",
            "Epoch #3. Accuracy on batch 552/3013  on Training is 86.35284810126582\n",
            "Epoch #3. Accuracy on batch 553/3013  on Training is 86.34927797833934\n",
            "Epoch #3. Accuracy on batch 554/3013  on Training is 86.35135135135135\n",
            "Epoch #3. Accuracy on batch 555/3013  on Training is 86.35903776978417\n",
            "Epoch #3. Accuracy on batch 556/3013  on Training is 86.34425493716337\n",
            "Epoch #3. Accuracy on batch 557/3013  on Training is 86.3519265232975\n",
            "Epoch #3. Accuracy on batch 558/3013  on Training is 86.34279964221825\n",
            "Epoch #3. Accuracy on batch 559/3013  on Training is 86.31696428571429\n",
            "Batch Id 560 is having training loss of 0.47670355439186096\n",
            "0.5270516872406006\n",
            "Epoch #3. Accuracy on batch 560/3013  on Training is 86.30793226381462\n",
            "Epoch #3. Accuracy on batch 561/3013  on Training is 86.31005338078292\n",
            "Epoch #3. Accuracy on batch 562/3013  on Training is 86.28996447602131\n",
            "Epoch #3. Accuracy on batch 563/3013  on Training is 86.29210992907801\n",
            "Epoch #3. Accuracy on batch 564/3013  on Training is 86.29424778761062\n",
            "Epoch #3. Accuracy on batch 565/3013  on Training is 86.30742049469964\n",
            "Epoch #3. Accuracy on batch 566/3013  on Training is 86.30401234567901\n",
            "Epoch #3. Accuracy on batch 567/3013  on Training is 86.3006161971831\n",
            "Epoch #3. Accuracy on batch 568/3013  on Training is 86.30821616871705\n",
            "Epoch #3. Accuracy on batch 569/3013  on Training is 86.3048245614035\n",
            "Epoch #3. Accuracy on batch 570/3013  on Training is 86.3069176882662\n",
            "Epoch #3. Accuracy on batch 571/3013  on Training is 86.29807692307692\n",
            "Epoch #3. Accuracy on batch 572/3013  on Training is 86.32198952879581\n",
            "Epoch #3. Accuracy on batch 573/3013  on Training is 86.32404181184668\n",
            "Epoch #3. Accuracy on batch 574/3013  on Training is 86.31521739130434\n",
            "Epoch #3. Accuracy on batch 575/3013  on Training is 86.32269965277777\n",
            "Epoch #3. Accuracy on batch 576/3013  on Training is 86.33015597920277\n",
            "Epoch #3. Accuracy on batch 577/3013  on Training is 86.33217993079585\n",
            "Epoch #3. Accuracy on batch 578/3013  on Training is 86.33959412780656\n",
            "Epoch #3. Accuracy on batch 579/3013  on Training is 86.3415948275862\n",
            "Batch Id 580 is having training loss of 0.4766288697719574\n",
            "0.6336996555328369\n",
            "Epoch #3. Accuracy on batch 580/3013  on Training is 86.3328313253012\n",
            "Epoch #3. Accuracy on batch 581/3013  on Training is 86.34020618556701\n",
            "Epoch #3. Accuracy on batch 582/3013  on Training is 86.35291595197256\n",
            "Epoch #3. Accuracy on batch 583/3013  on Training is 86.34417808219177\n",
            "Epoch #3. Accuracy on batch 584/3013  on Training is 86.31410256410257\n",
            "Epoch #3. Accuracy on batch 585/3013  on Training is 86.31612627986348\n",
            "Epoch #3. Accuracy on batch 586/3013  on Training is 86.3234667802385\n",
            "Epoch #3. Accuracy on batch 587/3013  on Training is 86.32546768707483\n",
            "Epoch #3. Accuracy on batch 588/3013  on Training is 86.32215619694398\n",
            "Epoch #3. Accuracy on batch 589/3013  on Training is 86.32944915254237\n",
            "Epoch #3. Accuracy on batch 590/3013  on Training is 86.33671742808798\n",
            "Epoch #3. Accuracy on batch 591/3013  on Training is 86.33868243243244\n",
            "Epoch #3. Accuracy on batch 592/3013  on Training is 86.32483136593592\n",
            "Epoch #3. Accuracy on batch 593/3013  on Training is 86.33733164983165\n",
            "Epoch #3. Accuracy on batch 594/3013  on Training is 86.33928571428571\n",
            "Epoch #3. Accuracy on batch 595/3013  on Training is 86.3307466442953\n",
            "Epoch #3. Accuracy on batch 596/3013  on Training is 86.32747068676717\n",
            "Epoch #3. Accuracy on batch 597/3013  on Training is 86.34510869565217\n",
            "Epoch #3. Accuracy on batch 598/3013  on Training is 86.32616861435726\n",
            "Epoch #3. Accuracy on batch 599/3013  on Training is 86.31770833333333\n",
            "Batch Id 600 is having training loss of 0.47661375999450684\n",
            "0.30165380239486694\n",
            "Epoch #3. Accuracy on batch 600/3013  on Training is 86.3248752079867\n",
            "Epoch #3. Accuracy on batch 601/3013  on Training is 86.31644518272425\n",
            "Epoch #3. Accuracy on batch 602/3013  on Training is 86.30804311774462\n",
            "Epoch #3. Accuracy on batch 603/3013  on Training is 86.32036423841059\n",
            "Epoch #3. Accuracy on batch 604/3013  on Training is 86.30681818181819\n",
            "Epoch #3. Accuracy on batch 605/3013  on Training is 86.30878712871286\n",
            "Epoch #3. Accuracy on batch 606/3013  on Training is 86.3158978583196\n",
            "Epoch #3. Accuracy on batch 607/3013  on Training is 86.30756578947368\n",
            "Epoch #3. Accuracy on batch 608/3013  on Training is 86.30439244663383\n",
            "Epoch #3. Accuracy on batch 609/3013  on Training is 86.30122950819673\n",
            "Epoch #3. Accuracy on batch 610/3013  on Training is 86.27250409165303\n",
            "Epoch #3. Accuracy on batch 611/3013  on Training is 86.28472222222223\n",
            "Epoch #3. Accuracy on batch 612/3013  on Training is 86.2969004893964\n",
            "Epoch #3. Accuracy on batch 613/3013  on Training is 86.30903908794788\n",
            "Epoch #3. Accuracy on batch 614/3013  on Training is 86.32113821138212\n",
            "Epoch #3. Accuracy on batch 615/3013  on Training is 86.30783279220779\n",
            "Epoch #3. Accuracy on batch 616/3013  on Training is 86.31482982171799\n",
            "Epoch #3. Accuracy on batch 617/3013  on Training is 86.30663430420712\n",
            "Epoch #3. Accuracy on batch 618/3013  on Training is 86.30351373182552\n",
            "Epoch #3. Accuracy on batch 619/3013  on Training is 86.31048387096774\n",
            "Batch Id 620 is having training loss of 0.47687968611717224\n",
            "0.3599500060081482\n",
            "Epoch #3. Accuracy on batch 620/3013  on Training is 86.32246376811594\n",
            "Epoch #3. Accuracy on batch 621/3013  on Training is 86.29923633440515\n",
            "Epoch #3. Accuracy on batch 622/3013  on Training is 86.27106741573034\n",
            "Epoch #3. Accuracy on batch 623/3013  on Training is 86.27303685897436\n",
            "Epoch #3. Accuracy on batch 624/3013  on Training is 86.255\n",
            "Epoch #3. Accuracy on batch 625/3013  on Training is 86.25698881789137\n",
            "Epoch #3. Accuracy on batch 626/3013  on Training is 86.24401913875599\n",
            "Epoch #3. Accuracy on batch 627/3013  on Training is 86.22113853503184\n",
            "Epoch #3. Accuracy on batch 628/3013  on Training is 86.22813990461049\n",
            "Epoch #3. Accuracy on batch 629/3013  on Training is 86.24007936507937\n",
            "Epoch #3. Accuracy on batch 630/3013  on Training is 86.25693343898574\n",
            "Epoch #3. Accuracy on batch 631/3013  on Training is 86.2589003164557\n",
            "Epoch #3. Accuracy on batch 632/3013  on Training is 86.25592417061611\n",
            "Epoch #3. Accuracy on batch 633/3013  on Training is 86.26774447949526\n",
            "Epoch #3. Accuracy on batch 634/3013  on Training is 86.25492125984252\n",
            "Epoch #3. Accuracy on batch 635/3013  on Training is 86.25196540880503\n",
            "Epoch #3. Accuracy on batch 636/3013  on Training is 86.25392464678178\n",
            "Epoch #3. Accuracy on batch 637/3013  on Training is 86.25587774294671\n",
            "Epoch #3. Accuracy on batch 638/3013  on Training is 86.24804381846636\n",
            "Epoch #3. Accuracy on batch 639/3013  on Training is 86.240234375\n",
            "Batch Id 640 is having training loss of 0.4787442088127136\n",
            "0.19907909631729126\n",
            "Epoch #3. Accuracy on batch 640/3013  on Training is 86.24707488299532\n",
            "Epoch #3. Accuracy on batch 641/3013  on Training is 86.23929127725857\n",
            "Epoch #3. Accuracy on batch 642/3013  on Training is 86.23153188180405\n",
            "Epoch #3. Accuracy on batch 643/3013  on Training is 86.22379658385093\n",
            "Epoch #3. Accuracy on batch 644/3013  on Training is 86.21608527131782\n",
            "Epoch #3. Accuracy on batch 645/3013  on Training is 86.20839783281734\n",
            "Epoch #3. Accuracy on batch 646/3013  on Training is 86.22488408037094\n",
            "Epoch #3. Accuracy on batch 647/3013  on Training is 86.22685185185185\n",
            "Epoch #3. Accuracy on batch 648/3013  on Training is 86.24325885978428\n",
            "Epoch #3. Accuracy on batch 649/3013  on Training is 86.2451923076923\n",
            "Epoch #3. Accuracy on batch 650/3013  on Training is 86.25192012288787\n",
            "Epoch #3. Accuracy on batch 651/3013  on Training is 86.24904141104294\n",
            "Epoch #3. Accuracy on batch 652/3013  on Training is 86.25574272588055\n",
            "Epoch #3. Accuracy on batch 653/3013  on Training is 86.25764525993884\n",
            "Epoch #3. Accuracy on batch 654/3013  on Training is 86.26431297709924\n",
            "Epoch #3. Accuracy on batch 655/3013  on Training is 86.25190548780488\n",
            "Epoch #3. Accuracy on batch 656/3013  on Training is 86.25380517503805\n",
            "Epoch #3. Accuracy on batch 657/3013  on Training is 86.26044832826747\n",
            "Epoch #3. Accuracy on batch 658/3013  on Training is 86.27655538694992\n",
            "Epoch #3. Accuracy on batch 659/3013  on Training is 86.2784090909091\n",
            "Batch Id 660 is having training loss of 0.477981299161911\n",
            "0.4523388743400574\n",
            "Epoch #3. Accuracy on batch 660/3013  on Training is 86.27552950075643\n",
            "Epoch #3. Accuracy on batch 661/3013  on Training is 86.26793806646526\n",
            "Epoch #3. Accuracy on batch 662/3013  on Training is 86.27450980392157\n",
            "Epoch #3. Accuracy on batch 663/3013  on Training is 86.28106174698796\n",
            "Epoch #3. Accuracy on batch 664/3013  on Training is 86.2875939849624\n",
            "Epoch #3. Accuracy on batch 665/3013  on Training is 86.28472222222223\n",
            "Epoch #3. Accuracy on batch 666/3013  on Training is 86.28185907046476\n",
            "Epoch #3. Accuracy on batch 667/3013  on Training is 86.29303892215569\n",
            "Epoch #3. Accuracy on batch 668/3013  on Training is 86.30418535127055\n",
            "Epoch #3. Accuracy on batch 669/3013  on Training is 86.31996268656717\n",
            "Epoch #3. Accuracy on batch 670/3013  on Training is 86.31706408345752\n",
            "Epoch #3. Accuracy on batch 671/3013  on Training is 86.3188244047619\n",
            "Epoch #3. Accuracy on batch 672/3013  on Training is 86.29736255572065\n",
            "Epoch #3. Accuracy on batch 673/3013  on Training is 86.31769287833828\n",
            "Epoch #3. Accuracy on batch 674/3013  on Training is 86.32407407407408\n",
            "Epoch #3. Accuracy on batch 675/3013  on Training is 86.31194526627219\n",
            "Epoch #3. Accuracy on batch 676/3013  on Training is 86.29062038404727\n",
            "Epoch #3. Accuracy on batch 677/3013  on Training is 86.28779498525074\n",
            "Epoch #3. Accuracy on batch 678/3013  on Training is 86.2987849779087\n",
            "Epoch #3. Accuracy on batch 679/3013  on Training is 86.26838235294117\n",
            "Batch Id 680 is having training loss of 0.4777921438217163\n",
            "0.7064226269721985\n",
            "Epoch #3. Accuracy on batch 680/3013  on Training is 86.25642437591777\n",
            "Epoch #3. Accuracy on batch 681/3013  on Training is 86.26282991202346\n",
            "Epoch #3. Accuracy on batch 682/3013  on Training is 86.26006588579796\n",
            "Epoch #3. Accuracy on batch 683/3013  on Training is 86.25730994152046\n",
            "Epoch #3. Accuracy on batch 684/3013  on Training is 86.25912408759125\n",
            "Epoch #3. Accuracy on batch 685/3013  on Training is 86.27004373177843\n",
            "Epoch #3. Accuracy on batch 686/3013  on Training is 86.28093158660845\n",
            "Epoch #3. Accuracy on batch 687/3013  on Training is 86.29178779069767\n",
            "Epoch #3. Accuracy on batch 688/3013  on Training is 86.30714804063861\n",
            "Epoch #3. Accuracy on batch 689/3013  on Training is 86.29528985507247\n",
            "Epoch #3. Accuracy on batch 690/3013  on Training is 86.29703328509407\n",
            "Epoch #3. Accuracy on batch 691/3013  on Training is 86.30328757225433\n",
            "Epoch #3. Accuracy on batch 692/3013  on Training is 86.30501443001442\n",
            "Epoch #3. Accuracy on batch 693/3013  on Training is 86.31123919308358\n",
            "Epoch #3. Accuracy on batch 694/3013  on Training is 86.32194244604317\n",
            "Epoch #3. Accuracy on batch 695/3013  on Training is 86.32363505747126\n",
            "Epoch #3. Accuracy on batch 696/3013  on Training is 86.32980631276901\n",
            "Epoch #3. Accuracy on batch 697/3013  on Training is 86.33595988538681\n",
            "Epoch #3. Accuracy on batch 698/3013  on Training is 86.32421316165951\n",
            "Epoch #3. Accuracy on batch 699/3013  on Training is 86.32589285714286\n",
            "Batch Id 700 is having training loss of 0.47535842657089233\n",
            "0.7338745594024658\n",
            "Epoch #3. Accuracy on batch 700/3013  on Training is 86.31865192582026\n",
            "Epoch #3. Accuracy on batch 701/3013  on Training is 86.32478632478633\n",
            "Epoch #3. Accuracy on batch 702/3013  on Training is 86.32201280227596\n",
            "Epoch #3. Accuracy on batch 703/3013  on Training is 86.32368607954545\n",
            "Epoch #3. Accuracy on batch 704/3013  on Training is 86.31648936170212\n",
            "Epoch #3. Accuracy on batch 705/3013  on Training is 86.30931303116148\n",
            "Epoch #3. Accuracy on batch 706/3013  on Training is 86.30215700141443\n",
            "Epoch #3. Accuracy on batch 707/3013  on Training is 86.29943502824858\n",
            "Epoch #3. Accuracy on batch 708/3013  on Training is 86.30994358251058\n",
            "Epoch #3. Accuracy on batch 709/3013  on Training is 86.31161971830986\n",
            "Epoch #3. Accuracy on batch 710/3013  on Training is 86.32208157524613\n",
            "Epoch #3. Accuracy on batch 711/3013  on Training is 86.31056882022472\n",
            "Epoch #3. Accuracy on batch 712/3013  on Training is 86.29908835904628\n",
            "Epoch #3. Accuracy on batch 713/3013  on Training is 86.29201680672269\n",
            "Epoch #3. Accuracy on batch 714/3013  on Training is 86.2805944055944\n",
            "Epoch #3. Accuracy on batch 715/3013  on Training is 86.27356843575419\n",
            "Epoch #3. Accuracy on batch 716/3013  on Training is 86.27963737796374\n",
            "Epoch #3. Accuracy on batch 717/3013  on Training is 86.28133704735376\n",
            "Epoch #3. Accuracy on batch 718/3013  on Training is 86.28303198887343\n",
            "Epoch #3. Accuracy on batch 719/3013  on Training is 86.27170138888889\n",
            "Batch Id 720 is having training loss of 0.4766750931739807\n",
            "0.3928135633468628\n",
            "Epoch #3. Accuracy on batch 720/3013  on Training is 86.27773925104022\n",
            "Epoch #3. Accuracy on batch 721/3013  on Training is 86.2621191135734\n",
            "Epoch #3. Accuracy on batch 722/3013  on Training is 86.27247579529737\n",
            "Epoch #3. Accuracy on batch 723/3013  on Training is 86.28280386740332\n",
            "Epoch #3. Accuracy on batch 724/3013  on Training is 86.28448275862068\n",
            "Epoch #3. Accuracy on batch 725/3013  on Training is 86.29046143250689\n",
            "Epoch #3. Accuracy on batch 726/3013  on Training is 86.29642365887207\n",
            "Epoch #3. Accuracy on batch 727/3013  on Training is 86.29807692307692\n",
            "Epoch #3. Accuracy on batch 728/3013  on Training is 86.295438957476\n",
            "Epoch #3. Accuracy on batch 729/3013  on Training is 86.28424657534246\n",
            "Epoch #3. Accuracy on batch 730/3013  on Training is 86.29445964432284\n",
            "Epoch #3. Accuracy on batch 731/3013  on Training is 86.28756830601093\n",
            "Epoch #3. Accuracy on batch 732/3013  on Training is 86.2849590723056\n",
            "Epoch #3. Accuracy on batch 733/3013  on Training is 86.28235694822888\n",
            "Epoch #3. Accuracy on batch 734/3013  on Training is 86.296768707483\n",
            "Epoch #3. Accuracy on batch 735/3013  on Training is 86.29415760869566\n",
            "Epoch #3. Accuracy on batch 736/3013  on Training is 86.30003392130257\n",
            "Epoch #3. Accuracy on batch 737/3013  on Training is 86.30165989159892\n",
            "Epoch #3. Accuracy on batch 738/3013  on Training is 86.30328146143437\n",
            "Epoch #3. Accuracy on batch 739/3013  on Training is 86.29645270270271\n",
            "Batch Id 740 is having training loss of 0.4760427176952362\n",
            "0.4438808858394623\n",
            "Epoch #3. Accuracy on batch 740/3013  on Training is 86.29807692307692\n",
            "Epoch #3. Accuracy on batch 741/3013  on Training is 86.28706199460916\n",
            "Epoch #3. Accuracy on batch 742/3013  on Training is 86.28869448183042\n",
            "Epoch #3. Accuracy on batch 743/3013  on Training is 86.29452284946237\n",
            "Epoch #3. Accuracy on batch 744/3013  on Training is 86.29194630872483\n",
            "Epoch #3. Accuracy on batch 745/3013  on Training is 86.29356568364611\n",
            "Epoch #3. Accuracy on batch 746/3013  on Training is 86.29518072289157\n",
            "Epoch #3. Accuracy on batch 747/3013  on Training is 86.29261363636364\n",
            "Epoch #3. Accuracy on batch 748/3013  on Training is 86.2733644859813\n",
            "Epoch #3. Accuracy on batch 749/3013  on Training is 86.27083333333333\n",
            "Epoch #3. Accuracy on batch 750/3013  on Training is 86.27247003994674\n",
            "Epoch #3. Accuracy on batch 751/3013  on Training is 86.2782579787234\n",
            "Epoch #3. Accuracy on batch 752/3013  on Training is 86.25913014608234\n",
            "Epoch #3. Accuracy on batch 753/3013  on Training is 86.25663129973475\n",
            "Epoch #3. Accuracy on batch 754/3013  on Training is 86.25827814569537\n",
            "Epoch #3. Accuracy on batch 755/3013  on Training is 86.25992063492063\n",
            "Epoch #3. Accuracy on batch 756/3013  on Training is 86.25743064729194\n",
            "Epoch #3. Accuracy on batch 757/3013  on Training is 86.25906992084433\n",
            "Epoch #3. Accuracy on batch 758/3013  on Training is 86.25247035573122\n",
            "Epoch #3. Accuracy on batch 759/3013  on Training is 86.25411184210526\n",
            "Batch Id 760 is having training loss of 0.4775145649909973\n",
            "0.38079938292503357\n",
            "Epoch #3. Accuracy on batch 760/3013  on Training is 86.25985545335085\n",
            "Epoch #3. Accuracy on batch 761/3013  on Training is 86.25738188976378\n",
            "Epoch #3. Accuracy on batch 762/3013  on Training is 86.27539318479685\n",
            "Epoch #3. Accuracy on batch 763/3013  on Training is 86.28517670157068\n",
            "Epoch #3. Accuracy on batch 764/3013  on Training is 86.28676470588235\n",
            "Epoch #3. Accuracy on batch 765/3013  on Training is 86.28426892950391\n",
            "Epoch #3. Accuracy on batch 766/3013  on Training is 86.28585397653194\n",
            "Epoch #3. Accuracy on batch 767/3013  on Training is 86.29557291666667\n",
            "Epoch #3. Accuracy on batch 768/3013  on Training is 86.30120286085825\n",
            "Epoch #3. Accuracy on batch 769/3013  on Training is 86.31087662337663\n",
            "Epoch #3. Accuracy on batch 770/3013  on Training is 86.30836575875486\n",
            "Epoch #3. Accuracy on batch 771/3013  on Training is 86.31395725388602\n",
            "Epoch #3. Accuracy on batch 772/3013  on Training is 86.3114489003881\n",
            "Epoch #3. Accuracy on batch 773/3013  on Training is 86.31298449612403\n",
            "Epoch #3. Accuracy on batch 774/3013  on Training is 86.3225806451613\n",
            "Epoch #3. Accuracy on batch 775/3013  on Training is 86.328125\n",
            "Epoch #3. Accuracy on batch 776/3013  on Training is 86.32561132561132\n",
            "Epoch #3. Accuracy on batch 777/3013  on Training is 86.3271208226221\n",
            "Epoch #3. Accuracy on batch 778/3013  on Training is 86.3165917843389\n",
            "Epoch #3. Accuracy on batch 779/3013  on Training is 86.31810897435898\n",
            "Batch Id 780 is having training loss of 0.47678816318511963\n",
            "0.431878000497818\n",
            "Epoch #3. Accuracy on batch 780/3013  on Training is 86.31962227912932\n",
            "Epoch #3. Accuracy on batch 781/3013  on Training is 86.32113171355499\n",
            "Epoch #3. Accuracy on batch 782/3013  on Training is 86.33061941251596\n",
            "Epoch #3. Accuracy on batch 783/3013  on Training is 86.34008290816327\n",
            "Epoch #3. Accuracy on batch 784/3013  on Training is 86.34554140127389\n",
            "Epoch #3. Accuracy on batch 785/3013  on Training is 86.35496183206106\n",
            "Epoch #3. Accuracy on batch 786/3013  on Training is 86.3524459974587\n",
            "Epoch #3. Accuracy on batch 787/3013  on Training is 86.3697652284264\n",
            "Epoch #3. Accuracy on batch 788/3013  on Training is 86.35931558935361\n",
            "Epoch #3. Accuracy on batch 789/3013  on Training is 86.36867088607595\n",
            "Epoch #3. Accuracy on batch 790/3013  on Training is 86.35429835651074\n",
            "Epoch #3. Accuracy on batch 791/3013  on Training is 86.35179924242425\n",
            "Epoch #3. Accuracy on batch 792/3013  on Training is 86.35718789407314\n",
            "Epoch #3. Accuracy on batch 793/3013  on Training is 86.35075566750629\n",
            "Epoch #3. Accuracy on batch 794/3013  on Training is 86.34433962264151\n",
            "Epoch #3. Accuracy on batch 795/3013  on Training is 86.33793969849246\n",
            "Epoch #3. Accuracy on batch 796/3013  on Training is 86.34331869510665\n",
            "Epoch #3. Accuracy on batch 797/3013  on Training is 86.34085213032581\n",
            "Epoch #3. Accuracy on batch 798/3013  on Training is 86.35794743429287\n",
            "Epoch #3. Accuracy on batch 799/3013  on Training is 86.36328125\n",
            "Batch Id 800 is having training loss of 0.4760220944881439\n",
            "0.20926062762737274\n",
            "Epoch #3. Accuracy on batch 800/3013  on Training is 86.37640449438203\n",
            "Epoch #3. Accuracy on batch 801/3013  on Training is 86.37780548628429\n",
            "Epoch #3. Accuracy on batch 802/3013  on Training is 86.3714196762142\n",
            "Epoch #3. Accuracy on batch 803/3013  on Training is 86.35727611940298\n",
            "Epoch #3. Accuracy on batch 804/3013  on Training is 86.34316770186335\n",
            "Epoch #3. Accuracy on batch 805/3013  on Training is 86.32909429280397\n",
            "Epoch #3. Accuracy on batch 806/3013  on Training is 86.32280049566295\n",
            "Epoch #3. Accuracy on batch 807/3013  on Training is 86.32038985148515\n",
            "Epoch #3. Accuracy on batch 808/3013  on Training is 86.32957354758962\n",
            "Epoch #3. Accuracy on batch 809/3013  on Training is 86.31944444444444\n",
            "Epoch #3. Accuracy on batch 810/3013  on Training is 86.30934032059186\n",
            "Epoch #3. Accuracy on batch 811/3013  on Training is 86.3108066502463\n",
            "Epoch #3. Accuracy on batch 812/3013  on Training is 86.30842558425584\n",
            "Epoch #3. Accuracy on batch 813/3013  on Training is 86.30988943488944\n",
            "Epoch #3. Accuracy on batch 814/3013  on Training is 86.29984662576688\n",
            "Epoch #3. Accuracy on batch 815/3013  on Training is 86.29365808823529\n",
            "Epoch #3. Accuracy on batch 816/3013  on Training is 86.28365973072215\n",
            "Epoch #3. Accuracy on batch 817/3013  on Training is 86.29278728606357\n",
            "Epoch #3. Accuracy on batch 818/3013  on Training is 86.28281440781441\n",
            "Epoch #3. Accuracy on batch 819/3013  on Training is 86.28048780487805\n",
            "Batch Id 820 is having training loss of 0.4791838526725769\n",
            "0.3468988537788391\n",
            "Epoch #3. Accuracy on batch 820/3013  on Training is 86.28958587088916\n",
            "Epoch #3. Accuracy on batch 821/3013  on Training is 86.28725669099757\n",
            "Epoch #3. Accuracy on batch 822/3013  on Training is 86.29252733900364\n",
            "Epoch #3. Accuracy on batch 823/3013  on Training is 86.28261529126213\n",
            "Epoch #3. Accuracy on batch 824/3013  on Training is 86.2840909090909\n",
            "Epoch #3. Accuracy on batch 825/3013  on Training is 86.28177966101696\n",
            "Epoch #3. Accuracy on batch 826/3013  on Training is 86.28703143893591\n",
            "Epoch #3. Accuracy on batch 827/3013  on Training is 86.28472222222223\n",
            "Epoch #3. Accuracy on batch 828/3013  on Training is 86.26734016887816\n",
            "Epoch #3. Accuracy on batch 829/3013  on Training is 86.25\n",
            "Epoch #3. Accuracy on batch 830/3013  on Training is 86.24774368231047\n",
            "Epoch #3. Accuracy on batch 831/3013  on Training is 86.2530048076923\n",
            "Epoch #3. Accuracy on batch 832/3013  on Training is 86.25825330132052\n",
            "Epoch #3. Accuracy on batch 833/3013  on Training is 86.25599520383693\n",
            "Epoch #3. Accuracy on batch 834/3013  on Training is 86.25374251497006\n",
            "Epoch #3. Accuracy on batch 835/3013  on Training is 86.26644736842105\n",
            "Epoch #3. Accuracy on batch 836/3013  on Training is 86.26045400238948\n",
            "Epoch #3. Accuracy on batch 837/3013  on Training is 86.25820405727923\n",
            "Epoch #3. Accuracy on batch 838/3013  on Training is 86.26340882002384\n",
            "Epoch #3. Accuracy on batch 839/3013  on Training is 86.26488095238095\n",
            "Batch Id 840 is having training loss of 0.48006555438041687\n",
            "0.6935603618621826\n",
            "Epoch #3. Accuracy on batch 840/3013  on Training is 86.25520214030915\n",
            "Epoch #3. Accuracy on batch 841/3013  on Training is 86.25668052256532\n",
            "Epoch #3. Accuracy on batch 842/3013  on Training is 86.26186239620404\n",
            "Epoch #3. Accuracy on batch 843/3013  on Training is 86.25222156398104\n",
            "Epoch #3. Accuracy on batch 844/3013  on Training is 86.25\n",
            "Epoch #3. Accuracy on batch 845/3013  on Training is 86.25147754137116\n",
            "Epoch #3. Accuracy on batch 846/3013  on Training is 86.24557260920898\n",
            "Epoch #3. Accuracy on batch 847/3013  on Training is 86.25810731132076\n",
            "Epoch #3. Accuracy on batch 848/3013  on Training is 86.25220848056537\n",
            "Epoch #3. Accuracy on batch 849/3013  on Training is 86.24632352941177\n",
            "Epoch #3. Accuracy on batch 850/3013  on Training is 86.24045240893066\n",
            "Epoch #3. Accuracy on batch 851/3013  on Training is 86.23459507042253\n",
            "Epoch #3. Accuracy on batch 852/3013  on Training is 86.22875146541618\n",
            "Epoch #3. Accuracy on batch 853/3013  on Training is 86.23755854800937\n",
            "Epoch #3. Accuracy on batch 854/3013  on Training is 86.24634502923976\n",
            "Epoch #3. Accuracy on batch 855/3013  on Training is 86.24780957943925\n",
            "Epoch #3. Accuracy on batch 856/3013  on Training is 86.23833138856476\n",
            "Epoch #3. Accuracy on batch 857/3013  on Training is 86.24708624708624\n",
            "Epoch #3. Accuracy on batch 858/3013  on Training is 86.24854481955762\n",
            "Epoch #3. Accuracy on batch 859/3013  on Training is 86.2390988372093\n",
            "Batch Id 860 is having training loss of 0.4811653196811676\n",
            "0.4011511504650116\n",
            "Epoch #3. Accuracy on batch 860/3013  on Training is 86.2369337979094\n",
            "Epoch #3. Accuracy on batch 861/3013  on Training is 86.24564965197216\n",
            "Epoch #3. Accuracy on batch 862/3013  on Training is 86.24348203939745\n",
            "Epoch #3. Accuracy on batch 863/3013  on Training is 86.23770254629629\n",
            "Epoch #3. Accuracy on batch 864/3013  on Training is 86.23554913294798\n",
            "Epoch #3. Accuracy on batch 865/3013  on Training is 86.23340069284065\n",
            "Epoch #3. Accuracy on batch 866/3013  on Training is 86.22765282583622\n",
            "Epoch #3. Accuracy on batch 867/3013  on Training is 86.23631912442396\n",
            "Epoch #3. Accuracy on batch 868/3013  on Training is 86.24496547756041\n",
            "Epoch #3. Accuracy on batch 869/3013  on Training is 86.24281609195403\n",
            "Epoch #3. Accuracy on batch 870/3013  on Training is 86.23349598163031\n",
            "Epoch #3. Accuracy on batch 871/3013  on Training is 86.22419724770643\n",
            "Epoch #3. Accuracy on batch 872/3013  on Training is 86.21849942726232\n",
            "Epoch #3. Accuracy on batch 873/3013  on Training is 86.2271167048055\n",
            "Epoch #3. Accuracy on batch 874/3013  on Training is 86.22142857142858\n",
            "Epoch #3. Accuracy on batch 875/3013  on Training is 86.23002283105023\n",
            "Epoch #3. Accuracy on batch 876/3013  on Training is 86.21721778791334\n",
            "Epoch #3. Accuracy on batch 877/3013  on Training is 86.21511958997722\n",
            "Epoch #3. Accuracy on batch 878/3013  on Training is 86.22013651877133\n",
            "Epoch #3. Accuracy on batch 879/3013  on Training is 86.22514204545455\n",
            "Batch Id 880 is having training loss of 0.4809432625770569\n",
            "0.5730027556419373\n",
            "Epoch #3. Accuracy on batch 880/3013  on Training is 86.22304199772985\n",
            "Epoch #3. Accuracy on batch 881/3013  on Training is 86.2280328798186\n",
            "Epoch #3. Accuracy on batch 882/3013  on Training is 86.2400906002265\n",
            "Epoch #3. Accuracy on batch 883/3013  on Training is 86.24858597285068\n",
            "Epoch #3. Accuracy on batch 884/3013  on Training is 86.24646892655367\n",
            "Epoch #3. Accuracy on batch 885/3013  on Training is 86.24082957110609\n",
            "Epoch #3. Accuracy on batch 886/3013  on Training is 86.24577226606539\n",
            "Epoch #3. Accuracy on batch 887/3013  on Training is 86.24718468468468\n",
            "Epoch #3. Accuracy on batch 888/3013  on Training is 86.24156355455568\n",
            "Epoch #3. Accuracy on batch 889/3013  on Training is 86.24648876404494\n",
            "Epoch #3. Accuracy on batch 890/3013  on Training is 86.24438832772167\n",
            "Epoch #3. Accuracy on batch 891/3013  on Training is 86.24929932735427\n",
            "Epoch #3. Accuracy on batch 892/3013  on Training is 86.24720044792834\n",
            "Epoch #3. Accuracy on batch 893/3013  on Training is 86.24161073825503\n",
            "Epoch #3. Accuracy on batch 894/3013  on Training is 86.24301675977654\n",
            "Epoch #3. Accuracy on batch 895/3013  on Training is 86.23744419642857\n",
            "Epoch #3. Accuracy on batch 896/3013  on Training is 86.23885172798217\n",
            "Epoch #3. Accuracy on batch 897/3013  on Training is 86.22633630289532\n",
            "Epoch #3. Accuracy on batch 898/3013  on Training is 86.23122914349277\n",
            "Epoch #3. Accuracy on batch 899/3013  on Training is 86.23958333333333\n",
            "Batch Id 900 is having training loss of 0.4811377227306366\n",
            "0.3984279930591583\n",
            "Epoch #3. Accuracy on batch 900/3013  on Training is 86.24445061043285\n",
            "Epoch #3. Accuracy on batch 901/3013  on Training is 86.24930709534368\n",
            "Epoch #3. Accuracy on batch 902/3013  on Training is 86.25069213732004\n",
            "Epoch #3. Accuracy on batch 903/3013  on Training is 86.25553097345133\n",
            "Epoch #3. Accuracy on batch 904/3013  on Training is 86.25690607734806\n",
            "Epoch #3. Accuracy on batch 905/3013  on Training is 86.25137969094922\n",
            "Epoch #3. Accuracy on batch 906/3013  on Training is 86.25275633958104\n",
            "Epoch #3. Accuracy on batch 907/3013  on Training is 86.26101321585904\n",
            "Epoch #3. Accuracy on batch 908/3013  on Training is 86.25893839383939\n",
            "Epoch #3. Accuracy on batch 909/3013  on Training is 86.25686813186813\n",
            "Epoch #3. Accuracy on batch 910/3013  on Training is 86.26166300768386\n",
            "Epoch #3. Accuracy on batch 911/3013  on Training is 86.25616776315789\n",
            "Epoch #3. Accuracy on batch 912/3013  on Training is 86.25068455640745\n",
            "Epoch #3. Accuracy on batch 913/3013  on Training is 86.2554704595186\n",
            "Epoch #3. Accuracy on batch 914/3013  on Training is 86.2568306010929\n",
            "Epoch #3. Accuracy on batch 915/3013  on Training is 86.26159934497817\n",
            "Epoch #3. Accuracy on batch 916/3013  on Training is 86.26294983642312\n",
            "Epoch #3. Accuracy on batch 917/3013  on Training is 86.25748910675381\n",
            "Epoch #3. Accuracy on batch 918/3013  on Training is 86.25884113166485\n",
            "Epoch #3. Accuracy on batch 919/3013  on Training is 86.26358695652173\n",
            "Batch Id 920 is having training loss of 0.4806933104991913\n",
            "0.4692140817642212\n",
            "Epoch #3. Accuracy on batch 920/3013  on Training is 86.26153637350706\n",
            "Epoch #3. Accuracy on batch 921/3013  on Training is 86.26965835140997\n",
            "Epoch #3. Accuracy on batch 922/3013  on Training is 86.27099133261105\n",
            "Epoch #3. Accuracy on batch 923/3013  on Training is 86.26555735930737\n",
            "Epoch #3. Accuracy on batch 924/3013  on Training is 86.25675675675676\n",
            "Epoch #3. Accuracy on batch 925/3013  on Training is 86.25472462203024\n",
            "Epoch #3. Accuracy on batch 926/3013  on Training is 86.24595469255664\n",
            "Epoch #3. Accuracy on batch 927/3013  on Training is 86.24730603448276\n",
            "Epoch #3. Accuracy on batch 928/3013  on Training is 86.255382131324\n",
            "Epoch #3. Accuracy on batch 929/3013  on Training is 86.24663978494624\n",
            "Epoch #3. Accuracy on batch 930/3013  on Training is 86.24462943071966\n",
            "Epoch #3. Accuracy on batch 931/3013  on Training is 86.24262339055794\n",
            "Epoch #3. Accuracy on batch 932/3013  on Training is 86.25066988210075\n",
            "Epoch #3. Accuracy on batch 933/3013  on Training is 86.24531584582441\n",
            "Epoch #3. Accuracy on batch 934/3013  on Training is 86.2433155080214\n",
            "Epoch #3. Accuracy on batch 935/3013  on Training is 86.24131944444444\n",
            "Epoch #3. Accuracy on batch 936/3013  on Training is 86.24266275346852\n",
            "Epoch #3. Accuracy on batch 937/3013  on Training is 86.23734008528784\n",
            "Epoch #3. Accuracy on batch 938/3013  on Training is 86.23868477103301\n",
            "Epoch #3. Accuracy on batch 939/3013  on Training is 86.23670212765957\n",
            "Batch Id 940 is having training loss of 0.48248225450515747\n",
            "0.7027983665466309\n",
            "Epoch #3. Accuracy on batch 940/3013  on Training is 86.22808182784271\n",
            "Epoch #3. Accuracy on batch 941/3013  on Training is 86.22279723991507\n",
            "Epoch #3. Accuracy on batch 942/3013  on Training is 86.21089607635207\n",
            "Epoch #3. Accuracy on batch 943/3013  on Training is 86.21226165254237\n",
            "Epoch #3. Accuracy on batch 944/3013  on Training is 86.20701058201058\n",
            "Epoch #3. Accuracy on batch 945/3013  on Training is 86.20507399577167\n",
            "Epoch #3. Accuracy on batch 946/3013  on Training is 86.19654171066526\n",
            "Epoch #3. Accuracy on batch 947/3013  on Training is 86.19462025316456\n",
            "Epoch #3. Accuracy on batch 948/3013  on Training is 86.1927028451001\n",
            "Epoch #3. Accuracy on batch 949/3013  on Training is 86.1842105263158\n",
            "Epoch #3. Accuracy on batch 950/3013  on Training is 86.18559411146163\n",
            "Epoch #3. Accuracy on batch 951/3013  on Training is 86.18369222689076\n",
            "Epoch #3. Accuracy on batch 952/3013  on Training is 86.17851521511018\n",
            "Epoch #3. Accuracy on batch 953/3013  on Training is 86.17990041928721\n",
            "Epoch #3. Accuracy on batch 954/3013  on Training is 86.18782722513089\n",
            "Epoch #3. Accuracy on batch 955/3013  on Training is 86.17612447698745\n",
            "Epoch #3. Accuracy on batch 956/3013  on Training is 86.18403866248694\n",
            "Epoch #3. Accuracy on batch 957/3013  on Training is 86.17888830897704\n",
            "Epoch #3. Accuracy on batch 958/3013  on Training is 86.18026590198123\n",
            "Epoch #3. Accuracy on batch 959/3013  on Training is 86.18489583333333\n",
            "Batch Id 960 is having training loss of 0.4829779863357544\n",
            "0.28036990761756897\n",
            "Epoch #3. Accuracy on batch 960/3013  on Training is 86.19276795005203\n",
            "Epoch #3. Accuracy on batch 961/3013  on Training is 86.18762993762994\n",
            "Epoch #3. Accuracy on batch 962/3013  on Training is 86.19223779854622\n",
            "Epoch #3. Accuracy on batch 963/3013  on Training is 86.19683609958506\n",
            "Epoch #3. Accuracy on batch 964/3013  on Training is 86.20142487046633\n",
            "Epoch #3. Accuracy on batch 965/3013  on Training is 86.20276915113871\n",
            "Epoch #3. Accuracy on batch 966/3013  on Training is 86.20087900723888\n",
            "Epoch #3. Accuracy on batch 967/3013  on Training is 86.20222107438016\n",
            "Epoch #3. Accuracy on batch 968/3013  on Training is 86.20678534571724\n",
            "Epoch #3. Accuracy on batch 969/3013  on Training is 86.2048969072165\n",
            "Epoch #3. Accuracy on batch 970/3013  on Training is 86.19979402677652\n",
            "Epoch #3. Accuracy on batch 971/3013  on Training is 86.20756172839506\n",
            "Epoch #3. Accuracy on batch 972/3013  on Training is 86.19925488180884\n",
            "Epoch #3. Accuracy on batch 973/3013  on Training is 86.20379876796714\n",
            "Epoch #3. Accuracy on batch 974/3013  on Training is 86.2051282051282\n",
            "Epoch #3. Accuracy on batch 975/3013  on Training is 86.2032530737705\n",
            "Epoch #3. Accuracy on batch 976/3013  on Training is 86.21097748208803\n",
            "Epoch #3. Accuracy on batch 977/3013  on Training is 86.20590490797547\n",
            "Epoch #3. Accuracy on batch 978/3013  on Training is 86.20722676200204\n",
            "Epoch #3. Accuracy on batch 979/3013  on Training is 86.21492346938776\n",
            "Batch Id 980 is having training loss of 0.4821283221244812\n",
            "0.5573533177375793\n",
            "Epoch #3. Accuracy on batch 980/3013  on Training is 86.20349133537206\n",
            "Epoch #3. Accuracy on batch 981/3013  on Training is 86.20799389002036\n",
            "Epoch #3. Accuracy on batch 982/3013  on Training is 86.21248728382503\n",
            "Epoch #3. Accuracy on batch 983/3013  on Training is 86.21697154471545\n",
            "Epoch #3. Accuracy on batch 984/3013  on Training is 86.21827411167513\n",
            "Epoch #3. Accuracy on batch 985/3013  on Training is 86.22591277890467\n",
            "Epoch #3. Accuracy on batch 986/3013  on Training is 86.22720364741642\n",
            "Epoch #3. Accuracy on batch 987/3013  on Training is 86.22849190283401\n",
            "Epoch #3. Accuracy on batch 988/3013  on Training is 86.22661779575328\n",
            "Epoch #3. Accuracy on batch 989/3013  on Training is 86.23106060606061\n",
            "Epoch #3. Accuracy on batch 990/3013  on Training is 86.2228809283552\n",
            "Epoch #3. Accuracy on batch 991/3013  on Training is 86.21156754032258\n",
            "Epoch #3. Accuracy on batch 992/3013  on Training is 86.21915911379658\n",
            "Epoch #3. Accuracy on batch 993/3013  on Training is 86.2204476861167\n",
            "Epoch #3. Accuracy on batch 994/3013  on Training is 86.2248743718593\n",
            "Epoch #3. Accuracy on batch 995/3013  on Training is 86.2292921686747\n",
            "Epoch #3. Accuracy on batch 996/3013  on Training is 86.22743229689067\n",
            "Epoch #3. Accuracy on batch 997/3013  on Training is 86.22244488977955\n",
            "Epoch #3. Accuracy on batch 998/3013  on Training is 86.22685185185185\n",
            "Epoch #3. Accuracy on batch 999/3013  on Training is 86.221875\n",
            "Batch Id 1000 is having training loss of 0.48088136315345764\n",
            "0.20105698704719543\n",
            "Epoch #3. Accuracy on batch 1000/3013  on Training is 86.2293956043956\n",
            "Epoch #3. Accuracy on batch 1001/3013  on Training is 86.22130738522954\n",
            "Epoch #3. Accuracy on batch 1002/3013  on Training is 86.22569790628116\n",
            "Epoch #3. Accuracy on batch 1003/3013  on Training is 86.22385458167331\n",
            "Epoch #3. Accuracy on batch 1004/3013  on Training is 86.22823383084577\n",
            "Epoch #3. Accuracy on batch 1005/3013  on Training is 86.22949801192843\n",
            "Epoch #3. Accuracy on batch 1006/3013  on Training is 86.23696623634558\n",
            "Epoch #3. Accuracy on batch 1007/3013  on Training is 86.24131944444444\n",
            "Epoch #3. Accuracy on batch 1008/3013  on Training is 86.24256689791873\n",
            "Epoch #3. Accuracy on batch 1009/3013  on Training is 86.24381188118812\n",
            "Epoch #3. Accuracy on batch 1010/3013  on Training is 86.23887240356083\n",
            "Epoch #3. Accuracy on batch 1011/3013  on Training is 86.24938241106719\n",
            "Epoch #3. Accuracy on batch 1012/3013  on Training is 86.2506169792695\n",
            "Epoch #3. Accuracy on batch 1013/3013  on Training is 86.23952169625247\n",
            "Epoch #3. Accuracy on batch 1014/3013  on Training is 86.23152709359606\n",
            "Epoch #3. Accuracy on batch 1015/3013  on Training is 86.22354822834646\n",
            "Epoch #3. Accuracy on batch 1016/3013  on Training is 86.22480334316617\n",
            "Epoch #3. Accuracy on batch 1017/3013  on Training is 86.23219548133595\n",
            "Epoch #3. Accuracy on batch 1018/3013  on Training is 86.23343964671247\n",
            "Epoch #3. Accuracy on batch 1019/3013  on Training is 86.23774509803921\n",
            "Batch Id 1020 is having training loss of 0.4800492525100708\n",
            "0.6878848671913147\n",
            "Epoch #3. Accuracy on batch 1020/3013  on Training is 86.23898139079334\n",
            "Epoch #3. Accuracy on batch 1021/3013  on Training is 86.231042074364\n",
            "Epoch #3. Accuracy on batch 1022/3013  on Training is 86.22922776148583\n",
            "Epoch #3. Accuracy on batch 1023/3013  on Training is 86.21826171875\n",
            "Epoch #3. Accuracy on batch 1024/3013  on Training is 86.21951219512195\n",
            "Epoch #3. Accuracy on batch 1025/3013  on Training is 86.21771442495127\n",
            "Epoch #3. Accuracy on batch 1026/3013  on Training is 86.20679162609542\n",
            "Epoch #3. Accuracy on batch 1027/3013  on Training is 86.20196984435798\n",
            "Epoch #3. Accuracy on batch 1028/3013  on Training is 86.203231292517\n",
            "Epoch #3. Accuracy on batch 1029/3013  on Training is 86.20449029126213\n",
            "Epoch #3. Accuracy on batch 1030/3013  on Training is 86.2027158098933\n",
            "Epoch #3. Accuracy on batch 1031/3013  on Training is 86.20700096899225\n",
            "Epoch #3. Accuracy on batch 1032/3013  on Training is 86.21430300096806\n",
            "Epoch #3. Accuracy on batch 1033/3013  on Training is 86.21554642166345\n",
            "Epoch #3. Accuracy on batch 1034/3013  on Training is 86.20772946859903\n",
            "Epoch #3. Accuracy on batch 1035/3013  on Training is 86.20596042471043\n",
            "Epoch #3. Accuracy on batch 1036/3013  on Training is 86.20720829315333\n",
            "Epoch #3. Accuracy on batch 1037/3013  on Training is 86.20243256262043\n",
            "Epoch #3. Accuracy on batch 1038/3013  on Training is 86.20368142444659\n",
            "Epoch #3. Accuracy on batch 1039/3013  on Training is 86.20492788461539\n",
            "Batch Id 1040 is having training loss of 0.48091837763786316\n",
            "0.4769735038280487\n",
            "Epoch #3. Accuracy on batch 1040/3013  on Training is 86.20016810758885\n",
            "Epoch #3. Accuracy on batch 1041/3013  on Training is 86.19541746641075\n",
            "Epoch #3. Accuracy on batch 1042/3013  on Training is 86.17869127516778\n",
            "Epoch #3. Accuracy on batch 1043/3013  on Training is 86.17397030651341\n",
            "Epoch #3. Accuracy on batch 1044/3013  on Training is 86.17822966507177\n",
            "Epoch #3. Accuracy on batch 1045/3013  on Training is 86.17650573613767\n",
            "Epoch #3. Accuracy on batch 1046/3013  on Training is 86.17180038204394\n",
            "Epoch #3. Accuracy on batch 1047/3013  on Training is 86.16710400763358\n",
            "Epoch #3. Accuracy on batch 1048/3013  on Training is 86.16837464251668\n",
            "Epoch #3. Accuracy on batch 1049/3013  on Training is 86.16964285714286\n",
            "Epoch #3. Accuracy on batch 1050/3013  on Training is 86.16198858230257\n",
            "Epoch #3. Accuracy on batch 1051/3013  on Training is 86.16623098859316\n",
            "Epoch #3. Accuracy on batch 1052/3013  on Training is 86.170465337132\n",
            "Epoch #3. Accuracy on batch 1053/3013  on Training is 86.16579696394687\n",
            "Epoch #3. Accuracy on batch 1054/3013  on Training is 86.17002369668246\n",
            "Epoch #3. Accuracy on batch 1055/3013  on Training is 86.17128314393939\n",
            "Epoch #3. Accuracy on batch 1056/3013  on Training is 86.16662724692526\n",
            "Epoch #3. Accuracy on batch 1057/3013  on Training is 86.17084120982987\n",
            "Epoch #3. Accuracy on batch 1058/3013  on Training is 86.17504721435316\n",
            "Epoch #3. Accuracy on batch 1059/3013  on Training is 86.17629716981132\n",
            "Batch Id 1060 is having training loss of 0.4818665385246277\n",
            "0.9258502721786499\n",
            "Epoch #3. Accuracy on batch 1060/3013  on Training is 86.17165409990575\n",
            "Epoch #3. Accuracy on batch 1061/3013  on Training is 86.17879001883239\n",
            "Epoch #3. Accuracy on batch 1062/3013  on Training is 86.17121354656632\n",
            "Epoch #3. Accuracy on batch 1063/3013  on Training is 86.17539943609023\n",
            "Epoch #3. Accuracy on batch 1064/3013  on Training is 86.17664319248826\n",
            "Epoch #3. Accuracy on batch 1065/3013  on Training is 86.1749530956848\n",
            "Epoch #3. Accuracy on batch 1066/3013  on Training is 86.17619493908154\n",
            "Epoch #3. Accuracy on batch 1067/3013  on Training is 86.17743445692884\n",
            "Epoch #3. Accuracy on batch 1068/3013  on Training is 86.18159494855004\n",
            "Epoch #3. Accuracy on batch 1069/3013  on Training is 86.18866822429906\n",
            "Epoch #3. Accuracy on batch 1070/3013  on Training is 86.18697478991596\n",
            "Epoch #3. Accuracy on batch 1071/3013  on Training is 86.17945429104478\n",
            "Epoch #3. Accuracy on batch 1072/3013  on Training is 86.18942218080149\n",
            "Epoch #3. Accuracy on batch 1073/3013  on Training is 86.19355214152701\n",
            "Epoch #3. Accuracy on batch 1074/3013  on Training is 86.19476744186046\n",
            "Epoch #3. Accuracy on batch 1075/3013  on Training is 86.19307620817844\n",
            "Epoch #3. Accuracy on batch 1076/3013  on Training is 86.19428969359332\n",
            "Epoch #3. Accuracy on batch 1077/3013  on Training is 86.19839981447124\n",
            "Epoch #3. Accuracy on batch 1078/3013  on Training is 86.19670991658944\n",
            "Epoch #3. Accuracy on batch 1079/3013  on Training is 86.20081018518519\n",
            "Batch Id 1080 is having training loss of 0.481280654668808\n",
            "0.44291046261787415\n",
            "Epoch #3. Accuracy on batch 1080/3013  on Training is 86.20201202590194\n",
            "Epoch #3. Accuracy on batch 1081/3013  on Training is 86.19743530499076\n",
            "Epoch #3. Accuracy on batch 1082/3013  on Training is 86.19575253924285\n",
            "Epoch #3. Accuracy on batch 1083/3013  on Training is 86.20560424354244\n",
            "Epoch #3. Accuracy on batch 1084/3013  on Training is 86.20679723502305\n",
            "Epoch #3. Accuracy on batch 1085/3013  on Training is 86.19647790055248\n",
            "Epoch #3. Accuracy on batch 1086/3013  on Training is 86.20055197792088\n",
            "Epoch #3. Accuracy on batch 1087/3013  on Training is 86.19887408088235\n",
            "Epoch #3. Accuracy on batch 1088/3013  on Training is 86.20293847566575\n",
            "Epoch #3. Accuracy on batch 1089/3013  on Training is 86.19839449541284\n",
            "Epoch #3. Accuracy on batch 1090/3013  on Training is 86.19672318973419\n",
            "Epoch #3. Accuracy on batch 1091/3013  on Training is 86.20364010989012\n",
            "Epoch #3. Accuracy on batch 1092/3013  on Training is 86.20768526989936\n",
            "Epoch #3. Accuracy on batch 1093/3013  on Training is 86.19172760511883\n",
            "Epoch #3. Accuracy on batch 1094/3013  on Training is 86.19577625570776\n",
            "Epoch #3. Accuracy on batch 1095/3013  on Training is 86.19696624087591\n",
            "Epoch #3. Accuracy on batch 1096/3013  on Training is 86.20385141294439\n",
            "Epoch #3. Accuracy on batch 1097/3013  on Training is 86.20218579234972\n",
            "Epoch #3. Accuracy on batch 1098/3013  on Training is 86.20052320291174\n",
            "Epoch #3. Accuracy on batch 1099/3013  on Training is 86.19602272727273\n",
            "Batch Id 1100 is having training loss of 0.48158615827560425\n",
            "0.3162306547164917\n",
            "Epoch #3. Accuracy on batch 1100/3013  on Training is 86.20004541326067\n",
            "Epoch #3. Accuracy on batch 1101/3013  on Training is 86.18988203266788\n",
            "Epoch #3. Accuracy on batch 1102/3013  on Training is 86.19390299184043\n",
            "Epoch #3. Accuracy on batch 1103/3013  on Training is 86.19225543478261\n",
            "Epoch #3. Accuracy on batch 1104/3013  on Training is 86.19626696832579\n",
            "Epoch #3. Accuracy on batch 1105/3013  on Training is 86.19744575045208\n",
            "Epoch #3. Accuracy on batch 1106/3013  on Training is 86.20426829268293\n",
            "Epoch #3. Accuracy on batch 1107/3013  on Training is 86.20825812274369\n",
            "Epoch #3. Accuracy on batch 1108/3013  on Training is 86.21224075743913\n",
            "Epoch #3. Accuracy on batch 1109/3013  on Training is 86.21340090090091\n",
            "Epoch #3. Accuracy on batch 1110/3013  on Training is 86.21174617461746\n",
            "Epoch #3. Accuracy on batch 1111/3013  on Training is 86.20728417266187\n",
            "Epoch #3. Accuracy on batch 1112/3013  on Training is 86.20844564240791\n",
            "Epoch #3. Accuracy on batch 1113/3013  on Training is 86.21241023339317\n",
            "Epoch #3. Accuracy on batch 1114/3013  on Training is 86.2079596412556\n",
            "Epoch #3. Accuracy on batch 1115/3013  on Training is 86.21191756272401\n",
            "Epoch #3. Accuracy on batch 1116/3013  on Training is 86.21307072515667\n",
            "Epoch #3. Accuracy on batch 1117/3013  on Training is 86.21422182468694\n",
            "Epoch #3. Accuracy on batch 1118/3013  on Training is 86.218163538874\n",
            "Epoch #3. Accuracy on batch 1119/3013  on Training is 86.21930803571429\n",
            "Batch Id 1120 is having training loss of 0.4816671907901764\n",
            "0.612380862236023\n",
            "Epoch #3. Accuracy on batch 1120/3013  on Training is 86.21208742194469\n",
            "Epoch #3. Accuracy on batch 1121/3013  on Training is 86.21045008912655\n",
            "Epoch #3. Accuracy on batch 1122/3013  on Training is 86.2115983971505\n",
            "Epoch #3. Accuracy on batch 1123/3013  on Training is 86.20440391459074\n",
            "Epoch #3. Accuracy on batch 1124/3013  on Training is 86.20555555555555\n",
            "Epoch #3. Accuracy on batch 1125/3013  on Training is 86.20670515097692\n",
            "Epoch #3. Accuracy on batch 1126/3013  on Training is 86.20785270629992\n",
            "Epoch #3. Accuracy on batch 1127/3013  on Training is 86.21176861702128\n",
            "Epoch #3. Accuracy on batch 1128/3013  on Training is 86.22121346324181\n",
            "Epoch #3. Accuracy on batch 1129/3013  on Training is 86.22234513274336\n",
            "Epoch #3. Accuracy on batch 1130/3013  on Training is 86.2290008841733\n",
            "Epoch #3. Accuracy on batch 1131/3013  on Training is 86.22736307420494\n",
            "Epoch #3. Accuracy on batch 1132/3013  on Training is 86.22572815533981\n",
            "Epoch #3. Accuracy on batch 1133/3013  on Training is 86.22409611992946\n",
            "Epoch #3. Accuracy on batch 1134/3013  on Training is 86.22522026431719\n",
            "Epoch #3. Accuracy on batch 1135/3013  on Training is 86.22359154929578\n",
            "Epoch #3. Accuracy on batch 1136/3013  on Training is 86.2137203166227\n",
            "Epoch #3. Accuracy on batch 1137/3013  on Training is 86.21759666080844\n",
            "Epoch #3. Accuracy on batch 1138/3013  on Training is 86.21323529411765\n",
            "Epoch #3. Accuracy on batch 1139/3013  on Training is 86.20888157894737\n",
            "Batch Id 1140 is having training loss of 0.4819282591342926\n",
            "0.611842691898346\n",
            "Epoch #3. Accuracy on batch 1140/3013  on Training is 86.20727432077125\n",
            "Epoch #3. Accuracy on batch 1141/3013  on Training is 86.20293345008757\n",
            "Epoch #3. Accuracy on batch 1142/3013  on Training is 86.20406824146981\n",
            "Epoch #3. Accuracy on batch 1143/3013  on Training is 86.19154283216783\n",
            "Epoch #3. Accuracy on batch 1144/3013  on Training is 86.19541484716157\n",
            "Epoch #3. Accuracy on batch 1145/3013  on Training is 86.19382635253054\n",
            "Epoch #3. Accuracy on batch 1146/3013  on Training is 86.18679163034001\n",
            "Epoch #3. Accuracy on batch 1147/3013  on Training is 86.18249128919861\n",
            "Epoch #3. Accuracy on batch 1148/3013  on Training is 86.17547867711053\n",
            "Epoch #3. Accuracy on batch 1149/3013  on Training is 86.17663043478261\n",
            "Epoch #3. Accuracy on batch 1150/3013  on Training is 86.16963509991312\n",
            "Epoch #3. Accuracy on batch 1151/3013  on Training is 86.17350260416667\n",
            "Epoch #3. Accuracy on batch 1152/3013  on Training is 86.17736339982653\n",
            "Epoch #3. Accuracy on batch 1153/3013  on Training is 86.16767764298093\n",
            "Epoch #3. Accuracy on batch 1154/3013  on Training is 86.16883116883118\n",
            "Epoch #3. Accuracy on batch 1155/3013  on Training is 86.17268598615917\n",
            "Epoch #3. Accuracy on batch 1156/3013  on Training is 86.17383318928263\n",
            "Epoch #3. Accuracy on batch 1157/3013  on Training is 86.18307426597582\n",
            "Epoch #3. Accuracy on batch 1158/3013  on Training is 86.18690681622088\n",
            "Epoch #3. Accuracy on batch 1159/3013  on Training is 86.1853448275862\n",
            "Batch Id 1160 is having training loss of 0.48272496461868286\n",
            "0.4725130498409271\n",
            "Epoch #3. Accuracy on batch 1160/3013  on Training is 86.18378552971576\n",
            "Epoch #3. Accuracy on batch 1161/3013  on Training is 86.17685025817556\n",
            "Epoch #3. Accuracy on batch 1162/3013  on Training is 86.17798796216681\n",
            "Epoch #3. Accuracy on batch 1163/3013  on Training is 86.17375429553265\n",
            "Epoch #3. Accuracy on batch 1164/3013  on Training is 86.17489270386267\n",
            "Epoch #3. Accuracy on batch 1165/3013  on Training is 86.17602915951973\n",
            "Epoch #3. Accuracy on batch 1166/3013  on Training is 86.17984147386461\n",
            "Epoch #3. Accuracy on batch 1167/3013  on Training is 86.17829623287672\n",
            "Epoch #3. Accuracy on batch 1168/3013  on Training is 86.17408041060736\n",
            "Epoch #3. Accuracy on batch 1169/3013  on Training is 86.1698717948718\n",
            "Epoch #3. Accuracy on batch 1170/3013  on Training is 86.17100768573869\n",
            "Epoch #3. Accuracy on batch 1171/3013  on Training is 86.16147610921502\n",
            "Epoch #3. Accuracy on batch 1172/3013  on Training is 86.15995311167946\n",
            "Epoch #3. Accuracy on batch 1173/3013  on Training is 86.16109454855196\n",
            "Epoch #3. Accuracy on batch 1174/3013  on Training is 86.15425531914893\n",
            "Epoch #3. Accuracy on batch 1175/3013  on Training is 86.1500850340136\n",
            "Epoch #3. Accuracy on batch 1176/3013  on Training is 86.14857689039933\n",
            "Epoch #3. Accuracy on batch 1177/3013  on Training is 86.14441850594227\n",
            "Epoch #3. Accuracy on batch 1178/3013  on Training is 86.14291772688719\n",
            "Epoch #3. Accuracy on batch 1179/3013  on Training is 86.14406779661017\n",
            "Batch Id 1180 is having training loss of 0.48394814133644104\n",
            "0.8460728526115417\n",
            "Epoch #3. Accuracy on batch 1180/3013  on Training is 86.13198560541913\n",
            "Epoch #3. Accuracy on batch 1181/3013  on Training is 86.13314297800338\n",
            "Epoch #3. Accuracy on batch 1182/3013  on Training is 86.13429839391378\n",
            "Epoch #3. Accuracy on batch 1183/3013  on Training is 86.13017314189189\n",
            "Epoch #3. Accuracy on batch 1184/3013  on Training is 86.13396624472574\n",
            "Epoch #3. Accuracy on batch 1185/3013  on Training is 86.13511804384486\n",
            "Epoch #3. Accuracy on batch 1186/3013  on Training is 86.14153327716933\n",
            "Epoch #3. Accuracy on batch 1187/3013  on Training is 86.13478535353535\n",
            "Epoch #3. Accuracy on batch 1188/3013  on Training is 86.13593355761144\n",
            "Epoch #3. Accuracy on batch 1189/3013  on Training is 86.1344537815126\n",
            "Epoch #3. Accuracy on batch 1190/3013  on Training is 86.14084802686818\n",
            "Epoch #3. Accuracy on batch 1191/3013  on Training is 86.13412332214764\n",
            "Epoch #3. Accuracy on batch 1192/3013  on Training is 86.12740989103101\n",
            "Epoch #3. Accuracy on batch 1193/3013  on Training is 86.12594221105527\n",
            "Epoch #3. Accuracy on batch 1194/3013  on Training is 86.11663179916317\n",
            "Epoch #3. Accuracy on batch 1195/3013  on Training is 86.11778846153847\n",
            "Epoch #3. Accuracy on batch 1196/3013  on Training is 86.11633249791144\n",
            "Epoch #3. Accuracy on batch 1197/3013  on Training is 86.11748747913188\n",
            "Epoch #3. Accuracy on batch 1198/3013  on Training is 86.12385321100918\n",
            "Epoch #3. Accuracy on batch 1199/3013  on Training is 86.1328125\n",
            "Batch Id 1200 is having training loss of 0.4842126667499542\n",
            "0.8453176021575928\n",
            "Epoch #3. Accuracy on batch 1200/3013  on Training is 86.12354288093256\n",
            "Epoch #3. Accuracy on batch 1201/3013  on Training is 86.11428868552413\n",
            "Epoch #3. Accuracy on batch 1202/3013  on Training is 86.10764754779717\n",
            "Epoch #3. Accuracy on batch 1203/3013  on Training is 86.11139950166113\n",
            "Epoch #3. Accuracy on batch 1204/3013  on Training is 86.11514522821577\n",
            "Epoch #3. Accuracy on batch 1205/3013  on Training is 86.12406716417911\n",
            "Epoch #3. Accuracy on batch 1206/3013  on Training is 86.11743993371996\n",
            "Epoch #3. Accuracy on batch 1207/3013  on Training is 86.11599751655629\n",
            "Epoch #3. Accuracy on batch 1208/3013  on Training is 86.1197270471464\n",
            "Epoch #3. Accuracy on batch 1209/3013  on Training is 86.12345041322314\n",
            "Epoch #3. Accuracy on batch 1210/3013  on Training is 86.12200660611066\n",
            "Epoch #3. Accuracy on batch 1211/3013  on Training is 86.12056518151815\n",
            "Epoch #3. Accuracy on batch 1212/3013  on Training is 86.11397361912613\n",
            "Epoch #3. Accuracy on batch 1213/3013  on Training is 86.10739291598023\n",
            "Epoch #3. Accuracy on batch 1214/3013  on Training is 86.10853909465021\n",
            "Epoch #3. Accuracy on batch 1215/3013  on Training is 86.09940378289474\n",
            "Epoch #3. Accuracy on batch 1216/3013  on Training is 86.09028348397699\n",
            "Epoch #3. Accuracy on batch 1217/3013  on Training is 86.0914408866995\n",
            "Epoch #3. Accuracy on batch 1218/3013  on Training is 86.09772354388843\n",
            "Epoch #3. Accuracy on batch 1219/3013  on Training is 86.09118852459017\n",
            "Batch Id 1220 is having training loss of 0.4855513274669647\n",
            "0.5589401721954346\n",
            "Epoch #3. Accuracy on batch 1220/3013  on Training is 86.08978296478297\n",
            "Epoch #3. Accuracy on batch 1221/3013  on Training is 86.08326513911621\n",
            "Epoch #3. Accuracy on batch 1222/3013  on Training is 86.08186835650041\n",
            "Epoch #3. Accuracy on batch 1223/3013  on Training is 86.08302696078431\n",
            "Epoch #3. Accuracy on batch 1224/3013  on Training is 86.08928571428571\n",
            "Epoch #3. Accuracy on batch 1225/3013  on Training is 86.09553425774878\n",
            "Epoch #3. Accuracy on batch 1226/3013  on Training is 86.1043194784026\n",
            "Epoch #3. Accuracy on batch 1227/3013  on Training is 86.10291123778502\n",
            "Epoch #3. Accuracy on batch 1228/3013  on Training is 86.0989625711961\n",
            "Epoch #3. Accuracy on batch 1229/3013  on Training is 86.10518292682927\n",
            "Epoch #3. Accuracy on batch 1230/3013  on Training is 86.09362307067425\n",
            "Epoch #3. Accuracy on batch 1231/3013  on Training is 86.09730113636364\n",
            "Epoch #3. Accuracy on batch 1232/3013  on Training is 86.10097323600974\n",
            "Epoch #3. Accuracy on batch 1233/3013  on Training is 86.10210696920583\n",
            "Epoch #3. Accuracy on batch 1234/3013  on Training is 86.10576923076923\n",
            "Epoch #3. Accuracy on batch 1235/3013  on Training is 86.09678398058253\n",
            "Epoch #3. Accuracy on batch 1236/3013  on Training is 86.10297089733226\n",
            "Epoch #3. Accuracy on batch 1237/3013  on Training is 86.10409935379644\n",
            "Epoch #3. Accuracy on batch 1238/3013  on Training is 86.10522598870057\n",
            "Epoch #3. Accuracy on batch 1239/3013  on Training is 86.11139112903226\n",
            "Batch Id 1240 is having training loss of 0.4845554232597351\n",
            "0.4474775195121765\n",
            "Epoch #3. Accuracy on batch 1240/3013  on Training is 86.11251007252216\n",
            "Epoch #3. Accuracy on batch 1241/3013  on Training is 86.10859500805152\n",
            "Epoch #3. Accuracy on batch 1242/3013  on Training is 86.10971440064361\n",
            "Epoch #3. Accuracy on batch 1243/3013  on Training is 86.10831993569131\n",
            "Epoch #3. Accuracy on batch 1244/3013  on Training is 86.10692771084338\n",
            "Epoch #3. Accuracy on batch 1245/3013  on Training is 86.1130617977528\n",
            "Epoch #3. Accuracy on batch 1246/3013  on Training is 86.1116680032077\n",
            "Epoch #3. Accuracy on batch 1247/3013  on Training is 86.1152844551282\n",
            "Epoch #3. Accuracy on batch 1248/3013  on Training is 86.11639311449159\n",
            "Epoch #3. Accuracy on batch 1249/3013  on Training is 86.1125\n",
            "Epoch #3. Accuracy on batch 1250/3013  on Training is 86.11610711430855\n",
            "Epoch #3. Accuracy on batch 1251/3013  on Training is 86.10722843450479\n",
            "Epoch #3. Accuracy on batch 1252/3013  on Training is 86.10335195530726\n",
            "Epoch #3. Accuracy on batch 1253/3013  on Training is 86.10197368421052\n",
            "Epoch #3. Accuracy on batch 1254/3013  on Training is 86.1030876494024\n",
            "Epoch #3. Accuracy on batch 1255/3013  on Training is 86.10668789808918\n",
            "Epoch #3. Accuracy on batch 1256/3013  on Training is 86.11276849642005\n",
            "Epoch #3. Accuracy on batch 1257/3013  on Training is 86.11138712241653\n",
            "Epoch #3. Accuracy on batch 1258/3013  on Training is 86.1075258141382\n",
            "Epoch #3. Accuracy on batch 1259/3013  on Training is 86.10863095238095\n",
            "Batch Id 1260 is having training loss of 0.4846126139163971\n",
            "0.43809765577316284\n",
            "Epoch #3. Accuracy on batch 1260/3013  on Training is 86.10973433782712\n",
            "Epoch #3. Accuracy on batch 1261/3013  on Training is 86.10340729001585\n",
            "Epoch #3. Accuracy on batch 1262/3013  on Training is 86.1069873317498\n",
            "Epoch #3. Accuracy on batch 1263/3013  on Training is 86.1056170886076\n",
            "Epoch #3. Accuracy on batch 1264/3013  on Training is 86.11413043478261\n",
            "Epoch #3. Accuracy on batch 1265/3013  on Training is 86.12016192733017\n",
            "Epoch #3. Accuracy on batch 1266/3013  on Training is 86.11878453038673\n",
            "Epoch #3. Accuracy on batch 1267/3013  on Training is 86.12480283911673\n",
            "Epoch #3. Accuracy on batch 1268/3013  on Training is 86.12834909377463\n",
            "Epoch #3. Accuracy on batch 1269/3013  on Training is 86.12450787401575\n",
            "Epoch #3. Accuracy on batch 1270/3013  on Training is 86.1182140047207\n",
            "Epoch #3. Accuracy on batch 1271/3013  on Training is 86.10701650943396\n",
            "Epoch #3. Accuracy on batch 1272/3013  on Training is 86.10320109976433\n",
            "Epoch #3. Accuracy on batch 1273/3013  on Training is 86.10184458398744\n",
            "Epoch #3. Accuracy on batch 1274/3013  on Training is 86.09558823529412\n",
            "Epoch #3. Accuracy on batch 1275/3013  on Training is 86.09423981191223\n",
            "Epoch #3. Accuracy on batch 1276/3013  on Training is 86.09534064213\n",
            "Epoch #3. Accuracy on batch 1277/3013  on Training is 86.09643974960876\n",
            "Epoch #3. Accuracy on batch 1278/3013  on Training is 86.09509382329945\n",
            "Epoch #3. Accuracy on batch 1279/3013  on Training is 86.0986328125\n",
            "Batch Id 1280 is having training loss of 0.48477864265441895\n",
            "0.763907790184021\n",
            "Epoch #3. Accuracy on batch 1280/3013  on Training is 86.09728727556596\n",
            "Epoch #3. Accuracy on batch 1281/3013  on Training is 86.10081903276131\n",
            "Epoch #3. Accuracy on batch 1282/3013  on Training is 86.10190958690569\n",
            "Epoch #3. Accuracy on batch 1283/3013  on Training is 86.1029984423676\n",
            "Epoch #3. Accuracy on batch 1284/3013  on Training is 86.09678988326849\n",
            "Epoch #3. Accuracy on batch 1285/3013  on Training is 86.10517107309487\n",
            "Epoch #3. Accuracy on batch 1286/3013  on Training is 86.10625485625485\n",
            "Epoch #3. Accuracy on batch 1287/3013  on Training is 86.1024844720497\n",
            "Epoch #3. Accuracy on batch 1288/3013  on Training is 86.11084173778123\n",
            "Epoch #3. Accuracy on batch 1289/3013  on Training is 86.10222868217055\n",
            "Epoch #3. Accuracy on batch 1290/3013  on Training is 86.10573199070488\n",
            "Epoch #3. Accuracy on batch 1291/3013  on Training is 86.10439241486068\n",
            "Epoch #3. Accuracy on batch 1292/3013  on Training is 86.10063805104409\n",
            "Epoch #3. Accuracy on batch 1293/3013  on Training is 86.10171947449768\n",
            "Epoch #3. Accuracy on batch 1294/3013  on Training is 86.10279922779922\n",
            "Epoch #3. Accuracy on batch 1295/3013  on Training is 86.10387731481481\n",
            "Epoch #3. Accuracy on batch 1296/3013  on Training is 86.09531611410948\n",
            "Epoch #3. Accuracy on batch 1297/3013  on Training is 86.10121340523882\n",
            "Epoch #3. Accuracy on batch 1298/3013  on Training is 86.10469591993841\n",
            "Epoch #3. Accuracy on batch 1299/3013  on Training is 86.10576923076923\n",
            "Batch Id 1300 is having training loss of 0.4842473268508911\n",
            "0.27567964792251587\n",
            "Epoch #3. Accuracy on batch 1300/3013  on Training is 86.11164488854727\n",
            "Epoch #3. Accuracy on batch 1301/3013  on Training is 86.1151113671275\n",
            "Epoch #3. Accuracy on batch 1302/3013  on Training is 86.11137759017652\n",
            "Epoch #3. Accuracy on batch 1303/3013  on Training is 86.11244248466258\n",
            "Epoch #3. Accuracy on batch 1304/3013  on Training is 86.11350574712644\n",
            "Epoch #3. Accuracy on batch 1305/3013  on Training is 86.10021056661562\n",
            "Epoch #3. Accuracy on batch 1306/3013  on Training is 86.09889058913542\n",
            "Epoch #3. Accuracy on batch 1307/3013  on Training is 86.09518348623853\n",
            "Epoch #3. Accuracy on batch 1308/3013  on Training is 86.09625668449198\n",
            "Epoch #3. Accuracy on batch 1309/3013  on Training is 86.0973282442748\n",
            "Epoch #3. Accuracy on batch 1310/3013  on Training is 86.10078184591914\n",
            "Epoch #3. Accuracy on batch 1311/3013  on Training is 86.09232088414635\n",
            "Epoch #3. Accuracy on batch 1312/3013  on Training is 86.09101294744859\n",
            "Epoch #3. Accuracy on batch 1313/3013  on Training is 86.0992199391172\n",
            "Epoch #3. Accuracy on batch 1314/3013  on Training is 86.10028517110266\n",
            "Epoch #3. Accuracy on batch 1315/3013  on Training is 86.08710106382979\n",
            "Epoch #3. Accuracy on batch 1316/3013  on Training is 86.08817388003037\n",
            "Epoch #3. Accuracy on batch 1317/3013  on Training is 86.08687405159333\n",
            "Epoch #3. Accuracy on batch 1318/3013  on Training is 86.08557619408643\n",
            "Epoch #3. Accuracy on batch 1319/3013  on Training is 86.07954545454545\n",
            "Batch Id 1320 is having training loss of 0.48516035079956055\n",
            "0.4722314476966858\n",
            "Epoch #3. Accuracy on batch 1320/3013  on Training is 86.07588947766844\n",
            "Epoch #3. Accuracy on batch 1321/3013  on Training is 86.08169440242058\n",
            "Epoch #3. Accuracy on batch 1322/3013  on Training is 86.07568027210884\n",
            "Epoch #3. Accuracy on batch 1323/3013  on Training is 86.08147658610272\n",
            "Epoch #3. Accuracy on batch 1324/3013  on Training is 86.0754716981132\n",
            "Epoch #3. Accuracy on batch 1325/3013  on Training is 86.07418929110105\n",
            "Epoch #3. Accuracy on batch 1326/3013  on Training is 86.07761868877166\n",
            "Epoch #3. Accuracy on batch 1327/3013  on Training is 86.07163027108433\n",
            "Epoch #3. Accuracy on batch 1328/3013  on Training is 86.0727050413845\n",
            "Epoch #3. Accuracy on batch 1329/3013  on Training is 86.06437969924812\n",
            "Epoch #3. Accuracy on batch 1330/3013  on Training is 86.06076258452292\n",
            "Epoch #3. Accuracy on batch 1331/3013  on Training is 86.059496996997\n",
            "Epoch #3. Accuracy on batch 1332/3013  on Training is 86.06526631657914\n",
            "Epoch #3. Accuracy on batch 1333/3013  on Training is 86.06165667166417\n",
            "Epoch #3. Accuracy on batch 1334/3013  on Training is 86.06741573033707\n",
            "Epoch #3. Accuracy on batch 1335/3013  on Training is 86.0684880239521\n",
            "Epoch #3. Accuracy on batch 1336/3013  on Training is 86.07189603590128\n",
            "Epoch #3. Accuracy on batch 1337/3013  on Training is 86.05894992526159\n",
            "Epoch #3. Accuracy on batch 1338/3013  on Training is 86.05535847647498\n",
            "Epoch #3. Accuracy on batch 1339/3013  on Training is 86.05643656716418\n",
            "Batch Id 1340 is having training loss of 0.4852050244808197\n",
            "0.5342555642127991\n",
            "Epoch #3. Accuracy on batch 1340/3013  on Training is 86.05285234899328\n",
            "Epoch #3. Accuracy on batch 1341/3013  on Training is 86.05160208643815\n",
            "Epoch #3. Accuracy on batch 1342/3013  on Training is 86.0503536857781\n",
            "Epoch #3. Accuracy on batch 1343/3013  on Training is 86.04910714285714\n",
            "Epoch #3. Accuracy on batch 1344/3013  on Training is 86.0478624535316\n",
            "Epoch #3. Accuracy on batch 1345/3013  on Training is 86.04429791976226\n",
            "Epoch #3. Accuracy on batch 1346/3013  on Training is 86.04073867854491\n",
            "Epoch #3. Accuracy on batch 1347/3013  on Training is 86.0487759643917\n",
            "Epoch #3. Accuracy on batch 1348/3013  on Training is 86.04985174203114\n",
            "Epoch #3. Accuracy on batch 1349/3013  on Training is 86.05092592592592\n",
            "Epoch #3. Accuracy on batch 1350/3013  on Training is 86.0519985196151\n",
            "Epoch #3. Accuracy on batch 1351/3013  on Training is 86.05075813609467\n",
            "Epoch #3. Accuracy on batch 1352/3013  on Training is 86.05644863266815\n",
            "Epoch #3. Accuracy on batch 1353/3013  on Training is 86.05520679468242\n",
            "Epoch #3. Accuracy on batch 1354/3013  on Training is 86.0539667896679\n",
            "Epoch #3. Accuracy on batch 1355/3013  on Training is 86.05272861356931\n",
            "Epoch #3. Accuracy on batch 1356/3013  on Training is 86.0445836403832\n",
            "Epoch #3. Accuracy on batch 1357/3013  on Training is 86.04335419734905\n",
            "Epoch #3. Accuracy on batch 1358/3013  on Training is 86.0467255334805\n",
            "Epoch #3. Accuracy on batch 1359/3013  on Training is 86.04319852941177\n",
            "Batch Id 1360 is having training loss of 0.48525670170783997\n",
            "0.5261818170547485\n",
            "Epoch #3. Accuracy on batch 1360/3013  on Training is 86.03967670830272\n",
            "Epoch #3. Accuracy on batch 1361/3013  on Training is 86.04533773861968\n",
            "Epoch #3. Accuracy on batch 1362/3013  on Training is 86.04411225238445\n",
            "Epoch #3. Accuracy on batch 1363/3013  on Training is 86.04976173020528\n",
            "Epoch #3. Accuracy on batch 1364/3013  on Training is 86.05082417582418\n",
            "Epoch #3. Accuracy on batch 1365/3013  on Training is 86.05417276720351\n",
            "Epoch #3. Accuracy on batch 1366/3013  on Training is 86.05294440380395\n",
            "Epoch #3. Accuracy on batch 1367/3013  on Training is 86.05400219298245\n",
            "Epoch #3. Accuracy on batch 1368/3013  on Training is 86.05962381300219\n",
            "Epoch #3. Accuracy on batch 1369/3013  on Training is 86.05839416058394\n",
            "Epoch #3. Accuracy on batch 1370/3013  on Training is 86.06172501823487\n",
            "Epoch #3. Accuracy on batch 1371/3013  on Training is 86.06732871720116\n",
            "Epoch #3. Accuracy on batch 1372/3013  on Training is 86.06837217771303\n",
            "Epoch #3. Accuracy on batch 1373/3013  on Training is 86.07396288209607\n",
            "Epoch #3. Accuracy on batch 1374/3013  on Training is 86.075\n",
            "Epoch #3. Accuracy on batch 1375/3013  on Training is 86.08057776162791\n",
            "Epoch #3. Accuracy on batch 1376/3013  on Training is 86.07933914306463\n",
            "Epoch #3. Accuracy on batch 1377/3013  on Training is 86.07356676342525\n",
            "Epoch #3. Accuracy on batch 1378/3013  on Training is 86.07460116026105\n",
            "Epoch #3. Accuracy on batch 1379/3013  on Training is 86.08242753623189\n",
            "Batch Id 1380 is having training loss of 0.4845421314239502\n",
            "0.6297736763954163\n",
            "Epoch #3. Accuracy on batch 1380/3013  on Training is 86.08119116582186\n",
            "Epoch #3. Accuracy on batch 1381/3013  on Training is 86.0776953690304\n",
            "Epoch #3. Accuracy on batch 1382/3013  on Training is 86.07646420824295\n",
            "Epoch #3. Accuracy on batch 1383/3013  on Training is 86.0752348265896\n",
            "Epoch #3. Accuracy on batch 1384/3013  on Training is 86.07175090252707\n",
            "Epoch #3. Accuracy on batch 1385/3013  on Training is 86.07503607503608\n",
            "Epoch #3. Accuracy on batch 1386/3013  on Training is 86.07381038211969\n",
            "Epoch #3. Accuracy on batch 1387/3013  on Training is 86.07258645533142\n",
            "Epoch #3. Accuracy on batch 1388/3013  on Training is 86.07361411087113\n",
            "Epoch #3. Accuracy on batch 1389/3013  on Training is 86.07014388489209\n",
            "Epoch #3. Accuracy on batch 1390/3013  on Training is 86.06892523364486\n",
            "Epoch #3. Accuracy on batch 1391/3013  on Training is 86.0699533045977\n",
            "Epoch #3. Accuracy on batch 1392/3013  on Training is 86.07097989949749\n",
            "Epoch #3. Accuracy on batch 1393/3013  on Training is 86.07200502152081\n",
            "Epoch #3. Accuracy on batch 1394/3013  on Training is 86.0752688172043\n",
            "Epoch #3. Accuracy on batch 1395/3013  on Training is 86.0807664756447\n",
            "Epoch #3. Accuracy on batch 1396/3013  on Training is 86.08401932712957\n",
            "Epoch #3. Accuracy on batch 1397/3013  on Training is 86.08279685264664\n",
            "Epoch #3. Accuracy on batch 1398/3013  on Training is 86.08380986418871\n",
            "Epoch #3. Accuracy on batch 1399/3013  on Training is 86.08705357142857\n",
            "Batch Id 1400 is having training loss of 0.48464664816856384\n",
            "0.4875875413417816\n",
            "Epoch #3. Accuracy on batch 1400/3013  on Training is 86.09029264810849\n",
            "Epoch #3. Accuracy on batch 1401/3013  on Training is 86.08906918687589\n",
            "Epoch #3. Accuracy on batch 1402/3013  on Training is 86.08784746970777\n",
            "Epoch #3. Accuracy on batch 1403/3013  on Training is 86.0866274928775\n",
            "Epoch #3. Accuracy on batch 1404/3013  on Training is 86.08096085409252\n",
            "Epoch #3. Accuracy on batch 1405/3013  on Training is 86.08419274537695\n",
            "Epoch #3. Accuracy on batch 1406/3013  on Training is 86.09186211798152\n",
            "Epoch #3. Accuracy on batch 1407/3013  on Training is 86.09508167613636\n",
            "Epoch #3. Accuracy on batch 1408/3013  on Training is 86.09386089425124\n",
            "Epoch #3. Accuracy on batch 1409/3013  on Training is 86.09264184397163\n",
            "Epoch #3. Accuracy on batch 1410/3013  on Training is 86.09142452161588\n",
            "Epoch #3. Accuracy on batch 1411/3013  on Training is 86.09020892351275\n",
            "Epoch #3. Accuracy on batch 1412/3013  on Training is 86.09341825902335\n",
            "Epoch #3. Accuracy on batch 1413/3013  on Training is 86.09220297029702\n",
            "Epoch #3. Accuracy on batch 1414/3013  on Training is 86.09319787985866\n",
            "Epoch #3. Accuracy on batch 1415/3013  on Training is 86.08757062146893\n",
            "Epoch #3. Accuracy on batch 1416/3013  on Training is 86.09297812279463\n",
            "Epoch #3. Accuracy on batch 1417/3013  on Training is 86.09837799717913\n",
            "Epoch #3. Accuracy on batch 1418/3013  on Training is 86.10156800563777\n",
            "Epoch #3. Accuracy on batch 1419/3013  on Training is 86.10255281690141\n",
            "Batch Id 1420 is having training loss of 0.4844864308834076\n",
            "0.43021243810653687\n",
            "Epoch #3. Accuracy on batch 1420/3013  on Training is 86.10353624208304\n",
            "Epoch #3. Accuracy on batch 1421/3013  on Training is 86.10232067510549\n",
            "Epoch #3. Accuracy on batch 1422/3013  on Training is 86.10549894588897\n",
            "Epoch #3. Accuracy on batch 1423/3013  on Training is 86.10647823033707\n",
            "Epoch #3. Accuracy on batch 1424/3013  on Training is 86.09649122807018\n",
            "Epoch #3. Accuracy on batch 1425/3013  on Training is 86.09747545582047\n",
            "Epoch #3. Accuracy on batch 1426/3013  on Training is 86.10502803083392\n",
            "Epoch #3. Accuracy on batch 1427/3013  on Training is 86.10819327731092\n",
            "Epoch #3. Accuracy on batch 1428/3013  on Training is 86.10698040587823\n",
            "Epoch #3. Accuracy on batch 1429/3013  on Training is 86.10358391608392\n",
            "Epoch #3. Accuracy on batch 1430/3013  on Training is 86.10455974842768\n",
            "Epoch #3. Accuracy on batch 1431/3013  on Training is 86.10335195530726\n",
            "Epoch #3. Accuracy on batch 1432/3013  on Training is 86.10868806699233\n",
            "Epoch #3. Accuracy on batch 1433/3013  on Training is 86.10094142259415\n",
            "Epoch #3. Accuracy on batch 1434/3013  on Training is 86.10191637630662\n",
            "Epoch #3. Accuracy on batch 1435/3013  on Training is 86.10506615598885\n",
            "Epoch #3. Accuracy on batch 1436/3013  on Training is 86.10168754349338\n",
            "Epoch #3. Accuracy on batch 1437/3013  on Training is 86.10265994436718\n",
            "Epoch #3. Accuracy on batch 1438/3013  on Training is 86.10145934676859\n",
            "Epoch #3. Accuracy on batch 1439/3013  on Training is 86.10243055555556\n",
            "Batch Id 1440 is having training loss of 0.4846639633178711\n",
            "0.2877994775772095\n",
            "Epoch #3. Accuracy on batch 1440/3013  on Training is 86.10340041637751\n",
            "Epoch #3. Accuracy on batch 1441/3013  on Training is 86.10220180305132\n",
            "Epoch #3. Accuracy on batch 1442/3013  on Training is 86.10100485100484\n",
            "Epoch #3. Accuracy on batch 1443/3013  on Training is 86.10197368421052\n",
            "Epoch #3. Accuracy on batch 1444/3013  on Training is 86.09645328719724\n",
            "Epoch #3. Accuracy on batch 1445/3013  on Training is 86.09958506224066\n",
            "Epoch #3. Accuracy on batch 1446/3013  on Training is 86.10271250863856\n",
            "Epoch #3. Accuracy on batch 1447/3013  on Training is 86.10367748618785\n",
            "Epoch #3. Accuracy on batch 1448/3013  on Training is 86.10032781228433\n",
            "Epoch #3. Accuracy on batch 1449/3013  on Training is 86.09913793103448\n",
            "Epoch #3. Accuracy on batch 1450/3013  on Training is 86.08933494141971\n",
            "Epoch #3. Accuracy on batch 1451/3013  on Training is 86.0816976584022\n",
            "Epoch #3. Accuracy on batch 1452/3013  on Training is 86.07407088781831\n",
            "Epoch #3. Accuracy on batch 1453/3013  on Training is 86.07720082530949\n",
            "Epoch #3. Accuracy on batch 1454/3013  on Training is 86.07603092783505\n",
            "Epoch #3. Accuracy on batch 1455/3013  on Training is 86.07271634615384\n",
            "Epoch #3. Accuracy on batch 1456/3013  on Training is 86.07798558682224\n",
            "Epoch #3. Accuracy on batch 1457/3013  on Training is 86.07681755829904\n",
            "Epoch #3. Accuracy on batch 1458/3013  on Training is 86.0777930089102\n",
            "Epoch #3. Accuracy on batch 1459/3013  on Training is 86.08090753424658\n",
            "Batch Id 1460 is having training loss of 0.4846166968345642\n",
            "0.303846538066864\n",
            "Epoch #3. Accuracy on batch 1460/3013  on Training is 86.08187885010267\n",
            "Epoch #3. Accuracy on batch 1461/3013  on Training is 86.08071135430916\n",
            "Epoch #3. Accuracy on batch 1462/3013  on Training is 86.0774094326726\n",
            "Epoch #3. Accuracy on batch 1463/3013  on Training is 86.08051571038251\n",
            "Epoch #3. Accuracy on batch 1464/3013  on Training is 86.07508532423208\n",
            "Epoch #3. Accuracy on batch 1465/3013  on Training is 86.07605729877217\n",
            "Epoch #3. Accuracy on batch 1466/3013  on Training is 86.0727675528289\n",
            "Epoch #3. Accuracy on batch 1467/3013  on Training is 86.07161103542235\n",
            "Epoch #3. Accuracy on batch 1468/3013  on Training is 86.07045609257999\n",
            "Epoch #3. Accuracy on batch 1469/3013  on Training is 86.0671768707483\n",
            "Epoch #3. Accuracy on batch 1470/3013  on Training is 86.06602651257649\n",
            "Epoch #3. Accuracy on batch 1471/3013  on Training is 86.07124660326087\n",
            "Epoch #3. Accuracy on batch 1472/3013  on Training is 86.07433808553971\n",
            "Epoch #3. Accuracy on batch 1473/3013  on Training is 86.0668249660787\n",
            "Epoch #3. Accuracy on batch 1474/3013  on Training is 86.0677966101695\n",
            "Epoch #3. Accuracy on batch 1475/3013  on Training is 86.07088414634147\n",
            "Epoch #3. Accuracy on batch 1476/3013  on Training is 86.06973595125254\n",
            "Epoch #3. Accuracy on batch 1477/3013  on Training is 86.06858930987822\n",
            "Epoch #3. Accuracy on batch 1478/3013  on Training is 86.0695571331981\n",
            "Epoch #3. Accuracy on batch 1479/3013  on Training is 86.06630067567568\n",
            "Batch Id 1480 is having training loss of 0.4855082929134369\n",
            "0.7875848412513733\n",
            "Epoch #3. Accuracy on batch 1480/3013  on Training is 86.06515867656988\n",
            "Epoch #3. Accuracy on batch 1481/3013  on Training is 86.07245276653171\n",
            "Epoch #3. Accuracy on batch 1482/3013  on Training is 86.07552258934592\n",
            "Epoch #3. Accuracy on batch 1483/3013  on Training is 86.07227088948787\n",
            "Epoch #3. Accuracy on batch 1484/3013  on Training is 86.07323232323232\n",
            "Epoch #3. Accuracy on batch 1485/3013  on Training is 86.07629542395694\n",
            "Epoch #3. Accuracy on batch 1486/3013  on Training is 86.07304976462676\n",
            "Epoch #3. Accuracy on batch 1487/3013  on Training is 86.06560819892474\n",
            "Epoch #3. Accuracy on batch 1488/3013  on Training is 86.07496642041639\n",
            "Epoch #3. Accuracy on batch 1489/3013  on Training is 86.0738255033557\n",
            "Epoch #3. Accuracy on batch 1490/3013  on Training is 86.0726861167002\n",
            "Epoch #3. Accuracy on batch 1491/3013  on Training is 86.07154825737265\n",
            "Epoch #3. Accuracy on batch 1492/3013  on Training is 86.07459812458139\n",
            "Epoch #3. Accuracy on batch 1493/3013  on Training is 86.07764390896921\n",
            "Epoch #3. Accuracy on batch 1494/3013  on Training is 86.08277591973244\n",
            "Epoch #3. Accuracy on batch 1495/3013  on Training is 86.08790106951872\n",
            "Epoch #3. Accuracy on batch 1496/3013  on Training is 86.09510688042752\n",
            "Epoch #3. Accuracy on batch 1497/3013  on Training is 86.0877002670227\n",
            "Epoch #3. Accuracy on batch 1498/3013  on Training is 86.09281187458305\n",
            "Epoch #3. Accuracy on batch 1499/3013  on Training is 86.08333333333333\n",
            "Batch Id 1500 is having training loss of 0.4852291941642761\n",
            "0.8968890905380249\n",
            "Epoch #3. Accuracy on batch 1500/3013  on Training is 86.07803131245836\n",
            "Epoch #3. Accuracy on batch 1501/3013  on Training is 86.07481691078561\n",
            "Epoch #3. Accuracy on batch 1502/3013  on Training is 86.06744843646041\n",
            "Epoch #3. Accuracy on batch 1503/3013  on Training is 86.06216755319149\n",
            "Epoch #3. Accuracy on batch 1504/3013  on Training is 86.06519933554817\n",
            "Epoch #3. Accuracy on batch 1505/3013  on Training is 86.06615205843293\n",
            "Epoch #3. Accuracy on batch 1506/3013  on Training is 86.05880889183808\n",
            "Epoch #3. Accuracy on batch 1507/3013  on Training is 86.04733090185677\n",
            "Epoch #3. Accuracy on batch 1508/3013  on Training is 86.04829357190192\n",
            "Epoch #3. Accuracy on batch 1509/3013  on Training is 86.05132450331126\n",
            "Epoch #3. Accuracy on batch 1510/3013  on Training is 86.05228325612177\n",
            "Epoch #3. Accuracy on batch 1511/3013  on Training is 86.05117394179894\n",
            "Epoch #3. Accuracy on batch 1512/3013  on Training is 86.05419695968276\n",
            "Epoch #3. Accuracy on batch 1513/3013  on Training is 86.05928005284017\n",
            "Epoch #3. Accuracy on batch 1514/3013  on Training is 86.06435643564356\n",
            "Epoch #3. Accuracy on batch 1515/3013  on Training is 86.0673647757256\n",
            "Epoch #3. Accuracy on batch 1516/3013  on Training is 86.06006921555702\n",
            "Epoch #3. Accuracy on batch 1517/3013  on Training is 86.06513504611331\n",
            "Epoch #3. Accuracy on batch 1518/3013  on Training is 86.05990783410138\n",
            "Epoch #3. Accuracy on batch 1519/3013  on Training is 86.06496710526316\n",
            "Batch Id 1520 is having training loss of 0.4850885570049286\n",
            "0.40956345200538635\n",
            "Epoch #3. Accuracy on batch 1520/3013  on Training is 86.06591058514135\n",
            "Epoch #3. Accuracy on batch 1521/3013  on Training is 86.06685282522996\n",
            "Epoch #3. Accuracy on batch 1522/3013  on Training is 86.06574195666448\n",
            "Epoch #3. Accuracy on batch 1523/3013  on Training is 86.06873359580052\n",
            "Epoch #3. Accuracy on batch 1524/3013  on Training is 86.07172131147541\n",
            "Epoch #3. Accuracy on batch 1525/3013  on Training is 86.07060943643512\n",
            "Epoch #3. Accuracy on batch 1526/3013  on Training is 86.06949901768174\n",
            "Epoch #3. Accuracy on batch 1527/3013  on Training is 86.0642997382199\n",
            "Epoch #3. Accuracy on batch 1528/3013  on Training is 86.06523871811642\n",
            "Epoch #3. Accuracy on batch 1529/3013  on Training is 86.0641339869281\n",
            "Epoch #3. Accuracy on batch 1530/3013  on Training is 86.05894839973874\n",
            "Epoch #3. Accuracy on batch 1531/3013  on Training is 86.06396866840731\n",
            "Epoch #3. Accuracy on batch 1532/3013  on Training is 86.07102087410307\n",
            "Epoch #3. Accuracy on batch 1533/3013  on Training is 86.06787809647979\n",
            "Epoch #3. Accuracy on batch 1534/3013  on Training is 86.06270358306189\n",
            "Epoch #3. Accuracy on batch 1535/3013  on Training is 86.0595703125\n",
            "Epoch #3. Accuracy on batch 1536/3013  on Training is 86.05847430058556\n",
            "Epoch #3. Accuracy on batch 1537/3013  on Training is 86.05534785435631\n",
            "Epoch #3. Accuracy on batch 1538/3013  on Training is 86.05628654970761\n",
            "Epoch #3. Accuracy on batch 1539/3013  on Training is 86.05113636363636\n",
            "Batch Id 1540 is having training loss of 0.4855164885520935\n",
            "0.7032955884933472\n",
            "Epoch #3. Accuracy on batch 1540/3013  on Training is 86.050048669695\n",
            "Epoch #3. Accuracy on batch 1541/3013  on Training is 86.05098897535667\n",
            "Epoch #3. Accuracy on batch 1542/3013  on Training is 86.04382696046662\n",
            "Epoch #3. Accuracy on batch 1543/3013  on Training is 86.04679404145078\n",
            "Epoch #3. Accuracy on batch 1544/3013  on Training is 86.04773462783172\n",
            "Epoch #3. Accuracy on batch 1545/3013  on Training is 86.05069534282018\n",
            "Epoch #3. Accuracy on batch 1546/3013  on Training is 86.05365223012282\n",
            "Epoch #3. Accuracy on batch 1547/3013  on Training is 86.0545865633075\n",
            "Epoch #3. Accuracy on batch 1548/3013  on Training is 86.06157198192382\n",
            "Epoch #3. Accuracy on batch 1549/3013  on Training is 86.0625\n",
            "Epoch #3. Accuracy on batch 1550/3013  on Training is 86.06141199226306\n",
            "Epoch #3. Accuracy on batch 1551/3013  on Training is 86.06032538659794\n",
            "Epoch #3. Accuracy on batch 1552/3013  on Training is 86.06728911783645\n",
            "Epoch #3. Accuracy on batch 1553/3013  on Training is 86.06620012870013\n",
            "Epoch #3. Accuracy on batch 1554/3013  on Training is 86.06913183279742\n",
            "Epoch #3. Accuracy on batch 1555/3013  on Training is 86.06804305912597\n",
            "Epoch #3. Accuracy on batch 1556/3013  on Training is 86.06494861913937\n",
            "Epoch #3. Accuracy on batch 1557/3013  on Training is 86.06386392811297\n",
            "Epoch #3. Accuracy on batch 1558/3013  on Training is 86.06077613855035\n",
            "Epoch #3. Accuracy on batch 1559/3013  on Training is 86.0556891025641\n",
            "Batch Id 1560 is having training loss of 0.48491358757019043\n",
            "0.3784783184528351\n",
            "Epoch #3. Accuracy on batch 1560/3013  on Training is 86.05461242793082\n",
            "Epoch #3. Accuracy on batch 1561/3013  on Training is 86.05153649167734\n",
            "Epoch #3. Accuracy on batch 1562/3013  on Training is 86.05246321177223\n",
            "Epoch #3. Accuracy on batch 1563/3013  on Training is 86.05338874680307\n",
            "Epoch #3. Accuracy on batch 1564/3013  on Training is 86.05630990415335\n",
            "Epoch #3. Accuracy on batch 1565/3013  on Training is 86.04924968071519\n",
            "Epoch #3. Accuracy on batch 1566/3013  on Training is 86.05017549457563\n",
            "Epoch #3. Accuracy on batch 1567/3013  on Training is 86.05508609693878\n",
            "Epoch #3. Accuracy on batch 1568/3013  on Training is 86.05999043977056\n",
            "Epoch #3. Accuracy on batch 1569/3013  on Training is 86.05294585987261\n",
            "Epoch #3. Accuracy on batch 1570/3013  on Training is 86.04591024824953\n",
            "Epoch #3. Accuracy on batch 1571/3013  on Training is 86.04484732824427\n",
            "Epoch #3. Accuracy on batch 1572/3013  on Training is 86.04577240940877\n",
            "Epoch #3. Accuracy on batch 1573/3013  on Training is 86.04471092757306\n",
            "Epoch #3. Accuracy on batch 1574/3013  on Training is 86.04563492063492\n",
            "Epoch #3. Accuracy on batch 1575/3013  on Training is 86.04259200507614\n",
            "Epoch #3. Accuracy on batch 1576/3013  on Training is 86.03955294863665\n",
            "Epoch #3. Accuracy on batch 1577/3013  on Training is 86.0444391634981\n",
            "Epoch #3. Accuracy on batch 1578/3013  on Training is 86.04931918936036\n",
            "Epoch #3. Accuracy on batch 1579/3013  on Training is 86.04825949367088\n",
            "Batch Id 1580 is having training loss of 0.48511219024658203\n",
            "0.6047501564025879\n",
            "Epoch #3. Accuracy on batch 1580/3013  on Training is 86.04324794433903\n",
            "Epoch #3. Accuracy on batch 1581/3013  on Training is 86.0402180783818\n",
            "Epoch #3. Accuracy on batch 1582/3013  on Training is 86.04114024005054\n",
            "Epoch #3. Accuracy on batch 1583/3013  on Training is 86.03614267676768\n",
            "Epoch #3. Accuracy on batch 1584/3013  on Training is 86.03706624605678\n",
            "Epoch #3. Accuracy on batch 1585/3013  on Training is 86.03995901639344\n",
            "Epoch #3. Accuracy on batch 1586/3013  on Training is 86.03103339634531\n",
            "Epoch #3. Accuracy on batch 1587/3013  on Training is 86.03392632241814\n",
            "Epoch #3. Accuracy on batch 1588/3013  on Training is 86.03878225298931\n",
            "Epoch #3. Accuracy on batch 1589/3013  on Training is 86.04166666666667\n",
            "Epoch #3. Accuracy on batch 1590/3013  on Training is 86.04454745443118\n",
            "Epoch #3. Accuracy on batch 1591/3013  on Training is 86.04938756281408\n",
            "Epoch #3. Accuracy on batch 1592/3013  on Training is 86.05029817953547\n",
            "Epoch #3. Accuracy on batch 1593/3013  on Training is 86.0551286072773\n",
            "Epoch #3. Accuracy on batch 1594/3013  on Training is 86.05995297805643\n",
            "Epoch #3. Accuracy on batch 1595/3013  on Training is 86.05889724310777\n",
            "Epoch #3. Accuracy on batch 1596/3013  on Training is 86.0558860363181\n",
            "Epoch #3. Accuracy on batch 1597/3013  on Training is 86.05483416770964\n",
            "Epoch #3. Accuracy on batch 1598/3013  on Training is 86.0576923076923\n",
            "Epoch #3. Accuracy on batch 1599/3013  on Training is 86.064453125\n",
            "Batch Id 1600 is having training loss of 0.4842924475669861\n",
            "0.4409531056880951\n",
            "Epoch #3. Accuracy on batch 1600/3013  on Training is 86.0633978763273\n",
            "Epoch #3. Accuracy on batch 1601/3013  on Training is 86.05454119850187\n",
            "Epoch #3. Accuracy on batch 1602/3013  on Training is 86.04764504054897\n",
            "Epoch #3. Accuracy on batch 1603/3013  on Training is 86.04855049875312\n",
            "Epoch #3. Accuracy on batch 1604/3013  on Training is 86.047507788162\n",
            "Epoch #3. Accuracy on batch 1605/3013  on Training is 86.05230386052304\n",
            "Epoch #3. Accuracy on batch 1606/3013  on Training is 86.0570939639079\n",
            "Epoch #3. Accuracy on batch 1607/3013  on Training is 86.05410447761194\n",
            "Epoch #3. Accuracy on batch 1608/3013  on Training is 86.0530609073959\n",
            "Epoch #3. Accuracy on batch 1609/3013  on Training is 86.0461956521739\n",
            "Epoch #3. Accuracy on batch 1610/3013  on Training is 86.04709807572937\n",
            "Epoch #3. Accuracy on batch 1611/3013  on Training is 86.04799937965261\n",
            "Epoch #3. Accuracy on batch 1612/3013  on Training is 86.05083694978302\n",
            "Epoch #3. Accuracy on batch 1613/3013  on Training is 86.04205390334573\n",
            "Epoch #3. Accuracy on batch 1614/3013  on Training is 86.04295665634675\n",
            "Epoch #3. Accuracy on batch 1615/3013  on Training is 86.04772586633663\n",
            "Epoch #3. Accuracy on batch 1616/3013  on Training is 86.05055658627087\n",
            "Epoch #3. Accuracy on batch 1617/3013  on Training is 86.0553152039555\n",
            "Epoch #3. Accuracy on batch 1618/3013  on Training is 86.05427733168622\n",
            "Epoch #3. Accuracy on batch 1619/3013  on Training is 86.05902777777777\n",
            "Batch Id 1620 is having training loss of 0.4849500358104706\n",
            "0.4651299715042114\n",
            "Epoch #3. Accuracy on batch 1620/3013  on Training is 86.05991671807526\n",
            "Epoch #3. Accuracy on batch 1621/3013  on Training is 86.06658446362515\n",
            "Epoch #3. Accuracy on batch 1622/3013  on Training is 86.0636167590881\n",
            "Epoch #3. Accuracy on batch 1623/3013  on Training is 86.06834975369458\n",
            "Epoch #3. Accuracy on batch 1624/3013  on Training is 86.07307692307693\n",
            "Epoch #3. Accuracy on batch 1625/3013  on Training is 86.07011070110701\n",
            "Epoch #3. Accuracy on batch 1626/3013  on Training is 86.06714812538414\n",
            "Epoch #3. Accuracy on batch 1627/3013  on Training is 86.0641891891892\n",
            "Epoch #3. Accuracy on batch 1628/3013  on Training is 86.06315224063843\n",
            "Epoch #3. Accuracy on batch 1629/3013  on Training is 86.06403374233129\n",
            "Epoch #3. Accuracy on batch 1630/3013  on Training is 86.06299816063765\n",
            "Epoch #3. Accuracy on batch 1631/3013  on Training is 86.05813419117646\n",
            "Epoch #3. Accuracy on batch 1632/3013  on Training is 86.05710349050827\n",
            "Epoch #3. Accuracy on batch 1633/3013  on Training is 86.05989902080783\n",
            "Epoch #3. Accuracy on batch 1634/3013  on Training is 86.06077981651376\n",
            "Epoch #3. Accuracy on batch 1635/3013  on Training is 86.0635696821516\n",
            "Epoch #3. Accuracy on batch 1636/3013  on Training is 86.06826511912034\n",
            "Epoch #3. Accuracy on batch 1637/3013  on Training is 86.07295482295483\n",
            "Epoch #3. Accuracy on batch 1638/3013  on Training is 86.07191885295912\n",
            "Epoch #3. Accuracy on batch 1639/3013  on Training is 86.06897865853658\n",
            "Batch Id 1640 is having training loss of 0.48441335558891296\n",
            "0.4200427234172821\n",
            "Epoch #3. Accuracy on batch 1640/3013  on Training is 86.066042047532\n",
            "Epoch #3. Accuracy on batch 1641/3013  on Training is 86.06691534713764\n",
            "Epoch #3. Accuracy on batch 1642/3013  on Training is 86.07159160073037\n",
            "Epoch #3. Accuracy on batch 1643/3013  on Training is 86.07626216545012\n",
            "Epoch #3. Accuracy on batch 1644/3013  on Training is 86.0790273556231\n",
            "Epoch #3. Accuracy on batch 1645/3013  on Training is 86.08368772782504\n",
            "Epoch #3. Accuracy on batch 1646/3013  on Training is 86.08454766241651\n",
            "Epoch #3. Accuracy on batch 1647/3013  on Training is 86.08919902912622\n",
            "Epoch #3. Accuracy on batch 1648/3013  on Training is 86.09194966646453\n",
            "Epoch #3. Accuracy on batch 1649/3013  on Training is 86.09469696969697\n",
            "Epoch #3. Accuracy on batch 1650/3013  on Training is 86.09933373712902\n",
            "Epoch #3. Accuracy on batch 1651/3013  on Training is 86.09828995157385\n",
            "Epoch #3. Accuracy on batch 1652/3013  on Training is 86.09913793103448\n",
            "Epoch #3. Accuracy on batch 1653/3013  on Training is 86.09998488512697\n",
            "Epoch #3. Accuracy on batch 1654/3013  on Training is 86.10083081570997\n",
            "Epoch #3. Accuracy on batch 1655/3013  on Training is 86.09978864734299\n",
            "Epoch #3. Accuracy on batch 1656/3013  on Training is 86.09120398310199\n",
            "Epoch #3. Accuracy on batch 1657/3013  on Training is 86.09582328106151\n",
            "Epoch #3. Accuracy on batch 1658/3013  on Training is 86.09478601567209\n",
            "Epoch #3. Accuracy on batch 1659/3013  on Training is 86.08621987951807\n",
            "Batch Id 1660 is having training loss of 0.48429664969444275\n",
            "0.8294177651405334\n",
            "Epoch #3. Accuracy on batch 1660/3013  on Training is 86.07954545454545\n",
            "Epoch #3. Accuracy on batch 1661/3013  on Training is 86.08228038507822\n",
            "Epoch #3. Accuracy on batch 1662/3013  on Training is 86.07561635598316\n",
            "Epoch #3. Accuracy on batch 1663/3013  on Training is 86.07271634615384\n",
            "Epoch #3. Accuracy on batch 1664/3013  on Training is 86.07169669669669\n",
            "Epoch #3. Accuracy on batch 1665/3013  on Training is 86.07067827130852\n",
            "Epoch #3. Accuracy on batch 1666/3013  on Training is 86.06966106778644\n",
            "Epoch #3. Accuracy on batch 1667/3013  on Training is 86.05927757793765\n",
            "Epoch #3. Accuracy on batch 1668/3013  on Training is 86.06201318154584\n",
            "Epoch #3. Accuracy on batch 1669/3013  on Training is 86.06100299401197\n",
            "Epoch #3. Accuracy on batch 1670/3013  on Training is 86.05999401555954\n",
            "Epoch #3. Accuracy on batch 1671/3013  on Training is 86.06459330143541\n",
            "Epoch #3. Accuracy on batch 1672/3013  on Training is 86.06545128511655\n",
            "Epoch #3. Accuracy on batch 1673/3013  on Training is 86.06444145758663\n",
            "Epoch #3. Accuracy on batch 1674/3013  on Training is 86.05783582089552\n",
            "Epoch #3. Accuracy on batch 1675/3013  on Training is 86.05310262529832\n",
            "Epoch #3. Accuracy on batch 1676/3013  on Training is 86.05210196779964\n",
            "Epoch #3. Accuracy on batch 1677/3013  on Training is 86.05296483909416\n",
            "Epoch #3. Accuracy on batch 1678/3013  on Training is 86.05382668254914\n",
            "Epoch #3. Accuracy on batch 1679/3013  on Training is 86.05840773809524\n",
            "Batch Id 1680 is having training loss of 0.4845317006111145\n",
            "0.3891969323158264\n",
            "Epoch #3. Accuracy on batch 1680/3013  on Training is 86.0611243307555\n",
            "Epoch #3. Accuracy on batch 1681/3013  on Training is 86.06012187871582\n",
            "Epoch #3. Accuracy on batch 1682/3013  on Training is 86.06097742127155\n",
            "Epoch #3. Accuracy on batch 1683/3013  on Training is 86.06183194774347\n",
            "Epoch #3. Accuracy on batch 1684/3013  on Training is 86.05712166172107\n",
            "Epoch #3. Accuracy on batch 1685/3013  on Training is 86.06539145907473\n",
            "Epoch #3. Accuracy on batch 1686/3013  on Training is 86.06438944872555\n",
            "Epoch #3. Accuracy on batch 1687/3013  on Training is 86.06153732227489\n",
            "Epoch #3. Accuracy on batch 1688/3013  on Training is 86.05683836589698\n",
            "Epoch #3. Accuracy on batch 1689/3013  on Training is 86.05954142011835\n",
            "Epoch #3. Accuracy on batch 1690/3013  on Training is 86.06039325842697\n",
            "Epoch #3. Accuracy on batch 1691/3013  on Training is 86.05939716312056\n",
            "Epoch #3. Accuracy on batch 1692/3013  on Training is 86.06393975191968\n",
            "Epoch #3. Accuracy on batch 1693/3013  on Training is 86.06478748524204\n",
            "Epoch #3. Accuracy on batch 1694/3013  on Training is 86.05825958702064\n",
            "Epoch #3. Accuracy on batch 1695/3013  on Training is 86.05910966981132\n",
            "Epoch #3. Accuracy on batch 1696/3013  on Training is 86.05811726576312\n",
            "Epoch #3. Accuracy on batch 1697/3013  on Training is 86.05896643109541\n",
            "Epoch #3. Accuracy on batch 1698/3013  on Training is 86.05429664508534\n",
            "Epoch #3. Accuracy on batch 1699/3013  on Training is 86.0533088235294\n",
            "Batch Id 1700 is having training loss of 0.48476892709732056\n",
            "0.5910131931304932\n",
            "Epoch #3. Accuracy on batch 1700/3013  on Training is 86.05048500881834\n",
            "Epoch #3. Accuracy on batch 1701/3013  on Training is 86.0513366627497\n",
            "Epoch #3. Accuracy on batch 1702/3013  on Training is 86.04851732237229\n",
            "Epoch #3. Accuracy on batch 1703/3013  on Training is 86.0475352112676\n",
            "Epoch #3. Accuracy on batch 1704/3013  on Training is 86.04655425219941\n",
            "Epoch #3. Accuracy on batch 1705/3013  on Training is 86.04374267291911\n",
            "Epoch #3. Accuracy on batch 1706/3013  on Training is 86.04276508494435\n",
            "Epoch #3. Accuracy on batch 1707/3013  on Training is 86.03995901639344\n",
            "Epoch #3. Accuracy on batch 1708/3013  on Training is 86.03349912229373\n",
            "Epoch #3. Accuracy on batch 1709/3013  on Training is 86.02887426900585\n",
            "Epoch #3. Accuracy on batch 1710/3013  on Training is 86.03156049094098\n",
            "Epoch #3. Accuracy on batch 1711/3013  on Training is 86.02329147196262\n",
            "Epoch #3. Accuracy on batch 1712/3013  on Training is 86.02597781669586\n",
            "Epoch #3. Accuracy on batch 1713/3013  on Training is 86.0250145857643\n",
            "Epoch #3. Accuracy on batch 1714/3013  on Training is 86.02405247813411\n",
            "Epoch #3. Accuracy on batch 1715/3013  on Training is 86.02673368298369\n",
            "Epoch #3. Accuracy on batch 1716/3013  on Training is 86.02577169481654\n",
            "Epoch #3. Accuracy on batch 1717/3013  on Training is 86.03208672875436\n",
            "Epoch #3. Accuracy on batch 1718/3013  on Training is 86.02566899360093\n",
            "Epoch #3. Accuracy on batch 1719/3013  on Training is 86.03015988372093\n",
            "Batch Id 1720 is having training loss of 0.48553964495658875\n",
            "0.20901228487491608\n",
            "Epoch #3. Accuracy on batch 1720/3013  on Training is 86.03827716443928\n",
            "Epoch #3. Accuracy on batch 1721/3013  on Training is 86.03912601626017\n",
            "Epoch #3. Accuracy on batch 1722/3013  on Training is 86.04360127684272\n",
            "Epoch #3. Accuracy on batch 1723/3013  on Training is 86.03900812064965\n",
            "Epoch #3. Accuracy on batch 1724/3013  on Training is 86.03985507246377\n",
            "Epoch #3. Accuracy on batch 1725/3013  on Training is 86.02983777520278\n",
            "Epoch #3. Accuracy on batch 1726/3013  on Training is 86.02887955993052\n",
            "Epoch #3. Accuracy on batch 1727/3013  on Training is 86.02611400462963\n",
            "Epoch #3. Accuracy on batch 1728/3013  on Training is 86.02515905147484\n",
            "Epoch #3. Accuracy on batch 1729/3013  on Training is 86.02059248554913\n",
            "Epoch #3. Accuracy on batch 1730/3013  on Training is 86.02325245522819\n",
            "Epoch #3. Accuracy on batch 1731/3013  on Training is 86.0241050808314\n",
            "Epoch #3. Accuracy on batch 1732/3013  on Training is 86.02495672244662\n",
            "Epoch #3. Accuracy on batch 1733/3013  on Training is 86.02400519031141\n",
            "Epoch #3. Accuracy on batch 1734/3013  on Training is 86.02485590778097\n",
            "Epoch #3. Accuracy on batch 1735/3013  on Training is 86.02210541474655\n",
            "Epoch #3. Accuracy on batch 1736/3013  on Training is 86.02655440414507\n",
            "Epoch #3. Accuracy on batch 1737/3013  on Training is 86.02380609896433\n",
            "Epoch #3. Accuracy on batch 1738/3013  on Training is 86.03004600345025\n",
            "Epoch #3. Accuracy on batch 1739/3013  on Training is 86.02550287356321\n",
            "Batch Id 1740 is having training loss of 0.4863736033439636\n",
            "0.5641401410102844\n",
            "Epoch #3. Accuracy on batch 1740/3013  on Training is 86.02634979896611\n",
            "Epoch #3. Accuracy on batch 1741/3013  on Training is 86.02181400688863\n",
            "Epoch #3. Accuracy on batch 1742/3013  on Training is 86.02086919104991\n",
            "Epoch #3. Accuracy on batch 1743/3013  on Training is 86.01813360091744\n",
            "Epoch #3. Accuracy on batch 1744/3013  on Training is 86.01719197707736\n",
            "Epoch #3. Accuracy on batch 1745/3013  on Training is 86.00730240549828\n",
            "Epoch #3. Accuracy on batch 1746/3013  on Training is 86.01173440183172\n",
            "Epoch #3. Accuracy on batch 1747/3013  on Training is 86.01258581235697\n",
            "Epoch #3. Accuracy on batch 1748/3013  on Training is 86.0134362492853\n",
            "Epoch #3. Accuracy on batch 1749/3013  on Training is 86.00714285714285\n",
            "Epoch #3. Accuracy on batch 1750/3013  on Training is 86.0097801256425\n",
            "Epoch #3. Accuracy on batch 1751/3013  on Training is 86.01241438356165\n",
            "Epoch #3. Accuracy on batch 1752/3013  on Training is 86.00969766115232\n",
            "Epoch #3. Accuracy on batch 1753/3013  on Training is 86.00342075256556\n",
            "Epoch #3. Accuracy on batch 1754/3013  on Training is 86.0042735042735\n",
            "Epoch #3. Accuracy on batch 1755/3013  on Training is 86.00690489749431\n",
            "Epoch #3. Accuracy on batch 1756/3013  on Training is 86.00953329538987\n",
            "Epoch #3. Accuracy on batch 1757/3013  on Training is 86.00860352673493\n",
            "Epoch #3. Accuracy on batch 1758/3013  on Training is 86.01122797043774\n",
            "Epoch #3. Accuracy on batch 1759/3013  on Training is 86.015625\n",
            "Batch Id 1760 is having training loss of 0.48694688081741333\n",
            "0.2593521773815155\n",
            "Epoch #3. Accuracy on batch 1760/3013  on Training is 86.01824247586599\n",
            "Epoch #3. Accuracy on batch 1761/3013  on Training is 86.01021566401816\n",
            "Epoch #3. Accuracy on batch 1762/3013  on Training is 86.00219795802609\n",
            "Epoch #3. Accuracy on batch 1763/3013  on Training is 86.00659013605443\n",
            "Epoch #3. Accuracy on batch 1764/3013  on Training is 86.00743626062322\n",
            "Epoch #3. Accuracy on batch 1765/3013  on Training is 86.00297281993205\n",
            "Epoch #3. Accuracy on batch 1766/3013  on Training is 86.00558856819468\n",
            "Epoch #3. Accuracy on batch 1767/3013  on Training is 86.00113122171946\n",
            "Epoch #3. Accuracy on batch 1768/3013  on Training is 85.99844544940645\n",
            "Epoch #3. Accuracy on batch 1769/3013  on Training is 85.99752824858757\n",
            "Epoch #3. Accuracy on batch 1770/3013  on Training is 86.00367024280068\n",
            "Epoch #3. Accuracy on batch 1771/3013  on Training is 85.99393340857787\n",
            "Epoch #3. Accuracy on batch 1772/3013  on Training is 85.9965454032713\n",
            "Epoch #3. Accuracy on batch 1773/3013  on Training is 85.99034667418263\n",
            "Epoch #3. Accuracy on batch 1774/3013  on Training is 85.9894366197183\n",
            "Epoch #3. Accuracy on batch 1775/3013  on Training is 85.99204673423424\n",
            "Epoch #3. Accuracy on batch 1776/3013  on Training is 85.9876195835678\n",
            "Epoch #3. Accuracy on batch 1777/3013  on Training is 85.9884701912261\n",
            "Epoch #3. Accuracy on batch 1778/3013  on Training is 85.98931984260821\n",
            "Epoch #3. Accuracy on batch 1779/3013  on Training is 85.99016853932584\n",
            "Batch Id 1780 is having training loss of 0.48701372742652893\n",
            "0.25648951530456543\n",
            "Epoch #3. Accuracy on batch 1780/3013  on Training is 85.99452554744525\n",
            "Epoch #3. Accuracy on batch 1781/3013  on Training is 85.99537037037037\n",
            "Epoch #3. Accuracy on batch 1782/3013  on Training is 85.99270891755468\n",
            "Epoch #3. Accuracy on batch 1783/3013  on Training is 85.9900504484305\n",
            "Epoch #3. Accuracy on batch 1784/3013  on Training is 85.99614845938375\n",
            "Epoch #3. Accuracy on batch 1785/3013  on Training is 86.00223964165734\n",
            "Epoch #3. Accuracy on batch 1786/3013  on Training is 86.00657526580862\n",
            "Epoch #3. Accuracy on batch 1787/3013  on Training is 86.00741051454139\n",
            "Epoch #3. Accuracy on batch 1788/3013  on Training is 86.00999161542761\n",
            "Epoch #3. Accuracy on batch 1789/3013  on Training is 86.00384078212291\n",
            "Epoch #3. Accuracy on batch 1790/3013  on Training is 86.00293132328308\n",
            "Epoch #3. Accuracy on batch 1791/3013  on Training is 86.00202287946429\n",
            "Epoch #3. Accuracy on batch 1792/3013  on Training is 86.00285833798104\n",
            "Epoch #3. Accuracy on batch 1793/3013  on Training is 86.00195094760312\n",
            "Epoch #3. Accuracy on batch 1794/3013  on Training is 86.00626740947075\n",
            "Epoch #3. Accuracy on batch 1795/3013  on Training is 86.00187917594654\n",
            "Epoch #3. Accuracy on batch 1796/3013  on Training is 86.00445186421814\n",
            "Epoch #3. Accuracy on batch 1797/3013  on Training is 86.00528364849833\n",
            "Epoch #3. Accuracy on batch 1798/3013  on Training is 86.00958866036687\n",
            "Epoch #3. Accuracy on batch 1799/3013  on Training is 86.01215277777777\n",
            "Batch Id 1800 is having training loss of 0.4863941967487335\n",
            "0.3147112727165222\n",
            "Epoch #3. Accuracy on batch 1800/3013  on Training is 86.01471404775126\n",
            "Epoch #3. Accuracy on batch 1801/3013  on Training is 86.01553829078802\n",
            "Epoch #3. Accuracy on batch 1802/3013  on Training is 86.01289517470882\n",
            "Epoch #3. Accuracy on batch 1803/3013  on Training is 86.00852272727273\n",
            "Epoch #3. Accuracy on batch 1804/3013  on Training is 86.00415512465374\n",
            "Epoch #3. Accuracy on batch 1805/3013  on Training is 86.00671373200443\n",
            "Epoch #3. Accuracy on batch 1806/3013  on Training is 86.01099889319313\n",
            "Epoch #3. Accuracy on batch 1807/3013  on Training is 86.00318030973452\n",
            "Epoch #3. Accuracy on batch 1808/3013  on Training is 86.00573521282476\n",
            "Epoch #3. Accuracy on batch 1809/3013  on Training is 86.0013812154696\n",
            "Epoch #3. Accuracy on batch 1810/3013  on Training is 86.00220872446162\n",
            "Epoch #3. Accuracy on batch 1811/3013  on Training is 86.0082091611479\n",
            "Epoch #3. Accuracy on batch 1812/3013  on Training is 86.00558466629896\n",
            "Epoch #3. Accuracy on batch 1813/3013  on Training is 86.00296306504961\n",
            "Epoch #3. Accuracy on batch 1814/3013  on Training is 86.00550964187327\n",
            "Epoch #3. Accuracy on batch 1815/3013  on Training is 86.00633259911895\n",
            "Epoch #3. Accuracy on batch 1816/3013  on Training is 86.00199504678041\n",
            "Epoch #3. Accuracy on batch 1817/3013  on Training is 86.00281903190319\n",
            "Epoch #3. Accuracy on batch 1818/3013  on Training is 86.00707806487081\n",
            "Epoch #3. Accuracy on batch 1819/3013  on Training is 86.00446428571429\n",
            "Batch Id 1820 is having training loss of 0.4872085750102997\n",
            "0.5432817935943604\n",
            "Epoch #3. Accuracy on batch 1820/3013  on Training is 86.00013728720484\n",
            "Epoch #3. Accuracy on batch 1821/3013  on Training is 86.00267563117454\n",
            "Epoch #3. Accuracy on batch 1822/3013  on Training is 86.00521119034559\n",
            "Epoch #3. Accuracy on batch 1823/3013  on Training is 86.00431743421052\n",
            "Epoch #3. Accuracy on batch 1824/3013  on Training is 86.00342465753425\n",
            "Epoch #3. Accuracy on batch 1825/3013  on Training is 86.00253285870755\n",
            "Epoch #3. Accuracy on batch 1826/3013  on Training is 85.99993158182814\n",
            "Epoch #3. Accuracy on batch 1827/3013  on Training is 85.99733315098469\n",
            "Epoch #3. Accuracy on batch 1828/3013  on Training is 85.99644614543466\n",
            "Epoch #3. Accuracy on batch 1829/3013  on Training is 86.0006830601093\n",
            "Epoch #3. Accuracy on batch 1830/3013  on Training is 85.99979519388313\n",
            "Epoch #3. Accuracy on batch 1831/3013  on Training is 86.00061408296943\n",
            "Epoch #3. Accuracy on batch 1832/3013  on Training is 86.00484178941626\n",
            "Epoch #3. Accuracy on batch 1833/3013  on Training is 86.00736095965104\n",
            "Epoch #3. Accuracy on batch 1834/3013  on Training is 86.00306539509536\n",
            "Epoch #3. Accuracy on batch 1835/3013  on Training is 86.00217864923748\n",
            "Epoch #3. Accuracy on batch 1836/3013  on Training is 86.00299401197604\n",
            "Epoch #3. Accuracy on batch 1837/3013  on Training is 86.00550870511425\n",
            "Epoch #3. Accuracy on batch 1838/3013  on Training is 86.00462207721588\n",
            "Epoch #3. Accuracy on batch 1839/3013  on Training is 86.0071331521739\n",
            "Batch Id 1840 is having training loss of 0.48681139945983887\n",
            "0.34839820861816406\n",
            "Epoch #3. Accuracy on batch 1840/3013  on Training is 86.00964149918522\n",
            "Epoch #3. Accuracy on batch 1841/3013  on Training is 86.01723669923996\n",
            "Epoch #3. Accuracy on batch 1842/3013  on Training is 86.01295442213782\n",
            "Epoch #3. Accuracy on batch 1843/3013  on Training is 86.01715021691975\n",
            "Epoch #3. Accuracy on batch 1844/3013  on Training is 86.01117886178862\n",
            "Epoch #3. Accuracy on batch 1845/3013  on Training is 86.00690682556879\n",
            "Epoch #3. Accuracy on batch 1846/3013  on Training is 86.0060232809962\n",
            "Epoch #3. Accuracy on batch 1847/3013  on Training is 86.0051406926407\n",
            "Epoch #3. Accuracy on batch 1848/3013  on Training is 86.00425905895078\n",
            "Epoch #3. Accuracy on batch 1849/3013  on Training is 86.00675675675676\n",
            "Epoch #3. Accuracy on batch 1850/3013  on Training is 86.00418692598595\n",
            "Epoch #3. Accuracy on batch 1851/3013  on Training is 86.00330723542116\n",
            "Epoch #3. Accuracy on batch 1852/3013  on Training is 86.00074203993525\n",
            "Epoch #3. Accuracy on batch 1853/3013  on Training is 85.99480852211435\n",
            "Epoch #3. Accuracy on batch 1854/3013  on Training is 85.99561994609165\n",
            "Epoch #3. Accuracy on batch 1855/3013  on Training is 85.9997979525862\n",
            "Epoch #3. Accuracy on batch 1856/3013  on Training is 86.00228863758751\n",
            "Epoch #3. Accuracy on batch 1857/3013  on Training is 86.00477664155005\n",
            "Epoch #3. Accuracy on batch 1858/3013  on Training is 86.00894298009683\n",
            "Epoch #3. Accuracy on batch 1859/3013  on Training is 86.00806451612904\n",
            "Batch Id 1860 is having training loss of 0.48641732335090637\n",
            "0.46307140588760376\n",
            "Epoch #3. Accuracy on batch 1860/3013  on Training is 86.00718699623859\n",
            "Epoch #3. Accuracy on batch 1861/3013  on Training is 86.01134532760473\n",
            "Epoch #3. Accuracy on batch 1862/3013  on Training is 86.00711218464842\n",
            "Epoch #3. Accuracy on batch 1863/3013  on Training is 86.00958959227468\n",
            "Epoch #3. Accuracy on batch 1864/3013  on Training is 86.01038873994638\n",
            "Epoch #3. Accuracy on batch 1865/3013  on Training is 86.00951232583066\n",
            "Epoch #3. Accuracy on batch 1866/3013  on Training is 86.01198446705945\n",
            "Epoch #3. Accuracy on batch 1867/3013  on Training is 86.01110813704497\n",
            "Epoch #3. Accuracy on batch 1868/3013  on Training is 86.01692081326912\n",
            "Epoch #3. Accuracy on batch 1869/3013  on Training is 86.01938502673796\n",
            "Epoch #3. Accuracy on batch 1870/3013  on Training is 86.02017637626938\n",
            "Epoch #3. Accuracy on batch 1871/3013  on Training is 86.01929754273505\n",
            "Epoch #3. Accuracy on batch 1872/3013  on Training is 86.02342498665243\n",
            "Epoch #3. Accuracy on batch 1873/3013  on Training is 86.02254535752401\n",
            "Epoch #3. Accuracy on batch 1874/3013  on Training is 86.02333333333333\n",
            "Epoch #3. Accuracy on batch 1875/3013  on Training is 86.01412579957356\n",
            "Epoch #3. Accuracy on batch 1876/3013  on Training is 86.0082578582845\n",
            "Epoch #3. Accuracy on batch 1877/3013  on Training is 86.00406017039404\n",
            "Epoch #3. Accuracy on batch 1878/3013  on Training is 86.00485630654603\n",
            "Epoch #3. Accuracy on batch 1879/3013  on Training is 86.00565159574468\n",
            "Batch Id 1880 is having training loss of 0.4864513874053955\n",
            "0.4105810821056366\n",
            "Epoch #3. Accuracy on batch 1880/3013  on Training is 86.00478468899522\n",
            "Epoch #3. Accuracy on batch 1881/3013  on Training is 86.00557917109458\n",
            "Epoch #3. Accuracy on batch 1882/3013  on Training is 86.00969198088157\n",
            "Epoch #3. Accuracy on batch 1883/3013  on Training is 86.01214171974522\n",
            "Epoch #3. Accuracy on batch 1884/3013  on Training is 86.01956233421751\n",
            "Epoch #3. Accuracy on batch 1885/3013  on Training is 86.01537645811241\n",
            "Epoch #3. Accuracy on batch 1886/3013  on Training is 86.01450715421304\n",
            "Epoch #3. Accuracy on batch 1887/3013  on Training is 86.01363877118644\n",
            "Epoch #3. Accuracy on batch 1888/3013  on Training is 86.00780836421387\n",
            "Epoch #3. Accuracy on batch 1889/3013  on Training is 86.00859788359789\n",
            "Epoch #3. Accuracy on batch 1890/3013  on Training is 86.00442887361184\n",
            "Epoch #3. Accuracy on batch 1891/3013  on Training is 86.00356765327696\n",
            "Epoch #3. Accuracy on batch 1892/3013  on Training is 86.00600898045431\n",
            "Epoch #3. Accuracy on batch 1893/3013  on Training is 86.00349788806759\n",
            "Epoch #3. Accuracy on batch 1894/3013  on Training is 86.00428759894459\n",
            "Epoch #3. Accuracy on batch 1895/3013  on Training is 86.00837289029536\n",
            "Epoch #3. Accuracy on batch 1896/3013  on Training is 86.00751186083289\n",
            "Epoch #3. Accuracy on batch 1897/3013  on Training is 86.00665173867229\n",
            "Epoch #3. Accuracy on batch 1898/3013  on Training is 86.00414691943128\n",
            "Epoch #3. Accuracy on batch 1899/3013  on Training is 86.00493421052632\n",
            "Batch Id 1900 is having training loss of 0.4862740933895111\n",
            "0.44490358233451843\n",
            "Epoch #3. Accuracy on batch 1900/3013  on Training is 86.00243293003682\n",
            "Epoch #3. Accuracy on batch 1901/3013  on Training is 86.00322029442692\n",
            "Epoch #3. Accuracy on batch 1902/3013  on Training is 86.0007225433526\n",
            "Epoch #3. Accuracy on batch 1903/3013  on Training is 85.99330357142857\n",
            "Epoch #3. Accuracy on batch 1904/3013  on Training is 85.99409448818898\n",
            "Epoch #3. Accuracy on batch 1905/3013  on Training is 85.99980325288563\n",
            "Epoch #3. Accuracy on batch 1906/3013  on Training is 85.99895123230205\n",
            "Epoch #3. Accuracy on batch 1907/3013  on Training is 85.9981001048218\n",
            "Epoch #3. Accuracy on batch 1908/3013  on Training is 85.99233892090099\n",
            "Epoch #3. Accuracy on batch 1909/3013  on Training is 85.99476439790575\n",
            "Epoch #3. Accuracy on batch 1910/3013  on Training is 85.99391679748823\n",
            "Epoch #3. Accuracy on batch 1911/3013  on Training is 85.99797332635983\n",
            "Epoch #3. Accuracy on batch 1912/3013  on Training is 85.99875849451124\n",
            "Epoch #3. Accuracy on batch 1913/3013  on Training is 85.99627742946709\n",
            "Epoch #3. Accuracy on batch 1914/3013  on Training is 85.99379895561357\n",
            "Epoch #3. Accuracy on batch 1915/3013  on Training is 85.99295407098121\n",
            "Epoch #3. Accuracy on batch 1916/3013  on Training is 85.9970005216484\n",
            "Epoch #3. Accuracy on batch 1917/3013  on Training is 85.99615484880083\n",
            "Epoch #3. Accuracy on batch 1918/3013  on Training is 85.99693850964044\n",
            "Epoch #3. Accuracy on batch 1919/3013  on Training is 86.0009765625\n",
            "Batch Id 1920 is having training loss of 0.48631349205970764\n",
            "0.4409002959728241\n",
            "Epoch #3. Accuracy on batch 1920/3013  on Training is 86.00175689744924\n",
            "Epoch #3. Accuracy on batch 1921/3013  on Training is 86.00091050988554\n",
            "Epoch #3. Accuracy on batch 1922/3013  on Training is 86.00169006760271\n",
            "Epoch #3. Accuracy on batch 1923/3013  on Training is 85.99922037422037\n",
            "Epoch #3. Accuracy on batch 1924/3013  on Training is 86.00324675324676\n",
            "Epoch #3. Accuracy on batch 1925/3013  on Training is 86.00240134994807\n",
            "Epoch #3. Accuracy on batch 1926/3013  on Training is 86.00317851582771\n",
            "Epoch #3. Accuracy on batch 1927/3013  on Training is 86.00233402489627\n",
            "Epoch #3. Accuracy on batch 1928/3013  on Training is 86.00473043027475\n",
            "Epoch #3. Accuracy on batch 1929/3013  on Training is 86.00226683937824\n",
            "Epoch #3. Accuracy on batch 1930/3013  on Training is 86.00466079751425\n",
            "Epoch #3. Accuracy on batch 1931/3013  on Training is 86.01028726708074\n",
            "Epoch #3. Accuracy on batch 1932/3013  on Training is 86.00135799275738\n",
            "Epoch #3. Accuracy on batch 1933/3013  on Training is 86.0005170630817\n",
            "Epoch #3. Accuracy on batch 1934/3013  on Training is 86.00290697674419\n",
            "Epoch #3. Accuracy on batch 1935/3013  on Training is 86.00045196280992\n",
            "Epoch #3. Accuracy on batch 1936/3013  on Training is 86.00283944243675\n",
            "Epoch #3. Accuracy on batch 1937/3013  on Training is 86.00361197110423\n",
            "Epoch #3. Accuracy on batch 1938/3013  on Training is 86.00116039195461\n",
            "Epoch #3. Accuracy on batch 1939/3013  on Training is 86.00032216494846\n",
            "Batch Id 1940 is having training loss of 0.4864611029624939\n",
            "0.7118632197380066\n",
            "Epoch #3. Accuracy on batch 1940/3013  on Training is 85.99948480164863\n",
            "Epoch #3. Accuracy on batch 1941/3013  on Training is 86.0018666323378\n",
            "Epoch #3. Accuracy on batch 1942/3013  on Training is 86.00263767370046\n",
            "Epoch #3. Accuracy on batch 1943/3013  on Training is 86.00019290123457\n",
            "Epoch #3. Accuracy on batch 1944/3013  on Training is 86.00257069408741\n",
            "Epoch #3. Accuracy on batch 1945/3013  on Training is 86.00334018499485\n",
            "Epoch #3. Accuracy on batch 1946/3013  on Training is 86.00410888546482\n",
            "Epoch #3. Accuracy on batch 1947/3013  on Training is 86.003272587269\n",
            "Epoch #3. Accuracy on batch 1948/3013  on Training is 86.00564391995896\n",
            "Epoch #3. Accuracy on batch 1949/3013  on Training is 86.00320512820512\n",
            "Epoch #3. Accuracy on batch 1950/3013  on Training is 86.00237057919016\n",
            "Epoch #3. Accuracy on batch 1951/3013  on Training is 85.99993596311475\n",
            "Epoch #3. Accuracy on batch 1952/3013  on Training is 85.99750384024577\n",
            "Epoch #3. Accuracy on batch 1953/3013  on Training is 85.99507420675538\n",
            "Epoch #3. Accuracy on batch 1954/3013  on Training is 85.99104859335038\n",
            "Epoch #3. Accuracy on batch 1955/3013  on Training is 85.99501533742331\n",
            "Epoch #3. Accuracy on batch 1956/3013  on Training is 85.99099386816556\n",
            "Epoch #3. Accuracy on batch 1957/3013  on Training is 85.99176455566905\n",
            "Epoch #3. Accuracy on batch 1958/3013  on Training is 85.98934405308832\n",
            "Epoch #3. Accuracy on batch 1959/3013  on Training is 85.98852040816327\n",
            "Batch Id 1960 is having training loss of 0.48702049255371094\n",
            "0.4324782192707062\n",
            "Epoch #3. Accuracy on batch 1960/3013  on Training is 85.98929117797043\n",
            "Epoch #3. Accuracy on batch 1961/3013  on Training is 85.99006116207951\n",
            "Epoch #3. Accuracy on batch 1962/3013  on Training is 85.98764645950077\n",
            "Epoch #3. Accuracy on batch 1963/3013  on Training is 85.988416496945\n",
            "Epoch #3. Accuracy on batch 1964/3013  on Training is 85.98600508905852\n",
            "Epoch #3. Accuracy on batch 1965/3013  on Training is 85.98677517802645\n",
            "Epoch #3. Accuracy on batch 1966/3013  on Training is 85.9891331977631\n",
            "Epoch #3. Accuracy on batch 1967/3013  on Training is 85.98990091463415\n",
            "Epoch #3. Accuracy on batch 1968/3013  on Training is 85.98908075165059\n",
            "Epoch #3. Accuracy on batch 1969/3013  on Training is 85.98984771573605\n",
            "Epoch #3. Accuracy on batch 1970/3013  on Training is 85.992199391172\n",
            "Epoch #3. Accuracy on batch 1971/3013  on Training is 85.98504056795132\n",
            "Epoch #3. Accuracy on batch 1972/3013  on Training is 85.98422453117081\n",
            "Epoch #3. Accuracy on batch 1973/3013  on Training is 85.9849924012158\n",
            "Epoch #3. Accuracy on batch 1974/3013  on Training is 85.98417721518987\n",
            "Epoch #3. Accuracy on batch 1975/3013  on Training is 85.97861842105263\n",
            "Epoch #3. Accuracy on batch 1976/3013  on Training is 85.97622660596863\n",
            "Epoch #3. Accuracy on batch 1977/3013  on Training is 85.9801567239636\n",
            "Epoch #3. Accuracy on batch 1978/3013  on Training is 85.98092470944921\n",
            "Epoch #3. Accuracy on batch 1979/3013  on Training is 85.98327020202021\n",
            "Batch Id 1980 is having training loss of 0.48705363273620605\n",
            "0.29443565011024475\n",
            "Epoch #3. Accuracy on batch 1980/3013  on Training is 85.98561332660273\n",
            "Epoch #3. Accuracy on batch 1981/3013  on Training is 85.98322401614531\n",
            "Epoch #3. Accuracy on batch 1982/3013  on Training is 85.98714069591529\n",
            "Epoch #3. Accuracy on batch 1983/3013  on Training is 85.98790322580645\n",
            "Epoch #3. Accuracy on batch 1984/3013  on Training is 85.98394206549118\n",
            "Epoch #3. Accuracy on batch 1985/3013  on Training is 85.98155840886203\n",
            "Epoch #3. Accuracy on batch 1986/3013  on Training is 85.97917715148465\n",
            "Epoch #3. Accuracy on batch 1987/3013  on Training is 85.98151408450704\n",
            "Epoch #3. Accuracy on batch 1988/3013  on Training is 85.97599296128708\n",
            "Epoch #3. Accuracy on batch 1989/3013  on Training is 85.97204773869346\n",
            "Epoch #3. Accuracy on batch 1990/3013  on Training is 85.96967604218986\n",
            "Epoch #3. Accuracy on batch 1991/3013  on Training is 85.96573795180723\n",
            "Epoch #3. Accuracy on batch 1992/3013  on Training is 85.96493978926242\n",
            "Epoch #3. Accuracy on batch 1993/3013  on Training is 85.96570962888666\n",
            "Epoch #3. Accuracy on batch 1994/3013  on Training is 85.96804511278195\n",
            "Epoch #3. Accuracy on batch 1995/3013  on Training is 85.96568136272545\n",
            "Epoch #3. Accuracy on batch 1996/3013  on Training is 85.96957936905358\n",
            "Epoch #3. Accuracy on batch 1997/3013  on Training is 85.96721721721721\n",
            "Epoch #3. Accuracy on batch 1998/3013  on Training is 85.967983991996\n",
            "Epoch #3. Accuracy on batch 1999/3013  on Training is 85.9640625\n",
            "Batch Id 2000 is having training loss of 0.4877418279647827\n",
            "0.48791182041168213\n",
            "Epoch #3. Accuracy on batch 2000/3013  on Training is 85.96326836581709\n",
            "Epoch #3. Accuracy on batch 2001/3013  on Training is 85.96403596403596\n",
            "Epoch #3. Accuracy on batch 2002/3013  on Training is 85.96480279580629\n",
            "Epoch #3. Accuracy on batch 2003/3013  on Training is 85.96089071856288\n",
            "Epoch #3. Accuracy on batch 2004/3013  on Training is 85.96321695760598\n",
            "Epoch #3. Accuracy on batch 2005/3013  on Training is 85.95930957128614\n",
            "Epoch #3. Accuracy on batch 2006/3013  on Training is 85.96163428001994\n",
            "Epoch #3. Accuracy on batch 2007/3013  on Training is 85.96240039840637\n",
            "Epoch #3. Accuracy on batch 2008/3013  on Training is 85.9647212543554\n",
            "Epoch #3. Accuracy on batch 2009/3013  on Training is 85.96548507462687\n",
            "Epoch #3. Accuracy on batch 2010/3013  on Training is 85.96469418199901\n",
            "Epoch #3. Accuracy on batch 2011/3013  on Training is 85.96545725646124\n",
            "Epoch #3. Accuracy on batch 2012/3013  on Training is 85.96466716343765\n",
            "Epoch #3. Accuracy on batch 2013/3013  on Training is 85.9638778550149\n",
            "Epoch #3. Accuracy on batch 2014/3013  on Training is 85.96308933002481\n",
            "Epoch #3. Accuracy on batch 2015/3013  on Training is 85.95765128968254\n",
            "Epoch #3. Accuracy on batch 2016/3013  on Training is 85.95841596430343\n",
            "Epoch #3. Accuracy on batch 2017/3013  on Training is 85.95917988107037\n",
            "Epoch #3. Accuracy on batch 2018/3013  on Training is 85.95839524517088\n",
            "Epoch #3. Accuracy on batch 2019/3013  on Training is 85.95606435643565\n",
            "Batch Id 2020 is having training loss of 0.4881989359855652\n",
            "0.6024894118309021\n",
            "Epoch #3. Accuracy on batch 2020/3013  on Training is 85.95528203859476\n",
            "Epoch #3. Accuracy on batch 2021/3013  on Training is 85.95913699307616\n",
            "Epoch #3. Accuracy on batch 2022/3013  on Training is 85.9537197231834\n",
            "Epoch #3. Accuracy on batch 2023/3013  on Training is 85.95448369565217\n",
            "Epoch #3. Accuracy on batch 2024/3013  on Training is 85.95061728395062\n",
            "Epoch #3. Accuracy on batch 2025/3013  on Training is 85.95446692991115\n",
            "Epoch #3. Accuracy on batch 2026/3013  on Training is 85.95060434139121\n",
            "Epoch #3. Accuracy on batch 2027/3013  on Training is 85.95136834319527\n",
            "Epoch #3. Accuracy on batch 2028/3013  on Training is 85.94597092163627\n",
            "Epoch #3. Accuracy on batch 2029/3013  on Training is 85.94519704433498\n",
            "Epoch #3. Accuracy on batch 2030/3013  on Training is 85.94596258000985\n",
            "Epoch #3. Accuracy on batch 2031/3013  on Training is 85.9498031496063\n",
            "Epoch #3. Accuracy on batch 2032/3013  on Training is 85.94595425479586\n",
            "Epoch #3. Accuracy on batch 2033/3013  on Training is 85.94364552605703\n",
            "Epoch #3. Accuracy on batch 2034/3013  on Training is 85.94441031941032\n",
            "Epoch #3. Accuracy on batch 2035/3013  on Training is 85.94824410609037\n",
            "Epoch #3. Accuracy on batch 2036/3013  on Training is 85.94440353460972\n",
            "Epoch #3. Accuracy on batch 2037/3013  on Training is 85.94516683022572\n",
            "Epoch #3. Accuracy on batch 2038/3013  on Training is 85.94439676311917\n",
            "Epoch #3. Accuracy on batch 2039/3013  on Training is 85.94822303921569\n",
            "Batch Id 2040 is having training loss of 0.48815470933914185\n",
            "0.23826472461223602\n",
            "Epoch #3. Accuracy on batch 2040/3013  on Training is 85.95204556589907\n",
            "Epoch #3. Accuracy on batch 2041/3013  on Training is 85.9497428991185\n",
            "Epoch #3. Accuracy on batch 2042/3013  on Training is 85.95050171316691\n",
            "Epoch #3. Accuracy on batch 2043/3013  on Training is 85.94973091976517\n",
            "Epoch #3. Accuracy on batch 2044/3013  on Training is 85.9489608801956\n",
            "Epoch #3. Accuracy on batch 2045/3013  on Training is 85.94971896383187\n",
            "Epoch #3. Accuracy on batch 2046/3013  on Training is 85.942843185149\n",
            "Epoch #3. Accuracy on batch 2047/3013  on Training is 85.94512939453125\n",
            "Epoch #3. Accuracy on batch 2048/3013  on Training is 85.94283796974133\n",
            "Epoch #3. Accuracy on batch 2049/3013  on Training is 85.9420731707317\n",
            "Epoch #3. Accuracy on batch 2050/3013  on Training is 85.94130911750365\n",
            "Epoch #3. Accuracy on batch 2051/3013  on Training is 85.94359161793372\n",
            "Epoch #3. Accuracy on batch 2052/3013  on Training is 85.94130540672187\n",
            "Epoch #3. Accuracy on batch 2053/3013  on Training is 85.93902142161636\n",
            "Epoch #3. Accuracy on batch 2054/3013  on Training is 85.93673965936739\n",
            "Epoch #3. Accuracy on batch 2055/3013  on Training is 85.93598005836576\n",
            "Epoch #3. Accuracy on batch 2056/3013  on Training is 85.93218279047156\n",
            "Epoch #3. Accuracy on batch 2057/3013  on Training is 85.92535228377065\n",
            "Epoch #3. Accuracy on batch 2058/3013  on Training is 85.92763477416221\n",
            "Epoch #3. Accuracy on batch 2059/3013  on Training is 85.92384708737865\n",
            "Batch Id 2060 is having training loss of 0.48891547322273254\n",
            "0.7287850975990295\n",
            "Epoch #3. Accuracy on batch 2060/3013  on Training is 85.92006307617662\n",
            "Epoch #3. Accuracy on batch 2061/3013  on Training is 85.92386032977691\n",
            "Epoch #3. Accuracy on batch 2062/3013  on Training is 85.91705041202133\n",
            "Epoch #3. Accuracy on batch 2063/3013  on Training is 85.90721899224806\n",
            "Epoch #3. Accuracy on batch 2064/3013  on Training is 85.90799031476998\n",
            "Epoch #3. Accuracy on batch 2065/3013  on Training is 85.9027105517909\n",
            "Epoch #3. Accuracy on batch 2066/3013  on Training is 85.90197145621674\n",
            "Epoch #3. Accuracy on batch 2067/3013  on Training is 85.89367746615088\n",
            "Epoch #3. Accuracy on batch 2068/3013  on Training is 85.88992266795553\n",
            "Epoch #3. Accuracy on batch 2069/3013  on Training is 85.89070048309179\n",
            "Epoch #3. Accuracy on batch 2070/3013  on Training is 85.89147754707871\n",
            "Epoch #3. Accuracy on batch 2071/3013  on Training is 85.89376206563706\n",
            "Epoch #3. Accuracy on batch 2072/3013  on Training is 85.89604438012542\n",
            "Epoch #3. Accuracy on batch 2073/3013  on Training is 85.8922974927676\n",
            "Epoch #3. Accuracy on batch 2074/3013  on Training is 85.894578313253\n",
            "Epoch #3. Accuracy on batch 2075/3013  on Training is 85.89535163776493\n",
            "Epoch #3. Accuracy on batch 2076/3013  on Training is 85.8946196437169\n",
            "Epoch #3. Accuracy on batch 2077/3013  on Training is 85.89689605389798\n",
            "Epoch #3. Accuracy on batch 2078/3013  on Training is 85.89315776815776\n",
            "Epoch #3. Accuracy on batch 2079/3013  on Training is 85.89242788461539\n",
            "Batch Id 2080 is having training loss of 0.48961472511291504\n",
            "0.3046995997428894\n",
            "Epoch #3. Accuracy on batch 2080/3013  on Training is 85.89169870254685\n",
            "Epoch #3. Accuracy on batch 2081/3013  on Training is 85.8894692603266\n",
            "Epoch #3. Accuracy on batch 2082/3013  on Training is 85.88724195871339\n",
            "Epoch #3. Accuracy on batch 2083/3013  on Training is 85.88651631477927\n",
            "Epoch #3. Accuracy on batch 2084/3013  on Training is 85.89028776978417\n",
            "Epoch #3. Accuracy on batch 2085/3013  on Training is 85.88806327900288\n",
            "Epoch #3. Accuracy on batch 2086/3013  on Training is 85.88584091998084\n",
            "Epoch #3. Accuracy on batch 2087/3013  on Training is 85.88511733716476\n",
            "Epoch #3. Accuracy on batch 2088/3013  on Training is 85.88888224030637\n",
            "Epoch #3. Accuracy on batch 2089/3013  on Training is 85.88666267942584\n",
            "Epoch #3. Accuracy on batch 2090/3013  on Training is 85.8889287422286\n",
            "Epoch #3. Accuracy on batch 2091/3013  on Training is 85.89119263862332\n",
            "Epoch #3. Accuracy on batch 2092/3013  on Training is 85.88748208313426\n",
            "Epoch #3. Accuracy on batch 2093/3013  on Training is 85.88377507163324\n",
            "Epoch #3. Accuracy on batch 2094/3013  on Training is 85.88603818615752\n",
            "Epoch #3. Accuracy on batch 2095/3013  on Training is 85.88829914122137\n",
            "Epoch #3. Accuracy on batch 2096/3013  on Training is 85.89204816404387\n",
            "Epoch #3. Accuracy on batch 2097/3013  on Training is 85.89579361296472\n",
            "Epoch #3. Accuracy on batch 2098/3013  on Training is 85.89506908051453\n",
            "Epoch #3. Accuracy on batch 2099/3013  on Training is 85.89583333333333\n",
            "Batch Id 2100 is having training loss of 0.4896017611026764\n",
            "0.9596105813980103\n",
            "Epoch #3. Accuracy on batch 2100/3013  on Training is 85.89064731080438\n",
            "Epoch #3. Accuracy on batch 2101/3013  on Training is 85.8914129400571\n",
            "Epoch #3. Accuracy on batch 2102/3013  on Training is 85.88771992391821\n",
            "Epoch #3. Accuracy on batch 2103/3013  on Training is 85.88997148288973\n",
            "Epoch #3. Accuracy on batch 2104/3013  on Training is 85.89073634204276\n",
            "Epoch #3. Accuracy on batch 2105/3013  on Training is 85.88853276353277\n",
            "Epoch #3. Accuracy on batch 2106/3013  on Training is 85.890780730897\n",
            "Epoch #3. Accuracy on batch 2107/3013  on Training is 85.88857922201139\n",
            "Epoch #3. Accuracy on batch 2108/3013  on Training is 85.89082503556187\n",
            "Epoch #3. Accuracy on batch 2109/3013  on Training is 85.89010663507109\n",
            "Epoch #3. Accuracy on batch 2110/3013  on Training is 85.89679062055897\n",
            "Epoch #3. Accuracy on batch 2111/3013  on Training is 85.89311079545455\n",
            "Epoch #3. Accuracy on batch 2112/3013  on Training is 85.88943445338381\n",
            "Epoch #3. Accuracy on batch 2113/3013  on Training is 85.8901963103122\n",
            "Epoch #3. Accuracy on batch 2114/3013  on Training is 85.89095744680851\n",
            "Epoch #3. Accuracy on batch 2115/3013  on Training is 85.88728733459357\n",
            "Epoch #3. Accuracy on batch 2116/3013  on Training is 85.88509683514407\n",
            "Epoch #3. Accuracy on batch 2117/3013  on Training is 85.88143295561851\n",
            "Epoch #3. Accuracy on batch 2118/3013  on Training is 85.88514629542237\n",
            "Epoch #3. Accuracy on batch 2119/3013  on Training is 85.88590801886792\n",
            "Batch Id 2120 is having training loss of 0.48947852849960327\n",
            "0.3754277229309082\n",
            "Epoch #3. Accuracy on batch 2120/3013  on Training is 85.88961574728901\n",
            "Epoch #3. Accuracy on batch 2121/3013  on Training is 85.89184731385485\n",
            "Epoch #3. Accuracy on batch 2122/3013  on Training is 85.89260480452191\n",
            "Epoch #3. Accuracy on batch 2123/3013  on Training is 85.89630414312617\n",
            "Epoch #3. Accuracy on batch 2124/3013  on Training is 85.88970588235294\n",
            "Epoch #3. Accuracy on batch 2125/3013  on Training is 85.88605362182503\n",
            "Epoch #3. Accuracy on batch 2126/3013  on Training is 85.88681241184767\n",
            "Epoch #3. Accuracy on batch 2127/3013  on Training is 85.8875704887218\n",
            "Epoch #3. Accuracy on batch 2128/3013  on Training is 85.88832785345232\n",
            "Epoch #3. Accuracy on batch 2129/3013  on Training is 85.88761737089202\n",
            "Epoch #3. Accuracy on batch 2130/3013  on Training is 85.89130689816987\n",
            "Epoch #3. Accuracy on batch 2131/3013  on Training is 85.890595684803\n",
            "Epoch #3. Accuracy on batch 2132/3013  on Training is 85.88402484763245\n",
            "Epoch #3. Accuracy on batch 2133/3013  on Training is 85.88331771321462\n",
            "Epoch #3. Accuracy on batch 2134/3013  on Training is 85.87968384074941\n",
            "Epoch #3. Accuracy on batch 2135/3013  on Training is 85.88044241573034\n",
            "Epoch #3. Accuracy on batch 2136/3013  on Training is 85.8826626111371\n",
            "Epoch #3. Accuracy on batch 2137/3013  on Training is 85.88488072965389\n",
            "Epoch #3. Accuracy on batch 2138/3013  on Training is 85.88271388499298\n",
            "Epoch #3. Accuracy on batch 2139/3013  on Training is 85.88054906542057\n",
            "Batch Id 2140 is having training loss of 0.489483118057251\n",
            "0.4614773094654083\n",
            "Epoch #3. Accuracy on batch 2140/3013  on Training is 85.8813054647361\n",
            "Epoch #3. Accuracy on batch 2141/3013  on Training is 85.88643790849673\n",
            "Epoch #3. Accuracy on batch 2142/3013  on Training is 85.88573261782548\n",
            "Epoch #3. Accuracy on batch 2143/3013  on Training is 85.88502798507463\n",
            "Epoch #3. Accuracy on batch 2144/3013  on Training is 85.88578088578089\n",
            "Epoch #3. Accuracy on batch 2145/3013  on Training is 85.88216449207829\n",
            "Epoch #3. Accuracy on batch 2146/3013  on Training is 85.88146250582207\n",
            "Epoch #3. Accuracy on batch 2147/3013  on Training is 85.87930633147114\n",
            "Epoch #3. Accuracy on batch 2148/3013  on Training is 85.88296882270824\n",
            "Epoch #3. Accuracy on batch 2149/3013  on Training is 85.88226744186046\n",
            "Epoch #3. Accuracy on batch 2150/3013  on Training is 85.88592515109252\n",
            "Epoch #3. Accuracy on batch 2151/3013  on Training is 85.8823187732342\n",
            "Epoch #3. Accuracy on batch 2152/3013  on Training is 85.88597306084533\n",
            "Epoch #3. Accuracy on batch 2153/3013  on Training is 85.88672237697307\n",
            "Epoch #3. Accuracy on batch 2154/3013  on Training is 85.88602088167053\n",
            "Epoch #3. Accuracy on batch 2155/3013  on Training is 85.88532003710576\n",
            "Epoch #3. Accuracy on batch 2156/3013  on Training is 85.88461984237367\n",
            "Epoch #3. Accuracy on batch 2157/3013  on Training is 85.88247219647822\n",
            "Epoch #3. Accuracy on batch 2158/3013  on Training is 85.87743168133395\n",
            "Epoch #3. Accuracy on batch 2159/3013  on Training is 85.88252314814815\n",
            "Batch Id 2160 is having training loss of 0.4897518455982208\n",
            "0.6672847270965576\n",
            "Epoch #3. Accuracy on batch 2160/3013  on Training is 85.88037945395651\n",
            "Epoch #3. Accuracy on batch 2161/3013  on Training is 85.87968316373728\n",
            "Epoch #3. Accuracy on batch 2162/3013  on Training is 85.88187702265373\n",
            "Epoch #3. Accuracy on batch 2163/3013  on Training is 85.87684842883549\n",
            "Epoch #3. Accuracy on batch 2164/3013  on Training is 85.88048498845265\n",
            "Epoch #3. Accuracy on batch 2165/3013  on Training is 85.88123268698061\n",
            "Epoch #3. Accuracy on batch 2166/3013  on Training is 85.88342178126442\n",
            "Epoch #3. Accuracy on batch 2167/3013  on Training is 85.88416743542436\n",
            "Epoch #3. Accuracy on batch 2168/3013  on Training is 85.88203088981098\n",
            "Epoch #3. Accuracy on batch 2169/3013  on Training is 85.87989631336406\n",
            "Epoch #3. Accuracy on batch 2170/3013  on Training is 85.88064256103178\n",
            "Epoch #3. Accuracy on batch 2171/3013  on Training is 85.8785105893186\n",
            "Epoch #3. Accuracy on batch 2172/3013  on Training is 85.88213299585826\n",
            "Epoch #3. Accuracy on batch 2173/3013  on Training is 85.88143974241031\n",
            "Epoch #3. Accuracy on batch 2174/3013  on Training is 85.87787356321839\n",
            "Epoch #3. Accuracy on batch 2175/3013  on Training is 85.87143841911765\n",
            "Epoch #3. Accuracy on batch 2176/3013  on Training is 85.87362195682131\n",
            "Epoch #3. Accuracy on batch 2177/3013  on Training is 85.87006427915519\n",
            "Epoch #3. Accuracy on batch 2178/3013  on Training is 85.86937815511703\n",
            "Epoch #3. Accuracy on batch 2179/3013  on Training is 85.86439220183486\n",
            "Batch Id 2180 is having training loss of 0.4902307689189911\n",
            "0.3478590250015259\n",
            "Epoch #3. Accuracy on batch 2180/3013  on Training is 85.8665749656121\n",
            "Epoch #3. Accuracy on batch 2181/3013  on Training is 85.86732355637031\n",
            "Epoch #3. Accuracy on batch 2182/3013  on Training is 85.86663994502977\n",
            "Epoch #3. Accuracy on batch 2183/3013  on Training is 85.86738782051282\n",
            "Epoch #3. Accuracy on batch 2184/3013  on Training is 85.8695652173913\n",
            "Epoch #3. Accuracy on batch 2185/3013  on Training is 85.87031107044831\n",
            "Epoch #3. Accuracy on batch 2186/3013  on Training is 85.87534293552812\n",
            "Epoch #3. Accuracy on batch 2187/3013  on Training is 85.8803702010969\n",
            "Epoch #3. Accuracy on batch 2188/3013  on Training is 85.87968250342622\n",
            "Epoch #3. Accuracy on batch 2189/3013  on Training is 85.88042237442923\n",
            "Epoch #3. Accuracy on batch 2190/3013  on Training is 85.88258785942492\n",
            "Epoch #3. Accuracy on batch 2191/3013  on Training is 85.88190009124088\n",
            "Epoch #3. Accuracy on batch 2192/3013  on Training is 85.88548791609666\n",
            "Epoch #3. Accuracy on batch 2193/3013  on Training is 85.88195077484048\n",
            "Epoch #3. Accuracy on batch 2194/3013  on Training is 85.88268792710706\n",
            "Epoch #3. Accuracy on batch 2195/3013  on Training is 85.88627049180327\n",
            "Epoch #3. Accuracy on batch 2196/3013  on Training is 85.88842740100137\n",
            "Epoch #3. Accuracy on batch 2197/3013  on Training is 85.88773885350318\n",
            "Epoch #3. Accuracy on batch 2198/3013  on Training is 85.88847203274216\n",
            "Epoch #3. Accuracy on batch 2199/3013  on Training is 85.8877840909091\n",
            "Batch Id 2200 is having training loss of 0.48947834968566895\n",
            "0.3697728216648102\n",
            "Epoch #3. Accuracy on batch 2200/3013  on Training is 85.88993639254885\n",
            "Epoch #3. Accuracy on batch 2201/3013  on Training is 85.88641008174388\n",
            "Epoch #3. Accuracy on batch 2202/3013  on Training is 85.8885610531094\n",
            "Epoch #3. Accuracy on batch 2203/3013  on Training is 85.88645644283122\n",
            "Epoch #3. Accuracy on batch 2204/3013  on Training is 85.8843537414966\n",
            "Epoch #3. Accuracy on batch 2205/3013  on Training is 85.88225294650952\n",
            "Epoch #3. Accuracy on batch 2206/3013  on Training is 85.88298595378342\n",
            "Epoch #3. Accuracy on batch 2207/3013  on Training is 85.88513360507247\n",
            "Epoch #3. Accuracy on batch 2208/3013  on Training is 85.88727931190584\n",
            "Epoch #3. Accuracy on batch 2209/3013  on Training is 85.88800904977376\n",
            "Epoch #3. Accuracy on batch 2210/3013  on Training is 85.89297829036634\n",
            "Epoch #3. Accuracy on batch 2211/3013  on Training is 85.8937047920434\n",
            "Epoch #3. Accuracy on batch 2212/3013  on Training is 85.89301852688658\n",
            "Epoch #3. Accuracy on batch 2213/3013  on Training is 85.89374435411021\n",
            "Epoch #3. Accuracy on batch 2214/3013  on Training is 85.89446952595937\n",
            "Epoch #3. Accuracy on batch 2215/3013  on Training is 85.89237364620939\n",
            "Epoch #3. Accuracy on batch 2216/3013  on Training is 85.89450834460983\n",
            "Epoch #3. Accuracy on batch 2217/3013  on Training is 85.89382326420198\n",
            "Epoch #3. Accuracy on batch 2218/3013  on Training is 85.89032221721496\n",
            "Epoch #3. Accuracy on batch 2219/3013  on Training is 85.89104729729729\n",
            "Batch Id 2220 is having training loss of 0.48969903588294983\n",
            "0.8015441298484802\n",
            "Epoch #3. Accuracy on batch 2220/3013  on Training is 85.8889576767222\n",
            "Epoch #3. Accuracy on batch 2221/3013  on Training is 85.89249549954995\n",
            "Epoch #3. Accuracy on batch 2222/3013  on Training is 85.89321862348179\n",
            "Epoch #3. Accuracy on batch 2223/3013  on Training is 85.89253597122303\n",
            "Epoch #3. Accuracy on batch 2224/3013  on Training is 85.89606741573034\n",
            "Epoch #3. Accuracy on batch 2225/3013  on Training is 85.89959568733154\n",
            "Epoch #3. Accuracy on batch 2226/3013  on Training is 85.89891109115402\n",
            "Epoch #3. Accuracy on batch 2227/3013  on Training is 85.90103231597845\n",
            "Epoch #3. Accuracy on batch 2228/3013  on Training is 85.9031516375056\n",
            "Epoch #3. Accuracy on batch 2229/3013  on Training is 85.90667040358744\n",
            "Epoch #3. Accuracy on batch 2230/3013  on Training is 85.90598386373823\n",
            "Epoch #3. Accuracy on batch 2231/3013  on Training is 85.9052979390681\n",
            "Epoch #3. Accuracy on batch 2232/3013  on Training is 85.9032131661442\n",
            "Epoch #3. Accuracy on batch 2233/3013  on Training is 85.90392793196061\n",
            "Epoch #3. Accuracy on batch 2234/3013  on Training is 85.90883668903803\n",
            "Epoch #3. Accuracy on batch 2235/3013  on Training is 85.90675313059035\n",
            "Epoch #3. Accuracy on batch 2236/3013  on Training is 85.90746535538668\n",
            "Epoch #3. Accuracy on batch 2237/3013  on Training is 85.91096961572833\n",
            "Epoch #3. Accuracy on batch 2238/3013  on Training is 85.90888789638231\n",
            "Epoch #3. Accuracy on batch 2239/3013  on Training is 85.90262276785714\n",
            "Batch Id 2240 is having training loss of 0.48934507369995117\n",
            "0.3410743176937103\n",
            "Epoch #3. Accuracy on batch 2240/3013  on Training is 85.90333556448014\n",
            "Epoch #3. Accuracy on batch 2241/3013  on Training is 85.90404772524532\n",
            "Epoch #3. Accuracy on batch 2242/3013  on Training is 85.90057958091842\n",
            "Epoch #3. Accuracy on batch 2243/3013  on Training is 85.90129233511587\n",
            "Epoch #3. Accuracy on batch 2244/3013  on Training is 85.89922048997772\n",
            "Epoch #3. Accuracy on batch 2245/3013  on Training is 85.9027159394479\n",
            "Epoch #3. Accuracy on batch 2246/3013  on Training is 85.90759902091678\n",
            "Epoch #3. Accuracy on batch 2247/3013  on Training is 85.91108763345196\n",
            "Epoch #3. Accuracy on batch 2248/3013  on Training is 85.91179413072477\n",
            "Epoch #3. Accuracy on batch 2249/3013  on Training is 85.90972222222223\n",
            "Epoch #3. Accuracy on batch 2250/3013  on Training is 85.91181697023545\n",
            "Epoch #3. Accuracy on batch 2251/3013  on Training is 85.91252220248668\n",
            "Epoch #3. Accuracy on batch 2252/3013  on Training is 85.90906569019086\n",
            "Epoch #3. Accuracy on batch 2253/3013  on Training is 85.91254436557232\n",
            "Epoch #3. Accuracy on batch 2254/3013  on Training is 85.91324833702882\n",
            "Epoch #3. Accuracy on batch 2255/3013  on Training is 85.91256648936171\n",
            "Epoch #3. Accuracy on batch 2256/3013  on Training is 85.91465440850686\n",
            "Epoch #3. Accuracy on batch 2257/3013  on Training is 85.91812444641276\n",
            "Epoch #3. Accuracy on batch 2258/3013  on Training is 85.92020805666225\n",
            "Epoch #3. Accuracy on batch 2259/3013  on Training is 85.92228982300885\n",
            "Batch Id 2260 is having training loss of 0.4886249899864197\n",
            "0.4511399269104004\n",
            "Epoch #3. Accuracy on batch 2260/3013  on Training is 85.92298761609906\n",
            "Epoch #3. Accuracy on batch 2261/3013  on Training is 85.92092175066313\n",
            "Epoch #3. Accuracy on batch 2262/3013  on Training is 85.92023862129916\n",
            "Epoch #3. Accuracy on batch 2263/3013  on Training is 85.91955609540636\n",
            "Epoch #3. Accuracy on batch 2264/3013  on Training is 85.92025386313466\n",
            "Epoch #3. Accuracy on batch 2265/3013  on Training is 85.91681376875552\n",
            "Epoch #3. Accuracy on batch 2266/3013  on Training is 85.91751213056904\n",
            "Epoch #3. Accuracy on batch 2267/3013  on Training is 85.92096560846561\n",
            "Epoch #3. Accuracy on batch 2268/3013  on Training is 85.92303878360511\n",
            "Epoch #3. Accuracy on batch 2269/3013  on Training is 85.92098017621146\n",
            "Epoch #3. Accuracy on batch 2270/3013  on Training is 85.92167547335976\n",
            "Epoch #3. Accuracy on batch 2271/3013  on Training is 85.9223701584507\n",
            "Epoch #3. Accuracy on batch 2272/3013  on Training is 85.92168939727233\n",
            "Epoch #3. Accuracy on batch 2273/3013  on Training is 85.92238346525946\n",
            "Epoch #3. Accuracy on batch 2274/3013  on Training is 85.91758241758242\n",
            "Epoch #3. Accuracy on batch 2275/3013  on Training is 85.9196507029877\n",
            "Epoch #3. Accuracy on batch 2276/3013  on Training is 85.92446201141853\n",
            "Epoch #3. Accuracy on batch 2277/3013  on Training is 85.9237818261633\n",
            "Epoch #3. Accuracy on batch 2278/3013  on Training is 85.92035980693286\n",
            "Epoch #3. Accuracy on batch 2279/3013  on Training is 85.92242324561404\n",
            "Batch Id 2280 is having training loss of 0.4888279438018799\n",
            "0.4325421154499054\n",
            "Epoch #3. Accuracy on batch 2280/3013  on Training is 85.9244848750548\n",
            "Epoch #3. Accuracy on batch 2281/3013  on Training is 85.92791411042944\n",
            "Epoch #3. Accuracy on batch 2282/3013  on Training is 85.92723390275953\n",
            "Epoch #3. Accuracy on batch 2283/3013  on Training is 85.92381786339755\n",
            "Epoch #3. Accuracy on batch 2284/3013  on Training is 85.91903719912473\n",
            "Epoch #3. Accuracy on batch 2285/3013  on Training is 85.92109580052494\n",
            "Epoch #3. Accuracy on batch 2286/3013  on Training is 85.92451902055095\n",
            "Epoch #3. Accuracy on batch 2287/3013  on Training is 85.92930506993007\n",
            "Epoch #3. Accuracy on batch 2288/3013  on Training is 85.92999126256007\n",
            "Epoch #3. Accuracy on batch 2289/3013  on Training is 85.92931222707423\n",
            "Epoch #3. Accuracy on batch 2290/3013  on Training is 85.93136185072021\n",
            "Epoch #3. Accuracy on batch 2291/3013  on Training is 85.92795593368237\n",
            "Epoch #3. Accuracy on batch 2292/3013  on Training is 85.92455298735281\n",
            "Epoch #3. Accuracy on batch 2293/3013  on Training is 85.92523975588492\n",
            "Epoch #3. Accuracy on batch 2294/3013  on Training is 85.92864923747277\n",
            "Epoch #3. Accuracy on batch 2295/3013  on Training is 85.92933362369338\n",
            "Epoch #3. Accuracy on batch 2296/3013  on Training is 85.9272964736613\n",
            "Epoch #3. Accuracy on batch 2297/3013  on Training is 85.92390121845082\n",
            "Epoch #3. Accuracy on batch 2298/3013  on Training is 85.92594606350588\n",
            "Epoch #3. Accuracy on batch 2299/3013  on Training is 85.91983695652173\n",
            "Batch Id 2300 is having training loss of 0.48932769894599915\n",
            "0.5305774807929993\n",
            "Epoch #3. Accuracy on batch 2300/3013  on Training is 85.91916558018254\n",
            "Epoch #3. Accuracy on batch 2301/3013  on Training is 85.91849478714161\n",
            "Epoch #3. Accuracy on batch 2302/3013  on Training is 85.9205384281372\n",
            "Epoch #3. Accuracy on batch 2303/3013  on Training is 85.91851128472223\n",
            "Epoch #3. Accuracy on batch 2304/3013  on Training is 85.92055314533623\n",
            "Epoch #3. Accuracy on batch 2305/3013  on Training is 85.91581743278404\n",
            "Epoch #3. Accuracy on batch 2306/3013  on Training is 85.91514954486345\n",
            "Epoch #3. Accuracy on batch 2307/3013  on Training is 85.91854419410745\n",
            "Epoch #3. Accuracy on batch 2308/3013  on Training is 85.91516890428757\n",
            "Epoch #3. Accuracy on batch 2309/3013  on Training is 85.91450216450217\n",
            "Epoch #3. Accuracy on batch 2310/3013  on Training is 85.90842708784076\n",
            "Epoch #3. Accuracy on batch 2311/3013  on Training is 85.91046712802768\n",
            "Epoch #3. Accuracy on batch 2312/3013  on Training is 85.91115434500648\n",
            "Epoch #3. Accuracy on batch 2313/3013  on Training is 85.91319144338807\n",
            "Epoch #3. Accuracy on batch 2314/3013  on Training is 85.91657667386609\n",
            "Epoch #3. Accuracy on batch 2315/3013  on Training is 85.91186312607945\n",
            "Epoch #3. Accuracy on batch 2316/3013  on Training is 85.90580492015538\n",
            "Epoch #3. Accuracy on batch 2317/3013  on Training is 85.907840811044\n",
            "Epoch #3. Accuracy on batch 2318/3013  on Training is 85.90583225528245\n",
            "Epoch #3. Accuracy on batch 2319/3013  on Training is 85.90786637931035\n",
            "Batch Id 2320 is having training loss of 0.489815354347229\n",
            "0.5532932877540588\n",
            "Epoch #3. Accuracy on batch 2320/3013  on Training is 85.90720594571306\n",
            "Epoch #3. Accuracy on batch 2321/3013  on Training is 85.90385443583118\n",
            "Epoch #3. Accuracy on batch 2322/3013  on Training is 85.90319629789066\n",
            "Epoch #3. Accuracy on batch 2323/3013  on Training is 85.9025387263339\n",
            "Epoch #3. Accuracy on batch 2324/3013  on Training is 85.90053763440861\n",
            "Epoch #3. Accuracy on batch 2325/3013  on Training is 85.90256878761822\n",
            "Epoch #3. Accuracy on batch 2326/3013  on Training is 85.90056940266437\n",
            "Epoch #3. Accuracy on batch 2327/3013  on Training is 85.90125644329896\n",
            "Epoch #3. Accuracy on batch 2328/3013  on Training is 85.9019428939459\n",
            "Epoch #3. Accuracy on batch 2329/3013  on Training is 85.90396995708154\n",
            "Epoch #3. Accuracy on batch 2330/3013  on Training is 85.8966108966109\n",
            "Epoch #3. Accuracy on batch 2331/3013  on Training is 85.89595840480274\n",
            "Epoch #3. Accuracy on batch 2332/3013  on Training is 85.8953064723532\n",
            "Epoch #3. Accuracy on batch 2333/3013  on Training is 85.89733290488432\n",
            "Epoch #3. Accuracy on batch 2334/3013  on Training is 85.90069593147751\n",
            "Epoch #3. Accuracy on batch 2335/3013  on Training is 85.89602953767124\n",
            "Epoch #3. Accuracy on batch 2336/3013  on Training is 85.89805305947796\n",
            "Epoch #3. Accuracy on batch 2337/3013  on Training is 85.90408468776732\n",
            "Epoch #3. Accuracy on batch 2338/3013  on Training is 85.90877511757161\n",
            "Epoch #3. Accuracy on batch 2339/3013  on Training is 85.9067841880342\n",
            "Batch Id 2340 is having training loss of 0.4901857078075409\n",
            "0.5865491032600403\n",
            "Epoch #3. Accuracy on batch 2340/3013  on Training is 85.90746475865015\n",
            "Epoch #3. Accuracy on batch 2341/3013  on Training is 85.90681041844577\n",
            "Epoch #3. Accuracy on batch 2342/3013  on Training is 85.90348911651729\n",
            "Epoch #3. Accuracy on batch 2343/3013  on Training is 85.90550341296928\n",
            "Epoch #3. Accuracy on batch 2344/3013  on Training is 85.90618336886993\n",
            "Epoch #3. Accuracy on batch 2345/3013  on Training is 85.90686274509804\n",
            "Epoch #3. Accuracy on batch 2346/3013  on Training is 85.90754154239454\n",
            "Epoch #3. Accuracy on batch 2347/3013  on Training is 85.90821976149915\n",
            "Epoch #3. Accuracy on batch 2348/3013  on Training is 85.90756704980843\n",
            "Epoch #3. Accuracy on batch 2349/3013  on Training is 85.90824468085107\n",
            "Epoch #3. Accuracy on batch 2350/3013  on Training is 85.90892173543173\n",
            "Epoch #3. Accuracy on batch 2351/3013  on Training is 85.90428358843538\n",
            "Epoch #3. Accuracy on batch 2352/3013  on Training is 85.90097747556311\n",
            "Epoch #3. Accuracy on batch 2353/3013  on Training is 85.90165675446049\n",
            "Epoch #3. Accuracy on batch 2354/3013  on Training is 85.90366242038216\n",
            "Epoch #3. Accuracy on batch 2355/3013  on Training is 85.90831918505943\n",
            "Epoch #3. Accuracy on batch 2356/3013  on Training is 85.90899448451421\n",
            "Epoch #3. Accuracy on batch 2357/3013  on Training is 85.90966921119593\n",
            "Epoch #3. Accuracy on batch 2358/3013  on Training is 85.9129927935566\n",
            "Epoch #3. Accuracy on batch 2359/3013  on Training is 85.91366525423729\n",
            "Batch Id 2360 is having training loss of 0.49038293957710266\n",
            "0.5718064904212952\n",
            "Epoch #3. Accuracy on batch 2360/3013  on Training is 85.91301355357899\n",
            "Epoch #3. Accuracy on batch 2361/3013  on Training is 85.91368543607112\n",
            "Epoch #3. Accuracy on batch 2362/3013  on Training is 85.9143567498942\n",
            "Epoch #3. Accuracy on batch 2363/3013  on Training is 85.91634940778341\n",
            "Epoch #3. Accuracy on batch 2364/3013  on Training is 85.92098308668076\n",
            "Epoch #3. Accuracy on batch 2365/3013  on Training is 85.92429205409975\n",
            "Epoch #3. Accuracy on batch 2366/3013  on Training is 85.92363751584284\n",
            "Epoch #3. Accuracy on batch 2367/3013  on Training is 85.92694256756756\n",
            "Epoch #3. Accuracy on batch 2368/3013  on Training is 85.93024482904178\n",
            "Epoch #3. Accuracy on batch 2369/3013  on Training is 85.93090717299577\n",
            "Epoch #3. Accuracy on batch 2370/3013  on Training is 85.93156895824546\n",
            "Epoch #3. Accuracy on batch 2371/3013  on Training is 85.92696037099495\n",
            "Epoch #3. Accuracy on batch 2372/3013  on Training is 85.92762326169405\n",
            "Epoch #3. Accuracy on batch 2373/3013  on Training is 85.9230202190396\n",
            "Epoch #3. Accuracy on batch 2374/3013  on Training is 85.91973684210527\n",
            "Epoch #3. Accuracy on batch 2375/3013  on Training is 85.9190867003367\n",
            "Epoch #3. Accuracy on batch 2376/3013  on Training is 85.91975178796802\n",
            "Epoch #3. Accuracy on batch 2377/3013  on Training is 85.91910218671153\n",
            "Epoch #3. Accuracy on batch 2378/3013  on Training is 85.91845313156789\n",
            "Epoch #3. Accuracy on batch 2379/3013  on Training is 85.91911764705883\n",
            "Batch Id 2380 is having training loss of 0.4905308187007904\n",
            "0.48821061849594116\n",
            "Epoch #3. Accuracy on batch 2380/3013  on Training is 85.92109407811844\n",
            "Epoch #3. Accuracy on batch 2381/3013  on Training is 85.92306884970613\n",
            "Epoch #3. Accuracy on batch 2382/3013  on Training is 85.92110784725136\n",
            "Epoch #3. Accuracy on batch 2383/3013  on Training is 85.91914848993288\n",
            "Epoch #3. Accuracy on batch 2384/3013  on Training is 85.91719077568135\n",
            "Epoch #3. Accuracy on batch 2385/3013  on Training is 85.91130553227158\n",
            "Epoch #3. Accuracy on batch 2386/3013  on Training is 85.90935274403016\n",
            "Epoch #3. Accuracy on batch 2387/3013  on Training is 85.90609296482413\n",
            "Epoch #3. Accuracy on batch 2388/3013  on Training is 85.90806822938468\n",
            "Epoch #3. Accuracy on batch 2389/3013  on Training is 85.9126569037657\n",
            "Epoch #3. Accuracy on batch 2390/3013  on Training is 85.90809284818067\n",
            "Epoch #3. Accuracy on batch 2391/3013  on Training is 85.9113712374582\n",
            "Epoch #3. Accuracy on batch 2392/3013  on Training is 85.90811742582532\n",
            "Epoch #3. Accuracy on batch 2393/3013  on Training is 85.90486633249792\n",
            "Epoch #3. Accuracy on batch 2394/3013  on Training is 85.90422755741128\n",
            "Epoch #3. Accuracy on batch 2395/3013  on Training is 85.90358931552588\n",
            "Epoch #3. Accuracy on batch 2396/3013  on Training is 85.90425531914893\n",
            "Epoch #3. Accuracy on batch 2397/3013  on Training is 85.9075271059216\n",
            "Epoch #3. Accuracy on batch 2398/3013  on Training is 85.90819091288037\n",
            "Epoch #3. Accuracy on batch 2399/3013  on Training is 85.90885416666667\n",
            "Batch Id 2400 is having training loss of 0.49071890115737915\n",
            "0.24277545511722565\n",
            "Epoch #3. Accuracy on batch 2400/3013  on Training is 85.91081840899625\n",
            "Epoch #3. Accuracy on batch 2401/3013  on Training is 85.91408201498751\n",
            "Epoch #3. Accuracy on batch 2402/3013  on Training is 85.91214107365792\n",
            "Epoch #3. Accuracy on batch 2403/3013  on Training is 85.91020174708818\n",
            "Epoch #3. Accuracy on batch 2404/3013  on Training is 85.91216216216216\n",
            "Epoch #3. Accuracy on batch 2405/3013  on Training is 85.91671862011637\n",
            "Epoch #3. Accuracy on batch 2406/3013  on Training is 85.91477980889074\n",
            "Epoch #3. Accuracy on batch 2407/3013  on Training is 85.91673588039868\n",
            "Epoch #3. Accuracy on batch 2408/3013  on Training is 85.92128476546284\n",
            "Epoch #3. Accuracy on batch 2409/3013  on Training is 85.92453319502074\n",
            "Epoch #3. Accuracy on batch 2410/3013  on Training is 85.92648278722521\n",
            "Epoch #3. Accuracy on batch 2411/3013  on Training is 85.924543946932\n",
            "Epoch #3. Accuracy on batch 2412/3013  on Training is 85.92131164525487\n",
            "Epoch #3. Accuracy on batch 2413/3013  on Training is 85.91678748964374\n",
            "Epoch #3. Accuracy on batch 2414/3013  on Training is 85.91873706004141\n",
            "Epoch #3. Accuracy on batch 2415/3013  on Training is 85.9168046357616\n",
            "Epoch #3. Accuracy on batch 2416/3013  on Training is 85.91616673562267\n",
            "Epoch #3. Accuracy on batch 2417/3013  on Training is 85.91552936311001\n",
            "Epoch #3. Accuracy on batch 2418/3013  on Training is 85.91489251756924\n",
            "Epoch #3. Accuracy on batch 2419/3013  on Training is 85.91554752066116\n",
            "Batch Id 2420 is having training loss of 0.49039068818092346\n",
            "0.3112454414367676\n",
            "Epoch #3. Accuracy on batch 2420/3013  on Training is 85.91749277158199\n",
            "Epoch #3. Accuracy on batch 2421/3013  on Training is 85.9168559042114\n",
            "Epoch #3. Accuracy on batch 2422/3013  on Training is 85.91879900949236\n",
            "Epoch #3. Accuracy on batch 2423/3013  on Training is 85.91816212871286\n",
            "Epoch #3. Accuracy on batch 2424/3013  on Training is 85.91623711340206\n",
            "Epoch #3. Accuracy on batch 2425/3013  on Training is 85.91044929925803\n",
            "Epoch #3. Accuracy on batch 2426/3013  on Training is 85.9136794396374\n",
            "Epoch #3. Accuracy on batch 2427/3013  on Training is 85.91433278418451\n",
            "Epoch #3. Accuracy on batch 2428/3013  on Training is 85.9098394400988\n",
            "Epoch #3. Accuracy on batch 2429/3013  on Training is 85.90792181069959\n",
            "Epoch #3. Accuracy on batch 2430/3013  on Training is 85.90600575894693\n",
            "Epoch #3. Accuracy on batch 2431/3013  on Training is 85.90280633223684\n",
            "Epoch #3. Accuracy on batch 2432/3013  on Training is 85.90346280312372\n",
            "Epoch #3. Accuracy on batch 2433/3013  on Training is 85.90411873459327\n",
            "Epoch #3. Accuracy on batch 2434/3013  on Training is 85.90220739219713\n",
            "Epoch #3. Accuracy on batch 2435/3013  on Training is 85.9054289819376\n",
            "Epoch #3. Accuracy on batch 2436/3013  on Training is 85.90223635617562\n",
            "Epoch #3. Accuracy on batch 2437/3013  on Training is 85.90545529122231\n",
            "Epoch #3. Accuracy on batch 2438/3013  on Training is 85.90354653546535\n",
            "Epoch #3. Accuracy on batch 2439/3013  on Training is 85.90420081967213\n",
            "Batch Id 2440 is having training loss of 0.490803986787796\n",
            "0.604061484336853\n",
            "Epoch #3. Accuracy on batch 2440/3013  on Training is 85.90357435477263\n",
            "Epoch #3. Accuracy on batch 2441/3013  on Training is 85.90038902538903\n",
            "Epoch #3. Accuracy on batch 2442/3013  on Training is 85.89848546868605\n",
            "Epoch #3. Accuracy on batch 2443/3013  on Training is 85.89786211129297\n",
            "Epoch #3. Accuracy on batch 2444/3013  on Training is 85.89596114519428\n",
            "Epoch #3. Accuracy on batch 2445/3013  on Training is 85.89917211774325\n",
            "Epoch #3. Accuracy on batch 2446/3013  on Training is 85.89727217000409\n",
            "Epoch #3. Accuracy on batch 2447/3013  on Training is 85.8953737745098\n",
            "Epoch #3. Accuracy on batch 2448/3013  on Training is 85.89730502245814\n",
            "Epoch #3. Accuracy on batch 2449/3013  on Training is 85.8954081632653\n",
            "Epoch #3. Accuracy on batch 2450/3013  on Training is 85.89351285189719\n",
            "Epoch #3. Accuracy on batch 2451/3013  on Training is 85.89416802610114\n",
            "Epoch #3. Accuracy on batch 2452/3013  on Training is 85.89354871585813\n",
            "Epoch #3. Accuracy on batch 2453/3013  on Training is 85.89802363488182\n",
            "Epoch #3. Accuracy on batch 2454/3013  on Training is 85.89867617107943\n",
            "Epoch #3. Accuracy on batch 2455/3013  on Training is 85.89551099348535\n",
            "Epoch #3. Accuracy on batch 2456/3013  on Training is 85.89489214489214\n",
            "Epoch #3. Accuracy on batch 2457/3013  on Training is 85.89554515866558\n",
            "Epoch #3. Accuracy on batch 2458/3013  on Training is 85.89492679951199\n",
            "Epoch #3. Accuracy on batch 2459/3013  on Training is 85.89176829268293\n",
            "Batch Id 2460 is having training loss of 0.4909888803958893\n",
            "0.39133238792419434\n",
            "Epoch #3. Accuracy on batch 2460/3013  on Training is 85.8911519707436\n",
            "Epoch #3. Accuracy on batch 2461/3013  on Training is 85.88799756295694\n",
            "Epoch #3. Accuracy on batch 2462/3013  on Training is 85.88611449451888\n",
            "Epoch #3. Accuracy on batch 2463/3013  on Training is 85.88296469155844\n",
            "Epoch #3. Accuracy on batch 2464/3013  on Training is 85.88362068965517\n",
            "Epoch #3. Accuracy on batch 2465/3013  on Training is 85.88554339010544\n",
            "Epoch #3. Accuracy on batch 2466/3013  on Training is 85.8849310903932\n",
            "Epoch #3. Accuracy on batch 2467/3013  on Training is 85.88305307941653\n",
            "Epoch #3. Accuracy on batch 2468/3013  on Training is 85.88117658971244\n",
            "Epoch #3. Accuracy on batch 2469/3013  on Training is 85.88183198380567\n",
            "Epoch #3. Accuracy on batch 2470/3013  on Training is 85.87869283690813\n",
            "Epoch #3. Accuracy on batch 2471/3013  on Training is 85.87808454692556\n",
            "Epoch #3. Accuracy on batch 2472/3013  on Training is 85.87494945410432\n",
            "Epoch #3. Accuracy on batch 2473/3013  on Training is 85.87686944219887\n",
            "Epoch #3. Accuracy on batch 2474/3013  on Training is 85.87878787878788\n",
            "Epoch #3. Accuracy on batch 2475/3013  on Training is 85.87818053311793\n",
            "Epoch #3. Accuracy on batch 2476/3013  on Training is 85.88135849818329\n",
            "Epoch #3. Accuracy on batch 2477/3013  on Training is 85.88327280064568\n",
            "Epoch #3. Accuracy on batch 2478/3013  on Training is 85.88140379185155\n",
            "Epoch #3. Accuracy on batch 2479/3013  on Training is 85.88079637096774\n",
            "Batch Id 2480 is having training loss of 0.49130165576934814\n",
            "0.4259197413921356\n",
            "Epoch #3. Accuracy on batch 2480/3013  on Training is 85.88270858524788\n",
            "Epoch #3. Accuracy on batch 2481/3013  on Training is 85.88461925866237\n",
            "Epoch #3. Accuracy on batch 2482/3013  on Training is 85.88401127668143\n",
            "Epoch #3. Accuracy on batch 2483/3013  on Training is 85.88466183574879\n",
            "Epoch #3. Accuracy on batch 2484/3013  on Training is 85.88908450704226\n",
            "Epoch #3. Accuracy on batch 2485/3013  on Training is 85.8884754625905\n",
            "Epoch #3. Accuracy on batch 2486/3013  on Training is 85.88912344189787\n",
            "Epoch #3. Accuracy on batch 2487/3013  on Training is 85.88851487138264\n",
            "Epoch #3. Accuracy on batch 2488/3013  on Training is 85.8916733627963\n",
            "Epoch #3. Accuracy on batch 2489/3013  on Training is 85.88855421686748\n",
            "Epoch #3. Accuracy on batch 2490/3013  on Training is 85.89045564030509\n",
            "Epoch #3. Accuracy on batch 2491/3013  on Training is 85.8923555377207\n",
            "Epoch #3. Accuracy on batch 2492/3013  on Training is 85.8904933814681\n",
            "Epoch #3. Accuracy on batch 2493/3013  on Training is 85.88988572574178\n",
            "Epoch #3. Accuracy on batch 2494/3013  on Training is 85.89178356713427\n",
            "Epoch #3. Accuracy on batch 2495/3013  on Training is 85.89367988782051\n",
            "Epoch #3. Accuracy on batch 2496/3013  on Training is 85.89307168602323\n",
            "Epoch #3. Accuracy on batch 2497/3013  on Training is 85.89371497197759\n",
            "Epoch #3. Accuracy on batch 2498/3013  on Training is 85.890606242497\n",
            "Epoch #3. Accuracy on batch 2499/3013  on Training is 85.89125\n",
            "Batch Id 2500 is having training loss of 0.4911549389362335\n",
            "0.603442370891571\n",
            "Epoch #3. Accuracy on batch 2500/3013  on Training is 85.88689524190323\n",
            "Epoch #3. Accuracy on batch 2501/3013  on Training is 85.88629096722622\n",
            "Epoch #3. Accuracy on batch 2502/3013  on Training is 85.88568717538953\n",
            "Epoch #3. Accuracy on batch 2503/3013  on Training is 85.88133985623003\n",
            "Epoch #3. Accuracy on batch 2504/3013  on Training is 85.87824351297405\n",
            "Epoch #3. Accuracy on batch 2505/3013  on Training is 85.87514964086193\n",
            "Epoch #3. Accuracy on batch 2506/3013  on Training is 85.87330474670921\n",
            "Epoch #3. Accuracy on batch 2507/3013  on Training is 85.87519936204147\n",
            "Epoch #3. Accuracy on batch 2508/3013  on Training is 85.87584695097648\n",
            "Epoch #3. Accuracy on batch 2509/3013  on Training is 85.87649402390439\n",
            "Epoch #3. Accuracy on batch 2510/3013  on Training is 85.87714058144165\n",
            "Epoch #3. Accuracy on batch 2511/3013  on Training is 85.88027468152866\n",
            "Epoch #3. Accuracy on batch 2512/3013  on Training is 85.88216275368086\n",
            "Epoch #3. Accuracy on batch 2513/3013  on Training is 85.87907716785999\n",
            "Epoch #3. Accuracy on batch 2514/3013  on Training is 85.8772365805169\n",
            "Epoch #3. Accuracy on batch 2515/3013  on Training is 85.87663950715421\n",
            "Epoch #3. Accuracy on batch 2516/3013  on Training is 85.87480135081447\n",
            "Epoch #3. Accuracy on batch 2517/3013  on Training is 85.87668784749802\n",
            "Epoch #3. Accuracy on batch 2518/3013  on Training is 85.8785728463676\n",
            "Epoch #3. Accuracy on batch 2519/3013  on Training is 85.88169642857143\n",
            "Batch Id 2520 is having training loss of 0.49121713638305664\n",
            "0.4308536946773529\n",
            "Epoch #3. Accuracy on batch 2520/3013  on Training is 85.88109877032923\n",
            "Epoch #3. Accuracy on batch 2521/3013  on Training is 85.87554520222047\n",
            "Epoch #3. Accuracy on batch 2522/3013  on Training is 85.87742766547761\n",
            "Epoch #3. Accuracy on batch 2523/3013  on Training is 85.88302297939778\n",
            "Epoch #3. Accuracy on batch 2524/3013  on Training is 85.88366336633663\n",
            "Epoch #3. Accuracy on batch 2525/3013  on Training is 85.88801464766429\n",
            "Epoch #3. Accuracy on batch 2526/3013  on Training is 85.88865255243371\n",
            "Epoch #3. Accuracy on batch 2527/3013  on Training is 85.88928995253164\n",
            "Epoch #3. Accuracy on batch 2528/3013  on Training is 85.88498418347173\n",
            "Epoch #3. Accuracy on batch 2529/3013  on Training is 85.88191699604744\n",
            "Epoch #3. Accuracy on batch 2530/3013  on Training is 85.88008692216515\n",
            "Epoch #3. Accuracy on batch 2531/3013  on Training is 85.88072669826224\n",
            "Epoch #3. Accuracy on batch 2532/3013  on Training is 85.8739636794315\n",
            "Epoch #3. Accuracy on batch 2533/3013  on Training is 85.87090568271508\n",
            "Epoch #3. Accuracy on batch 2534/3013  on Training is 85.8715483234714\n",
            "Epoch #3. Accuracy on batch 2535/3013  on Training is 85.86726143533123\n",
            "Epoch #3. Accuracy on batch 2536/3013  on Training is 85.86790500591249\n",
            "Epoch #3. Accuracy on batch 2537/3013  on Training is 85.86977935382191\n",
            "Epoch #3. Accuracy on batch 2538/3013  on Training is 85.86672902717605\n",
            "Epoch #3. Accuracy on batch 2539/3013  on Training is 85.86737204724409\n",
            "Batch Id 2540 is having training loss of 0.4915403723716736\n",
            "0.7293100953102112\n",
            "Epoch #3. Accuracy on batch 2540/3013  on Training is 85.86801456119638\n",
            "Epoch #3. Accuracy on batch 2541/3013  on Training is 85.8698859166011\n",
            "Epoch #3. Accuracy on batch 2542/3013  on Training is 85.87175580023595\n",
            "Epoch #3. Accuracy on batch 2543/3013  on Training is 85.87116745283019\n",
            "Epoch #3. Accuracy on batch 2544/3013  on Training is 85.87057956777996\n",
            "Epoch #3. Accuracy on batch 2545/3013  on Training is 85.86876472898665\n",
            "Epoch #3. Accuracy on batch 2546/3013  on Training is 85.87308598351001\n",
            "Epoch #3. Accuracy on batch 2547/3013  on Training is 85.87372448979592\n",
            "Epoch #3. Accuracy on batch 2548/3013  on Training is 85.8731365241271\n",
            "Epoch #3. Accuracy on batch 2549/3013  on Training is 85.875\n",
            "Epoch #3. Accuracy on batch 2550/3013  on Training is 85.87318698549588\n",
            "Epoch #3. Accuracy on batch 2551/3013  on Training is 85.87504898119123\n",
            "Epoch #3. Accuracy on batch 2552/3013  on Training is 85.87568546807677\n",
            "Epoch #3. Accuracy on batch 2553/3013  on Training is 85.87509788566953\n",
            "Epoch #3. Accuracy on batch 2554/3013  on Training is 85.87084148727985\n",
            "Epoch #3. Accuracy on batch 2555/3013  on Training is 85.87147887323944\n",
            "Epoch #3. Accuracy on batch 2556/3013  on Training is 85.87578216660148\n",
            "Epoch #3. Accuracy on batch 2557/3013  on Training is 85.87886043784206\n",
            "Epoch #3. Accuracy on batch 2558/3013  on Training is 85.88071512309496\n",
            "Epoch #3. Accuracy on batch 2559/3013  on Training is 85.88134765625\n",
            "Batch Id 2560 is having training loss of 0.49140453338623047\n",
            "1.0113513469696045\n",
            "Epoch #3. Accuracy on batch 2560/3013  on Training is 85.87709878953534\n",
            "Epoch #3. Accuracy on batch 2561/3013  on Training is 85.87651249024199\n",
            "Epoch #3. Accuracy on batch 2562/3013  on Training is 85.87104955130707\n",
            "Epoch #3. Accuracy on batch 2563/3013  on Training is 85.87168486739469\n",
            "Epoch #3. Accuracy on batch 2564/3013  on Training is 85.86988304093568\n",
            "Epoch #3. Accuracy on batch 2565/3013  on Training is 85.87051831644582\n",
            "Epoch #3. Accuracy on batch 2566/3013  on Training is 85.8675009738995\n",
            "Epoch #3. Accuracy on batch 2567/3013  on Training is 85.86570288161994\n",
            "Epoch #3. Accuracy on batch 2568/3013  on Training is 85.86390618917866\n",
            "Epoch #3. Accuracy on batch 2569/3013  on Training is 85.86454280155642\n",
            "Epoch #3. Accuracy on batch 2570/3013  on Training is 85.86396343835084\n",
            "Epoch #3. Accuracy on batch 2571/3013  on Training is 85.86581454121307\n",
            "Epoch #3. Accuracy on batch 2572/3013  on Training is 85.86159152739992\n",
            "Epoch #3. Accuracy on batch 2573/3013  on Training is 85.85979992229993\n",
            "Epoch #3. Accuracy on batch 2574/3013  on Training is 85.8628640776699\n",
            "Epoch #3. Accuracy on batch 2575/3013  on Training is 85.85743400621118\n",
            "Epoch #3. Accuracy on batch 2576/3013  on Training is 85.8580714008537\n",
            "Epoch #3. Accuracy on batch 2577/3013  on Training is 85.85628394103956\n",
            "Epoch #3. Accuracy on batch 2578/3013  on Training is 85.85328615742536\n",
            "Epoch #3. Accuracy on batch 2579/3013  on Training is 85.85513565891473\n",
            "Batch Id 2580 is having training loss of 0.4920805096626282\n",
            "0.2887404263019562\n",
            "Epoch #3. Accuracy on batch 2580/3013  on Training is 85.85577295621852\n",
            "Epoch #3. Accuracy on batch 2581/3013  on Training is 85.84914794732765\n",
            "Epoch #3. Accuracy on batch 2582/3013  on Training is 85.84615756871854\n",
            "Epoch #3. Accuracy on batch 2583/3013  on Training is 85.84558823529412\n",
            "Epoch #3. Accuracy on batch 2584/3013  on Training is 85.84743713733076\n",
            "Epoch #3. Accuracy on batch 2585/3013  on Training is 85.84686774941996\n",
            "Epoch #3. Accuracy on batch 2586/3013  on Training is 85.8475067645922\n",
            "Epoch #3. Accuracy on batch 2587/3013  on Training is 85.84452279752705\n",
            "Epoch #3. Accuracy on batch 2588/3013  on Training is 85.84516222479722\n",
            "Epoch #3. Accuracy on batch 2589/3013  on Training is 85.85062741312741\n",
            "Epoch #3. Accuracy on batch 2590/3013  on Training is 85.85005789270552\n",
            "Epoch #3. Accuracy on batch 2591/3013  on Training is 85.84828317901234\n",
            "Epoch #3. Accuracy on batch 2592/3013  on Training is 85.84892016968762\n",
            "Epoch #3. Accuracy on batch 2593/3013  on Training is 85.84714726291442\n",
            "Epoch #3. Accuracy on batch 2594/3013  on Training is 85.84537572254335\n",
            "Epoch #3. Accuracy on batch 2595/3013  on Training is 85.84360554699538\n",
            "Epoch #3. Accuracy on batch 2596/3013  on Training is 85.84304004620716\n",
            "Epoch #3. Accuracy on batch 2597/3013  on Training is 85.83886643571978\n",
            "Epoch #3. Accuracy on batch 2598/3013  on Training is 85.84191035013467\n",
            "Epoch #3. Accuracy on batch 2599/3013  on Training is 85.84254807692308\n",
            "Batch Id 2600 is having training loss of 0.49248436093330383\n",
            "0.5331571102142334\n",
            "Epoch #3. Accuracy on batch 2600/3013  on Training is 85.84318531334102\n",
            "Epoch #3. Accuracy on batch 2601/3013  on Training is 85.84262106072252\n",
            "Epoch #3. Accuracy on batch 2602/3013  on Training is 85.8408567038033\n",
            "Epoch #3. Accuracy on batch 2603/3013  on Training is 85.84269393241168\n",
            "Epoch #3. Accuracy on batch 2604/3013  on Training is 85.83853166986565\n",
            "Epoch #3. Accuracy on batch 2605/3013  on Training is 85.83797006907137\n",
            "Epoch #3. Accuracy on batch 2606/3013  on Training is 85.8362102032988\n",
            "Epoch #3. Accuracy on batch 2607/3013  on Training is 85.84044286809817\n",
            "Epoch #3. Accuracy on batch 2608/3013  on Training is 85.83988118052893\n",
            "Epoch #3. Accuracy on batch 2609/3013  on Training is 85.84171455938697\n",
            "Epoch #3. Accuracy on batch 2610/3013  on Training is 85.84474339333589\n",
            "Epoch #3. Accuracy on batch 2611/3013  on Training is 85.84657350689127\n",
            "Epoch #3. Accuracy on batch 2612/3013  on Training is 85.84601033295063\n",
            "Epoch #3. Accuracy on batch 2613/3013  on Training is 85.84783856159143\n",
            "Epoch #3. Accuracy on batch 2614/3013  on Training is 85.84847036328871\n",
            "Epoch #3. Accuracy on batch 2615/3013  on Training is 85.84910168195718\n",
            "Epoch #3. Accuracy on batch 2616/3013  on Training is 85.8545089797478\n",
            "Epoch #3. Accuracy on batch 2617/3013  on Training is 85.8515565317036\n",
            "Epoch #3. Accuracy on batch 2618/3013  on Training is 85.8450267277587\n",
            "Epoch #3. Accuracy on batch 2619/3013  on Training is 85.84804389312977\n",
            "Batch Id 2620 is having training loss of 0.492627888917923\n",
            "0.6213448643684387\n",
            "Epoch #3. Accuracy on batch 2620/3013  on Training is 85.84748187714612\n",
            "Epoch #3. Accuracy on batch 2621/3013  on Training is 85.84453661327231\n",
            "Epoch #3. Accuracy on batch 2622/3013  on Training is 85.84516774685474\n",
            "Epoch #3. Accuracy on batch 2623/3013  on Training is 85.84818025914635\n",
            "Epoch #3. Accuracy on batch 2624/3013  on Training is 85.85\n",
            "Epoch #3. Accuracy on batch 2625/3013  on Training is 85.85181835491241\n",
            "Epoch #3. Accuracy on batch 2626/3013  on Training is 85.84649790635706\n",
            "Epoch #3. Accuracy on batch 2627/3013  on Training is 85.85069444444444\n",
            "Epoch #3. Accuracy on batch 2628/3013  on Training is 85.85013313046785\n",
            "Epoch #3. Accuracy on batch 2629/3013  on Training is 85.85432509505704\n",
            "Epoch #3. Accuracy on batch 2630/3013  on Training is 85.85138730520714\n",
            "Epoch #3. Accuracy on batch 2631/3013  on Training is 85.84963905775076\n",
            "Epoch #3. Accuracy on batch 2632/3013  on Training is 85.84789213824534\n",
            "Epoch #3. Accuracy on batch 2633/3013  on Training is 85.85207858769931\n",
            "Epoch #3. Accuracy on batch 2634/3013  on Training is 85.85270398481974\n",
            "Epoch #3. Accuracy on batch 2635/3013  on Training is 85.85332890743551\n",
            "Epoch #3. Accuracy on batch 2636/3013  on Training is 85.85158323852863\n",
            "Epoch #3. Accuracy on batch 2637/3013  on Training is 85.85339272175891\n",
            "Epoch #3. Accuracy on batch 2638/3013  on Training is 85.85756915498295\n",
            "Epoch #3. Accuracy on batch 2639/3013  on Training is 85.859375\n",
            "Batch Id 2640 is having training loss of 0.49255427718162537\n",
            "0.4953966438770294\n",
            "Epoch #3. Accuracy on batch 2640/3013  on Training is 85.85881294964028\n",
            "Epoch #3. Accuracy on batch 2641/3013  on Training is 85.86061695685088\n",
            "Epoch #3. Accuracy on batch 2642/3013  on Training is 85.86123723041997\n",
            "Epoch #3. Accuracy on batch 2643/3013  on Training is 85.8642208774584\n",
            "Epoch #3. Accuracy on batch 2644/3013  on Training is 85.86365784499054\n",
            "Epoch #3. Accuracy on batch 2645/3013  on Training is 85.86663832199547\n",
            "Epoch #3. Accuracy on batch 2646/3013  on Training is 85.86961654703438\n",
            "Epoch #3. Accuracy on batch 2647/3013  on Training is 85.86787197885197\n",
            "Epoch #3. Accuracy on batch 2648/3013  on Training is 85.87320687051718\n",
            "Epoch #3. Accuracy on batch 2649/3013  on Training is 85.87617924528301\n",
            "Epoch #3. Accuracy on batch 2650/3013  on Training is 85.87679177668804\n",
            "Epoch #3. Accuracy on batch 2651/3013  on Training is 85.87622549019608\n",
            "Epoch #3. Accuracy on batch 2652/3013  on Training is 85.87919336600075\n",
            "Epoch #3. Accuracy on batch 2653/3013  on Training is 85.88098153730219\n",
            "Epoch #3. Accuracy on batch 2654/3013  on Training is 85.87806026365348\n",
            "Epoch #3. Accuracy on batch 2655/3013  on Training is 85.87514118975903\n",
            "Epoch #3. Accuracy on batch 2656/3013  on Training is 85.87340045163718\n",
            "Epoch #3. Accuracy on batch 2657/3013  on Training is 85.87401241534988\n",
            "Epoch #3. Accuracy on batch 2658/3013  on Training is 85.87579917262129\n",
            "Epoch #3. Accuracy on batch 2659/3013  on Training is 85.87993421052632\n",
            "Batch Id 2660 is having training loss of 0.4920312464237213\n",
            "0.3192541003227234\n",
            "Epoch #3. Accuracy on batch 2660/3013  on Training is 85.88289177001127\n",
            "Epoch #3. Accuracy on batch 2661/3013  on Training is 85.8846731780616\n",
            "Epoch #3. Accuracy on batch 2662/3013  on Training is 85.87941231693578\n",
            "Epoch #3. Accuracy on batch 2663/3013  on Training is 85.88236674174175\n",
            "Epoch #3. Accuracy on batch 2664/3013  on Training is 85.88531894934334\n",
            "Epoch #3. Accuracy on batch 2665/3013  on Training is 85.88358027006751\n",
            "Epoch #3. Accuracy on batch 2666/3013  on Training is 85.88184289463817\n",
            "Epoch #3. Accuracy on batch 2667/3013  on Training is 85.88127811094452\n",
            "Epoch #3. Accuracy on batch 2668/3013  on Training is 85.88305545147996\n",
            "Epoch #3. Accuracy on batch 2669/3013  on Training is 85.88014981273409\n",
            "Epoch #3. Accuracy on batch 2670/3013  on Training is 85.87958629726694\n",
            "Epoch #3. Accuracy on batch 2671/3013  on Training is 85.88019273952096\n",
            "Epoch #3. Accuracy on batch 2672/3013  on Training is 85.87729143284699\n",
            "Epoch #3. Accuracy on batch 2673/3013  on Training is 85.87789827973074\n",
            "Epoch #3. Accuracy on batch 2674/3013  on Training is 85.8785046728972\n",
            "Epoch #3. Accuracy on batch 2675/3013  on Training is 85.87327167414051\n",
            "Epoch #3. Accuracy on batch 2676/3013  on Training is 85.87504669406052\n",
            "Epoch #3. Accuracy on batch 2677/3013  on Training is 85.87682038834951\n",
            "Epoch #3. Accuracy on batch 2678/3013  on Training is 85.87625979843224\n",
            "Epoch #3. Accuracy on batch 2679/3013  on Training is 85.88036380597015\n",
            "Batch Id 2680 is having training loss of 0.4921058416366577\n",
            "0.4244132936000824\n",
            "Epoch #3. Accuracy on batch 2680/3013  on Training is 85.88213353226408\n",
            "Epoch #3. Accuracy on batch 2681/3013  on Training is 85.88506711409396\n",
            "Epoch #3. Accuracy on batch 2682/3013  on Training is 85.88450428624674\n",
            "Epoch #3. Accuracy on batch 2683/3013  on Training is 85.8851061847988\n",
            "Epoch #3. Accuracy on batch 2684/3013  on Training is 85.87872439478585\n",
            "Epoch #3. Accuracy on batch 2685/3013  on Training is 85.87583767684289\n",
            "Epoch #3. Accuracy on batch 2686/3013  on Training is 85.87411611462598\n",
            "Epoch #3. Accuracy on batch 2687/3013  on Training is 85.87588355654762\n",
            "Epoch #3. Accuracy on batch 2688/3013  on Training is 85.87532539977687\n",
            "Epoch #3. Accuracy on batch 2689/3013  on Training is 85.87592936802974\n",
            "Epoch #3. Accuracy on batch 2690/3013  on Training is 85.87769416573764\n",
            "Epoch #3. Accuracy on batch 2691/3013  on Training is 85.8759751114413\n",
            "Epoch #3. Accuracy on batch 2692/3013  on Training is 85.87657816561456\n",
            "Epoch #3. Accuracy on batch 2693/3013  on Training is 85.87486080178174\n",
            "Epoch #3. Accuracy on batch 2694/3013  on Training is 85.8754638218924\n",
            "Epoch #3. Accuracy on batch 2695/3013  on Training is 85.87606639465875\n",
            "Epoch #3. Accuracy on batch 2696/3013  on Training is 85.87898591027067\n",
            "Epoch #3. Accuracy on batch 2697/3013  on Training is 85.8761119347665\n",
            "Epoch #3. Accuracy on batch 2698/3013  on Training is 85.8778714338644\n",
            "Epoch #3. Accuracy on batch 2699/3013  on Training is 85.8761574074074\n",
            "Batch Id 2700 is having training loss of 0.4922383725643158\n",
            "0.47069239616394043\n",
            "Epoch #3. Accuracy on batch 2700/3013  on Training is 85.87560162902629\n",
            "Epoch #3. Accuracy on batch 2701/3013  on Training is 85.87504626202812\n",
            "Epoch #3. Accuracy on batch 2702/3013  on Training is 85.87564742878283\n",
            "Epoch #3. Accuracy on batch 2703/3013  on Training is 85.87393676035504\n",
            "Epoch #3. Accuracy on batch 2704/3013  on Training is 85.87453789279112\n",
            "Epoch #3. Accuracy on batch 2705/3013  on Training is 85.8739837398374\n",
            "Epoch #3. Accuracy on batch 2706/3013  on Training is 85.87573882526783\n",
            "Epoch #3. Accuracy on batch 2707/3013  on Training is 85.87403064992614\n",
            "Epoch #3. Accuracy on batch 2708/3013  on Training is 85.8734772978959\n",
            "Epoch #3. Accuracy on batch 2709/3013  on Training is 85.87869003690037\n",
            "Epoch #3. Accuracy on batch 2710/3013  on Training is 85.87928808557727\n",
            "Epoch #3. Accuracy on batch 2711/3013  on Training is 85.88334255162242\n",
            "Epoch #3. Accuracy on batch 2712/3013  on Training is 85.88509030593438\n",
            "Epoch #3. Accuracy on batch 2713/3013  on Training is 85.88683677229182\n",
            "Epoch #3. Accuracy on batch 2714/3013  on Training is 85.88858195211786\n",
            "Epoch #3. Accuracy on batch 2715/3013  on Training is 85.88802466863034\n",
            "Epoch #3. Accuracy on batch 2716/3013  on Training is 85.88861796098638\n",
            "Epoch #3. Accuracy on batch 2717/3013  on Training is 85.8926600441501\n",
            "Epoch #3. Accuracy on batch 2718/3013  on Training is 85.89210187568959\n",
            "Epoch #3. Accuracy on batch 2719/3013  on Training is 85.89728860294117\n",
            "Batch Id 2720 is having training loss of 0.4919109046459198\n",
            "0.5835528373718262\n",
            "Epoch #3. Accuracy on batch 2720/3013  on Training is 85.89672914369717\n",
            "Epoch #3. Accuracy on batch 2721/3013  on Training is 85.896170095518\n",
            "Epoch #3. Accuracy on batch 2722/3013  on Training is 85.89331619537275\n",
            "Epoch #3. Accuracy on batch 2723/3013  on Training is 85.89620044052863\n",
            "Epoch #3. Accuracy on batch 2724/3013  on Training is 85.89678899082568\n",
            "Epoch #3. Accuracy on batch 2725/3013  on Training is 85.8996698459281\n",
            "Epoch #3. Accuracy on batch 2726/3013  on Training is 85.89681884855152\n",
            "Epoch #3. Accuracy on batch 2727/3013  on Training is 85.89740652492668\n",
            "Epoch #3. Accuracy on batch 2728/3013  on Training is 85.89913887871015\n",
            "Epoch #3. Accuracy on batch 2729/3013  on Training is 85.90201465201466\n",
            "Epoch #3. Accuracy on batch 2730/3013  on Training is 85.90603258879531\n",
            "Epoch #3. Accuracy on batch 2731/3013  on Training is 85.90318448023426\n",
            "Epoch #3. Accuracy on batch 2732/3013  on Training is 85.902625320161\n",
            "Epoch #3. Accuracy on batch 2733/3013  on Training is 85.90206656912947\n",
            "Epoch #3. Accuracy on batch 2734/3013  on Training is 85.90379341864717\n",
            "Epoch #3. Accuracy on batch 2735/3013  on Training is 85.90209247076024\n",
            "Epoch #3. Accuracy on batch 2736/3013  on Training is 85.90039276580197\n",
            "Epoch #3. Accuracy on batch 2737/3013  on Training is 85.90097699050402\n",
            "Epoch #3. Accuracy on batch 2738/3013  on Training is 85.90156078860898\n",
            "Epoch #3. Accuracy on batch 2739/3013  on Training is 85.90214416058394\n",
            "Batch Id 2740 is having training loss of 0.49165138602256775\n",
            "0.2666361927986145\n",
            "Epoch #3. Accuracy on batch 2740/3013  on Training is 85.90386720175118\n",
            "Epoch #3. Accuracy on batch 2741/3013  on Training is 85.90558898614151\n",
            "Epoch #3. Accuracy on batch 2742/3013  on Training is 85.90503098796938\n",
            "Epoch #3. Accuracy on batch 2743/3013  on Training is 85.90561224489795\n",
            "Epoch #3. Accuracy on batch 2744/3013  on Training is 85.90277777777777\n",
            "Epoch #3. Accuracy on batch 2745/3013  on Training is 85.90108339402768\n",
            "Epoch #3. Accuracy on batch 2746/3013  on Training is 85.90280305788133\n",
            "Epoch #3. Accuracy on batch 2747/3013  on Training is 85.90224708879185\n",
            "Epoch #3. Accuracy on batch 2748/3013  on Training is 85.90169152419061\n",
            "Epoch #3. Accuracy on batch 2749/3013  on Training is 85.90113636363637\n",
            "Epoch #3. Accuracy on batch 2750/3013  on Training is 85.89944565612504\n",
            "Epoch #3. Accuracy on batch 2751/3013  on Training is 85.90116279069767\n",
            "Epoch #3. Accuracy on batch 2752/3013  on Training is 85.90060842717035\n",
            "Epoch #3. Accuracy on batch 2753/3013  on Training is 85.90232389251997\n",
            "Epoch #3. Accuracy on batch 2754/3013  on Training is 85.89950090744102\n",
            "Epoch #3. Accuracy on batch 2755/3013  on Training is 85.90008164005806\n",
            "Epoch #3. Accuracy on batch 2756/3013  on Training is 85.90519586507072\n",
            "Epoch #3. Accuracy on batch 2757/3013  on Training is 85.90464104423495\n",
            "Epoch #3. Accuracy on batch 2758/3013  on Training is 85.90521928234868\n",
            "Epoch #3. Accuracy on batch 2759/3013  on Training is 85.90466485507247\n",
            "Batch Id 2760 is having training loss of 0.49166205525398254\n",
            "0.4752463400363922\n",
            "Epoch #3. Accuracy on batch 2760/3013  on Training is 85.90297899311844\n",
            "Epoch #3. Accuracy on batch 2761/3013  on Training is 85.90129435191889\n",
            "Epoch #3. Accuracy on batch 2762/3013  on Training is 85.90413499819037\n",
            "Epoch #3. Accuracy on batch 2763/3013  on Training is 85.90358176555716\n",
            "Epoch #3. Accuracy on batch 2764/3013  on Training is 85.90641952983725\n",
            "Epoch #3. Accuracy on batch 2765/3013  on Training is 85.90473608098337\n",
            "Epoch #3. Accuracy on batch 2766/3013  on Training is 85.90644199494037\n",
            "Epoch #3. Accuracy on batch 2767/3013  on Training is 85.90927565028902\n",
            "Epoch #3. Accuracy on batch 2768/3013  on Training is 85.90985012639942\n",
            "Epoch #3. Accuracy on batch 2769/3013  on Training is 85.9115523465704\n",
            "Epoch #3. Accuracy on batch 2770/3013  on Training is 85.90648682785998\n",
            "Epoch #3. Accuracy on batch 2771/3013  on Training is 85.90706168831169\n",
            "Epoch #3. Accuracy on batch 2772/3013  on Training is 85.90876307248467\n",
            "Epoch #3. Accuracy on batch 2773/3013  on Training is 85.90595710165826\n",
            "Epoch #3. Accuracy on batch 2774/3013  on Training is 85.90653153153153\n",
            "Epoch #3. Accuracy on batch 2775/3013  on Training is 85.90710554755043\n",
            "Epoch #3. Accuracy on batch 2776/3013  on Training is 85.90542851998559\n",
            "Epoch #3. Accuracy on batch 2777/3013  on Training is 85.90150287976962\n",
            "Epoch #3. Accuracy on batch 2778/3013  on Training is 85.89982907520691\n",
            "Epoch #3. Accuracy on batch 2779/3013  on Training is 85.90040467625899\n",
            "Batch Id 2780 is having training loss of 0.4919157028198242\n",
            "0.5376043915748596\n",
            "Epoch #3. Accuracy on batch 2780/3013  on Training is 85.89648507731032\n",
            "Epoch #3. Accuracy on batch 2781/3013  on Training is 85.89706146657082\n",
            "Epoch #3. Accuracy on batch 2782/3013  on Training is 85.89876033057851\n",
            "Epoch #3. Accuracy on batch 2783/3013  on Training is 85.90045797413794\n",
            "Epoch #3. Accuracy on batch 2784/3013  on Training is 85.90103231597845\n",
            "Epoch #3. Accuracy on batch 2785/3013  on Training is 85.89936288585785\n",
            "Epoch #3. Accuracy on batch 2786/3013  on Training is 85.89769465374955\n",
            "Epoch #3. Accuracy on batch 2787/3013  on Training is 85.89826936872309\n",
            "Epoch #3. Accuracy on batch 2788/3013  on Training is 85.89212083183936\n",
            "Epoch #3. Accuracy on batch 2789/3013  on Training is 85.88933691756273\n",
            "Epoch #3. Accuracy on batch 2790/3013  on Training is 85.88207631673235\n",
            "Epoch #3. Accuracy on batch 2791/3013  on Training is 85.88153653295129\n",
            "Epoch #3. Accuracy on batch 2792/3013  on Training is 85.88099713569639\n",
            "Epoch #3. Accuracy on batch 2793/3013  on Training is 85.88045812455262\n",
            "Epoch #3. Accuracy on batch 2794/3013  on Training is 85.87768336314848\n",
            "Epoch #3. Accuracy on batch 2795/3013  on Training is 85.87491058655222\n",
            "Epoch #3. Accuracy on batch 2796/3013  on Training is 85.87660886664283\n",
            "Epoch #3. Accuracy on batch 2797/3013  on Training is 85.8760721944246\n",
            "Epoch #3. Accuracy on batch 2798/3013  on Training is 85.87665237584852\n",
            "Epoch #3. Accuracy on batch 2799/3013  on Training is 85.87723214285714\n",
            "Batch Id 2800 is having training loss of 0.4924330711364746\n",
            "0.6093508005142212\n",
            "Epoch #3. Accuracy on batch 2800/3013  on Training is 85.87781149589432\n",
            "Epoch #3. Accuracy on batch 2801/3013  on Training is 85.87615988579586\n",
            "Epoch #3. Accuracy on batch 2802/3013  on Training is 85.87450945415627\n",
            "Epoch #3. Accuracy on batch 2803/3013  on Training is 85.87397467902996\n",
            "Epoch #3. Accuracy on batch 2804/3013  on Training is 85.87121212121212\n",
            "Epoch #3. Accuracy on batch 2805/3013  on Training is 85.86733784746971\n",
            "Epoch #3. Accuracy on batch 2806/3013  on Training is 85.8679194869968\n",
            "Epoch #3. Accuracy on batch 2807/3013  on Training is 85.86627492877493\n",
            "Epoch #3. Accuracy on batch 2808/3013  on Training is 85.86463154147384\n",
            "Epoch #3. Accuracy on batch 2809/3013  on Training is 85.8663256227758\n",
            "Epoch #3. Accuracy on batch 2810/3013  on Training is 85.86801849875489\n",
            "Epoch #3. Accuracy on batch 2811/3013  on Training is 85.86637624466572\n",
            "Epoch #3. Accuracy on batch 2812/3013  on Training is 85.86362424457874\n",
            "Epoch #3. Accuracy on batch 2813/3013  on Training is 85.86642679459844\n",
            "Epoch #3. Accuracy on batch 2814/3013  on Training is 85.8614564831261\n",
            "Epoch #3. Accuracy on batch 2815/3013  on Training is 85.8609286221591\n",
            "Epoch #3. Accuracy on batch 2816/3013  on Training is 85.86040113596025\n",
            "Epoch #3. Accuracy on batch 2817/3013  on Training is 85.86098296664301\n",
            "Epoch #3. Accuracy on batch 2818/3013  on Training is 85.86156438453352\n",
            "Epoch #3. Accuracy on batch 2819/3013  on Training is 85.86325354609929\n",
            "Batch Id 2820 is having training loss of 0.49267399311065674\n",
            "0.397015243768692\n",
            "Epoch #3. Accuracy on batch 2820/3013  on Training is 85.8649415101028\n",
            "Epoch #3. Accuracy on batch 2821/3013  on Training is 85.86219879518072\n",
            "Epoch #3. Accuracy on batch 2822/3013  on Training is 85.86499291533829\n",
            "Epoch #3. Accuracy on batch 2823/3013  on Training is 85.86667847025495\n",
            "Epoch #3. Accuracy on batch 2824/3013  on Training is 85.86061946902655\n",
            "Epoch #3. Accuracy on batch 2825/3013  on Training is 85.85788216560509\n",
            "Epoch #3. Accuracy on batch 2826/3013  on Training is 85.8562522108242\n",
            "Epoch #3. Accuracy on batch 2827/3013  on Training is 85.85241336633663\n",
            "Epoch #3. Accuracy on batch 2828/3013  on Training is 85.85410038882998\n",
            "Epoch #3. Accuracy on batch 2829/3013  on Training is 85.8535777385159\n",
            "Epoch #3. Accuracy on batch 2830/3013  on Training is 85.85415930766514\n",
            "Epoch #3. Accuracy on batch 2831/3013  on Training is 85.85143008474576\n",
            "Epoch #3. Accuracy on batch 2832/3013  on Training is 85.85421814331097\n",
            "Epoch #3. Accuracy on batch 2833/3013  on Training is 85.85590155257586\n",
            "Epoch #3. Accuracy on batch 2834/3013  on Training is 85.85537918871252\n",
            "Epoch #3. Accuracy on batch 2835/3013  on Training is 85.85706100141044\n",
            "Epoch #3. Accuracy on batch 2836/3013  on Training is 85.85984314416638\n",
            "Epoch #3. Accuracy on batch 2837/3013  on Training is 85.85821881606765\n",
            "Epoch #3. Accuracy on batch 2838/3013  on Training is 85.85769637196196\n",
            "Epoch #3. Accuracy on batch 2839/3013  on Training is 85.85387323943662\n",
            "Batch Id 2840 is having training loss of 0.4931192696094513\n",
            "0.23910334706306458\n",
            "Epoch #3. Accuracy on batch 2840/3013  on Training is 85.85665258711721\n",
            "Epoch #3. Accuracy on batch 2841/3013  on Training is 85.85393209007741\n",
            "Epoch #3. Accuracy on batch 2842/3013  on Training is 85.85561027084066\n",
            "Epoch #3. Accuracy on batch 2843/3013  on Training is 85.85618846694796\n",
            "Epoch #3. Accuracy on batch 2844/3013  on Training is 85.85237258347979\n",
            "Epoch #3. Accuracy on batch 2845/3013  on Training is 85.85075544624034\n",
            "Epoch #3. Accuracy on batch 2846/3013  on Training is 85.85023709167545\n",
            "Epoch #3. Accuracy on batch 2847/3013  on Training is 85.84862183988764\n",
            "Epoch #3. Accuracy on batch 2848/3013  on Training is 85.85029835029835\n",
            "Epoch #3. Accuracy on batch 2849/3013  on Training is 85.84868421052632\n",
            "Epoch #3. Accuracy on batch 2850/3013  on Training is 85.85145562960365\n",
            "Epoch #3. Accuracy on batch 2851/3013  on Training is 85.85422510518934\n",
            "Epoch #3. Accuracy on batch 2852/3013  on Training is 85.85589730108657\n",
            "Epoch #3. Accuracy on batch 2853/3013  on Training is 85.85866327960757\n",
            "Epoch #3. Accuracy on batch 2854/3013  on Training is 85.85814360770578\n",
            "Epoch #3. Accuracy on batch 2855/3013  on Training is 85.85762429971989\n",
            "Epoch #3. Accuracy on batch 2856/3013  on Training is 85.86038676933846\n",
            "Epoch #3. Accuracy on batch 2857/3013  on Training is 85.85877361791462\n",
            "Epoch #3. Accuracy on batch 2858/3013  on Training is 85.8604407135362\n",
            "Epoch #3. Accuracy on batch 2859/3013  on Training is 85.86101398601399\n",
            "Batch Id 2860 is having training loss of 0.49307090044021606\n",
            "0.6190704107284546\n",
            "Epoch #3. Accuracy on batch 2860/3013  on Training is 85.85831003145753\n",
            "Epoch #3. Accuracy on batch 2861/3013  on Training is 85.85342417889588\n",
            "Epoch #3. Accuracy on batch 2862/3013  on Training is 85.85399930143207\n",
            "Epoch #3. Accuracy on batch 2863/3013  on Training is 85.85893854748603\n",
            "Epoch #3. Accuracy on batch 2864/3013  on Training is 85.85514834205934\n",
            "Epoch #3. Accuracy on batch 2865/3013  on Training is 85.8491800418702\n",
            "Epoch #3. Accuracy on batch 2866/3013  on Training is 85.85084583188001\n",
            "Epoch #3. Accuracy on batch 2867/3013  on Training is 85.85033124128313\n",
            "Epoch #3. Accuracy on batch 2868/3013  on Training is 85.85199546880446\n",
            "Epoch #3. Accuracy on batch 2869/3013  on Training is 85.85365853658537\n",
            "Epoch #3. Accuracy on batch 2870/3013  on Training is 85.85314350400557\n",
            "Epoch #3. Accuracy on batch 2871/3013  on Training is 85.85371692200557\n",
            "Epoch #3. Accuracy on batch 2872/3013  on Training is 85.85320222763661\n",
            "Epoch #3. Accuracy on batch 2873/3013  on Training is 85.85486256089075\n",
            "Epoch #3. Accuracy on batch 2874/3013  on Training is 85.85434782608695\n",
            "Epoch #3. Accuracy on batch 2875/3013  on Training is 85.8549200278164\n",
            "Epoch #3. Accuracy on batch 2876/3013  on Training is 85.85875043448036\n",
            "Epoch #3. Accuracy on batch 2877/3013  on Training is 85.8604065323141\n",
            "Epoch #3. Accuracy on batch 2878/3013  on Training is 85.86097603334491\n",
            "Epoch #3. Accuracy on batch 2879/3013  on Training is 85.86263020833333\n",
            "Batch Id 2880 is having training loss of 0.4928414523601532\n",
            "0.43535861372947693\n",
            "Epoch #3. Accuracy on batch 2880/3013  on Training is 85.86428323498785\n",
            "Epoch #3. Accuracy on batch 2881/3013  on Training is 85.8648507980569\n",
            "Epoch #3. Accuracy on batch 2882/3013  on Training is 85.8621661463753\n",
            "Epoch #3. Accuracy on batch 2883/3013  on Training is 85.8616504854369\n",
            "Epoch #3. Accuracy on batch 2884/3013  on Training is 85.8578856152513\n",
            "Epoch #3. Accuracy on batch 2885/3013  on Training is 85.85953742203742\n",
            "Epoch #3. Accuracy on batch 2886/3013  on Training is 85.85902320748181\n",
            "Epoch #3. Accuracy on batch 2887/3013  on Training is 85.8617555401662\n",
            "Epoch #3. Accuracy on batch 2888/3013  on Training is 85.8623226029768\n",
            "Epoch #3. Accuracy on batch 2889/3013  on Training is 85.86180795847751\n",
            "Epoch #3. Accuracy on batch 2890/3013  on Training is 85.8634555517122\n",
            "Epoch #3. Accuracy on batch 2891/3013  on Training is 85.86294087136929\n",
            "Epoch #3. Accuracy on batch 2892/3013  on Training is 85.86350674040789\n",
            "Epoch #3. Accuracy on batch 2893/3013  on Training is 85.86407221838286\n",
            "Epoch #3. Accuracy on batch 2894/3013  on Training is 85.86463730569949\n",
            "Epoch #3. Accuracy on batch 2895/3013  on Training is 85.8641229281768\n",
            "Epoch #3. Accuracy on batch 2896/3013  on Training is 85.86468760787021\n",
            "Epoch #3. Accuracy on batch 2897/3013  on Training is 85.86309523809524\n",
            "Epoch #3. Accuracy on batch 2898/3013  on Training is 85.86150396688514\n",
            "Epoch #3. Accuracy on batch 2899/3013  on Training is 85.86422413793103\n",
            "Batch Id 2900 is having training loss of 0.4931398332118988\n",
            "0.45766088366508484\n",
            "Epoch #3. Accuracy on batch 2900/3013  on Training is 85.86263357462944\n",
            "Epoch #3. Accuracy on batch 2901/3013  on Training is 85.8664283252929\n",
            "Epoch #3. Accuracy on batch 2902/3013  on Training is 85.86806751636239\n",
            "Epoch #3. Accuracy on batch 2903/3013  on Training is 85.8697055785124\n",
            "Epoch #3. Accuracy on batch 2904/3013  on Training is 85.8670395869191\n",
            "Epoch #3. Accuracy on batch 2905/3013  on Training is 85.86222470750172\n",
            "Epoch #3. Accuracy on batch 2906/3013  on Training is 85.85956312349501\n",
            "Epoch #3. Accuracy on batch 2907/3013  on Training is 85.86120185694635\n",
            "Epoch #3. Accuracy on batch 2908/3013  on Training is 85.85854245445171\n",
            "Epoch #3. Accuracy on batch 2909/3013  on Training is 85.85910652920963\n",
            "Epoch #3. Accuracy on batch 2910/3013  on Training is 85.85752318790793\n",
            "Epoch #3. Accuracy on batch 2911/3013  on Training is 85.85701407967034\n",
            "Epoch #3. Accuracy on batch 2912/3013  on Training is 85.85757809818057\n",
            "Epoch #3. Accuracy on batch 2913/3013  on Training is 85.85170727522306\n",
            "Epoch #3. Accuracy on batch 2914/3013  on Training is 85.85012864493997\n",
            "Epoch #3. Accuracy on batch 2915/3013  on Training is 85.8485510973937\n",
            "Epoch #3. Accuracy on batch 2916/3013  on Training is 85.85125985601645\n",
            "Epoch #3. Accuracy on batch 2917/3013  on Training is 85.85289581905414\n",
            "Epoch #3. Accuracy on batch 2918/3013  on Training is 85.85131894484412\n",
            "Epoch #3. Accuracy on batch 2919/3013  on Training is 85.84760273972603\n",
            "Batch Id 2920 is having training loss of 0.49347013235092163\n",
            "0.2984118163585663\n",
            "Epoch #3. Accuracy on batch 2920/3013  on Training is 85.8492382745635\n",
            "Epoch #3. Accuracy on batch 2921/3013  on Training is 85.84873374401096\n",
            "Epoch #3. Accuracy on batch 2922/3013  on Training is 85.84929866575436\n",
            "Epoch #3. Accuracy on batch 2923/3013  on Training is 85.8498632010944\n",
            "Epoch #3. Accuracy on batch 2924/3013  on Training is 85.85042735042735\n",
            "Epoch #3. Accuracy on batch 2925/3013  on Training is 85.85099111414901\n",
            "Epoch #3. Accuracy on batch 2926/3013  on Training is 85.85262213870857\n",
            "Epoch #3. Accuracy on batch 2927/3013  on Training is 85.85318476775956\n",
            "Epoch #3. Accuracy on batch 2928/3013  on Training is 85.85268009559577\n",
            "Epoch #3. Accuracy on batch 2929/3013  on Training is 85.85110921501706\n",
            "Epoch #3. Accuracy on batch 2930/3013  on Training is 85.85060559535995\n",
            "Epoch #3. Accuracy on batch 2931/3013  on Training is 85.85223396998636\n",
            "Epoch #3. Accuracy on batch 2932/3013  on Training is 85.85173031026252\n",
            "Epoch #3. Accuracy on batch 2933/3013  on Training is 85.85122699386503\n",
            "Epoch #3. Accuracy on batch 2934/3013  on Training is 85.84752981260647\n",
            "Epoch #3. Accuracy on batch 2935/3013  on Training is 85.84596389645776\n",
            "Epoch #3. Accuracy on batch 2936/3013  on Training is 85.8454630575417\n",
            "Epoch #3. Accuracy on batch 2937/3013  on Training is 85.8470898570456\n",
            "Epoch #3. Accuracy on batch 2938/3013  on Training is 85.84765226267437\n",
            "Epoch #3. Accuracy on batch 2939/3013  on Training is 85.84715136054422\n",
            "Batch Id 2940 is having training loss of 0.49374985694885254\n",
            "0.5281694531440735\n",
            "Epoch #3. Accuracy on batch 2940/3013  on Training is 85.84983849030942\n",
            "Epoch #3. Accuracy on batch 2941/3013  on Training is 85.84827498300476\n",
            "Epoch #3. Accuracy on batch 2942/3013  on Training is 85.84883622154264\n",
            "Epoch #3. Accuracy on batch 2943/3013  on Training is 85.85045855978261\n",
            "Epoch #3. Accuracy on batch 2944/3013  on Training is 85.84995755517826\n",
            "Epoch #3. Accuracy on batch 2945/3013  on Training is 85.84839613034623\n",
            "Epoch #3. Accuracy on batch 2946/3013  on Training is 85.84577536477774\n",
            "Epoch #3. Accuracy on batch 2947/3013  on Training is 85.84527645861601\n",
            "Epoch #3. Accuracy on batch 2948/3013  on Training is 85.84795693455409\n",
            "Epoch #3. Accuracy on batch 2949/3013  on Training is 85.84851694915254\n",
            "Epoch #3. Accuracy on batch 2950/3013  on Training is 85.846958658082\n",
            "Epoch #3. Accuracy on batch 2951/3013  on Training is 85.8496358401084\n",
            "Epoch #3. Accuracy on batch 2952/3013  on Training is 85.84701997968168\n",
            "Epoch #3. Accuracy on batch 2953/3013  on Training is 85.84757955314828\n",
            "Epoch #3. Accuracy on batch 2954/3013  on Training is 85.84813874788495\n",
            "Epoch #3. Accuracy on batch 2955/3013  on Training is 85.84764039242219\n",
            "Epoch #3. Accuracy on batch 2956/3013  on Training is 85.84925600270545\n",
            "Epoch #3. Accuracy on batch 2957/3013  on Training is 85.8466446923597\n",
            "Epoch #3. Accuracy on batch 2958/3013  on Training is 85.84614734707671\n",
            "Epoch #3. Accuracy on batch 2959/3013  on Training is 85.84565033783784\n",
            "Batch Id 2960 is having training loss of 0.49373915791511536\n",
            "0.5576905608177185\n",
            "Epoch #3. Accuracy on batch 2960/3013  on Training is 85.84409827760892\n",
            "Epoch #3. Accuracy on batch 2961/3013  on Training is 85.84571235651586\n",
            "Epoch #3. Accuracy on batch 2962/3013  on Training is 85.84627067161661\n",
            "Epoch #3. Accuracy on batch 2963/3013  on Training is 85.84471997300945\n",
            "Epoch #3. Accuracy on batch 2964/3013  on Training is 85.84422428330522\n",
            "Epoch #3. Accuracy on batch 2965/3013  on Training is 85.84372892784896\n",
            "Epoch #3. Accuracy on batch 2966/3013  on Training is 85.84218065385912\n",
            "Epoch #3. Accuracy on batch 2967/3013  on Training is 85.83747473045823\n",
            "Epoch #3. Accuracy on batch 2968/3013  on Training is 85.83908723475918\n",
            "Epoch #3. Accuracy on batch 2969/3013  on Training is 85.83964646464646\n",
            "Epoch #3. Accuracy on batch 2970/3013  on Training is 85.84020531807472\n",
            "Epoch #3. Accuracy on batch 2971/3013  on Training is 85.84181527590847\n",
            "Epoch #3. Accuracy on batch 2972/3013  on Training is 85.84447527749748\n",
            "Epoch #3. Accuracy on batch 2973/3013  on Training is 85.84713349024882\n",
            "Epoch #3. Accuracy on batch 2974/3013  on Training is 85.85084033613445\n",
            "Epoch #3. Accuracy on batch 2975/3013  on Training is 85.8492943548387\n",
            "Epoch #3. Accuracy on batch 2976/3013  on Training is 85.8477494121599\n",
            "Epoch #3. Accuracy on batch 2977/3013  on Training is 85.84935359301545\n",
            "Epoch #3. Accuracy on batch 2978/3013  on Training is 85.84780966767372\n",
            "Epoch #3. Accuracy on batch 2979/3013  on Training is 85.85151006711409\n",
            "Batch Id 2980 is having training loss of 0.4937049448490143\n",
            "0.8927416801452637\n",
            "Epoch #3. Accuracy on batch 2980/3013  on Training is 85.84682153639719\n",
            "Epoch #3. Accuracy on batch 2981/3013  on Training is 85.84842387659289\n",
            "Epoch #3. Accuracy on batch 2982/3013  on Training is 85.85107274555816\n",
            "Epoch #3. Accuracy on batch 2983/3013  on Training is 85.8495308310992\n",
            "Epoch #3. Accuracy on batch 2984/3013  on Training is 85.84380234505862\n",
            "Epoch #3. Accuracy on batch 2985/3013  on Training is 85.84331044876089\n",
            "Epoch #3. Accuracy on batch 2986/3013  on Training is 85.83968028121862\n",
            "Epoch #3. Accuracy on batch 2987/3013  on Training is 85.8402359437751\n",
            "Epoch #3. Accuracy on batch 2988/3013  on Training is 85.83660923385747\n",
            "Epoch #3. Accuracy on batch 2989/3013  on Training is 85.83716555183946\n",
            "Epoch #3. Accuracy on batch 2990/3013  on Training is 85.83354229354731\n",
            "Epoch #3. Accuracy on batch 2991/3013  on Training is 85.83409926470588\n",
            "Epoch #3. Accuracy on batch 2992/3013  on Training is 85.83361176077514\n",
            "Epoch #3. Accuracy on batch 2993/3013  on Training is 85.83416833667334\n",
            "Epoch #3. Accuracy on batch 2994/3013  on Training is 85.83681135225376\n",
            "Epoch #3. Accuracy on batch 2995/3013  on Training is 85.83528037383178\n",
            "Epoch #3. Accuracy on batch 2996/3013  on Training is 85.83687854521187\n",
            "Epoch #3. Accuracy on batch 2997/3013  on Training is 85.83222148098733\n",
            "Epoch #3. Accuracy on batch 2998/3013  on Training is 85.83173557852618\n",
            "Epoch #3. Accuracy on batch 2999/3013  on Training is 85.83333333333333\n",
            "Batch Id 3000 is having training loss of 0.4941389560699463\n",
            "0.35879650712013245\n",
            "Epoch #3. Accuracy on batch 3000/3013  on Training is 85.83388870376541\n",
            "Epoch #3. Accuracy on batch 3001/3013  on Training is 85.83132078614257\n",
            "Epoch #3. Accuracy on batch 3002/3013  on Training is 85.83187645687646\n",
            "Epoch #3. Accuracy on batch 3003/3013  on Training is 85.83347203728363\n",
            "Epoch #3. Accuracy on batch 3004/3013  on Training is 85.83506655574043\n",
            "Epoch #3. Accuracy on batch 3005/3013  on Training is 85.83354125083167\n",
            "Epoch #3. Accuracy on batch 3006/3013  on Training is 85.8361739275025\n",
            "Epoch #3. Accuracy on batch 3007/3013  on Training is 85.8388048537234\n",
            "Epoch #3. Accuracy on batch 3008/3013  on Training is 85.83312562313061\n",
            "Epoch #3. Accuracy on batch 3009/3013  on Training is 85.83783222591362\n",
            "Epoch #3. Accuracy on batch 3010/3013  on Training is 85.84045998007306\n",
            "Epoch #3. Accuracy on batch 3011/3013  on Training is 85.8410109561753\n",
            "Epoch #3. Accuracy on batch 3012/3013  on Training is 85.8393675954935\n",
            "Epoch #3. Batch Id 0/278  is having validation loss of 0.9726901650428772\n",
            "0.9726901650428772\n",
            "Epoch #3. Batch Id 0/278  is having validation accuracy of 71.875\n",
            "Epoch #3. Batch Id 1/278  is having validation loss of 0.7956085205078125\n",
            "0.6185268759727478\n",
            "Epoch #3. Batch Id 1/278  is having validation accuracy of 79.6875\n",
            "Epoch #3. Batch Id 2/278  is having validation loss of 0.6580615639686584\n",
            "0.38296765089035034\n",
            "Epoch #3. Batch Id 2/278  is having validation accuracy of 81.25\n",
            "Epoch #3. Batch Id 3/278  is having validation loss of 0.5899057388305664\n",
            "0.3854382336139679\n",
            "Epoch #3. Batch Id 3/278  is having validation accuracy of 83.59375\n",
            "Epoch #3. Batch Id 4/278  is having validation loss of 0.654603123664856\n",
            "0.9133927822113037\n",
            "Epoch #3. Batch Id 4/278  is having validation accuracy of 80.625\n",
            "Epoch #3. Batch Id 5/278  is having validation loss of 0.659636914730072\n",
            "0.6848058104515076\n",
            "Epoch #3. Batch Id 5/278  is having validation accuracy of 81.77083333333333\n",
            "Epoch #3. Batch Id 6/278  is having validation loss of 0.7114757299423218\n",
            "1.0225086212158203\n",
            "Epoch #3. Batch Id 6/278  is having validation accuracy of 80.35714285714286\n",
            "Epoch #3. Batch Id 7/278  is having validation loss of 0.6449639797210693\n",
            "0.17938165366649628\n",
            "Epoch #3. Batch Id 7/278  is having validation accuracy of 82.421875\n",
            "Epoch #3. Batch Id 8/278  is having validation loss of 0.6030377745628357\n",
            "0.26762789487838745\n",
            "Epoch #3. Batch Id 8/278  is having validation accuracy of 83.33333333333333\n",
            "Epoch #3. Batch Id 9/278  is having validation loss of 0.5657131671905518\n",
            "0.22979199886322021\n",
            "Epoch #3. Batch Id 9/278  is having validation accuracy of 84.375\n",
            "Epoch #3. Batch Id 10/278  is having validation loss of 0.5753062963485718\n",
            "0.6712374091148376\n",
            "Epoch #3. Batch Id 10/278  is having validation accuracy of 84.375\n",
            "Epoch #3. Batch Id 11/278  is having validation loss of 0.584110677242279\n",
            "0.6809588074684143\n",
            "Epoch #3. Batch Id 11/278  is having validation accuracy of 84.63541666666667\n",
            "Epoch #3. Batch Id 12/278  is having validation loss of 0.6001971364021301\n",
            "0.7932347059249878\n",
            "Epoch #3. Batch Id 12/278  is having validation accuracy of 84.375\n",
            "Epoch #3. Batch Id 13/278  is having validation loss of 0.5945349335670471\n",
            "0.520926296710968\n",
            "Epoch #3. Batch Id 13/278  is having validation accuracy of 84.375\n",
            "Epoch #3. Batch Id 14/278  is having validation loss of 0.5902784466743469\n",
            "0.5306879281997681\n",
            "Epoch #3. Batch Id 14/278  is having validation accuracy of 84.58333333333333\n",
            "Epoch #3. Batch Id 15/278  is having validation loss of 0.5913613438606262\n",
            "0.6076050996780396\n",
            "Epoch #3. Batch Id 15/278  is having validation accuracy of 84.765625\n",
            "Epoch #3. Batch Id 16/278  is having validation loss of 0.6117372512817383\n",
            "0.9377517104148865\n",
            "Epoch #3. Batch Id 16/278  is having validation accuracy of 84.74264705882354\n",
            "Epoch #3. Batch Id 17/278  is having validation loss of 0.601559042930603\n",
            "0.4285290539264679\n",
            "Epoch #3. Batch Id 17/278  is having validation accuracy of 84.89583333333333\n",
            "Epoch #3. Batch Id 18/278  is having validation loss of 0.5900329351425171\n",
            "0.38256317377090454\n",
            "Epoch #3. Batch Id 18/278  is having validation accuracy of 85.19736842105263\n",
            "Epoch #3. Batch Id 19/278  is having validation loss of 0.5905347466468811\n",
            "0.6000695824623108\n",
            "Epoch #3. Batch Id 19/278  is having validation accuracy of 85.15625\n",
            "Epoch #3. Batch Id 20/278  is having validation loss of 0.586685299873352\n",
            "0.5096961259841919\n",
            "Epoch #3. Batch Id 20/278  is having validation accuracy of 85.26785714285714\n",
            "Epoch #3. Batch Id 21/278  is having validation loss of 0.5855383276939392\n",
            "0.56145179271698\n",
            "Epoch #3. Batch Id 21/278  is having validation accuracy of 85.22727272727273\n",
            "Epoch #3. Batch Id 22/278  is having validation loss of 0.5749109387397766\n",
            "0.3411087095737457\n",
            "Epoch #3. Batch Id 22/278  is having validation accuracy of 85.46195652173913\n",
            "Epoch #3. Batch Id 23/278  is having validation loss of 0.5791508555412292\n",
            "0.6766695380210876\n",
            "Epoch #3. Batch Id 23/278  is having validation accuracy of 85.28645833333333\n",
            "Epoch #3. Batch Id 24/278  is having validation loss of 0.5735363960266113\n",
            "0.43879005312919617\n",
            "Epoch #3. Batch Id 24/278  is having validation accuracy of 85.375\n",
            "Epoch #3. Batch Id 25/278  is having validation loss of 0.573341965675354\n",
            "0.5684816837310791\n",
            "Epoch #3. Batch Id 25/278  is having validation accuracy of 85.45673076923077\n",
            "Epoch #3. Batch Id 26/278  is having validation loss of 0.5757021307945251\n",
            "0.6370671391487122\n",
            "Epoch #3. Batch Id 26/278  is having validation accuracy of 85.41666666666667\n",
            "Epoch #3. Batch Id 27/278  is having validation loss of 0.5788892507553101\n",
            "0.6649408340454102\n",
            "Epoch #3. Batch Id 27/278  is having validation accuracy of 85.37946428571429\n",
            "Epoch #3. Batch Id 28/278  is having validation loss of 0.588512122631073\n",
            "0.8579529523849487\n",
            "Epoch #3. Batch Id 28/278  is having validation accuracy of 85.02155172413794\n",
            "Epoch #3. Batch Id 29/278  is having validation loss of 0.5787091255187988\n",
            "0.29442211985588074\n",
            "Epoch #3. Batch Id 29/278  is having validation accuracy of 85.41666666666667\n",
            "Epoch #3. Batch Id 30/278  is having validation loss of 0.5720698237419128\n",
            "0.37289032340049744\n",
            "Epoch #3. Batch Id 30/278  is having validation accuracy of 85.38306451612904\n",
            "Epoch #3. Batch Id 31/278  is having validation loss of 0.5765409469604492\n",
            "0.7151460647583008\n",
            "Epoch #3. Batch Id 31/278  is having validation accuracy of 85.3515625\n",
            "Epoch #3. Batch Id 32/278  is having validation loss of 0.5711143016815186\n",
            "0.3974621295928955\n",
            "Epoch #3. Batch Id 32/278  is having validation accuracy of 85.70075757575758\n",
            "Epoch #3. Batch Id 33/278  is having validation loss of 0.5703932046890259\n",
            "0.546596348285675\n",
            "Epoch #3. Batch Id 33/278  is having validation accuracy of 85.66176470588235\n",
            "Epoch #3. Batch Id 34/278  is having validation loss of 0.5816071033477783\n",
            "0.9628794193267822\n",
            "Epoch #3. Batch Id 34/278  is having validation accuracy of 85.44642857142857\n",
            "Epoch #3. Batch Id 35/278  is having validation loss of 0.5819011330604553\n",
            "0.592192530632019\n",
            "Epoch #3. Batch Id 35/278  is having validation accuracy of 85.24305555555556\n",
            "Epoch #3. Batch Id 36/278  is having validation loss of 0.5799923539161682\n",
            "0.5112754106521606\n",
            "Epoch #3. Batch Id 36/278  is having validation accuracy of 85.30405405405405\n",
            "Epoch #3. Batch Id 37/278  is having validation loss of 0.5752431750297546\n",
            "0.3995237648487091\n",
            "Epoch #3. Batch Id 37/278  is having validation accuracy of 85.52631578947368\n",
            "Epoch #3. Batch Id 38/278  is having validation loss of 0.5812950134277344\n",
            "0.8112649321556091\n",
            "Epoch #3. Batch Id 38/278  is having validation accuracy of 85.49679487179488\n",
            "Epoch #3. Batch Id 39/278  is having validation loss of 0.5779381394386292\n",
            "0.4470200538635254\n",
            "Epoch #3. Batch Id 39/278  is having validation accuracy of 85.390625\n",
            "Epoch #3. Batch Id 40/278  is having validation loss of 0.5732058882713318\n",
            "0.38391566276550293\n",
            "Epoch #3. Batch Id 40/278  is having validation accuracy of 85.51829268292683\n",
            "Epoch #3. Batch Id 41/278  is having validation loss of 0.5762757658958435\n",
            "0.7021403312683105\n",
            "Epoch #3. Batch Id 41/278  is having validation accuracy of 85.41666666666667\n",
            "Epoch #3. Batch Id 42/278  is having validation loss of 0.5757699608802795\n",
            "0.5545258522033691\n",
            "Epoch #3. Batch Id 42/278  is having validation accuracy of 85.31976744186046\n",
            "Epoch #3. Batch Id 43/278  is having validation loss of 0.5736908316612244\n",
            "0.4842892289161682\n",
            "Epoch #3. Batch Id 43/278  is having validation accuracy of 85.15625\n",
            "Epoch #3. Batch Id 44/278  is having validation loss of 0.5811479091644287\n",
            "0.9092580080032349\n",
            "Epoch #3. Batch Id 44/278  is having validation accuracy of 84.79166666666667\n",
            "Epoch #3. Batch Id 45/278  is having validation loss of 0.5826392769813538\n",
            "0.6497518420219421\n",
            "Epoch #3. Batch Id 45/278  is having validation accuracy of 84.78260869565217\n",
            "Epoch #3. Batch Id 46/278  is having validation loss of 0.580802857875824\n",
            "0.49632665514945984\n",
            "Epoch #3. Batch Id 46/278  is having validation accuracy of 84.77393617021276\n",
            "Epoch #3. Batch Id 47/278  is having validation loss of 0.5838226079940796\n",
            "0.7257496118545532\n",
            "Epoch #3. Batch Id 47/278  is having validation accuracy of 84.765625\n",
            "Epoch #3. Batch Id 48/278  is having validation loss of 0.5841163992881775\n",
            "0.5982176661491394\n",
            "Epoch #3. Batch Id 48/278  is having validation accuracy of 84.63010204081633\n",
            "Epoch #3. Batch Id 49/278  is having validation loss of 0.5839327573776245\n",
            "0.5749331712722778\n",
            "Epoch #3. Batch Id 49/278  is having validation accuracy of 84.5625\n",
            "Epoch #3. Batch Id 50/278  is having validation loss of 0.5800767540931702\n",
            "0.38727569580078125\n",
            "Epoch #3. Batch Id 50/278  is having validation accuracy of 84.62009803921569\n",
            "Epoch #3. Batch Id 51/278  is having validation loss of 0.5742519497871399\n",
            "0.2771865129470825\n",
            "Epoch #3. Batch Id 51/278  is having validation accuracy of 84.67548076923077\n",
            "Epoch #3. Batch Id 52/278  is having validation loss of 0.5741087794303894\n",
            "0.566664457321167\n",
            "Epoch #3. Batch Id 52/278  is having validation accuracy of 84.61084905660377\n",
            "Epoch #3. Batch Id 53/278  is having validation loss of 0.5748088359832764\n",
            "0.6119130849838257\n",
            "Epoch #3. Batch Id 53/278  is having validation accuracy of 84.49074074074075\n",
            "Epoch #3. Batch Id 54/278  is having validation loss of 0.5702202916145325\n",
            "0.3224397301673889\n",
            "Epoch #3. Batch Id 54/278  is having validation accuracy of 84.54545454545455\n",
            "Epoch #3. Batch Id 55/278  is having validation loss of 0.5662410855293274\n",
            "0.34738487005233765\n",
            "Epoch #3. Batch Id 55/278  is having validation accuracy of 84.65401785714286\n",
            "Epoch #3. Batch Id 56/278  is having validation loss of 0.5739525556564331\n",
            "1.0057964324951172\n",
            "Epoch #3. Batch Id 56/278  is having validation accuracy of 84.48464912280701\n",
            "Epoch #3. Batch Id 57/278  is having validation loss of 0.5702799558639526\n",
            "0.360943078994751\n",
            "Epoch #3. Batch Id 57/278  is having validation accuracy of 84.64439655172414\n",
            "Epoch #3. Batch Id 58/278  is having validation loss of 0.5666735172271729\n",
            "0.35749855637550354\n",
            "Epoch #3. Batch Id 58/278  is having validation accuracy of 84.63983050847457\n",
            "Epoch #3. Batch Id 59/278  is having validation loss of 0.564141035079956\n",
            "0.414724737405777\n",
            "Epoch #3. Batch Id 59/278  is having validation accuracy of 84.73958333333333\n",
            "Epoch #3. Batch Id 60/278  is having validation loss of 0.5637776255607605\n",
            "0.5419721603393555\n",
            "Epoch #3. Batch Id 60/278  is having validation accuracy of 84.78483606557377\n",
            "Epoch #3. Batch Id 61/278  is having validation loss of 0.5615755915641785\n",
            "0.4272504448890686\n",
            "Epoch #3. Batch Id 61/278  is having validation accuracy of 84.87903225806451\n",
            "Epoch #3. Batch Id 62/278  is having validation loss of 0.5574902296066284\n",
            "0.3041967451572418\n",
            "Epoch #3. Batch Id 62/278  is having validation accuracy of 84.9702380952381\n",
            "Epoch #3. Batch Id 63/278  is having validation loss of 0.5565871000289917\n",
            "0.4996902644634247\n",
            "Epoch #3. Batch Id 63/278  is having validation accuracy of 84.9609375\n",
            "Epoch #3. Batch Id 64/278  is having validation loss of 0.5583505034446716\n",
            "0.6712081432342529\n",
            "Epoch #3. Batch Id 64/278  is having validation accuracy of 84.8076923076923\n",
            "Epoch #3. Batch Id 65/278  is having validation loss of 0.5531637072563171\n",
            "0.21602188050746918\n",
            "Epoch #3. Batch Id 65/278  is having validation accuracy of 84.94318181818181\n",
            "Epoch #3. Batch Id 66/278  is having validation loss of 0.5503833293914795\n",
            "0.3668798804283142\n",
            "Epoch #3. Batch Id 66/278  is having validation accuracy of 85.02798507462687\n",
            "Epoch #3. Batch Id 67/278  is having validation loss of 0.5541197061538696\n",
            "0.8044583797454834\n",
            "Epoch #3. Batch Id 67/278  is having validation accuracy of 85.01838235294117\n",
            "Epoch #3. Batch Id 68/278  is having validation loss of 0.5502220392227173\n",
            "0.28518128395080566\n",
            "Epoch #3. Batch Id 68/278  is having validation accuracy of 85.14492753623189\n",
            "Epoch #3. Batch Id 69/278  is having validation loss of 0.5479121804237366\n",
            "0.38853371143341064\n",
            "Epoch #3. Batch Id 69/278  is having validation accuracy of 85.17857142857143\n",
            "Epoch #3. Batch Id 70/278  is having validation loss of 0.5500715970993042\n",
            "0.701231062412262\n",
            "Epoch #3. Batch Id 70/278  is having validation accuracy of 85.12323943661971\n",
            "Epoch #3. Batch Id 71/278  is having validation loss of 0.5460918545722961\n",
            "0.2635282576084137\n",
            "Epoch #3. Batch Id 71/278  is having validation accuracy of 85.15625\n",
            "Epoch #3. Batch Id 72/278  is having validation loss of 0.5448211431503296\n",
            "0.4533312916755676\n",
            "Epoch #3. Batch Id 72/278  is having validation accuracy of 85.27397260273973\n",
            "Epoch #3. Batch Id 73/278  is having validation loss of 0.5449281930923462\n",
            "0.5527421236038208\n",
            "Epoch #3. Batch Id 73/278  is having validation accuracy of 85.2195945945946\n",
            "Epoch #3. Batch Id 74/278  is having validation loss of 0.5499327778816223\n",
            "0.9202725887298584\n",
            "Epoch #3. Batch Id 74/278  is having validation accuracy of 85.16666666666667\n",
            "Epoch #3. Batch Id 75/278  is having validation loss of 0.5545880198478699\n",
            "0.903730034828186\n",
            "Epoch #3. Batch Id 75/278  is having validation accuracy of 85.07401315789474\n",
            "Epoch #3. Batch Id 76/278  is having validation loss of 0.5534760355949402\n",
            "0.4689640998840332\n",
            "Epoch #3. Batch Id 76/278  is having validation accuracy of 85.10551948051948\n",
            "Epoch #3. Batch Id 77/278  is having validation loss of 0.551476776599884\n",
            "0.3975350558757782\n",
            "Epoch #3. Batch Id 77/278  is having validation accuracy of 85.13621794871794\n",
            "Epoch #3. Batch Id 78/278  is having validation loss of 0.5508167147636414\n",
            "0.49933022260665894\n",
            "Epoch #3. Batch Id 78/278  is having validation accuracy of 85.12658227848101\n",
            "Epoch #3. Batch Id 79/278  is having validation loss of 0.5476042628288269\n",
            "0.2938201129436493\n",
            "Epoch #3. Batch Id 79/278  is having validation accuracy of 85.1953125\n",
            "Epoch #3. Batch Id 80/278  is having validation loss of 0.5456271171569824\n",
            "0.3874572515487671\n",
            "Epoch #3. Batch Id 80/278  is having validation accuracy of 85.22376543209876\n",
            "Epoch #3. Batch Id 81/278  is having validation loss of 0.545757532119751\n",
            "0.5563226938247681\n",
            "Epoch #3. Batch Id 81/278  is having validation accuracy of 85.28963414634147\n",
            "Epoch #3. Batch Id 82/278  is having validation loss of 0.5471594929695129\n",
            "0.6621208786964417\n",
            "Epoch #3. Batch Id 82/278  is having validation accuracy of 85.20331325301204\n",
            "Epoch #3. Batch Id 83/278  is having validation loss of 0.5462374091148376\n",
            "0.46970638632774353\n",
            "Epoch #3. Batch Id 83/278  is having validation accuracy of 85.23065476190476\n",
            "Epoch #3. Batch Id 84/278  is having validation loss of 0.5474448204040527\n",
            "0.6488687992095947\n",
            "Epoch #3. Batch Id 84/278  is having validation accuracy of 85.22058823529412\n",
            "Epoch #3. Batch Id 85/278  is having validation loss of 0.5467012524604797\n",
            "0.4834998846054077\n",
            "Epoch #3. Batch Id 85/278  is having validation accuracy of 85.24709302325581\n",
            "Epoch #3. Batch Id 86/278  is having validation loss of 0.544581413269043\n",
            "0.36227360367774963\n",
            "Epoch #3. Batch Id 86/278  is having validation accuracy of 85.308908045977\n",
            "Epoch #3. Batch Id 87/278  is having validation loss of 0.541805624961853\n",
            "0.3003125488758087\n",
            "Epoch #3. Batch Id 87/278  is having validation accuracy of 85.2627840909091\n",
            "Epoch #3. Batch Id 88/278  is having validation loss of 0.5426871180534363\n",
            "0.6202594637870789\n",
            "Epoch #3. Batch Id 88/278  is having validation accuracy of 85.25280898876404\n",
            "Epoch #3. Batch Id 89/278  is having validation loss of 0.5401263236999512\n",
            "0.3122141361236572\n",
            "Epoch #3. Batch Id 89/278  is having validation accuracy of 85.3125\n",
            "Epoch #3. Batch Id 90/278  is having validation loss of 0.5390274524688721\n",
            "0.4401305317878723\n",
            "Epoch #3. Batch Id 90/278  is having validation accuracy of 85.33653846153847\n",
            "Epoch #3. Batch Id 91/278  is having validation loss of 0.5382512807846069\n",
            "0.4676190912723541\n",
            "Epoch #3. Batch Id 91/278  is having validation accuracy of 85.39402173913044\n",
            "Epoch #3. Batch Id 92/278  is having validation loss of 0.5367457866668701\n",
            "0.3982389569282532\n",
            "Epoch #3. Batch Id 92/278  is having validation accuracy of 85.41666666666667\n",
            "Epoch #3. Batch Id 93/278  is having validation loss of 0.5354065299034119\n",
            "0.4108550548553467\n",
            "Epoch #3. Batch Id 93/278  is having validation accuracy of 85.47207446808511\n",
            "Epoch #3. Batch Id 94/278  is having validation loss of 0.5338452458381653\n",
            "0.38708364963531494\n",
            "Epoch #3. Batch Id 94/278  is having validation accuracy of 85.49342105263158\n",
            "Epoch #3. Batch Id 95/278  is having validation loss of 0.5346655249595642\n",
            "0.6125901937484741\n",
            "Epoch #3. Batch Id 95/278  is having validation accuracy of 85.51432291666667\n",
            "Epoch #3. Batch Id 96/278  is having validation loss of 0.5368661284446716\n",
            "0.7481228709220886\n",
            "Epoch #3. Batch Id 96/278  is having validation accuracy of 85.37371134020619\n",
            "Epoch #3. Batch Id 97/278  is having validation loss of 0.538738489151001\n",
            "0.7203565835952759\n",
            "Epoch #3. Batch Id 97/278  is having validation accuracy of 85.36352040816327\n",
            "Epoch #3. Batch Id 98/278  is having validation loss of 0.5374420881271362\n",
            "0.41039371490478516\n",
            "Epoch #3. Batch Id 98/278  is having validation accuracy of 85.38510101010101\n",
            "Epoch #3. Batch Id 99/278  is having validation loss of 0.5388218760490417\n",
            "0.6754198670387268\n",
            "Epoch #3. Batch Id 99/278  is having validation accuracy of 85.21875\n",
            "Epoch #3. Batch Id 100/278  is having validation loss of 0.5381863713264465\n",
            "0.4746333062648773\n",
            "Epoch #3. Batch Id 100/278  is having validation accuracy of 85.14851485148515\n",
            "Epoch #3. Batch Id 101/278  is having validation loss of 0.535254180431366\n",
            "0.23910236358642578\n",
            "Epoch #3. Batch Id 101/278  is having validation accuracy of 85.2328431372549\n",
            "Epoch #3. Batch Id 102/278  is having validation loss of 0.5359480977058411\n",
            "0.606725811958313\n",
            "Epoch #3. Batch Id 102/278  is having validation accuracy of 85.16383495145631\n",
            "Epoch #3. Batch Id 103/278  is having validation loss of 0.5345147252082825\n",
            "0.38687893748283386\n",
            "Epoch #3. Batch Id 103/278  is having validation accuracy of 85.18629807692308\n",
            "Epoch #3. Batch Id 104/278  is having validation loss of 0.533057451248169\n",
            "0.38150137662887573\n",
            "Epoch #3. Batch Id 104/278  is having validation accuracy of 85.17857142857143\n",
            "Epoch #3. Batch Id 105/278  is having validation loss of 0.5328683853149414\n",
            "0.5130195617675781\n",
            "Epoch #3. Batch Id 105/278  is having validation accuracy of 85.25943396226415\n",
            "Epoch #3. Batch Id 106/278  is having validation loss of 0.5306413769721985\n",
            "0.29457971453666687\n",
            "Epoch #3. Batch Id 106/278  is having validation accuracy of 85.30957943925233\n",
            "Epoch #3. Batch Id 107/278  is having validation loss of 0.5298877954483032\n",
            "0.44925516843795776\n",
            "Epoch #3. Batch Id 107/278  is having validation accuracy of 85.30092592592592\n",
            "Epoch #3. Batch Id 108/278  is having validation loss of 0.5316333174705505\n",
            "0.7201516628265381\n",
            "Epoch #3. Batch Id 108/278  is having validation accuracy of 85.20642201834862\n",
            "Epoch #3. Batch Id 109/278  is having validation loss of 0.5333136320114136\n",
            "0.7164652347564697\n",
            "Epoch #3. Batch Id 109/278  is having validation accuracy of 85.11363636363636\n",
            "Epoch #3. Batch Id 110/278  is having validation loss of 0.5319639444351196\n",
            "0.3835012912750244\n",
            "Epoch #3. Batch Id 110/278  is having validation accuracy of 85.19144144144144\n",
            "Epoch #3. Batch Id 111/278  is having validation loss of 0.531416654586792\n",
            "0.47066646814346313\n",
            "Epoch #3. Batch Id 111/278  is having validation accuracy of 85.18415178571429\n",
            "Epoch #3. Batch Id 112/278  is having validation loss of 0.5345725417137146\n",
            "0.8880323171615601\n",
            "Epoch #3. Batch Id 112/278  is having validation accuracy of 85.1216814159292\n",
            "Epoch #3. Batch Id 113/278  is having validation loss of 0.5337299108505249\n",
            "0.4385155737400055\n",
            "Epoch #3. Batch Id 113/278  is having validation accuracy of 85.14254385964912\n",
            "Epoch #3. Batch Id 114/278  is having validation loss of 0.5328532457351685\n",
            "0.43291348218917847\n",
            "Epoch #3. Batch Id 114/278  is having validation accuracy of 85.16304347826087\n",
            "Epoch #3. Batch Id 115/278  is having validation loss of 0.5330847501754761\n",
            "0.559704601764679\n",
            "Epoch #3. Batch Id 115/278  is having validation accuracy of 85.18318965517241\n",
            "Epoch #3. Batch Id 116/278  is having validation loss of 0.5329768657684326\n",
            "0.5204606056213379\n",
            "Epoch #3. Batch Id 116/278  is having validation accuracy of 85.22970085470085\n",
            "Epoch #3. Batch Id 117/278  is having validation loss of 0.5321240425109863\n",
            "0.43234458565711975\n",
            "Epoch #3. Batch Id 117/278  is having validation accuracy of 85.27542372881356\n",
            "Epoch #3. Batch Id 118/278  is having validation loss of 0.5335302352905273\n",
            "0.699459433555603\n",
            "Epoch #3. Batch Id 118/278  is having validation accuracy of 85.29411764705883\n",
            "Epoch #3. Batch Id 119/278  is having validation loss of 0.5326738357543945\n",
            "0.43076395988464355\n",
            "Epoch #3. Batch Id 119/278  is having validation accuracy of 85.28645833333333\n",
            "Epoch #3. Batch Id 120/278  is having validation loss of 0.5315259695053101\n",
            "0.393784761428833\n",
            "Epoch #3. Batch Id 120/278  is having validation accuracy of 85.35640495867769\n",
            "Epoch #3. Batch Id 121/278  is having validation loss of 0.5328410267829895\n",
            "0.6919649243354797\n",
            "Epoch #3. Batch Id 121/278  is having validation accuracy of 85.32274590163935\n",
            "Epoch #3. Batch Id 122/278  is having validation loss of 0.5331563949584961\n",
            "0.5716336965560913\n",
            "Epoch #3. Batch Id 122/278  is having validation accuracy of 85.28963414634147\n",
            "Epoch #3. Batch Id 123/278  is having validation loss of 0.5342159271240234\n",
            "0.664535403251648\n",
            "Epoch #3. Batch Id 123/278  is having validation accuracy of 85.30745967741936\n",
            "Epoch #3. Batch Id 124/278  is having validation loss of 0.5356981158256531\n",
            "0.7194869518280029\n",
            "Epoch #3. Batch Id 124/278  is having validation accuracy of 85.35\n",
            "Epoch #3. Batch Id 125/278  is having validation loss of 0.5370571613311768\n",
            "0.7069405317306519\n",
            "Epoch #3. Batch Id 125/278  is having validation accuracy of 85.26785714285714\n",
            "Epoch #3. Batch Id 126/278  is having validation loss of 0.536774218082428\n",
            "0.5011243224143982\n",
            "Epoch #3. Batch Id 126/278  is having validation accuracy of 85.26082677165354\n",
            "Epoch #3. Batch Id 127/278  is having validation loss of 0.5358028411865234\n",
            "0.4124358892440796\n",
            "Epoch #3. Batch Id 127/278  is having validation accuracy of 85.2783203125\n",
            "Epoch #3. Batch Id 128/278  is having validation loss of 0.5346376299858093\n",
            "0.3854939937591553\n",
            "Epoch #3. Batch Id 128/278  is having validation accuracy of 85.36821705426357\n",
            "Epoch #3. Batch Id 129/278  is having validation loss of 0.5354572534561157\n",
            "0.641186535358429\n",
            "Epoch #3. Batch Id 129/278  is having validation accuracy of 85.33653846153847\n",
            "Epoch #3. Batch Id 130/278  is having validation loss of 0.5343021154403687\n",
            "0.3841303884983063\n",
            "Epoch #3. Batch Id 130/278  is having validation accuracy of 85.30534351145039\n",
            "Epoch #3. Batch Id 131/278  is having validation loss of 0.5347538590431213\n",
            "0.5939289927482605\n",
            "Epoch #3. Batch Id 131/278  is having validation accuracy of 85.27462121212122\n",
            "Epoch #3. Batch Id 132/278  is having validation loss of 0.5338654518127441\n",
            "0.41659489274024963\n",
            "Epoch #3. Batch Id 132/278  is having validation accuracy of 85.29135338345864\n",
            "Epoch #3. Batch Id 133/278  is having validation loss of 0.5328883528709412\n",
            "0.4029359817504883\n",
            "Epoch #3. Batch Id 133/278  is having validation accuracy of 85.33115671641791\n",
            "Epoch #3. Batch Id 134/278  is having validation loss of 0.5347994565963745\n",
            "0.7908880114555359\n",
            "Epoch #3. Batch Id 134/278  is having validation accuracy of 85.20833333333333\n",
            "Epoch #3. Batch Id 135/278  is having validation loss of 0.5376092195510864\n",
            "0.9169302582740784\n",
            "Epoch #3. Batch Id 135/278  is having validation accuracy of 85.13327205882354\n",
            "Epoch #3. Batch Id 136/278  is having validation loss of 0.5367345213890076\n",
            "0.41777223348617554\n",
            "Epoch #3. Batch Id 136/278  is having validation accuracy of 85.10492700729927\n",
            "Epoch #3. Batch Id 137/278  is having validation loss of 0.5392167568206787\n",
            "0.8792847990989685\n",
            "Epoch #3. Batch Id 137/278  is having validation accuracy of 85.05434782608695\n",
            "Epoch #3. Batch Id 138/278  is having validation loss of 0.5388243198394775\n",
            "0.48467177152633667\n",
            "Epoch #3. Batch Id 138/278  is having validation accuracy of 85.09442446043165\n",
            "Epoch #3. Batch Id 139/278  is having validation loss of 0.5385698676109314\n",
            "0.5032017827033997\n",
            "Epoch #3. Batch Id 139/278  is having validation accuracy of 85.11160714285714\n",
            "Epoch #3. Batch Id 140/278  is having validation loss of 0.5392286777496338\n",
            "0.6314660906791687\n",
            "Epoch #3. Batch Id 140/278  is having validation accuracy of 85.06205673758865\n",
            "Epoch #3. Batch Id 141/278  is having validation loss of 0.5388827323913574\n",
            "0.4901004433631897\n",
            "Epoch #3. Batch Id 141/278  is having validation accuracy of 85.10123239436619\n",
            "Epoch #3. Batch Id 142/278  is having validation loss of 0.5396194458007812\n",
            "0.644233226776123\n",
            "Epoch #3. Batch Id 142/278  is having validation accuracy of 85.05244755244755\n",
            "Epoch #3. Batch Id 143/278  is having validation loss of 0.5407387614250183\n",
            "0.7008040547370911\n",
            "Epoch #3. Batch Id 143/278  is having validation accuracy of 85.06944444444444\n",
            "Epoch #3. Batch Id 144/278  is having validation loss of 0.5387078523635864\n",
            "0.24625416100025177\n",
            "Epoch #3. Batch Id 144/278  is having validation accuracy of 85.10775862068965\n",
            "Epoch #3. Batch Id 145/278  is having validation loss of 0.5392264127731323\n",
            "0.6144149899482727\n",
            "Epoch #3. Batch Id 145/278  is having validation accuracy of 85.1027397260274\n",
            "Epoch #3. Batch Id 146/278  is having validation loss of 0.5398759245872498\n",
            "0.6347060799598694\n",
            "Epoch #3. Batch Id 146/278  is having validation accuracy of 85.05527210884354\n",
            "Epoch #3. Batch Id 147/278  is having validation loss of 0.5417966842651367\n",
            "0.8241450190544128\n",
            "Epoch #3. Batch Id 147/278  is having validation accuracy of 85.05067567567568\n",
            "Epoch #3. Batch Id 148/278  is having validation loss of 0.5414288640022278\n",
            "0.48699304461479187\n",
            "Epoch #3. Batch Id 148/278  is having validation accuracy of 85.0251677852349\n",
            "Epoch #3. Batch Id 149/278  is having validation loss of 0.5399297475814819\n",
            "0.3165636956691742\n",
            "Epoch #3. Batch Id 149/278  is having validation accuracy of 85.04166666666667\n",
            "Epoch #3. Batch Id 150/278  is having validation loss of 0.5433134436607361\n",
            "1.0508710145950317\n",
            "Epoch #3. Batch Id 150/278  is having validation accuracy of 84.9751655629139\n",
            "Epoch #3. Batch Id 151/278  is having validation loss of 0.543123185634613\n",
            "0.5143924951553345\n",
            "Epoch #3. Batch Id 151/278  is having validation accuracy of 84.93009868421052\n",
            "Epoch #3. Batch Id 152/278  is having validation loss of 0.5439527034759521\n",
            "0.670043408870697\n",
            "Epoch #3. Batch Id 152/278  is having validation accuracy of 84.88562091503267\n",
            "Epoch #3. Batch Id 153/278  is having validation loss of 0.5429674386978149\n",
            "0.39222297072410583\n",
            "Epoch #3. Batch Id 153/278  is having validation accuracy of 84.90259740259741\n",
            "Epoch #3. Batch Id 154/278  is having validation loss of 0.543734610080719\n",
            "0.6618797183036804\n",
            "Epoch #3. Batch Id 154/278  is having validation accuracy of 84.8991935483871\n",
            "Epoch #3. Batch Id 155/278  is having validation loss of 0.5424027442932129\n",
            "0.33596283197402954\n",
            "Epoch #3. Batch Id 155/278  is having validation accuracy of 84.89583333333333\n",
            "Epoch #3. Batch Id 156/278  is having validation loss of 0.5454996824264526\n",
            "1.0286256074905396\n",
            "Epoch #3. Batch Id 156/278  is having validation accuracy of 84.77308917197452\n",
            "Epoch #3. Batch Id 157/278  is having validation loss of 0.5461727380752563\n",
            "0.6518420577049255\n",
            "Epoch #3. Batch Id 157/278  is having validation accuracy of 84.7507911392405\n",
            "Epoch #3. Batch Id 158/278  is having validation loss of 0.5438498854637146\n",
            "0.17684306204319\n",
            "Epoch #3. Batch Id 158/278  is having validation accuracy of 84.82704402515724\n",
            "Epoch #3. Batch Id 159/278  is having validation loss of 0.5444952845573425\n",
            "0.6471146941184998\n",
            "Epoch #3. Batch Id 159/278  is having validation accuracy of 84.8046875\n",
            "Epoch #3. Batch Id 160/278  is having validation loss of 0.5468111038208008\n",
            "0.9173464179039001\n",
            "Epoch #3. Batch Id 160/278  is having validation accuracy of 84.74378881987577\n",
            "Epoch #3. Batch Id 161/278  is having validation loss of 0.546074390411377\n",
            "0.4274655282497406\n",
            "Epoch #3. Batch Id 161/278  is having validation accuracy of 84.7608024691358\n",
            "Epoch #3. Batch Id 162/278  is having validation loss of 0.544842541217804\n",
            "0.3452798128128052\n",
            "Epoch #3. Batch Id 162/278  is having validation accuracy of 84.8351226993865\n",
            "Epoch #3. Batch Id 163/278  is having validation loss of 0.5447681546211243\n",
            "0.5326418280601501\n",
            "Epoch #3. Batch Id 163/278  is having validation accuracy of 84.8513719512195\n",
            "Epoch #3. Batch Id 164/278  is having validation loss of 0.545615017414093\n",
            "0.6845049262046814\n",
            "Epoch #3. Batch Id 164/278  is having validation accuracy of 84.84848484848484\n",
            "Epoch #3. Batch Id 165/278  is having validation loss of 0.5455745458602905\n",
            "0.538899302482605\n",
            "Epoch #3. Batch Id 165/278  is having validation accuracy of 84.82680722891567\n",
            "Epoch #3. Batch Id 166/278  is having validation loss of 0.544521689414978\n",
            "0.3697461187839508\n",
            "Epoch #3. Batch Id 166/278  is having validation accuracy of 84.82410179640719\n",
            "Epoch #3. Batch Id 167/278  is having validation loss of 0.5461239814758301\n",
            "0.8137019872665405\n",
            "Epoch #3. Batch Id 167/278  is having validation accuracy of 84.84002976190476\n",
            "Epoch #3. Batch Id 168/278  is having validation loss of 0.5436215996742249\n",
            "0.1232212483882904\n",
            "Epoch #3. Batch Id 168/278  is having validation accuracy of 84.92973372781066\n",
            "Epoch #3. Batch Id 169/278  is having validation loss of 0.5420606136322021\n",
            "0.27825841307640076\n",
            "Epoch #3. Batch Id 169/278  is having validation accuracy of 85.0\n",
            "Epoch #3. Batch Id 170/278  is having validation loss of 0.5409995317459106\n",
            "0.36061227321624756\n",
            "Epoch #3. Batch Id 170/278  is having validation accuracy of 85.03289473684211\n",
            "Epoch #3. Batch Id 171/278  is having validation loss of 0.540738582611084\n",
            "0.4961126148700714\n",
            "Epoch #3. Batch Id 171/278  is having validation accuracy of 85.0109011627907\n",
            "Epoch #3. Batch Id 172/278  is having validation loss of 0.5392270088195801\n",
            "0.2792334258556366\n",
            "Epoch #3. Batch Id 172/278  is having validation accuracy of 85.0614161849711\n",
            "Epoch #3. Batch Id 173/278  is having validation loss of 0.539498507976532\n",
            "0.5864722728729248\n",
            "Epoch #3. Batch Id 173/278  is having validation accuracy of 85.05747126436782\n",
            "Epoch #3. Batch Id 174/278  is having validation loss of 0.5395318865776062\n",
            "0.5453388094902039\n",
            "Epoch #3. Batch Id 174/278  is having validation accuracy of 85.01785714285714\n",
            "Epoch #3. Batch Id 175/278  is having validation loss of 0.5405384302139282\n",
            "0.716680645942688\n",
            "Epoch #3. Batch Id 175/278  is having validation accuracy of 85.03196022727273\n",
            "Epoch #3. Batch Id 176/278  is having validation loss of 0.5396222472190857\n",
            "0.3783717751502991\n",
            "Epoch #3. Batch Id 176/278  is having validation accuracy of 85.0635593220339\n",
            "Epoch #3. Batch Id 177/278  is having validation loss of 0.5383707880973816\n",
            "0.31685781478881836\n",
            "Epoch #3. Batch Id 177/278  is having validation accuracy of 85.07724719101124\n",
            "Epoch #3. Batch Id 178/278  is having validation loss of 0.5383314490318298\n",
            "0.5313267707824707\n",
            "Epoch #3. Batch Id 178/278  is having validation accuracy of 85.05586592178771\n",
            "Epoch #3. Batch Id 179/278  is having validation loss of 0.5400362014770508\n",
            "0.8451844453811646\n",
            "Epoch #3. Batch Id 179/278  is having validation accuracy of 85.0\n",
            "Epoch #3. Batch Id 180/278  is having validation loss of 0.5411521196365356\n",
            "0.7420143485069275\n",
            "Epoch #3. Batch Id 180/278  is having validation accuracy of 84.9274861878453\n",
            "Epoch #3. Batch Id 181/278  is having validation loss of 0.540398895740509\n",
            "0.40406885743141174\n",
            "Epoch #3. Batch Id 181/278  is having validation accuracy of 84.95879120879121\n",
            "Epoch #3. Batch Id 182/278  is having validation loss of 0.540519654750824\n",
            "0.5624952912330627\n",
            "Epoch #3. Batch Id 182/278  is having validation accuracy of 84.9214480874317\n",
            "Epoch #3. Batch Id 183/278  is having validation loss of 0.540144681930542\n",
            "0.47152867913246155\n",
            "Epoch #3. Batch Id 183/278  is having validation accuracy of 84.91847826086956\n",
            "Epoch #3. Batch Id 184/278  is having validation loss of 0.5396838188171387\n",
            "0.4548836946487427\n",
            "Epoch #3. Batch Id 184/278  is having validation accuracy of 84.91554054054055\n",
            "Epoch #3. Batch Id 185/278  is having validation loss of 0.5388615727424622\n",
            "0.3867509961128235\n",
            "Epoch #3. Batch Id 185/278  is having validation accuracy of 84.94623655913979\n",
            "Epoch #3. Batch Id 186/278  is having validation loss of 0.5392414927482605\n",
            "0.6099041700363159\n",
            "Epoch #3. Batch Id 186/278  is having validation accuracy of 84.94318181818181\n",
            "Epoch #3. Batch Id 187/278  is having validation loss of 0.538077712059021\n",
            "0.3204536437988281\n",
            "Epoch #3. Batch Id 187/278  is having validation accuracy of 85.00664893617021\n",
            "Epoch #3. Batch Id 188/278  is having validation loss of 0.539088785648346\n",
            "0.7291688323020935\n",
            "Epoch #3. Batch Id 188/278  is having validation accuracy of 84.98677248677248\n",
            "Epoch #3. Batch Id 189/278  is having validation loss of 0.5404803156852722\n",
            "0.8034745454788208\n",
            "Epoch #3. Batch Id 189/278  is having validation accuracy of 84.95065789473684\n",
            "Epoch #3. Batch Id 190/278  is having validation loss of 0.5399993062019348\n",
            "0.4486120045185089\n",
            "Epoch #3. Batch Id 190/278  is having validation accuracy of 84.94764397905759\n",
            "Epoch #3. Batch Id 191/278  is having validation loss of 0.5432392358779907\n",
            "1.1620707511901855\n",
            "Epoch #3. Batch Id 191/278  is having validation accuracy of 84.92838541666667\n",
            "Epoch #3. Batch Id 192/278  is having validation loss of 0.5440369844436646\n",
            "0.6972038745880127\n",
            "Epoch #3. Batch Id 192/278  is having validation accuracy of 84.94170984455958\n",
            "Epoch #3. Batch Id 193/278  is having validation loss of 0.5454117655754089\n",
            "0.8107420206069946\n",
            "Epoch #3. Batch Id 193/278  is having validation accuracy of 84.8743556701031\n",
            "Epoch #3. Batch Id 194/278  is having validation loss of 0.544704794883728\n",
            "0.40755730867385864\n",
            "Epoch #3. Batch Id 194/278  is having validation accuracy of 84.85576923076923\n",
            "Epoch #3. Batch Id 195/278  is having validation loss of 0.5457408428192139\n",
            "0.7477659583091736\n",
            "Epoch #3. Batch Id 195/278  is having validation accuracy of 84.80548469387755\n",
            "Epoch #3. Batch Id 196/278  is having validation loss of 0.5459170937538147\n",
            "0.5804617404937744\n",
            "Epoch #3. Batch Id 196/278  is having validation accuracy of 84.77157360406092\n",
            "Epoch #3. Batch Id 197/278  is having validation loss of 0.5461846590042114\n",
            "0.5988911390304565\n",
            "Epoch #3. Batch Id 197/278  is having validation accuracy of 84.75378787878788\n",
            "Epoch #3. Batch Id 198/278  is having validation loss of 0.5487619638442993\n",
            "1.0590651035308838\n",
            "Epoch #3. Batch Id 198/278  is having validation accuracy of 84.70477386934674\n",
            "Epoch #3. Batch Id 199/278  is having validation loss of 0.5490740537643433\n",
            "0.6111844778060913\n",
            "Epoch #3. Batch Id 199/278  is having validation accuracy of 84.6875\n",
            "Epoch #3. Batch Id 200/278  is having validation loss of 0.5493142008781433\n",
            "0.5973440408706665\n",
            "Epoch #3. Batch Id 200/278  is having validation accuracy of 84.67039800995025\n",
            "Epoch #3. Batch Id 201/278  is having validation loss of 0.5498179793357849\n",
            "0.651073694229126\n",
            "Epoch #3. Batch Id 201/278  is having validation accuracy of 84.65346534653466\n",
            "Epoch #3. Batch Id 202/278  is having validation loss of 0.549988329410553\n",
            "0.5844012498855591\n",
            "Epoch #3. Batch Id 202/278  is having validation accuracy of 84.62130541871922\n",
            "Epoch #3. Batch Id 203/278  is having validation loss of 0.5501599907875061\n",
            "0.5850093364715576\n",
            "Epoch #3. Batch Id 203/278  is having validation accuracy of 84.62009803921569\n",
            "Epoch #3. Batch Id 204/278  is having validation loss of 0.5492152571678162\n",
            "0.3564877510070801\n",
            "Epoch #3. Batch Id 204/278  is having validation accuracy of 84.6189024390244\n",
            "Epoch #3. Batch Id 205/278  is having validation loss of 0.5486520528793335\n",
            "0.4332003593444824\n",
            "Epoch #3. Batch Id 205/278  is having validation accuracy of 84.63288834951456\n",
            "Epoch #3. Batch Id 206/278  is having validation loss of 0.5474802255630493\n",
            "0.3060869574546814\n",
            "Epoch #3. Batch Id 206/278  is having validation accuracy of 84.66183574879227\n",
            "Epoch #3. Batch Id 207/278  is having validation loss of 0.5468417406082153\n",
            "0.41467735171318054\n",
            "Epoch #3. Batch Id 207/278  is having validation accuracy of 84.67548076923077\n",
            "Epoch #3. Batch Id 208/278  is having validation loss of 0.5468382239341736\n",
            "0.5461099147796631\n",
            "Epoch #3. Batch Id 208/278  is having validation accuracy of 84.6590909090909\n",
            "Epoch #3. Batch Id 209/278  is having validation loss of 0.5454822182655334\n",
            "0.2620714604854584\n",
            "Epoch #3. Batch Id 209/278  is having validation accuracy of 84.70238095238095\n",
            "Epoch #3. Batch Id 210/278  is having validation loss of 0.5481947064399719\n",
            "1.1178213357925415\n",
            "Epoch #3. Batch Id 210/278  is having validation accuracy of 84.62677725118483\n",
            "Epoch #3. Batch Id 211/278  is having validation loss of 0.5480652451515198\n",
            "0.5207508206367493\n",
            "Epoch #3. Batch Id 211/278  is having validation accuracy of 84.64033018867924\n",
            "Epoch #3. Batch Id 212/278  is having validation loss of 0.5505096316337585\n",
            "1.0687168836593628\n",
            "Epoch #3. Batch Id 212/278  is having validation accuracy of 84.58039906103286\n",
            "Epoch #3. Batch Id 213/278  is having validation loss of 0.551742434501648\n",
            "0.814329206943512\n",
            "Epoch #3. Batch Id 213/278  is having validation accuracy of 84.50642523364486\n",
            "Epoch #3. Batch Id 214/278  is having validation loss of 0.5523850321769714\n",
            "0.6899011731147766\n",
            "Epoch #3. Batch Id 214/278  is having validation accuracy of 84.50581395348837\n",
            "Epoch #3. Batch Id 215/278  is having validation loss of 0.5528081059455872\n",
            "0.643763542175293\n",
            "Epoch #3. Batch Id 215/278  is having validation accuracy of 84.49074074074075\n",
            "Epoch #3. Batch Id 216/278  is having validation loss of 0.5530925393104553\n",
            "0.6145334243774414\n",
            "Epoch #3. Batch Id 216/278  is having validation accuracy of 84.50460829493088\n",
            "Epoch #3. Batch Id 217/278  is having validation loss of 0.554345965385437\n",
            "0.826343834400177\n",
            "Epoch #3. Batch Id 217/278  is having validation accuracy of 84.46100917431193\n",
            "Epoch #3. Batch Id 218/278  is having validation loss of 0.5544807314872742\n",
            "0.5838536620140076\n",
            "Epoch #3. Batch Id 218/278  is having validation accuracy of 84.40353881278538\n",
            "Epoch #3. Batch Id 219/278  is having validation loss of 0.5547205805778503\n",
            "0.6072444915771484\n",
            "Epoch #3. Batch Id 219/278  is having validation accuracy of 84.43181818181819\n",
            "Epoch #3. Batch Id 220/278  is having validation loss of 0.5539301037788391\n",
            "0.38002920150756836\n",
            "Epoch #3. Batch Id 220/278  is having validation accuracy of 84.44570135746606\n",
            "Epoch #3. Batch Id 221/278  is having validation loss of 0.5533422231674194\n",
            "0.42341482639312744\n",
            "Epoch #3. Batch Id 221/278  is having validation accuracy of 84.45945945945945\n",
            "Epoch #3. Batch Id 222/278  is having validation loss of 0.5539197325706482\n",
            "0.6821205615997314\n",
            "Epoch #3. Batch Id 222/278  is having validation accuracy of 84.4310538116592\n",
            "Epoch #3. Batch Id 223/278  is having validation loss of 0.5534389615058899\n",
            "0.4462207853794098\n",
            "Epoch #3. Batch Id 223/278  is having validation accuracy of 84.44475446428571\n",
            "Epoch #3. Batch Id 224/278  is having validation loss of 0.5538668632507324\n",
            "0.6497227549552917\n",
            "Epoch #3. Batch Id 224/278  is having validation accuracy of 84.44444444444444\n",
            "Epoch #3. Batch Id 225/278  is having validation loss of 0.5536006093025208\n",
            "0.49368855357170105\n",
            "Epoch #3. Batch Id 225/278  is having validation accuracy of 84.47179203539822\n",
            "Epoch #3. Batch Id 226/278  is having validation loss of 0.5531466007232666\n",
            "0.45054692029953003\n",
            "Epoch #3. Batch Id 226/278  is having validation accuracy of 84.4851321585903\n",
            "Epoch #3. Batch Id 227/278  is having validation loss of 0.5538199543952942\n",
            "0.7066754102706909\n",
            "Epoch #3. Batch Id 227/278  is having validation accuracy of 84.47094298245614\n",
            "Epoch #3. Batch Id 228/278  is having validation loss of 0.5541754364967346\n",
            "0.6352265477180481\n",
            "Epoch #3. Batch Id 228/278  is having validation accuracy of 84.48417030567686\n",
            "Epoch #3. Batch Id 229/278  is having validation loss of 0.5559725761413574\n",
            "0.9675207138061523\n",
            "Epoch #3. Batch Id 229/278  is having validation accuracy of 84.45652173913044\n",
            "Epoch #3. Batch Id 230/278  is having validation loss of 0.5558892488479614\n",
            "0.5367252826690674\n",
            "Epoch #3. Batch Id 230/278  is having validation accuracy of 84.4426406926407\n",
            "Epoch #3. Batch Id 231/278  is having validation loss of 0.5542051196098328\n",
            "0.16517217457294464\n",
            "Epoch #3. Batch Id 231/278  is having validation accuracy of 84.50969827586206\n",
            "Epoch #3. Batch Id 232/278  is having validation loss of 0.5538745522499084\n",
            "0.4771772623062134\n",
            "Epoch #3. Batch Id 232/278  is having validation accuracy of 84.53594420600858\n",
            "Epoch #3. Batch Id 233/278  is having validation loss of 0.5531105399131775\n",
            "0.3751008212566376\n",
            "Epoch #3. Batch Id 233/278  is having validation accuracy of 84.54861111111111\n",
            "Epoch #3. Batch Id 234/278  is having validation loss of 0.5521578192710876\n",
            "0.32921546697616577\n",
            "Epoch #3. Batch Id 234/278  is having validation accuracy of 84.57446808510639\n",
            "Epoch #3. Batch Id 235/278  is having validation loss of 0.5523050427436829\n",
            "0.586907148361206\n",
            "Epoch #3. Batch Id 235/278  is having validation accuracy of 84.58686440677967\n",
            "Epoch #3. Batch Id 236/278  is having validation loss of 0.5529667139053345\n",
            "0.7091225385665894\n",
            "Epoch #3. Batch Id 236/278  is having validation accuracy of 84.5464135021097\n",
            "Epoch #3. Batch Id 237/278  is having validation loss of 0.5521087050437927\n",
            "0.348755419254303\n",
            "Epoch #3. Batch Id 237/278  is having validation accuracy of 84.5719537815126\n",
            "Epoch #3. Batch Id 238/278  is having validation loss of 0.5531578063964844\n",
            "0.8028489947319031\n",
            "Epoch #3. Batch Id 238/278  is having validation accuracy of 84.57112970711297\n",
            "Epoch #3. Batch Id 239/278  is having validation loss of 0.551684558391571\n",
            "0.1995774209499359\n",
            "Epoch #3. Batch Id 239/278  is having validation accuracy of 84.609375\n",
            "Epoch #3. Batch Id 240/278  is having validation loss of 0.5533885955810547\n",
            "0.9623581171035767\n",
            "Epoch #3. Batch Id 240/278  is having validation accuracy of 84.58246887966806\n",
            "Epoch #3. Batch Id 241/278  is having validation loss of 0.5533338189125061\n",
            "0.5401306748390198\n",
            "Epoch #3. Batch Id 241/278  is having validation accuracy of 84.59452479338843\n",
            "Epoch #3. Batch Id 242/278  is having validation loss of 0.552107036113739\n",
            "0.2552321255207062\n",
            "Epoch #3. Batch Id 242/278  is having validation accuracy of 84.64506172839506\n",
            "Epoch #3. Batch Id 243/278  is having validation loss of 0.5510661602020264\n",
            "0.2981390357017517\n",
            "Epoch #3. Batch Id 243/278  is having validation accuracy of 84.66956967213115\n",
            "Epoch #3. Batch Id 244/278  is having validation loss of 0.5520646572113037\n",
            "0.7956946492195129\n",
            "Epoch #3. Batch Id 244/278  is having validation accuracy of 84.63010204081633\n",
            "Epoch #3. Batch Id 245/278  is having validation loss of 0.5526294112205505\n",
            "0.6910003423690796\n",
            "Epoch #3. Batch Id 245/278  is having validation accuracy of 84.61636178861788\n",
            "Epoch #3. Batch Id 246/278  is having validation loss of 0.5557785630226135\n",
            "1.3304741382598877\n",
            "Epoch #3. Batch Id 246/278  is having validation accuracy of 84.55212550607287\n",
            "Epoch #3. Batch Id 247/278  is having validation loss of 0.5556323528289795\n",
            "0.5195159316062927\n",
            "Epoch #3. Batch Id 247/278  is having validation accuracy of 84.56401209677419\n",
            "Epoch #3. Batch Id 248/278  is having validation loss of 0.5560597777366638\n",
            "0.6620619297027588\n",
            "Epoch #3. Batch Id 248/278  is having validation accuracy of 84.5632530120482\n",
            "Epoch #3. Batch Id 249/278  is having validation loss of 0.5560741424560547\n",
            "0.5596489310264587\n",
            "Epoch #3. Batch Id 249/278  is having validation accuracy of 84.55\n",
            "Epoch #3. Batch Id 250/278  is having validation loss of 0.5575584173202515\n",
            "0.9286267161369324\n",
            "Epoch #3. Batch Id 250/278  is having validation accuracy of 84.49950199203187\n",
            "Epoch #3. Batch Id 251/278  is having validation loss of 0.5586931109428406\n",
            "0.8434988260269165\n",
            "Epoch #3. Batch Id 251/278  is having validation accuracy of 84.46180555555556\n",
            "Epoch #3. Batch Id 252/278  is having validation loss of 0.558052659034729\n",
            "0.39666521549224854\n",
            "Epoch #3. Batch Id 252/278  is having validation accuracy of 84.49851778656127\n",
            "Epoch #3. Batch Id 253/278  is having validation loss of 0.5593323707580566\n",
            "0.8830984234809875\n",
            "Epoch #3. Batch Id 253/278  is having validation accuracy of 84.46112204724409\n",
            "Epoch #3. Batch Id 254/278  is having validation loss of 0.5589125752449036\n",
            "0.4522829055786133\n",
            "Epoch #3. Batch Id 254/278  is having validation accuracy of 84.46078431372548\n",
            "Epoch #3. Batch Id 255/278  is having validation loss of 0.558235228061676\n",
            "0.38550665974617004\n",
            "Epoch #3. Batch Id 255/278  is having validation accuracy of 84.4482421875\n",
            "Epoch #3. Batch Id 256/278  is having validation loss of 0.5574345588684082\n",
            "0.3524557054042816\n",
            "Epoch #3. Batch Id 256/278  is having validation accuracy of 84.44795719844358\n",
            "Epoch #3. Batch Id 257/278  is having validation loss of 0.5562455058097839\n",
            "0.2506660223007202\n",
            "Epoch #3. Batch Id 257/278  is having validation accuracy of 84.49612403100775\n",
            "Epoch #3. Batch Id 258/278  is having validation loss of 0.5557346940040588\n",
            "0.4239433705806732\n",
            "Epoch #3. Batch Id 258/278  is having validation accuracy of 84.51978764478764\n",
            "Epoch #3. Batch Id 259/278  is having validation loss of 0.5551678538322449\n",
            "0.40835869312286377\n",
            "Epoch #3. Batch Id 259/278  is having validation accuracy of 84.55528846153847\n",
            "Epoch #3. Batch Id 260/278  is having validation loss of 0.5539132356643677\n",
            "0.22771687805652618\n",
            "Epoch #3. Batch Id 260/278  is having validation accuracy of 84.59051724137932\n",
            "Epoch #3. Batch Id 261/278  is having validation loss of 0.5530735850334167\n",
            "0.3339207172393799\n",
            "Epoch #3. Batch Id 261/278  is having validation accuracy of 84.60162213740458\n",
            "Epoch #3. Batch Id 262/278  is having validation loss of 0.5529984831809998\n",
            "0.5333207249641418\n",
            "Epoch #3. Batch Id 262/278  is having validation accuracy of 84.5888783269962\n",
            "Epoch #3. Batch Id 263/278  is having validation loss of 0.5535624623298645\n",
            "0.7018952369689941\n",
            "Epoch #3. Batch Id 263/278  is having validation accuracy of 84.56439393939394\n",
            "Epoch #3. Batch Id 264/278  is having validation loss of 0.5532453060150146\n",
            "0.46951109170913696\n",
            "Epoch #3. Batch Id 264/278  is having validation accuracy of 84.5872641509434\n",
            "Epoch #3. Batch Id 265/278  is having validation loss of 0.5540667772293091\n",
            "0.7717548608779907\n",
            "Epoch #3. Batch Id 265/278  is having validation accuracy of 84.57471804511279\n",
            "Epoch #3. Batch Id 266/278  is having validation loss of 0.5544607639312744\n",
            "0.6592611074447632\n",
            "Epoch #3. Batch Id 266/278  is having validation accuracy of 84.57397003745318\n",
            "Epoch #3. Batch Id 267/278  is having validation loss of 0.5533654093742371\n",
            "0.2609134912490845\n",
            "Epoch #3. Batch Id 267/278  is having validation accuracy of 84.61986940298507\n",
            "Epoch #3. Batch Id 268/278  is having validation loss of 0.5529490113258362\n",
            "0.4413619041442871\n",
            "Epoch #3. Batch Id 268/278  is having validation accuracy of 84.64219330855019\n",
            "Epoch #3. Batch Id 269/278  is having validation loss of 0.5521777868270874\n",
            "0.34472182393074036\n",
            "Epoch #3. Batch Id 269/278  is having validation accuracy of 84.62962962962963\n",
            "Epoch #3. Batch Id 270/278  is having validation loss of 0.553255021572113\n",
            "0.8441060781478882\n",
            "Epoch #3. Batch Id 270/278  is having validation accuracy of 84.58256457564576\n",
            "Epoch #3. Batch Id 271/278  is having validation loss of 0.5537793636322021\n",
            "0.6958692669868469\n",
            "Epoch #3. Batch Id 271/278  is having validation accuracy of 84.58180147058823\n",
            "Epoch #3. Batch Id 272/278  is having validation loss of 0.5548630356788635\n",
            "0.8496187925338745\n",
            "Epoch #3. Batch Id 272/278  is having validation accuracy of 84.5467032967033\n",
            "Epoch #3. Batch Id 273/278  is having validation loss of 0.556207001209259\n",
            "0.9231123328208923\n",
            "Epoch #3. Batch Id 273/278  is having validation accuracy of 84.52326642335767\n",
            "Epoch #3. Batch Id 274/278  is having validation loss of 0.5555787682533264\n",
            "0.383441686630249\n",
            "Epoch #3. Batch Id 274/278  is having validation accuracy of 84.54545454545455\n",
            "Epoch #3. Batch Id 275/278  is having validation loss of 0.5562583804130554\n",
            "0.7431542873382568\n",
            "Epoch #3. Batch Id 275/278  is having validation accuracy of 84.55615942028986\n",
            "Epoch #3. Batch Id 276/278  is having validation loss of 0.5557230114936829\n",
            "0.4079640507698059\n",
            "Epoch #3. Batch Id 276/278  is having validation accuracy of 84.5667870036101\n",
            "Epoch #3. Batch Id 277/278  is having validation loss of 0.5537522435188293\n",
            "0.007849754765629768\n",
            "Epoch #3. Batch Id 277/278  is having validation accuracy of 84.57374830852504\n",
            "Эпоха #3 train_loss: 5.126349606143776e-06, val_loss: 6.244386895559728e-05\n",
            "Потрачено 8.8 минут на 3 эпоху\n",
            "Batch Id 0 is having training loss of 0.358568012714386\n",
            "0.358568012714386\n",
            "Epoch #4. Accuracy on batch 0/3013  on Training is 84.375\n",
            "Epoch #4. Accuracy on batch 1/3013  on Training is 84.375\n",
            "Epoch #4. Accuracy on batch 2/3013  on Training is 85.41666666666667\n",
            "Epoch #4. Accuracy on batch 3/3013  on Training is 87.5\n",
            "Epoch #4. Accuracy on batch 4/3013  on Training is 88.75\n",
            "Epoch #4. Accuracy on batch 5/3013  on Training is 90.625\n",
            "Epoch #4. Accuracy on batch 6/3013  on Training is 89.73214285714286\n",
            "Epoch #4. Accuracy on batch 7/3013  on Training is 91.015625\n",
            "Epoch #4. Accuracy on batch 8/3013  on Training is 91.66666666666667\n",
            "Epoch #4. Accuracy on batch 9/3013  on Training is 92.1875\n",
            "Epoch #4. Accuracy on batch 10/3013  on Training is 91.47727272727273\n",
            "Epoch #4. Accuracy on batch 11/3013  on Training is 90.625\n",
            "Epoch #4. Accuracy on batch 12/3013  on Training is 90.625\n",
            "Epoch #4. Accuracy on batch 13/3013  on Training is 90.625\n",
            "Epoch #4. Accuracy on batch 14/3013  on Training is 90.41666666666667\n",
            "Epoch #4. Accuracy on batch 15/3013  on Training is 89.2578125\n",
            "Epoch #4. Accuracy on batch 16/3013  on Training is 88.6029411764706\n",
            "Epoch #4. Accuracy on batch 17/3013  on Training is 88.19444444444444\n",
            "Epoch #4. Accuracy on batch 18/3013  on Training is 87.99342105263158\n",
            "Epoch #4. Accuracy on batch 19/3013  on Training is 87.96875\n",
            "Batch Id 20 is having training loss of 0.4164620637893677\n",
            "0.1038336455821991\n",
            "Epoch #4. Accuracy on batch 20/3013  on Training is 88.39285714285714\n",
            "Epoch #4. Accuracy on batch 21/3013  on Training is 87.92613636363636\n",
            "Epoch #4. Accuracy on batch 22/3013  on Training is 88.31521739130434\n",
            "Epoch #4. Accuracy on batch 23/3013  on Training is 88.02083333333333\n",
            "Epoch #4. Accuracy on batch 24/3013  on Training is 88.0\n",
            "Epoch #4. Accuracy on batch 25/3013  on Training is 88.10096153846153\n",
            "Epoch #4. Accuracy on batch 26/3013  on Training is 88.19444444444444\n",
            "Epoch #4. Accuracy on batch 27/3013  on Training is 87.83482142857143\n",
            "Epoch #4. Accuracy on batch 28/3013  on Training is 88.14655172413794\n",
            "Epoch #4. Accuracy on batch 29/3013  on Training is 88.4375\n",
            "Epoch #4. Accuracy on batch 30/3013  on Training is 88.81048387096774\n",
            "Epoch #4. Accuracy on batch 31/3013  on Training is 88.76953125\n",
            "Epoch #4. Accuracy on batch 32/3013  on Training is 88.63636363636364\n",
            "Epoch #4. Accuracy on batch 33/3013  on Training is 88.51102941176471\n",
            "Epoch #4. Accuracy on batch 34/3013  on Training is 88.75\n",
            "Epoch #4. Accuracy on batch 35/3013  on Training is 88.62847222222223\n",
            "Epoch #4. Accuracy on batch 36/3013  on Training is 88.76689189189189\n",
            "Epoch #4. Accuracy on batch 37/3013  on Training is 88.48684210526316\n",
            "Epoch #4. Accuracy on batch 38/3013  on Training is 88.46153846153847\n",
            "Epoch #4. Accuracy on batch 39/3013  on Training is 88.59375\n",
            "Batch Id 40 is having training loss of 0.4135187566280365\n",
            "0.40753263235092163\n",
            "Epoch #4. Accuracy on batch 40/3013  on Training is 88.64329268292683\n",
            "Epoch #4. Accuracy on batch 41/3013  on Training is 88.76488095238095\n",
            "Epoch #4. Accuracy on batch 42/3013  on Training is 88.66279069767442\n",
            "Epoch #4. Accuracy on batch 43/3013  on Training is 88.7784090909091\n",
            "Epoch #4. Accuracy on batch 44/3013  on Training is 88.68055555555556\n",
            "Epoch #4. Accuracy on batch 45/3013  on Training is 88.79076086956522\n",
            "Epoch #4. Accuracy on batch 46/3013  on Training is 88.69680851063829\n",
            "Epoch #4. Accuracy on batch 47/3013  on Training is 88.54166666666667\n",
            "Epoch #4. Accuracy on batch 48/3013  on Training is 88.39285714285714\n",
            "Epoch #4. Accuracy on batch 49/3013  on Training is 88.5\n",
            "Epoch #4. Accuracy on batch 50/3013  on Training is 88.66421568627452\n",
            "Epoch #4. Accuracy on batch 51/3013  on Training is 88.70192307692308\n",
            "Epoch #4. Accuracy on batch 52/3013  on Training is 88.73820754716981\n",
            "Epoch #4. Accuracy on batch 53/3013  on Training is 88.77314814814815\n",
            "Epoch #4. Accuracy on batch 54/3013  on Training is 88.69318181818181\n",
            "Epoch #4. Accuracy on batch 55/3013  on Training is 88.78348214285714\n",
            "Epoch #4. Accuracy on batch 56/3013  on Training is 88.7609649122807\n",
            "Epoch #4. Accuracy on batch 57/3013  on Training is 88.84698275862068\n",
            "Epoch #4. Accuracy on batch 58/3013  on Training is 88.77118644067797\n",
            "Epoch #4. Accuracy on batch 59/3013  on Training is 88.85416666666667\n",
            "Batch Id 60 is having training loss of 0.4078174829483032\n",
            "0.48966988921165466\n",
            "Epoch #4. Accuracy on batch 60/3013  on Training is 88.78073770491804\n",
            "Epoch #4. Accuracy on batch 61/3013  on Training is 88.86088709677419\n",
            "Epoch #4. Accuracy on batch 62/3013  on Training is 88.69047619047619\n",
            "Epoch #4. Accuracy on batch 63/3013  on Training is 88.4765625\n",
            "Epoch #4. Accuracy on batch 64/3013  on Training is 88.50961538461539\n",
            "Epoch #4. Accuracy on batch 65/3013  on Training is 88.54166666666667\n",
            "Epoch #4. Accuracy on batch 66/3013  on Training is 88.61940298507463\n",
            "Epoch #4. Accuracy on batch 67/3013  on Training is 88.69485294117646\n",
            "Epoch #4. Accuracy on batch 68/3013  on Training is 88.6322463768116\n",
            "Epoch #4. Accuracy on batch 69/3013  on Training is 88.66071428571429\n",
            "Epoch #4. Accuracy on batch 70/3013  on Training is 88.60035211267606\n",
            "Epoch #4. Accuracy on batch 71/3013  on Training is 88.58506944444444\n",
            "Epoch #4. Accuracy on batch 72/3013  on Training is 88.57020547945206\n",
            "Epoch #4. Accuracy on batch 73/3013  on Training is 88.59797297297297\n",
            "Epoch #4. Accuracy on batch 74/3013  on Training is 88.54166666666667\n",
            "Epoch #4. Accuracy on batch 75/3013  on Training is 88.61019736842105\n",
            "Epoch #4. Accuracy on batch 76/3013  on Training is 88.59577922077922\n",
            "Epoch #4. Accuracy on batch 77/3013  on Training is 88.50160256410257\n",
            "Epoch #4. Accuracy on batch 78/3013  on Training is 88.48892405063292\n",
            "Epoch #4. Accuracy on batch 79/3013  on Training is 88.5546875\n",
            "Batch Id 80 is having training loss of 0.4118000268936157\n",
            "0.5506386756896973\n",
            "Epoch #4. Accuracy on batch 80/3013  on Training is 88.50308641975309\n",
            "Epoch #4. Accuracy on batch 81/3013  on Training is 88.52896341463415\n",
            "Epoch #4. Accuracy on batch 82/3013  on Training is 88.4789156626506\n",
            "Epoch #4. Accuracy on batch 83/3013  on Training is 88.54166666666667\n",
            "Epoch #4. Accuracy on batch 84/3013  on Training is 88.41911764705883\n",
            "Epoch #4. Accuracy on batch 85/3013  on Training is 88.44476744186046\n",
            "Epoch #4. Accuracy on batch 86/3013  on Training is 88.39798850574712\n",
            "Epoch #4. Accuracy on batch 87/3013  on Training is 88.45880681818181\n",
            "Epoch #4. Accuracy on batch 88/3013  on Training is 88.41292134831461\n",
            "Epoch #4. Accuracy on batch 89/3013  on Training is 88.47222222222223\n",
            "Epoch #4. Accuracy on batch 90/3013  on Training is 88.56456043956044\n",
            "Epoch #4. Accuracy on batch 91/3013  on Training is 88.4850543478261\n",
            "Epoch #4. Accuracy on batch 92/3013  on Training is 88.44086021505376\n",
            "Epoch #4. Accuracy on batch 93/3013  on Training is 88.36436170212765\n",
            "Epoch #4. Accuracy on batch 94/3013  on Training is 88.45394736842105\n",
            "Epoch #4. Accuracy on batch 95/3013  on Training is 88.44401041666667\n",
            "Epoch #4. Accuracy on batch 96/3013  on Training is 88.4020618556701\n",
            "Epoch #4. Accuracy on batch 97/3013  on Training is 88.48852040816327\n",
            "Epoch #4. Accuracy on batch 98/3013  on Training is 88.51010101010101\n",
            "Epoch #4. Accuracy on batch 99/3013  on Training is 88.625\n",
            "Batch Id 100 is having training loss of 0.40655985474586487\n",
            "0.5726876854896545\n",
            "Epoch #4. Accuracy on batch 100/3013  on Training is 88.58292079207921\n",
            "Epoch #4. Accuracy on batch 101/3013  on Training is 88.51102941176471\n",
            "Epoch #4. Accuracy on batch 102/3013  on Training is 88.37985436893204\n",
            "Epoch #4. Accuracy on batch 103/3013  on Training is 88.31129807692308\n",
            "Epoch #4. Accuracy on batch 104/3013  on Training is 88.33333333333333\n",
            "Epoch #4. Accuracy on batch 105/3013  on Training is 88.2370283018868\n",
            "Epoch #4. Accuracy on batch 106/3013  on Training is 88.23014018691589\n",
            "Epoch #4. Accuracy on batch 107/3013  on Training is 88.25231481481481\n",
            "Epoch #4. Accuracy on batch 108/3013  on Training is 88.2454128440367\n",
            "Epoch #4. Accuracy on batch 109/3013  on Training is 88.21022727272727\n",
            "Epoch #4. Accuracy on batch 110/3013  on Training is 88.17567567567568\n",
            "Epoch #4. Accuracy on batch 111/3013  on Training is 88.16964285714286\n",
            "Epoch #4. Accuracy on batch 112/3013  on Training is 88.2466814159292\n",
            "Epoch #4. Accuracy on batch 113/3013  on Training is 88.29495614035088\n",
            "Epoch #4. Accuracy on batch 114/3013  on Training is 88.3695652173913\n",
            "Epoch #4. Accuracy on batch 115/3013  on Training is 88.44288793103448\n",
            "Epoch #4. Accuracy on batch 116/3013  on Training is 88.38141025641026\n",
            "Epoch #4. Accuracy on batch 117/3013  on Training is 88.40042372881356\n",
            "Epoch #4. Accuracy on batch 118/3013  on Training is 88.47163865546219\n",
            "Epoch #4. Accuracy on batch 119/3013  on Training is 88.48958333333333\n",
            "Batch Id 120 is having training loss of 0.40926578640937805\n",
            "0.1902415007352829\n",
            "Epoch #4. Accuracy on batch 120/3013  on Training is 88.53305785123968\n",
            "Epoch #4. Accuracy on batch 121/3013  on Training is 88.47336065573771\n",
            "Epoch #4. Accuracy on batch 122/3013  on Training is 88.49085365853658\n",
            "Epoch #4. Accuracy on batch 123/3013  on Training is 88.50806451612904\n",
            "Epoch #4. Accuracy on batch 124/3013  on Training is 88.55\n",
            "Epoch #4. Accuracy on batch 125/3013  on Training is 88.59126984126983\n",
            "Epoch #4. Accuracy on batch 126/3013  on Training is 88.55807086614173\n",
            "Epoch #4. Accuracy on batch 127/3013  on Training is 88.5986328125\n",
            "Epoch #4. Accuracy on batch 128/3013  on Training is 88.66279069767442\n",
            "Epoch #4. Accuracy on batch 129/3013  on Training is 88.6298076923077\n",
            "Epoch #4. Accuracy on batch 130/3013  on Training is 88.64503816793894\n",
            "Epoch #4. Accuracy on batch 131/3013  on Training is 88.63636363636364\n",
            "Epoch #4. Accuracy on batch 132/3013  on Training is 88.60432330827068\n",
            "Epoch #4. Accuracy on batch 133/3013  on Training is 88.50279850746269\n",
            "Epoch #4. Accuracy on batch 134/3013  on Training is 88.49537037037037\n",
            "Epoch #4. Accuracy on batch 135/3013  on Training is 88.51102941176471\n",
            "Epoch #4. Accuracy on batch 136/3013  on Training is 88.5264598540146\n",
            "Epoch #4. Accuracy on batch 137/3013  on Training is 88.51902173913044\n",
            "Epoch #4. Accuracy on batch 138/3013  on Training is 88.44424460431655\n",
            "Epoch #4. Accuracy on batch 139/3013  on Training is 88.41517857142857\n",
            "Batch Id 140 is having training loss of 0.40986761450767517\n",
            "0.7389364242553711\n",
            "Epoch #4. Accuracy on batch 140/3013  on Training is 88.36436170212765\n",
            "Epoch #4. Accuracy on batch 141/3013  on Training is 88.35827464788733\n",
            "Epoch #4. Accuracy on batch 142/3013  on Training is 88.33041958041959\n",
            "Epoch #4. Accuracy on batch 143/3013  on Training is 88.28125\n",
            "Epoch #4. Accuracy on batch 144/3013  on Training is 88.27586206896552\n",
            "Epoch #4. Accuracy on batch 145/3013  on Training is 88.24914383561644\n",
            "Epoch #4. Accuracy on batch 146/3013  on Training is 88.26530612244898\n",
            "Epoch #4. Accuracy on batch 147/3013  on Training is 88.23902027027027\n",
            "Epoch #4. Accuracy on batch 148/3013  on Training is 88.21308724832215\n",
            "Epoch #4. Accuracy on batch 149/3013  on Training is 88.1875\n",
            "Epoch #4. Accuracy on batch 150/3013  on Training is 88.18294701986756\n",
            "Epoch #4. Accuracy on batch 151/3013  on Training is 88.17845394736842\n",
            "Epoch #4. Accuracy on batch 152/3013  on Training is 88.13316993464052\n",
            "Epoch #4. Accuracy on batch 153/3013  on Training is 88.14935064935065\n",
            "Epoch #4. Accuracy on batch 154/3013  on Training is 88.125\n",
            "Epoch #4. Accuracy on batch 155/3013  on Training is 88.1610576923077\n",
            "Epoch #4. Accuracy on batch 156/3013  on Training is 88.19665605095541\n",
            "Epoch #4. Accuracy on batch 157/3013  on Training is 88.1131329113924\n",
            "Epoch #4. Accuracy on batch 158/3013  on Training is 88.08962264150944\n",
            "Epoch #4. Accuracy on batch 159/3013  on Training is 88.02734375\n",
            "Batch Id 160 is having training loss of 0.41759151220321655\n",
            "0.8556603193283081\n",
            "Epoch #4. Accuracy on batch 160/3013  on Training is 87.92701863354037\n",
            "Epoch #4. Accuracy on batch 161/3013  on Training is 87.8858024691358\n",
            "Epoch #4. Accuracy on batch 162/3013  on Training is 87.90260736196319\n",
            "Epoch #4. Accuracy on batch 163/3013  on Training is 87.86204268292683\n",
            "Epoch #4. Accuracy on batch 164/3013  on Training is 87.8409090909091\n",
            "Epoch #4. Accuracy on batch 165/3013  on Training is 87.87650602409639\n",
            "Epoch #4. Accuracy on batch 166/3013  on Training is 87.89296407185628\n",
            "Epoch #4. Accuracy on batch 167/3013  on Training is 87.87202380952381\n",
            "Epoch #4. Accuracy on batch 168/3013  on Training is 87.88831360946746\n",
            "Epoch #4. Accuracy on batch 169/3013  on Training is 87.88602941176471\n",
            "Epoch #4. Accuracy on batch 170/3013  on Training is 87.90204678362574\n",
            "Epoch #4. Accuracy on batch 171/3013  on Training is 87.93604651162791\n",
            "Epoch #4. Accuracy on batch 172/3013  on Training is 87.87933526011561\n",
            "Epoch #4. Accuracy on batch 173/3013  on Training is 87.93103448275862\n",
            "Epoch #4. Accuracy on batch 174/3013  on Training is 87.92857142857143\n",
            "Epoch #4. Accuracy on batch 175/3013  on Training is 87.890625\n",
            "Epoch #4. Accuracy on batch 176/3013  on Training is 87.85310734463278\n",
            "Epoch #4. Accuracy on batch 177/3013  on Training is 87.85112359550561\n",
            "Epoch #4. Accuracy on batch 178/3013  on Training is 87.81424581005587\n",
            "Epoch #4. Accuracy on batch 179/3013  on Training is 87.77777777777777\n",
            "Batch Id 180 is having training loss of 0.4186044931411743\n",
            "0.2094954401254654\n",
            "Epoch #4. Accuracy on batch 180/3013  on Training is 87.81077348066299\n",
            "Epoch #4. Accuracy on batch 181/3013  on Training is 87.77472527472527\n",
            "Epoch #4. Accuracy on batch 182/3013  on Training is 87.80737704918033\n",
            "Epoch #4. Accuracy on batch 183/3013  on Training is 87.80570652173913\n",
            "Epoch #4. Accuracy on batch 184/3013  on Training is 87.80405405405405\n",
            "Epoch #4. Accuracy on batch 185/3013  on Training is 87.81922043010752\n",
            "Epoch #4. Accuracy on batch 186/3013  on Training is 87.75066844919786\n",
            "Epoch #4. Accuracy on batch 187/3013  on Training is 87.76595744680851\n",
            "Epoch #4. Accuracy on batch 188/3013  on Training is 87.76455026455027\n",
            "Epoch #4. Accuracy on batch 189/3013  on Training is 87.76315789473684\n",
            "Epoch #4. Accuracy on batch 190/3013  on Training is 87.76178010471205\n",
            "Epoch #4. Accuracy on batch 191/3013  on Training is 87.77669270833333\n",
            "Epoch #4. Accuracy on batch 192/3013  on Training is 87.77525906735751\n",
            "Epoch #4. Accuracy on batch 193/3013  on Training is 87.80605670103093\n",
            "Epoch #4. Accuracy on batch 194/3013  on Training is 87.75641025641026\n",
            "Epoch #4. Accuracy on batch 195/3013  on Training is 87.77104591836735\n",
            "Epoch #4. Accuracy on batch 196/3013  on Training is 87.76967005076142\n",
            "Epoch #4. Accuracy on batch 197/3013  on Training is 87.73674242424242\n",
            "Epoch #4. Accuracy on batch 198/3013  on Training is 87.75125628140704\n",
            "Epoch #4. Accuracy on batch 199/3013  on Training is 87.75\n",
            "Batch Id 200 is having training loss of 0.42071226239204407\n",
            "0.3275771737098694\n",
            "Epoch #4. Accuracy on batch 200/3013  on Training is 87.76430348258707\n",
            "Epoch #4. Accuracy on batch 201/3013  on Training is 87.82487623762377\n",
            "Epoch #4. Accuracy on batch 202/3013  on Training is 87.80788177339902\n",
            "Epoch #4. Accuracy on batch 203/3013  on Training is 87.83700980392157\n",
            "Epoch #4. Accuracy on batch 204/3013  on Training is 87.85060975609755\n",
            "Epoch #4. Accuracy on batch 205/3013  on Training is 87.80339805825243\n",
            "Epoch #4. Accuracy on batch 206/3013  on Training is 87.81702898550725\n",
            "Epoch #4. Accuracy on batch 207/3013  on Training is 87.7704326923077\n",
            "Epoch #4. Accuracy on batch 208/3013  on Training is 87.67942583732058\n",
            "Epoch #4. Accuracy on batch 209/3013  on Training is 87.69345238095238\n",
            "Epoch #4. Accuracy on batch 210/3013  on Training is 87.6925355450237\n",
            "Epoch #4. Accuracy on batch 211/3013  on Training is 87.69162735849056\n",
            "Epoch #4. Accuracy on batch 212/3013  on Training is 87.72007042253522\n",
            "Epoch #4. Accuracy on batch 213/3013  on Training is 87.68983644859813\n",
            "Epoch #4. Accuracy on batch 214/3013  on Training is 87.65988372093024\n",
            "Epoch #4. Accuracy on batch 215/3013  on Training is 87.68807870370371\n",
            "Epoch #4. Accuracy on batch 216/3013  on Training is 87.67281105990783\n",
            "Epoch #4. Accuracy on batch 217/3013  on Training is 87.65768348623853\n",
            "Epoch #4. Accuracy on batch 218/3013  on Training is 87.67123287671232\n",
            "Epoch #4. Accuracy on batch 219/3013  on Training is 87.67045454545455\n",
            "Batch Id 220 is having training loss of 0.41944146156311035\n",
            "0.4702807366847992\n",
            "Epoch #4. Accuracy on batch 220/3013  on Training is 87.64140271493213\n",
            "Epoch #4. Accuracy on batch 221/3013  on Training is 87.64076576576576\n",
            "Epoch #4. Accuracy on batch 222/3013  on Training is 87.62612107623319\n",
            "Epoch #4. Accuracy on batch 223/3013  on Training is 87.61160714285714\n",
            "Epoch #4. Accuracy on batch 224/3013  on Training is 87.61111111111111\n",
            "Epoch #4. Accuracy on batch 225/3013  on Training is 87.61061946902655\n",
            "Epoch #4. Accuracy on batch 226/3013  on Training is 87.59636563876651\n",
            "Epoch #4. Accuracy on batch 227/3013  on Training is 87.62335526315789\n",
            "Epoch #4. Accuracy on batch 228/3013  on Training is 87.60917030567686\n",
            "Epoch #4. Accuracy on batch 229/3013  on Training is 87.5679347826087\n",
            "Epoch #4. Accuracy on batch 230/3013  on Training is 87.51352813852814\n",
            "Epoch #4. Accuracy on batch 231/3013  on Training is 87.52693965517241\n",
            "Epoch #4. Accuracy on batch 232/3013  on Training is 87.48658798283262\n",
            "Epoch #4. Accuracy on batch 233/3013  on Training is 87.5\n",
            "Epoch #4. Accuracy on batch 234/3013  on Training is 87.46010638297872\n",
            "Epoch #4. Accuracy on batch 235/3013  on Training is 87.5\n",
            "Epoch #4. Accuracy on batch 236/3013  on Training is 87.51318565400844\n",
            "Epoch #4. Accuracy on batch 237/3013  on Training is 87.53939075630252\n",
            "Epoch #4. Accuracy on batch 238/3013  on Training is 87.57845188284519\n",
            "Epoch #4. Accuracy on batch 239/3013  on Training is 87.60416666666667\n",
            "Batch Id 240 is having training loss of 0.42536669969558716\n",
            "0.8274530172348022\n",
            "Epoch #4. Accuracy on batch 240/3013  on Training is 87.53890041493776\n",
            "Epoch #4. Accuracy on batch 241/3013  on Training is 87.53873966942149\n",
            "Epoch #4. Accuracy on batch 242/3013  on Training is 87.55144032921811\n",
            "Epoch #4. Accuracy on batch 243/3013  on Training is 87.57684426229508\n",
            "Epoch #4. Accuracy on batch 244/3013  on Training is 87.56377551020408\n",
            "Epoch #4. Accuracy on batch 245/3013  on Training is 87.5635162601626\n",
            "Epoch #4. Accuracy on batch 246/3013  on Training is 87.57591093117409\n",
            "Epoch #4. Accuracy on batch 247/3013  on Training is 87.61340725806451\n",
            "Epoch #4. Accuracy on batch 248/3013  on Training is 87.63805220883535\n",
            "Epoch #4. Accuracy on batch 249/3013  on Training is 87.65\n",
            "Epoch #4. Accuracy on batch 250/3013  on Training is 87.5871513944223\n",
            "Epoch #4. Accuracy on batch 251/3013  on Training is 87.59920634920636\n",
            "Epoch #4. Accuracy on batch 252/3013  on Training is 87.61116600790514\n",
            "Epoch #4. Accuracy on batch 253/3013  on Training is 87.64763779527559\n",
            "Epoch #4. Accuracy on batch 254/3013  on Training is 87.6470588235294\n",
            "Epoch #4. Accuracy on batch 255/3013  on Training is 87.63427734375\n",
            "Epoch #4. Accuracy on batch 256/3013  on Training is 87.6215953307393\n",
            "Epoch #4. Accuracy on batch 257/3013  on Training is 87.60901162790698\n",
            "Epoch #4. Accuracy on batch 258/3013  on Training is 87.58445945945945\n",
            "Epoch #4. Accuracy on batch 259/3013  on Training is 87.58413461538461\n",
            "Batch Id 260 is having training loss of 0.4262699484825134\n",
            "0.31391844153404236\n",
            "Epoch #4. Accuracy on batch 260/3013  on Training is 87.60775862068965\n",
            "Epoch #4. Accuracy on batch 261/3013  on Training is 87.58349236641222\n",
            "Epoch #4. Accuracy on batch 262/3013  on Training is 87.61882129277566\n",
            "Epoch #4. Accuracy on batch 263/3013  on Training is 87.61837121212122\n",
            "Epoch #4. Accuracy on batch 264/3013  on Training is 87.55896226415095\n",
            "Epoch #4. Accuracy on batch 265/3013  on Training is 87.58223684210526\n",
            "Epoch #4. Accuracy on batch 266/3013  on Training is 87.59363295880149\n",
            "Epoch #4. Accuracy on batch 267/3013  on Training is 87.60494402985074\n",
            "Epoch #4. Accuracy on batch 268/3013  on Training is 87.59293680297398\n",
            "Epoch #4. Accuracy on batch 269/3013  on Training is 87.60416666666667\n",
            "Epoch #4. Accuracy on batch 270/3013  on Training is 87.63837638376384\n",
            "Epoch #4. Accuracy on batch 271/3013  on Training is 87.63786764705883\n",
            "Epoch #4. Accuracy on batch 272/3013  on Training is 87.62591575091575\n",
            "Epoch #4. Accuracy on batch 273/3013  on Training is 87.63686131386861\n",
            "Epoch #4. Accuracy on batch 274/3013  on Training is 87.64772727272727\n",
            "Epoch #4. Accuracy on batch 275/3013  on Training is 87.60190217391305\n",
            "Epoch #4. Accuracy on batch 276/3013  on Training is 87.61281588447653\n",
            "Epoch #4. Accuracy on batch 277/3013  on Training is 87.61241007194245\n",
            "Epoch #4. Accuracy on batch 278/3013  on Training is 87.62320788530467\n",
            "Epoch #4. Accuracy on batch 279/3013  on Training is 87.60044642857143\n",
            "Batch Id 280 is having training loss of 0.42516499757766724\n",
            "0.3250157833099365\n",
            "Epoch #4. Accuracy on batch 280/3013  on Training is 87.61120996441281\n",
            "Epoch #4. Accuracy on batch 281/3013  on Training is 87.57757092198581\n",
            "Epoch #4. Accuracy on batch 282/3013  on Training is 87.61042402826855\n",
            "Epoch #4. Accuracy on batch 283/3013  on Training is 87.58802816901408\n",
            "Epoch #4. Accuracy on batch 284/3013  on Training is 87.58771929824562\n",
            "Epoch #4. Accuracy on batch 285/3013  on Training is 87.57648601398601\n",
            "Epoch #4. Accuracy on batch 286/3013  on Training is 87.58710801393728\n",
            "Epoch #4. Accuracy on batch 287/3013  on Training is 87.58680555555556\n",
            "Epoch #4. Accuracy on batch 288/3013  on Training is 87.58650519031141\n",
            "Epoch #4. Accuracy on batch 289/3013  on Training is 87.59698275862068\n",
            "Epoch #4. Accuracy on batch 290/3013  on Training is 87.63960481099656\n",
            "Epoch #4. Accuracy on batch 291/3013  on Training is 87.64982876712328\n",
            "Epoch #4. Accuracy on batch 292/3013  on Training is 87.62798634812286\n",
            "Epoch #4. Accuracy on batch 293/3013  on Training is 87.61692176870748\n",
            "Epoch #4. Accuracy on batch 294/3013  on Training is 87.58474576271186\n",
            "Epoch #4. Accuracy on batch 295/3013  on Training is 87.59501689189189\n",
            "Epoch #4. Accuracy on batch 296/3013  on Training is 87.59469696969697\n",
            "Epoch #4. Accuracy on batch 297/3013  on Training is 87.58389261744966\n",
            "Epoch #4. Accuracy on batch 298/3013  on Training is 87.60451505016722\n",
            "Epoch #4. Accuracy on batch 299/3013  on Training is 87.59375\n",
            "Batch Id 300 is having training loss of 0.4246061146259308\n",
            "0.22443446516990662\n",
            "Epoch #4. Accuracy on batch 300/3013  on Training is 87.61420265780731\n",
            "Epoch #4. Accuracy on batch 301/3013  on Training is 87.58278145695364\n",
            "Epoch #4. Accuracy on batch 302/3013  on Training is 87.58250825082509\n",
            "Epoch #4. Accuracy on batch 303/3013  on Training is 87.57195723684211\n",
            "Epoch #4. Accuracy on batch 304/3013  on Training is 87.55122950819673\n",
            "Epoch #4. Accuracy on batch 305/3013  on Training is 87.58169934640523\n",
            "Epoch #4. Accuracy on batch 306/3013  on Training is 87.59161237785017\n",
            "Epoch #4. Accuracy on batch 307/3013  on Training is 87.59131493506493\n",
            "Epoch #4. Accuracy on batch 308/3013  on Training is 87.61124595469256\n",
            "Epoch #4. Accuracy on batch 309/3013  on Training is 87.62096774193549\n",
            "Epoch #4. Accuracy on batch 310/3013  on Training is 87.62057877813506\n",
            "Epoch #4. Accuracy on batch 311/3013  on Training is 87.6201923076923\n",
            "Epoch #4. Accuracy on batch 312/3013  on Training is 87.63977635782747\n",
            "Epoch #4. Accuracy on batch 313/3013  on Training is 87.64928343949045\n",
            "Epoch #4. Accuracy on batch 314/3013  on Training is 87.64880952380952\n",
            "Epoch #4. Accuracy on batch 315/3013  on Training is 87.62856012658227\n",
            "Epoch #4. Accuracy on batch 316/3013  on Training is 87.61829652996846\n",
            "Epoch #4. Accuracy on batch 317/3013  on Training is 87.61792452830188\n",
            "Epoch #4. Accuracy on batch 318/3013  on Training is 87.62735109717869\n",
            "Epoch #4. Accuracy on batch 319/3013  on Training is 87.65625\n",
            "Batch Id 320 is having training loss of 0.42291149497032166\n",
            "0.3829916715621948\n",
            "Epoch #4. Accuracy on batch 320/3013  on Training is 87.6654984423676\n",
            "Epoch #4. Accuracy on batch 321/3013  on Training is 87.6649844720497\n",
            "Epoch #4. Accuracy on batch 322/3013  on Training is 87.65479876160991\n",
            "Epoch #4. Accuracy on batch 323/3013  on Training is 87.65432098765432\n",
            "Epoch #4. Accuracy on batch 324/3013  on Training is 87.66346153846153\n",
            "Epoch #4. Accuracy on batch 325/3013  on Training is 87.65337423312883\n",
            "Epoch #4. Accuracy on batch 326/3013  on Training is 87.6624617737003\n",
            "Epoch #4. Accuracy on batch 327/3013  on Training is 87.65243902439025\n",
            "Epoch #4. Accuracy on batch 328/3013  on Training is 87.64247720364742\n",
            "Epoch #4. Accuracy on batch 329/3013  on Training is 87.66098484848484\n",
            "Epoch #4. Accuracy on batch 330/3013  on Training is 87.6510574018127\n",
            "Epoch #4. Accuracy on batch 331/3013  on Training is 87.66942771084338\n",
            "Epoch #4. Accuracy on batch 332/3013  on Training is 87.66891891891892\n",
            "Epoch #4. Accuracy on batch 333/3013  on Training is 87.6309880239521\n",
            "Epoch #4. Accuracy on batch 334/3013  on Training is 87.64925373134328\n",
            "Epoch #4. Accuracy on batch 335/3013  on Training is 87.62090773809524\n",
            "Epoch #4. Accuracy on batch 336/3013  on Training is 87.63909495548961\n",
            "Epoch #4. Accuracy on batch 337/3013  on Training is 87.6664201183432\n",
            "Epoch #4. Accuracy on batch 338/3013  on Training is 87.67514749262537\n",
            "Epoch #4. Accuracy on batch 339/3013  on Training is 87.67463235294117\n",
            "Batch Id 340 is having training loss of 0.42409229278564453\n",
            "0.42058202624320984\n",
            "Epoch #4. Accuracy on batch 340/3013  on Training is 87.6741202346041\n",
            "Epoch #4. Accuracy on batch 341/3013  on Training is 87.63706140350877\n",
            "Epoch #4. Accuracy on batch 342/3013  on Training is 87.64577259475219\n",
            "Epoch #4. Accuracy on batch 343/3013  on Training is 87.62718023255815\n",
            "Epoch #4. Accuracy on batch 344/3013  on Training is 87.6268115942029\n",
            "Epoch #4. Accuracy on batch 345/3013  on Training is 87.66257225433526\n",
            "Epoch #4. Accuracy on batch 346/3013  on Training is 87.68011527377521\n",
            "Epoch #4. Accuracy on batch 347/3013  on Training is 87.69755747126437\n",
            "Epoch #4. Accuracy on batch 348/3013  on Training is 87.68803724928367\n",
            "Epoch #4. Accuracy on batch 349/3013  on Training is 87.69642857142857\n",
            "Epoch #4. Accuracy on batch 350/3013  on Training is 87.66915954415954\n",
            "Epoch #4. Accuracy on batch 351/3013  on Training is 87.66867897727273\n",
            "Epoch #4. Accuracy on batch 352/3013  on Training is 87.65049575070822\n",
            "Epoch #4. Accuracy on batch 353/3013  on Training is 87.68538135593221\n",
            "Epoch #4. Accuracy on batch 354/3013  on Training is 87.65845070422536\n",
            "Epoch #4. Accuracy on batch 355/3013  on Training is 87.66678370786516\n",
            "Epoch #4. Accuracy on batch 356/3013  on Training is 87.64880952380952\n",
            "Epoch #4. Accuracy on batch 357/3013  on Training is 87.65712290502793\n",
            "Epoch #4. Accuracy on batch 358/3013  on Training is 87.66538997214485\n",
            "Epoch #4. Accuracy on batch 359/3013  on Training is 87.64756944444444\n",
            "Batch Id 360 is having training loss of 0.4272090792655945\n",
            "0.4493686854839325\n",
            "Epoch #4. Accuracy on batch 360/3013  on Training is 87.63850415512465\n",
            "Epoch #4. Accuracy on batch 361/3013  on Training is 87.62948895027624\n",
            "Epoch #4. Accuracy on batch 362/3013  on Training is 87.62913223140495\n",
            "Epoch #4. Accuracy on batch 363/3013  on Training is 87.6201923076923\n",
            "Epoch #4. Accuracy on batch 364/3013  on Training is 87.6027397260274\n",
            "Epoch #4. Accuracy on batch 365/3013  on Training is 87.60245901639344\n",
            "Epoch #4. Accuracy on batch 366/3013  on Training is 87.60217983651226\n",
            "Epoch #4. Accuracy on batch 367/3013  on Training is 87.58491847826087\n",
            "Epoch #4. Accuracy on batch 368/3013  on Training is 87.61009485094851\n",
            "Epoch #4. Accuracy on batch 369/3013  on Training is 87.61824324324324\n",
            "Epoch #4. Accuracy on batch 370/3013  on Training is 87.62634770889488\n",
            "Epoch #4. Accuracy on batch 371/3013  on Training is 87.63440860215054\n",
            "Epoch #4. Accuracy on batch 372/3013  on Training is 87.60891420911528\n",
            "Epoch #4. Accuracy on batch 373/3013  on Training is 87.60026737967914\n",
            "Epoch #4. Accuracy on batch 374/3013  on Training is 87.625\n",
            "Epoch #4. Accuracy on batch 375/3013  on Training is 87.62466755319149\n",
            "Epoch #4. Accuracy on batch 376/3013  on Training is 87.63262599469496\n",
            "Epoch #4. Accuracy on batch 377/3013  on Training is 87.64880952380952\n",
            "Epoch #4. Accuracy on batch 378/3013  on Training is 87.62368073878628\n",
            "Epoch #4. Accuracy on batch 379/3013  on Training is 87.63157894736842\n",
            "Batch Id 380 is having training loss of 0.4287102520465851\n",
            "0.8166100382804871\n",
            "Epoch #4. Accuracy on batch 380/3013  on Training is 87.5984251968504\n",
            "Epoch #4. Accuracy on batch 381/3013  on Training is 87.58180628272251\n",
            "Epoch #4. Accuracy on batch 382/3013  on Training is 87.60607049608355\n",
            "Epoch #4. Accuracy on batch 383/3013  on Training is 87.58951822916667\n",
            "Epoch #4. Accuracy on batch 384/3013  on Training is 87.60551948051948\n",
            "Epoch #4. Accuracy on batch 385/3013  on Training is 87.55667098445596\n",
            "Epoch #4. Accuracy on batch 386/3013  on Training is 87.57267441860465\n",
            "Epoch #4. Accuracy on batch 387/3013  on Training is 87.58054123711341\n",
            "Epoch #4. Accuracy on batch 388/3013  on Training is 87.57230077120822\n",
            "Epoch #4. Accuracy on batch 389/3013  on Training is 87.57211538461539\n",
            "Epoch #4. Accuracy on batch 390/3013  on Training is 87.5559462915601\n",
            "Epoch #4. Accuracy on batch 391/3013  on Training is 87.53188775510205\n",
            "Epoch #4. Accuracy on batch 392/3013  on Training is 87.53180661577608\n",
            "Epoch #4. Accuracy on batch 393/3013  on Training is 87.53172588832487\n",
            "Epoch #4. Accuracy on batch 394/3013  on Training is 87.55537974683544\n",
            "Epoch #4. Accuracy on batch 395/3013  on Training is 87.57102272727273\n",
            "Epoch #4. Accuracy on batch 396/3013  on Training is 87.55510075566751\n",
            "Epoch #4. Accuracy on batch 397/3013  on Training is 87.5\n",
            "Epoch #4. Accuracy on batch 398/3013  on Training is 87.4921679197995\n",
            "Epoch #4. Accuracy on batch 399/3013  on Training is 87.5078125\n",
            "Batch Id 400 is having training loss of 0.4323115646839142\n",
            "0.3351690173149109\n",
            "Epoch #4. Accuracy on batch 400/3013  on Training is 87.51558603491272\n",
            "Epoch #4. Accuracy on batch 401/3013  on Training is 87.5155472636816\n",
            "Epoch #4. Accuracy on batch 402/3013  on Training is 87.51550868486352\n",
            "Epoch #4. Accuracy on batch 403/3013  on Training is 87.5\n",
            "Epoch #4. Accuracy on batch 404/3013  on Training is 87.5\n",
            "Epoch #4. Accuracy on batch 405/3013  on Training is 87.47690886699507\n",
            "Epoch #4. Accuracy on batch 406/3013  on Training is 87.46928746928747\n",
            "Epoch #4. Accuracy on batch 407/3013  on Training is 87.47702205882354\n",
            "Epoch #4. Accuracy on batch 408/3013  on Training is 87.46179706601467\n",
            "Epoch #4. Accuracy on batch 409/3013  on Training is 87.46189024390245\n",
            "Epoch #4. Accuracy on batch 410/3013  on Training is 87.46198296836982\n",
            "Epoch #4. Accuracy on batch 411/3013  on Training is 87.43932038834951\n",
            "Epoch #4. Accuracy on batch 412/3013  on Training is 87.43946731234867\n",
            "Epoch #4. Accuracy on batch 413/3013  on Training is 87.4320652173913\n",
            "Epoch #4. Accuracy on batch 414/3013  on Training is 87.43975903614458\n",
            "Epoch #4. Accuracy on batch 415/3013  on Training is 87.46243990384616\n",
            "Epoch #4. Accuracy on batch 416/3013  on Training is 87.44754196642685\n",
            "Epoch #4. Accuracy on batch 417/3013  on Training is 87.46261961722487\n",
            "Epoch #4. Accuracy on batch 418/3013  on Training is 87.45525059665871\n",
            "Epoch #4. Accuracy on batch 419/3013  on Training is 87.44047619047619\n",
            "Batch Id 420 is having training loss of 0.43192151188850403\n",
            "0.4618109464645386\n",
            "Epoch #4. Accuracy on batch 420/3013  on Training is 87.4480403800475\n",
            "Epoch #4. Accuracy on batch 421/3013  on Training is 87.4629739336493\n",
            "Epoch #4. Accuracy on batch 422/3013  on Training is 87.47044917257683\n",
            "Epoch #4. Accuracy on batch 423/3013  on Training is 87.48525943396227\n",
            "Epoch #4. Accuracy on batch 424/3013  on Training is 87.4779411764706\n",
            "Epoch #4. Accuracy on batch 425/3013  on Training is 87.48532863849765\n",
            "Epoch #4. Accuracy on batch 426/3013  on Training is 87.49268149882904\n",
            "Epoch #4. Accuracy on batch 427/3013  on Training is 87.5\n",
            "Epoch #4. Accuracy on batch 428/3013  on Training is 87.49271561771562\n",
            "Epoch #4. Accuracy on batch 429/3013  on Training is 87.50726744186046\n",
            "Epoch #4. Accuracy on batch 430/3013  on Training is 87.5072505800464\n",
            "Epoch #4. Accuracy on batch 431/3013  on Training is 87.4855324074074\n",
            "Epoch #4. Accuracy on batch 432/3013  on Training is 87.48556581986143\n",
            "Epoch #4. Accuracy on batch 433/3013  on Training is 87.5\n",
            "Epoch #4. Accuracy on batch 434/3013  on Training is 87.48563218390805\n",
            "Epoch #4. Accuracy on batch 435/3013  on Training is 87.47849770642202\n",
            "Epoch #4. Accuracy on batch 436/3013  on Training is 87.5\n",
            "Epoch #4. Accuracy on batch 437/3013  on Training is 87.5\n",
            "Epoch #4. Accuracy on batch 438/3013  on Training is 87.51423690205011\n",
            "Epoch #4. Accuracy on batch 439/3013  on Training is 87.5\n",
            "Batch Id 440 is having training loss of 0.4316022992134094\n",
            "0.2983812391757965\n",
            "Epoch #4. Accuracy on batch 440/3013  on Training is 87.50708616780045\n",
            "Epoch #4. Accuracy on batch 441/3013  on Training is 87.5\n",
            "Epoch #4. Accuracy on batch 442/3013  on Training is 87.49294582392777\n",
            "Epoch #4. Accuracy on batch 443/3013  on Training is 87.50703828828829\n",
            "Epoch #4. Accuracy on batch 444/3013  on Training is 87.50702247191012\n",
            "Epoch #4. Accuracy on batch 445/3013  on Training is 87.4929932735426\n",
            "Epoch #4. Accuracy on batch 446/3013  on Training is 87.48601789709173\n",
            "Epoch #4. Accuracy on batch 447/3013  on Training is 87.49302455357143\n",
            "Epoch #4. Accuracy on batch 448/3013  on Training is 87.50695991091314\n",
            "Epoch #4. Accuracy on batch 449/3013  on Training is 87.51388888888889\n",
            "Epoch #4. Accuracy on batch 450/3013  on Training is 87.49307095343681\n",
            "Epoch #4. Accuracy on batch 451/3013  on Training is 87.47925884955752\n",
            "Epoch #4. Accuracy on batch 452/3013  on Training is 87.4793046357616\n",
            "Epoch #4. Accuracy on batch 453/3013  on Training is 87.44493392070484\n",
            "Epoch #4. Accuracy on batch 454/3013  on Training is 87.45879120879121\n",
            "Epoch #4. Accuracy on batch 455/3013  on Training is 87.48629385964912\n",
            "Epoch #4. Accuracy on batch 456/3013  on Training is 87.47948577680525\n",
            "Epoch #4. Accuracy on batch 457/3013  on Training is 87.47953056768559\n",
            "Epoch #4. Accuracy on batch 458/3013  on Training is 87.46595860566448\n",
            "Epoch #4. Accuracy on batch 459/3013  on Training is 87.45923913043478\n",
            "Batch Id 460 is having training loss of 0.4322856366634369\n",
            "0.3156159222126007\n",
            "Epoch #4. Accuracy on batch 460/3013  on Training is 87.46610629067246\n",
            "Epoch #4. Accuracy on batch 461/3013  on Training is 87.44588744588745\n",
            "Epoch #4. Accuracy on batch 462/3013  on Training is 87.45950323974083\n",
            "Epoch #4. Accuracy on batch 463/3013  on Training is 87.45959051724138\n",
            "Epoch #4. Accuracy on batch 464/3013  on Training is 87.46639784946237\n",
            "Epoch #4. Accuracy on batch 465/3013  on Training is 87.46646995708154\n",
            "Epoch #4. Accuracy on batch 466/3013  on Training is 87.47323340471092\n",
            "Epoch #4. Accuracy on batch 467/3013  on Training is 87.46661324786325\n",
            "Epoch #4. Accuracy on batch 468/3013  on Training is 87.46002132196162\n",
            "Epoch #4. Accuracy on batch 469/3013  on Training is 87.46010638297872\n",
            "Epoch #4. Accuracy on batch 470/3013  on Training is 87.46682590233546\n",
            "Epoch #4. Accuracy on batch 471/3013  on Training is 87.46689618644068\n",
            "Epoch #4. Accuracy on batch 472/3013  on Training is 87.48678646934461\n",
            "Epoch #4. Accuracy on batch 473/3013  on Training is 87.4670358649789\n",
            "Epoch #4. Accuracy on batch 474/3013  on Training is 87.46052631578948\n",
            "Epoch #4. Accuracy on batch 475/3013  on Training is 87.45404411764706\n",
            "Epoch #4. Accuracy on batch 476/3013  on Training is 87.44758909853249\n",
            "Epoch #4. Accuracy on batch 477/3013  on Training is 87.4411610878661\n",
            "Epoch #4. Accuracy on batch 478/3013  on Training is 87.44780793319416\n",
            "Epoch #4. Accuracy on batch 479/3013  on Training is 87.44140625\n",
            "Batch Id 480 is having training loss of 0.4338313639163971\n",
            "0.6209635734558105\n",
            "Epoch #4. Accuracy on batch 480/3013  on Training is 87.4285343035343\n",
            "Epoch #4. Accuracy on batch 481/3013  on Training is 87.42219917012449\n",
            "Epoch #4. Accuracy on batch 482/3013  on Training is 87.43530020703933\n",
            "Epoch #4. Accuracy on batch 483/3013  on Training is 87.41606404958678\n",
            "Epoch #4. Accuracy on batch 484/3013  on Training is 87.42912371134021\n",
            "Epoch #4. Accuracy on batch 485/3013  on Training is 87.43569958847736\n",
            "Epoch #4. Accuracy on batch 486/3013  on Training is 87.44224845995893\n",
            "Epoch #4. Accuracy on batch 487/3013  on Training is 87.4295594262295\n",
            "Epoch #4. Accuracy on batch 488/3013  on Training is 87.44887525562372\n",
            "Epoch #4. Accuracy on batch 489/3013  on Training is 87.44897959183673\n",
            "Epoch #4. Accuracy on batch 490/3013  on Training is 87.45544806517312\n",
            "Epoch #4. Accuracy on batch 491/3013  on Training is 87.45553861788618\n",
            "Epoch #4. Accuracy on batch 492/3013  on Training is 87.46830628803245\n",
            "Epoch #4. Accuracy on batch 493/3013  on Training is 87.4746963562753\n",
            "Epoch #4. Accuracy on batch 494/3013  on Training is 87.48737373737374\n",
            "Epoch #4. Accuracy on batch 495/3013  on Training is 87.50630040322581\n",
            "Epoch #4. Accuracy on batch 496/3013  on Training is 87.51886317907444\n",
            "Epoch #4. Accuracy on batch 497/3013  on Training is 87.51882530120481\n",
            "Epoch #4. Accuracy on batch 498/3013  on Training is 87.5250501002004\n",
            "Epoch #4. Accuracy on batch 499/3013  on Training is 87.49375\n",
            "Batch Id 500 is having training loss of 0.4316893219947815\n",
            "0.5128249526023865\n",
            "Epoch #4. Accuracy on batch 500/3013  on Training is 87.4875249500998\n",
            "Epoch #4. Accuracy on batch 501/3013  on Training is 87.5062250996016\n",
            "Epoch #4. Accuracy on batch 502/3013  on Training is 87.50621272365805\n",
            "Epoch #4. Accuracy on batch 503/3013  on Training is 87.49379960317461\n",
            "Epoch #4. Accuracy on batch 504/3013  on Training is 87.47524752475248\n",
            "Epoch #4. Accuracy on batch 505/3013  on Training is 87.4505928853755\n",
            "Epoch #4. Accuracy on batch 506/3013  on Training is 87.46301775147928\n",
            "Epoch #4. Accuracy on batch 507/3013  on Training is 87.4507874015748\n",
            "Epoch #4. Accuracy on batch 508/3013  on Training is 87.43860510805501\n",
            "Epoch #4. Accuracy on batch 509/3013  on Training is 87.43872549019608\n",
            "Epoch #4. Accuracy on batch 510/3013  on Training is 87.43272994129158\n",
            "Epoch #4. Accuracy on batch 511/3013  on Training is 87.41455078125\n",
            "Epoch #4. Accuracy on batch 512/3013  on Training is 87.4208089668616\n",
            "Epoch #4. Accuracy on batch 513/3013  on Training is 87.43312256809338\n",
            "Epoch #4. Accuracy on batch 514/3013  on Training is 87.43325242718447\n",
            "Epoch #4. Accuracy on batch 515/3013  on Training is 87.42732558139535\n",
            "Epoch #4. Accuracy on batch 516/3013  on Training is 87.43955512572533\n",
            "Epoch #4. Accuracy on batch 517/3013  on Training is 87.43967181467181\n",
            "Epoch #4. Accuracy on batch 518/3013  on Training is 87.4397880539499\n",
            "Epoch #4. Accuracy on batch 519/3013  on Training is 87.44591346153847\n",
            "Batch Id 520 is having training loss of 0.43303182721138\n",
            "0.31838738918304443\n",
            "Epoch #4. Accuracy on batch 520/3013  on Training is 87.45801343570058\n",
            "Epoch #4. Accuracy on batch 521/3013  on Training is 87.44612068965517\n",
            "Epoch #4. Accuracy on batch 522/3013  on Training is 87.43427342256214\n",
            "Epoch #4. Accuracy on batch 523/3013  on Training is 87.44036259541984\n",
            "Epoch #4. Accuracy on batch 524/3013  on Training is 87.43452380952381\n",
            "Epoch #4. Accuracy on batch 525/3013  on Training is 87.42276615969581\n",
            "Epoch #4. Accuracy on batch 526/3013  on Training is 87.42884250474383\n",
            "Epoch #4. Accuracy on batch 527/3013  on Training is 87.42305871212122\n",
            "Epoch #4. Accuracy on batch 528/3013  on Training is 87.42911153119093\n",
            "Epoch #4. Accuracy on batch 529/3013  on Training is 87.43514150943396\n",
            "Epoch #4. Accuracy on batch 530/3013  on Training is 87.45291902071563\n",
            "Epoch #4. Accuracy on batch 531/3013  on Training is 87.46475563909775\n",
            "Epoch #4. Accuracy on batch 532/3013  on Training is 87.4765478424015\n",
            "Epoch #4. Accuracy on batch 533/3013  on Training is 87.4882958801498\n",
            "Epoch #4. Accuracy on batch 534/3013  on Training is 87.4766355140187\n",
            "Epoch #4. Accuracy on batch 535/3013  on Training is 87.47667910447761\n",
            "Epoch #4. Accuracy on batch 536/3013  on Training is 87.48836126629423\n",
            "Epoch #4. Accuracy on batch 537/3013  on Training is 87.47676579925651\n",
            "Epoch #4. Accuracy on batch 538/3013  on Training is 87.4652133580705\n",
            "Epoch #4. Accuracy on batch 539/3013  on Training is 87.46527777777777\n",
            "Batch Id 540 is having training loss of 0.43276074528694153\n",
            "0.67824786901474\n",
            "Epoch #4. Accuracy on batch 540/3013  on Training is 87.45378927911275\n",
            "Epoch #4. Accuracy on batch 541/3013  on Training is 87.42504612546125\n",
            "Epoch #4. Accuracy on batch 542/3013  on Training is 87.40216390423572\n",
            "Epoch #4. Accuracy on batch 543/3013  on Training is 87.40808823529412\n",
            "Epoch #4. Accuracy on batch 544/3013  on Training is 87.41399082568807\n",
            "Epoch #4. Accuracy on batch 545/3013  on Training is 87.42559523809524\n",
            "Epoch #4. Accuracy on batch 546/3013  on Training is 87.42001828153565\n",
            "Epoch #4. Accuracy on batch 547/3013  on Training is 87.41446167883211\n",
            "Epoch #4. Accuracy on batch 548/3013  on Training is 87.40892531876139\n",
            "Epoch #4. Accuracy on batch 549/3013  on Training is 87.41477272727273\n",
            "Epoch #4. Accuracy on batch 550/3013  on Training is 87.40925589836661\n",
            "Epoch #4. Accuracy on batch 551/3013  on Training is 87.40375905797102\n",
            "Epoch #4. Accuracy on batch 552/3013  on Training is 87.39828209764919\n",
            "Epoch #4. Accuracy on batch 553/3013  on Training is 87.40974729241877\n",
            "Epoch #4. Accuracy on batch 554/3013  on Training is 87.42117117117117\n",
            "Epoch #4. Accuracy on batch 555/3013  on Training is 87.41007194244604\n",
            "Epoch #4. Accuracy on batch 556/3013  on Training is 87.40462298025135\n",
            "Epoch #4. Accuracy on batch 557/3013  on Training is 87.40479390681004\n",
            "Epoch #4. Accuracy on batch 558/3013  on Training is 87.41055456171735\n",
            "Epoch #4. Accuracy on batch 559/3013  on Training is 87.40513392857143\n",
            "Batch Id 560 is having training loss of 0.4349603056907654\n",
            "0.33965399861335754\n",
            "Epoch #4. Accuracy on batch 560/3013  on Training is 87.4108734402852\n",
            "Epoch #4. Accuracy on batch 561/3013  on Training is 87.40547153024912\n",
            "Epoch #4. Accuracy on batch 562/3013  on Training is 87.40563943161634\n",
            "Epoch #4. Accuracy on batch 563/3013  on Training is 87.41688829787235\n",
            "Epoch #4. Accuracy on batch 564/3013  on Training is 87.41703539823008\n",
            "Epoch #4. Accuracy on batch 565/3013  on Training is 87.42270318021201\n",
            "Epoch #4. Accuracy on batch 566/3013  on Training is 87.42835097001763\n",
            "Epoch #4. Accuracy on batch 567/3013  on Training is 87.44498239436619\n",
            "Epoch #4. Accuracy on batch 568/3013  on Training is 87.4286028119508\n",
            "Epoch #4. Accuracy on batch 569/3013  on Training is 87.43969298245614\n",
            "Epoch #4. Accuracy on batch 570/3013  on Training is 87.43432574430823\n",
            "Epoch #4. Accuracy on batch 571/3013  on Training is 87.44536713286713\n",
            "Epoch #4. Accuracy on batch 572/3013  on Training is 87.42364746945898\n",
            "Epoch #4. Accuracy on batch 573/3013  on Training is 87.42922473867596\n",
            "Epoch #4. Accuracy on batch 574/3013  on Training is 87.42391304347827\n",
            "Epoch #4. Accuracy on batch 575/3013  on Training is 87.44032118055556\n",
            "Epoch #4. Accuracy on batch 576/3013  on Training is 87.44042461005199\n",
            "Epoch #4. Accuracy on batch 577/3013  on Training is 87.42971453287197\n",
            "Epoch #4. Accuracy on batch 578/3013  on Training is 87.42983592400691\n",
            "Epoch #4. Accuracy on batch 579/3013  on Training is 87.42995689655173\n",
            "Batch Id 580 is having training loss of 0.4344783127307892\n",
            "0.4016244113445282\n",
            "Epoch #4. Accuracy on batch 580/3013  on Training is 87.43007745266782\n",
            "Epoch #4. Accuracy on batch 581/3013  on Training is 87.43556701030928\n",
            "Epoch #4. Accuracy on batch 582/3013  on Training is 87.42495711835335\n",
            "Epoch #4. Accuracy on batch 583/3013  on Training is 87.43043664383562\n",
            "Epoch #4. Accuracy on batch 584/3013  on Training is 87.42521367521367\n",
            "Epoch #4. Accuracy on batch 585/3013  on Training is 87.40934300341297\n",
            "Epoch #4. Accuracy on batch 586/3013  on Training is 87.42546848381602\n",
            "Epoch #4. Accuracy on batch 587/3013  on Training is 87.43622448979592\n",
            "Epoch #4. Accuracy on batch 588/3013  on Training is 87.43633276740238\n",
            "Epoch #4. Accuracy on batch 589/3013  on Training is 87.43114406779661\n",
            "Epoch #4. Accuracy on batch 590/3013  on Training is 87.42597292724196\n",
            "Epoch #4. Accuracy on batch 591/3013  on Training is 87.42081925675676\n",
            "Epoch #4. Accuracy on batch 592/3013  on Training is 87.410413153457\n",
            "Epoch #4. Accuracy on batch 593/3013  on Training is 87.40530303030303\n",
            "Epoch #4. Accuracy on batch 594/3013  on Training is 87.38970588235294\n",
            "Epoch #4. Accuracy on batch 595/3013  on Training is 87.37940436241611\n",
            "Epoch #4. Accuracy on batch 596/3013  on Training is 87.37437185929649\n",
            "Epoch #4. Accuracy on batch 597/3013  on Training is 87.39548494983278\n",
            "Epoch #4. Accuracy on batch 598/3013  on Training is 87.41131051752922\n",
            "Epoch #4. Accuracy on batch 599/3013  on Training is 87.41145833333333\n",
            "Batch Id 600 is having training loss of 0.4338439702987671\n",
            "0.26416754722595215\n",
            "Epoch #4. Accuracy on batch 600/3013  on Training is 87.41680532445923\n",
            "Epoch #4. Accuracy on batch 601/3013  on Training is 87.41694352159469\n",
            "Epoch #4. Accuracy on batch 602/3013  on Training is 87.41189883913765\n",
            "Epoch #4. Accuracy on batch 603/3013  on Training is 87.40169701986756\n",
            "Epoch #4. Accuracy on batch 604/3013  on Training is 87.38636363636364\n",
            "Epoch #4. Accuracy on batch 605/3013  on Training is 87.38139438943894\n",
            "Epoch #4. Accuracy on batch 606/3013  on Training is 87.36614497528831\n",
            "Epoch #4. Accuracy on batch 607/3013  on Training is 87.37150493421052\n",
            "Epoch #4. Accuracy on batch 608/3013  on Training is 87.36658456486043\n",
            "Epoch #4. Accuracy on batch 609/3013  on Training is 87.36168032786885\n",
            "Epoch #4. Accuracy on batch 610/3013  on Training is 87.35167757774141\n",
            "Epoch #4. Accuracy on batch 611/3013  on Training is 87.3672385620915\n",
            "Epoch #4. Accuracy on batch 612/3013  on Training is 87.3623572593801\n",
            "Epoch #4. Accuracy on batch 613/3013  on Training is 87.34731270358306\n",
            "Epoch #4. Accuracy on batch 614/3013  on Training is 87.35772357723577\n",
            "Epoch #4. Accuracy on batch 615/3013  on Training is 87.33766233766234\n",
            "Epoch #4. Accuracy on batch 616/3013  on Training is 87.32779578606159\n",
            "Epoch #4. Accuracy on batch 617/3013  on Training is 87.33818770226537\n",
            "Epoch #4. Accuracy on batch 618/3013  on Training is 87.35359450726979\n",
            "Epoch #4. Accuracy on batch 619/3013  on Training is 87.36391129032258\n",
            "Batch Id 620 is having training loss of 0.43491071462631226\n",
            "0.38108575344085693\n",
            "Epoch #4. Accuracy on batch 620/3013  on Training is 87.35406602254429\n",
            "Epoch #4. Accuracy on batch 621/3013  on Training is 87.3693729903537\n",
            "Epoch #4. Accuracy on batch 622/3013  on Training is 87.37459871589085\n",
            "Epoch #4. Accuracy on batch 623/3013  on Training is 87.3798076923077\n",
            "Epoch #4. Accuracy on batch 624/3013  on Training is 87.38\n",
            "Epoch #4. Accuracy on batch 625/3013  on Training is 87.38019169329074\n",
            "Epoch #4. Accuracy on batch 626/3013  on Training is 87.38038277511961\n",
            "Epoch #4. Accuracy on batch 627/3013  on Training is 87.37559713375796\n",
            "Epoch #4. Accuracy on batch 628/3013  on Training is 87.38076311605724\n",
            "Epoch #4. Accuracy on batch 629/3013  on Training is 87.38095238095238\n",
            "Epoch #4. Accuracy on batch 630/3013  on Training is 87.37123613312203\n",
            "Epoch #4. Accuracy on batch 631/3013  on Training is 87.37638449367088\n",
            "Epoch #4. Accuracy on batch 632/3013  on Training is 87.38151658767772\n",
            "Epoch #4. Accuracy on batch 633/3013  on Training is 87.35705835962145\n",
            "Epoch #4. Accuracy on batch 634/3013  on Training is 87.36712598425197\n",
            "Epoch #4. Accuracy on batch 635/3013  on Training is 87.36733490566037\n",
            "Epoch #4. Accuracy on batch 636/3013  on Training is 87.35773155416013\n",
            "Epoch #4. Accuracy on batch 637/3013  on Training is 87.37264890282131\n",
            "Epoch #4. Accuracy on batch 638/3013  on Training is 87.35817683881064\n",
            "Epoch #4. Accuracy on batch 639/3013  on Training is 87.3486328125\n",
            "Batch Id 640 is having training loss of 0.43357616662979126\n",
            "0.5075286030769348\n",
            "Epoch #4. Accuracy on batch 640/3013  on Training is 87.35374414976599\n",
            "Epoch #4. Accuracy on batch 641/3013  on Training is 87.36857476635514\n",
            "Epoch #4. Accuracy on batch 642/3013  on Training is 87.37849922239502\n",
            "Epoch #4. Accuracy on batch 643/3013  on Training is 87.36898291925466\n",
            "Epoch #4. Accuracy on batch 644/3013  on Training is 87.37403100775194\n",
            "Epoch #4. Accuracy on batch 645/3013  on Training is 87.38873839009288\n",
            "Epoch #4. Accuracy on batch 646/3013  on Training is 87.36959041731066\n",
            "Epoch #4. Accuracy on batch 647/3013  on Training is 87.37943672839506\n",
            "Epoch #4. Accuracy on batch 648/3013  on Training is 87.38925269645608\n",
            "Epoch #4. Accuracy on batch 649/3013  on Training is 87.3798076923077\n",
            "Epoch #4. Accuracy on batch 650/3013  on Training is 87.37999231950845\n",
            "Epoch #4. Accuracy on batch 651/3013  on Training is 87.37059049079754\n",
            "Epoch #4. Accuracy on batch 652/3013  on Training is 87.37557427258805\n",
            "Epoch #4. Accuracy on batch 653/3013  on Training is 87.37098623853211\n",
            "Epoch #4. Accuracy on batch 654/3013  on Training is 87.36164122137404\n",
            "Epoch #4. Accuracy on batch 655/3013  on Training is 87.36185213414635\n",
            "Epoch #4. Accuracy on batch 656/3013  on Training is 87.3668188736682\n",
            "Epoch #4. Accuracy on batch 657/3013  on Training is 87.35752279635258\n",
            "Epoch #4. Accuracy on batch 658/3013  on Training is 87.35773899848255\n",
            "Epoch #4. Accuracy on batch 659/3013  on Training is 87.3532196969697\n",
            "Batch Id 660 is having training loss of 0.4346425235271454\n",
            "0.5474072098731995\n",
            "Epoch #4. Accuracy on batch 660/3013  on Training is 87.34398638426626\n",
            "Epoch #4. Accuracy on batch 661/3013  on Training is 87.32061933534743\n",
            "Epoch #4. Accuracy on batch 662/3013  on Training is 87.30674962292609\n",
            "Epoch #4. Accuracy on batch 663/3013  on Training is 87.3023343373494\n",
            "Epoch #4. Accuracy on batch 664/3013  on Training is 87.30733082706767\n",
            "Epoch #4. Accuracy on batch 665/3013  on Training is 87.31700450450451\n",
            "Epoch #4. Accuracy on batch 666/3013  on Training is 87.33133433283358\n",
            "Epoch #4. Accuracy on batch 667/3013  on Training is 87.32223053892216\n",
            "Epoch #4. Accuracy on batch 668/3013  on Training is 87.32716741405082\n",
            "Epoch #4. Accuracy on batch 669/3013  on Training is 87.33208955223881\n",
            "Epoch #4. Accuracy on batch 670/3013  on Training is 87.34631147540983\n",
            "Epoch #4. Accuracy on batch 671/3013  on Training is 87.34654017857143\n",
            "Epoch #4. Accuracy on batch 672/3013  on Training is 87.35605497771174\n",
            "Epoch #4. Accuracy on batch 673/3013  on Training is 87.36090504451039\n",
            "Epoch #4. Accuracy on batch 674/3013  on Training is 87.36111111111111\n",
            "Epoch #4. Accuracy on batch 675/3013  on Training is 87.35669378698225\n",
            "Epoch #4. Accuracy on batch 676/3013  on Training is 87.34767355982275\n",
            "Epoch #4. Accuracy on batch 677/3013  on Training is 87.35250737463127\n",
            "Epoch #4. Accuracy on batch 678/3013  on Training is 87.35732695139912\n",
            "Epoch #4. Accuracy on batch 679/3013  on Training is 87.36672794117646\n",
            "Batch Id 680 is having training loss of 0.43468987941741943\n",
            "0.4046561121940613\n",
            "Epoch #4. Accuracy on batch 680/3013  on Training is 87.36692364170338\n",
            "Epoch #4. Accuracy on batch 681/3013  on Training is 87.36253665689149\n",
            "Epoch #4. Accuracy on batch 682/3013  on Training is 87.36731332357247\n",
            "Epoch #4. Accuracy on batch 683/3013  on Training is 87.36293859649123\n",
            "Epoch #4. Accuracy on batch 684/3013  on Training is 87.36313868613139\n",
            "Epoch #4. Accuracy on batch 685/3013  on Training is 87.36333819241983\n",
            "Epoch #4. Accuracy on batch 686/3013  on Training is 87.36353711790393\n",
            "Epoch #4. Accuracy on batch 687/3013  on Training is 87.36373546511628\n",
            "Epoch #4. Accuracy on batch 688/3013  on Training is 87.36393323657475\n",
            "Epoch #4. Accuracy on batch 689/3013  on Training is 87.36865942028986\n",
            "Epoch #4. Accuracy on batch 690/3013  on Training is 87.3598046309696\n",
            "Epoch #4. Accuracy on batch 691/3013  on Training is 87.3735549132948\n",
            "Epoch #4. Accuracy on batch 692/3013  on Training is 87.36471861471861\n",
            "Epoch #4. Accuracy on batch 693/3013  on Training is 87.37842219020173\n",
            "Epoch #4. Accuracy on batch 694/3013  on Training is 87.37410071942446\n",
            "Epoch #4. Accuracy on batch 695/3013  on Training is 87.37877155172414\n",
            "Epoch #4. Accuracy on batch 696/3013  on Training is 87.38342898134864\n",
            "Epoch #4. Accuracy on batch 697/3013  on Training is 87.39255014326648\n",
            "Epoch #4. Accuracy on batch 698/3013  on Training is 87.39717453505007\n",
            "Epoch #4. Accuracy on batch 699/3013  on Training is 87.39285714285714\n",
            "Batch Id 700 is having training loss of 0.4337479770183563\n",
            "0.3436483144760132\n",
            "Epoch #4. Accuracy on batch 700/3013  on Training is 87.40192582025678\n",
            "Epoch #4. Accuracy on batch 701/3013  on Training is 87.40206552706553\n",
            "Epoch #4. Accuracy on batch 702/3013  on Training is 87.40220483641536\n",
            "Epoch #4. Accuracy on batch 703/3013  on Training is 87.41566051136364\n",
            "Epoch #4. Accuracy on batch 704/3013  on Training is 87.38475177304964\n",
            "Epoch #4. Accuracy on batch 705/3013  on Training is 87.36720963172804\n",
            "Epoch #4. Accuracy on batch 706/3013  on Training is 87.36739745403112\n",
            "Epoch #4. Accuracy on batch 707/3013  on Training is 87.35875706214689\n",
            "Epoch #4. Accuracy on batch 708/3013  on Training is 87.3589562764457\n",
            "Epoch #4. Accuracy on batch 709/3013  on Training is 87.37235915492958\n",
            "Epoch #4. Accuracy on batch 710/3013  on Training is 87.37253867791843\n",
            "Epoch #4. Accuracy on batch 711/3013  on Training is 87.38149578651685\n",
            "Epoch #4. Accuracy on batch 712/3013  on Training is 87.39042776998598\n",
            "Epoch #4. Accuracy on batch 713/3013  on Training is 87.38620448179272\n",
            "Epoch #4. Accuracy on batch 714/3013  on Training is 87.37762237762237\n",
            "Epoch #4. Accuracy on batch 715/3013  on Training is 87.39088687150839\n",
            "Epoch #4. Accuracy on batch 716/3013  on Training is 87.38668061366806\n",
            "Epoch #4. Accuracy on batch 717/3013  on Training is 87.39554317548746\n",
            "Epoch #4. Accuracy on batch 718/3013  on Training is 87.40438108484005\n",
            "Epoch #4. Accuracy on batch 719/3013  on Training is 87.41753472222223\n",
            "Batch Id 720 is having training loss of 0.4339677095413208\n",
            "0.4295981526374817\n",
            "Epoch #4. Accuracy on batch 720/3013  on Training is 87.41764909847434\n",
            "Epoch #4. Accuracy on batch 721/3013  on Training is 87.41343490304709\n",
            "Epoch #4. Accuracy on batch 722/3013  on Training is 87.42219917012449\n",
            "Epoch #4. Accuracy on batch 723/3013  on Training is 87.42230662983425\n",
            "Epoch #4. Accuracy on batch 724/3013  on Training is 87.42672413793103\n",
            "Epoch #4. Accuracy on batch 725/3013  on Training is 87.43112947658402\n",
            "Epoch #4. Accuracy on batch 726/3013  on Training is 87.42692572214581\n",
            "Epoch #4. Accuracy on batch 727/3013  on Training is 87.4270260989011\n",
            "Epoch #4. Accuracy on batch 728/3013  on Training is 87.43141289437585\n",
            "Epoch #4. Accuracy on batch 729/3013  on Training is 87.44006849315069\n",
            "Epoch #4. Accuracy on batch 730/3013  on Training is 87.44870041039671\n",
            "Epoch #4. Accuracy on batch 731/3013  on Training is 87.43169398907104\n",
            "Epoch #4. Accuracy on batch 732/3013  on Training is 87.44457708049113\n",
            "Epoch #4. Accuracy on batch 733/3013  on Training is 87.44891008174388\n",
            "Epoch #4. Accuracy on batch 734/3013  on Training is 87.44047619047619\n",
            "Epoch #4. Accuracy on batch 735/3013  on Training is 87.45329483695652\n",
            "Epoch #4. Accuracy on batch 736/3013  on Training is 87.45335820895522\n",
            "Epoch #4. Accuracy on batch 737/3013  on Training is 87.43224932249322\n",
            "Epoch #4. Accuracy on batch 738/3013  on Training is 87.4196549391069\n",
            "Epoch #4. Accuracy on batch 739/3013  on Training is 87.42820945945945\n",
            "Batch Id 740 is having training loss of 0.4347323179244995\n",
            "0.2712899446487427\n",
            "Epoch #4. Accuracy on batch 740/3013  on Training is 87.43674089068826\n",
            "Epoch #4. Accuracy on batch 741/3013  on Training is 87.41997978436657\n",
            "Epoch #4. Accuracy on batch 742/3013  on Training is 87.40326379542395\n",
            "Epoch #4. Accuracy on batch 743/3013  on Training is 87.3991935483871\n",
            "Epoch #4. Accuracy on batch 744/3013  on Training is 87.39513422818791\n",
            "Epoch #4. Accuracy on batch 745/3013  on Training is 87.4036528150134\n",
            "Epoch #4. Accuracy on batch 746/3013  on Training is 87.39541499330656\n",
            "Epoch #4. Accuracy on batch 747/3013  on Training is 87.40391042780749\n",
            "Epoch #4. Accuracy on batch 748/3013  on Training is 87.39569425901202\n",
            "Epoch #4. Accuracy on batch 749/3013  on Training is 87.39583333333333\n",
            "Epoch #4. Accuracy on batch 750/3013  on Training is 87.38764980026632\n",
            "Epoch #4. Accuracy on batch 751/3013  on Training is 87.37948803191489\n",
            "Epoch #4. Accuracy on batch 752/3013  on Training is 87.36304780876495\n",
            "Epoch #4. Accuracy on batch 753/3013  on Training is 87.3590848806366\n",
            "Epoch #4. Accuracy on batch 754/3013  on Training is 87.3592715231788\n",
            "Epoch #4. Accuracy on batch 755/3013  on Training is 87.36359126984127\n",
            "Epoch #4. Accuracy on batch 756/3013  on Training is 87.36789960369882\n",
            "Epoch #4. Accuracy on batch 757/3013  on Training is 87.35982849604221\n",
            "Epoch #4. Accuracy on batch 758/3013  on Training is 87.36001317523056\n",
            "Epoch #4. Accuracy on batch 759/3013  on Training is 87.35197368421052\n",
            "Batch Id 760 is having training loss of 0.4364473521709442\n",
            "0.5894381999969482\n",
            "Epoch #4. Accuracy on batch 760/3013  on Training is 87.348061760841\n",
            "Epoch #4. Accuracy on batch 761/3013  on Training is 87.33595800524934\n",
            "Epoch #4. Accuracy on batch 762/3013  on Training is 87.32798165137615\n",
            "Epoch #4. Accuracy on batch 763/3013  on Training is 87.33638743455498\n",
            "Epoch #4. Accuracy on batch 764/3013  on Training is 87.33660130718954\n",
            "Epoch #4. Accuracy on batch 765/3013  on Training is 87.33681462140993\n",
            "Epoch #4. Accuracy on batch 766/3013  on Training is 87.32073011734029\n",
            "Epoch #4. Accuracy on batch 767/3013  on Training is 87.3291015625\n",
            "Epoch #4. Accuracy on batch 768/3013  on Training is 87.3252600780234\n",
            "Epoch #4. Accuracy on batch 769/3013  on Training is 87.32548701298701\n",
            "Epoch #4. Accuracy on batch 770/3013  on Training is 87.32976653696498\n",
            "Epoch #4. Accuracy on batch 771/3013  on Training is 87.32998704663213\n",
            "Epoch #4. Accuracy on batch 772/3013  on Training is 87.32212160413971\n",
            "Epoch #4. Accuracy on batch 773/3013  on Training is 87.32638888888889\n",
            "Epoch #4. Accuracy on batch 774/3013  on Training is 87.33064516129032\n",
            "Epoch #4. Accuracy on batch 775/3013  on Training is 87.3389175257732\n",
            "Epoch #4. Accuracy on batch 776/3013  on Training is 87.3270592020592\n",
            "Epoch #4. Accuracy on batch 777/3013  on Training is 87.31924807197943\n",
            "Epoch #4. Accuracy on batch 778/3013  on Training is 87.31948010269576\n",
            "Epoch #4. Accuracy on batch 779/3013  on Training is 87.33573717948718\n",
            "Batch Id 780 is having training loss of 0.4361935257911682\n",
            "0.4185732901096344\n",
            "Epoch #4. Accuracy on batch 780/3013  on Training is 87.33194622279129\n",
            "Epoch #4. Accuracy on batch 781/3013  on Training is 87.34414961636828\n",
            "Epoch #4. Accuracy on batch 782/3013  on Training is 87.35233077905492\n",
            "Epoch #4. Accuracy on batch 783/3013  on Training is 87.35251913265306\n",
            "Epoch #4. Accuracy on batch 784/3013  on Training is 87.35668789808918\n",
            "Epoch #4. Accuracy on batch 785/3013  on Training is 87.3449427480916\n",
            "Epoch #4. Accuracy on batch 786/3013  on Training is 87.34116899618806\n",
            "Epoch #4. Accuracy on batch 787/3013  on Training is 87.35326776649747\n",
            "Epoch #4. Accuracy on batch 788/3013  on Training is 87.34553231939164\n",
            "Epoch #4. Accuracy on batch 789/3013  on Training is 87.3496835443038\n",
            "Epoch #4. Accuracy on batch 790/3013  on Training is 87.34987357774969\n",
            "Epoch #4. Accuracy on batch 791/3013  on Training is 87.35006313131314\n",
            "Epoch #4. Accuracy on batch 792/3013  on Training is 87.35025220680959\n",
            "Epoch #4. Accuracy on batch 793/3013  on Training is 87.34650503778337\n",
            "Epoch #4. Accuracy on batch 794/3013  on Training is 87.33883647798743\n",
            "Epoch #4. Accuracy on batch 795/3013  on Training is 87.33511306532664\n",
            "Epoch #4. Accuracy on batch 796/3013  on Training is 87.3392409033877\n",
            "Epoch #4. Accuracy on batch 797/3013  on Training is 87.35119047619048\n",
            "Epoch #4. Accuracy on batch 798/3013  on Training is 87.35528785982478\n",
            "Epoch #4. Accuracy on batch 799/3013  on Training is 87.359375\n",
            "Batch Id 800 is having training loss of 0.43506795167922974\n",
            "0.49920982122421265\n",
            "Epoch #4. Accuracy on batch 800/3013  on Training is 87.35564918851436\n",
            "Epoch #4. Accuracy on batch 801/3013  on Training is 87.34413965087282\n",
            "Epoch #4. Accuracy on batch 802/3013  on Training is 87.3365504358655\n",
            "Epoch #4. Accuracy on batch 803/3013  on Training is 87.33286691542288\n",
            "Epoch #4. Accuracy on batch 804/3013  on Training is 87.32531055900621\n",
            "Epoch #4. Accuracy on batch 805/3013  on Training is 87.33328163771712\n",
            "Epoch #4. Accuracy on batch 806/3013  on Training is 87.32961586121438\n",
            "Epoch #4. Accuracy on batch 807/3013  on Training is 87.32595915841584\n",
            "Epoch #4. Accuracy on batch 808/3013  on Training is 87.32231149567367\n",
            "Epoch #4. Accuracy on batch 809/3013  on Training is 87.31481481481481\n",
            "Epoch #4. Accuracy on batch 810/3013  on Training is 87.3150431565968\n",
            "Epoch #4. Accuracy on batch 811/3013  on Training is 87.31142241379311\n",
            "Epoch #4. Accuracy on batch 812/3013  on Training is 87.31934194341943\n",
            "Epoch #4. Accuracy on batch 813/3013  on Training is 87.31188574938575\n",
            "Epoch #4. Accuracy on batch 814/3013  on Training is 87.31978527607362\n",
            "Epoch #4. Accuracy on batch 815/3013  on Training is 87.32000612745098\n",
            "Epoch #4. Accuracy on batch 816/3013  on Training is 87.32405140758874\n",
            "Epoch #4. Accuracy on batch 817/3013  on Training is 87.30516503667482\n",
            "Epoch #4. Accuracy on batch 818/3013  on Training is 87.29395604395604\n",
            "Epoch #4. Accuracy on batch 819/3013  on Training is 87.29801829268293\n",
            "Batch Id 820 is having training loss of 0.43633294105529785\n",
            "0.4726167917251587\n",
            "Epoch #4. Accuracy on batch 820/3013  on Training is 87.29445797807551\n",
            "Epoch #4. Accuracy on batch 821/3013  on Training is 87.30231143552311\n",
            "Epoch #4. Accuracy on batch 822/3013  on Training is 87.29875455650061\n",
            "Epoch #4. Accuracy on batch 823/3013  on Training is 87.29141383495146\n",
            "Epoch #4. Accuracy on batch 824/3013  on Training is 87.29545454545455\n",
            "Epoch #4. Accuracy on batch 825/3013  on Training is 87.29570217917676\n",
            "Epoch #4. Accuracy on batch 826/3013  on Training is 87.29972793228536\n",
            "Epoch #4. Accuracy on batch 827/3013  on Training is 87.2961956521739\n",
            "Epoch #4. Accuracy on batch 828/3013  on Training is 87.30021109770809\n",
            "Epoch #4. Accuracy on batch 829/3013  on Training is 87.30045180722891\n",
            "Epoch #4. Accuracy on batch 830/3013  on Training is 87.3082129963899\n",
            "Epoch #4. Accuracy on batch 831/3013  on Training is 87.3046875\n",
            "Epoch #4. Accuracy on batch 832/3013  on Training is 87.30117046818728\n",
            "Epoch #4. Accuracy on batch 833/3013  on Training is 87.30515587529976\n",
            "Epoch #4. Accuracy on batch 834/3013  on Training is 87.29790419161677\n",
            "Epoch #4. Accuracy on batch 835/3013  on Training is 87.29814593301435\n",
            "Epoch #4. Accuracy on batch 836/3013  on Training is 87.29838709677419\n",
            "Epoch #4. Accuracy on batch 837/3013  on Training is 87.2948985680191\n",
            "Epoch #4. Accuracy on batch 838/3013  on Training is 87.29514302741359\n",
            "Epoch #4. Accuracy on batch 839/3013  on Training is 87.29166666666667\n",
            "Batch Id 840 is having training loss of 0.4359257221221924\n",
            "0.44319048523902893\n",
            "Epoch #4. Accuracy on batch 840/3013  on Training is 87.28819857312723\n",
            "Epoch #4. Accuracy on batch 841/3013  on Training is 87.28473871733966\n",
            "Epoch #4. Accuracy on batch 842/3013  on Training is 87.29240806642942\n",
            "Epoch #4. Accuracy on batch 843/3013  on Training is 87.30376184834124\n",
            "Epoch #4. Accuracy on batch 844/3013  on Training is 87.30399408284023\n",
            "Epoch #4. Accuracy on batch 845/3013  on Training is 87.3079196217494\n",
            "Epoch #4. Accuracy on batch 846/3013  on Training is 87.3155253837072\n",
            "Epoch #4. Accuracy on batch 847/3013  on Training is 87.31574292452831\n",
            "Epoch #4. Accuracy on batch 848/3013  on Training is 87.31964075382804\n",
            "Epoch #4. Accuracy on batch 849/3013  on Training is 87.32720588235294\n",
            "Epoch #4. Accuracy on batch 850/3013  on Training is 87.31639247943596\n",
            "Epoch #4. Accuracy on batch 851/3013  on Training is 87.31660798122066\n",
            "Epoch #4. Accuracy on batch 852/3013  on Training is 87.31315943728019\n",
            "Epoch #4. Accuracy on batch 853/3013  on Training is 87.31337822014052\n",
            "Epoch #4. Accuracy on batch 854/3013  on Training is 87.3172514619883\n",
            "Epoch #4. Accuracy on batch 855/3013  on Training is 87.30651285046729\n",
            "Epoch #4. Accuracy on batch 856/3013  on Training is 87.30673862310385\n",
            "Epoch #4. Accuracy on batch 857/3013  on Training is 87.31060606060606\n",
            "Epoch #4. Accuracy on batch 858/3013  on Training is 87.30718859138533\n",
            "Epoch #4. Accuracy on batch 859/3013  on Training is 87.3001453488372\n",
            "Batch Id 860 is having training loss of 0.43675389885902405\n",
            "0.5307450890541077\n",
            "Epoch #4. Accuracy on batch 860/3013  on Training is 87.30400696864112\n",
            "Epoch #4. Accuracy on batch 861/3013  on Training is 87.29698375870069\n",
            "Epoch #4. Accuracy on batch 862/3013  on Training is 87.2935979142526\n",
            "Epoch #4. Accuracy on batch 863/3013  on Training is 87.2902199074074\n",
            "Epoch #4. Accuracy on batch 864/3013  on Training is 87.30130057803468\n",
            "Epoch #4. Accuracy on batch 865/3013  on Training is 87.30153002309468\n",
            "Epoch #4. Accuracy on batch 866/3013  on Training is 87.29455017301038\n",
            "Epoch #4. Accuracy on batch 867/3013  on Training is 87.28758640552995\n",
            "Epoch #4. Accuracy on batch 868/3013  on Training is 87.28783084004603\n",
            "Epoch #4. Accuracy on batch 869/3013  on Training is 87.29885057471265\n",
            "Epoch #4. Accuracy on batch 870/3013  on Training is 87.30266934557979\n",
            "Epoch #4. Accuracy on batch 871/3013  on Training is 87.29572821100918\n",
            "Epoch #4. Accuracy on batch 872/3013  on Training is 87.28880297823596\n",
            "Epoch #4. Accuracy on batch 873/3013  on Training is 87.28189359267735\n",
            "Epoch #4. Accuracy on batch 874/3013  on Training is 87.28571428571429\n",
            "Epoch #4. Accuracy on batch 875/3013  on Training is 87.28239155251141\n",
            "Epoch #4. Accuracy on batch 876/3013  on Training is 87.2790763968073\n",
            "Epoch #4. Accuracy on batch 877/3013  on Training is 87.28288724373576\n",
            "Epoch #4. Accuracy on batch 878/3013  on Training is 87.27957906712173\n",
            "Epoch #4. Accuracy on batch 879/3013  on Training is 87.27982954545455\n",
            "Batch Id 880 is having training loss of 0.4365767538547516\n",
            "0.30608344078063965\n",
            "Epoch #4. Accuracy on batch 880/3013  on Training is 87.28362656072645\n",
            "Epoch #4. Accuracy on batch 881/3013  on Training is 87.27678571428571\n",
            "Epoch #4. Accuracy on batch 882/3013  on Training is 87.28411664779162\n",
            "Epoch #4. Accuracy on batch 883/3013  on Training is 87.28082579185521\n",
            "Epoch #4. Accuracy on batch 884/3013  on Training is 87.2704802259887\n",
            "Epoch #4. Accuracy on batch 885/3013  on Training is 87.27073927765237\n",
            "Epoch #4. Accuracy on batch 886/3013  on Training is 87.2533821871477\n",
            "Epoch #4. Accuracy on batch 887/3013  on Training is 87.2606981981982\n",
            "Epoch #4. Accuracy on batch 888/3013  on Training is 87.26096737907761\n",
            "Epoch #4. Accuracy on batch 889/3013  on Training is 87.26123595505618\n",
            "Epoch #4. Accuracy on batch 890/3013  on Training is 87.25799663299664\n",
            "Epoch #4. Accuracy on batch 891/3013  on Training is 87.25476457399103\n",
            "Epoch #4. Accuracy on batch 892/3013  on Training is 87.255039193729\n",
            "Epoch #4. Accuracy on batch 893/3013  on Training is 87.25181767337807\n",
            "Epoch #4. Accuracy on batch 894/3013  on Training is 87.24511173184358\n",
            "Epoch #4. Accuracy on batch 895/3013  on Training is 87.25237165178571\n",
            "Epoch #4. Accuracy on batch 896/3013  on Training is 87.2561315496098\n",
            "Epoch #4. Accuracy on batch 897/3013  on Training is 87.25988307349665\n",
            "Epoch #4. Accuracy on batch 898/3013  on Training is 87.2531979977753\n",
            "Epoch #4. Accuracy on batch 899/3013  on Training is 87.25347222222223\n",
            "Batch Id 900 is having training loss of 0.43697893619537354\n",
            "0.4146163761615753\n",
            "Epoch #4. Accuracy on batch 900/3013  on Training is 87.24334073251943\n",
            "Epoch #4. Accuracy on batch 901/3013  on Training is 87.24362527716187\n",
            "Epoch #4. Accuracy on batch 902/3013  on Training is 87.24390919158361\n",
            "Epoch #4. Accuracy on batch 903/3013  on Training is 87.24764933628319\n",
            "Epoch #4. Accuracy on batch 904/3013  on Training is 87.24102209944752\n",
            "Epoch #4. Accuracy on batch 905/3013  on Training is 87.24130794701986\n",
            "Epoch #4. Accuracy on batch 906/3013  on Training is 87.24503858875414\n",
            "Epoch #4. Accuracy on batch 907/3013  on Training is 87.24531938325991\n",
            "Epoch #4. Accuracy on batch 908/3013  on Training is 87.24559955995599\n",
            "Epoch #4. Accuracy on batch 909/3013  on Training is 87.25618131868131\n",
            "Epoch #4. Accuracy on batch 910/3013  on Training is 87.25301866081229\n",
            "Epoch #4. Accuracy on batch 911/3013  on Training is 87.26356907894737\n",
            "Epoch #4. Accuracy on batch 912/3013  on Training is 87.2604052573932\n",
            "Epoch #4. Accuracy on batch 913/3013  on Training is 87.26066739606127\n",
            "Epoch #4. Accuracy on batch 914/3013  on Training is 87.25751366120218\n",
            "Epoch #4. Accuracy on batch 915/3013  on Training is 87.26118995633188\n",
            "Epoch #4. Accuracy on batch 916/3013  on Training is 87.2614503816794\n",
            "Epoch #4. Accuracy on batch 917/3013  on Training is 87.26851851851852\n",
            "Epoch #4. Accuracy on batch 918/3013  on Training is 87.26877040261154\n",
            "Epoch #4. Accuracy on batch 919/3013  on Training is 87.25883152173913\n",
            "Batch Id 920 is having training loss of 0.4372533857822418\n",
            "0.4960707128047943\n",
            "Epoch #4. Accuracy on batch 920/3013  on Training is 87.25909337676438\n",
            "Epoch #4. Accuracy on batch 921/3013  on Training is 87.2593546637744\n",
            "Epoch #4. Accuracy on batch 922/3013  on Training is 87.26638678223185\n",
            "Epoch #4. Accuracy on batch 923/3013  on Training is 87.2666396103896\n",
            "Epoch #4. Accuracy on batch 924/3013  on Training is 87.26013513513513\n",
            "Epoch #4. Accuracy on batch 925/3013  on Training is 87.25701943844493\n",
            "Epoch #4. Accuracy on batch 926/3013  on Training is 87.25391046386191\n",
            "Epoch #4. Accuracy on batch 927/3013  on Training is 87.25754310344827\n",
            "Epoch #4. Accuracy on batch 928/3013  on Training is 87.24771259418729\n",
            "Epoch #4. Accuracy on batch 929/3013  on Training is 87.24462365591398\n",
            "Epoch #4. Accuracy on batch 930/3013  on Training is 87.24154135338345\n",
            "Epoch #4. Accuracy on batch 931/3013  on Training is 87.2485246781116\n",
            "Epoch #4. Accuracy on batch 932/3013  on Training is 87.2521436227224\n",
            "Epoch #4. Accuracy on batch 933/3013  on Training is 87.25910064239828\n",
            "Epoch #4. Accuracy on batch 934/3013  on Training is 87.26270053475936\n",
            "Epoch #4. Accuracy on batch 935/3013  on Training is 87.26295405982906\n",
            "Epoch #4. Accuracy on batch 936/3013  on Training is 87.25320170757738\n",
            "Epoch #4. Accuracy on batch 937/3013  on Training is 87.24013859275053\n",
            "Epoch #4. Accuracy on batch 938/3013  on Training is 87.24707135250266\n",
            "Epoch #4. Accuracy on batch 939/3013  on Training is 87.2373670212766\n",
            "Batch Id 940 is having training loss of 0.4381033182144165\n",
            "0.7527022361755371\n",
            "Epoch #4. Accuracy on batch 940/3013  on Training is 87.22768331562168\n",
            "Epoch #4. Accuracy on batch 941/3013  on Training is 87.22797239915074\n",
            "Epoch #4. Accuracy on batch 942/3013  on Training is 87.22494697773065\n",
            "Epoch #4. Accuracy on batch 943/3013  on Training is 87.22523834745763\n",
            "Epoch #4. Accuracy on batch 944/3013  on Training is 87.22883597883597\n",
            "Epoch #4. Accuracy on batch 945/3013  on Training is 87.22912262156449\n",
            "Epoch #4. Accuracy on batch 946/3013  on Training is 87.22940865892292\n",
            "Epoch #4. Accuracy on batch 947/3013  on Training is 87.229694092827\n",
            "Epoch #4. Accuracy on batch 948/3013  on Training is 87.23656480505795\n",
            "Epoch #4. Accuracy on batch 949/3013  on Training is 87.23684210526316\n",
            "Epoch #4. Accuracy on batch 950/3013  on Training is 87.23383280757098\n",
            "Epoch #4. Accuracy on batch 951/3013  on Training is 87.24067752100841\n",
            "Epoch #4. Accuracy on batch 952/3013  on Training is 87.23439139559287\n",
            "Epoch #4. Accuracy on batch 953/3013  on Training is 87.23139412997904\n",
            "Epoch #4. Accuracy on batch 954/3013  on Training is 87.22840314136126\n",
            "Epoch #4. Accuracy on batch 955/3013  on Training is 87.22541841004184\n",
            "Epoch #4. Accuracy on batch 956/3013  on Training is 87.2257053291536\n",
            "Epoch #4. Accuracy on batch 957/3013  on Training is 87.22599164926932\n",
            "Epoch #4. Accuracy on batch 958/3013  on Training is 87.23605318039624\n",
            "Epoch #4. Accuracy on batch 959/3013  on Training is 87.22981770833333\n",
            "Batch Id 960 is having training loss of 0.437391996383667\n",
            "0.34213295578956604\n",
            "Epoch #4. Accuracy on batch 960/3013  on Training is 87.23335067637878\n",
            "Epoch #4. Accuracy on batch 961/3013  on Training is 87.23037941787942\n",
            "Epoch #4. Accuracy on batch 962/3013  on Training is 87.23714953271028\n",
            "Epoch #4. Accuracy on batch 963/3013  on Training is 87.23742219917013\n",
            "Epoch #4. Accuracy on batch 964/3013  on Training is 87.24093264248705\n",
            "Epoch #4. Accuracy on batch 965/3013  on Training is 87.24120082815735\n",
            "Epoch #4. Accuracy on batch 966/3013  on Training is 87.23500517063081\n",
            "Epoch #4. Accuracy on batch 967/3013  on Training is 87.23527892561984\n",
            "Epoch #4. Accuracy on batch 968/3013  on Training is 87.23555211558308\n",
            "Epoch #4. Accuracy on batch 969/3013  on Training is 87.23904639175258\n",
            "Epoch #4. Accuracy on batch 970/3013  on Training is 87.24253347064881\n",
            "Epoch #4. Accuracy on batch 971/3013  on Training is 87.2460133744856\n",
            "Epoch #4. Accuracy on batch 972/3013  on Training is 87.2494861253854\n",
            "Epoch #4. Accuracy on batch 973/3013  on Training is 87.24974332648871\n",
            "Epoch #4. Accuracy on batch 974/3013  on Training is 87.24358974358974\n",
            "Epoch #4. Accuracy on batch 975/3013  on Training is 87.2438524590164\n",
            "Epoch #4. Accuracy on batch 976/3013  on Training is 87.224923234391\n",
            "Epoch #4. Accuracy on batch 977/3013  on Training is 87.21881390593047\n",
            "Epoch #4. Accuracy on batch 978/3013  on Training is 87.20952502553627\n",
            "Epoch #4. Accuracy on batch 979/3013  on Training is 87.20982142857143\n",
            "Batch Id 980 is having training loss of 0.4377255439758301\n",
            "0.4035373628139496\n",
            "Epoch #4. Accuracy on batch 980/3013  on Training is 87.21967380224261\n",
            "Epoch #4. Accuracy on batch 981/3013  on Training is 87.2231415478615\n",
            "Epoch #4. Accuracy on batch 982/3013  on Training is 87.22978128179044\n",
            "Epoch #4. Accuracy on batch 983/3013  on Training is 87.2364075203252\n",
            "Epoch #4. Accuracy on batch 984/3013  on Training is 87.2239847715736\n",
            "Epoch #4. Accuracy on batch 985/3013  on Training is 87.23060344827586\n",
            "Epoch #4. Accuracy on batch 986/3013  on Training is 87.2403748733536\n",
            "Epoch #4. Accuracy on batch 987/3013  on Training is 87.22798582995951\n",
            "Epoch #4. Accuracy on batch 988/3013  on Training is 87.23142062689585\n",
            "Epoch #4. Accuracy on batch 989/3013  on Training is 87.23800505050505\n",
            "Epoch #4. Accuracy on batch 990/3013  on Training is 87.23511604439959\n",
            "Epoch #4. Accuracy on batch 991/3013  on Training is 87.21963205645162\n",
            "Epoch #4. Accuracy on batch 992/3013  on Training is 87.21047331319235\n",
            "Epoch #4. Accuracy on batch 993/3013  on Training is 87.20133299798793\n",
            "Epoch #4. Accuracy on batch 994/3013  on Training is 87.20791457286433\n",
            "Epoch #4. Accuracy on batch 995/3013  on Training is 87.2144829317269\n",
            "Epoch #4. Accuracy on batch 996/3013  on Training is 87.19909729187563\n",
            "Epoch #4. Accuracy on batch 997/3013  on Training is 87.18687374749499\n",
            "Epoch #4. Accuracy on batch 998/3013  on Training is 87.18718718718719\n",
            "Epoch #4. Accuracy on batch 999/3013  on Training is 87.175\n",
            "Batch Id 1000 is having training loss of 0.43918493390083313\n",
            "0.0631585419178009\n",
            "Epoch #4. Accuracy on batch 1000/3013  on Training is 87.18781218781218\n",
            "Epoch #4. Accuracy on batch 1001/3013  on Training is 87.19748003992017\n",
            "Epoch #4. Accuracy on batch 1002/3013  on Training is 87.19155034895314\n",
            "Epoch #4. Accuracy on batch 1003/3013  on Training is 87.19808266932272\n",
            "Epoch #4. Accuracy on batch 1004/3013  on Training is 87.19838308457712\n",
            "Epoch #4. Accuracy on batch 1005/3013  on Training is 87.1986829025845\n",
            "Epoch #4. Accuracy on batch 1006/3013  on Training is 87.20208540218471\n",
            "Epoch #4. Accuracy on batch 1007/3013  on Training is 87.20238095238095\n",
            "Epoch #4. Accuracy on batch 1008/3013  on Training is 87.20267591674926\n",
            "Epoch #4. Accuracy on batch 1009/3013  on Training is 87.19987623762377\n",
            "Epoch #4. Accuracy on batch 1010/3013  on Training is 87.2001730959446\n",
            "Epoch #4. Accuracy on batch 1011/3013  on Training is 87.206645256917\n",
            "Epoch #4. Accuracy on batch 1012/3013  on Training is 87.20693484698914\n",
            "Epoch #4. Accuracy on batch 1013/3013  on Training is 87.21030571992111\n",
            "Epoch #4. Accuracy on batch 1014/3013  on Training is 87.20751231527093\n",
            "Epoch #4. Accuracy on batch 1015/3013  on Training is 87.20472440944881\n",
            "Epoch #4. Accuracy on batch 1016/3013  on Training is 87.21116027531957\n",
            "Epoch #4. Accuracy on batch 1017/3013  on Training is 87.2022347740668\n",
            "Epoch #4. Accuracy on batch 1018/3013  on Training is 87.19332679097154\n",
            "Epoch #4. Accuracy on batch 1019/3013  on Training is 87.19975490196079\n",
            "Batch Id 1020 is having training loss of 0.43844395875930786\n",
            "0.3463362753391266\n",
            "Epoch #4. Accuracy on batch 1020/3013  on Training is 87.19698824681684\n",
            "Epoch #4. Accuracy on batch 1021/3013  on Training is 87.20034246575342\n",
            "Epoch #4. Accuracy on batch 1022/3013  on Training is 87.20063538611926\n",
            "Epoch #4. Accuracy on batch 1023/3013  on Training is 87.1917724609375\n",
            "Epoch #4. Accuracy on batch 1024/3013  on Training is 87.1859756097561\n",
            "Epoch #4. Accuracy on batch 1025/3013  on Training is 87.18932748538012\n",
            "Epoch #4. Accuracy on batch 1026/3013  on Training is 87.19571567672834\n",
            "Epoch #4. Accuracy on batch 1027/3013  on Training is 87.19601167315174\n",
            "Epoch #4. Accuracy on batch 1028/3013  on Training is 87.19630709426627\n",
            "Epoch #4. Accuracy on batch 1029/3013  on Training is 87.20266990291262\n",
            "Epoch #4. Accuracy on batch 1030/3013  on Training is 87.20598933074685\n",
            "Epoch #4. Accuracy on batch 1031/3013  on Training is 87.21233042635659\n",
            "Epoch #4. Accuracy on batch 1032/3013  on Training is 87.20050822846079\n",
            "Epoch #4. Accuracy on batch 1033/3013  on Training is 87.20382011605416\n",
            "Epoch #4. Accuracy on batch 1034/3013  on Training is 87.18900966183575\n",
            "Epoch #4. Accuracy on batch 1035/3013  on Training is 87.18327702702703\n",
            "Epoch #4. Accuracy on batch 1036/3013  on Training is 87.18056894889104\n",
            "Epoch #4. Accuracy on batch 1037/3013  on Training is 87.183887283237\n",
            "Epoch #4. Accuracy on batch 1038/3013  on Training is 87.19020692974013\n",
            "Epoch #4. Accuracy on batch 1039/3013  on Training is 87.1905048076923\n",
            "Batch Id 1040 is having training loss of 0.43934816122055054\n",
            "0.5748967528343201\n",
            "Epoch #4. Accuracy on batch 1040/3013  on Training is 87.18479827089337\n",
            "Epoch #4. Accuracy on batch 1041/3013  on Training is 87.18809980806142\n",
            "Epoch #4. Accuracy on batch 1042/3013  on Training is 87.1943911792905\n",
            "Epoch #4. Accuracy on batch 1043/3013  on Training is 87.19468390804597\n",
            "Epoch #4. Accuracy on batch 1044/3013  on Training is 87.19198564593302\n",
            "Epoch #4. Accuracy on batch 1045/3013  on Training is 87.18929254302103\n",
            "Epoch #4. Accuracy on batch 1046/3013  on Training is 87.18958930276982\n",
            "Epoch #4. Accuracy on batch 1047/3013  on Training is 87.18093988549619\n",
            "Epoch #4. Accuracy on batch 1048/3013  on Training is 87.18124404194471\n",
            "Epoch #4. Accuracy on batch 1049/3013  on Training is 87.17559523809524\n",
            "Epoch #4. Accuracy on batch 1050/3013  on Training is 87.17293054234062\n",
            "Epoch #4. Accuracy on batch 1051/3013  on Training is 87.17324144486692\n",
            "Epoch #4. Accuracy on batch 1052/3013  on Training is 87.17355175688509\n",
            "Epoch #4. Accuracy on batch 1053/3013  on Training is 87.1738614800759\n",
            "Epoch #4. Accuracy on batch 1054/3013  on Training is 87.17417061611374\n",
            "Epoch #4. Accuracy on batch 1055/3013  on Training is 87.17151988636364\n",
            "Epoch #4. Accuracy on batch 1056/3013  on Training is 87.1747871333964\n",
            "Epoch #4. Accuracy on batch 1057/3013  on Training is 87.1632797731569\n",
            "Epoch #4. Accuracy on batch 1058/3013  on Training is 87.16654863078377\n",
            "Epoch #4. Accuracy on batch 1059/3013  on Training is 87.16981132075472\n",
            "Batch Id 1060 is having training loss of 0.43954819440841675\n",
            "0.23101237416267395\n",
            "Epoch #4. Accuracy on batch 1060/3013  on Training is 87.17895852968897\n",
            "Epoch #4. Accuracy on batch 1061/3013  on Training is 87.17926082862523\n",
            "Epoch #4. Accuracy on batch 1062/3013  on Training is 87.18250235183443\n",
            "Epoch #4. Accuracy on batch 1063/3013  on Training is 87.1828007518797\n",
            "Epoch #4. Accuracy on batch 1064/3013  on Training is 87.18603286384976\n",
            "Epoch #4. Accuracy on batch 1065/3013  on Training is 87.18339587242026\n",
            "Epoch #4. Accuracy on batch 1066/3013  on Training is 87.18369259606374\n",
            "Epoch #4. Accuracy on batch 1067/3013  on Training is 87.1810627340824\n",
            "Epoch #4. Accuracy on batch 1068/3013  on Training is 87.1872076707203\n",
            "Epoch #4. Accuracy on batch 1069/3013  on Training is 87.18457943925233\n",
            "Epoch #4. Accuracy on batch 1070/3013  on Training is 87.19362745098039\n",
            "Epoch #4. Accuracy on batch 1071/3013  on Training is 87.19391324626865\n",
            "Epoch #4. Accuracy on batch 1072/3013  on Training is 87.19711090400746\n",
            "Epoch #4. Accuracy on batch 1073/3013  on Training is 87.19448324022346\n",
            "Epoch #4. Accuracy on batch 1074/3013  on Training is 87.19767441860465\n",
            "Epoch #4. Accuracy on batch 1075/3013  on Training is 87.1921468401487\n",
            "Epoch #4. Accuracy on batch 1076/3013  on Training is 87.19823584029712\n",
            "Epoch #4. Accuracy on batch 1077/3013  on Training is 87.20431354359926\n",
            "Epoch #4. Accuracy on batch 1078/3013  on Training is 87.2045875810936\n",
            "Epoch #4. Accuracy on batch 1079/3013  on Training is 87.19618055555556\n",
            "Batch Id 1080 is having training loss of 0.43918314576148987\n",
            "0.22390621900558472\n",
            "Epoch #4. Accuracy on batch 1080/3013  on Training is 87.20513413506013\n",
            "Epoch #4. Accuracy on batch 1081/3013  on Training is 87.20829482439926\n",
            "Epoch #4. Accuracy on batch 1082/3013  on Training is 87.20856417359188\n",
            "Epoch #4. Accuracy on batch 1083/3013  on Training is 87.2174815498155\n",
            "Epoch #4. Accuracy on batch 1084/3013  on Training is 87.21198156682027\n",
            "Epoch #4. Accuracy on batch 1085/3013  on Training is 87.2122467771639\n",
            "Epoch #4. Accuracy on batch 1086/3013  on Training is 87.21251149954001\n",
            "Epoch #4. Accuracy on batch 1087/3013  on Training is 87.20703125\n",
            "Epoch #4. Accuracy on batch 1088/3013  on Training is 87.21016988062442\n",
            "Epoch #4. Accuracy on batch 1089/3013  on Training is 87.20470183486239\n",
            "Epoch #4. Accuracy on batch 1090/3013  on Training is 87.19637946837763\n",
            "Epoch #4. Accuracy on batch 1091/3013  on Training is 87.1966575091575\n",
            "Epoch #4. Accuracy on batch 1092/3013  on Training is 87.19693504117109\n",
            "Epoch #4. Accuracy on batch 1093/3013  on Training is 87.18864259597807\n",
            "Epoch #4. Accuracy on batch 1094/3013  on Training is 87.19463470319634\n",
            "Epoch #4. Accuracy on batch 1095/3013  on Training is 87.19206204379562\n",
            "Epoch #4. Accuracy on batch 1096/3013  on Training is 87.18664539653601\n",
            "Epoch #4. Accuracy on batch 1097/3013  on Training is 87.18977686703097\n",
            "Epoch #4. Accuracy on batch 1098/3013  on Training is 87.17868516833485\n",
            "Epoch #4. Accuracy on batch 1099/3013  on Training is 87.17045454545455\n",
            "Batch Id 1100 is having training loss of 0.44064512848854065\n",
            "0.5466437935829163\n",
            "Epoch #4. Accuracy on batch 1100/3013  on Training is 87.16507720254315\n",
            "Epoch #4. Accuracy on batch 1101/3013  on Training is 87.15687386569873\n",
            "Epoch #4. Accuracy on batch 1102/3013  on Training is 87.15435176790571\n",
            "Epoch #4. Accuracy on batch 1103/3013  on Training is 87.15183423913044\n",
            "Epoch #4. Accuracy on batch 1104/3013  on Training is 87.15497737556561\n",
            "Epoch #4. Accuracy on batch 1105/3013  on Training is 87.15528933092224\n",
            "Epoch #4. Accuracy on batch 1106/3013  on Training is 87.1556007226739\n",
            "Epoch #4. Accuracy on batch 1107/3013  on Training is 87.15591155234657\n",
            "Epoch #4. Accuracy on batch 1108/3013  on Training is 87.15903967538323\n",
            "Epoch #4. Accuracy on batch 1109/3013  on Training is 87.15934684684684\n",
            "Epoch #4. Accuracy on batch 1110/3013  on Training is 87.16527902790278\n",
            "Epoch #4. Accuracy on batch 1111/3013  on Training is 87.16276978417267\n",
            "Epoch #4. Accuracy on batch 1112/3013  on Training is 87.15745732255166\n",
            "Epoch #4. Accuracy on batch 1113/3013  on Training is 87.15776481149013\n",
            "Epoch #4. Accuracy on batch 1114/3013  on Training is 87.15807174887892\n",
            "Epoch #4. Accuracy on batch 1115/3013  on Training is 87.15557795698925\n",
            "Epoch #4. Accuracy on batch 1116/3013  on Training is 87.15868397493286\n",
            "Epoch #4. Accuracy on batch 1117/3013  on Training is 87.16178443649373\n",
            "Epoch #4. Accuracy on batch 1118/3013  on Training is 87.16208668453977\n",
            "Epoch #4. Accuracy on batch 1119/3013  on Training is 87.16238839285714\n",
            "Batch Id 1120 is having training loss of 0.44081607460975647\n",
            "0.6023406982421875\n",
            "Epoch #4. Accuracy on batch 1120/3013  on Training is 87.15990187332739\n",
            "Epoch #4. Accuracy on batch 1121/3013  on Training is 87.16020499108734\n",
            "Epoch #4. Accuracy on batch 1122/3013  on Training is 87.1577248441674\n",
            "Epoch #4. Accuracy on batch 1123/3013  on Training is 87.144128113879\n",
            "Epoch #4. Accuracy on batch 1124/3013  on Training is 87.14166666666667\n",
            "Epoch #4. Accuracy on batch 1125/3013  on Training is 87.13920959147424\n",
            "Epoch #4. Accuracy on batch 1126/3013  on Training is 87.14784826974268\n",
            "Epoch #4. Accuracy on batch 1127/3013  on Training is 87.15647163120568\n",
            "Epoch #4. Accuracy on batch 1128/3013  on Training is 87.14847209920283\n",
            "Epoch #4. Accuracy on batch 1129/3013  on Training is 87.14325221238938\n",
            "Epoch #4. Accuracy on batch 1130/3013  on Training is 87.13527851458886\n",
            "Epoch #4. Accuracy on batch 1131/3013  on Training is 87.12731890459364\n",
            "Epoch #4. Accuracy on batch 1132/3013  on Training is 87.13592233009709\n",
            "Epoch #4. Accuracy on batch 1133/3013  on Training is 87.13348765432099\n",
            "Epoch #4. Accuracy on batch 1134/3013  on Training is 87.1283039647577\n",
            "Epoch #4. Accuracy on batch 1135/3013  on Training is 87.13413292253522\n",
            "Epoch #4. Accuracy on batch 1136/3013  on Training is 87.12895778364116\n",
            "Epoch #4. Accuracy on batch 1137/3013  on Training is 87.14026801405976\n",
            "Epoch #4. Accuracy on batch 1138/3013  on Training is 87.1268656716418\n",
            "Epoch #4. Accuracy on batch 1139/3013  on Training is 87.1217105263158\n",
            "Batch Id 1140 is having training loss of 0.4409343898296356\n",
            "0.3003496527671814\n",
            "Epoch #4. Accuracy on batch 1140/3013  on Training is 87.12204206836108\n",
            "Epoch #4. Accuracy on batch 1141/3013  on Training is 87.11142732049036\n",
            "Epoch #4. Accuracy on batch 1142/3013  on Training is 87.10903324584427\n",
            "Epoch #4. Accuracy on batch 1143/3013  on Training is 87.109375\n",
            "Epoch #4. Accuracy on batch 1144/3013  on Training is 87.10698689956332\n",
            "Epoch #4. Accuracy on batch 1145/3013  on Training is 87.09914921465969\n",
            "Epoch #4. Accuracy on batch 1146/3013  on Training is 87.1049476896251\n",
            "Epoch #4. Accuracy on batch 1147/3013  on Training is 87.10529181184668\n",
            "Epoch #4. Accuracy on batch 1148/3013  on Training is 87.10563533507398\n",
            "Epoch #4. Accuracy on batch 1149/3013  on Training is 87.10597826086956\n",
            "Epoch #4. Accuracy on batch 1150/3013  on Training is 87.11718071242397\n",
            "Epoch #4. Accuracy on batch 1151/3013  on Training is 87.109375\n",
            "Epoch #4. Accuracy on batch 1152/3013  on Training is 87.11784475281874\n",
            "Epoch #4. Accuracy on batch 1153/3013  on Training is 87.11546793760832\n",
            "Epoch #4. Accuracy on batch 1154/3013  on Training is 87.11580086580086\n",
            "Epoch #4. Accuracy on batch 1155/3013  on Training is 87.11613321799308\n",
            "Epoch #4. Accuracy on batch 1156/3013  on Training is 87.11376404494382\n",
            "Epoch #4. Accuracy on batch 1157/3013  on Training is 87.10060449050086\n",
            "Epoch #4. Accuracy on batch 1158/3013  on Training is 87.09286022433132\n",
            "Epoch #4. Accuracy on batch 1159/3013  on Training is 87.09321120689656\n",
            "Batch Id 1160 is having training loss of 0.441908061504364\n",
            "0.48585331439971924\n",
            "Epoch #4. Accuracy on batch 1160/3013  on Training is 87.09356158484066\n",
            "Epoch #4. Accuracy on batch 1161/3013  on Training is 87.09391135972461\n",
            "Epoch #4. Accuracy on batch 1162/3013  on Training is 87.09426053310405\n",
            "Epoch #4. Accuracy on batch 1163/3013  on Training is 87.0946091065292\n",
            "Epoch #4. Accuracy on batch 1164/3013  on Training is 87.08959227467811\n",
            "Epoch #4. Accuracy on batch 1165/3013  on Training is 87.09530445969125\n",
            "Epoch #4. Accuracy on batch 1166/3013  on Training is 87.10100685518424\n",
            "Epoch #4. Accuracy on batch 1167/3013  on Training is 87.09599743150685\n",
            "Epoch #4. Accuracy on batch 1168/3013  on Training is 87.08297690333619\n",
            "Epoch #4. Accuracy on batch 1169/3013  on Training is 87.07799145299145\n",
            "Epoch #4. Accuracy on batch 1170/3013  on Training is 87.06767719897523\n",
            "Epoch #4. Accuracy on batch 1171/3013  on Training is 87.07071245733789\n",
            "Epoch #4. Accuracy on batch 1172/3013  on Training is 87.06575021312872\n",
            "Epoch #4. Accuracy on batch 1173/3013  on Training is 87.06345826235093\n",
            "Epoch #4. Accuracy on batch 1174/3013  on Training is 87.05053191489361\n",
            "Epoch #4. Accuracy on batch 1175/3013  on Training is 87.05357142857143\n",
            "Epoch #4. Accuracy on batch 1176/3013  on Training is 87.05660577740016\n",
            "Epoch #4. Accuracy on batch 1177/3013  on Training is 87.06228777589133\n",
            "Epoch #4. Accuracy on batch 1178/3013  on Training is 87.06796013570823\n",
            "Epoch #4. Accuracy on batch 1179/3013  on Training is 87.06038135593221\n",
            "Batch Id 1180 is having training loss of 0.44273874163627625\n",
            "0.5690258741378784\n",
            "Epoch #4. Accuracy on batch 1180/3013  on Training is 87.05281541066893\n",
            "Epoch #4. Accuracy on batch 1181/3013  on Training is 87.04526226734349\n",
            "Epoch #4. Accuracy on batch 1182/3013  on Training is 87.04564666103127\n",
            "Epoch #4. Accuracy on batch 1183/3013  on Training is 87.04866976351352\n",
            "Epoch #4. Accuracy on batch 1184/3013  on Training is 87.04905063291139\n",
            "Epoch #4. Accuracy on batch 1185/3013  on Training is 87.04679595278246\n",
            "Epoch #4. Accuracy on batch 1186/3013  on Training is 87.04981044650378\n",
            "Epoch #4. Accuracy on batch 1187/3013  on Training is 87.05018939393939\n",
            "Epoch #4. Accuracy on batch 1188/3013  on Training is 87.05056770395291\n",
            "Epoch #4. Accuracy on batch 1189/3013  on Training is 87.05882352941177\n",
            "Epoch #4. Accuracy on batch 1190/3013  on Training is 87.05919395465995\n",
            "Epoch #4. Accuracy on batch 1191/3013  on Training is 87.05956375838926\n",
            "Epoch #4. Accuracy on batch 1192/3013  on Training is 87.06255238893546\n",
            "Epoch #4. Accuracy on batch 1193/3013  on Training is 87.06553601340033\n",
            "Epoch #4. Accuracy on batch 1194/3013  on Training is 87.06328451882845\n",
            "Epoch #4. Accuracy on batch 1195/3013  on Training is 87.05842391304348\n",
            "Epoch #4. Accuracy on batch 1196/3013  on Training is 87.0561821219716\n",
            "Epoch #4. Accuracy on batch 1197/3013  on Training is 87.06176961602671\n",
            "Epoch #4. Accuracy on batch 1198/3013  on Training is 87.06474145120934\n",
            "Epoch #4. Accuracy on batch 1199/3013  on Training is 87.06510416666667\n",
            "Batch Id 1200 is having training loss of 0.4424964487552643\n",
            "0.30161505937576294\n",
            "Epoch #4. Accuracy on batch 1200/3013  on Training is 87.06546627810158\n",
            "Epoch #4. Accuracy on batch 1201/3013  on Training is 87.06062811980033\n",
            "Epoch #4. Accuracy on batch 1202/3013  on Training is 87.06099334995844\n",
            "Epoch #4. Accuracy on batch 1203/3013  on Training is 87.06395348837209\n",
            "Epoch #4. Accuracy on batch 1204/3013  on Training is 87.0643153526971\n",
            "Epoch #4. Accuracy on batch 1205/3013  on Training is 87.06467661691542\n",
            "Epoch #4. Accuracy on batch 1206/3013  on Training is 87.05985915492958\n",
            "Epoch #4. Accuracy on batch 1207/3013  on Training is 87.06281043046357\n",
            "Epoch #4. Accuracy on batch 1208/3013  on Training is 87.06834160463193\n",
            "Epoch #4. Accuracy on batch 1209/3013  on Training is 87.06353305785125\n",
            "Epoch #4. Accuracy on batch 1210/3013  on Training is 87.06131296449216\n",
            "Epoch #4. Accuracy on batch 1211/3013  on Training is 87.05651815181518\n",
            "Epoch #4. Accuracy on batch 1212/3013  on Training is 87.05173124484749\n",
            "Epoch #4. Accuracy on batch 1213/3013  on Training is 87.05724876441516\n",
            "Epoch #4. Accuracy on batch 1214/3013  on Training is 87.05761316872427\n",
            "Epoch #4. Accuracy on batch 1215/3013  on Training is 87.05026726973684\n",
            "Epoch #4. Accuracy on batch 1216/3013  on Training is 87.05063681183238\n",
            "Epoch #4. Accuracy on batch 1217/3013  on Training is 87.05100574712644\n",
            "Epoch #4. Accuracy on batch 1218/3013  on Training is 87.0539376538146\n",
            "Epoch #4. Accuracy on batch 1219/3013  on Training is 87.05430327868852\n",
            "Batch Id 1220 is having training loss of 0.4428233802318573\n",
            "0.19311387836933136\n",
            "Epoch #4. Accuracy on batch 1220/3013  on Training is 87.05978705978706\n",
            "Epoch #4. Accuracy on batch 1221/3013  on Training is 87.060147299509\n",
            "Epoch #4. Accuracy on batch 1222/3013  on Training is 87.0630621422731\n",
            "Epoch #4. Accuracy on batch 1223/3013  on Training is 87.05575980392157\n",
            "Epoch #4. Accuracy on batch 1224/3013  on Training is 87.0561224489796\n",
            "Epoch #4. Accuracy on batch 1225/3013  on Training is 87.0590334420881\n",
            "Epoch #4. Accuracy on batch 1226/3013  on Training is 87.05939282803585\n",
            "Epoch #4. Accuracy on batch 1227/3013  on Training is 87.05466205211727\n",
            "Epoch #4. Accuracy on batch 1228/3013  on Training is 87.0550244100895\n",
            "Epoch #4. Accuracy on batch 1229/3013  on Training is 87.0604674796748\n",
            "Epoch #4. Accuracy on batch 1230/3013  on Training is 87.06082453290009\n",
            "Epoch #4. Accuracy on batch 1231/3013  on Training is 87.05864448051948\n",
            "Epoch #4. Accuracy on batch 1232/3013  on Training is 87.05900243309003\n",
            "Epoch #4. Accuracy on batch 1233/3013  on Training is 87.06442463533226\n",
            "Epoch #4. Accuracy on batch 1234/3013  on Training is 87.05971659919028\n",
            "Epoch #4. Accuracy on batch 1235/3013  on Training is 87.05248786407768\n",
            "Epoch #4. Accuracy on batch 1236/3013  on Training is 87.04779708973322\n",
            "Epoch #4. Accuracy on batch 1237/3013  on Training is 87.05068659127625\n",
            "Epoch #4. Accuracy on batch 1238/3013  on Training is 87.046004842615\n",
            "Epoch #4. Accuracy on batch 1239/3013  on Training is 87.0413306451613\n",
            "Batch Id 1240 is having training loss of 0.44290298223495483\n",
            "0.23925483226776123\n",
            "Epoch #4. Accuracy on batch 1240/3013  on Training is 87.04170024174053\n",
            "Epoch #4. Accuracy on batch 1241/3013  on Training is 87.03703703703704\n",
            "Epoch #4. Accuracy on batch 1242/3013  on Training is 87.03238133547868\n",
            "Epoch #4. Accuracy on batch 1243/3013  on Training is 87.02773311897106\n",
            "Epoch #4. Accuracy on batch 1244/3013  on Training is 87.02560240963855\n",
            "Epoch #4. Accuracy on batch 1245/3013  on Training is 87.02347512038523\n",
            "Epoch #4. Accuracy on batch 1246/3013  on Training is 87.02636327185245\n",
            "Epoch #4. Accuracy on batch 1247/3013  on Training is 87.02674278846153\n",
            "Epoch #4. Accuracy on batch 1248/3013  on Training is 87.02712169735788\n",
            "Epoch #4. Accuracy on batch 1249/3013  on Training is 87.0325\n",
            "Epoch #4. Accuracy on batch 1250/3013  on Training is 87.03537170263789\n",
            "Epoch #4. Accuracy on batch 1251/3013  on Training is 87.03324680511182\n",
            "Epoch #4. Accuracy on batch 1252/3013  on Training is 87.04359537110933\n",
            "Epoch #4. Accuracy on batch 1253/3013  on Training is 87.0414673046252\n",
            "Epoch #4. Accuracy on batch 1254/3013  on Training is 87.03685258964144\n",
            "Epoch #4. Accuracy on batch 1255/3013  on Training is 87.0421974522293\n",
            "Epoch #4. Accuracy on batch 1256/3013  on Training is 87.0450477326969\n",
            "Epoch #4. Accuracy on batch 1257/3013  on Training is 87.05037758346582\n",
            "Epoch #4. Accuracy on batch 1258/3013  on Training is 87.05569896743447\n",
            "Epoch #4. Accuracy on batch 1259/3013  on Training is 87.05605158730158\n",
            "Batch Id 1260 is having training loss of 0.44283777475357056\n",
            "0.6461225748062134\n",
            "Epoch #4. Accuracy on batch 1260/3013  on Training is 87.05392545598731\n",
            "Epoch #4. Accuracy on batch 1261/3013  on Training is 87.05427892234549\n",
            "Epoch #4. Accuracy on batch 1262/3013  on Training is 87.0595803642122\n",
            "Epoch #4. Accuracy on batch 1263/3013  on Training is 87.05745648734177\n",
            "Epoch #4. Accuracy on batch 1264/3013  on Training is 87.05533596837945\n",
            "Epoch #4. Accuracy on batch 1265/3013  on Training is 87.05075039494471\n",
            "Epoch #4. Accuracy on batch 1266/3013  on Training is 87.05357142857143\n",
            "Epoch #4. Accuracy on batch 1267/3013  on Training is 87.06131703470031\n",
            "Epoch #4. Accuracy on batch 1268/3013  on Training is 87.05920015760441\n",
            "Epoch #4. Accuracy on batch 1269/3013  on Training is 87.06200787401575\n",
            "Epoch #4. Accuracy on batch 1270/3013  on Training is 87.0623524783635\n",
            "Epoch #4. Accuracy on batch 1271/3013  on Training is 87.06023977987421\n",
            "Epoch #4. Accuracy on batch 1272/3013  on Training is 87.06058523173606\n",
            "Epoch #4. Accuracy on batch 1273/3013  on Training is 87.05847723704866\n",
            "Epoch #4. Accuracy on batch 1274/3013  on Training is 87.06372549019608\n",
            "Epoch #4. Accuracy on batch 1275/3013  on Training is 87.06896551724138\n",
            "Epoch #4. Accuracy on batch 1276/3013  on Training is 87.06930305403289\n",
            "Epoch #4. Accuracy on batch 1277/3013  on Training is 87.07208528951487\n",
            "Epoch #4. Accuracy on batch 1278/3013  on Training is 87.07241985926505\n",
            "Epoch #4. Accuracy on batch 1279/3013  on Training is 87.07275390625\n",
            "Batch Id 1280 is having training loss of 0.4422341585159302\n",
            "0.27691155672073364\n",
            "Epoch #4. Accuracy on batch 1280/3013  on Training is 87.07796643247462\n",
            "Epoch #4. Accuracy on batch 1281/3013  on Training is 87.07829563182527\n",
            "Epoch #4. Accuracy on batch 1282/3013  on Training is 87.07862431800467\n",
            "Epoch #4. Accuracy on batch 1283/3013  on Training is 87.086253894081\n",
            "Epoch #4. Accuracy on batch 1284/3013  on Training is 87.09387159533074\n",
            "Epoch #4. Accuracy on batch 1285/3013  on Training is 87.08932737169518\n",
            "Epoch #4. Accuracy on batch 1286/3013  on Training is 87.08964646464646\n",
            "Epoch #4. Accuracy on batch 1287/3013  on Training is 87.0899650621118\n",
            "Epoch #4. Accuracy on batch 1288/3013  on Training is 87.08301008533748\n",
            "Epoch #4. Accuracy on batch 1289/3013  on Training is 87.08091085271317\n",
            "Epoch #4. Accuracy on batch 1290/3013  on Training is 87.0860766847405\n",
            "Epoch #4. Accuracy on batch 1291/3013  on Training is 87.093653250774\n",
            "Epoch #4. Accuracy on batch 1292/3013  on Training is 87.09638437741685\n",
            "Epoch #4. Accuracy on batch 1293/3013  on Training is 87.09669629057187\n",
            "Epoch #4. Accuracy on batch 1294/3013  on Training is 87.10424710424711\n",
            "Epoch #4. Accuracy on batch 1295/3013  on Training is 87.10214120370371\n",
            "Epoch #4. Accuracy on batch 1296/3013  on Training is 87.09762914417887\n",
            "Epoch #4. Accuracy on batch 1297/3013  on Training is 87.09553158705701\n",
            "Epoch #4. Accuracy on batch 1298/3013  on Training is 87.09824865280986\n",
            "Epoch #4. Accuracy on batch 1299/3013  on Training is 87.10336538461539\n",
            "Batch Id 1300 is having training loss of 0.4414820373058319\n",
            "0.24664051830768585\n",
            "Epoch #4. Accuracy on batch 1300/3013  on Training is 87.10367025365103\n",
            "Epoch #4. Accuracy on batch 1301/3013  on Training is 87.09437403993856\n",
            "Epoch #4. Accuracy on batch 1302/3013  on Training is 87.09468534151956\n",
            "Epoch #4. Accuracy on batch 1303/3013  on Training is 87.09978911042944\n",
            "Epoch #4. Accuracy on batch 1304/3013  on Training is 87.10249042145594\n",
            "Epoch #4. Accuracy on batch 1305/3013  on Training is 87.0980091883614\n",
            "Epoch #4. Accuracy on batch 1306/3013  on Training is 87.09592578423872\n",
            "Epoch #4. Accuracy on batch 1307/3013  on Training is 87.09623470948013\n",
            "Epoch #4. Accuracy on batch 1308/3013  on Training is 87.09654316271963\n",
            "Epoch #4. Accuracy on batch 1309/3013  on Training is 87.10639312977099\n",
            "Epoch #4. Accuracy on batch 1310/3013  on Training is 87.10907704042715\n",
            "Epoch #4. Accuracy on batch 1311/3013  on Training is 87.1069931402439\n",
            "Epoch #4. Accuracy on batch 1312/3013  on Training is 87.10967250571211\n",
            "Epoch #4. Accuracy on batch 1313/3013  on Training is 87.11234779299848\n",
            "Epoch #4. Accuracy on batch 1314/3013  on Training is 87.11501901140684\n",
            "Epoch #4. Accuracy on batch 1315/3013  on Training is 87.11531155015197\n",
            "Epoch #4. Accuracy on batch 1316/3013  on Training is 87.11560364464692\n",
            "Epoch #4. Accuracy on batch 1317/3013  on Training is 87.11589529590289\n",
            "Epoch #4. Accuracy on batch 1318/3013  on Training is 87.11855572403336\n",
            "Epoch #4. Accuracy on batch 1319/3013  on Training is 87.11174242424242\n",
            "Batch Id 1320 is having training loss of 0.4406140148639679\n",
            "0.2712114751338959\n",
            "Epoch #4. Accuracy on batch 1320/3013  on Training is 87.11676760030281\n",
            "Epoch #4. Accuracy on batch 1321/3013  on Training is 87.12178517397882\n",
            "Epoch #4. Accuracy on batch 1322/3013  on Training is 87.11498488284202\n",
            "Epoch #4. Accuracy on batch 1323/3013  on Training is 87.11763595166163\n",
            "Epoch #4. Accuracy on batch 1324/3013  on Training is 87.11556603773585\n",
            "Epoch #4. Accuracy on batch 1325/3013  on Training is 87.1205693815988\n",
            "Epoch #4. Accuracy on batch 1326/3013  on Training is 87.12321024868123\n",
            "Epoch #4. Accuracy on batch 1327/3013  on Training is 87.13290662650603\n",
            "Epoch #4. Accuracy on batch 1328/3013  on Training is 87.13083145221971\n",
            "Epoch #4. Accuracy on batch 1329/3013  on Training is 87.13110902255639\n",
            "Epoch #4. Accuracy on batch 1330/3013  on Training is 87.12669045830202\n",
            "Epoch #4. Accuracy on batch 1331/3013  on Training is 87.134009009009\n",
            "Epoch #4. Accuracy on batch 1332/3013  on Training is 87.12959489872468\n",
            "Epoch #4. Accuracy on batch 1333/3013  on Training is 87.13221514242879\n",
            "Epoch #4. Accuracy on batch 1334/3013  on Training is 87.13014981273409\n",
            "Epoch #4. Accuracy on batch 1335/3013  on Training is 87.1280875748503\n",
            "Epoch #4. Accuracy on batch 1336/3013  on Training is 87.12369109947645\n",
            "Epoch #4. Accuracy on batch 1337/3013  on Training is 87.12397234678625\n",
            "Epoch #4. Accuracy on batch 1338/3013  on Training is 87.1289208364451\n",
            "Epoch #4. Accuracy on batch 1339/3013  on Training is 87.12453358208955\n",
            "Batch Id 1340 is having training loss of 0.4410846531391144\n",
            "0.3926312029361725\n",
            "Epoch #4. Accuracy on batch 1340/3013  on Training is 87.12248322147651\n",
            "Epoch #4. Accuracy on batch 1341/3013  on Training is 87.11345007451565\n",
            "Epoch #4. Accuracy on batch 1342/3013  on Training is 87.11373790022338\n",
            "Epoch #4. Accuracy on batch 1343/3013  on Training is 87.1186755952381\n",
            "Epoch #4. Accuracy on batch 1344/3013  on Training is 87.114312267658\n",
            "Epoch #4. Accuracy on batch 1345/3013  on Training is 87.1169205052006\n",
            "Epoch #4. Accuracy on batch 1346/3013  on Training is 87.11488492947291\n",
            "Epoch #4. Accuracy on batch 1347/3013  on Training is 87.11748887240356\n",
            "Epoch #4. Accuracy on batch 1348/3013  on Training is 87.12008895478132\n",
            "Epoch #4. Accuracy on batch 1349/3013  on Training is 87.12268518518519\n",
            "Epoch #4. Accuracy on batch 1350/3013  on Training is 87.12527757216877\n",
            "Epoch #4. Accuracy on batch 1351/3013  on Training is 87.12324334319527\n",
            "Epoch #4. Accuracy on batch 1352/3013  on Training is 87.11659275683665\n",
            "Epoch #4. Accuracy on batch 1353/3013  on Training is 87.11687592319055\n",
            "Epoch #4. Accuracy on batch 1354/3013  on Training is 87.11715867158672\n",
            "Epoch #4. Accuracy on batch 1355/3013  on Training is 87.11974557522124\n",
            "Epoch #4. Accuracy on batch 1356/3013  on Training is 87.12232866617539\n",
            "Epoch #4. Accuracy on batch 1357/3013  on Training is 87.1157032400589\n",
            "Epoch #4. Accuracy on batch 1358/3013  on Training is 87.10908756438558\n",
            "Epoch #4. Accuracy on batch 1359/3013  on Training is 87.10477941176471\n",
            "Batch Id 1360 is having training loss of 0.44131946563720703\n",
            "0.2180822789669037\n",
            "Epoch #4. Accuracy on batch 1360/3013  on Training is 87.10736590742101\n",
            "Epoch #4. Accuracy on batch 1361/3013  on Training is 87.11453744493392\n",
            "Epoch #4. Accuracy on batch 1362/3013  on Training is 87.1102347762289\n",
            "Epoch #4. Accuracy on batch 1363/3013  on Training is 87.10364736070382\n",
            "Epoch #4. Accuracy on batch 1364/3013  on Training is 87.09706959706959\n",
            "Epoch #4. Accuracy on batch 1365/3013  on Training is 87.09507686676427\n",
            "Epoch #4. Accuracy on batch 1366/3013  on Training is 87.09308705193855\n",
            "Epoch #4. Accuracy on batch 1367/3013  on Training is 87.09110014619883\n",
            "Epoch #4. Accuracy on batch 1368/3013  on Training is 87.0891161431702\n",
            "Epoch #4. Accuracy on batch 1369/3013  on Training is 87.08941605839416\n",
            "Epoch #4. Accuracy on batch 1370/3013  on Training is 87.09883296863603\n",
            "Epoch #4. Accuracy on batch 1371/3013  on Training is 87.10368075801749\n",
            "Epoch #4. Accuracy on batch 1372/3013  on Training is 87.1016933721777\n",
            "Epoch #4. Accuracy on batch 1373/3013  on Training is 87.10653202328966\n",
            "Epoch #4. Accuracy on batch 1374/3013  on Training is 87.1\n",
            "Epoch #4. Accuracy on batch 1375/3013  on Training is 87.10710392441861\n",
            "Epoch #4. Accuracy on batch 1376/3013  on Training is 87.10738925199709\n",
            "Epoch #4. Accuracy on batch 1377/3013  on Training is 87.10540638606676\n",
            "Epoch #4. Accuracy on batch 1378/3013  on Training is 87.10795866569978\n",
            "Epoch #4. Accuracy on batch 1379/3013  on Training is 87.10824275362319\n",
            "Batch Id 1380 is having training loss of 0.4416649341583252\n",
            "0.397853821516037\n",
            "Epoch #4. Accuracy on batch 1380/3013  on Training is 87.11078928312817\n",
            "Epoch #4. Accuracy on batch 1381/3013  on Training is 87.11107091172214\n",
            "Epoch #4. Accuracy on batch 1382/3013  on Training is 87.11361171366595\n",
            "Epoch #4. Accuracy on batch 1383/3013  on Training is 87.109375\n",
            "Epoch #4. Accuracy on batch 1384/3013  on Training is 87.11416967509025\n",
            "Epoch #4. Accuracy on batch 1385/3013  on Training is 87.11219336219337\n",
            "Epoch #4. Accuracy on batch 1386/3013  on Training is 87.11697909156453\n",
            "Epoch #4. Accuracy on batch 1387/3013  on Training is 87.11725504322767\n",
            "Epoch #4. Accuracy on batch 1388/3013  on Training is 87.11978041756659\n",
            "Epoch #4. Accuracy on batch 1389/3013  on Training is 87.12455035971223\n",
            "Epoch #4. Accuracy on batch 1390/3013  on Training is 87.12257368799425\n",
            "Epoch #4. Accuracy on batch 1391/3013  on Training is 87.12733477011494\n",
            "Epoch #4. Accuracy on batch 1392/3013  on Training is 87.1186288585786\n",
            "Epoch #4. Accuracy on batch 1393/3013  on Training is 87.12114418938307\n",
            "Epoch #4. Accuracy on batch 1394/3013  on Training is 87.11021505376344\n",
            "Epoch #4. Accuracy on batch 1395/3013  on Training is 87.11049426934098\n",
            "Epoch #4. Accuracy on batch 1396/3013  on Training is 87.11524695776664\n",
            "Epoch #4. Accuracy on batch 1397/3013  on Training is 87.11552217453504\n",
            "Epoch #4. Accuracy on batch 1398/3013  on Training is 87.11579699785561\n",
            "Epoch #4. Accuracy on batch 1399/3013  on Training is 87.11607142857143\n",
            "Batch Id 1400 is having training loss of 0.441245973110199\n",
            "0.3811195492744446\n",
            "Epoch #4. Accuracy on batch 1400/3013  on Training is 87.1163454675232\n",
            "Epoch #4. Accuracy on batch 1401/3013  on Training is 87.11439015691869\n",
            "Epoch #4. Accuracy on batch 1402/3013  on Training is 87.11911974340698\n",
            "Epoch #4. Accuracy on batch 1403/3013  on Training is 87.12161680911682\n",
            "Epoch #4. Accuracy on batch 1404/3013  on Training is 87.12188612099644\n",
            "Epoch #4. Accuracy on batch 1405/3013  on Training is 87.11548719772404\n",
            "Epoch #4. Accuracy on batch 1406/3013  on Training is 87.1179815209666\n",
            "Epoch #4. Accuracy on batch 1407/3013  on Training is 87.12047230113636\n",
            "Epoch #4. Accuracy on batch 1408/3013  on Training is 87.12295954577715\n",
            "Epoch #4. Accuracy on batch 1409/3013  on Training is 87.12101063829788\n",
            "Epoch #4. Accuracy on batch 1410/3013  on Training is 87.12349397590361\n",
            "Epoch #4. Accuracy on batch 1411/3013  on Training is 87.12597379603399\n",
            "Epoch #4. Accuracy on batch 1412/3013  on Training is 87.12845010615712\n",
            "Epoch #4. Accuracy on batch 1413/3013  on Training is 87.12871287128714\n",
            "Epoch #4. Accuracy on batch 1414/3013  on Training is 87.13339222614842\n",
            "Epoch #4. Accuracy on batch 1415/3013  on Training is 87.13144420903954\n",
            "Epoch #4. Accuracy on batch 1416/3013  on Training is 87.13611503175723\n",
            "Epoch #4. Accuracy on batch 1417/3013  on Training is 87.1319640338505\n",
            "Epoch #4. Accuracy on batch 1418/3013  on Training is 87.13662790697674\n",
            "Epoch #4. Accuracy on batch 1419/3013  on Training is 87.13248239436619\n",
            "Batch Id 1420 is having training loss of 0.44080308079719543\n",
            "0.2915569841861725\n",
            "Epoch #4. Accuracy on batch 1420/3013  on Training is 87.13494018296974\n",
            "Epoch #4. Accuracy on batch 1421/3013  on Training is 87.12860407876231\n",
            "Epoch #4. Accuracy on batch 1422/3013  on Training is 87.13325720309206\n",
            "Epoch #4. Accuracy on batch 1423/3013  on Training is 87.12693117977528\n",
            "Epoch #4. Accuracy on batch 1424/3013  on Training is 87.125\n",
            "Epoch #4. Accuracy on batch 1425/3013  on Training is 87.12307152875175\n",
            "Epoch #4. Accuracy on batch 1426/3013  on Training is 87.12552557813595\n",
            "Epoch #4. Accuracy on batch 1427/3013  on Training is 87.13016456582633\n",
            "Epoch #4. Accuracy on batch 1428/3013  on Training is 87.13261021693492\n",
            "Epoch #4. Accuracy on batch 1429/3013  on Training is 87.1284965034965\n",
            "Epoch #4. Accuracy on batch 1430/3013  on Training is 87.12438853948288\n",
            "Epoch #4. Accuracy on batch 1431/3013  on Training is 87.13119762569832\n",
            "Epoch #4. Accuracy on batch 1432/3013  on Training is 87.13363572923936\n",
            "Epoch #4. Accuracy on batch 1433/3013  on Training is 87.12953277545327\n",
            "Epoch #4. Accuracy on batch 1434/3013  on Training is 87.13414634146342\n",
            "Epoch #4. Accuracy on batch 1435/3013  on Training is 87.13222493036211\n",
            "Epoch #4. Accuracy on batch 1436/3013  on Training is 87.1303061934586\n",
            "Epoch #4. Accuracy on batch 1437/3013  on Training is 87.12621696801112\n",
            "Epoch #4. Accuracy on batch 1438/3013  on Training is 87.12430507296733\n",
            "Epoch #4. Accuracy on batch 1439/3013  on Training is 87.12456597222223\n",
            "Batch Id 1440 is having training loss of 0.441177099943161\n",
            "0.8188365697860718\n",
            "Epoch #4. Accuracy on batch 1440/3013  on Training is 87.1161519777932\n",
            "Epoch #4. Accuracy on batch 1441/3013  on Training is 87.11425104022192\n",
            "Epoch #4. Accuracy on batch 1442/3013  on Training is 87.11668399168398\n",
            "Epoch #4. Accuracy on batch 1443/3013  on Training is 87.12127770083103\n",
            "Epoch #4. Accuracy on batch 1444/3013  on Training is 87.12370242214533\n",
            "Epoch #4. Accuracy on batch 1445/3013  on Training is 87.12396265560166\n",
            "Epoch #4. Accuracy on batch 1446/3013  on Training is 87.12422252937111\n",
            "Epoch #4. Accuracy on batch 1447/3013  on Training is 87.12879834254143\n",
            "Epoch #4. Accuracy on batch 1448/3013  on Training is 87.12042788129745\n",
            "Epoch #4. Accuracy on batch 1449/3013  on Training is 87.11853448275862\n",
            "Epoch #4. Accuracy on batch 1450/3013  on Training is 87.12310475534115\n",
            "Epoch #4. Accuracy on batch 1451/3013  on Training is 87.11475550964187\n",
            "Epoch #4. Accuracy on batch 1452/3013  on Training is 87.11071920165176\n",
            "Epoch #4. Accuracy on batch 1453/3013  on Training is 87.10453920220083\n",
            "Epoch #4. Accuracy on batch 1454/3013  on Training is 87.10910652920963\n",
            "Epoch #4. Accuracy on batch 1455/3013  on Training is 87.10293612637362\n",
            "Epoch #4. Accuracy on batch 1456/3013  on Training is 87.10535346602609\n",
            "Epoch #4. Accuracy on batch 1457/3013  on Training is 87.09919410150891\n",
            "Epoch #4. Accuracy on batch 1458/3013  on Training is 87.10803632625085\n",
            "Epoch #4. Accuracy on batch 1459/3013  on Training is 87.10402397260275\n",
            "Batch Id 1460 is having training loss of 0.4416294991970062\n",
            "0.44418299198150635\n",
            "Epoch #4. Accuracy on batch 1460/3013  on Training is 87.10001711156742\n",
            "Epoch #4. Accuracy on batch 1461/3013  on Training is 87.09815321477429\n",
            "Epoch #4. Accuracy on batch 1462/3013  on Training is 87.09842788790158\n",
            "Epoch #4. Accuracy on batch 1463/3013  on Training is 87.0944330601093\n",
            "Epoch #4. Accuracy on batch 1464/3013  on Training is 87.09684300341297\n",
            "Epoch #4. Accuracy on batch 1465/3013  on Training is 87.0949863574352\n",
            "Epoch #4. Accuracy on batch 1466/3013  on Training is 87.09526244035446\n",
            "Epoch #4. Accuracy on batch 1467/3013  on Training is 87.09128065395096\n",
            "Epoch #4. Accuracy on batch 1468/3013  on Training is 87.09368618107557\n",
            "Epoch #4. Accuracy on batch 1469/3013  on Training is 87.09821428571429\n",
            "Epoch #4. Accuracy on batch 1470/3013  on Training is 87.09636301835486\n",
            "Epoch #4. Accuracy on batch 1471/3013  on Training is 87.09239130434783\n",
            "Epoch #4. Accuracy on batch 1472/3013  on Training is 87.09266802443992\n",
            "Epoch #4. Accuracy on batch 1473/3013  on Training is 87.0950644504749\n",
            "Epoch #4. Accuracy on batch 1474/3013  on Training is 87.09322033898304\n",
            "Epoch #4. Accuracy on batch 1475/3013  on Training is 87.08926151761517\n",
            "Epoch #4. Accuracy on batch 1476/3013  on Training is 87.0937711577522\n",
            "Epoch #4. Accuracy on batch 1477/3013  on Training is 87.08770297699594\n",
            "Epoch #4. Accuracy on batch 1478/3013  on Training is 87.08375591615956\n",
            "Epoch #4. Accuracy on batch 1479/3013  on Training is 87.08192567567568\n",
            "Batch Id 1480 is having training loss of 0.4421842396259308\n",
            "0.45096978545188904\n",
            "Epoch #4. Accuracy on batch 1480/3013  on Training is 87.08009790681972\n",
            "Epoch #4. Accuracy on batch 1481/3013  on Training is 87.08459851551957\n",
            "Epoch #4. Accuracy on batch 1482/3013  on Training is 87.08277140930547\n",
            "Epoch #4. Accuracy on batch 1483/3013  on Training is 87.08515835579514\n",
            "Epoch #4. Accuracy on batch 1484/3013  on Training is 87.08333333333333\n",
            "Epoch #4. Accuracy on batch 1485/3013  on Training is 87.08361372812921\n",
            "Epoch #4. Accuracy on batch 1486/3013  on Training is 87.07969065232011\n",
            "Epoch #4. Accuracy on batch 1487/3013  on Training is 87.08207325268818\n",
            "Epoch #4. Accuracy on batch 1488/3013  on Training is 87.07815648085963\n",
            "Epoch #4. Accuracy on batch 1489/3013  on Training is 87.08053691275168\n",
            "Epoch #4. Accuracy on batch 1490/3013  on Training is 87.08081824279007\n",
            "Epoch #4. Accuracy on batch 1491/3013  on Training is 87.07691018766756\n",
            "Epoch #4. Accuracy on batch 1492/3013  on Training is 87.0771935699933\n",
            "Epoch #4. Accuracy on batch 1493/3013  on Training is 87.07956827309236\n",
            "Epoch #4. Accuracy on batch 1494/3013  on Training is 87.07775919732441\n",
            "Epoch #4. Accuracy on batch 1495/3013  on Training is 87.07595254010695\n",
            "Epoch #4. Accuracy on batch 1496/3013  on Training is 87.07623580494322\n",
            "Epoch #4. Accuracy on batch 1497/3013  on Training is 87.07443257676903\n",
            "Epoch #4. Accuracy on batch 1498/3013  on Training is 87.07680120080053\n",
            "Epoch #4. Accuracy on batch 1499/3013  on Training is 87.07916666666667\n",
            "Batch Id 1500 is having training loss of 0.4428228437900543\n",
            "0.7839342951774597\n",
            "Epoch #4. Accuracy on batch 1500/3013  on Training is 87.07111925383077\n",
            "Epoch #4. Accuracy on batch 1501/3013  on Training is 87.0693242343542\n",
            "Epoch #4. Accuracy on batch 1502/3013  on Training is 87.06129407850965\n",
            "Epoch #4. Accuracy on batch 1503/3013  on Training is 87.0595079787234\n",
            "Epoch #4. Accuracy on batch 1504/3013  on Training is 87.05564784053156\n",
            "Epoch #4. Accuracy on batch 1505/3013  on Training is 87.05179282868527\n",
            "Epoch #4. Accuracy on batch 1506/3013  on Training is 87.0520902455209\n",
            "Epoch #4. Accuracy on batch 1507/3013  on Training is 87.05445954907162\n",
            "Epoch #4. Accuracy on batch 1508/3013  on Training is 87.0547548045063\n",
            "Epoch #4. Accuracy on batch 1509/3013  on Training is 87.05711920529801\n",
            "Epoch #4. Accuracy on batch 1510/3013  on Training is 87.06361681005956\n",
            "Epoch #4. Accuracy on batch 1511/3013  on Training is 87.06183862433862\n",
            "Epoch #4. Accuracy on batch 1512/3013  on Training is 87.0703899537343\n",
            "Epoch #4. Accuracy on batch 1513/3013  on Training is 87.06860964332893\n",
            "Epoch #4. Accuracy on batch 1514/3013  on Training is 87.0647689768977\n",
            "Epoch #4. Accuracy on batch 1515/3013  on Training is 87.05887203166228\n",
            "Epoch #4. Accuracy on batch 1516/3013  on Training is 87.06122280817402\n",
            "Epoch #4. Accuracy on batch 1517/3013  on Training is 87.05945322793148\n",
            "Epoch #4. Accuracy on batch 1518/3013  on Training is 87.05974325213957\n",
            "Epoch #4. Accuracy on batch 1519/3013  on Training is 87.06003289473684\n",
            "Batch Id 1520 is having training loss of 0.44287994503974915\n",
            "0.43698638677597046\n",
            "Epoch #4. Accuracy on batch 1520/3013  on Training is 87.060322156476\n",
            "Epoch #4. Accuracy on batch 1521/3013  on Training is 87.06061103810775\n",
            "Epoch #4. Accuracy on batch 1522/3013  on Training is 87.0526920551543\n",
            "Epoch #4. Accuracy on batch 1523/3013  on Training is 87.05503608923884\n",
            "Epoch #4. Accuracy on batch 1524/3013  on Training is 87.05532786885246\n",
            "Epoch #4. Accuracy on batch 1525/3013  on Training is 87.05357142857143\n",
            "Epoch #4. Accuracy on batch 1526/3013  on Training is 87.05181728880157\n",
            "Epoch #4. Accuracy on batch 1527/3013  on Training is 87.0541557591623\n",
            "Epoch #4. Accuracy on batch 1528/3013  on Training is 87.05035971223022\n",
            "Epoch #4. Accuracy on batch 1529/3013  on Training is 87.05065359477125\n",
            "Epoch #4. Accuracy on batch 1530/3013  on Training is 87.04482364467668\n",
            "Epoch #4. Accuracy on batch 1531/3013  on Training is 87.04512075718016\n",
            "Epoch #4. Accuracy on batch 1532/3013  on Training is 87.04541748206132\n",
            "Epoch #4. Accuracy on batch 1533/3013  on Training is 87.04367666232073\n",
            "Epoch #4. Accuracy on batch 1534/3013  on Training is 87.03990228013029\n",
            "Epoch #4. Accuracy on batch 1535/3013  on Training is 87.04020182291667\n",
            "Epoch #4. Accuracy on batch 1536/3013  on Training is 87.04660052049447\n",
            "Epoch #4. Accuracy on batch 1537/3013  on Training is 87.03673602080625\n",
            "Epoch #4. Accuracy on batch 1538/3013  on Training is 87.04109811565952\n",
            "Epoch #4. Accuracy on batch 1539/3013  on Training is 87.0413961038961\n",
            "Batch Id 1540 is having training loss of 0.4430985748767853\n",
            "0.5846851468086243\n",
            "Epoch #4. Accuracy on batch 1540/3013  on Training is 87.03763789746918\n",
            "Epoch #4. Accuracy on batch 1541/3013  on Training is 87.035911154345\n",
            "Epoch #4. Accuracy on batch 1542/3013  on Training is 87.0301360985094\n",
            "Epoch #4. Accuracy on batch 1543/3013  on Training is 87.03651230569949\n",
            "Epoch #4. Accuracy on batch 1544/3013  on Training is 87.03478964401295\n",
            "Epoch #4. Accuracy on batch 1545/3013  on Training is 87.03104786545924\n",
            "Epoch #4. Accuracy on batch 1546/3013  on Training is 87.03741111829348\n",
            "Epoch #4. Accuracy on batch 1547/3013  on Training is 87.0437661498708\n",
            "Epoch #4. Accuracy on batch 1548/3013  on Training is 87.04809554551323\n",
            "Epoch #4. Accuracy on batch 1549/3013  on Training is 87.04637096774194\n",
            "Epoch #4. Accuracy on batch 1550/3013  on Training is 87.04666344294004\n",
            "Epoch #4. Accuracy on batch 1551/3013  on Training is 87.04896907216495\n",
            "Epoch #4. Accuracy on batch 1552/3013  on Training is 87.05328396651642\n",
            "Epoch #4. Accuracy on batch 1553/3013  on Training is 87.04753861003861\n",
            "Epoch #4. Accuracy on batch 1554/3013  on Training is 87.04983922829582\n",
            "Epoch #4. Accuracy on batch 1555/3013  on Training is 87.04410347043702\n",
            "Epoch #4. Accuracy on batch 1556/3013  on Training is 87.04038214515093\n",
            "Epoch #4. Accuracy on batch 1557/3013  on Training is 87.04067715019255\n",
            "Epoch #4. Accuracy on batch 1558/3013  on Training is 87.04698524695317\n",
            "Epoch #4. Accuracy on batch 1559/3013  on Training is 87.05328525641026\n",
            "Batch Id 1560 is having training loss of 0.44293737411499023\n",
            "0.32128846645355225\n",
            "Epoch #4. Accuracy on batch 1560/3013  on Training is 87.0555733504164\n",
            "Epoch #4. Accuracy on batch 1561/3013  on Training is 87.05785851472471\n",
            "Epoch #4. Accuracy on batch 1562/3013  on Training is 87.05814139475368\n",
            "Epoch #4. Accuracy on batch 1563/3013  on Training is 87.06242007672634\n",
            "Epoch #4. Accuracy on batch 1564/3013  on Training is 87.05670926517571\n",
            "Epoch #4. Accuracy on batch 1565/3013  on Training is 87.0609833971903\n",
            "Epoch #4. Accuracy on batch 1566/3013  on Training is 87.06126356094448\n",
            "Epoch #4. Accuracy on batch 1567/3013  on Training is 87.0655293367347\n",
            "Epoch #4. Accuracy on batch 1568/3013  on Training is 87.06779796048438\n",
            "Epoch #4. Accuracy on batch 1569/3013  on Training is 87.06608280254777\n",
            "Epoch #4. Accuracy on batch 1570/3013  on Training is 87.07033736473583\n",
            "Epoch #4. Accuracy on batch 1571/3013  on Training is 87.07458651399492\n",
            "Epoch #4. Accuracy on batch 1572/3013  on Training is 87.0748569612206\n",
            "Epoch #4. Accuracy on batch 1573/3013  on Training is 87.0731416772554\n",
            "Epoch #4. Accuracy on batch 1574/3013  on Training is 87.0813492063492\n",
            "Epoch #4. Accuracy on batch 1575/3013  on Training is 87.07764911167513\n",
            "Epoch #4. Accuracy on batch 1576/3013  on Training is 87.07593532022828\n",
            "Epoch #4. Accuracy on batch 1577/3013  on Training is 87.08214512040557\n",
            "Epoch #4. Accuracy on batch 1578/3013  on Training is 87.08636795440152\n",
            "Epoch #4. Accuracy on batch 1579/3013  on Training is 87.09058544303798\n",
            "Batch Id 1580 is having training loss of 0.4424467980861664\n",
            "0.7085302472114563\n",
            "Epoch #4. Accuracy on batch 1580/3013  on Training is 87.0888678051866\n",
            "Epoch #4. Accuracy on batch 1581/3013  on Training is 87.08715233881163\n",
            "Epoch #4. Accuracy on batch 1582/3013  on Training is 87.08741313960834\n",
            "Epoch #4. Accuracy on batch 1583/3013  on Training is 87.08964646464646\n",
            "Epoch #4. Accuracy on batch 1584/3013  on Training is 87.09187697160883\n",
            "Epoch #4. Accuracy on batch 1585/3013  on Training is 87.09016393442623\n",
            "Epoch #4. Accuracy on batch 1586/3013  on Training is 87.08845305608065\n",
            "Epoch #4. Accuracy on batch 1587/3013  on Training is 87.08280856423174\n",
            "Epoch #4. Accuracy on batch 1588/3013  on Training is 87.08700440528635\n",
            "Epoch #4. Accuracy on batch 1589/3013  on Training is 87.09119496855345\n",
            "Epoch #4. Accuracy on batch 1590/3013  on Training is 87.09145191703331\n",
            "Epoch #4. Accuracy on batch 1591/3013  on Training is 87.08778266331659\n",
            "Epoch #4. Accuracy on batch 1592/3013  on Training is 87.08804143126177\n",
            "Epoch #4. Accuracy on batch 1593/3013  on Training is 87.08829987452948\n",
            "Epoch #4. Accuracy on batch 1594/3013  on Training is 87.0885579937304\n",
            "Epoch #4. Accuracy on batch 1595/3013  on Training is 87.07902568922306\n",
            "Epoch #4. Accuracy on batch 1596/3013  on Training is 87.08515967438949\n",
            "Epoch #4. Accuracy on batch 1597/3013  on Training is 87.08150813516896\n",
            "Epoch #4. Accuracy on batch 1598/3013  on Training is 87.0817698561601\n",
            "Epoch #4. Accuracy on batch 1599/3013  on Training is 87.083984375\n",
            "Batch Id 1600 is having training loss of 0.44270896911621094\n",
            "0.5881142020225525\n",
            "Epoch #4. Accuracy on batch 1600/3013  on Training is 87.08034041224235\n",
            "Epoch #4. Accuracy on batch 1601/3013  on Training is 87.08060237203496\n",
            "Epoch #4. Accuracy on batch 1602/3013  on Training is 87.0847629444791\n",
            "Epoch #4. Accuracy on batch 1603/3013  on Training is 87.08697007481297\n",
            "Epoch #4. Accuracy on batch 1604/3013  on Training is 87.08138629283489\n",
            "Epoch #4. Accuracy on batch 1605/3013  on Training is 87.08553860523038\n",
            "Epoch #4. Accuracy on batch 1606/3013  on Training is 87.0857965152458\n",
            "Epoch #4. Accuracy on batch 1607/3013  on Training is 87.08799751243781\n",
            "Epoch #4. Accuracy on batch 1608/3013  on Training is 87.08436917339962\n",
            "Epoch #4. Accuracy on batch 1609/3013  on Training is 87.08462732919254\n",
            "Epoch #4. Accuracy on batch 1610/3013  on Training is 87.0848851644941\n",
            "Epoch #4. Accuracy on batch 1611/3013  on Training is 87.09095843672456\n",
            "Epoch #4. Accuracy on batch 1612/3013  on Training is 87.08539987600744\n",
            "Epoch #4. Accuracy on batch 1613/3013  on Training is 87.08565675340768\n",
            "Epoch #4. Accuracy on batch 1614/3013  on Training is 87.08204334365325\n",
            "Epoch #4. Accuracy on batch 1615/3013  on Training is 87.08423576732673\n",
            "Epoch #4. Accuracy on batch 1616/3013  on Training is 87.08835807050093\n",
            "Epoch #4. Accuracy on batch 1617/3013  on Training is 87.08861248454883\n",
            "Epoch #4. Accuracy on batch 1618/3013  on Training is 87.09272699197035\n",
            "Epoch #4. Accuracy on batch 1619/3013  on Training is 87.08912037037037\n",
            "Batch Id 1620 is having training loss of 0.44229915738105774\n",
            "0.28339794278144836\n",
            "Epoch #4. Accuracy on batch 1620/3013  on Training is 87.09322948797039\n",
            "Epoch #4. Accuracy on batch 1621/3013  on Training is 87.09926017262639\n",
            "Epoch #4. Accuracy on batch 1622/3013  on Training is 87.09950708564386\n",
            "Epoch #4. Accuracy on batch 1623/3013  on Training is 87.0959051724138\n",
            "Epoch #4. Accuracy on batch 1624/3013  on Training is 87.09038461538462\n",
            "Epoch #4. Accuracy on batch 1625/3013  on Training is 87.09640221402213\n",
            "Epoch #4. Accuracy on batch 1626/3013  on Training is 87.08896742470804\n",
            "Epoch #4. Accuracy on batch 1627/3013  on Training is 87.08538083538083\n",
            "Epoch #4. Accuracy on batch 1628/3013  on Training is 87.0798802946593\n",
            "Epoch #4. Accuracy on batch 1629/3013  on Training is 87.0763036809816\n",
            "Epoch #4. Accuracy on batch 1630/3013  on Training is 87.0784794604537\n",
            "Epoch #4. Accuracy on batch 1631/3013  on Training is 87.07873774509804\n",
            "Epoch #4. Accuracy on batch 1632/3013  on Training is 87.08282302510716\n",
            "Epoch #4. Accuracy on batch 1633/3013  on Training is 87.08307833537332\n",
            "Epoch #4. Accuracy on batch 1634/3013  on Training is 87.08142201834862\n",
            "Epoch #4. Accuracy on batch 1635/3013  on Training is 87.0835880195599\n",
            "Epoch #4. Accuracy on batch 1636/3013  on Training is 87.0781154551008\n",
            "Epoch #4. Accuracy on batch 1637/3013  on Training is 87.07264957264957\n",
            "Epoch #4. Accuracy on batch 1638/3013  on Training is 87.07481696156192\n",
            "Epoch #4. Accuracy on batch 1639/3013  on Training is 87.07698170731707\n",
            "Batch Id 1640 is having training loss of 0.4423156976699829\n",
            "0.38293060660362244\n",
            "Epoch #4. Accuracy on batch 1640/3013  on Training is 87.0753351614869\n",
            "Epoch #4. Accuracy on batch 1641/3013  on Training is 87.07369062119366\n",
            "Epoch #4. Accuracy on batch 1642/3013  on Training is 87.07585209981741\n",
            "Epoch #4. Accuracy on batch 1643/3013  on Training is 87.07230839416059\n",
            "Epoch #4. Accuracy on batch 1644/3013  on Training is 87.07256838905775\n",
            "Epoch #4. Accuracy on batch 1645/3013  on Training is 87.07852369380316\n",
            "Epoch #4. Accuracy on batch 1646/3013  on Training is 87.07688221007894\n",
            "Epoch #4. Accuracy on batch 1647/3013  on Training is 87.07713895631068\n",
            "Epoch #4. Accuracy on batch 1648/3013  on Training is 87.07360521528199\n",
            "Epoch #4. Accuracy on batch 1649/3013  on Training is 87.07575757575758\n",
            "Epoch #4. Accuracy on batch 1650/3013  on Training is 87.07033615990309\n",
            "Epoch #4. Accuracy on batch 1651/3013  on Training is 87.07248789346247\n",
            "Epoch #4. Accuracy on batch 1652/3013  on Training is 87.07463702359347\n",
            "Epoch #4. Accuracy on batch 1653/3013  on Training is 87.07678355501814\n",
            "Epoch #4. Accuracy on batch 1654/3013  on Training is 87.08081570996978\n",
            "Epoch #4. Accuracy on batch 1655/3013  on Training is 87.0810688405797\n",
            "Epoch #4. Accuracy on batch 1656/3013  on Training is 87.08132166566084\n",
            "Epoch #4. Accuracy on batch 1657/3013  on Training is 87.08534378769602\n",
            "Epoch #4. Accuracy on batch 1658/3013  on Training is 87.08182640144665\n",
            "Epoch #4. Accuracy on batch 1659/3013  on Training is 87.08396084337349\n",
            "Batch Id 1660 is having training loss of 0.4421798586845398\n",
            "1.0652474164962769\n",
            "Epoch #4. Accuracy on batch 1660/3013  on Training is 87.06916014449126\n",
            "Epoch #4. Accuracy on batch 1661/3013  on Training is 87.07129963898917\n",
            "Epoch #4. Accuracy on batch 1662/3013  on Training is 87.06967829224294\n",
            "Epoch #4. Accuracy on batch 1663/3013  on Training is 87.06805889423077\n",
            "Epoch #4. Accuracy on batch 1664/3013  on Training is 87.06644144144144\n",
            "Epoch #4. Accuracy on batch 1665/3013  on Training is 87.06670168067227\n",
            "Epoch #4. Accuracy on batch 1666/3013  on Training is 87.0632123575285\n",
            "Epoch #4. Accuracy on batch 1667/3013  on Training is 87.05972721822542\n",
            "Epoch #4. Accuracy on batch 1668/3013  on Training is 87.05624625524266\n",
            "Epoch #4. Accuracy on batch 1669/3013  on Training is 87.062125748503\n",
            "Epoch #4. Accuracy on batch 1670/3013  on Training is 87.06051765409934\n",
            "Epoch #4. Accuracy on batch 1671/3013  on Training is 87.05704246411483\n",
            "Epoch #4. Accuracy on batch 1672/3013  on Training is 87.05170352659893\n",
            "Epoch #4. Accuracy on batch 1673/3013  on Training is 87.05383811230585\n",
            "Epoch #4. Accuracy on batch 1674/3013  on Training is 87.04664179104478\n",
            "Epoch #4. Accuracy on batch 1675/3013  on Training is 87.04691229116945\n",
            "Epoch #4. Accuracy on batch 1676/3013  on Training is 87.04531902206321\n",
            "Epoch #4. Accuracy on batch 1677/3013  on Training is 87.03814064362336\n",
            "Epoch #4. Accuracy on batch 1678/3013  on Training is 87.04213817748659\n",
            "Epoch #4. Accuracy on batch 1679/3013  on Training is 87.04613095238095\n",
            "Batch Id 1680 is having training loss of 0.44260314106941223\n",
            "0.4227175712585449\n",
            "Epoch #4. Accuracy on batch 1680/3013  on Training is 87.04640095181439\n",
            "Epoch #4. Accuracy on batch 1681/3013  on Training is 87.0429548156956\n",
            "Epoch #4. Accuracy on batch 1682/3013  on Training is 87.04136957813428\n",
            "Epoch #4. Accuracy on batch 1683/3013  on Training is 87.03793052256532\n",
            "Epoch #4. Accuracy on batch 1684/3013  on Training is 87.03635014836796\n",
            "Epoch #4. Accuracy on batch 1685/3013  on Training is 87.0329181494662\n",
            "Epoch #4. Accuracy on batch 1686/3013  on Training is 87.03319502074689\n",
            "Epoch #4. Accuracy on batch 1687/3013  on Training is 87.03347156398104\n",
            "Epoch #4. Accuracy on batch 1688/3013  on Training is 87.03559798697454\n",
            "Epoch #4. Accuracy on batch 1689/3013  on Training is 87.03957100591715\n",
            "Epoch #4. Accuracy on batch 1690/3013  on Training is 87.03799526907156\n",
            "Epoch #4. Accuracy on batch 1691/3013  on Training is 87.03272754137116\n",
            "Epoch #4. Accuracy on batch 1692/3013  on Training is 87.03115770821027\n",
            "Epoch #4. Accuracy on batch 1693/3013  on Training is 87.02958972845336\n",
            "Epoch #4. Accuracy on batch 1694/3013  on Training is 87.02802359882006\n",
            "Epoch #4. Accuracy on batch 1695/3013  on Training is 87.02645931603773\n",
            "Epoch #4. Accuracy on batch 1696/3013  on Training is 87.03042133176193\n",
            "Epoch #4. Accuracy on batch 1697/3013  on Training is 87.02701707891637\n",
            "Epoch #4. Accuracy on batch 1698/3013  on Training is 87.02545615067687\n",
            "Epoch #4. Accuracy on batch 1699/3013  on Training is 87.02389705882354\n",
            "Batch Id 1700 is having training loss of 0.44302716851234436\n",
            "0.1818118542432785\n",
            "Epoch #4. Accuracy on batch 1700/3013  on Training is 87.02785126396238\n",
            "Epoch #4. Accuracy on batch 1701/3013  on Training is 87.02812867215042\n",
            "Epoch #4. Accuracy on batch 1702/3013  on Training is 87.02106576629477\n",
            "Epoch #4. Accuracy on batch 1703/3013  on Training is 87.01951291079813\n",
            "Epoch #4. Accuracy on batch 1704/3013  on Training is 87.01796187683284\n",
            "Epoch #4. Accuracy on batch 1705/3013  on Training is 87.01458089097304\n",
            "Epoch #4. Accuracy on batch 1706/3013  on Training is 87.0130345635618\n",
            "Epoch #4. Accuracy on batch 1707/3013  on Training is 87.0114900468384\n",
            "Epoch #4. Accuracy on batch 1708/3013  on Training is 87.01360444704505\n",
            "Epoch #4. Accuracy on batch 1709/3013  on Training is 87.015716374269\n",
            "Epoch #4. Accuracy on batch 1710/3013  on Training is 87.01782583284628\n",
            "Epoch #4. Accuracy on batch 1711/3013  on Training is 87.02175817757009\n",
            "Epoch #4. Accuracy on batch 1712/3013  on Training is 87.025685931115\n",
            "Epoch #4. Accuracy on batch 1713/3013  on Training is 87.02413943990665\n",
            "Epoch #4. Accuracy on batch 1714/3013  on Training is 87.024416909621\n",
            "Epoch #4. Accuracy on batch 1715/3013  on Training is 87.02833624708624\n",
            "Epoch #4. Accuracy on batch 1716/3013  on Training is 87.02861094933023\n",
            "Epoch #4. Accuracy on batch 1717/3013  on Training is 87.02524738067521\n",
            "Epoch #4. Accuracy on batch 1718/3013  on Training is 87.02006980802793\n",
            "Epoch #4. Accuracy on batch 1719/3013  on Training is 87.02216569767442\n",
            "Batch Id 1720 is having training loss of 0.4431079030036926\n",
            "0.18961532413959503\n",
            "Epoch #4. Accuracy on batch 1720/3013  on Training is 87.02789076118536\n",
            "Epoch #4. Accuracy on batch 1721/3013  on Training is 87.02635017421603\n",
            "Epoch #4. Accuracy on batch 1722/3013  on Training is 87.02118398142774\n",
            "Epoch #4. Accuracy on batch 1723/3013  on Training is 87.02508700696056\n",
            "Epoch #4. Accuracy on batch 1724/3013  on Training is 87.0163043478261\n",
            "Epoch #4. Accuracy on batch 1725/3013  on Training is 87.01658458864426\n",
            "Epoch #4. Accuracy on batch 1726/3013  on Training is 87.01324551244933\n",
            "Epoch #4. Accuracy on batch 1727/3013  on Training is 87.00991030092592\n",
            "Epoch #4. Accuracy on batch 1728/3013  on Training is 87.01561596298438\n",
            "Epoch #4. Accuracy on batch 1729/3013  on Training is 87.01589595375722\n",
            "Epoch #4. Accuracy on batch 1730/3013  on Training is 87.0143703061814\n",
            "Epoch #4. Accuracy on batch 1731/3013  on Training is 87.01465069284065\n",
            "Epoch #4. Accuracy on batch 1732/3013  on Training is 87.0113242931333\n",
            "Epoch #4. Accuracy on batch 1733/3013  on Training is 87.0080017301038\n",
            "Epoch #4. Accuracy on batch 1734/3013  on Training is 87.00468299711815\n",
            "Epoch #4. Accuracy on batch 1735/3013  on Training is 87.00676843317973\n",
            "Epoch #4. Accuracy on batch 1736/3013  on Training is 87.00885146804836\n",
            "Epoch #4. Accuracy on batch 1737/3013  on Training is 87.00553797468355\n",
            "Epoch #4. Accuracy on batch 1738/3013  on Training is 87.00043128234617\n",
            "Epoch #4. Accuracy on batch 1739/3013  on Training is 87.00790229885058\n",
            "Batch Id 1740 is having training loss of 0.4436144232749939\n",
            "0.3745425045490265\n",
            "Epoch #4. Accuracy on batch 1740/3013  on Training is 87.00818495117748\n",
            "Epoch #4. Accuracy on batch 1741/3013  on Training is 87.01205510907003\n",
            "Epoch #4. Accuracy on batch 1742/3013  on Training is 87.01412794033276\n",
            "Epoch #4. Accuracy on batch 1743/3013  on Training is 87.01082282110092\n",
            "Epoch #4. Accuracy on batch 1744/3013  on Training is 87.01110315186246\n",
            "Epoch #4. Accuracy on batch 1745/3013  on Training is 87.01138316151203\n",
            "Epoch #4. Accuracy on batch 1746/3013  on Training is 87.00808528906697\n",
            "Epoch #4. Accuracy on batch 1747/3013  on Training is 87.00657894736842\n",
            "Epoch #4. Accuracy on batch 1748/3013  on Training is 87.00864779874213\n",
            "Epoch #4. Accuracy on batch 1749/3013  on Training is 87.00178571428572\n",
            "Epoch #4. Accuracy on batch 1750/3013  on Training is 87.00742432895488\n",
            "Epoch #4. Accuracy on batch 1751/3013  on Training is 87.00057077625571\n",
            "Epoch #4. Accuracy on batch 1752/3013  on Training is 87.0062036508842\n",
            "Epoch #4. Accuracy on batch 1753/3013  on Training is 87.00470353477765\n",
            "Epoch #4. Accuracy on batch 1754/3013  on Training is 87.00498575498575\n",
            "Epoch #4. Accuracy on batch 1755/3013  on Training is 87.00882687927107\n",
            "Epoch #4. Accuracy on batch 1756/3013  on Training is 87.01088503130336\n",
            "Epoch #4. Accuracy on batch 1757/3013  on Training is 87.00760807736064\n",
            "Epoch #4. Accuracy on batch 1758/3013  on Training is 87.00966458214894\n",
            "Epoch #4. Accuracy on batch 1759/3013  on Training is 87.00639204545455\n",
            "Batch Id 1760 is having training loss of 0.44380563497543335\n",
            "0.27277570962905884\n",
            "Epoch #4. Accuracy on batch 1760/3013  on Training is 87.01022146507665\n",
            "Epoch #4. Accuracy on batch 1761/3013  on Training is 87.00872587968217\n",
            "Epoch #4. Accuracy on batch 1762/3013  on Training is 87.00900453771979\n",
            "Epoch #4. Accuracy on batch 1763/3013  on Training is 87.0092828798186\n",
            "Epoch #4. Accuracy on batch 1764/3013  on Training is 87.00779036827196\n",
            "Epoch #4. Accuracy on batch 1765/3013  on Training is 87.01160815402038\n",
            "Epoch #4. Accuracy on batch 1766/3013  on Training is 87.01188455008489\n",
            "Epoch #4. Accuracy on batch 1767/3013  on Training is 87.01569570135747\n",
            "Epoch #4. Accuracy on batch 1768/3013  on Training is 87.01773600904465\n",
            "Epoch #4. Accuracy on batch 1769/3013  on Training is 87.01624293785311\n",
            "Epoch #4. Accuracy on batch 1770/3013  on Training is 87.02004517221908\n",
            "Epoch #4. Accuracy on batch 1771/3013  on Training is 87.02384311512415\n",
            "Epoch #4. Accuracy on batch 1772/3013  on Training is 87.02763677382967\n",
            "Epoch #4. Accuracy on batch 1773/3013  on Training is 87.02790304396844\n",
            "Epoch #4. Accuracy on batch 1774/3013  on Training is 87.02992957746478\n",
            "Epoch #4. Accuracy on batch 1775/3013  on Training is 87.02843468468468\n",
            "Epoch #4. Accuracy on batch 1776/3013  on Training is 87.03045863815419\n",
            "Epoch #4. Accuracy on batch 1777/3013  on Training is 87.02720753655792\n",
            "Epoch #4. Accuracy on batch 1778/3013  on Training is 87.02747329960653\n",
            "Epoch #4. Accuracy on batch 1779/3013  on Training is 87.02422752808988\n",
            "Batch Id 1780 is having training loss of 0.4436902105808258\n",
            "0.5031108856201172\n",
            "Epoch #4. Accuracy on batch 1780/3013  on Training is 87.02449466591803\n",
            "Epoch #4. Accuracy on batch 1781/3013  on Training is 87.02651515151516\n",
            "Epoch #4. Accuracy on batch 1782/3013  on Training is 87.02678070667415\n",
            "Epoch #4. Accuracy on batch 1783/3013  on Training is 87.02529428251121\n",
            "Epoch #4. Accuracy on batch 1784/3013  on Training is 87.02556022408963\n",
            "Epoch #4. Accuracy on batch 1785/3013  on Training is 87.02757558790593\n",
            "Epoch #4. Accuracy on batch 1786/3013  on Training is 87.02609121432569\n",
            "Epoch #4. Accuracy on batch 1787/3013  on Training is 87.02460850111856\n",
            "Epoch #4. Accuracy on batch 1788/3013  on Training is 87.01963387367245\n",
            "Epoch #4. Accuracy on batch 1789/3013  on Training is 87.01641061452514\n",
            "Epoch #4. Accuracy on batch 1790/3013  on Training is 87.02191513121161\n",
            "Epoch #4. Accuracy on batch 1791/3013  on Training is 87.02392578125\n",
            "Epoch #4. Accuracy on batch 1792/3013  on Training is 87.02244841048523\n",
            "Epoch #4. Accuracy on batch 1793/3013  on Training is 87.01574693422519\n",
            "Epoch #4. Accuracy on batch 1794/3013  on Training is 87.01427576601671\n",
            "Epoch #4. Accuracy on batch 1795/3013  on Training is 87.01454621380846\n",
            "Epoch #4. Accuracy on batch 1796/3013  on Training is 87.0130773511408\n",
            "Epoch #4. Accuracy on batch 1797/3013  on Training is 87.00987208008898\n",
            "Epoch #4. Accuracy on batch 1798/3013  on Training is 87.01188160088938\n",
            "Epoch #4. Accuracy on batch 1799/3013  on Training is 87.00694444444444\n",
            "Batch Id 1800 is having training loss of 0.44409385323524475\n",
            "0.347966730594635\n",
            "Epoch #4. Accuracy on batch 1800/3013  on Training is 87.00721821210439\n",
            "Epoch #4. Accuracy on batch 1801/3013  on Training is 87.00575749167592\n",
            "Epoch #4. Accuracy on batch 1802/3013  on Training is 87.0042983915696\n",
            "Epoch #4. Accuracy on batch 1803/3013  on Training is 87.0028409090909\n",
            "Epoch #4. Accuracy on batch 1804/3013  on Training is 87.0031163434903\n",
            "Epoch #4. Accuracy on batch 1805/3013  on Training is 87.00512181616833\n",
            "Epoch #4. Accuracy on batch 1806/3013  on Training is 87.00885445489762\n",
            "Epoch #4. Accuracy on batch 1807/3013  on Training is 87.00912610619469\n",
            "Epoch #4. Accuracy on batch 1808/3013  on Training is 87.01112493090105\n",
            "Epoch #4. Accuracy on batch 1809/3013  on Training is 87.0113950276243\n",
            "Epoch #4. Accuracy on batch 1810/3013  on Training is 87.01166482606295\n",
            "Epoch #4. Accuracy on batch 1811/3013  on Training is 87.01020971302428\n",
            "Epoch #4. Accuracy on batch 1812/3013  on Training is 87.01047986762272\n",
            "Epoch #4. Accuracy on batch 1813/3013  on Training is 87.00902701212789\n",
            "Epoch #4. Accuracy on batch 1814/3013  on Training is 87.00929752066116\n",
            "Epoch #4. Accuracy on batch 1815/3013  on Training is 87.0112885462555\n",
            "Epoch #4. Accuracy on batch 1816/3013  on Training is 87.0098376444689\n",
            "Epoch #4. Accuracy on batch 1817/3013  on Training is 87.00666941694169\n",
            "Epoch #4. Accuracy on batch 1818/3013  on Training is 87.00694062671798\n",
            "Epoch #4. Accuracy on batch 1819/3013  on Training is 87.00377747252747\n",
            "Batch Id 1820 is having training loss of 0.4440724551677704\n",
            "0.5712367296218872\n",
            "Epoch #4. Accuracy on batch 1820/3013  on Training is 87.00061779242175\n",
            "Epoch #4. Accuracy on batch 1821/3013  on Training is 86.99231613611416\n",
            "Epoch #4. Accuracy on batch 1822/3013  on Training is 86.97716675809106\n",
            "Epoch #4. Accuracy on batch 1823/3013  on Training is 86.97402686403508\n",
            "Epoch #4. Accuracy on batch 1824/3013  on Training is 86.9777397260274\n",
            "Epoch #4. Accuracy on batch 1825/3013  on Training is 86.97460295728368\n",
            "Epoch #4. Accuracy on batch 1826/3013  on Training is 86.9714696223317\n",
            "Epoch #4. Accuracy on batch 1827/3013  on Training is 86.97004923413567\n",
            "Epoch #4. Accuracy on batch 1828/3013  on Training is 86.97204756697649\n",
            "Epoch #4. Accuracy on batch 1829/3013  on Training is 86.97233606557377\n",
            "Epoch #4. Accuracy on batch 1830/3013  on Training is 86.97262424904424\n",
            "Epoch #4. Accuracy on batch 1831/3013  on Training is 86.97461790393012\n",
            "Epoch #4. Accuracy on batch 1832/3013  on Training is 86.9714948172395\n",
            "Epoch #4. Accuracy on batch 1833/3013  on Training is 86.96667121046892\n",
            "Epoch #4. Accuracy on batch 1834/3013  on Training is 86.96696185286103\n",
            "Epoch #4. Accuracy on batch 1835/3013  on Training is 86.97065631808279\n",
            "Epoch #4. Accuracy on batch 1836/3013  on Training is 86.97604790419162\n",
            "Epoch #4. Accuracy on batch 1837/3013  on Training is 86.97803318824809\n",
            "Epoch #4. Accuracy on batch 1838/3013  on Training is 86.97491843393148\n",
            "Epoch #4. Accuracy on batch 1839/3013  on Training is 86.97350543478261\n",
            "Batch Id 1840 is having training loss of 0.4451332688331604\n",
            "0.6325171589851379\n",
            "Epoch #4. Accuracy on batch 1840/3013  on Training is 86.97039652362847\n",
            "Epoch #4. Accuracy on batch 1841/3013  on Training is 86.9723805646037\n",
            "Epoch #4. Accuracy on batch 1842/3013  on Training is 86.9726668475312\n",
            "Epoch #4. Accuracy on batch 1843/3013  on Training is 86.97125813449024\n",
            "Epoch #4. Accuracy on batch 1844/3013  on Training is 86.96815718157181\n",
            "Epoch #4. Accuracy on batch 1845/3013  on Training is 86.97352383531961\n",
            "Epoch #4. Accuracy on batch 1846/3013  on Training is 86.97042501353546\n",
            "Epoch #4. Accuracy on batch 1847/3013  on Training is 86.97071158008659\n",
            "Epoch #4. Accuracy on batch 1848/3013  on Training is 86.96761763115198\n",
            "Epoch #4. Accuracy on batch 1849/3013  on Training is 86.97128378378379\n",
            "Epoch #4. Accuracy on batch 1850/3013  on Training is 86.97663425175581\n",
            "Epoch #4. Accuracy on batch 1851/3013  on Training is 86.97691684665227\n",
            "Epoch #4. Accuracy on batch 1852/3013  on Training is 86.97551268213708\n",
            "Epoch #4. Accuracy on batch 1853/3013  on Training is 86.9724244875944\n",
            "Epoch #4. Accuracy on batch 1854/3013  on Training is 86.97102425876011\n",
            "Epoch #4. Accuracy on batch 1855/3013  on Training is 86.97130926724138\n",
            "Epoch #4. Accuracy on batch 1856/3013  on Training is 86.97159396876683\n",
            "Epoch #4. Accuracy on batch 1857/3013  on Training is 86.97524219590959\n",
            "Epoch #4. Accuracy on batch 1858/3013  on Training is 86.97216245293168\n",
            "Epoch #4. Accuracy on batch 1859/3013  on Training is 86.96908602150538\n",
            "Batch Id 1860 is having training loss of 0.4453555941581726\n",
            "0.4150915741920471\n",
            "Epoch #4. Accuracy on batch 1860/3013  on Training is 86.96769210102096\n",
            "Epoch #4. Accuracy on batch 1861/3013  on Training is 86.96965628356605\n",
            "Epoch #4. Accuracy on batch 1862/3013  on Training is 86.96826355340848\n",
            "Epoch #4. Accuracy on batch 1863/3013  on Training is 86.97190182403433\n",
            "Epoch #4. Accuracy on batch 1864/3013  on Training is 86.97553619302948\n",
            "Epoch #4. Accuracy on batch 1865/3013  on Training is 86.97246784565917\n",
            "Epoch #4. Accuracy on batch 1866/3013  on Training is 86.97107659346545\n",
            "Epoch #4. Accuracy on batch 1867/3013  on Training is 86.97303265524626\n",
            "Epoch #4. Accuracy on batch 1868/3013  on Training is 86.97331460674157\n",
            "Epoch #4. Accuracy on batch 1869/3013  on Training is 86.9769385026738\n",
            "Epoch #4. Accuracy on batch 1870/3013  on Training is 86.97554783538214\n",
            "Epoch #4. Accuracy on batch 1871/3013  on Training is 86.97415865384616\n",
            "Epoch #4. Accuracy on batch 1872/3013  on Training is 86.97277095568606\n",
            "Epoch #4. Accuracy on batch 1873/3013  on Training is 86.97305229455709\n",
            "Epoch #4. Accuracy on batch 1874/3013  on Training is 86.97166666666666\n",
            "Epoch #4. Accuracy on batch 1875/3013  on Training is 86.97028251599147\n",
            "Epoch #4. Accuracy on batch 1876/3013  on Training is 86.96889984017048\n",
            "Epoch #4. Accuracy on batch 1877/3013  on Training is 86.96419062832801\n",
            "Epoch #4. Accuracy on batch 1878/3013  on Training is 86.96447578499202\n",
            "Epoch #4. Accuracy on batch 1879/3013  on Training is 86.96642287234043\n",
            "Batch Id 1880 is having training loss of 0.44544780254364014\n",
            "0.46519941091537476\n",
            "Epoch #4. Accuracy on batch 1880/3013  on Training is 86.96670653907496\n",
            "Epoch #4. Accuracy on batch 1881/3013  on Training is 86.9653294367694\n",
            "Epoch #4. Accuracy on batch 1882/3013  on Training is 86.96561338289963\n",
            "Epoch #4. Accuracy on batch 1883/3013  on Training is 86.9692144373673\n",
            "Epoch #4. Accuracy on batch 1884/3013  on Training is 86.97115384615384\n",
            "Epoch #4. Accuracy on batch 1885/3013  on Training is 86.9730911983033\n",
            "Epoch #4. Accuracy on batch 1886/3013  on Training is 86.9783386327504\n",
            "Epoch #4. Accuracy on batch 1887/3013  on Training is 86.97695974576271\n",
            "Epoch #4. Accuracy on batch 1888/3013  on Training is 86.97558231868713\n",
            "Epoch #4. Accuracy on batch 1889/3013  on Training is 86.97255291005291\n",
            "Epoch #4. Accuracy on batch 1890/3013  on Training is 86.96952670544685\n",
            "Epoch #4. Accuracy on batch 1891/3013  on Training is 86.96650369978859\n",
            "Epoch #4. Accuracy on batch 1892/3013  on Training is 86.96678552562071\n",
            "Epoch #4. Accuracy on batch 1893/3013  on Training is 86.96706705385428\n",
            "Epoch #4. Accuracy on batch 1894/3013  on Training is 86.96734828496042\n",
            "Epoch #4. Accuracy on batch 1895/3013  on Training is 86.96598101265823\n",
            "Epoch #4. Accuracy on batch 1896/3013  on Training is 86.96790985767001\n",
            "Epoch #4. Accuracy on batch 1897/3013  on Training is 86.96654373024236\n",
            "Epoch #4. Accuracy on batch 1898/3013  on Training is 86.96847024749869\n",
            "Epoch #4. Accuracy on batch 1899/3013  on Training is 86.96381578947368\n",
            "Batch Id 1900 is having training loss of 0.44509759545326233\n",
            "0.24963611364364624\n",
            "Epoch #4. Accuracy on batch 1900/3013  on Training is 86.9657417148869\n",
            "Epoch #4. Accuracy on batch 1901/3013  on Training is 86.96602260778128\n",
            "Epoch #4. Accuracy on batch 1902/3013  on Training is 86.96958749343142\n",
            "Epoch #4. Accuracy on batch 1903/3013  on Training is 86.97150735294117\n",
            "Epoch #4. Accuracy on batch 1904/3013  on Training is 86.9717847769029\n",
            "Epoch #4. Accuracy on batch 1905/3013  on Training is 86.96714323189927\n",
            "Epoch #4. Accuracy on batch 1906/3013  on Training is 86.96742265338227\n",
            "Epoch #4. Accuracy on batch 1907/3013  on Training is 86.9660639412998\n",
            "Epoch #4. Accuracy on batch 1908/3013  on Training is 86.9712545835516\n",
            "Epoch #4. Accuracy on batch 1909/3013  on Training is 86.97316753926701\n",
            "Epoch #4. Accuracy on batch 1910/3013  on Training is 86.97344322344323\n",
            "Epoch #4. Accuracy on batch 1911/3013  on Training is 86.9753530334728\n",
            "Epoch #4. Accuracy on batch 1912/3013  on Training is 86.97072660742289\n",
            "Epoch #4. Accuracy on batch 1913/3013  on Training is 86.96937042842215\n",
            "Epoch #4. Accuracy on batch 1914/3013  on Training is 86.96475195822454\n",
            "Epoch #4. Accuracy on batch 1915/3013  on Training is 86.96176931106471\n",
            "Epoch #4. Accuracy on batch 1916/3013  on Training is 86.9636802295253\n",
            "Epoch #4. Accuracy on batch 1917/3013  on Training is 86.96070125130345\n",
            "Epoch #4. Accuracy on batch 1918/3013  on Training is 86.95772537780094\n",
            "Epoch #4. Accuracy on batch 1919/3013  on Training is 86.95963541666667\n",
            "Batch Id 1920 is having training loss of 0.4453566372394562\n",
            "0.38142114877700806\n",
            "Epoch #4. Accuracy on batch 1920/3013  on Training is 86.9615434669443\n",
            "Epoch #4. Accuracy on batch 1921/3013  on Training is 86.95857180020812\n",
            "Epoch #4. Accuracy on batch 1922/3013  on Training is 86.95885335413416\n",
            "Epoch #4. Accuracy on batch 1923/3013  on Training is 86.96238305613305\n",
            "Epoch #4. Accuracy on batch 1924/3013  on Training is 86.96428571428571\n",
            "Epoch #4. Accuracy on batch 1925/3013  on Training is 86.96294132917964\n",
            "Epoch #4. Accuracy on batch 1926/3013  on Training is 86.96159833938765\n",
            "Epoch #4. Accuracy on batch 1927/3013  on Training is 86.9602567427386\n",
            "Epoch #4. Accuracy on batch 1928/3013  on Training is 86.9653965785381\n",
            "Epoch #4. Accuracy on batch 1929/3013  on Training is 86.96729274611398\n",
            "Epoch #4. Accuracy on batch 1930/3013  on Training is 86.96271361988607\n",
            "Epoch #4. Accuracy on batch 1931/3013  on Training is 86.96622670807453\n",
            "Epoch #4. Accuracy on batch 1932/3013  on Training is 86.96488618727366\n",
            "Epoch #4. Accuracy on batch 1933/3013  on Training is 86.96354705274044\n",
            "Epoch #4. Accuracy on batch 1934/3013  on Training is 86.96382428940568\n",
            "Epoch #4. Accuracy on batch 1935/3013  on Training is 86.96732954545455\n",
            "Epoch #4. Accuracy on batch 1936/3013  on Training is 86.9676045431079\n",
            "Epoch #4. Accuracy on batch 1937/3013  on Training is 86.96465428276574\n",
            "Epoch #4. Accuracy on batch 1938/3013  on Training is 86.96976534296029\n",
            "Epoch #4. Accuracy on batch 1939/3013  on Training is 86.96842783505154\n",
            "Batch Id 1940 is having training loss of 0.4451656639575958\n",
            "0.44857171177864075\n",
            "Epoch #4. Accuracy on batch 1940/3013  on Training is 86.96870170015455\n",
            "Epoch #4. Accuracy on batch 1941/3013  on Training is 86.96575695159629\n",
            "Epoch #4. Accuracy on batch 1942/3013  on Training is 86.95959855892949\n",
            "Epoch #4. Accuracy on batch 1943/3013  on Training is 86.95987654320987\n",
            "Epoch #4. Accuracy on batch 1944/3013  on Training is 86.96015424164524\n",
            "Epoch #4. Accuracy on batch 1945/3013  on Training is 86.96203751284686\n",
            "Прервано пользователем\n"
          ]
        }
      ],
      "source": [
        "# Загрузка словарей с лоссами\n",
        "if last_epoch is not None:\n",
        "    train_losses = checkpoint['losses_train']\n",
        "    val_losses = checkpoint['losses_val']\n",
        "    train_accuracies = checkpoint['accuracies_train']\n",
        "    val_accuracies = checkpoint['accuracies_val']\n",
        "    train_f1_micros = checkpoint['train_f1_micro']\n",
        "    val_f1_micros = checkpoint['val_f1_micro']\n",
        "    train_f1_macros = checkpoint['train_f1_macro']\n",
        "    val_f1_macros = checkpoint['val_f1_macro']\n",
        "    train_f1_weighteds = checkpoint['train_f1_weighted']\n",
        "    val_f1_weighteds = checkpoint['val_f1_weighted']\n",
        "else:\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    train_f1_micros = []\n",
        "    val_f1_micros = []\n",
        "    train_f1_macros = []\n",
        "    val_f1_macros = []\n",
        "    train_f1_weighteds = []\n",
        "    val_f1_weighteds = []\n",
        "\n",
        "if last_epoch is None:\n",
        "    start_epoch = 0\n",
        "else:\n",
        "    start_epoch = last_epoch +1\n",
        "\n",
        "try:\n",
        "    for epoch in range(start_epoch, n_epochs):\n",
        "        start = time.time()\n",
        "        train_loss, train_accuracy, train_f1_micro, train_f1_macro, train_f1_weighted = train(train_data_loader, epoch)\n",
        "        val_loss, val_accuracy, val_f1_micro, val_f1_macro, val_f1_weighted = val(val_data_loader, epoch)\n",
        "        #lr_scheduler.step()\n",
        "        print(f\"Эпоха #{epoch} train_loss: {train_loss}, val_loss: {val_loss}\")  \n",
        "        end = time.time()\n",
        "        print(f\"Потрачено {round((end - start) / 60, 1)} минут на {epoch} эпоху\")\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "        train_f1_micros.append(train_f1_micro)\n",
        "        val_f1_micros.append(val_f1_micro)\n",
        "        train_f1_macros.append(train_f1_macro)\n",
        "        val_f1_macros.append(val_f1_macro)\n",
        "        train_f1_weighteds.append(train_f1_weighted)\n",
        "        val_f1_weighteds.append(val_f1_weighted)\n",
        "        \n",
        "\n",
        "        torch.save({'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    #'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "                    'losses_train': train_losses,\n",
        "                    'losses_val': val_losses,\n",
        "                    'accuracies_train': train_accuracies,\n",
        "                    'accuracies_val': val_accuracies,\n",
        "                    'f1_micros_train': train_f1_micros,\n",
        "                    'f1_micros_val': val_f1_micros,\n",
        "                    'f1_macros_train': train_f1_macros,\n",
        "                    'f1_macros_val': val_f1_macros,\n",
        "                    'f1_weighteds_train': train_f1_weighteds,\n",
        "                    'f1_weighteds_val': val_f1_weighteds,\n",
        "                    }, os.path.join(checkpoints_path, f'chkpt_classifier_{model_name}_{epoch}.pth'))\n",
        "    \n",
        "        torch.save(model, os.path.join(checkpoints_path, f'model_classifier_{model_name}_{epoch}.pth'))\n",
        "    \n",
        "except KeyboardInterrupt:\n",
        "    print('Прервано пользователем')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(41, 116)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "item = 5509\n",
        "model.eval()\n",
        "pred = model(val_dataset.__getitem__(item)['images'].unsqueeze(0).to(device)).data.max(1,keepdim=True)[1], \n",
        "int(pred[0][0][0]), int(val_dataset.__getitem__(item)['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.8046910239061795,\n",
              " 0.8287099684258006,\n",
              " 0.8424672981506539,\n",
              " 0.8456247180875056,\n",
              " 0.8575778078484438,\n",
              " 0.8581416328371674,\n",
              " 0.860509697789806,\n",
              " 0.8623139377537212,\n",
              " 0.8636671177266576,\n",
              " 0.8653585926928282]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_f1_micros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'resnet152_test_with_bg_v100_tvs_erasing_1_04_0003_01_2_06_0003_005_2_06_0003_002_5_06_0001_001_adam_001'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "RLL0C1078HWu",
        "outputId": "d92014cd-dea2-4e7e-ee4f-d54968066738"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAACPdUlEQVR4nOzdd1wT9/8H8FcSMth7iQiIEwcgS0XrLo5aR6vgArVqh9qh/dXa1r1rtdq6qrXar9U6qm2ttdaWah1VURH3QkVQ2SvMJCSf3x+Bg8jGwDHez8cjD5K7z929E0Ly4nOfuxMwxhgIIYQQQhoJId8FEEIIIYToE4UbQgghhDQqFG4IIYQQ0qhQuCGEEEJIo0LhhhBCCCGNCoUbQgghhDQqFG4IIYQQ0qhQuCGEEEJIo0LhhhBCCCGNCoUbQmrBwoULIRAIqtU2JSXlhbc7ceJEmJiYvPB6CCnSu3dv9O7dm+8yXlh1/ibr2sSJE+Hq6sp3GY0KhZtG4NmzZ1i4cCGioqJKzbt79y4++OADdO/eHTKZDAKBADExMWWux9XVFQKBoNTtrbfe0mkXHh6OyZMno02bNjAyMkLLli0xZcoUxMfHV7v2o0ePYuHChdVerjpyc3OxcOFCnDx5sla3U5nly5fjl19+4bUGvi1btgyvvvoq7O3tIRAIKvzdP336FKNHj4aFhQXMzMwwbNgwPHz4sMy227dvR/v27SGTydC6dWt8/fXX1a7t1q1bWLhwYbl/H4Q0VRqNBp9//jnc3Nwgk8nQuXNn/Pjjj2W2vX37NgYOHAgTExNYWVlhwoQJSE5OLtWuOp8FNcJIg3fx4kUGgO3YsaPUvB07djChUMg6duzIvLy8GAD26NGjMtfj4uLCvLy82K5du3RuFy5c0Gnn4+PD3Nzc2EcffcS2bdvG5s6dy0xNTZm9vT2Lj4+vVu3Tp09ntf02TE5OZgDYggULanU7JalUKpaXl6czzdjYmIWFhZVqu2DBAgaAJScnv/B2w8LCmLGx8Quvp7YAYA4ODiwoKKjC30lWVhZr3bo1s7OzY6tWrWJr165lzs7OrHnz5iwlJUWn7ZYtWxgA9tprr7GtW7eyCRMmMABs5cqV1artwIEDDAA7ceJEDZ9d46RQKJhCoeC7jBdW1t9kfREWFsZcXFz4LqNcH3/8MQPApk6dyrZu3cqGDBnCALAff/xRp11cXByzsbFh7u7ubP369WzZsmXM0tKSeXp6lnoPVfWzoKYM9BuVGqecnBwYGxvzXUaNvPrqq8jIyICpqSm++OKLMnt3SnJycsL48eMrbLN27Vr06NEDQmFxx9/AgQPRq1cvbNiwAUuXLtVH6Q2agYEBDAzoz+t5jx49gqurK1JSUmBra1tuu02bNuH+/fuIiIiAn58fAGDQoEHo2LEj1qxZg+XLlwMA8vLy8Omnn2LIkCH46aefAABTp06FRqPBkiVLMG3aNFhaWtb+E6snauOzSiKR6HV9fKG/yZp5+vQp1qxZg+nTp2PDhg0AgClTpqBXr174v//7P4waNQoikQiAtnc6JycHly9fRosWLQAA/v7+GDBgAHbu3Ilp06Zx663qZ0GN6TUqNQJF/0XfvHmTjRkzhllYWDAvLy/GGGO7du1iXbp0YTKZjFlaWrLg4GAWGxurs/y9e/fYyJEjmb29PZNKpczJyYkFBwezjIwMrg0ANn36dPbzzz+zDh06MIlEwjw8PNgff/xRqp4nT56wSZMmMTs7O67d9u3bufknTpxgAErdyurFWb16daU9N0OGDGEKhYJlZ2dX+7WzsrJiI0eOrHL7sLCwMmsvolar2Zdffsk8PDyYVCpldnZ2bNq0aSwtLU1nPRcvXmQvv/wys7a2ZjKZjLm6urJJkyYxxhh79OhRmduoyn8JGo2GWVtbsw8++ECnJnNzcyYUCll6ejo3feXKlUwkErGsrCzGWPH7qEhZNRT14hS1vX//PgsLC2Pm5ubMzMyMTZw4keXk5FT59Sx6TY2NjdmDBw/Yyy+/zIyMjJijoyNbtGgR02g0Om1TUlLY+PHjmampKTM3N2ehoaEsKiqq3PdPWRISEphIJGILFy4sNe/OnTsMAPv6669LzausN83Pz4/5+fmVmv7yyy8zd3d37vHvv//OALDff/9dp91///3HALBdu3ZV6Xns2LGjzN/RiRMn2JAhQ5ibm1uZy3Xt2pX5+Phwj48fP84CAwOZubk5MzY2Zm3atGFz586tUg0lHT16lPXo0YMZGRkxExMTNnjwYHbjxg2dNkW/6+joaDZo0CBmYmLChg0bxhhj7NSpU+z1119nzs7OTCKRsObNm7P333+f5ebm6qwjPj6eTZw4kTk5OTGJRMIcHBzYq6++qvMZ0atXL9arVy/ucdFnzr59+9jSpUuZk5MTk0qlrG/fvuz+/fulnsuGDRuYm5sbk8lkzM/Pj506darUOqui6PPpxIkTzMfHh8lkMtaxY0eup+3gwYOsY8eOTCqVsi5durDIyEid5Z//m/zuu+8YAJ3PU8YYW7ZsWZnvqYpU9fVmjHGf+1KplHXo0IEdOnSozJ6b1atXs27dujErKysmk8lYly5d2IEDB0qtr+j7ZP/+/ax9+/ZMJpOxrl27smvXrjHGtD2b7u7uTCqVsl69epX7+V+ejRs3ct+JJe3Zs4cBYKdPn+am2dnZsVGjRpVaR5s2bVi/fv3KXH9t9axTjC3HqFGj0Lp1ayxfvhyMMSxbtgzz5s3D6NGjMWXKFCQnJ+Prr7/GSy+9hCtXrsDCwgJKpRJBQUFQKBSYOXMmHBwc8PTpUxw5cgQZGRkwNzfn1n/mzBkcOnQI77zzDkxNTfHVV1/htddeQ2xsLKytrQEAiYmJ6Nq1KwQCAWbMmAFbW1v88ccfeOONNyCXy/H++++jffv2WLx4MebPn49p06ahZ8+eAIDu3bvX6Hn/888/MDIyglqthouLCz744AO89957lS6XnZ2N7Oxs2NjYVHlbb775Jp49e4a//voLu3btKnP+zp07MWnSJLz77rt49OgRNmzYgCtXruDs2bMQi8VISkrCyy+/DFtbW3z88cewsLBATEwMDh06BACwtbXF5s2b8fbbb2PEiBEYOXIkAKBz586V1icQCBAYGIhTp05x065du4bMzEwIhUKcPXsWQ4YMAQCcPn0a3t7e5Q7m3bVrF6ZMmQJ/f3/uvxd3d3edNqNHj4abmxtWrFiByMhIfPvtt7Czs8OqVauq8GoWU6vVGDhwILp27YrPP/8cx44dw4IFC1BQUIDFixcD0O5DHzp0KCIiIvD222+jXbt2+PXXXxEWFlatbdnb26NXr17Yv38/FixYoDNv3759EIlEGDVqVLXWqdFocO3aNUyePLnUPH9/fxw/fhxZWVkwNTXFlStXAAC+vr467Xx8fCAUCnHlypVKeyIB4KWXXsK7776Lr776Cp988gnat28PAGjfvj2Cg4MRGhqKixcvcr1IAPD48WOcP38eq1evBgDcvHkTr7zyCjp37ozFixdDKpUiOjoaZ8+erdbz37VrF8LCwhAUFIRVq1YhNzcXmzdvRo8ePXDlyhWdgacFBQUICgpCjx498MUXX8DIyAgAcODAAeTm5uLtt9+GtbU1IiIi8PXXX+PJkyc4cOAAt/xrr72GmzdvYubMmXB1dUVSUhL++usvxMbGVjrAdeXKlRAKhfjwww+RmZmJzz//HOPGjcOFCxe4Nps3b8aMGTPQs2dPfPDBB4iJicHw4cNhaWmJ5s2bV+t1AYDo6GiMHTsWb775JsaPH48vvvgCQ4cOxZYtW/DJJ5/gnXfeAQCsWLECo0ePxt27d3V6mEuaNGkSDh06hFmzZmHAgAFwdnbG9evXsWjRIrzxxhsYPHhwleuq6ut9/PhxvPbaa/Dw8MCKFSuQmpqKSZMmlflarF+/Hq+++irGjRsHpVKJvXv3YtSoUThy5Aj3uVPk9OnTOHz4MKZPn849/1deeQUfffQRNm3ahHfeeQfp6en4/PPPMXnyZPzzzz9Vfm5XrlyBsbEx9zdRxN/fn5vfo0cPPH36FElJSaX+FovaHj16tMrb1Au9RqVGoCjdjxkzhpsWExPDRCIRW7ZsmU7b69evMwMDA276lStXGIAy03VJAJhEImHR0dHctKtXr5b6L/eNN95gjo6OpcYYhISEMHNzc+6/gorG3JRUWc/N0KFD2apVq9gvv/zCtm/fznr27MkAsI8++qjC9TLG2JIlSxgAFh4eXmnbksobc3P69GkGgO3evVtn+rFjx3Sm//zzzwwAu3jxYrnbeJH/DFavXs1EIhGTy+WMMca++uor5uLiwvz9/dmcOXMYY9reHAsLC50enuf/S2Ss8jE3kydP1pk+YsQIZm1tXa16i3rDZs6cyU3TaDRsyJAhTCKRcON6Dh48yACwdevWce3UajXr27dvtXpuGGPsm2++YQDY9evXdaZ7eHiwvn37lrlMRb+TonmLFy8uNa/ov8g7d+4wxrTvH5FIVOY2bG1tWUhISJWfR3ljbjIzM5lUKmWzZ8/Wmf75558zgUDAHj9+zBhj7Msvv3zhsVNZWVnMwsKCTZ06VWd6QkICMzc315le9Lv++OOPS62nrB6DFStW6NSbnp7OALDVq1dXWFN5PTft27fXGUexfv16nfeBQqFg1tbWzM/Pj6lUKq7dzp07GYAa9dwAYP/99x837c8//2QAmKGhIfe8GCt+T5b8XZb1NxkfH8+srKzYgAEDmEKhYN7e3qxFixYsMzOzWrVV5fVmjDEvLy/m6Oio05N//PhxBqBUz83z61Qqlaxjx46l/qYAMKlUqvO5XvT8HRwcuM8uxhibO3duhd8BZRkyZAhr2bJlqek5OTk677+i76H//e9/pdr+3//9HwPA8vPzS82rrZ4bOlqqHCWPEDp06BA0Gg1Gjx6NlJQU7ubg4IDWrVvjxIkTAMD1zPz555/Izc2tcP39+/fX+c+9c+fOMDMz444GYYzh4MGDGDp0KBhjOtsNCgpCZmYmIiMj9fqcDx8+jI8++gjDhg3D5MmT8e+//yIoKAhr167FkydPyl3u1KlTWLRoEUaPHo2+ffvqpZYDBw7A3NwcAwYM0HnuPj4+MDEx4V5zCwsLAMCRI0egUqn0su2SevbsCbVajf/++w+A9j+knj17omfPnjh9+jQA4MaNG8jIyOB6zWrq+aPSevbsidTUVMjl8mqva8aMGdz9op4/pVKJv//+GwBw7NgxiMViTJ06lWsnFAq5//yqY+TIkTAwMMC+ffu4aTdu3MCtW7cQHBxc7fXl5eUBAKRSaal5MplMp01eXl65Y0JkMhnX7kWYmZlh0KBB2L9/Pxhj3PR9+/aha9eu3NiCovfir7/+Co1GU6Nt/fXXX8jIyMCYMWN03vcikQgBAQHc+76kt99+u9Q0Q0ND7n5OTg5SUlLQvXt3MMa43i5DQ0NIJBKcPHkS6enp1a510qRJOq990fu/6DPs0qVLSE1NxdSpU3XGuowbN67G46A8PDzQrVs37nFAQAAAoG/fvtzvoeT08o6uK+Lg4ICNGzfir7/+Qs+ePREVFYXvvvsOZmZm1aqrKq93fHw8oqKiEBYWptOLP2DAAHh4eFS4zvT0dGRmZqJnz55lfu7369dPp6et6Pm/9tprMDU1LTW9stelpLy8vCr/LQJV+7utCxRuyuHm5sbdv3//PhhjaN26NWxtbXVut2/fRlJSErfMrFmz8O2338LGxgZBQUHYuHEjMjMzS62/5B9iEUtLS+5DJjk5GRkZGdi6dWupbU6aNAkAuO3WFoFAgA8++AAFBQXlHkZ9584djBgxAh07dsS3336rt23fv38fmZmZsLOzK/X8s7Ozuefeq1cvvPbaa1i0aBFsbGwwbNgw7NixAwqFQi91dOnSBUZGRlyQKQo3L730Ei5duoT8/HxuXo8ePV5oW8+/J4q+AKr7xSMUCtGyZUudaW3atAEA7jDnx48fw9HRkduNUaRVq1bV2hYA2NjYoF+/fti/fz83bd++fTAwMOB2A1ZH0Yd6Wb/D/Px8nTaGhoZQKpVlric/P1/nC+JFBAcHIy4uDufOnQMAPHjwAJcvX9YJb8HBwQgMDMSUKVNgb2+PkJAQ7N+/v1pB5/79+wC0X9bPv++PHz9e6m/ewMCgzF0asbGxmDhxIqysrGBiYgJbW1v06tULALjPI6lUilWrVuGPP/6Avb09XnrpJXz++edISEioUq2VvV8fP34MoPR7ysDAoMbndHl+m0UhwdnZuczpVfnbCQkJwZAhQxAREYGpU6eiX79+1a6rKq930evRunXrUsu3bdu21LQjR46ga9eukMlksLKy4naxV+X7RB+vSxFDQ8Mq/y0CVfu7rQs05qYcJX8JGo0GAoEAf/zxBzcqvKSS4yzWrFmDiRMn4tdff8Xx48fx7rvvYsWKFTh//rzOh1BZ6wHA/WdY9IE4fvz4csdBVGXcyIsq+uNIS0srNS8uLg4vv/wyzM3NcfToUZ3/EF6URqOBnZ0ddu/eXeb8otH1AoEAP/30E86fP4/ffvsNf/75JyZPnow1a9bg/PnzL3xCO7FYjICAAJw6dQrR0dFISEhAz549YW9vD5VKhQsXLuD06dNo167dC4/4r+w9UZ+FhIRg0qRJiIqKgpeXF/bv349+/fpVawxWESsrK0il0jLPm1Q0rVmzZgAAR0dHqNVqJCUlwc7OjmunVCqRmprKtXtRQ4cOhZGREfbv34/u3btj//79EAqFOuOJDA0NcerUKZw4cQK///47jh07hn379qFv3744fvx4ub/fkor+7nft2gUHB4dS858/2kcqlZYaU6JWqzFgwACkpaVhzpw5aNeuHYyNjfH06VNMnDhRJ2y9//77GDp0KH755Rf8+eefmDdvHlasWIF//vkH3t7eFdbKx/u1vG2+SC2pqam4dOkSAO25jjQaTbnjdMpSnde7qk6fPo1XX30VL730EjZt2gRHR0eIxWLs2LEDe/bsKdW+Nl6XIo6Ojjhx4gQYYzonQSzrb7Hk9JLi4+O5v+u6QuGmCtzd3cEYg5ubG/cfcEU6deqETp064bPPPsN///2HwMBAbNmypVqHSNva2sLU1BRqtRr9+/evsG1tnnWzqPvy+S/u1NRUvPzyy1AoFAgPD+fe2NVVXu3u7u74+++/ERgYWKW037VrV3Tt2hXLli3Dnj17MG7cOOzduxdTpkx54denZ8+eWLVqFf7++2/Y2NigXbt2EAgE6NChA06fPo3Tp0/jlVdeqXQ9dXV2VI1Gg4cPH+q8V+/duwcA3H/MLi4uOHHiBHJzc3V6b6Kjo2u0zeHDh+PNN9/kdk3du3cPc+fOrdG6hEIhOnXqxH3hlHThwgW0bNmSC9JeXl4AtLtASg4AvXTpEjQaDTe/Kir6/RgbG+OVV17BgQMHsHbtWuzbtw89e/YsFZ6EQiH69euHfv36Ye3atVi+fDk+/fRTnDhxotK/Y6B4kLmdnV2V2pfl+vXruHfvHr7//nuEhoZy0//6669ytzl79mzMnj0b9+/fh5eXF9asWYMffvihRtsv4uLiAkD7nurTpw83vaCgADExMXXyz1lVTJ8+HVlZWVixYgXmzp2LdevWYdasWVVevqqvd9HrUdQ7V9Ldu3d1Hh88eBAymQx//vmnTiDYsWNHlevSFy8vL3z77be4ffu2zu6zooHjRX9jTk5OsLW1LfPvNiIiolp/i/pAu6WqYOTIkRCJRFi0aFGpxMsYQ2pqKgBALpejoKBAZ36nTp0gFAqrvZtEJBLhtddew8GDB3Hjxo1S80ue8bHovBYZGRnV2kZJaWlpUKvVOtNUKhVWrlwJiUSi8+GUk5ODwYMH4+nTpzh69GiZ3axVVV7to0ePhlqtxpIlS0otU1BQwLVPT08v9Tsp+iMqes2Lvrxr+vr07NkTCoUC69atQ48ePbgvwZ49e2LXrl149uxZlcbbGBsbv9DvqDqKzkcBaN+jGzZsgFgs5rrcg4KCoFKpsG3bNq6dRqPBxo0ba7Q9CwsLBAUFYf/+/di7dy8kEgmGDx9e4/pff/11XLx4UeeD8u7du/jnn390ekv69u0LKysrbN68WWf5zZs3w8jIqNRRJRWp7O8oODgYz549w7fffourV6+WGk9UVu/m8+/FygQFBcHMzAzLly8vcwxZWWd6fV7Rf+sl/y4YY1i/fr1Ou9zcXG53QRF3d3eYmprqZbeur68vrK2tsW3bNp3Pxd27d9dojE9t+Omnn7Bv3z6sXLkSH3/8MUJCQvDZZ59x/wxURVVfb0dHR3h5eeH777/X2bX0119/4datW6XWKRAIdD6TY2JieDnD+bBhwyAWi7Fp0yZuGmMMW7ZsgZOTk86Rua+99hqOHDmCuLg4blp4eDju3btX7aMmXxT13FSBu7s7li5dirlz53KHMpqamuLRo0f4+eefMW3aNHz44Yf4559/MGPGDIwaNQpt2rRBQUEBdu3axQWV6lq5ciVOnDiBgIAATJ06FR4eHkhLS0NkZCT+/vtv7sPU3d0dFhYW2LJlC0xNTWFsbIyAgAC4ubkhMzOTOxV90SGpGzZsgIWFBSwsLLiBp4cPH8bSpUvx+uuvw83NDWlpadizZw9u3LiB5cuX63SRjxs3DhEREZg8eTJu376N27dvc/NMTEyq9aXm4+MDAHj33XcRFBQEkUiEkJAQ9OrVC2+++SZWrFiBqKgovPzyyxCLxbh//z4OHDiA9evX4/XXX8f333+PTZs2YcSIEXB3d0dWVha2bdsGMzMz7j95Q0NDeHh4YN++fWjTpg2srKzQsWNHdOzYsUo1duvWDQYGBrh7967OSaheeukl7ku1KuHGx8cHf//9N9auXYtmzZrBzc2NG+CnTzKZDMeOHUNYWBgCAgLwxx9/4Pfff8cnn3zC9cANHz4c/v7+mD17NqKjo9GuXTscPnyYe0/VpJcpODgY48ePx6ZNmxAUFMQNsC1p165dePz4MTfg/tSpU1yP5oQJE7j/bt955x1s27YNQ4YMwYcffgixWIy1a9fC3t4es2fP5tZnaGiIJUuWYPr06Rg1ahSCgoJw+vRp/PDDD1i2bBmsrKyqXL+XlxdEIhFWrVqFzMxMSKVS9O3bl9vdNXjwYJiamuLDDz8s82968eLFOHXqFIYMGQIXFxckJSVh06ZNaN68eZXHY5mZmWHz5s2YMGECunTpgpCQENja2iI2Nha///47AgMDdYJrWdq1awd3d3d8+OGHePr0KczMzHDw4MFSgeLevXvo168fRo8eDQ8PDxgYGODnn39GYmIiQkJCqvy6lUcikWDhwoWYOXMm+vbti9GjRyMmJgY7d+6Eu7s779d5SkpKwttvv40+ffpwn4MbNmzAiRMnMHHiRJw5c6ZKu6eq+noD2kO0hwwZgh49emDy5MlIS0vD119/jQ4dOiA7O5trN2TIEKxduxYDBw7E2LFjkZSUhI0bN6JVq1a4du2a/l6EKmjevDnef/99rF69GiqVCn5+fvjll19w+vRp7N69W2fX1yeffIIDBw6gT58+eO+995CdnY3Vq1ejU6dO3FjRIlX9LKgxvR571QhUdCr8gwcPsh49ejBjY2NmbGzM2rVrx6ZPn87u3r3LGGPs4cOHbPLkyczd3Z3JZDJmZWXF+vTpw/7++2+d9aDwpEvPc3FxKXWocGJiIps+fTpzdnZmYrGYOTg4sH79+rGtW7fqtPv111+Zh4cHMzAw0DmUt7yT2OG5Qw8vXbrEhg4dyp3My8TEhPXo0YPt37+/zDqrss6qKCgoYDNnzmS2trZMIBCUOlRz69atzMfHhxkaGjJTU1PWqVMn9tFHH7Fnz54xxhiLjIxkY8aMYS1atOBO9PfKK6+wS5cu6aznv//+Yz4+PkwikdTosEM/Pz8GQOdSFE+ePGEAmLOzc6n2ZR12eufOHfbSSy8xQ0PDMk/i9/x7rujEctU5bLOsk/jZ29uzBQsWMLVardM2OTmZjR07ljuJ38SJE9nZs2cZALZ3794qb7OIXC7nntsPP/xQZptevXqV+955/hDsuLg49vrrrzMzMzNmYmLCXnnllTJPEseY9n3Stm1bJpFImLu7O/vyyy9LnbSwKrZt28ZatmzJRCJRmTWNGzeOAWD9+/cvtWx4eDgbNmwYa9asGZNIJKxZs2ZszJgx7N69e9Wu48SJEywoKIiZm5szmUzG3N3d2cSJE3Xe1xVdauPWrVusf//+zMTEhNnY2LCpU6dyp5so+mxISUlh06dPZ+3atWPGxsbM3NycBQQElPqbL+9Q8OdPeVH0WfP8aQSKTp8glUqZv78/O3v2LPPx8WEDBw6s1mtSdBK/55X1eVpUS8nD3J//mxw5ciQzNTVlMTExOsv++uuvDABbtWpVlWuryutd5ODBg6x9+/ZMKpUyDw+Pck/it337dta6dWsmlUpZu3bt2I4dO8r8XKnq82es/N9dZdRqNVu+fDlzcXFhEomEdejQody/8Rs3bnCfPRYWFmzcuHEsISGhVLvqfBbUhICxBjBakRBSJ3755ReMGDECZ86cQWBgIN/lkEZIo9HA1tYWI0eO1NktSog+0ZgbQpqo5885oVar8fXXX8PMzAxdunThqSrSmOTn55caE/e///0PaWlp6N27Nz9FkSaBxtyQWpGZmVnpCZvKOtS1riiVyjIHgJZkbm5ep+dlqEhtvJ4zZ85EXl4eunXrBoVCgUOHDuG///7D8uXLufPHNKTXqDx5eXllnhukJCsrq1q/QGRycnKpQfslSSSSao0RagjOnz+PDz74AKNGjYK1tTUiIyOxfft2dOzYkRtgWp9fl7S0tHLPowRoB/7WykUf60B9+buoNS+8Y4uQMpR3UcySNz6Vd8HRkrfqXIKgttXG67l7927WpUsXZmZmxl2UteTlPxraa1Se8i6KWfKmj338lalorBpqcDmChuDRo0ds6NChzN7enonFYmZvb88mTZrEEhMTuTb1+XWpaFwIajDGsD6pL38XtYXG3JBacevWLTx79qzCNjU9j4c+pKen4/LlyxW26dChQ43P36NvfLyeDe01Kk98fDxu3rxZYRsfH58aXxKgqs6ePVth75ulpSV39GBTUp9fl8uXL1d42LqhoWGDHZtWX/4uaguFG0IIIYQ0KjSgmBBCCCGNSpMbUKzRaPDs2TOYmpryfhIpQgghhFQNYwxZWVlo1qxZpSdYbHLh5tmzZ6WulEoIIYSQhiEuLk7nQtRlaXLhpuiCe3FxcTAzM+O5GkIIIYRUhVwuh7OzM/c9XpEmF26KdkWZmZlRuCGEEEIamKoMKaEBxYQQQghpVCjcEEIIIaRRoXBDCCGEkEaFwg0hhBBCGhUKN4QQQghpVCjcEEIIIaRRoXBDCCGEkEaFwg0hhBBCGhUKN4QQQghpVCjcEEIIIaRRoXBDCCGEkEaFwg0hhBBCGpUmd+FMQgghhOiBRgNoVICmAFAX/iy6LzQAzBx5K43CDSGEEKJPjBV+0auLv/A1aoCVfFxQGA4K7xfNUxeUCAwF5YeHUvdVhe3Luq8qrEX1Yut5viamKf81cO4KvPFn3b3mz6FwQwghpPYwVvqLVa0q/WVZNE3ncYm2pR4/107zXHBgJYIDN0+tGySen15mCNE8t1516fYlHzN1xV/6jZ1ApO21EYl5LYPCDSGENBSMab/M1QrtzwIFoFZqbyXvq5VAQdH9MtqWnF+V4FDVgFHmdBXfr1r9IhQDwsIAUPRT8Nxjkbjwccn7YkBkUM79onWKy1n2ufUIRYWPC6eJDMq5//zylSwrNACE9WMoL4UbQkj9xpj2P2GmKb4PVsHjytqUnIYqtCmahuLHGnUFoUFRfgB5PnQUKCtYVll6vlrJz++gNnBfxOLiL0iRWPeLtNzp4nK+cIuCgqjEl21FQaJkOwNAINR9/HybcpcVlZhX4ku+1HL144u/KaBwQwjRH8aAvHQg4zGQ/rjEz1jt/Zzk0kGhZJB4fhoYv8+nvhOIAJEEMJBof4qkJe4X3gyk2i9+UeFPA6nu/AoDRTUCRmXLPR9GBAK+Xz3SiFG4IYRUjzJHG1Z0wkuJnwo53xUWEwgBCLQ/BYKyHwsElbfhHheuUyAsOyzoBAlJxUGjstCh07ZEeCnZViji89UlpN6icEMI0aVWAZlx5YeXnOTK12FsB1i6ABYuuj9NHAr/ay/snq8wdDw/rQohhJtW1J4Q0hRRuCGkqdFogOyE8sOL/GnlR3tIzQHLFoWhxVU3xFi0ACRGdfJUCCGkLBRuCGlsGANy04CMmLLHvWTEaQesVsRAVrrXpSi4WLoAhpZ18lQIIaQmKNwQ0hApssvudSkKMcqsipcXiADz5s+FF9fixyZ2tFuHENJgUbghpC5p1IAqDyjI195U+UBBnvYQ4Iqm56bqhpjc1Mq3ZeJQ9rgXCxfAzEl7NAshhDRC9OlGmibGtOcMqUnQKMgv/KnQTlfll2j7/PTn2ujzhGaGlmUEF1ftT/PmgNhQf9sihJAGhMINaRw0GiDrGZAaXXh7oL3lJJcfRvg+h4pIAhgYAmKZ9tBe7r6h9rHYUDv2xUAGyMxL977IzPitnxBC6ikKN6RhyU0rEWCeCzIFeTVcqaAwSJQMGIW3kgGjrOBRadsK2tDZSgkhpFZQuCH1jzKnMLBEF/9MK/yZl17+ckID7WHJ1q0Kb+6AqWPlIUUkocGzhBDSiFC4IfxQq7SDY8vqhcl6VvGyZs21wcXavUSQaaU9TJnnK9ESQgjhH4UbUnvKHAdT+DM9BmDq8pc1tNLtgSm6b9WSThBHCCGkQhRuyIur6TgYsVFxcLFy1w0zRlZ1Vz8hhJBGhcINqRp9joMpum/qSGNdCCGE6B2FG6JLmQPEXQASb9E4GEIIIQ0ShZumrkAJPL0EPDoFPPwXeHKx/BPN0TgYQgghDQCFm6ZGowbir2rDzKN/gdjzgCpXt41Zc6C5D2DdmsbBEEJII1eg1iC/QIM8pRr5Ku0tT6VGvkqDPJUaeUo1FAXanyWnc21LTC9ato29CVaM7Mzbc6Jw09gxBiTfKe6ZiTkDKDJ12xjZAG4vFd+sWtJYGEII4RFjDIoCjW7QKAwRisJpOkFDWRxKdIKGUo38wmCSXzKwlAgnKrX+z9au1vB7BngKN40NY9rDrB/9W9g7c0p7CYKSpGaAa4/CMNMLsGtPYYYQUi+o1Bpk5RcgO78A8nwVshUF2scKFbLyC7hb0ePs/AJkKwrAGMDAwAq/Uxm0AaH4fvF0lDm9xLKs+OIsResons7KbMO1Kmd6edvBc20VRT0oBWqd+XXFUCyCTCws/Km9GUrKmFY03UAImUTEzSv6aWMiqfviS6Bw0xjI44uDzKNTQGas7nwDQ6BFV6BlL22gcfCkK0ITQvRKo2HIVhZwgSMrX4Ushe7joqCSVeLx89MUBRq+n0q9IxYJIDMQlQgR5QQNsVAnYBiKtcvIDIQwLBFAitvoTpcaCCFoJP/o0jdcQ5SbBsScLg4zKfd05wvFQHO/4t1MzX21lxoghJDnMMaQr9KUGUbKDSeKwsdcL4r2pk9GEhFMpAYwlRnARCaGmcyg+LFUDFOZAXczkhjAQKj9UtZ+NxffL/qqFggEJe4Xd1YLUNxIUNiu+H5xG0GJNihnOresznaLnlE5bZ/bTlFAkYmLw4pYRNehqy4KNw2BIgt4fK5wV9O/QMIN6F7RWgA08yoOMy26ARJjnoolhFSFRsOgVGugUGmgUKuhLNBob2pN8f0CDRSFjxUFJaerddqV3UZTZhtlgZprpyjQIEdRgAI9jo+QiISFgaQoiBjAVCaGqbTkNN1wUvTYRGoAM5kYxlIRDOgLnbwACjf1kSofeBJRPAj46eXSlyqwbV8cZlwDAUNLfmolpJHSaBjk+Sqk5Sh1b7lKZOapoFCVDiLPhwmFSjeElLyvz0ChD0IBioNIyV6SwsemUt2wUhRUTIuCSeFjqYGI76dCCIWbekFdADy7Ajw6qQ00sRcAtUK3jaWrdvCv20uAa0/A1J6PSglpsPJVaqTmKJH+fFgpDCzpOUpufnquEum5qjo94kNiIIRUJITEQHuTGhTfl3DTRZCIiudJS80vflzcRlRuG5lYyPWaGElEjWa8BSEUbvig0QCJN4rHzDz+D1Bm6bYxcSgeAOzaE7B04adWQuohtYYhI1cbQlKztT/TclRIy1EU/8xV6QSZPFUFF2qtgKnUAJbGElgV3iyNJLAwEpcKH9KSQaKCwKHTpnC6WCSgYEGIHlG4qQuMaS9jwB2efRrIS9NtY2ipDTFFh2fbtKbDs0mTwBhDrlKt04uSxgWWsntYMvJUNTpMViwScAHF6rnAYm1S+NNYwoUZSyMJJAY09oOQhobCTW3JiNM9PPv5azNJTACX7sVhxr4jIKQPUdI45KvUSM5SICVbgZRspfZnlgKpz4WV9FztriBlDQ//NTcU6wYULpiIYWUshZWxuHC6FJbGYphIDaiHhJAmgPdws3HjRqxevRoJCQnw9PTE119/DX9//3Lbr1u3Dps3b0ZsbCxsbGzw+uuvY8WKFZDJZHVYdRly04CHJ4oHAac/0p0vkgLO/oW7mnoBzbzpgpKkwWCMIUepRgoXWEqElmwFUrKUOtNrcliw1ECo02tSOrDoTrc0EtMRNYSQMvEabvbt24dZs2Zhy5YtCAgIwLp16xAUFIS7d+/Czs6uVPs9e/bg448/xnfffYfu3bvj3r17mDhxIgQCAdauXcvDMyjhyUXgp8nFjwUiwMmn+IgmZ39AbMhffYQ8hzEGeX4B16uiE1ayFUjO0n2cr6pe74rEQAhbEylsTCSwMZHCxkQKaxNtOCnaBVQysBhJeP9fixDSSAgY4+MEz1oBAQHw8/PDhg0bAAAajQbOzs6YOXMmPv7441LtZ8yYgdu3byM8PJybNnv2bFy4cAFnzpyp0jblcjnMzc2RmZkJMzMz/TwRAMiXA9+/UjxupkU3QKbH9RNSBYwxZOSqtOGkqHelrN6WLAVSarA7yFAsgo1pcVixMZHC1kQCG1NpiWnax6a0C4gQokfV+f7m7V8lpVKJy5cvY+7cudw0oVCI/v3749y5c2Uu0717d/zwww+IiIiAv78/Hj58iKNHj2LChAnlbkehUEChKD6sWi6X6+9JlCQzA948VTvrJk2aRsOQlqsstfsnudTuIAVSs5XVPn+KidRAp3elVHgp8dhYSr0rhJD6j7dPqpSUFKjVatjb656vxd7eHnfu3ClzmbFjxyIlJQU9evQAYwwFBQV466238Mknn5S7nRUrVmDRokV6rZ0QfclXqZEkVyA+Mw8J8nwkyvMRn6n9mZCZj0S5Aony/GoHFjOZAdeborNryLRE74qJFLamUsjEdNI1Qkjj0qD+DTt58iSWL1+OTZs2ISAgANHR0XjvvfewZMkSzJs3r8xl5s6di1mzZnGP5XI5nJ2d66pk0kQxxpCZp0ICF1J0Q0vR/fRcVZXXaWkkLtG7UiKgPNfbYm0iobPEEkKaNN7CjY2NDUQiERITE3WmJyYmwsHBocxl5s2bhwkTJmDKlCkAgE6dOiEnJwfTpk3Dp59+CmEZh1JLpVJIpXTRSKI/BWoNkrMVSMjUBpUEufaWWCK0JMjzqzwAV2oghIO5DA5mMu6nvZkMjuYy2Bc+tjWV0sXzCCGkingLNxKJBD4+PggPD8fw4cMBaAcUh4eHY8aMGWUuk5ubWyrAiETa/1B5HBdNGpEcRQEXVIpCS1GIKQotyVkKVHUvkaWRGPYlQgsXXsy14cXBTAZzQzENvCWEED3idbfUrFmzEBYWBl9fX/j7+2PdunXIycnBpEmTAAChoaFwcnLCihUrAABDhw7F2rVr4e3tze2WmjdvHoYOHcqFHELKUjQot6xdRAklfmblV+38LAZCAexMpVxIsTfTDS8OhdNoPAshhNQ9XsNNcHAwkpOTMX/+fCQkJMDLywvHjh3jBhnHxsbq9NR89tlnEAgE+Oyzz/D06VPY2tpi6NChWLZsGV9PgdQzjDE8TMnB5Zh0XH6cjgfJ2UiQ5yNJroBSXbXdRMYSUanQwt0vDC/WJlKIhNTbQggh9RGv57nhQ62d54bwQlGgxo2nmbgUk45Lj9MR+TgdqTnKctvbmEjhYC7VHddSGFqK7pvK6MzRhBBS3zSI89wQUhPpOUpcfqwNMpdi0nDtaWapE9FJDITwam4BH1dLeDiaoZmFNrTYmcroIoiEENIEULgh9RZjDDGpubgYk4bLMem49DgND5JzSrWzNpbAx8USvq6W8HGxQkcnMzoUmhBCmjAKN6Te0O5ikuPy4zRcKhwzU9YuJndbY/i6WMHH1RJ+rlZwtTaio40IIYRwKNwQ3mTk6u5iuvqk7F1Mns3N4eNiBV8XS/i4WMLSWMJTxYQQQhoCCjekTjDG8Dg1lwsylx6nIzopu1Q7q6JdTIW7mTo6mdMuJkIIIdVC4YbUCmWBBjeeZXJjZS4/TkdKduldTC1tjbVBpnA3U0sbY9rFRAgh5IVQuCF6kZmrwuXYNO6Q7KtxGVA8v4tJJESn5ubwdS0MMy6WsKJdTIQQQvSMwg2pNsYYYtNyC4OMNtDcL2MXk6WRWDtWxlW7m6mjkzmdsZcQQkito3BDKqUs0ODms0zt4N/CnpmUbEWpdi1tjLlDsn1drWgXEyGEEF5QuCGlZCsKcPFRGtcrc/VJRqkrXEtEQnR0MoOva/FRTNYmdPV1Qggh/KNwQ3RExqZj8s6LyMhV6Uy3MBIXhhjtbqZOtIuJEEJIPUXhhnDOP0zFGzsvIkephpOFIbq5W3OHZLe0MYGQLhRJCCGkAaBwQwAAJ+8m4c1dl6Eo0CCwlTW2hfrCSEJvD0IIIQ0PfXsR/HkzATP2REKlZujbzg6bxnWhXU6EEEIaLAo3TdyvUU8xa/9VqDUMQzo54stgL7pyNiGEkAaNwk0Ttv9iHOYcugbGgJHeTvj89c4wEFGwIYQQ0rBRuGmidp59hIW/3QIAjAtogSXDOtKAYUIIIY0ChZsmaPPJB1h17A4AYEoPN3w6pD2dbI8QQkijQeGmCWGM4cu/7uGrf6IBAO/2bYUPBrShYEMIIaRRoXDTRDDGsOz32/j2zCMAwEcD2+Kd3q14rooQQgjRPwo3TYBGwzDv1xvYfSEWALBwqAcmBrrxXBUhhBBSOyjcNHIFag0+OngNhyKfQiAAVo7shGC/FnyXRQghhNQaCjeNmLJAgw/2ReH36/EQCQVYO9oTw7yc+C6LEEIIqVUUbhqpfJUa03dHIvxOEsQiAb4e0wUDOzrwXRYhhBBS6yjcNEK5ygJM+99lnIlOgdRAiG8m+KB3Wzu+yyKEEELqBIWbRiYrX4XJOy/iYkw6jCQibA/zQzd3a77LIoQQQuoMhZtGJCNXidDvInDtSSZMZQb4frI/urSw5LssQgghpE5RuGkkkrMUmLD9Au4kZMHSSIxdbwSgo5M532URQgghdY7CTSMQn5mHcd9ewMPkHNiaSrF7SgDa2JvyXRYhhBDCCwo3DVxcWi7GfnsecWl5aGYuw+6pXeFmY8x3WYQQQghvKNw0YA+SszH+2wuIz8yHi7URdk8JQHNLI77LIoQQQnhF4aaBupMgx/hvLyAlW4lWdibYPSUA9mYyvssihBBCeEfhpgG69iQDod9FICNXBQ9HM+x6wx/WJlK+yyKEEELqBQo3DcylmDRM2nERWYoCeDlb4PtJ/jA3EvNdFiGEEFJvULhpQM5Gp2DK95eQp1IjwM0K2yf6wURKv0JCCCGkJPpmbCD+uZOIt36IhLJAg56tbbB1gi8MJSK+yyKEEELqHQo3DcDR6/F4b+8VqNQMAzzssWGsN6QGFGwIIYSQslC4qecORT7BhweuQsOAoZ7NsHa0J8QiId9lEUIIIfUWhZt6bM+FWHz6y3UwBoz2bY4VIztDJBTwXRYhhBBSr1G4qae+Pf0QS3+/DQAI6+aCBUM7QEjBhhBCCKkUhZt6aMM/9/HF8XsAgLd6uWPOwLYQCCjYEEIIIVVB4aYeYYxh9Z93senkAwDArAFtMLNvKwo2hBBCSDVQuKknGGNY9Nst7PwvBgDw6eD2mPpSS36LIoQQQhqgenHYzcaNG+Hq6gqZTIaAgABERESU27Z3794QCASlbkOGDKnDivVLrWGYe+g6F2yWDO9IwYYQQgipId7Dzb59+zBr1iwsWLAAkZGR8PT0RFBQEJKSkspsf+jQIcTHx3O3GzduQCQSYdSoUXVcuX4UqDWYtT8Key/GQSgAvhjliQldXfguixBCCKkWxhii06Ox+/Zu/PbgN15rETDGGJ8FBAQEwM/PDxs2bAAAaDQaODs7Y+bMmfj4448rXX7dunWYP38+4uPjYWxsXGl7uVwOc3NzZGZmwszM7IXrfxGKAjXe/fEK/ryZCAOhAOtCvPBK52a81kQIIYRUVUJOAs7Hn8f5+PO4EH8BKXkpAIBONp2wZ8gevW6rOt/fvI65USqVuHz5MubOnctNEwqF6N+/P86dO1eldWzfvh0hISHlBhuFQgGFQsE9lsvlL1a0nuSr1Hhz12X8ey8ZEpEQm8Z1QX8Pe77LIoQQQsqVqcjExYSLXJiJkcfozJeKpOhi1wXdm3UHY4y3A2J4DTcpKSlQq9Wwt9f9Ure3t8edO3cqXT4iIgI3btzA9u3by22zYsUKLFq06IVr1accRQGmfH8J5x6mQiYWYluoL3q2tuW7LEIIIURHfkE+riRdwYX4Czgffx63025DwzTcfKFAiI7WHRHgGICujl3haecJqUjKY8VaDfpoqe3bt6NTp07w9/cvt83cuXMxa9Ys7rFcLoezs3NdlFemzDwVJu2IQGRsBkykBvhuoh/83ax4q4cQQggpotaocSv1Fi4kXMD5Z+dxJekKlBqlThs3czd0deyKro5d4evgCzMJv0M8ysJruLGxsYFIJEJiYqLO9MTERDg4OFS4bE5ODvbu3YvFixdX2E4qlUIq5T9FAkBajhITtl/AzWdymBuK8b/J/vB0tuC7LEIIIU0UYwwx8hhuN1NEQgSylFk6bewM7dC1WVcEOAYgwCEA9sb1fwgFr+FGIpHAx8cH4eHhGD58OADtgOLw8HDMmDGjwmUPHDgAhUKB8ePH10GlLy5Jno/x2y/gXmI2rI0l+GFKANo71r+0SwghpHFLyk3idjOdjz+PpFzdo5NNxabwc/DT7mpq1hVuZm4N7mSyvO+WmjVrFsLCwuDr6wt/f3+sW7cOOTk5mDRpEgAgNDQUTk5OWLFihc5y27dvx/Dhw2Ftbc1H2dXyNCMP47adR0xqLuzNpNg9pSta2ZnwXRYhhJAmIEuZhYsJF7lA8zDzoc58sVCMLnZduHEz7a3bw0DIezx4IbxXHxwcjOTkZMyfPx8JCQnw8vLCsWPHuEHGsbGxEAp1T8dz9+5dnDlzBsePH+ej5Gp5nJqDsdsu4GlGHppbGmLPlK5oYW3Ed1mEEEIaKaVaiavJV3Hu2TlcSLiAGyk3dAYBCyBAe+v26Oqo3dXkbecNQwNDHivWP97Pc1PX6vI8N9FJWRi77QKSshRoaWOMH6YEoJlF43oDEUII4ZeGaXAn7Q43biYyMRL56nydNi5mLlyY8Xfwh7nUnKdqa67BnOemMbv5LBOh2yOQmqNEW3tT7JriDztTGd9lEUIIaeAYY4jLiuPGzEQkRCBTkanTxlpmze1m6urYFY4mjjxVyw8KN7XgSmw6wr6LgDy/AJ2czPG/yf6wNJbwXRYhhJAGKiUvBRHxEVygic+J15lvLDaGr70v1zvTyqJVgxsErE8UbvTswsNUTN55ETlKNXxcLLFjkh/MZGK+yyKEkEYjU5GJe+n3cCftDu6k3UGMPAZCCCEVSSERScr8WZNpz883EBjUWWDIUeXgcuJlbtzM/fT7OvMNhAbwtPXkemY62HSAWEjfNUUo3OjRqXvJmLbrEvJVGnR3t8a2UF8YS+klJoSQmmCM4VnOM9xJu4O7aXe5n89ynvFSj1BQIkAJqxaWnp9X5nyhdj4Dw9Xkqzgffx7Xk6+jgBXobL+dVTsEOGgPz+5i1wVGYjo4pTz0zasnJ+4m4c3/XYZSrUGftrbYPN4HMrGI77IIIaRBUKlVeJD5oFSQyVJlldneycQJbS3bop1VO7hbuEMkEEGhVkChVkCpVmp/apTc46JpOvOf+1nmvBJn59UwDfIK8pBXkFcnr0lzk+bcuWb8HfxhJaOz2VcVhRs9cbM2hoWRGD4ullgf4g2JgbDyhQghpAmSK+W4m3aXCzF30u7gQeYDFGgKSrU1EBqglUUrLsi0tWqLtlZt6+yU/xqmgUqjqjQEvci0op8qjQptLNtozwTsGABnU/4uFdTQUbjRE1cbYxx6pzsczGQwEFGwIYQQxhjic+J1e2PS7+Jp9tMy25tKTLUBpjDItLNqh5bmLSEW8TeWpGhXVH24GCSpOgo3etTckvZ/EkKaJpVahYeZD7memLvp2jDz/HWKijQzboa2VsUhpp1VOzgaOzbpI3yI/lC4IYQQUi3P71a6m34X0RnRZe9WEhjA3cJdJ8i0sWzTIE8iRxoOCjeEEELKxBhDQk6Ctjcm/Q7upFayW0lsyoWYop8tzVtCIqLzfJG6ReGGEEIIVBoVHmY85HYnFfXKyJXyMtuX3K1U9LOZcTParUTqBQo3hBDSxKg1atxNv4srSVe4IBOdEQ2VRlWqLe1WIg0RhRtCCGnkGGOIzohGREIEIuIjcCnxUpk9MiZik+LemBLnkKHdSqShoXBDCCGNDGMMj+WPtWEmIQIXEy4iLT9Np42x2Bhd7Lqgg00HtLPU7lpyMnGi3UqkUaBwQwghjcCz7Ge4EH+BCzRJuUk682UiGbztvOHv6A9/B394WHvAQEhfAaRxonc2IYQ0QEm5SVyvzIX4C6WOYBILxfC09eTCTCebTrR7iTQZFG4IIaQBSMtPw8WEi1yYiZHH6MwXCUToaNMR/g7+8Hf0h5etF2QGMn6KJYRnFG4IIaQekivluJRwSRtmEi7gfvp9nfkCCNDeuj0CHALg5+CHLvZdYCw25qlaQuoXCjeEEFIP5KpycTnxMhdm7qTdgYZpdNq0tmyt7Zlx8IePvQ8djk1IOSjcEEIID/IL8hGVHIWIeO0A4JspN1HAdC9f4Grmyu1m8nPwg5XMiqdqCWlYKNwQQkgdUKlVuJ5yHRcSLuBiwkVEJUWVOmmek4kTF2b8HfxhZ2THU7WENGwUbgghpBYUaApwO/U2F2auJF1BXkGeThs7IztuN5O/oz+cTJx4qpYQ/dAoFFCnpwNqNcRO/L2fKdwQQogeaJgG99Lv4UK8NsxcTryMbFW2ThsrmRX8HPy4QONi5kInzSP1FlOroc7MhDo9Her0dBSkp0Odls49Vmeko6Dk4/R0aHJzAQBGAQFw+X4nb7VTuCGEkBpgjOFh5kMuzFxMvIhMRaZOGzOJGXztfbndTK0sWlGYIbxgjEGTk1McVNLSoE7PqDCoqDMzAcaqvzGRqGbL6RGFG0IIqaKUvBSceXoG/z39DxEJEUjNT9WZb2RgBB97HwQ4ag/PbmvZFiKhiKdqSWOmUSqLQ0hamrZXhQsrzz/W3piq9IVRq0Jobg4DCwuILC25m4FV4X2LomkWMLCygsjSEkJTU95DPIUbQggph1qjxo3UGzj95DROPz2NW6m3dObLRDJ42XlxYcbD2gNioZinaklDpVEqocnMhFouL979UxRO0tK0vSolH5fY/VNdAkNDbRApCiVWVtrHliXCipVl8WNzcwjEDe89TeGGEEJKyFRk4uzTszj99DTOPj2LdEW6zvyO1h3Ro3kPBDgEoLNtZ7qkAQFjDCw/XxtOMjOhkcuhlmdBLS+8nymHWi6HRp7J3dfOy4JaLgfLz6/ZhkUibS+KpQVEllZcD4p2mqXOtKKwIjQ01O+Tr6co3BBCmjTGGO6m38XpJ6dx6skpXEu5pnPyPFOxKbo7dUdPp54IdAqEjaENj9WS2sIYA8vNLQweJUJKyTCSKYc6K6v4fmFbTWZmjXf5cAQCCE1NC4OIVYldQIW7e0ru/inscakPu3/qKwo3hJAmJ0eVg/PPzuPU01M48+QMkvJ0r6Dd2rI1ejr1xEvNX4KnrSddPbuBYBqNdtBsZmEvCRdOintJygomark2tKCgoPKNVEQkgsjUFEJzM4jMzCEyM4PI3AxCs6LHpsX3i6aba9sJTUwgEAr180IQCjeEkMaPMYZHmY9w+ulpnH5yGpeTLqNAU/xFZmhgiK6OXdGzeU/0dOoJB2MHHqsl5WFqNVTx8VA+ioEyJgbKx4+hjImBKi4O6owMbUDRaCpfUUXEYm0oMTOD0My07JDy3H1toDGH0NiYelLqCQo3hJBGKa8gDxcTLnKDgZ9mP9WZ72rmih5OPdCzeU/42vvS2Jl6gjGGguRknfCijCkMMbGxVdr9I5BIdHtPzMx0HnOhxbwoxBTfFxgaUkBpBCjcEEIajSdZT7jemYiECCjUCm6eRCiBn4Mf1zvTwqwFj5USdWZmifASoxNiKjoSSCAWQ+zSAhJXV0hdXSF2cYGkhQsMrK0gNC3sYZHJ6vCZkPqIwg0hpMFSqVWITIrUDgZ+egqPMh/pzHc0duTGzvg5+MFIbMRTpU2TJi8PytjYUruRlDEx2lP0l0cohNjJCRJXV+3NxYW7L3Z0gEBE5w4iFaNwQwhpUJJyk3Dm6RmcenIK556dQ25B8X/5IoEI3nbeeKn5S+jp1BPuFu60i6GWMZUKyidPytyNVJCQUOGyBnZ2uuHFrTDANG8OoYR2E5Kao3BDCKnX1Bo1rqVc48bO3Em7ozPfWmbN7Wrq1qwbTCWmPFXaeDGNBgUJCTo9L4qYGKhiHkP55AmgVpe7rNDcHFJXV0hcXXR7YlxcIDQ2rsNnQZoSCjeEkHonLT+NO5Hef8/+07lmkwACdLLthJ5OPdGzeU+0t2oPoYAOoX1RjDGo09O14eX53UiPH4MpFOUuKzA0LLHryEWnN8bA0rIOnwUhWhRuCCG80zANbqfd5npnridfB0PxhffMJGYIdApET6ee6OHUA5ayuvvCZIyBKZW6N5UK0GjAGNNeIFCjAdNoAAaAaYrnaZju48K2YAzs+XlFjxkrXBcrfz06bYvWWc56ymoL7TyWlw9lXBzXG6PJyir/hTAwgMTZufQ4GDdXGNjZ0e4/Uq9QuCGE8CJLmYVzz87h1JNTOPP0TPFFKBmDgRroYNYGgbYB6GbjizYmLSEqUIMplNDcjkGO8n5hyNANHRqFAkypKiOMVDBPqYSmjGk6QaapEAggdnQsDjAldiWJmzWDwIC+MkjDQO9UQkitYkolci5eRPbJk8i4dQ3yrBTk5GaiID8X4gKGIDXwihoQqwGJWgiDgqKTsN0uvO3EYx7rf55ALNZeSFAoBIRCbY+FQFDOYwEEAiH3uKJ5EAogQAXrKTlPKABQPA+CwnVx6xUARY8FKHeewMAAYufmxYdVt2gBoVTK90tMyAujcEMI0buC1FRk/3sK2SdPIvvsWbCcHG6eaeGtbGWcXVYshlAshkAi0b1JpRBIxBCKy54ukEggLJomrmAed6tgnlRauB4x7X4hpAGgcEMIeWGMMSju3tWGmRMnkXftmnbMSKF0YyCylQD3XcRwtm+Ddg6d0MHRC/YWzblQUTpsFN7oejuEkGqicEMIqRGNQoHc8+eRdfIksk/+i4L4eJ35Dx2Ay+4CXG4thLpVC4R4jMXSVsPoUG1CSK2jcEMIqTJVYhKy/9WGmZxz58Dy8rh5GokB7rhLcNolH5GtBEg3FaCHUw982G4sAp0C6XBtQkid4T3cbNy4EatXr0ZCQgI8PT3x9ddfw9/fv9z2GRkZ+PTTT3Ho0CGkpaXBxcUF69atw+DBg+uwakKaBqbRIP/mLe3uppMnkX/zpm4DOxs87GCFX+3jcKm5EiqxEiZiMwxvNRwh7ULgYubCT+GEkCaN13Czb98+zJo1C1u2bEFAQADWrVuHoKAg3L17F3Z2dqXaK5VKDBgwAHZ2dvjpp5/g5OSEx48fw8LCou6LJ6SR0uTmIufcucJA8y8KkpOLZwoEkHXqhJQurvjV/gl+FVwFBBkAADfzlhjbbiyGug+FsZjOPEsI4Y+AsRKj/upYQEAA/Pz8sGHDBgCARqOBs7MzZs6ciY8//rhU+y1btmD16tW4c+cOxGJxjbYpl8thbm6OzMxMmJmZvVD9hDQWqmfPCsfOnETu+QtgSiU3T2hkBOPAQIh6BuAfp0z8kPAbnmQ/AaA9W3Cv5r0wpv0YdHPsRkcSEUJqTXW+v3nruVEqlbh8+TLmzp3LTRMKhejfvz/OnTtX5jKHDx9Gt27dMH36dPz666+wtbXF2LFjMWfOHIjKuUqsQqGAosRpw+VyuX6fCCENEFOrkX/9OrJOaAON4u5dnfliJyeY9OkDk969Ed/aCt89PIAjD9cjL1o7xsZUYoqRrUYiuF0wnE2d+XgKhBBSLt7CTUpKCtRqNezt7XWm29vb486dO2Uu8/DhQ/zzzz8YN24cjh49iujoaLzzzjtQqVRYsGBBmcusWLECixYt0nv9hDQ06uxs5Jz9D9knTiD71Cmo09KKZwqFMPT2hknvXjDt3Ruilm7498m/2HPnO0Qci+CatbJohbHtx2KI2xAYiY14eBaEEFI53gcUV4dGo4GdnR22bt0KkUgEHx8fPH36FKtXry433MydOxezZs3iHsvlcjg703+apGlQxsVpw8zJk8i5eAkocSkBoakpTHr2gEnv3jDu2RMGlpbIyM/AD/cPYt/P0xGfoz20WygQoq9zX4xtPxa+9r6064kQUu/xFm5sbGwgEomQmJioMz0xMREODg5lLuPo6AixWKyzC6p9+/ZISEiAUqmERCIptYxUKoWUTidOmghWUIC8qChknTiB7JP/Qvnggc58iYsLt7vJyKeL9jICAO6m3cWe/9bh94e/Q6HW7sa1kFrgtdavIbhtMBxNHOv8uRBCSE3xFm4kEgl8fHwQHh6O4cOHA9D2zISHh2PGjBllLhMYGIg9e/ZAo9FAWHjW0nv37sHR0bHMYENIU6DOzET26TPao5tOn4YmM7N4pkgEIx+fwkDTC1I3N26WSqPCPzF/Ys/tPYhMiuSmt7Nqh7HtxmKQ2yDIDGR1+VQIIUQveN0tNWvWLISFhcHX1xf+/v5Yt24dcnJyMGnSJABAaGgonJycsGLFCgDA22+/jQ0bNuC9997DzJkzcf/+fSxfvhzvvvsun0+DkDrFGIPyUQy3uyk3MhJQq7n5InNzGL/0Ekz79IZxjx4QPXdUQWpeKg7eP4h9d/chKTdJu4xAhP4u/TG23Vh423nTridCSIPGa7gJDg5GcnIy5s+fj4SEBHh5eeHYsWPcIOPY2FiuhwYAnJ2d8eeff+KDDz5A586d4eTkhPfeew9z5szh6ykQUieYUoncyEhknziBrJMnoXocqzNf0sodpr17w6RPHxh6ekJgUPpP+2bKTey5swd/PPoDKo127I2VzAqvt3kdo9uMhr2xfallCCGkIeL1PDd8oPPckIaAqVTIv30buZcjkXv5EnLPX4AmO7u4gVgMYz8/mPTuDZM+vSEpZ5C8Sq3C8cfHsefOHlxLvsZN72jdEWPbj0WQaxAkItqlSwip/xrEeW4IIcU0eXnIu3oVuZcuI/fyJeRdvQaWm6vTRmRlBZNevWDSpzeMuwdCZFL+WYCTc5Nx4N4BHLh3ACl5KQAAA6EBglyDMLbdWHS27VybT4cQQnhF4YYQHqgzMpAbGcmFmfybt4CCAp02QjMzGHXpAiNfHxj5+UHWqRMEwvIvPskYw9Xkq9hzZw/+evwXCjTa9dka2mJU21EY1WYUbAxtavV5EUJIfUDhhpA6oHr2jNvFlHf5MhT3o0u1MbC3h5GPDwx9fWDk4wtp61YVhpkiCrUCxx4dw547e3Ar9RY33cvWC2Pbj0X/Fv0hFtXsciWEENIQUbghRM8YY1A+eFDYK6PtmSl4Fl+qncTNDUa+PjD08YGRry/ETk7VOkopIScB++/ux8H7B5GWrz3bsEQowSC3QRjbfiw8rD309pwIIaQhoXBDyAviBv8Whpm8y5ehzsjQbSQSQda+fYmeGR8YWFlVf1uMITIpErtv78Y/sf9AzbSHgNsb2SOkXQhGth4JK1n110sIIY0JhRtCqqnU4N+oq2B5eTptBFIpDD09uZ4ZQ0+vCgcAVya/IB9HHx3Fntt7cDe9+CKXPvY+GNd+HPo494GBkP6cCSEEqGG4iYuLg0AgQPPmzQEAERER2LNnDzw8PDBt2jS9FkgI3wrS05EXGcmNmSlz8K+5OYy8vYvDTIcOEOjhrNkKtQLf3fgOu2/vRqZCe+ZhmUiGIS2HYEy7MWhr1faFt0EIIY1NjcLN2LFjMW3aNEyYMAEJCQkYMGAAOnTogN27dyMhIQHz58/Xd52E1Bnt4N/LXM+MMvpBqTYGDg4w8vHhwoy0VdUG/1ZHRHwElpxfghh5DADAycQJwW2DMbL1SJhLzfW6LUIIaUxqFG5u3LgBf39/AMD+/fvRsWNHnD17FsePH8dbb71F4YY0GFUe/NuyZYkw4wuxU7Nau0RBRn4Gvrj0BX598CsA7aHcH/p+iCDXIIiEokqWJoQQUqNwo1KpuCtt//3333j11VcBAO3atUN8fOkvBkLqiyoP/vXwgFGXLi80+LfatTGG3x7+hi8ufoF0RToEEGB029F4r8t7MJWY1vr2CSGksahRuOnQoQO2bNmCIUOG4K+//sKSJUsAAM+ePYO1tbVeCyTkRWhyc4sH/0ZeLnvwr0ymHfxb1DPj6Qmhcc0H/9bEY/ljLDm/BBfiLwAAWlm0woJuC+Bl51WndRBCSGNQo3CzatUqjBgxAqtXr0ZYWBg8PT0BAIcPH+Z2VxHCF6ZUIis8HOn79iP30qWyB/8WnfnXxwcyDw+9DP6tCZVahe9ufIet17ZCqVFCKpLiLc+3ENYhDGIhnXiPEEJqosYXzlSr1ZDL5bC0tOSmxcTEwMjICHZ2dnorUN/owpmNl/LJU2QcOICMgwehTknhptfF4N+aiEyMxKJzi/Aw8yEAoHuz7vis62dwNi37IpiEENKU1fqFM/Py8sAY44LN48eP8fPPP6N9+/YICgqqySoJqRGmViP79Glk/LgX2adOAYVZ3cDWFhajRsF8xPByr5jNl0xFJr68/CUO3j8IALCSWeEjv48w2G1wrQ1SJoSQpqRG4WbYsGEYOXIk3nrrLWRkZCAgIABisRgpKSlYu3Yt3n77bX3XSYiOgpQUZPx0EBn790P17Bk33bh7N1iEhMC0Tx8IxPVrtw5jDMdijmFVxCqk5qcCAF5r/Ro+8PmADu0mhBA9qlG4iYyMxJdffgkA+Omnn2Bvb48rV67g4MGDmD9/PoUbUisYY8iNuIj0vT8i6+9wQKUCAIjMzWE+ciQsg0dD4urKb5HleJL1BEsvLMXZp2cBAC3NW2J+t/nwsffhuTJCCGl8ahRucnNzYWqqPTT1+PHjGDlyJIRCIbp27YrHjx/rtUBC1HI5Mn/5Fen79kH5oPiEeoZeXrAcEwLToCAIZTIeKyyfSqPCrlu7sDlqM/LV+RALxZjWeRomd5wMiYifQcyEENLY1SjctGrVCr/88gtGjBiBP//8Ex988AEAICkpiQbpEr3Ju34D6Xt/hPz3o2D5+QAAgZERzIcOheWYEMjateO5wopdS76GRecW4V76PQCAv4M/5nWdB1dzV34LI4SQRq5G4Wb+/PkYO3YsPvjgA/Tt2xfdunUDoO3F8fb21muBpGnR5OZCfvQo0n/ci/ybN7np0jZtYDkmBGZDh0JkYsJjhZXLUmbhq8ivsO/uPjAwWEgt8KHvh3jV/VUaMEwIIXWgxoeCJyQkID4+Hp6enhAWHlYbEREBMzMztKvH/1HToeD1kyI6Gul79yHz11+hycoCAAjEYpgOGgjLkDEw9Paq98GAMYa/Y//GygsrkZSXBAB41f1VfOj7ISxllpUsTQghpCK1fig4ADg4OMDBwQFPnjwBADRv3pxO4EeqhSmVkP/1FzJ+3Ks92V4hcYsWsAwOhvnIETCwbBihID47HssvLMfJJycBAC5mLpjXdR4CHAP4LYwQQpqgGoUbjUaDpUuXYs2aNcjOzgYAmJqaYvbs2fj000+5nhxCyqJ88hQZ+/Yh49AhqFO1h0RDJIJp3z6wCA6Bcfdu9eIke1VRoCnAj3d+xNdXvkZeQR4MhAZ4o+MbmNp5KqQiKd/lEUJIk1SjcPPpp59i+/btWLlyJQIDAwEAZ86cwcKFC5Gfn49ly5bptUjS8DG1GtmnTiF9717knDpdfLI9OztYjB4Ni1GvQ2xvz3OV1XMz9SYW/bcIt9NuAwC62HXB/G7z4W7hznNlhBDStNVozE2zZs2wZcsW7mrgRX799Ve88847ePr0qd4K1Dcac1O3CpKTkXHwINL370fBs+Irxht37w6LMYUn2zOo8d5RXuSqcvH1la+x584eaJgGphJTzPKZhZGtR0IoaBg9ToQQ0tDU+pibtLS0MgcNt2vXDmlpaTVZJWlEGGPIvRCB9L17kfX339yFK0UWFsUn23Nx4bnKmjkZdxLLLixDQk4CAGCQ2yB85PcRbAxt+C2MEEIIp0bhxtPTExs2bMBXX32lM33Dhg3o3LmzXgojDY86MxOZv/yC9L37oHz0iJtu6O1dfLI9acMch5KYk4iVESvxd+zfAAAnEyd81vUz9HDqwXNlhBBCnlejcPP5559jyJAh+Pvvv7lz3Jw7dw5xcXE4evSoXgsk9RtjDPnXryN97z7IjxafbE9oZASzYa/CMiQEsrZtea6y5tQaNfbf24/1keuRo8qBSCBCWIcwvOX5FgwNDPkujxBCSBlqFG569eqFe/fuYePGjbhz5w4AYOTIkZg2bRqWLl2Knj176rVIUv9ocnOR+fvvyPhxL/Jv3eKmS9u21Z5s75WhEJkY81jhi7ubdheLzy3GtZRrAIDONp0xv9t8tLVquGGNEEKaghqfxK8sV69eRZcuXaBWq/W1Sr2jAcUvRnH/fvHJ9gpPAyCQSGA2aBAsQoJh6FX/T7ZXmbyCPGy+uhn/u/k/qJkaJmITvNflPYxqMwoioYjv8gghpEmqk5P4kaZDo1Qi6/hfSN/7I/IuXeami11awDI4BOYjhjeYk+1V5szTM1h6fimeZmuP+BvgMgAf+38MOyM7nisjhBBSVRRuSLmUT55oT7Z38BDURUfBiUQw7dsXlmNCYNS1a4M52V5lUvJS8HnE5/gj5g8AgIOxAz4N+BS9nXvzWxghhJBqo3BDSsk+exZp33+PnNNnik+2Z28Pi9GjYPF6wzvZXkU0TIOD9w/iy8tfIkuZBaFAiHHtx2GG1wwYiY34Lo8QQkgNVCvcjBw5ssL5GRkZL1IL4RljDCmbNyPlq6+5acY9esAyJBgmvXs3uJPtVeZBxgMsPrcYkUmRAAAPaw8s6LYAHtYePFdGCCHkRVTr28rc3LzS+aGhoS9UEOEHU6kQv2gRMn86CACwCA6G9RuTIWnRgufK9E+hVmDrta347sZ3KNAUwNDAEDO9Z2JMuzEwEDauAEcIIU1RtT7Jd+zYUVt1EB6ps3Pw9IMPkHP6NCAUwmH+PFiGhPBdVq04H38eS84tQWxWLACgt3NvfBrwKRyMHXiujBBCiL7Qv6lNnCopCXFvvQXFrdsQGBrCac0amPbtw3dZepeWn4Y1l9bg8IPDAAA7QzvMDZiLfi36NfhD1wkhhOiicNOEKaKjETttGgqexUNkbQ3nLZth2KkT32XpFWMMvz74FWsurUGGIgMCCBDSLgQzvWfCVGLKd3mEEEJqAYWbJionIgJPZsyERi6HxNUVztu2QuLszHdZehWTGYMl55cgIiECANDGsg0WdFuAzrZ0/TNCCGnMKNw0QZm//474j+eCqVQw9PZG800bG81J+IpcTLiIGeEzkFuQC5lIhne83sF4j/EQC8V8l0YIIaSWUbhpQhhjSNu+HUlfrAEAmL78Mpp9vgpCmYznyvTrzNMzeP/E+1CoFehi1wXLeixDc9PmfJdFCCGkjlC4aSKYWo3EZcuQvudHAIBVWBjs5nzUaM4wXOSvx3/ho1MfoUBTgF7Ne2FN7zWQiqR8l0UIIaQOUbhpAjR5eXg6+0Nk//MPIBDA/uM5sAoL47ssvfvtwW/47Oxn0DANglyDsKLnCtoNRQghTRCFm0auIDUVcW+/g/xr1yCQStHs889hFvQy32Xp3b47+7D0wlIAwIhWI7Cg2wK6gjchhDRR9WKfxMaNG+Hq6gqZTIaAgABERESU23bnzp0QCAQ6N1kjGzOiL4pHjxATMgb5165BZGGBFjt2NMpgs+PGDi7YjGs/Dgu7L6RgQwghTRjvPTf79u3DrFmzsGXLFgQEBGDdunUICgrC3bt3YWdnV+YyZmZmuHv3LveYTsJWWm7kFTx55x2oMzIgdnaG89ZvIHVz47ssvWKMYdPVTdhydQsAYGqnqZjpPZPeD4QQ0sTx3nOzdu1aTJ06FZMmTYKHhwe2bNkCIyMjfPfdd+UuIxAI4ODgwN3sG9FVqvVBfvw4YidNgjojA7JOneC698dGGWxWX1rNBZv3uryHd7u8S8GGEEIIv+FGqVTi8uXL6N+/PzdNKBSif//+OHfuXLnLZWdnw8XFBc7Ozhg2bBhu3rxZbluFQgG5XK5za8zS/vc/PH3vfTCFAiZ9+sDl+50wsLbmuyy9UmvUWHRuEXbd2gUAmOs/F1M6TeG5KkIIIfUFr+EmJSUFarW6VM+Lvb09EhISylymbdu2+O677/Drr7/ihx9+gEajQffu3fHkyZMy269YsQLm5ubczbmRnYW3CNNokLhiJRKXrwAYg8WYEDTf8DWERkZ8l6ZXKo0Kn5z5BAfvH4RQIMTi7osxtv1YvssihBBSj/C+W6q6unXrhtDQUHh5eaFXr144dOgQbG1t8c0335TZfu7cucjMzORucXFxdVxx7dMoFHj6wSykff89AMDuw9lwmD8fAlHjGlSrVCsx++RsHH10FAYCA6x6aRVGtB7Bd1mEEELqGV4HFNvY2EAkEiExMVFnemJiIhwcHKq0DrFYDG9vb0RHR5c5XyqVQiptvCdxK0hPx5PpM5AXGQmBWAzHFStg/soQvsvSu1xVLt4/8T7OxZ+DRCjB2t5r0cu5F99lEUIIqYd47bmRSCTw8fFBeHg4N02j0SA8PBzdunWr0jrUajWuX78OR0fH2iqz3lLGxeHxmLHIi4yE0MwMztu/bZTBJkuZhbf/fhvn4s/B0MAQm/pvomBDCCGkXLwfCj5r1iyEhYXB19cX/v7+WLduHXJycjBp0iQAQGhoKJycnLBixQoAwOLFi9G1a1e0atUKGRkZWL16NR4/fowpU5rWgNK869cR99bbUKemwqCZI1ps3Qppq1Z8l6V3GfkZePPvN3Er9RZMxabY1H8TvOy8+C6LEEJIPcZ7uAkODkZycjLmz5+PhIQEeHl54dixY9wg49jYWAhLXP8oPT0dU6dORUJCAiwtLeHj44P//vsPHh4efD2FOpd14gSezpoNlpcHafv2cN6yBWL7ss8J1JCl5KVg6vGpiM6IhqXUEt8M+AbtrdvzXRYhhJB6TsAYY3wXUZfkcjnMzc2RmZkJMzMzvsuptvS9e5GweAmg0cC4Rw84rVsHkYkx32Xp3bPsZ5h6fCpis2JhZ2iHbS9vQ0uLlnyXRQghhCfV+f7mveeGVA3TaJD85TqkbtsGADB//TU4LlgAgbjxXRjysfwxphyfgoScBDiZOGHby9vgbNo4D+EnhBCifxRuGgCNUon4Tz6F/MgRAIDNuzNh8/bbjfJsvPfT72Pq8alIzU+Fq5krtr28DQ7GVTtyjhBCCAEo3NR7arkcT2bMRG5EBGBgAMclS2AxYjjfZdWKmyk38ebfbyJTkYm2lm3xzYBvYG3YuM6uTAghpPZRuKnHVM+eIe7NN6G4Hw2hsTGcvloPk8BAvsuqFZcTL2N6+HTkqHLQ2aYzNvXfBHOpOd9lEUIIaYAo3NRT+bdvI27amyhIToaBnR2ct34DWbt2fJdVK/57+h/eO/Ee8tX58HPww9d9v4axuPENkiaEEFI3GtzlF5qC7NNn8HjceBQkJ0PaujVc9+1ttMEmPDYcM/6ZgXx1Pno49cCmfpso2BBCCHkhFG7qmYyDhxD31lvQ5ObCqGtXuOz+AeJGevblIw+PYPbJ2VBpVBjgMgBf9fkKMgMZ32URQghp4Gi3VD3BGEPKho1I2bgRAGD26lA0W7oUAomE58pqx4F7B7Dk3BIwMLzq/ioWdV8EAyG9HQkhhLw4+japB5hKhfgFC5F56BAAwPqtN2H73nuN8lBvAPjfzf9h9aXVAIDgtsH4JOATCAXUiUgIIUQ/KNzwTJ2djafvvY+cs2cBkQgO8+fDMng032XVCsYYtlzbgk1RmwAAkztOxvtd3m+0IY4QQgg/KNzwSJWYpD3U+84dCAwN0XzdlzDp1Tivds0Yw9rLa7Hz5k4AwEzvmZjaaSoFG0IIIXpH4YYnivv3ETvtTRTEx0NkYwPnzZth2Kkj32XVCg3TYNn5Zdh/bz8A4CO/jzDBYwLPVRFCCGmsKNzwIOf8BTyZOROarCxI3NzgvG0rJM2b811WrSjQFGD+2fn47eFvEECAhd0XYmTrkXyXRQghpBGjcFPHMn/7Dc8++RRQqWDo4wPnjRsgsrDgu6xaoVQrMefUHPwd+zdEAhGW91iOwS0H810WIYSQRo7CTR1hjCF16zYkf/klAMB00EA0W7kSQqmU58pqR15BHj44+QHOPj0LsVCMNb3WoE+LPnyXRQghpAmgcFMHWEEBEpYuRcbefQAAq0mTYPd/H0IgbJyHP+eocjAjfAYuJV6CoYEh1vdZj27NuvFdFiGEkCaCwk0t0+Tm4ums2cg+eRIQCGD/ySewmjCe77JqTaYiE2///Taup1yHidgEm/pvgredN99lEUIIaUIo3NSigpQUxL31NvJv3IBAKkWzL1bDbMAAvsuqNSl5KZj21zTcT78PC6kFtgzYgg7WHfguixBCSBND4aaWKB4+Qty0aVA9eQKRpSWcN2+CoZcX32XVmoScBEw9PhUx8hjYGNpg24BtaGXZiu+yCCGENEEUbmpBbmQknrz9DtSZmRC3aIEW27ZC4uLCd1m1Jk4ehynHp+BZzjM4Gjvi25e/RQuzFnyXRQghpIlqnCNaeSQ/9idiJ06COjMTMs/OcN37Y6MONg8yHiDsWBie5TyDi5kL/jfofxRsCCGE8IrCjR6l7tyJpx98AKZUwqRfP7js3AkDKyu+y6o1t1JvYeKxiUjOS0Zry9bYOXAnHIwd+C6LEEJIE0fhRk8yfvoJSStXAYzBctw4NP9qPYSGhnyXVWuikqLwxp9vIEORgY7WHbEjaAdsDG34LosQQgihMTf6YjZ4MNL3H4DZwIGwmjSxUV8Q8tyzc3jvxHvIK8iDj70PNvTdABOJCd9lEUIIIQAo3OiN0MgIrrt/gEAs5ruUWnUy7iRmnZwFlUaFwGaB+LLPlzA0aLw9VIQQQhoe2i2lR4092Bx7dAwfnPgAKo0K/Vr0w1d9v6JgQwghpN6hcEOq5ND9Q/jo1EcoYAV4peUr+KLXF5CIJHyXRQghhJRCu6VIpX649QNWXVwFABjVZhQ+6/oZhALKxYQQQuonCjekQtuubcNXV74CAIR5hGG27+xGPViaEEJIw0fhhpSJMYb1keux/cZ2AMA7Xu/grc5vUbAhhBBS71G4IaVomAYrI1bixzs/AgA+9P0QYR3CeK6KEEIIqRoKN0QHYwwL/1uIn6N/hgACzOs2D6PajOK7LEIIIaTKKNwQHaefnsbP0T9DJBBhaY+leKXlK3yXRAghhFQLHfJCOIwxbIraBACY4DGBgg0hhJAGicIN4fz75F/cTL0JQwNDTOwwke9yCCGEkBqhcEMA6PbahLQLgbWhNc8VEUIIITVD4YYA0F4z6nbabRgaGGJSh0l8l0MIIYTUGIUbAsYYNl/dDAAY224sLGWWPFdECCGE1ByFG4J/4v7B7bTbMDIworE2hBBCGjwKN02chmmwOUrbazOu/ThYyCz4LYgQQgh5QRRumrh/Yv/B3fS7MBYb01mICSGENAoUbpowDdNg01XtEVLj2o+DudSc54oIIYSQF0fhpgn7+/HfuJ9+HyZiE4R6hPJdDiGEEKIX9SLcbNy4Ea6urpDJZAgICEBERESVltu7dy8EAgGGDx9euwU2Qhqm4Y6Qol4bQgghjQnv4Wbfvn2YNWsWFixYgMjISHh6eiIoKAhJSUkVLhcTE4MPP/wQPXv2rKNKG5fjj48jOiMapmJTTPCYwHc5hBBCiN7wHm7Wrl2LqVOnYtKkSfDw8MCWLVtgZGSE7777rtxl1Go1xo0bh0WLFqFly5Z1WG3joGEabInaAgAY7zGeem0IIYQ0KryGG6VSicuXL6N///7cNKFQiP79++PcuXPlLrd48WLY2dnhjTfeqHQbCoUCcrlc59bUHY85jgeZD2AqNsV4j/F8l0MIIYToFa/hJiUlBWq1Gvb29jrT7e3tkZCQUOYyZ86cwfbt27Ft27YqbWPFihUwNzfnbs7Ozi9cd0Om1qi5sTYTOkyAmcSM54oIIYQQ/eJ9t1R1ZGVlYcKECdi2bRtsbGyqtMzcuXORmZnJ3eLi4mq5yvrtz5g/8TDzIUwlphjfnnptCCGEND4GfG7cxsYGIpEIiYmJOtMTExPh4OBQqv2DBw8QExODoUOHctM0Gg0AwMDAAHfv3oW7u7vOMlKpFFKptBaqb3jUGjW2XNOOtQnzCIOpxJTnigghhBD947XnRiKRwMfHB+Hh4dw0jUaD8PBwdOvWrVT7du3a4fr164iKiuJur776Kvr06YOoqKgmv8upMn/E/IFHmY9gJjHDuPbj+C6HEEIIqRW89twAwKxZsxAWFgZfX1/4+/tj3bp1yMnJwaRJkwAAoaGhcHJywooVKyCTydCxY0ed5S0sLACg1HSiq0BTgG+ufgMACOsQBhOJCc8VEUIIIbWD93ATHByM5ORkzJ8/HwkJCfDy8sKxY8e4QcaxsbEQChvU0KB66Y9HfyBGHgNzqTnGthvLdzmEkAZGrVZDpVLxXQZp5CQSiV6+8wWMMaaHehoMuVwOc3NzZGZmwsysaRwpVKApwPBfh+Ox/DHe6/IepnSawndJhJAGgjGGhIQEZGRk8F0KaQKEQiHc3NwgkUhKzavO9zfvPTek9h19dBSP5Y9hIbXAmHZj+C6HENKAFAUbOzs7GBkZQSAQ8F0SaaQ0Gg2ePXuG+Ph4tGjR4oXeaxRuGrmSY20mdpgIY7ExzxURQhoKtVrNBRtra2u+yyFNgK2tLZ49e4aCggKIxeIar4cGszRyRx4eQWxWLCylltRrQwiplqIxNkZGRjxXQpqKot1RarX6hdZD4aYRU2lUXK/NpI6TYCSmDyhCSPXRrihSV/T1XqNw04gdeXAET7KfwEpmheC2wXyXQwghhNQJCjeNlEqjwjfXtL02kztOpl4bQgjh0c6dO7nzsjUWAoEAv/zyC99llInCTSN1OPownmY/hZXMCqPajOK7HEIIqVMTJ06EQCAodYuOjsapU6cwdOhQNGvWrM6+oIODg3Hv3r1a305FXF1dsW7dOr2tLz4+HoMGDdLb+vSJwk0jpFKrsO269qrp1GtDCGmqBg4ciPj4eJ2bm5sbcnJy4OnpiY0bN9ZZLYaGhrCzs6vx8kqlUo/VlE+tVnPXbKyMg4NDvb12I4WbRujXB7/iafZTWMusMbrtaL7LIYQQXkilUjg4OOjcRCIRBg0ahKVLl2LEiBE1Wq+rqyuWLl2K0NBQmJiYwMXFBYcPH0ZycjKGDRsGExMTdO7cGZcuXeKWKWu31G+//QY/Pz/IZDLY2Njo1OPq6oolS5YgNDQUZmZmmDZtGgDg4MGD6NChA6RSKVxdXbFmzZoq1dy7d288fvwYH3zwAdeLVbKuw4cPw8PDA1KpFLGxsbh48SIGDBgAGxsbmJubo1evXoiMjNRZZ8ler5iYGAgEAhw6dAh9+vSBkZERPD09ce7cueq+vHpB4aaRUalV2HptKwDgjU5vwNDAkOeKCCGNCWMMucoCXm716YT6X375JQIDA3HlyhUMGTIEEyZMQGhoKMaPH4/IyEi4u7sjNDS03Jp///13jBgxAoMHD8aVK1cQHh4Of39/nTZffPEFPD09ceXKFcybNw+XL1/G6NGjERISguvXr2PhwoWYN28edu7cWWm9hw4dQvPmzbF48WKuF6tIbm4uVq1ahW+//RY3b96EnZ0dsrKyEBYWhjNnzuD8+fNo3bo1Bg8ejKysrAq38+mnn+LDDz9EVFQU2rRpgzFjxqCgoKDyF1TP6CR+jczP0T8jPicetoa2NNaGEKJ3eSo1POb/ycu2by0OgpGk6l9bR44cgYlJ8UWCBw0ahAMHDuillsGDB+PNN98EAMyfPx+bN2+Gn58fRo3Sfu7OmTMH3bp1Q2JiIhwcHEotv2zZMoSEhGDRokXcNE9PT502ffv2xezZs7nH48aNQ79+/TBv3jwAQJs2bXDr1i2sXr0aEydOrLBeKysriEQimJqalqpHpVJh06ZNOtvv27evTputW7fCwsIC//77L1555ZVyt/Phhx9iyJAhAIBFixahQ4cOiI6ORrt27SqsT9+o56YRUaqV3FibNzq9AZmBjOeKCCGEP3369EFUVBR3++qrr/S27s6dO3P3iy703KlTp1LTkpKSylw+KioK/fr1q3Abvr6+Oo9v376NwMBAnWmBgYG4f//+C530TiKR6DwfAEhMTMTUqVPRunVrmJubw8zMDNnZ2YiNja1wXSXX4+joCKD816A2Uc9NI/Lz/Z+RkJMAO0M7vN7mdb7LIYQ0QoZiEW4tDuJt29VhbGyMVq1a1UotJS8NUDR+paxp5Q3ONTSsfMiAsXHdXC7H0NCw1MnzwsLCkJqaivXr18PFxQVSqRTdunWrdGBzdV6D2kThppF4vtdGKqqfI9gJIQ2bQCCo1q4hUrbOnTsjPDwckyZNqvIy7du3x9mzZ3WmnT17Fm3atIFIVHnwk0gkVe7hOXv2LDZt2oTBgwcDAOLi4pCSklLlWvlG79BG4uD9g0jMTYSdkR1ea/Ma3+UQQki9lZ2djejoaO7xo0ePEBUVBSsrK7Ro0aJOaliwYAH69esHd3d3hISEoKCgAEePHsWcOXPKXWb27Nnw8/PDkiVLEBwcjHPnzmHDhg3YtGlTlbbp6uqKU6dOISQkBFKpFDY2NuW2bd26NXbt2gVfX1/I5XL83//9X5V6m+oLGnPTCCjUCnx77VsAwJROU6jXhhBCKnDp0iV4e3vD29sbADBr1ix4e3tj/vz5dVZD7969ceDAARw+fBheXl7o27cvIiIiKlymS5cu2L9/P/bu3YuOHTti/vz5WLx4caWDiYssXrwYMTExcHd3h62tbYVtt2/fjvT0dHTp0gUTJkzAu++++0Ln6alrAlafjq2rA3K5HObm5sjMzISZmRnf5ejFntt7sCJiBeyN7HF05FFIRBK+SyKENAL5+fl49OgR3NzcIJPRAQqk9lX0nqvO9zf13DRwCrUC269vBwBM7TSVgg0hhJAmj8JNA/fTvZ+QlJcEB2MHjGhds7NtEkII0Tp9+jRMTEzKvdVXDbXu2kIDihuw/IJ8fHtdO9aGem0IIeTF+fr6Iioqiu8yqq2h1l1bKNw0YAfuHUBKXgqaGTfDiFbUa0MIIS/K0NCw1s6NU5saat21hXZLNVB5BXnFY206T4VYJK5kCUIIIaRpoHDTQO2/ux+p+alwMnHCsFbD+C6HEEIIqTco3DRAuapcfHfjOwDAtM7TIBZSrw0hhBBShMJNA3Tg3gGk5afBycQJQ92H8l0OIYQQUq9QuGlgSvbavNn5Teq1IYQQQp5D4aaB2Xd3H9Ly09DcpDlecX+F73IIIYRUwc6dO2FhYcF3GS9MIBDgl19+4buMSlG4aUByVbnYcWMHAOBNT+q1IYSQ8kycOBECgaDULTo6GqdOncLQoUPRrFmzOvuyDg4Oxr1792p9O0SLwk0D8uOdH5GuSEcL0xZ4pSX12hBCSEUGDhyI+Ph4nZubmxtycnLg6emJjRs31lkthoaGL3ThSaVSqcdqGj8KNw1EjioHO2/uBKDttTEQ0vkXCSGkIlKpFA4ODjo3kUiEQYMGYenSpRgxomYnP3V1dcXSpUsRGhoKExMTuLi44PDhw0hOTsawYcNgYmKCzp0749KlS9wyZe2W+u233+Dn5weZTAYbGxudelxdXbFkyRKEhobCzMwM06ZNAwAcPHgQHTp0gFQqhaurK9asWVOlmj/55BMEBASUmu7p6YnFixcDAC5evIgBAwbAxsYG5ubm6NWrFyIjI6v78tQLFG4aiB/v/IgMRQZczFww2G0w3+UQQpoqxgBlDj83xvh+9pwvv/wSgYGBuHLlCoYMGYIJEyYgNDQU48ePR2RkJNzd3REaGgpWTs2///47RowYgcGDB+PKlSsIDw+Hv7+/TpsvvvgCnp6euHLlCubNm4fLly9j9OjRCAkJwfXr17Fw4ULMmzcPO3furLTecePGISIiAg8ePOCm3bx5E9euXcPYsWMBAFlZWQgLC8OZM2dw/vx5tG7dGoMHD0ZWVlbNXyie0L//DUC2Mru416Yz9doQQnikygWWN+Nn2588AyTGVW5+5MgRnYtGDho0CAcOHNBLKYMHD8abb74JAJg/fz42b94MPz8/jBo1CgAwZ84cdOvWDYmJiXBwcCi1/LJlyxASEoJFixZx0zw9PXXa9O3bF7Nnz+Yejxs3Dv369cO8efMAAG3atMGtW7ewevVqTJw4scJ6O3ToAE9PT+zZs4dbfvfu3QgICOAu29C3b1+dZbZu3QoLCwv8+++/eOWVhjUUgnpuGoA9d/YgU5EJVzNX6rUhhJAq6tOnD6KiorjbV199pbd1d+7cmbtvb28PAOjUqVOpaUlJSWUuHxUVhX79+lW4DV9fX53Ht2/fRmBgoM60wMBA3L9/H2q1utKax40bhz179gAAGGP48ccfMW7cOG5+YmIipk6ditatW8Pc3BxmZmbIzs5GbGxspeuub6gLoJ7LVmbj+5vfA9COtREJRTxXRAhp0sRG2h4UvrZdDcbGxrV2MUmxuPhoVYFAUO40jUZT5vKGhoaVbsPYuOq9VFUxZswYzJkzB5GRkcjLy0NcXByCg4O5+WFhYUhNTcX69evh4uICqVSKbt26NcjBzBRu6rndt3dDrpTDzdwNg1wH8V0OIaSpEwiqtWuIlK1z584IDw/HpEmTqrxM+/btcfbsWZ1pZ8+eRZs2bSASVf6Pb/PmzdGrVy/s3r0beXl5GDBggM4RXGfPnsWmTZsweLB2D0FcXBxSUlKqXF99QuGmHstSZuH7W9pem7c6v0W9NoQQogfZ2dmIjo7mHj969AhRUVGwsrJCixYt6qSGBQsWoF+/fnB3d0dISAgKCgpw9OhRzJkzp9xlZs+eDT8/PyxZsgTBwcE4d+4cNmzYgE2bNlV5u+PGjcOCBQugVCrx5Zdf6sxr3bo1du3aBV9fX8jlcvzf//1flXqY6iMac1OP/XD7B2Qps9DSvCWCXIP4LocQQhqFS5cuwdvbG97e3gCAWbNmwdvbG/Pnz6+zGnr37o0DBw7g8OHD8PLyQt++fREREVHhMl26dMH+/fuxd+9edOzYEfPnz8fixYsrHUxc0uuvv47U1FTk5uZi+PDhOvO2b9+O9PR0dOnSBRMmTMC77777Qufm4ZOAlXecWiMll8thbm6OzMxMmJmZ8V1OueRKOQb+NBBZqiysfmk1BroN5LskQkgTk5+fj0ePHsHNzQ0ymYzvckgTUNF7rjrf39RzU0/9cOsHZKmy0MqiFV52fZnvcgghhJAGg8JNPZSpyMSuW7sAAG95vgWhgH5NhBBSF06fPg0TE5Nyb/VVQ627ttCA4npo161dyFZlo5VFKwxwGcB3OYQQ0mT4+voiKiqK7zKqraHWXVso3NQzmYpM7L69GwDwtufb1GtDCCF1yNDQsNbOjVObGmrdtYW+OeuZ/936H7JV2Whj2Qb9XfrzXQ4hhBDS4NSLcLNx40a4urpCJpMhICCgwsPhDh06BF9fX1hYWMDY2BheXl7YtWtXHVZbe6jXhhBCCHlxvH977tu3D7NmzcKCBQsQGRkJT09PBAUFlXs9DisrK3z66ac4d+4crl27hkmTJmHSpEn4888/67hy/fv+5vfIUeWgrWVb9G3Rt/IFCCGEEFIK7+Fm7dq1mDp1KiZNmgQPDw9s2bIFRkZG+O6778ps37t3b4wYMQLt27eHu7s73nvvPXTu3Blnzpyp48r1Kz0/vbjXxot6bQghhJCa4vUbVKlU4vLly+jfv3hsiVAoRP/+/XHu3LlKl2eMITw8HHfv3sVLL71UZhuFQgG5XK5zq4++v/k9cgty0d6qPfo6U68NIYQQUlO8hpuUlBSo1Wru0vBF7O3tkZCQUO5ymZmZMDExgUQiwZAhQ/D1119jwICyD5lesWIFzM3NuZuzs7Nen4M+pOWnYc8d7WXo3/Z8m7uaLCGEENJQnDx5EgKBABkZGXyXwv9uqZowNTVFVFQULl68iGXLlmHWrFk4efJkmW3nzp2LzMxM7hYXF1e3xVbBzps7kVeQBw9rD/R27s13OYQQ0uBNnDgRAoGg1C06OhqnTp3C0KFD0axZMwgEAvzyyy98l8uLmJgYCAQCvZ0fp3v37oiPj4e5uble1vcieD3PjY2NDUQiERITE3WmJyYmwsHBodzlhEIhdzy/l5cXbt++jRUrVqB3796l2kqlUkilUr3WrU9p+WnYe2cvAOAdz3eo14YQQvRk4MCB2LFjh840W1tb3L9/H56enpg8eTJGjhzJU3UvTqVSQSwW1/p2lEolJBJJpe0kEkmF3911ideeG4lEAh8fH4SHh3PTNBoNwsPD0a1btyqvR6PRQKFQ1EaJtW7nDW2vTQfrDnipednjhgghhFSfVCqFg4ODzk0kEmHQoEFYunQpRowYUaP1urq6YunSpQgNDYWJiQlcXFxw+PBhJCcnY9iwYTAxMUHnzp1x6dIlbpnU1FSMGTMGTk5OMDIyQqdOnfDjjz/qrFej0eDzzz9Hq1atIJVK0aJFCyxbtgxAcS/Lvn370KtXL8hkMuzevRsajQaLFy9G8+bNIZVK4eXlhWPHjlXpebi5uQEAvL29IRAIuA6CiRMnYvjw4Vi2bBmaNWuGtm3bAgB27doFX19fmJqawsHBAWPHjtU5svn53VI7d+6EhYUF/vzzT7Rv3x4mJiYYOHAg4uPja/S6Vwfvu6VmzZqFbdu24fvvv8ft27fx9ttvIycnB5MmTQIAhIaGYu7cuVz7FStW4K+//sLDhw9x+/ZtrFmzBrt27cL48eP5ego1lpqXir13C3ttvKjXhhBS/zHGkKvK5eXGGOP76XO+/PJLBAYG4sqVKxgyZAgmTJiA0NBQjB8/HpGRkXB3d0doaChXc35+Pnx8fPD777/jxo0bmDZtGiZMmKBzXre5c+di5cqVmDdvHm7duoU9e/aUGpP68ccf47333sPt27cRFBSE9evXY82aNfjiiy9w7do1BAUF4dVXX8X9+/crfQ5F2/77778RHx+PQ4cOcfOKDtb566+/cOTIEQDanqIlS5bg6tWr+OWXXxATE4OJEydWuI3c3Fx88cUX2LVrF06dOoXY2Fh8+OGHVXqNXwTvl18IDg5GcnIy5s+fj4SEBC51Fv1CY2NjIRQWZ7CcnBy88847ePLkCQwNDdGuXTv88MMPCA4O5usp1NiOGzuQV5CHTjad0NOpJ9/lEEJIpfIK8hCwJ4CXbV8YewFGYqMqtz9y5IjORSMHDRqEAwcO6KWWwYMH48033wQAzJ8/H5s3b4afnx9GjRoFAJgzZw66devGDbNwcnLS+VKfOXMm/vzzT+zfvx/+/v7IysrC+vXrsWHDBoSFhQEA3N3d0aNHD53tvv/++zq70r744gvMmTMHISEhAIBVq1bhxIkTWLduHTZu3Fjhc7C1tQUAWFtbl9qdZGxsjG+//VZnd9TkyZO5+y1btsRXX30FPz8/ZGdnl3txTpVKhS1btsDd3R0AMGPGDCxevLjCuvSB93ADaJ/sjBkzypz3/EDhpUuXYunSpXVQVe1KyUvBvrv7ANARUoQQUhv69OmDzZs3c4+NjY31tu7OnTtz94v+Ge/UqVOpaUlJSXBwcIBarcby5cuxf/9+PH36FEqlEgqFAkZG2rB2+/ZtKBQK9OvXr8Lt+vr6cvflcjmePXuGwMBAnTaBgYG4evXqCz2/Tp06lRpnc/nyZSxcuBBXr15Feno6NBoNAG0nhIeHR5nrMTIy4oINADg6OpZ7kl59qhfhpin67sZ3yFfno7NNZ/Rw6lH5AoQQUg8YGhjiwtgLvG27OoyNjWvtYpIlB/IW/XNa1rSiALB69WqsX78e69atQ6dOnWBsbIz3338fSqUSgPbCl1Whz4BWne3k5OQgKCgIQUFB2L17N2xtbREbG4ugoCDuOZTl+QHPAoGgTnYvUrjhQXJuMvbf3Q+AxtoQQhoWgUBQrV1DROvs2bMYNmwYNz5Uo9Hg3r17XI9H69atYWhoiPDwcEyZMqVK6zQzM0OzZs1w9uxZ9OrVS2db/v7+lS5f1DOjVqsrbXvnzh2kpqZi5cqV3PniSg6Yrm8o3PDguxvfQaFWwNPWE92bdee7HEIIaVKys7MRHR3NPX706BGioqJgZWWFFi1a1Mo2W7dujZ9++gn//fcfLC0tsXbtWiQmJnLhRiaTYc6cOfjoo48gkUgQGBiI5ORk3Lx5E2+88Ua56/2///s/LFiwAO7u7vDy8sKOHTsQFRWF3bt3V1qTnZ0dDA0NcezYMTRv3hwymazcc9S0aNECEokEX3/9Nd566y3cuHEDS5YsqdmLUQd4P1qqqUnKTaJeG0II4dGlS5fg7e0Nb29vANqjdr29vTF//vxa2+Znn32GLl26ICgoCL1794aDgwOGDx+u02bevHmYPXs25s+fj/bt2yM4OLjS8SnvvvsuZs2ahdmzZ6NTp044duwYDh8+jNatW1dak4GBAb766it88803aNasGYYNG1ZuW1tbW+zcuRMHDhyAh4cHVq5ciS+++KJKz50PAlafjq2rA3K5HObm5sjMzISZmVmdb39lxErsvr0b3nbe+H7g9xRuCCH1Vn5+Ph49egQ3NzfIZDK+yyFNQEXvuep8f1PPTR1KzEnEgbvawxDpCClCCCGkdlC4qUPbb2yHUqNEF7su6OrYle9yCCGEPOf06dMwMTEp99aQLF++vNznMWjQIL7Lq1U0oLiOJOQk4Kd7PwGgsTaEEFJf+fr66u1Cknx76623MHr06DLnVfXQ84aKwk0d+fb6t1BpVPCx94G/Q+WH6BFCCKl7hoaGtXZunLpmZWUFKysrvsvgBe2WqgMJOQk4dF97zY7pXtOp14YQQgipRRRu6sC2a9ug0qjg5+AHPwc/vsshhBBCGjUKN7XsWfYzHIrW9tq84/kOz9UQQgghjR+Fm1r27fVvUaApQIBDAHwdfCtfgBBCCCEvhMJNLXqW/Qw/R/8MAHjb622eqyGEEEKaBgo3tWjrta3aXhvHAPjY+/BdDiGEEJ7s3LkTFhYWfJfxwgQCAX755Re+y6gUhZta8iTrCX6N/hWA9ggpQgghdWfixIkQCASlbtHR0Th16hSGDh2KZs2a1dmXdXBwMO7du1fr2yFaFG5qybbr21DACtDNsRu87bz5LocQQpqcgQMHIj4+Xufm5uaGnJwceHp6YuPGjXVWi6GhIezs7Gq8vFKp1GM1jR+Fm1oQlxXH9dq840VHSBFCCB+kUikcHBx0biKRCIMGDcLSpUsxYsSIGq3X1dUVS5cuRWhoKExMTODi4oLDhw8jOTkZw4YNg4mJCTp37oxLly5xy5S1W+q3336Dn58fZDIZbGxsdOpxdXXFkiVLEBoaCjMzM0ybNg0AcPDgQXTo0AFSqRSurq5Ys2ZNlWr+5JNPEBAQUGq6p6cnFi9eDAC4ePEiBgwYABsbG5ibm6NXr16IjIys7stTL1C4qQVbr22FmqkR2CwQXnZefJdDCCF6wxiDJjeXlxtjjO+nz/nyyy8RGBiIK1euYMiQIZgwYQJCQ0Mxfvx4REZGwt3dHaGhoeXW/Pvvv2PEiBEYPHgwrly5gvDwcPj76569/osvvoCnpyeuXLmCefPm4fLlyxg9ejRCQkJw/fp1LFy4EPPmzcPOnTsrrXfcuHGIiIjAgwcPuGk3b97EtWvXMHbsWABAVlYWwsLCcObMGZw/fx6tW7fG4MGDkZWVVfMXiid0+QU9i5XH4rcHvwGgXhtCSOPD8vJwtws/B0i0jbwMgZFRldsfOXJE52KXgwYNwoEDB/RSy+DBg/Hmm28CAObPn4/NmzfDz88Po0aNAgDMmTMH3bp1Q2JiIhwcHEotv2zZMoSEhGDRokXcNE9PT502ffv2xezZs7nH48aNQ79+/TBv3jwAQJs2bXDr1i2sXr0aEydOrLDeDh06wNPTE3v27OGW3717NwICArjLTfTt21dnma1bt8LCwgL//vsvXnnllaq8LPUG9dzo2TfXvoGaqdHDqQc623bmuxxCCGmy+vTpg6ioKO721Vdf6W3dnTsXf77b29sDADp16lRqWlJSUpnLR0VFoV+/fhVuw9dX99xot2/fRmBgoM60wMBA3L9/H2q1utKax40bhz179gDQ9sD9+OOPGDduHDc/MTERU6dORevWrWFubg4zMzNkZ2cjNja20nXXN9Rzo0ex8lj8/vB3AHQ2YkJI4yQwNETbyMu8bbs6jI2Na+0imGKxmLtfdL3AsqZpNJoyl6/KVbmNjY1fpMRSxowZgzlz5iAyMhJ5eXmIi4tDcHAwNz8sLAypqalYv349XFxcIJVK0a1btwY5mJnCjR4V9dq81PwldLLtVPkChBDSwAgEgmrtGiJl69y5M8LDwzFp0qQqL9O+fXucPXtWZ9rZs2fRpk0biESiSpdv3rw5evXqhd27dyMvLw8DBgzQOYLr7Nmz2LRpEwYPHgwAiIuLQ0pKSpXrq08o3OhJTGYMjjw8AgB425PORkwIIfVVdnY2oqOjucePHj1CVFQUrKys0KJFizqpYcGCBejXrx/c3d0REhKCgoICHD16FHPmzCl3mdmzZ8PPzw9LlixBcHAwzp07hw0bNmDTpk1V3u64ceOwYMECKJVKfPnllzrzWrdujV27dsHX1xdyuRz/93//V6UepvqIxtzoybOcZ7CR2aBX817oaNOR73IIIYSU49KlS/D29oa3t/YcZLNmzYK3tzfmz59fZzX07t0bBw4cwOHDh+Hl5YW+ffsiIiKiwmW6dOmC/fv3Y+/evejYsSPmz5+PxYsXVzqYuKTXX38dqampyM3NxfDhw3Xmbd++Henp6ejSpQsmTJiAd99994XOzcMnAatPx9bVAblcDnNzc2RmZsLMzEyv61aoFZAr5LA1stXregkhhA/5+fl49OgR3NzcIJPJ+C6HNAEVveeq8/1NPTd6JBVJKdgQQgghPKNwQwghhBQ6ffo0TExMyr3VVw217tpCA4oJIYSQQr6+voiKiuK7jGprqHXXFgo3hBBCSCFDQ8NaOzdObWqoddcW2i1FCCGEkEaFwg0hhJAKNbGDagmP9PVeo3BDCCGkTEWXE8jNzeW5EtJUFF3qoSpnXK4IjbkhhBBSJpFIBAsLC+7ij0ZGRtw1kwjRN41Gg+TkZBgZGcHA4MXiCYUbQggh5XJwcABQ/tWtCdEnoVCIFi1avHCIpnBDCCGkXAKBAI6OjrCzs4NKpeK7HNLISSQSCIUvPmKGwg0hhJBKiUSiFx4HQUhdoQHFhBBCCGlUKNwQQgghpFGhcEMIIYSQRqXJjbkpOkGQXC7nuRJCCCGEVFXR93ZVTvTX5MJNVlYWAMDZ2ZnnSgghhBBSXVlZWTA3N6+wjYA1sfNqazQaPHv2DKampno/GZVcLoezszPi4uJgZmam13WT6qPfR/1Cv4/6hX4f9Q/9TirGGENWVhaaNWtW6eHiTa7nRigUonnz5rW6DTMzM3pj1iP0+6hf6PdRv9Dvo/6h30n5KuuxKUIDigkhhBDSqFC4IYQQQkijQuFGj6RSKRYsWACpVMp3KQT0+6hv6PdRv9Dvo/6h34n+NLkBxYQQQghp3KjnhhBCCCGNCoUbQgghhDQqFG4IIYQQ0qhQuCGEEEJIo0LhRk82btwIV1dXyGQyBAQEICIigu+SmqwVK1bAz88PpqamsLOzw/Dhw3H37l2+yyKFVq5cCYFAgPfff5/vUpqsp0+fYvz48bC2toahoSE6deqES5cu8V1Wk6RWqzFv3jy4ubnB0NAQ7u7uWLJkSZWun0TKR+FGD/bt24dZs2ZhwYIFiIyMhKenJ4KCgpCUlMR3aU3Sv//+i+nTp+P8+fP466+/oFKp8PLLLyMnJ4fv0pq8ixcv4ptvvkHnzp35LqXJSk9PR2BgIMRiMf744w/cunULa9asgaWlJd+lNUmrVq3C5s2bsWHDBty+fRurVq3C559/jq+//prv0ho0OhRcDwICAuDn54cNGzYA0F6/ytnZGTNnzsTHH3/Mc3UkOTkZdnZ2+Pfff/HSSy/xXU6TlZ2djS5dumDTpk1YunQpvLy8sG7dOr7LanI+/vhjnD17FqdPn+a7FALglVdegb29PbZv385Ne+2112BoaIgffviBx8oaNuq5eUFKpRKXL19G//79uWlCoRD9+/fHuXPneKyMFMnMzAQAWFlZ8VxJ0zZ9+nQMGTJE52+F1L3Dhw/D19cXo0aNgp2dHby9vbFt2za+y2qyunfvjvDwcNy7dw8AcPXqVZw5cwaDBg3iubKGrcldOFPfUlJSoFarYW9vrzPd3t4ed+7c4akqUkSj0eD9999HYGAgOnbsyHc5TdbevXsRGRmJixcv8l1Kk/fw4UNs3rwZs2bNwieffIKLFy/i3XffhUQiQVhYGN/lNTkff/wx5HI52rVrB5FIBLVajWXLlmHcuHF8l9agUbghjdr06dNx48YNnDlzhu9Smqy4uDi89957+OuvvyCTyfgup8nTaDTw9fXF8uXLAQDe3t64ceMGtmzZQuGGB/v378fu3buxZ88edOjQAVFRUXj//ffRrFkz+n28AAo3L8jGxgYikQiJiYk60xMTE+Hg4MBTVQQAZsyYgSNHjuDUqVNo/v/t3V9IU/0Dx/HPcaVsY8VSqslDZRQypT/USpZdVF6kQVAYYoyYBYmlEklBUZZdWBeBRQiDQXnVH7BYSVFB6yIQwohmu7A/V93EsOjGLfKinefigcHweX78fr/HdvLs/YIDO9/vpp/vlR/O+Z75xx9Wxylar1+/1uTkpDZs2JAb+/nzp168eKHBwUFNT0/L4XBYmLC4+Hw+1dTU5I35/X7du3fPokTF7eTJkzp16pRaW1slSWvWrNGnT5906dIlys2/wJ6bf6m0tFQbN25UPB7PjWWzWcXjcQWDQQuTFS/TNNXV1aVYLKbnz5+rqqrK6khFraGhQclkUolEIncEAgGFQiElEgmKTYHV19fP+GqEDx8+aPny5RYlKm7fv39XSUn+n2KHw6FsNmtRInvgys0s6OnpUTgcViAQ0ObNm3X16lVlMhkdPHjQ6mhFqbOzU7du3dKDBw/k8XiUSqUkSQsXLpTT6bQ4XfHxeDwz9ju53W6Vl5ezD8oCx48f15YtW3Tx4kW1tLRobGxM0WhU0WjU6mhFaffu3erv79eyZctUW1urN2/eaGBgQIcOHbI62pzGo+CzZHBwUJcvX1YqldL69et17do11dXVWR2rKBmG8bfjQ0NDamtrK2wY/K1t27bxKLiFHj58qNOnT+vjx4+qqqpST0+PDh8+bHWsojQ1NaXe3l7FYjFNTk6qsrJS+/fv17lz51RaWmp1vDmLcgMAAGyFPTcAAMBWKDcAAMBWKDcAAMBWKDcAAMBWKDcAAMBWKDcAAMBWKDcAAMBWKDcAip5hGLp//77VMQDMEsoNAEu1tbXJMIwZR2Njo9XRAMxR/G8pAJZrbGzU0NBQ3lhZWZlFaQDMdVy5AWC5srIyLV26NO/wer2S/rplFIlE1NTUJKfTqZUrV+ru3bt5n08mk9qxY4ecTqfKy8vV3t6udDqd954bN26otrZWZWVl8vl86urqypv/+vWr9u7dK5fLpdWrV2tkZOTXLhrAL0O5AfDb6+3tVXNzs8bHxxUKhdTa2qqJiQlJUiaT0c6dO+X1evXq1SsNDw/r2bNneeUlEomos7NT7e3tSiaTGhkZ0apVq/J+x4ULF9TS0qK3b99q165dCoVC+vbtW0HXCWCWmABgoXA4bDocDtPtducd/f39pmmapiSzo6Mj7zN1dXXmkSNHTNM0zWg0anq9XjOdTufmHz16ZJaUlJipVMo0TdOsrKw0z5w5848ZJJlnz57NnafTaVOS+fjx41lbJ4DCYc8NAMtt375dkUgkb2zRokW518FgMG8uGAwqkUhIkiYmJrRu3Tq53e7cfH19vbLZrN6/fy/DMPT582c1NDT8xwxr167NvXa73VqwYIEmJyf/3yUBsBDlBoDl3G73jNtEs8XpdP5X75s/f37euWEYymazvyISgF+MPTcAfnsvX76cce73+yVJfr9f4+PjymQyufnR0VGVlJSourpaHo9HK1asUDweL2hmANbhyg0Ay01PTyuVSuWNzZs3TxUVFZKk4eFhBQIBbd26VTdv3tTY2JiuX78uSQqFQjp//rzC4bD6+vr05csXdXd368CBA1qyZIkkqa+vTx0dHVq8eLGampo0NTWl0dFRdXd3F3ahAAqCcgPAck+ePJHP58sbq66u1rt37yT99STTnTt3dPToUfl8Pt2+fVs1NTWSJJfLpadPn+rYsWPatGmTXC6XmpubNTAwkPtZ4XBYP3780JUrV3TixAlVVFRo3759hVsggIIyTNM0rQ4BAP/EMAzFYjHt2bPH6igA5gj23AAAAFuh3AAAAFthzw2A3xp3zgH8r7hyAwAAbIVyAwAAbIVyAwAAbIVyAwAAbIVyAwAAbIVyAwAAbIVyAwAAbIVyAwAAbIVyAwAAbOVPEIoJbDu8L78AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(train_f1_micros, label='F1_micro_train')\n",
        "ax.plot(val_f1_micros, label='F1_micro_val')\n",
        "ax.plot(train_f1_macros, label='F1_macro_train')\n",
        "ax.plot(val_f1_macros, label='F1_micro_val')\n",
        "ax.set_title(model_name)\n",
        "ax.set(xlabel='Epoch', ylabel='Loss')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pVD7IpU8HWu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "242586dd62d544a39c122c7b1ed6efc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78cb1778f71b45b88ffdb20bfe0cd66e",
              "IPY_MODEL_6d83c78727204f529982e56c3bfe32c1",
              "IPY_MODEL_55191ea6a8eb4574aff8a9bc21fdd55a"
            ],
            "layout": "IPY_MODEL_ae7f4e349b634abd8b36184774421f7a"
          }
        },
        "4146164713eb4c2db70cf52335398a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55191ea6a8eb4574aff8a9bc21fdd55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b17d80f4da05457781be26c19a1dca17",
            "placeholder": "​",
            "style": "IPY_MODEL_8e403bce502349d28da4553899f80c33",
            "value": " 160M/160M [00:00&lt;00:00, 331MB/s]"
          }
        },
        "6d83c78727204f529982e56c3bfe32c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4146164713eb4c2db70cf52335398a3e",
            "max": 167502836,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e66226838c994913b2d58fd0db3f4282",
            "value": 167502836
          }
        },
        "78cb1778f71b45b88ffdb20bfe0cd66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e012c54a3a9f48b38c500c17227f67b8",
            "placeholder": "​",
            "style": "IPY_MODEL_91eb94ac4f6347c6b7d860b73e3742da",
            "value": "100%"
          }
        },
        "8e403bce502349d28da4553899f80c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91eb94ac4f6347c6b7d860b73e3742da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae7f4e349b634abd8b36184774421f7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b17d80f4da05457781be26c19a1dca17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e012c54a3a9f48b38c500c17227f67b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e66226838c994913b2d58fd0db3f4282": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
