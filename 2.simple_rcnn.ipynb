{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ8-zW_yJ279"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis-R-V/TSR/blob/main/2.simple_rcnn.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xtJ8o7tJ27-"
      },
      "source": [
        "# Система распознавания дорожных знаков на датасете RTSD\n",
        "## Простой вариант обучения Faster R-CNN для детекции 155 классов (слабый baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "colab = False\n",
        "\n",
        "if colab == True:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    !pip install kaggle\n",
        "    !mkdir ~/.kaggle\n",
        "    !cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "    !kaggle datasets download watchman/rtsd-dataset\n",
        "    !unzip rtsd-dataset.zip -d ./data/RTSD\n",
        "    !rm rtsd-dataset.zip\n",
        "    !cp -r data/RTSD/rtsd-frames/rtsd-frames/ data/RTSD/\n",
        "    !rm -r data/RTSD/rtsd-frames/rtsd-frames/\n",
        "    !pip install fiftyone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import fiftyone as fo\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.transforms import functional as func"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Пути и параметры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NVIDIA GeForce RTX 3090\n"
          ]
        }
      ],
      "source": [
        "dataset_path = 'data/RTSD'\n",
        "checkpoints_path = 'checkpoints' if colab == False else '../content/drive/MyDrive/TSR/checkpoints'\n",
        "model_name = 'resnet50v2_all_classes'\n",
        "\n",
        "n_epochs = 10\n",
        "batch_size = 8\n",
        "num_classes = 156\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(torch.cuda.get_device_name(0) if device.type == 'cuda' else device.type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Загрузчик данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RTSD_dataset(Dataset):\n",
        "    '''\n",
        "    Faster R-CNN при обучении ожидает на вход:\n",
        "    - список тензоров размерностью [C, H, W] для каждого изображения со значениями в диапазоне 0-1\n",
        "    - таргет: список словарей с ключами:\n",
        "                - boxes (FloatTensor[N, 4]): ограничивающие рамки ground-truth в формате [x1, y1, x2, y2], с 0 <= x1 < x2 <= W и 0 <= y1 < y2 <= H.\n",
        "                - labels (Int64Tensor[N]): метки классов для каждой ограничивающей рамки ground-truth (включая background)\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    def __init__(self, root, annotation, transforms=None):\n",
        "        super().__init__()\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.coco = COCO(annotation)\n",
        "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Файл coco\n",
        "        coco = self.coco\n",
        "        # Image ID\n",
        "        img_id = self.ids[index]\n",
        "        # List: получение ID аннотаций из coco\n",
        "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
        "        # Dictionary: загрузка аннатаций для изображения\n",
        "        coco_annotation = coco.loadAnns(ann_ids)\n",
        "        # Путь к изображению\n",
        "        path = coco.loadImgs(img_id)[0]['file_name']\n",
        "        # Загрузка изображения\n",
        "        img = Image.open(os.path.join(self.root, path))\n",
        "\n",
        "        # Количество объектов на изображении\n",
        "        num_objs = len(coco_annotation)\n",
        "        \n",
        "        # Bounding boxes для объектов\n",
        "        # В coco формате bbox = [xmin, ymin, width, height]\n",
        "        # Для pytorch bbox должны быть в формате [xmin, ymin, xmax, ymax]\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        for i in range(num_objs):\n",
        "            xmin = coco_annotation[i]['bbox'][0]\n",
        "            ymin = coco_annotation[i]['bbox'][1]\n",
        "            xmax = xmin + coco_annotation[i]['bbox'][2]\n",
        "            ymax = ymin + coco_annotation[i]['bbox'][3]\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            labels.append(coco_annotation[i]['category_id'])\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        # Метки классов\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        # Аннотация в формате словаря\n",
        "        my_annotation = {}\n",
        "        my_annotation[\"boxes\"] = boxes\n",
        "        my_annotation[\"labels\"] = labels\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, my_annotation\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# преобразование изображения в тензор\n",
        "def get_transform():\n",
        "    custom_transforms = []\n",
        "    custom_transforms.append(torchvision.transforms.ToTensor())\n",
        "    return torchvision.transforms.Compose(custom_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.36s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "train_dataset = RTSD_dataset(root=dataset_path,\n",
        "                             annotation=os.path.join(dataset_path, 'train_anno.json'),\n",
        "                             transforms=get_transform()\n",
        "                             )\n",
        "\n",
        "val_dataset = RTSD_dataset(root=dataset_path,\n",
        "                           annotation=os.path.join(dataset_path, 'val_anno.json'),\n",
        "                           transforms=get_transform()\n",
        "                           )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TnfiyYUJ28Z"
      },
      "source": [
        "### Формирование батча"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ltY8LK2BJ28Z"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "val_data_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "for data in train_data_loader:\n",
        "    images, targets = data[0], data[1]\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'boxes': tensor([[1065.,  121., 1129.,  184.],\n",
              "          [1069.,  183., 1134.,  245.]]),\n",
              "  'labels': tensor([57,  4])},\n",
              " {'boxes': tensor([[1079.,  331., 1108.,  358.]]), 'labels': tensor([7])},\n",
              " {'boxes': tensor([[1094.,  273., 1128.,  306.]]), 'labels': tensor([26])},\n",
              " {'boxes': tensor([[   0.,  332.,   62.,  394.],\n",
              "          [   0.,  407.,   63.,  438.],\n",
              "          [1428.,  270., 1463.,  336.],\n",
              "          [1414.,  338., 1473.,  370.]]),\n",
              "  'labels': tensor([  7, 122,   7, 122])},\n",
              " {'boxes': tensor([[855., 289., 885., 318.],\n",
              "          [856., 320., 882., 344.]]),\n",
              "  'labels': tensor([ 1, 63])},\n",
              " {'boxes': tensor([[ 769.,  311.,  801.,  343.],\n",
              "          [1085.,  320., 1108.,  342.],\n",
              "          [ 728.,  344.,  748.,  362.]]),\n",
              "  'labels': tensor([1, 7, 7])},\n",
              " {'boxes': tensor([[839., 300., 900., 358.],\n",
              "          [841., 358., 900., 388.]]),\n",
              "  'labels': tensor([2, 5])},\n",
              " {'boxes': tensor([[230., 276., 264., 310.]]), 'labels': tensor([15])})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo40ASBXJ28Z"
      },
      "source": [
        "### Инициализация модели, задание оптимизатора и функции потерь"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HNRGcfkIJ28Z"
      },
      "outputs": [],
      "source": [
        "def create_model(num_classes):\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(weights='FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT')\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZdWxX5-PJ28Z"
      },
      "outputs": [],
      "source": [
        "model = create_model(num_classes=num_classes).to(device)\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "                            momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "# learning rate scheduler уменьшает learning rate в 10 раз каждые 3 эпохи\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                               step_size=3,\n",
        "                                               gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YimGoL3J28Z"
      },
      "source": [
        "### Трейн луп"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "A7iQ-nA4J28Z"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, epoch): \n",
        "    len_dataloader = len(train_dataloader)\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for i, data in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        images, targets = data[0], data[1]\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        loss_dict = model(images, targets)\n",
        "        loss = sum(loss for loss in loss_dict.values())\n",
        "        running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if i % 50 == 0:\n",
        "            print(f\"\\tЭпоха {epoch}. Итерация {i}/{len_dataloader} на обучающей выборке. Loss: {loss}\")\n",
        "    train_loss = running_loss/len(train_dataloader.dataset)\n",
        "    return train_loss\n",
        "\n",
        "def val(val_dataloader, epoch):\n",
        "    len_dataloader = len(val_dataloader)\n",
        "    running_loss = 0\n",
        "    for i, data in enumerate(val_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        images, targets = data[0], data[1]\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        with torch.no_grad():\n",
        "            loss_dict = model(images, targets)\n",
        "        loss = sum(loss for loss in loss_dict.values())\n",
        "        running_loss += loss.item()\n",
        "        if i % 50 == 0:\n",
        "            print(f\"\\tЭпоха {epoch}. Итерация {i}/{len_dataloader} на тестовой выборке. Loss: {loss}\")\n",
        "    val_loss = running_loss/len(val_dataloader.dataset)\n",
        "    return val_loss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPWlmt4_J28a",
        "outputId": "6907b343-fdc4-4118-d3d1-62247206d21a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tЭпоха 0. Итерация 0/6774 на обучающей выборке. Loss: 4.870737075805664\n",
            "\tЭпоха 0. Итерация 50/6774 на обучающей выборке. Loss: 0.2959800660610199\n",
            "\tЭпоха 0. Итерация 100/6774 на обучающей выборке. Loss: 0.4345476031303406\n",
            "\tЭпоха 0. Итерация 150/6774 на обучающей выборке. Loss: 0.26420533657073975\n",
            "\tЭпоха 0. Итерация 200/6774 на обучающей выборке. Loss: 0.4213874936103821\n",
            "\tЭпоха 0. Итерация 250/6774 на обучающей выборке. Loss: 0.24070952832698822\n",
            "\tЭпоха 0. Итерация 300/6774 на обучающей выборке. Loss: 0.15361906588077545\n",
            "\tЭпоха 0. Итерация 350/6774 на обучающей выборке. Loss: 0.23922733962535858\n",
            "\tЭпоха 0. Итерация 400/6774 на обучающей выборке. Loss: 0.498391717672348\n",
            "\tЭпоха 0. Итерация 450/6774 на обучающей выборке. Loss: 0.3942912220954895\n",
            "\tЭпоха 0. Итерация 500/6774 на обучающей выборке. Loss: 0.29100939631462097\n",
            "\tЭпоха 0. Итерация 550/6774 на обучающей выборке. Loss: 0.21472826600074768\n",
            "\tЭпоха 0. Итерация 600/6774 на обучающей выборке. Loss: 0.12603454291820526\n",
            "\tЭпоха 0. Итерация 650/6774 на обучающей выборке. Loss: 0.4610670506954193\n",
            "\tЭпоха 0. Итерация 700/6774 на обучающей выборке. Loss: 0.18387025594711304\n",
            "\tЭпоха 0. Итерация 750/6774 на обучающей выборке. Loss: 0.2339681088924408\n",
            "\tЭпоха 0. Итерация 800/6774 на обучающей выборке. Loss: 0.14893901348114014\n",
            "\tЭпоха 0. Итерация 850/6774 на обучающей выборке. Loss: 0.1396195888519287\n",
            "\tЭпоха 0. Итерация 900/6774 на обучающей выборке. Loss: 0.21699219942092896\n",
            "\tЭпоха 0. Итерация 950/6774 на обучающей выборке. Loss: 0.08351306617259979\n",
            "\tЭпоха 0. Итерация 1000/6774 на обучающей выборке. Loss: 0.26553836464881897\n",
            "\tЭпоха 0. Итерация 1050/6774 на обучающей выборке. Loss: 0.2019454538822174\n",
            "\tЭпоха 0. Итерация 1100/6774 на обучающей выборке. Loss: 0.19605018198490143\n",
            "\tЭпоха 0. Итерация 1150/6774 на обучающей выборке. Loss: 0.17296336591243744\n",
            "\tЭпоха 0. Итерация 1200/6774 на обучающей выборке. Loss: 0.17629018425941467\n",
            "\tЭпоха 0. Итерация 1250/6774 на обучающей выборке. Loss: 0.20221467316150665\n",
            "\tЭпоха 0. Итерация 1300/6774 на обучающей выборке. Loss: 0.11805036664009094\n",
            "\tЭпоха 0. Итерация 1350/6774 на обучающей выборке. Loss: 0.13742142915725708\n",
            "\tЭпоха 0. Итерация 1400/6774 на обучающей выборке. Loss: 0.19941076636314392\n",
            "\tЭпоха 0. Итерация 1450/6774 на обучающей выборке. Loss: 0.15832215547561646\n",
            "\tЭпоха 0. Итерация 1500/6774 на обучающей выборке. Loss: 0.21836702525615692\n",
            "\tЭпоха 0. Итерация 1550/6774 на обучающей выборке. Loss: 0.1467108428478241\n",
            "\tЭпоха 0. Итерация 1600/6774 на обучающей выборке. Loss: 0.17720763385295868\n",
            "\tЭпоха 0. Итерация 1650/6774 на обучающей выборке. Loss: 0.2617184817790985\n",
            "\tЭпоха 0. Итерация 1700/6774 на обучающей выборке. Loss: 0.09222980588674545\n",
            "\tЭпоха 0. Итерация 1750/6774 на обучающей выборке. Loss: 0.15608499944210052\n",
            "\tЭпоха 0. Итерация 1800/6774 на обучающей выборке. Loss: 0.1285281777381897\n",
            "\tЭпоха 0. Итерация 1850/6774 на обучающей выборке. Loss: 0.14651919901371002\n",
            "\tЭпоха 0. Итерация 1900/6774 на обучающей выборке. Loss: 0.1083933636546135\n",
            "\tЭпоха 0. Итерация 1950/6774 на обучающей выборке. Loss: 0.34299033880233765\n",
            "\tЭпоха 0. Итерация 2000/6774 на обучающей выборке. Loss: 0.17520608007907867\n",
            "\tЭпоха 0. Итерация 2050/6774 на обучающей выборке. Loss: 0.20991648733615875\n",
            "\tЭпоха 0. Итерация 2100/6774 на обучающей выборке. Loss: 0.17254316806793213\n",
            "\tЭпоха 0. Итерация 2150/6774 на обучающей выборке. Loss: 0.19626711308956146\n",
            "\tЭпоха 0. Итерация 2200/6774 на обучающей выборке. Loss: 0.16193337738513947\n",
            "\tЭпоха 0. Итерация 2250/6774 на обучающей выборке. Loss: 0.25541967153549194\n",
            "\tЭпоха 0. Итерация 2300/6774 на обучающей выборке. Loss: 0.1436612457036972\n",
            "\tЭпоха 0. Итерация 2350/6774 на обучающей выборке. Loss: 0.10746351629495621\n",
            "\tЭпоха 0. Итерация 2400/6774 на обучающей выборке. Loss: 0.13701769709587097\n",
            "\tЭпоха 0. Итерация 2450/6774 на обучающей выборке. Loss: 0.21070300042629242\n",
            "\tЭпоха 0. Итерация 2500/6774 на обучающей выборке. Loss: 0.1620059758424759\n",
            "\tЭпоха 0. Итерация 2550/6774 на обучающей выборке. Loss: 0.21826322376728058\n",
            "\tЭпоха 0. Итерация 2600/6774 на обучающей выборке. Loss: 0.15924569964408875\n",
            "\tЭпоха 0. Итерация 2650/6774 на обучающей выборке. Loss: 0.1857844889163971\n",
            "\tЭпоха 0. Итерация 2700/6774 на обучающей выборке. Loss: 0.15306825935840607\n",
            "\tЭпоха 0. Итерация 2750/6774 на обучающей выборке. Loss: 0.13398116827011108\n",
            "\tЭпоха 0. Итерация 2800/6774 на обучающей выборке. Loss: 0.2022431343793869\n",
            "\tЭпоха 0. Итерация 2850/6774 на обучающей выборке. Loss: 0.1345183402299881\n",
            "\tЭпоха 0. Итерация 2900/6774 на обучающей выборке. Loss: 0.18304406106472015\n",
            "\tЭпоха 0. Итерация 2950/6774 на обучающей выборке. Loss: 0.18512439727783203\n",
            "\tЭпоха 0. Итерация 3000/6774 на обучающей выборке. Loss: 0.0913810208439827\n",
            "\tЭпоха 0. Итерация 3050/6774 на обучающей выборке. Loss: 0.08226832002401352\n",
            "\tЭпоха 0. Итерация 3100/6774 на обучающей выборке. Loss: 0.08330325782299042\n",
            "\tЭпоха 0. Итерация 3150/6774 на обучающей выборке. Loss: 0.10432548820972443\n",
            "\tЭпоха 0. Итерация 3200/6774 на обучающей выборке. Loss: 0.1621582955121994\n",
            "\tЭпоха 0. Итерация 3250/6774 на обучающей выборке. Loss: 0.13324114680290222\n",
            "\tЭпоха 0. Итерация 3300/6774 на обучающей выборке. Loss: 0.1410200148820877\n",
            "\tЭпоха 0. Итерация 3350/6774 на обучающей выборке. Loss: 0.15760478377342224\n",
            "\tЭпоха 0. Итерация 3400/6774 на обучающей выборке. Loss: 0.14781107008457184\n",
            "\tЭпоха 0. Итерация 3450/6774 на обучающей выборке. Loss: 0.1095820963382721\n",
            "\tЭпоха 0. Итерация 3500/6774 на обучающей выборке. Loss: 0.12326209992170334\n",
            "\tЭпоха 0. Итерация 3550/6774 на обучающей выборке. Loss: 0.07247763872146606\n",
            "\tЭпоха 0. Итерация 3600/6774 на обучающей выборке. Loss: 0.14792689681053162\n",
            "\tЭпоха 0. Итерация 3650/6774 на обучающей выборке. Loss: 0.1468549519777298\n",
            "\tЭпоха 0. Итерация 3700/6774 на обучающей выборке. Loss: 0.08761006593704224\n",
            "\tЭпоха 0. Итерация 3750/6774 на обучающей выборке. Loss: 0.10527066886425018\n",
            "\tЭпоха 0. Итерация 3800/6774 на обучающей выборке. Loss: 0.16338993608951569\n",
            "\tЭпоха 0. Итерация 3850/6774 на обучающей выборке. Loss: 0.15203478932380676\n",
            "\tЭпоха 0. Итерация 3900/6774 на обучающей выборке. Loss: 0.07266408950090408\n",
            "\tЭпоха 0. Итерация 3950/6774 на обучающей выборке. Loss: 0.11817954480648041\n",
            "\tЭпоха 0. Итерация 4000/6774 на обучающей выборке. Loss: 0.09780048578977585\n",
            "\tЭпоха 0. Итерация 4050/6774 на обучающей выборке. Loss: 0.12994679808616638\n",
            "\tЭпоха 0. Итерация 4100/6774 на обучающей выборке. Loss: 0.1152699813246727\n",
            "\tЭпоха 0. Итерация 4150/6774 на обучающей выборке. Loss: 0.08890307694673538\n",
            "\tЭпоха 0. Итерация 4200/6774 на обучающей выборке. Loss: 0.15646809339523315\n",
            "\tЭпоха 0. Итерация 4250/6774 на обучающей выборке. Loss: 0.14617875218391418\n",
            "\tЭпоха 0. Итерация 4300/6774 на обучающей выборке. Loss: 0.16679947078227997\n",
            "\tЭпоха 0. Итерация 4350/6774 на обучающей выборке. Loss: 0.08227869123220444\n",
            "\tЭпоха 0. Итерация 4400/6774 на обучающей выборке. Loss: 0.11031416058540344\n",
            "\tЭпоха 0. Итерация 4450/6774 на обучающей выборке. Loss: 0.12663739919662476\n",
            "\tЭпоха 0. Итерация 4500/6774 на обучающей выборке. Loss: 0.0942835807800293\n",
            "\tЭпоха 0. Итерация 4550/6774 на обучающей выборке. Loss: 0.11633975803852081\n",
            "\tЭпоха 0. Итерация 4600/6774 на обучающей выборке. Loss: 0.12405724078416824\n",
            "\tЭпоха 0. Итерация 4650/6774 на обучающей выборке. Loss: 0.16212880611419678\n",
            "\tЭпоха 0. Итерация 4700/6774 на обучающей выборке. Loss: 0.10915976762771606\n",
            "\tЭпоха 0. Итерация 4750/6774 на обучающей выборке. Loss: 0.11436347663402557\n",
            "\tЭпоха 0. Итерация 4800/6774 на обучающей выборке. Loss: 0.09693633019924164\n",
            "\tЭпоха 0. Итерация 4850/6774 на обучающей выборке. Loss: 0.1390787959098816\n",
            "\tЭпоха 0. Итерация 4900/6774 на обучающей выборке. Loss: 0.08235487341880798\n",
            "\tЭпоха 0. Итерация 4950/6774 на обучающей выборке. Loss: 0.05405419319868088\n",
            "\tЭпоха 0. Итерация 5000/6774 на обучающей выборке. Loss: 0.11545634269714355\n",
            "\tЭпоха 0. Итерация 5050/6774 на обучающей выборке. Loss: 0.06918226927518845\n",
            "\tЭпоха 0. Итерация 5100/6774 на обучающей выборке. Loss: 0.12495095282793045\n",
            "\tЭпоха 0. Итерация 5150/6774 на обучающей выборке. Loss: 0.11957836896181107\n",
            "\tЭпоха 0. Итерация 5200/6774 на обучающей выборке. Loss: 0.0998385027050972\n",
            "\tЭпоха 0. Итерация 5250/6774 на обучающей выборке. Loss: 0.10666584223508835\n",
            "\tЭпоха 0. Итерация 5300/6774 на обучающей выборке. Loss: 0.11806721985340118\n",
            "\tЭпоха 0. Итерация 5350/6774 на обучающей выборке. Loss: 0.1548648327589035\n",
            "\tЭпоха 0. Итерация 5400/6774 на обучающей выборке. Loss: 0.10442887246608734\n",
            "\tЭпоха 0. Итерация 5450/6774 на обучающей выборке. Loss: 0.13859930634498596\n",
            "\tЭпоха 0. Итерация 5500/6774 на обучающей выборке. Loss: 0.1831110715866089\n",
            "\tЭпоха 0. Итерация 5550/6774 на обучающей выборке. Loss: 0.11877269297838211\n",
            "\tЭпоха 0. Итерация 5600/6774 на обучающей выборке. Loss: 0.11209031939506531\n",
            "\tЭпоха 0. Итерация 5650/6774 на обучающей выборке. Loss: 0.1854000985622406\n",
            "\tЭпоха 0. Итерация 5700/6774 на обучающей выборке. Loss: 0.11311579495668411\n",
            "\tЭпоха 0. Итерация 5750/6774 на обучающей выборке. Loss: 0.09857252240180969\n",
            "\tЭпоха 0. Итерация 5800/6774 на обучающей выборке. Loss: 0.10944584757089615\n",
            "\tЭпоха 0. Итерация 5850/6774 на обучающей выборке. Loss: 0.11277784407138824\n",
            "\tЭпоха 0. Итерация 5900/6774 на обучающей выборке. Loss: 0.09140168875455856\n",
            "\tЭпоха 0. Итерация 5950/6774 на обучающей выборке. Loss: 0.09328731894493103\n",
            "\tЭпоха 0. Итерация 6000/6774 на обучающей выборке. Loss: 0.1576133817434311\n",
            "\tЭпоха 0. Итерация 6050/6774 на обучающей выборке. Loss: 0.14858563244342804\n",
            "\tЭпоха 0. Итерация 6100/6774 на обучающей выборке. Loss: 0.10476727783679962\n",
            "\tЭпоха 0. Итерация 6150/6774 на обучающей выборке. Loss: 0.05878978595137596\n",
            "\tЭпоха 0. Итерация 6200/6774 на обучающей выборке. Loss: 0.13322226703166962\n",
            "\tЭпоха 0. Итерация 6250/6774 на обучающей выборке. Loss: 0.10668886452913284\n",
            "\tЭпоха 0. Итерация 6300/6774 на обучающей выборке. Loss: 0.08644610643386841\n",
            "\tЭпоха 0. Итерация 6350/6774 на обучающей выборке. Loss: 0.05447561666369438\n",
            "\tЭпоха 0. Итерация 6400/6774 на обучающей выборке. Loss: 0.10336188971996307\n",
            "\tЭпоха 0. Итерация 6450/6774 на обучающей выборке. Loss: 0.10983280092477798\n",
            "\tЭпоха 0. Итерация 6500/6774 на обучающей выборке. Loss: 0.10492240637540817\n",
            "\tЭпоха 0. Итерация 6550/6774 на обучающей выборке. Loss: 0.13393458724021912\n",
            "\tЭпоха 0. Итерация 6600/6774 на обучающей выборке. Loss: 0.08503888547420502\n",
            "\tЭпоха 0. Итерация 6650/6774 на обучающей выборке. Loss: 0.11458184570074081\n",
            "\tЭпоха 0. Итерация 6700/6774 на обучающей выборке. Loss: 0.06645217537879944\n",
            "\tЭпоха 0. Итерация 6750/6774 на обучающей выборке. Loss: 0.12294290214776993\n",
            "\tЭпоха 0. Итерация 0/625 на тестовой выборке. Loss: 0.09015113860368729\n",
            "\tЭпоха 0. Итерация 50/625 на тестовой выборке. Loss: 0.13493576645851135\n",
            "\tЭпоха 0. Итерация 100/625 на тестовой выборке. Loss: 0.09219758212566376\n",
            "\tЭпоха 0. Итерация 150/625 на тестовой выборке. Loss: 0.055606693029403687\n",
            "\tЭпоха 0. Итерация 200/625 на тестовой выборке. Loss: 0.10854148864746094\n",
            "\tЭпоха 0. Итерация 250/625 на тестовой выборке. Loss: 0.15518008172512054\n",
            "\tЭпоха 0. Итерация 300/625 на тестовой выборке. Loss: 0.18359512090682983\n",
            "\tЭпоха 0. Итерация 350/625 на тестовой выборке. Loss: 0.17382802069187164\n",
            "\tЭпоха 0. Итерация 400/625 на тестовой выборке. Loss: 0.11751452088356018\n",
            "\tЭпоха 0. Итерация 450/625 на тестовой выборке. Loss: 0.09974189847707748\n",
            "\tЭпоха 0. Итерация 500/625 на тестовой выборке. Loss: 0.0972403958439827\n",
            "\tЭпоха 0. Итерация 550/625 на тестовой выборке. Loss: 0.06181247904896736\n",
            "\tЭпоха 0. Итерация 600/625 на тестовой выборке. Loss: 0.1800978034734726\n",
            "Эпоха #0 train_loss: 0.019847465929565433, val_loss: 0.01461440633535385\n",
            "Потрачено 87.9 минут на 0 эпоху\n",
            "\tЭпоха 1. Итерация 0/6774 на обучающей выборке. Loss: 0.12624923884868622\n",
            "\tЭпоха 1. Итерация 50/6774 на обучающей выборке. Loss: 0.12591420114040375\n",
            "\tЭпоха 1. Итерация 100/6774 на обучающей выборке. Loss: 0.17782340943813324\n",
            "\tЭпоха 1. Итерация 150/6774 на обучающей выборке. Loss: 0.08900722861289978\n",
            "\tЭпоха 1. Итерация 200/6774 на обучающей выборке. Loss: 0.09695391356945038\n",
            "\tЭпоха 1. Итерация 250/6774 на обучающей выборке. Loss: 0.11784899979829788\n",
            "\tЭпоха 1. Итерация 300/6774 на обучающей выборке. Loss: 0.10129713267087936\n",
            "\tЭпоха 1. Итерация 350/6774 на обучающей выборке. Loss: 0.0792100727558136\n",
            "\tЭпоха 1. Итерация 400/6774 на обучающей выборке. Loss: 0.08905452489852905\n",
            "\tЭпоха 1. Итерация 450/6774 на обучающей выборке. Loss: 0.05278662592172623\n",
            "\tЭпоха 1. Итерация 500/6774 на обучающей выборке. Loss: 0.09688134491443634\n",
            "\tЭпоха 1. Итерация 550/6774 на обучающей выборке. Loss: 0.10936982929706573\n",
            "\tЭпоха 1. Итерация 600/6774 на обучающей выборке. Loss: 0.0789278969168663\n",
            "\tЭпоха 1. Итерация 650/6774 на обучающей выборке. Loss: 0.12692177295684814\n",
            "\tЭпоха 1. Итерация 700/6774 на обучающей выборке. Loss: 0.14255814254283905\n",
            "\tЭпоха 1. Итерация 750/6774 на обучающей выборке. Loss: 0.07080281525850296\n",
            "\tЭпоха 1. Итерация 800/6774 на обучающей выборке. Loss: 0.07336805760860443\n",
            "\tЭпоха 1. Итерация 850/6774 на обучающей выборке. Loss: 0.08730614185333252\n",
            "\tЭпоха 1. Итерация 900/6774 на обучающей выборке. Loss: 0.157621830701828\n",
            "\tЭпоха 1. Итерация 950/6774 на обучающей выборке. Loss: 0.12077517062425613\n",
            "\tЭпоха 1. Итерация 1000/6774 на обучающей выборке. Loss: 0.07428724318742752\n",
            "\tЭпоха 1. Итерация 1050/6774 на обучающей выборке. Loss: 0.09557580202817917\n",
            "\tЭпоха 1. Итерация 1100/6774 на обучающей выборке. Loss: 0.06286575645208359\n",
            "\tЭпоха 1. Итерация 1150/6774 на обучающей выборке. Loss: 0.06805218756198883\n",
            "\tЭпоха 1. Итерация 1200/6774 на обучающей выборке. Loss: 0.11483214795589447\n",
            "\tЭпоха 1. Итерация 1250/6774 на обучающей выборке. Loss: 0.08005236834287643\n",
            "\tЭпоха 1. Итерация 1300/6774 на обучающей выборке. Loss: 0.13883645832538605\n",
            "\tЭпоха 1. Итерация 1350/6774 на обучающей выборке. Loss: 0.08545740693807602\n",
            "\tЭпоха 1. Итерация 1400/6774 на обучающей выборке. Loss: 0.09451965987682343\n",
            "\tЭпоха 1. Итерация 1450/6774 на обучающей выборке. Loss: 0.11028150469064713\n",
            "\tЭпоха 1. Итерация 1500/6774 на обучающей выборке. Loss: 0.13886837661266327\n",
            "\tЭпоха 1. Итерация 1550/6774 на обучающей выборке. Loss: 0.08430544286966324\n",
            "\tЭпоха 1. Итерация 1600/6774 на обучающей выборке. Loss: 0.11017610132694244\n",
            "\tЭпоха 1. Итерация 1650/6774 на обучающей выборке. Loss: 0.10722361505031586\n",
            "\tЭпоха 1. Итерация 1700/6774 на обучающей выборке. Loss: 0.05786684900522232\n",
            "\tЭпоха 1. Итерация 1750/6774 на обучающей выборке. Loss: 0.09384742379188538\n",
            "\tЭпоха 1. Итерация 1800/6774 на обучающей выборке. Loss: 0.13139130175113678\n",
            "\tЭпоха 1. Итерация 1850/6774 на обучающей выборке. Loss: 0.060519877821207047\n",
            "\tЭпоха 1. Итерация 1900/6774 на обучающей выборке. Loss: 0.11805003881454468\n",
            "\tЭпоха 1. Итерация 1950/6774 на обучающей выборке. Loss: 0.12333258986473083\n",
            "\tЭпоха 1. Итерация 2000/6774 на обучающей выборке. Loss: 0.1571391224861145\n",
            "\tЭпоха 1. Итерация 2050/6774 на обучающей выборке. Loss: 0.1086597591638565\n",
            "\tЭпоха 1. Итерация 2100/6774 на обучающей выборке. Loss: 0.09120772033929825\n",
            "\tЭпоха 1. Итерация 2150/6774 на обучающей выборке. Loss: 0.08069368451833725\n",
            "\tЭпоха 1. Итерация 2200/6774 на обучающей выборке. Loss: 0.11268920451402664\n",
            "\tЭпоха 1. Итерация 2250/6774 на обучающей выборке. Loss: 0.10951117426156998\n",
            "\tЭпоха 1. Итерация 2300/6774 на обучающей выборке. Loss: 0.09302788972854614\n",
            "\tЭпоха 1. Итерация 2350/6774 на обучающей выборке. Loss: 0.10977493226528168\n",
            "\tЭпоха 1. Итерация 2400/6774 на обучающей выборке. Loss: 0.06466244161128998\n",
            "\tЭпоха 1. Итерация 2450/6774 на обучающей выборке. Loss: 0.0719151571393013\n",
            "\tЭпоха 1. Итерация 2500/6774 на обучающей выборке. Loss: 0.11902477592229843\n",
            "\tЭпоха 1. Итерация 2550/6774 на обучающей выборке. Loss: 0.1541575938463211\n",
            "\tЭпоха 1. Итерация 2600/6774 на обучающей выборке. Loss: 0.08670130372047424\n",
            "\tЭпоха 1. Итерация 2650/6774 на обучающей выборке. Loss: 0.11184816062450409\n",
            "\tЭпоха 1. Итерация 2700/6774 на обучающей выборке. Loss: 0.06592212617397308\n",
            "\tЭпоха 1. Итерация 2750/6774 на обучающей выборке. Loss: 0.13116209208965302\n",
            "\tЭпоха 1. Итерация 2800/6774 на обучающей выборке. Loss: 0.0862683579325676\n",
            "\tЭпоха 1. Итерация 2850/6774 на обучающей выборке. Loss: 0.09332841634750366\n",
            "\tЭпоха 1. Итерация 2900/6774 на обучающей выборке. Loss: 0.09665179997682571\n",
            "\tЭпоха 1. Итерация 2950/6774 на обучающей выборке. Loss: 0.042782511562108994\n",
            "\tЭпоха 1. Итерация 3000/6774 на обучающей выборке. Loss: 0.11074817180633545\n",
            "\tЭпоха 1. Итерация 3050/6774 на обучающей выборке. Loss: 0.0909595713019371\n",
            "\tЭпоха 1. Итерация 3100/6774 на обучающей выборке. Loss: 0.09327778965234756\n",
            "\tЭпоха 1. Итерация 3150/6774 на обучающей выборке. Loss: 0.07482625544071198\n",
            "\tЭпоха 1. Итерация 3200/6774 на обучающей выборке. Loss: 0.07690365612506866\n",
            "\tЭпоха 1. Итерация 3250/6774 на обучающей выборке. Loss: 0.07974513620138168\n",
            "\tЭпоха 1. Итерация 3300/6774 на обучающей выборке. Loss: 0.11823058873414993\n",
            "\tЭпоха 1. Итерация 3350/6774 на обучающей выборке. Loss: 0.10066268593072891\n",
            "\tЭпоха 1. Итерация 3400/6774 на обучающей выборке. Loss: 0.09746435284614563\n",
            "\tЭпоха 1. Итерация 3450/6774 на обучающей выборке. Loss: 0.07207876443862915\n",
            "\tЭпоха 1. Итерация 3500/6774 на обучающей выборке. Loss: 0.1318279206752777\n",
            "\tЭпоха 1. Итерация 3550/6774 на обучающей выборке. Loss: 0.1385188102722168\n",
            "\tЭпоха 1. Итерация 3600/6774 на обучающей выборке. Loss: 0.09077923744916916\n",
            "\tЭпоха 1. Итерация 3650/6774 на обучающей выборке. Loss: 0.10532139241695404\n",
            "\tЭпоха 1. Итерация 3700/6774 на обучающей выборке. Loss: 0.06259999424219131\n",
            "\tЭпоха 1. Итерация 3750/6774 на обучающей выборке. Loss: 0.08909249305725098\n",
            "\tЭпоха 1. Итерация 3800/6774 на обучающей выборке. Loss: 0.10154034942388535\n",
            "\tЭпоха 1. Итерация 3850/6774 на обучающей выборке. Loss: 0.08971881121397018\n",
            "\tЭпоха 1. Итерация 3900/6774 на обучающей выборке. Loss: 0.11044915020465851\n",
            "\tЭпоха 1. Итерация 3950/6774 на обучающей выборке. Loss: 0.13332420587539673\n",
            "\tЭпоха 1. Итерация 4000/6774 на обучающей выборке. Loss: 0.11938342452049255\n",
            "\tЭпоха 1. Итерация 4050/6774 на обучающей выборке. Loss: 0.06940434873104095\n",
            "\tЭпоха 1. Итерация 4100/6774 на обучающей выборке. Loss: 0.16530954837799072\n",
            "\tЭпоха 1. Итерация 4150/6774 на обучающей выборке. Loss: 0.07270112633705139\n",
            "\tЭпоха 1. Итерация 4200/6774 на обучающей выборке. Loss: 0.09647352993488312\n",
            "\tЭпоха 1. Итерация 4250/6774 на обучающей выборке. Loss: 0.10419740527868271\n",
            "\tЭпоха 1. Итерация 4300/6774 на обучающей выборке. Loss: 0.12701092660427094\n",
            "\tЭпоха 1. Итерация 4350/6774 на обучающей выборке. Loss: 0.08232659101486206\n",
            "\tЭпоха 1. Итерация 4400/6774 на обучающей выборке. Loss: 0.06136808171868324\n",
            "\tЭпоха 1. Итерация 4450/6774 на обучающей выборке. Loss: 0.18144099414348602\n",
            "\tЭпоха 1. Итерация 4500/6774 на обучающей выборке. Loss: 0.10612562298774719\n",
            "\tЭпоха 1. Итерация 4550/6774 на обучающей выборке. Loss: 0.08504006266593933\n",
            "\tЭпоха 1. Итерация 4600/6774 на обучающей выборке. Loss: 0.08021234720945358\n",
            "\tЭпоха 1. Итерация 4650/6774 на обучающей выборке. Loss: 0.08907352387905121\n",
            "\tЭпоха 1. Итерация 4700/6774 на обучающей выборке. Loss: 0.16393017768859863\n",
            "\tЭпоха 1. Итерация 4750/6774 на обучающей выборке. Loss: 0.08815919607877731\n",
            "\tЭпоха 1. Итерация 4800/6774 на обучающей выборке. Loss: 0.06013766676187515\n",
            "\tЭпоха 1. Итерация 4850/6774 на обучающей выборке. Loss: 0.1951962560415268\n",
            "\tЭпоха 1. Итерация 4900/6774 на обучающей выборке. Loss: 0.08285871148109436\n",
            "\tЭпоха 1. Итерация 4950/6774 на обучающей выборке. Loss: 0.08124817162752151\n",
            "\tЭпоха 1. Итерация 5000/6774 на обучающей выборке. Loss: 0.06531927734613419\n",
            "\tЭпоха 1. Итерация 5050/6774 на обучающей выборке. Loss: 0.12497802823781967\n",
            "\tЭпоха 1. Итерация 5100/6774 на обучающей выборке. Loss: 0.11877472698688507\n",
            "\tЭпоха 1. Итерация 5150/6774 на обучающей выборке. Loss: 0.06897449493408203\n",
            "\tЭпоха 1. Итерация 5200/6774 на обучающей выборке. Loss: 0.12737317383289337\n",
            "\tЭпоха 1. Итерация 5250/6774 на обучающей выборке. Loss: 0.13820791244506836\n",
            "\tЭпоха 1. Итерация 5300/6774 на обучающей выборке. Loss: 0.06753265857696533\n",
            "\tЭпоха 1. Итерация 5350/6774 на обучающей выборке. Loss: 0.07482865452766418\n",
            "\tЭпоха 1. Итерация 5400/6774 на обучающей выборке. Loss: 0.13065901398658752\n",
            "\tЭпоха 1. Итерация 5450/6774 на обучающей выборке. Loss: 0.07366899400949478\n",
            "\tЭпоха 1. Итерация 5500/6774 на обучающей выборке. Loss: 0.09097582846879959\n",
            "\tЭпоха 1. Итерация 5550/6774 на обучающей выборке. Loss: 0.05931450054049492\n",
            "\tЭпоха 1. Итерация 5600/6774 на обучающей выборке. Loss: 0.07864960283041\n",
            "\tЭпоха 1. Итерация 5650/6774 на обучающей выборке. Loss: 0.1308986097574234\n",
            "\tЭпоха 1. Итерация 5700/6774 на обучающей выборке. Loss: 0.09833332896232605\n",
            "\tЭпоха 1. Итерация 5750/6774 на обучающей выборке. Loss: 0.09210040420293808\n",
            "\tЭпоха 1. Итерация 5800/6774 на обучающей выборке. Loss: 0.11351511627435684\n",
            "\tЭпоха 1. Итерация 5850/6774 на обучающей выборке. Loss: 0.10842330008745193\n",
            "\tЭпоха 1. Итерация 5900/6774 на обучающей выборке. Loss: 0.07861620932817459\n",
            "\tЭпоха 1. Итерация 5950/6774 на обучающей выборке. Loss: 0.10231495648622513\n",
            "\tЭпоха 1. Итерация 6000/6774 на обучающей выборке. Loss: 0.07867392897605896\n",
            "\tЭпоха 1. Итерация 6050/6774 на обучающей выборке. Loss: 0.13721963763237\n",
            "\tЭпоха 1. Итерация 6100/6774 на обучающей выборке. Loss: 0.08428674936294556\n",
            "\tЭпоха 1. Итерация 6150/6774 на обучающей выборке. Loss: 0.10596856474876404\n",
            "\tЭпоха 1. Итерация 6200/6774 на обучающей выборке. Loss: 0.04279378801584244\n",
            "\tЭпоха 1. Итерация 6250/6774 на обучающей выборке. Loss: 0.12422829866409302\n",
            "\tЭпоха 1. Итерация 6300/6774 на обучающей выборке. Loss: 0.07461096346378326\n",
            "\tЭпоха 1. Итерация 6350/6774 на обучающей выборке. Loss: 0.09172287583351135\n",
            "\tЭпоха 1. Итерация 6400/6774 на обучающей выборке. Loss: 0.08838965743780136\n",
            "\tЭпоха 1. Итерация 6450/6774 на обучающей выборке. Loss: 0.04768042266368866\n",
            "\tЭпоха 1. Итерация 6500/6774 на обучающей выборке. Loss: 0.0659133717417717\n",
            "\tЭпоха 1. Итерация 6550/6774 на обучающей выборке. Loss: 0.13031665980815887\n",
            "\tЭпоха 1. Итерация 6600/6774 на обучающей выборке. Loss: 0.09438864886760712\n",
            "\tЭпоха 1. Итерация 6650/6774 на обучающей выборке. Loss: 0.062440961599349976\n",
            "\tЭпоха 1. Итерация 6700/6774 на обучающей выборке. Loss: 0.04810423403978348\n",
            "\tЭпоха 1. Итерация 6750/6774 на обучающей выборке. Loss: 0.14312738180160522\n",
            "\tЭпоха 1. Итерация 0/625 на тестовой выборке. Loss: 0.07584988325834274\n",
            "\tЭпоха 1. Итерация 50/625 на тестовой выборке. Loss: 0.10570809990167618\n",
            "\tЭпоха 1. Итерация 100/625 на тестовой выборке. Loss: 0.07544279098510742\n",
            "\tЭпоха 1. Итерация 150/625 на тестовой выборке. Loss: 0.05676102638244629\n",
            "\tЭпоха 1. Итерация 200/625 на тестовой выборке. Loss: 0.11326666921377182\n",
            "\tЭпоха 1. Итерация 250/625 на тестовой выборке. Loss: 0.11792971938848495\n",
            "\tЭпоха 1. Итерация 300/625 на тестовой выборке. Loss: 0.19056439399719238\n",
            "\tЭпоха 1. Итерация 350/625 на тестовой выборке. Loss: 0.12031441926956177\n",
            "\tЭпоха 1. Итерация 400/625 на тестовой выборке. Loss: 0.12216556817293167\n",
            "\tЭпоха 1. Итерация 450/625 на тестовой выборке. Loss: 0.11025697737932205\n",
            "\tЭпоха 1. Итерация 500/625 на тестовой выборке. Loss: 0.08375786244869232\n",
            "\tЭпоха 1. Итерация 550/625 на тестовой выборке. Loss: 0.05733252689242363\n",
            "\tЭпоха 1. Итерация 600/625 на тестовой выборке. Loss: 0.16302283108234406\n",
            "Эпоха #1 train_loss: 0.012480823496580586, val_loss: 0.012693846774846316\n",
            "Потрачено 87.2 минут на 1 эпоху\n",
            "\tЭпоха 2. Итерация 0/6774 на обучающей выборке. Loss: 0.07808864861726761\n",
            "\tЭпоха 2. Итерация 50/6774 на обучающей выборке. Loss: 0.10332178324460983\n",
            "\tЭпоха 2. Итерация 100/6774 на обучающей выборке. Loss: 0.08009275048971176\n",
            "\tЭпоха 2. Итерация 150/6774 на обучающей выборке. Loss: 0.09815825521945953\n",
            "\tЭпоха 2. Итерация 200/6774 на обучающей выборке. Loss: 0.12366056442260742\n",
            "\tЭпоха 2. Итерация 250/6774 на обучающей выборке. Loss: 0.06418813765048981\n",
            "\tЭпоха 2. Итерация 300/6774 на обучающей выборке. Loss: 0.064247265458107\n",
            "\tЭпоха 2. Итерация 350/6774 на обучающей выборке. Loss: 0.06207960471510887\n",
            "\tЭпоха 2. Итерация 400/6774 на обучающей выборке. Loss: 0.06894146651029587\n",
            "\tЭпоха 2. Итерация 450/6774 на обучающей выборке. Loss: 0.06968195736408234\n",
            "\tЭпоха 2. Итерация 500/6774 на обучающей выборке. Loss: 0.06822927296161652\n",
            "\tЭпоха 2. Итерация 550/6774 на обучающей выборке. Loss: 0.08608127385377884\n",
            "\tЭпоха 2. Итерация 600/6774 на обучающей выборке. Loss: 0.0606531985104084\n",
            "\tЭпоха 2. Итерация 650/6774 на обучающей выборке. Loss: 0.06945400685071945\n",
            "\tЭпоха 2. Итерация 700/6774 на обучающей выборке. Loss: 0.05391804128885269\n",
            "\tЭпоха 2. Итерация 750/6774 на обучающей выборке. Loss: 0.07311838865280151\n",
            "\tЭпоха 2. Итерация 800/6774 на обучающей выборке. Loss: 0.10322695970535278\n",
            "\tЭпоха 2. Итерация 850/6774 на обучающей выборке. Loss: 0.07910147309303284\n",
            "\tЭпоха 2. Итерация 900/6774 на обучающей выборке. Loss: 0.06741984933614731\n",
            "\tЭпоха 2. Итерация 950/6774 на обучающей выборке. Loss: 0.07655923813581467\n",
            "\tЭпоха 2. Итерация 1000/6774 на обучающей выборке. Loss: 0.08856862783432007\n",
            "\tЭпоха 2. Итерация 1050/6774 на обучающей выборке. Loss: 0.07713577896356583\n",
            "\tЭпоха 2. Итерация 1100/6774 на обучающей выборке. Loss: 0.12295086681842804\n",
            "\tЭпоха 2. Итерация 1150/6774 на обучающей выборке. Loss: 0.09979228675365448\n",
            "\tЭпоха 2. Итерация 1200/6774 на обучающей выборке. Loss: 0.0718102753162384\n",
            "\tЭпоха 2. Итерация 1250/6774 на обучающей выборке. Loss: 0.04335993900895119\n",
            "\tЭпоха 2. Итерация 1300/6774 на обучающей выборке. Loss: 0.08932152390480042\n",
            "\tЭпоха 2. Итерация 1350/6774 на обучающей выборке. Loss: 0.13143472373485565\n",
            "\tЭпоха 2. Итерация 1400/6774 на обучающей выборке. Loss: 0.06689216196537018\n",
            "\tЭпоха 2. Итерация 1450/6774 на обучающей выборке. Loss: 0.08884598314762115\n",
            "\tЭпоха 2. Итерация 1500/6774 на обучающей выборке. Loss: 0.08915704488754272\n",
            "\tЭпоха 2. Итерация 1550/6774 на обучающей выборке. Loss: 0.07632307708263397\n",
            "\tЭпоха 2. Итерация 1600/6774 на обучающей выборке. Loss: 0.07648716121912003\n",
            "\tЭпоха 2. Итерация 1650/6774 на обучающей выборке. Loss: 0.11761865764856339\n",
            "\tЭпоха 2. Итерация 1700/6774 на обучающей выборке. Loss: 0.06433901190757751\n",
            "\tЭпоха 2. Итерация 1750/6774 на обучающей выборке. Loss: 0.07790905237197876\n",
            "\tЭпоха 2. Итерация 1800/6774 на обучающей выборке. Loss: 0.11905176937580109\n",
            "\tЭпоха 2. Итерация 1850/6774 на обучающей выборке. Loss: 0.08073751628398895\n",
            "\tЭпоха 2. Итерация 1900/6774 на обучающей выборке. Loss: 0.11873309314250946\n",
            "\tЭпоха 2. Итерация 1950/6774 на обучающей выборке. Loss: 0.08516602963209152\n",
            "\tЭпоха 2. Итерация 2000/6774 на обучающей выборке. Loss: 0.07085471600294113\n",
            "\tЭпоха 2. Итерация 2050/6774 на обучающей выборке. Loss: 0.09732675552368164\n",
            "\tЭпоха 2. Итерация 2100/6774 на обучающей выборке. Loss: 0.1110052838921547\n",
            "\tЭпоха 2. Итерация 2150/6774 на обучающей выборке. Loss: 0.07011484354734421\n",
            "\tЭпоха 2. Итерация 2200/6774 на обучающей выборке. Loss: 0.08039557933807373\n",
            "\tЭпоха 2. Итерация 2250/6774 на обучающей выборке. Loss: 0.04638494551181793\n",
            "\tЭпоха 2. Итерация 2300/6774 на обучающей выборке. Loss: 0.07440578937530518\n",
            "\tЭпоха 2. Итерация 2350/6774 на обучающей выборке. Loss: 0.12422513961791992\n",
            "\tЭпоха 2. Итерация 2400/6774 на обучающей выборке. Loss: 0.0736616849899292\n",
            "\tЭпоха 2. Итерация 2450/6774 на обучающей выборке. Loss: 0.07886380702257156\n",
            "\tЭпоха 2. Итерация 2500/6774 на обучающей выборке. Loss: 0.06390610337257385\n",
            "\tЭпоха 2. Итерация 2550/6774 на обучающей выборке. Loss: 0.09528055787086487\n",
            "\tЭпоха 2. Итерация 2600/6774 на обучающей выборке. Loss: 0.09906540811061859\n",
            "\tЭпоха 2. Итерация 2650/6774 на обучающей выборке. Loss: 0.0813249722123146\n",
            "\tЭпоха 2. Итерация 2700/6774 на обучающей выборке. Loss: 0.06798447668552399\n",
            "\tЭпоха 2. Итерация 2750/6774 на обучающей выборке. Loss: 0.10659204423427582\n",
            "\tЭпоха 2. Итерация 2800/6774 на обучающей выборке. Loss: 0.12732386589050293\n",
            "\tЭпоха 2. Итерация 2850/6774 на обучающей выборке. Loss: 0.07848504185676575\n",
            "\tЭпоха 2. Итерация 2900/6774 на обучающей выборке. Loss: 0.1196606382727623\n",
            "\tЭпоха 2. Итерация 2950/6774 на обучающей выборке. Loss: 0.053214095532894135\n",
            "\tЭпоха 2. Итерация 3000/6774 на обучающей выборке. Loss: 0.08709031343460083\n",
            "\tЭпоха 2. Итерация 3050/6774 на обучающей выборке. Loss: 0.1476222723722458\n",
            "\tЭпоха 2. Итерация 3100/6774 на обучающей выборке. Loss: 0.07727152109146118\n",
            "\tЭпоха 2. Итерация 3150/6774 на обучающей выборке. Loss: 0.11601659655570984\n",
            "\tЭпоха 2. Итерация 3200/6774 на обучающей выборке. Loss: 0.08708979934453964\n",
            "\tЭпоха 2. Итерация 3250/6774 на обучающей выборке. Loss: 0.09537941962480545\n",
            "\tЭпоха 2. Итерация 3300/6774 на обучающей выборке. Loss: 0.10245127975940704\n",
            "\tЭпоха 2. Итерация 3350/6774 на обучающей выборке. Loss: 0.06920041143894196\n",
            "\tЭпоха 2. Итерация 3400/6774 на обучающей выборке. Loss: 0.08522581309080124\n",
            "\tЭпоха 2. Итерация 3450/6774 на обучающей выборке. Loss: 0.09640724956989288\n",
            "\tЭпоха 2. Итерация 3500/6774 на обучающей выборке. Loss: 0.12048759311437607\n",
            "\tЭпоха 2. Итерация 3550/6774 на обучающей выборке. Loss: 0.09335942566394806\n",
            "\tЭпоха 2. Итерация 3600/6774 на обучающей выборке. Loss: 0.08133573830127716\n",
            "\tЭпоха 2. Итерация 3650/6774 на обучающей выборке. Loss: 0.09164488315582275\n",
            "\tЭпоха 2. Итерация 3700/6774 на обучающей выборке. Loss: 0.06804001331329346\n",
            "\tЭпоха 2. Итерация 3750/6774 на обучающей выборке. Loss: 0.0907723531126976\n",
            "\tЭпоха 2. Итерация 3800/6774 на обучающей выборке. Loss: 0.0970562994480133\n",
            "\tЭпоха 2. Итерация 3850/6774 на обучающей выборке. Loss: 0.07056362926959991\n",
            "\tЭпоха 2. Итерация 3900/6774 на обучающей выборке. Loss: 0.10518357157707214\n",
            "\tЭпоха 2. Итерация 3950/6774 на обучающей выборке. Loss: 0.06575828045606613\n",
            "\tЭпоха 2. Итерация 4000/6774 на обучающей выборке. Loss: 0.10467896610498428\n",
            "\tЭпоха 2. Итерация 4050/6774 на обучающей выборке. Loss: 0.06617694348096848\n",
            "\tЭпоха 2. Итерация 4100/6774 на обучающей выборке. Loss: 0.05248090252280235\n",
            "\tЭпоха 2. Итерация 4150/6774 на обучающей выборке. Loss: 0.0708974078297615\n",
            "\tЭпоха 2. Итерация 4200/6774 на обучающей выборке. Loss: 0.05345495417714119\n",
            "\tЭпоха 2. Итерация 4250/6774 на обучающей выборке. Loss: 0.08352159708738327\n",
            "\tЭпоха 2. Итерация 4300/6774 на обучающей выборке. Loss: 0.07134027779102325\n",
            "\tЭпоха 2. Итерация 4350/6774 на обучающей выборке. Loss: 0.10188072174787521\n",
            "\tЭпоха 2. Итерация 4400/6774 на обучающей выборке. Loss: 0.08394346386194229\n",
            "\tЭпоха 2. Итерация 4450/6774 на обучающей выборке. Loss: 0.1398579180240631\n",
            "\tЭпоха 2. Итерация 4500/6774 на обучающей выборке. Loss: 0.054750412702560425\n",
            "\tЭпоха 2. Итерация 4550/6774 на обучающей выборке. Loss: 0.07965576648712158\n",
            "\tЭпоха 2. Итерация 4600/6774 на обучающей выборке. Loss: 0.0627443939447403\n",
            "\tЭпоха 2. Итерация 4650/6774 на обучающей выборке. Loss: 0.09111721068620682\n",
            "\tЭпоха 2. Итерация 4700/6774 на обучающей выборке. Loss: 0.10135749727487564\n",
            "\tЭпоха 2. Итерация 4750/6774 на обучающей выборке. Loss: 0.05598324164748192\n",
            "\tЭпоха 2. Итерация 4800/6774 на обучающей выборке. Loss: 0.1066158339381218\n",
            "\tЭпоха 2. Итерация 4850/6774 на обучающей выборке. Loss: 0.09342849254608154\n",
            "\tЭпоха 2. Итерация 4900/6774 на обучающей выборке. Loss: 0.10036419332027435\n",
            "\tЭпоха 2. Итерация 4950/6774 на обучающей выборке. Loss: 0.036957915872335434\n",
            "\tЭпоха 2. Итерация 5000/6774 на обучающей выборке. Loss: 0.11520373821258545\n",
            "\tЭпоха 2. Итерация 5050/6774 на обучающей выборке. Loss: 0.08287323266267776\n",
            "\tЭпоха 2. Итерация 5100/6774 на обучающей выборке. Loss: 0.06387791037559509\n",
            "\tЭпоха 2. Итерация 5150/6774 на обучающей выборке. Loss: 0.15117911994457245\n",
            "\tЭпоха 2. Итерация 5200/6774 на обучающей выборке. Loss: 0.09647974371910095\n",
            "\tЭпоха 2. Итерация 5250/6774 на обучающей выборке. Loss: 0.08055157214403152\n",
            "\tЭпоха 2. Итерация 5300/6774 на обучающей выборке. Loss: 0.06333959102630615\n",
            "\tЭпоха 2. Итерация 5350/6774 на обучающей выборке. Loss: 0.08419223129749298\n",
            "\tЭпоха 2. Итерация 5400/6774 на обучающей выборке. Loss: 0.11089176684617996\n",
            "\tЭпоха 2. Итерация 5450/6774 на обучающей выборке. Loss: 0.1343514770269394\n",
            "\tЭпоха 2. Итерация 5500/6774 на обучающей выборке. Loss: 0.05355215072631836\n",
            "\tЭпоха 2. Итерация 5550/6774 на обучающей выборке. Loss: 0.03797033056616783\n",
            "\tЭпоха 2. Итерация 5600/6774 на обучающей выборке. Loss: 0.0886974111199379\n",
            "\tЭпоха 2. Итерация 5650/6774 на обучающей выборке. Loss: 0.14395587146282196\n",
            "\tЭпоха 2. Итерация 5700/6774 на обучающей выборке. Loss: 0.069675512611866\n",
            "\tЭпоха 2. Итерация 5750/6774 на обучающей выборке. Loss: 0.07610571384429932\n",
            "\tЭпоха 2. Итерация 5800/6774 на обучающей выборке. Loss: 0.113798126578331\n",
            "\tЭпоха 2. Итерация 5850/6774 на обучающей выборке. Loss: 0.09569258242845535\n",
            "\tЭпоха 2. Итерация 5900/6774 на обучающей выборке. Loss: 0.08419671654701233\n",
            "\tЭпоха 2. Итерация 5950/6774 на обучающей выборке. Loss: 0.07272221893072128\n",
            "\tЭпоха 2. Итерация 6000/6774 на обучающей выборке. Loss: 0.09189359098672867\n",
            "\tЭпоха 2. Итерация 6050/6774 на обучающей выборке. Loss: 0.0689023807644844\n",
            "\tЭпоха 2. Итерация 6100/6774 на обучающей выборке. Loss: 0.057353146374225616\n",
            "\tЭпоха 2. Итерация 6150/6774 на обучающей выборке. Loss: 0.0858059823513031\n",
            "\tЭпоха 2. Итерация 6200/6774 на обучающей выборке. Loss: 0.04640612006187439\n",
            "\tЭпоха 2. Итерация 6250/6774 на обучающей выборке. Loss: 0.12479989230632782\n",
            "\tЭпоха 2. Итерация 6300/6774 на обучающей выборке. Loss: 0.047282010316848755\n",
            "\tЭпоха 2. Итерация 6350/6774 на обучающей выборке. Loss: 0.05824420601129532\n",
            "\tЭпоха 2. Итерация 6400/6774 на обучающей выборке. Loss: 0.11434680223464966\n",
            "\tЭпоха 2. Итерация 6450/6774 на обучающей выборке. Loss: 0.10454916954040527\n",
            "\tЭпоха 2. Итерация 6500/6774 на обучающей выборке. Loss: 0.07991809397935867\n",
            "\tЭпоха 2. Итерация 6550/6774 на обучающей выборке. Loss: 0.06253671646118164\n",
            "\tЭпоха 2. Итерация 6600/6774 на обучающей выборке. Loss: 0.10255126655101776\n",
            "\tЭпоха 2. Итерация 6650/6774 на обучающей выборке. Loss: 0.13690607249736786\n",
            "\tЭпоха 2. Итерация 6700/6774 на обучающей выборке. Loss: 0.08765151351690292\n",
            "\tЭпоха 2. Итерация 6750/6774 на обучающей выборке. Loss: 0.09147156029939651\n",
            "\tЭпоха 2. Итерация 0/625 на тестовой выборке. Loss: 0.08480868488550186\n",
            "\tЭпоха 2. Итерация 50/625 на тестовой выборке. Loss: 0.11275602877140045\n",
            "\tЭпоха 2. Итерация 100/625 на тестовой выборке. Loss: 0.06475963443517685\n",
            "\tЭпоха 2. Итерация 150/625 на тестовой выборке. Loss: 0.05160803720355034\n",
            "\tЭпоха 2. Итерация 200/625 на тестовой выборке. Loss: 0.11882183700799942\n",
            "\tЭпоха 2. Итерация 250/625 на тестовой выборке. Loss: 0.11167240142822266\n",
            "\tЭпоха 2. Итерация 300/625 на тестовой выборке. Loss: 0.17823632061481476\n",
            "\tЭпоха 2. Итерация 350/625 на тестовой выборке. Loss: 0.1198819950222969\n",
            "\tЭпоха 2. Итерация 400/625 на тестовой выборке. Loss: 0.14709915220737457\n",
            "\tЭпоха 2. Итерация 450/625 на тестовой выборке. Loss: 0.09883560985326767\n",
            "\tЭпоха 2. Итерация 500/625 на тестовой выборке. Loss: 0.084803007543087\n",
            "\tЭпоха 2. Итерация 550/625 на тестовой выборке. Loss: 0.06418249011039734\n",
            "\tЭпоха 2. Итерация 600/625 на тестовой выборке. Loss: 0.13622832298278809\n",
            "Эпоха #2 train_loss: 0.010799943972868452, val_loss: 0.012076417721807956\n",
            "Потрачено 87.4 минут на 2 эпоху\n",
            "\tЭпоха 3. Итерация 0/6774 на обучающей выборке. Loss: 0.08642494678497314\n",
            "\tЭпоха 3. Итерация 50/6774 на обучающей выборке. Loss: 0.06212101876735687\n",
            "\tЭпоха 3. Итерация 100/6774 на обучающей выборке. Loss: 0.1202026903629303\n",
            "\tЭпоха 3. Итерация 150/6774 на обучающей выборке. Loss: 0.0989188700914383\n",
            "\tЭпоха 3. Итерация 200/6774 на обучающей выборке. Loss: 0.06220752000808716\n",
            "\tЭпоха 3. Итерация 250/6774 на обучающей выборке. Loss: 0.08100369572639465\n",
            "\tЭпоха 3. Итерация 300/6774 на обучающей выборке. Loss: 0.05398137494921684\n",
            "\tЭпоха 3. Итерация 350/6774 на обучающей выборке. Loss: 0.06011999770998955\n",
            "\tЭпоха 3. Итерация 400/6774 на обучающей выборке. Loss: 0.06796097010374069\n",
            "\tЭпоха 3. Итерация 450/6774 на обучающей выборке. Loss: 0.057616226375103\n",
            "\tЭпоха 3. Итерация 500/6774 на обучающей выборке. Loss: 0.11355794966220856\n",
            "\tЭпоха 3. Итерация 550/6774 на обучающей выборке. Loss: 0.039344217628240585\n",
            "\tЭпоха 3. Итерация 600/6774 на обучающей выборке. Loss: 0.09637683629989624\n",
            "\tЭпоха 3. Итерация 650/6774 на обучающей выборке. Loss: 0.08165492862462997\n",
            "\tЭпоха 3. Итерация 700/6774 на обучающей выборке. Loss: 0.05567425489425659\n",
            "\tЭпоха 3. Итерация 750/6774 на обучающей выборке. Loss: 0.12039686739444733\n",
            "\tЭпоха 3. Итерация 800/6774 на обучающей выборке. Loss: 0.05191304534673691\n",
            "\tЭпоха 3. Итерация 850/6774 на обучающей выборке. Loss: 0.050632722675800323\n",
            "\tЭпоха 3. Итерация 900/6774 на обучающей выборке. Loss: 0.07048867642879486\n",
            "\tЭпоха 3. Итерация 950/6774 на обучающей выборке. Loss: 0.07612636685371399\n",
            "\tЭпоха 3. Итерация 1000/6774 на обучающей выборке. Loss: 0.14976489543914795\n",
            "\tЭпоха 3. Итерация 1050/6774 на обучающей выборке. Loss: 0.06031901016831398\n",
            "\tЭпоха 3. Итерация 1100/6774 на обучающей выборке. Loss: 0.08659858256578445\n",
            "\tЭпоха 3. Итерация 1150/6774 на обучающей выборке. Loss: 0.061284951865673065\n",
            "\tЭпоха 3. Итерация 1200/6774 на обучающей выборке. Loss: 0.0497286282479763\n",
            "\tЭпоха 3. Итерация 1250/6774 на обучающей выборке. Loss: 0.044236574321985245\n",
            "\tЭпоха 3. Итерация 1300/6774 на обучающей выборке. Loss: 0.056695543229579926\n",
            "\tЭпоха 3. Итерация 1350/6774 на обучающей выборке. Loss: 0.07949721813201904\n",
            "\tЭпоха 3. Итерация 1400/6774 на обучающей выборке. Loss: 0.056003812700510025\n",
            "\tЭпоха 3. Итерация 1450/6774 на обучающей выборке. Loss: 0.08422239124774933\n",
            "\tЭпоха 3. Итерация 1500/6774 на обучающей выборке. Loss: 0.05275317281484604\n",
            "\tЭпоха 3. Итерация 1550/6774 на обучающей выборке. Loss: 0.06199504807591438\n",
            "\tЭпоха 3. Итерация 1600/6774 на обучающей выборке. Loss: 0.06702414155006409\n",
            "\tЭпоха 3. Итерация 1650/6774 на обучающей выборке. Loss: 0.072775699198246\n",
            "\tЭпоха 3. Итерация 1700/6774 на обучающей выборке. Loss: 0.05097467824816704\n",
            "\tЭпоха 3. Итерация 1750/6774 на обучающей выборке. Loss: 0.05811135843396187\n",
            "\tЭпоха 3. Итерация 1800/6774 на обучающей выборке. Loss: 0.046301648020744324\n",
            "\tЭпоха 3. Итерация 1850/6774 на обучающей выборке. Loss: 0.06669014692306519\n",
            "\tЭпоха 3. Итерация 1900/6774 на обучающей выборке. Loss: 0.058850400149822235\n",
            "\tЭпоха 3. Итерация 1950/6774 на обучающей выборке. Loss: 0.07271641492843628\n",
            "\tЭпоха 3. Итерация 2000/6774 на обучающей выборке. Loss: 0.16328999400138855\n",
            "\tЭпоха 3. Итерация 2050/6774 на обучающей выборке. Loss: 0.035661857575178146\n",
            "\tЭпоха 3. Итерация 2100/6774 на обучающей выборке. Loss: 0.048510052263736725\n",
            "\tЭпоха 3. Итерация 2150/6774 на обучающей выборке. Loss: 0.05984428897500038\n",
            "\tЭпоха 3. Итерация 2200/6774 на обучающей выборке. Loss: 0.053395070135593414\n",
            "\tЭпоха 3. Итерация 2250/6774 на обучающей выборке. Loss: 0.07766406238079071\n",
            "\tЭпоха 3. Итерация 2300/6774 на обучающей выборке. Loss: 0.04954050853848457\n",
            "\tЭпоха 3. Итерация 2350/6774 на обучающей выборке. Loss: 0.05796120688319206\n",
            "\tЭпоха 3. Итерация 2400/6774 на обучающей выборке. Loss: 0.06772883236408234\n",
            "\tЭпоха 3. Итерация 2450/6774 на обучающей выборке. Loss: 0.08902637660503387\n",
            "\tЭпоха 3. Итерация 2500/6774 на обучающей выборке. Loss: 0.06124432384967804\n",
            "\tЭпоха 3. Итерация 2550/6774 на обучающей выборке. Loss: 0.11360986530780792\n",
            "\tЭпоха 3. Итерация 2600/6774 на обучающей выборке. Loss: 0.09366653114557266\n",
            "\tЭпоха 3. Итерация 2650/6774 на обучающей выборке. Loss: 0.09821215271949768\n",
            "\tЭпоха 3. Итерация 2700/6774 на обучающей выборке. Loss: 0.06453490257263184\n",
            "\tЭпоха 3. Итерация 2750/6774 на обучающей выборке. Loss: 0.049593791365623474\n",
            "\tЭпоха 3. Итерация 2800/6774 на обучающей выборке. Loss: 0.09683143347501755\n",
            "\tЭпоха 3. Итерация 2850/6774 на обучающей выборке. Loss: 0.04700734093785286\n",
            "\tЭпоха 3. Итерация 2900/6774 на обучающей выборке. Loss: 0.03669869899749756\n",
            "\tЭпоха 3. Итерация 2950/6774 на обучающей выборке. Loss: 0.08101214468479156\n",
            "\tЭпоха 3. Итерация 3000/6774 на обучающей выборке. Loss: 0.04540696740150452\n",
            "\tЭпоха 3. Итерация 3050/6774 на обучающей выборке. Loss: 0.14588043093681335\n",
            "\tЭпоха 3. Итерация 3100/6774 на обучающей выборке. Loss: 0.05912671983242035\n",
            "\tЭпоха 3. Итерация 3150/6774 на обучающей выборке. Loss: 0.052976664155721664\n",
            "\tЭпоха 3. Итерация 3200/6774 на обучающей выборке. Loss: 0.048713020980358124\n",
            "\tЭпоха 3. Итерация 3250/6774 на обучающей выборке. Loss: 0.07892362028360367\n",
            "\tЭпоха 3. Итерация 3300/6774 на обучающей выборке. Loss: 0.07591035962104797\n",
            "\tЭпоха 3. Итерация 3350/6774 на обучающей выборке. Loss: 0.05257699638605118\n",
            "\tЭпоха 3. Итерация 3400/6774 на обучающей выборке. Loss: 0.08286212384700775\n",
            "\tЭпоха 3. Итерация 3450/6774 на обучающей выборке. Loss: 0.059464726597070694\n",
            "\tЭпоха 3. Итерация 3500/6774 на обучающей выборке. Loss: 0.04162641614675522\n",
            "\tЭпоха 3. Итерация 3550/6774 на обучающей выборке. Loss: 0.051785003393888474\n",
            "\tЭпоха 3. Итерация 3600/6774 на обучающей выборке. Loss: 0.06264989078044891\n",
            "\tЭпоха 3. Итерация 3650/6774 на обучающей выборке. Loss: 0.09070870280265808\n",
            "\tЭпоха 3. Итерация 3700/6774 на обучающей выборке. Loss: 0.06459745764732361\n",
            "\tЭпоха 3. Итерация 3750/6774 на обучающей выборке. Loss: 0.03598533570766449\n",
            "\tЭпоха 3. Итерация 3800/6774 на обучающей выборке. Loss: 0.0769001916050911\n",
            "\tЭпоха 3. Итерация 3850/6774 на обучающей выборке. Loss: 0.046710506081581116\n",
            "\tЭпоха 3. Итерация 3900/6774 на обучающей выборке. Loss: 0.06638333946466446\n",
            "\tЭпоха 3. Итерация 3950/6774 на обучающей выборке. Loss: 0.060317762196063995\n",
            "\tЭпоха 3. Итерация 4000/6774 на обучающей выборке. Loss: 0.0770297572016716\n",
            "\tЭпоха 3. Итерация 4050/6774 на обучающей выборке. Loss: 0.0460074208676815\n",
            "\tЭпоха 3. Итерация 4100/6774 на обучающей выборке. Loss: 0.04896268993616104\n",
            "\tЭпоха 3. Итерация 4150/6774 на обучающей выборке. Loss: 0.05520262196660042\n",
            "\tЭпоха 3. Итерация 4200/6774 на обучающей выборке. Loss: 0.07069330662488937\n",
            "\tЭпоха 3. Итерация 4250/6774 на обучающей выборке. Loss: 0.080477774143219\n",
            "\tЭпоха 3. Итерация 4300/6774 на обучающей выборке. Loss: 0.036845043301582336\n",
            "\tЭпоха 3. Итерация 4350/6774 на обучающей выборке. Loss: 0.07595733553171158\n",
            "\tЭпоха 3. Итерация 4400/6774 на обучающей выборке. Loss: 0.07847587764263153\n",
            "\tЭпоха 3. Итерация 4450/6774 на обучающей выборке. Loss: 0.04898928105831146\n",
            "\tЭпоха 3. Итерация 4500/6774 на обучающей выборке. Loss: 0.0757913663983345\n",
            "\tЭпоха 3. Итерация 4550/6774 на обучающей выборке. Loss: 0.06851640343666077\n",
            "\tЭпоха 3. Итерация 4600/6774 на обучающей выборке. Loss: 0.0459086149930954\n",
            "\tЭпоха 3. Итерация 4650/6774 на обучающей выборке. Loss: 0.05584058165550232\n",
            "\tЭпоха 3. Итерация 4700/6774 на обучающей выборке. Loss: 0.042694464325904846\n",
            "\tЭпоха 3. Итерация 4750/6774 на обучающей выборке. Loss: 0.11079122126102448\n",
            "\tЭпоха 3. Итерация 4800/6774 на обучающей выборке. Loss: 0.0532701276242733\n",
            "\tЭпоха 3. Итерация 4850/6774 на обучающей выборке. Loss: 0.04035243019461632\n",
            "\tЭпоха 3. Итерация 4900/6774 на обучающей выборке. Loss: 0.06717664003372192\n",
            "\tЭпоха 3. Итерация 4950/6774 на обучающей выборке. Loss: 0.05116678774356842\n",
            "\tЭпоха 3. Итерация 5000/6774 на обучающей выборке. Loss: 0.0925820991396904\n",
            "\tЭпоха 3. Итерация 5050/6774 на обучающей выборке. Loss: 0.09789542853832245\n",
            "\tЭпоха 3. Итерация 5100/6774 на обучающей выборке. Loss: 0.04146202653646469\n",
            "\tЭпоха 3. Итерация 5150/6774 на обучающей выборке. Loss: 0.09654758125543594\n",
            "\tЭпоха 3. Итерация 5200/6774 на обучающей выборке. Loss: 0.066517673432827\n",
            "\tЭпоха 3. Итерация 5250/6774 на обучающей выборке. Loss: 0.029735857620835304\n",
            "\tЭпоха 3. Итерация 5300/6774 на обучающей выборке. Loss: 0.06667647510766983\n",
            "\tЭпоха 3. Итерация 5350/6774 на обучающей выборке. Loss: 0.07364578545093536\n",
            "\tЭпоха 3. Итерация 5400/6774 на обучающей выборке. Loss: 0.06419773399829865\n",
            "\tЭпоха 3. Итерация 5450/6774 на обучающей выборке. Loss: 0.038515605032444\n",
            "\tЭпоха 3. Итерация 5500/6774 на обучающей выборке. Loss: 0.043633703142404556\n",
            "\tЭпоха 3. Итерация 5550/6774 на обучающей выборке. Loss: 0.0450630821287632\n",
            "\tЭпоха 3. Итерация 5600/6774 на обучающей выборке. Loss: 0.08361374586820602\n",
            "\tЭпоха 3. Итерация 5650/6774 на обучающей выборке. Loss: 0.04047173261642456\n",
            "\tЭпоха 3. Итерация 5700/6774 на обучающей выборке. Loss: 0.04956279695034027\n",
            "\tЭпоха 3. Итерация 5750/6774 на обучающей выборке. Loss: 0.0374714657664299\n",
            "\tЭпоха 3. Итерация 5800/6774 на обучающей выборке. Loss: 0.1626843810081482\n",
            "\tЭпоха 3. Итерация 5850/6774 на обучающей выборке. Loss: 0.0595109760761261\n",
            "\tЭпоха 3. Итерация 5900/6774 на обучающей выборке. Loss: 0.0439482256770134\n",
            "\tЭпоха 3. Итерация 5950/6774 на обучающей выборке. Loss: 0.06583023071289062\n",
            "\tЭпоха 3. Итерация 6000/6774 на обучающей выборке. Loss: 0.05122985318303108\n",
            "\tЭпоха 3. Итерация 6050/6774 на обучающей выборке. Loss: 0.044673264026641846\n",
            "\tЭпоха 3. Итерация 6100/6774 на обучающей выборке. Loss: 0.0634220615029335\n",
            "\tЭпоха 3. Итерация 6150/6774 на обучающей выборке. Loss: 0.05870363488793373\n",
            "\tЭпоха 3. Итерация 6200/6774 на обучающей выборке. Loss: 0.037227559834718704\n",
            "\tЭпоха 3. Итерация 6250/6774 на обучающей выборке. Loss: 0.06843899935483932\n",
            "\tЭпоха 3. Итерация 6300/6774 на обучающей выборке. Loss: 0.06005656719207764\n",
            "\tЭпоха 3. Итерация 6350/6774 на обучающей выборке. Loss: 0.09002211689949036\n",
            "\tЭпоха 3. Итерация 6400/6774 на обучающей выборке. Loss: 0.07274492084980011\n",
            "\tЭпоха 3. Итерация 6450/6774 на обучающей выборке. Loss: 0.08720149099826813\n",
            "\tЭпоха 3. Итерация 6500/6774 на обучающей выборке. Loss: 0.07343127578496933\n",
            "\tЭпоха 3. Итерация 6550/6774 на обучающей выборке. Loss: 0.062186602503061295\n",
            "\tЭпоха 3. Итерация 6600/6774 на обучающей выборке. Loss: 0.041689470410346985\n",
            "\tЭпоха 3. Итерация 6650/6774 на обучающей выборке. Loss: 0.0765841007232666\n",
            "\tЭпоха 3. Итерация 6700/6774 на обучающей выборке. Loss: 0.05211039260029793\n",
            "\tЭпоха 3. Итерация 6750/6774 на обучающей выборке. Loss: 0.05377567932009697\n",
            "\tЭпоха 3. Итерация 0/625 на тестовой выборке. Loss: 0.08909844607114792\n",
            "\tЭпоха 3. Итерация 50/625 на тестовой выборке. Loss: 0.09374291449785233\n",
            "\tЭпоха 3. Итерация 100/625 на тестовой выборке. Loss: 0.05292681232094765\n",
            "\tЭпоха 3. Итерация 150/625 на тестовой выборке. Loss: 0.04412050172686577\n",
            "\tЭпоха 3. Итерация 200/625 на тестовой выборке. Loss: 0.10289405286312103\n",
            "\tЭпоха 3. Итерация 250/625 на тестовой выборке. Loss: 0.08826185017824173\n",
            "\tЭпоха 3. Итерация 300/625 на тестовой выборке. Loss: 0.169669508934021\n",
            "\tЭпоха 3. Итерация 350/625 на тестовой выборке. Loss: 0.1644209921360016\n",
            "\tЭпоха 3. Итерация 400/625 на тестовой выборке. Loss: 0.12443792074918747\n",
            "\tЭпоха 3. Итерация 450/625 на тестовой выборке. Loss: 0.08947627991437912\n",
            "\tЭпоха 3. Итерация 500/625 на тестовой выборке. Loss: 0.07653943449258804\n",
            "\tЭпоха 3. Итерация 550/625 на тестовой выборке. Loss: 0.048637766391038895\n",
            "\tЭпоха 3. Итерация 600/625 на тестовой выборке. Loss: 0.12884606420993805\n",
            "Эпоха #3 train_loss: 0.008386627608303712, val_loss: 0.010372497848048806\n",
            "Потрачено 87.3 минут на 3 эпоху\n",
            "\tЭпоха 4. Итерация 0/6774 на обучающей выборке. Loss: 0.0432332418859005\n",
            "\tЭпоха 4. Итерация 50/6774 на обучающей выборке. Loss: 0.07435690611600876\n",
            "\tЭпоха 4. Итерация 100/6774 на обучающей выборке. Loss: 0.052265916019678116\n",
            "\tЭпоха 4. Итерация 150/6774 на обучающей выборке. Loss: 0.03650087118148804\n",
            "\tЭпоха 4. Итерация 200/6774 на обучающей выборке. Loss: 0.052702128887176514\n",
            "\tЭпоха 4. Итерация 250/6774 на обучающей выборке. Loss: 0.08865265548229218\n",
            "\tЭпоха 4. Итерация 300/6774 на обучающей выборке. Loss: 0.061257630586624146\n",
            "\tЭпоха 4. Итерация 350/6774 на обучающей выборке. Loss: 0.07277613133192062\n",
            "\tЭпоха 4. Итерация 400/6774 на обучающей выборке. Loss: 0.06114504486322403\n",
            "\tЭпоха 4. Итерация 450/6774 на обучающей выборке. Loss: 0.05441083759069443\n",
            "\tЭпоха 4. Итерация 500/6774 на обучающей выборке. Loss: 0.04417910799384117\n",
            "\tЭпоха 4. Итерация 550/6774 на обучающей выборке. Loss: 0.043200746178627014\n",
            "\tЭпоха 4. Итерация 600/6774 на обучающей выборке. Loss: 0.07192523032426834\n",
            "\tЭпоха 4. Итерация 650/6774 на обучающей выборке. Loss: 0.07721491903066635\n",
            "\tЭпоха 4. Итерация 700/6774 на обучающей выборке. Loss: 0.08333641290664673\n",
            "\tЭпоха 4. Итерация 750/6774 на обучающей выборке. Loss: 0.06167101114988327\n",
            "\tЭпоха 4. Итерация 800/6774 на обучающей выборке. Loss: 0.06833595037460327\n",
            "\tЭпоха 4. Итерация 850/6774 на обучающей выборке. Loss: 0.05326685681939125\n",
            "\tЭпоха 4. Итерация 900/6774 на обучающей выборке. Loss: 0.0826527401804924\n",
            "\tЭпоха 4. Итерация 950/6774 на обучающей выборке. Loss: 0.0709996297955513\n",
            "\tЭпоха 4. Итерация 1000/6774 на обучающей выборке. Loss: 0.05178503319621086\n",
            "\tЭпоха 4. Итерация 1050/6774 на обучающей выборке. Loss: 0.12771382927894592\n",
            "\tЭпоха 4. Итерация 1100/6774 на обучающей выборке. Loss: 0.024627581238746643\n",
            "\tЭпоха 4. Итерация 1150/6774 на обучающей выборке. Loss: 0.03284517675638199\n",
            "\tЭпоха 4. Итерация 1200/6774 на обучающей выборке. Loss: 0.05667725205421448\n",
            "\tЭпоха 4. Итерация 1250/6774 на обучающей выборке. Loss: 0.04470355436205864\n",
            "\tЭпоха 4. Итерация 1300/6774 на обучающей выборке. Loss: 0.04402432590723038\n",
            "\tЭпоха 4. Итерация 1350/6774 на обучающей выборке. Loss: 0.04038200527429581\n",
            "\tЭпоха 4. Итерация 1400/6774 на обучающей выборке. Loss: 0.040417030453681946\n",
            "\tЭпоха 4. Итерация 1450/6774 на обучающей выборке. Loss: 0.031072765588760376\n",
            "\tЭпоха 4. Итерация 1500/6774 на обучающей выборке. Loss: 0.056937724351882935\n",
            "\tЭпоха 4. Итерация 1550/6774 на обучающей выборке. Loss: 0.05135786905884743\n",
            "\tЭпоха 4. Итерация 1600/6774 на обучающей выборке. Loss: 0.09168350696563721\n",
            "\tЭпоха 4. Итерация 1650/6774 на обучающей выборке. Loss: 0.06413871049880981\n",
            "\tЭпоха 4. Итерация 1700/6774 на обучающей выборке. Loss: 0.05806306004524231\n",
            "\tЭпоха 4. Итерация 1750/6774 на обучающей выборке. Loss: 0.06183924898505211\n",
            "\tЭпоха 4. Итерация 1800/6774 на обучающей выборке. Loss: 0.10291766375303268\n",
            "\tЭпоха 4. Итерация 1850/6774 на обучающей выборке. Loss: 0.06067458540201187\n",
            "\tЭпоха 4. Итерация 1900/6774 на обучающей выборке. Loss: 0.043665237724781036\n",
            "\tЭпоха 4. Итерация 1950/6774 на обучающей выборке. Loss: 0.04348447173833847\n",
            "\tЭпоха 4. Итерация 2000/6774 на обучающей выборке. Loss: 0.06880934536457062\n",
            "\tЭпоха 4. Итерация 2050/6774 на обучающей выборке. Loss: 0.049820948392152786\n",
            "\tЭпоха 4. Итерация 2100/6774 на обучающей выборке. Loss: 0.06695996224880219\n",
            "\tЭпоха 4. Итерация 2150/6774 на обучающей выборке. Loss: 0.07071971148252487\n",
            "\tЭпоха 4. Итерация 2200/6774 на обучающей выборке. Loss: 0.06555851548910141\n",
            "\tЭпоха 4. Итерация 2250/6774 на обучающей выборке. Loss: 0.043515902012586594\n",
            "\tЭпоха 4. Итерация 2300/6774 на обучающей выборке. Loss: 0.10481733083724976\n",
            "\tЭпоха 4. Итерация 2350/6774 на обучающей выборке. Loss: 0.066820427775383\n",
            "\tЭпоха 4. Итерация 2400/6774 на обучающей выборке. Loss: 0.08183883130550385\n",
            "\tЭпоха 4. Итерация 2450/6774 на обучающей выборке. Loss: 0.053403791040182114\n",
            "\tЭпоха 4. Итерация 2500/6774 на обучающей выборке. Loss: 0.04934057220816612\n",
            "\tЭпоха 4. Итерация 2550/6774 на обучающей выборке. Loss: 0.08668843656778336\n",
            "\tЭпоха 4. Итерация 2600/6774 на обучающей выборке. Loss: 0.05715538188815117\n",
            "\tЭпоха 4. Итерация 2650/6774 на обучающей выборке. Loss: 0.06024465709924698\n",
            "\tЭпоха 4. Итерация 2700/6774 на обучающей выборке. Loss: 0.06935924291610718\n",
            "\tЭпоха 4. Итерация 2750/6774 на обучающей выборке. Loss: 0.05769994109869003\n",
            "\tЭпоха 4. Итерация 2800/6774 на обучающей выборке. Loss: 0.07123981416225433\n",
            "\tЭпоха 4. Итерация 2850/6774 на обучающей выборке. Loss: 0.07727815210819244\n",
            "\tЭпоха 4. Итерация 2900/6774 на обучающей выборке. Loss: 0.039588894695043564\n",
            "\tЭпоха 4. Итерация 2950/6774 на обучающей выборке. Loss: 0.034104958176612854\n",
            "\tЭпоха 4. Итерация 3000/6774 на обучающей выборке. Loss: 0.06859531998634338\n",
            "\tЭпоха 4. Итерация 3050/6774 на обучающей выборке. Loss: 0.09555365890264511\n",
            "\tЭпоха 4. Итерация 3100/6774 на обучающей выборке. Loss: 0.07600978761911392\n",
            "\tЭпоха 4. Итерация 3150/6774 на обучающей выборке. Loss: 0.08174531161785126\n",
            "\tЭпоха 4. Итерация 3200/6774 на обучающей выборке. Loss: 0.127258762717247\n",
            "\tЭпоха 4. Итерация 3250/6774 на обучающей выборке. Loss: 0.03898325189948082\n",
            "\tЭпоха 4. Итерация 3300/6774 на обучающей выборке. Loss: 0.05597928911447525\n",
            "\tЭпоха 4. Итерация 3350/6774 на обучающей выборке. Loss: 0.06941153109073639\n",
            "\tЭпоха 4. Итерация 3400/6774 на обучающей выборке. Loss: 0.055611349642276764\n",
            "\tЭпоха 4. Итерация 3450/6774 на обучающей выборке. Loss: 0.12045235186815262\n",
            "\tЭпоха 4. Итерация 3500/6774 на обучающей выборке. Loss: 0.06057004630565643\n",
            "\tЭпоха 4. Итерация 3550/6774 на обучающей выборке. Loss: 0.044737111777067184\n",
            "\tЭпоха 4. Итерация 3600/6774 на обучающей выборке. Loss: 0.0665302723646164\n",
            "\tЭпоха 4. Итерация 3650/6774 на обучающей выборке. Loss: 0.03997650370001793\n",
            "\tЭпоха 4. Итерация 3700/6774 на обучающей выборке. Loss: 0.05536152794957161\n",
            "\tЭпоха 4. Итерация 3750/6774 на обучающей выборке. Loss: 0.06339087337255478\n",
            "\tЭпоха 4. Итерация 3800/6774 на обучающей выборке. Loss: 0.1051381453871727\n",
            "\tЭпоха 4. Итерация 3850/6774 на обучающей выборке. Loss: 0.06532658636569977\n",
            "\tЭпоха 4. Итерация 3900/6774 на обучающей выборке. Loss: 0.03278910741209984\n",
            "\tЭпоха 4. Итерация 3950/6774 на обучающей выборке. Loss: 0.05354917049407959\n",
            "\tЭпоха 4. Итерация 4000/6774 на обучающей выборке. Loss: 0.07410405576229095\n",
            "\tЭпоха 4. Итерация 4050/6774 на обучающей выборке. Loss: 0.061627455055713654\n",
            "\tЭпоха 4. Итерация 4100/6774 на обучающей выборке. Loss: 0.05700819194316864\n",
            "\tЭпоха 4. Итерация 4150/6774 на обучающей выборке. Loss: 0.05702267214655876\n",
            "\tЭпоха 4. Итерация 4200/6774 на обучающей выборке. Loss: 0.05195175111293793\n",
            "\tЭпоха 4. Итерация 4250/6774 на обучающей выборке. Loss: 0.07369600236415863\n",
            "\tЭпоха 4. Итерация 4300/6774 на обучающей выборке. Loss: 0.06261172890663147\n",
            "\tЭпоха 4. Итерация 4350/6774 на обучающей выборке. Loss: 0.04620510712265968\n",
            "\tЭпоха 4. Итерация 4400/6774 на обучающей выборке. Loss: 0.03662111982703209\n",
            "\tЭпоха 4. Итерация 4450/6774 на обучающей выборке. Loss: 0.06285101920366287\n",
            "\tЭпоха 4. Итерация 4500/6774 на обучающей выборке. Loss: 0.05553436651825905\n",
            "\tЭпоха 4. Итерация 4550/6774 на обучающей выборке. Loss: 0.096793033182621\n",
            "\tЭпоха 4. Итерация 4600/6774 на обучающей выборке. Loss: 0.031314149498939514\n",
            "\tЭпоха 4. Итерация 4650/6774 на обучающей выборке. Loss: 0.05120602622628212\n",
            "\tЭпоха 4. Итерация 4700/6774 на обучающей выборке. Loss: 0.06449326127767563\n",
            "\tЭпоха 4. Итерация 4750/6774 на обучающей выборке. Loss: 0.03904008865356445\n",
            "\tЭпоха 4. Итерация 4800/6774 на обучающей выборке. Loss: 0.10041462630033493\n",
            "\tЭпоха 4. Итерация 4850/6774 на обучающей выборке. Loss: 0.06377972662448883\n",
            "\tЭпоха 4. Итерация 4900/6774 на обучающей выборке. Loss: 0.05261252820491791\n",
            "\tЭпоха 4. Итерация 4950/6774 на обучающей выборке. Loss: 0.03912513703107834\n",
            "\tЭпоха 4. Итерация 5000/6774 на обучающей выборке. Loss: 0.08873692154884338\n",
            "\tЭпоха 4. Итерация 5050/6774 на обучающей выборке. Loss: 0.07444535195827484\n",
            "\tЭпоха 4. Итерация 5100/6774 на обучающей выборке. Loss: 0.04317014291882515\n",
            "\tЭпоха 4. Итерация 5150/6774 на обучающей выборке. Loss: 0.07393677532672882\n",
            "\tЭпоха 4. Итерация 5200/6774 на обучающей выборке. Loss: 0.060693275183439255\n",
            "\tЭпоха 4. Итерация 5250/6774 на обучающей выборке. Loss: 0.0627107247710228\n",
            "\tЭпоха 4. Итерация 5300/6774 на обучающей выборке. Loss: 0.08183299005031586\n",
            "\tЭпоха 4. Итерация 5350/6774 на обучающей выборке. Loss: 0.047007251530885696\n",
            "\tЭпоха 4. Итерация 5400/6774 на обучающей выборке. Loss: 0.04151032865047455\n",
            "\tЭпоха 4. Итерация 5450/6774 на обучающей выборке. Loss: 0.048214446753263474\n",
            "\tЭпоха 4. Итерация 5500/6774 на обучающей выборке. Loss: 0.054544847458601\n",
            "\tЭпоха 4. Итерация 5550/6774 на обучающей выборке. Loss: 0.03752770274877548\n",
            "\tЭпоха 4. Итерация 5600/6774 на обучающей выборке. Loss: 0.06870739907026291\n",
            "\tЭпоха 4. Итерация 5650/6774 на обучающей выборке. Loss: 0.045407749712467194\n",
            "\tЭпоха 4. Итерация 5700/6774 на обучающей выборке. Loss: 0.04545583575963974\n",
            "\tЭпоха 4. Итерация 5750/6774 на обучающей выборке. Loss: 0.04490531608462334\n",
            "\tЭпоха 4. Итерация 5800/6774 на обучающей выборке. Loss: 0.04905826598405838\n",
            "\tЭпоха 4. Итерация 5850/6774 на обучающей выборке. Loss: 0.07587055116891861\n",
            "\tЭпоха 4. Итерация 5900/6774 на обучающей выборке. Loss: 0.04699090123176575\n",
            "\tЭпоха 4. Итерация 5950/6774 на обучающей выборке. Loss: 0.05261721834540367\n",
            "\tЭпоха 4. Итерация 6000/6774 на обучающей выборке. Loss: 0.07444130629301071\n",
            "\tЭпоха 4. Итерация 6050/6774 на обучающей выборке. Loss: 0.04979981482028961\n",
            "\tЭпоха 4. Итерация 6100/6774 на обучающей выборке. Loss: 0.06478478014469147\n",
            "\tЭпоха 4. Итерация 6150/6774 на обучающей выборке. Loss: 0.05010680854320526\n",
            "\tЭпоха 4. Итерация 6200/6774 на обучающей выборке. Loss: 0.07209282368421555\n",
            "\tЭпоха 4. Итерация 6250/6774 на обучающей выборке. Loss: 0.04252171888947487\n",
            "\tЭпоха 4. Итерация 6300/6774 на обучающей выборке. Loss: 0.039040107280015945\n",
            "\tЭпоха 4. Итерация 6350/6774 на обучающей выборке. Loss: 0.04714203625917435\n",
            "\tЭпоха 4. Итерация 6400/6774 на обучающей выборке. Loss: 0.06851978600025177\n",
            "\tЭпоха 4. Итерация 6450/6774 на обучающей выборке. Loss: 0.06063864380121231\n",
            "\tЭпоха 4. Итерация 6500/6774 на обучающей выборке. Loss: 0.035107117146253586\n",
            "\tЭпоха 4. Итерация 6550/6774 на обучающей выборке. Loss: 0.04549438878893852\n",
            "\tЭпоха 4. Итерация 6600/6774 на обучающей выборке. Loss: 0.05287288874387741\n",
            "\tЭпоха 4. Итерация 6650/6774 на обучающей выборке. Loss: 0.06858329474925995\n",
            "\tЭпоха 4. Итерация 6700/6774 на обучающей выборке. Loss: 0.04377073049545288\n",
            "\tЭпоха 4. Итерация 6750/6774 на обучающей выборке. Loss: 0.05377402529120445\n",
            "\tЭпоха 4. Итерация 0/625 на тестовой выборке. Loss: 0.06987357139587402\n",
            "\tЭпоха 4. Итерация 50/625 на тестовой выборке. Loss: 0.09134417772293091\n",
            "\tЭпоха 4. Итерация 100/625 на тестовой выборке. Loss: 0.04751763120293617\n",
            "\tЭпоха 4. Итерация 150/625 на тестовой выборке. Loss: 0.04653416946530342\n",
            "\tЭпоха 4. Итерация 200/625 на тестовой выборке. Loss: 0.09574882686138153\n",
            "\tЭпоха 4. Итерация 250/625 на тестовой выборке. Loss: 0.07851194590330124\n",
            "\tЭпоха 4. Итерация 300/625 на тестовой выборке. Loss: 0.18151791393756866\n",
            "\tЭпоха 4. Итерация 350/625 на тестовой выборке. Loss: 0.13985872268676758\n",
            "\tЭпоха 4. Итерация 400/625 на тестовой выборке. Loss: 0.1098051369190216\n",
            "\tЭпоха 4. Итерация 450/625 на тестовой выборке. Loss: 0.0939321368932724\n",
            "\tЭпоха 4. Итерация 500/625 на тестовой выборке. Loss: 0.0762682855129242\n",
            "\tЭпоха 4. Итерация 550/625 на тестовой выборке. Loss: 0.051084890961647034\n",
            "\tЭпоха 4. Итерация 600/625 на тестовой выборке. Loss: 0.126338928937912\n",
            "Эпоха #4 train_loss: 0.00789909027828268, val_loss: 0.01026051184348762\n",
            "Потрачено 87.4 минут на 4 эпоху\n",
            "\tЭпоха 5. Итерация 0/6774 на обучающей выборке. Loss: 0.03685493767261505\n",
            "\tЭпоха 5. Итерация 50/6774 на обучающей выборке. Loss: 0.08384358137845993\n",
            "\tЭпоха 5. Итерация 100/6774 на обучающей выборке. Loss: 0.06261704117059708\n",
            "\tЭпоха 5. Итерация 150/6774 на обучающей выборке. Loss: 0.03035934641957283\n",
            "\tЭпоха 5. Итерация 200/6774 на обучающей выборке. Loss: 0.033784594386816025\n",
            "\tЭпоха 5. Итерация 250/6774 на обучающей выборке. Loss: 0.05527728796005249\n",
            "\tЭпоха 5. Итерация 300/6774 на обучающей выборке. Loss: 0.07508876174688339\n",
            "\tЭпоха 5. Итерация 350/6774 на обучающей выборке. Loss: 0.10269834101200104\n",
            "\tЭпоха 5. Итерация 400/6774 на обучающей выборке. Loss: 0.050939880311489105\n",
            "\tЭпоха 5. Итерация 450/6774 на обучающей выборке. Loss: 0.06684772670269012\n",
            "\tЭпоха 5. Итерация 500/6774 на обучающей выборке. Loss: 0.038124002516269684\n",
            "\tЭпоха 5. Итерация 550/6774 на обучающей выборке. Loss: 0.042984817177057266\n",
            "\tЭпоха 5. Итерация 600/6774 на обучающей выборке. Loss: 0.08194443583488464\n",
            "\tЭпоха 5. Итерация 650/6774 на обучающей выборке. Loss: 0.04976753145456314\n",
            "\tЭпоха 5. Итерация 700/6774 на обучающей выборке. Loss: 0.057993195950984955\n",
            "\tЭпоха 5. Итерация 750/6774 на обучающей выборке. Loss: 0.06546875834465027\n",
            "\tЭпоха 5. Итерация 800/6774 на обучающей выборке. Loss: 0.0451473593711853\n",
            "\tЭпоха 5. Итерация 850/6774 на обучающей выборке. Loss: 0.037364661693573\n",
            "\tЭпоха 5. Итерация 900/6774 на обучающей выборке. Loss: 0.05273715779185295\n",
            "\tЭпоха 5. Итерация 950/6774 на обучающей выборке. Loss: 0.08084392547607422\n",
            "\tЭпоха 5. Итерация 1000/6774 на обучающей выборке. Loss: 0.08065838366746902\n",
            "\tЭпоха 5. Итерация 1050/6774 на обучающей выборке. Loss: 0.04735267907381058\n",
            "\tЭпоха 5. Итерация 1100/6774 на обучающей выборке. Loss: 0.032124970108270645\n",
            "\tЭпоха 5. Итерация 1150/6774 на обучающей выборке. Loss: 0.07646505534648895\n",
            "\tЭпоха 5. Итерация 1200/6774 на обучающей выборке. Loss: 0.06081539765000343\n",
            "\tЭпоха 5. Итерация 1250/6774 на обучающей выборке. Loss: 0.039500392973423004\n",
            "\tЭпоха 5. Итерация 1300/6774 на обучающей выборке. Loss: 0.06689303368330002\n",
            "\tЭпоха 5. Итерация 1350/6774 на обучающей выборке. Loss: 0.05580246075987816\n",
            "\tЭпоха 5. Итерация 1400/6774 на обучающей выборке. Loss: 0.1020466685295105\n",
            "\tЭпоха 5. Итерация 1450/6774 на обучающей выборке. Loss: 0.06747125834226608\n",
            "\tЭпоха 5. Итерация 1500/6774 на обучающей выборке. Loss: 0.06271753460168839\n",
            "\tЭпоха 5. Итерация 1550/6774 на обучающей выборке. Loss: 0.03885555639863014\n",
            "\tЭпоха 5. Итерация 1600/6774 на обучающей выборке. Loss: 0.05123061314225197\n",
            "\tЭпоха 5. Итерация 1650/6774 на обучающей выборке. Loss: 0.052273139357566833\n",
            "\tЭпоха 5. Итерация 1700/6774 на обучающей выборке. Loss: 0.04555048421025276\n",
            "\tЭпоха 5. Итерация 1750/6774 на обучающей выборке. Loss: 0.08162309974431992\n",
            "\tЭпоха 5. Итерация 1800/6774 на обучающей выборке. Loss: 0.12398746609687805\n",
            "\tЭпоха 5. Итерация 1850/6774 на обучающей выборке. Loss: 0.08421913534402847\n",
            "\tЭпоха 5. Итерация 1900/6774 на обучающей выборке. Loss: 0.05328795686364174\n",
            "\tЭпоха 5. Итерация 1950/6774 на обучающей выборке. Loss: 0.087827667593956\n",
            "\tЭпоха 5. Итерация 2000/6774 на обучающей выборке. Loss: 0.0779239758849144\n",
            "\tЭпоха 5. Итерация 2050/6774 на обучающей выборке. Loss: 0.06001181900501251\n",
            "\tЭпоха 5. Итерация 2100/6774 на обучающей выборке. Loss: 0.06553274393081665\n",
            "\tЭпоха 5. Итерация 2150/6774 на обучающей выборке. Loss: 0.05360262468457222\n",
            "\tЭпоха 5. Итерация 2200/6774 на обучающей выборке. Loss: 0.07494384795427322\n",
            "\tЭпоха 5. Итерация 2250/6774 на обучающей выборке. Loss: 0.040294088423252106\n",
            "\tЭпоха 5. Итерация 2300/6774 на обучающей выборке. Loss: 0.05737323686480522\n",
            "\tЭпоха 5. Итерация 2350/6774 на обучающей выборке. Loss: 0.04236244782805443\n",
            "\tЭпоха 5. Итерация 2400/6774 на обучающей выборке. Loss: 0.08345761150121689\n",
            "\tЭпоха 5. Итерация 2450/6774 на обучающей выборке. Loss: 0.0622040294110775\n",
            "\tЭпоха 5. Итерация 2500/6774 на обучающей выборке. Loss: 0.06400986760854721\n",
            "\tЭпоха 5. Итерация 2550/6774 на обучающей выборке. Loss: 0.0894101932644844\n",
            "\tЭпоха 5. Итерация 2600/6774 на обучающей выборке. Loss: 0.08510106056928635\n",
            "\tЭпоха 5. Итерация 2650/6774 на обучающей выборке. Loss: 0.06415363401174545\n",
            "\tЭпоха 5. Итерация 2700/6774 на обучающей выборке. Loss: 0.05368705093860626\n",
            "\tЭпоха 5. Итерация 2750/6774 на обучающей выборке. Loss: 0.032120395451784134\n",
            "\tЭпоха 5. Итерация 2800/6774 на обучающей выборке. Loss: 0.05033953860402107\n",
            "\tЭпоха 5. Итерация 2850/6774 на обучающей выборке. Loss: 0.12420138716697693\n",
            "\tЭпоха 5. Итерация 2900/6774 на обучающей выборке. Loss: 0.08868959546089172\n",
            "\tЭпоха 5. Итерация 2950/6774 на обучающей выборке. Loss: 0.03597840666770935\n",
            "\tЭпоха 5. Итерация 3000/6774 на обучающей выборке. Loss: 0.08309799432754517\n",
            "\tЭпоха 5. Итерация 3050/6774 на обучающей выборке. Loss: 0.07045415043830872\n",
            "\tЭпоха 5. Итерация 3100/6774 на обучающей выборке. Loss: 0.08699395507574081\n",
            "\tЭпоха 5. Итерация 3150/6774 на обучающей выборке. Loss: 0.06655040383338928\n",
            "\tЭпоха 5. Итерация 3200/6774 на обучающей выборке. Loss: 0.11149219423532486\n",
            "\tЭпоха 5. Итерация 3250/6774 на обучающей выборке. Loss: 0.05484791472554207\n",
            "\tЭпоха 5. Итерация 3300/6774 на обучающей выборке. Loss: 0.04685423895716667\n",
            "\tЭпоха 5. Итерация 3350/6774 на обучающей выборке. Loss: 0.054930686950683594\n",
            "\tЭпоха 5. Итерация 3400/6774 на обучающей выборке. Loss: 0.057430822402238846\n",
            "\tЭпоха 5. Итерация 3450/6774 на обучающей выборке. Loss: 0.03629939630627632\n",
            "\tЭпоха 5. Итерация 3500/6774 на обучающей выборке. Loss: 0.06239643320441246\n",
            "\tЭпоха 5. Итерация 3550/6774 на обучающей выборке. Loss: 0.05562714859843254\n",
            "\tЭпоха 5. Итерация 3600/6774 на обучающей выборке. Loss: 0.063364677131176\n",
            "\tЭпоха 5. Итерация 3650/6774 на обучающей выборке. Loss: 0.05114998668432236\n",
            "\tЭпоха 5. Итерация 3700/6774 на обучающей выборке. Loss: 0.07452971488237381\n",
            "\tЭпоха 5. Итерация 3750/6774 на обучающей выборке. Loss: 0.05048820748925209\n",
            "\tЭпоха 5. Итерация 3800/6774 на обучающей выборке. Loss: 0.04445798322558403\n",
            "\tЭпоха 5. Итерация 3850/6774 на обучающей выборке. Loss: 0.05379294231534004\n",
            "\tЭпоха 5. Итерация 3900/6774 на обучающей выборке. Loss: 0.054420214146375656\n",
            "\tЭпоха 5. Итерация 3950/6774 на обучающей выборке. Loss: 0.052715200930833817\n",
            "\tЭпоха 5. Итерация 4000/6774 на обучающей выборке. Loss: 0.09378319978713989\n",
            "\tЭпоха 5. Итерация 4050/6774 на обучающей выборке. Loss: 0.05054895207285881\n",
            "\tЭпоха 5. Итерация 4100/6774 на обучающей выборке. Loss: 0.03325463458895683\n",
            "\tЭпоха 5. Итерация 4150/6774 на обучающей выборке. Loss: 0.036759376525878906\n",
            "\tЭпоха 5. Итерация 4200/6774 на обучающей выборке. Loss: 0.051578693091869354\n",
            "\tЭпоха 5. Итерация 4250/6774 на обучающей выборке. Loss: 0.04782714322209358\n",
            "\tЭпоха 5. Итерация 4300/6774 на обучающей выборке. Loss: 0.05718260258436203\n",
            "\tЭпоха 5. Итерация 4350/6774 на обучающей выборке. Loss: 0.07652753591537476\n",
            "\tЭпоха 5. Итерация 4400/6774 на обучающей выборке. Loss: 0.03397262096405029\n",
            "\tЭпоха 5. Итерация 4450/6774 на обучающей выборке. Loss: 0.08923190832138062\n",
            "\tЭпоха 5. Итерация 4500/6774 на обучающей выборке. Loss: 0.08018065243959427\n",
            "\tЭпоха 5. Итерация 4550/6774 на обучающей выборке. Loss: 0.03324835002422333\n",
            "\tЭпоха 5. Итерация 4600/6774 на обучающей выборке. Loss: 0.047848671674728394\n",
            "\tЭпоха 5. Итерация 4650/6774 на обучающей выборке. Loss: 0.1339678317308426\n",
            "\tЭпоха 5. Итерация 4700/6774 на обучающей выборке. Loss: 0.050623662769794464\n",
            "\tЭпоха 5. Итерация 4750/6774 на обучающей выборке. Loss: 0.06420964747667313\n",
            "\tЭпоха 5. Итерация 4800/6774 на обучающей выборке. Loss: 0.06287156045436859\n",
            "\tЭпоха 5. Итерация 4850/6774 на обучающей выборке. Loss: 0.0573742613196373\n",
            "\tЭпоха 5. Итерация 4900/6774 на обучающей выборке. Loss: 0.043764352798461914\n",
            "\tЭпоха 5. Итерация 4950/6774 на обучающей выборке. Loss: 0.03947114944458008\n",
            "\tЭпоха 5. Итерация 5000/6774 на обучающей выборке. Loss: 0.0699898824095726\n",
            "\tЭпоха 5. Итерация 5050/6774 на обучающей выборке. Loss: 0.057600077241659164\n",
            "\tЭпоха 5. Итерация 5100/6774 на обучающей выборке. Loss: 0.07145530730485916\n",
            "\tЭпоха 5. Итерация 5150/6774 на обучающей выборке. Loss: 0.052796825766563416\n",
            "\tЭпоха 5. Итерация 5200/6774 на обучающей выборке. Loss: 0.10631794482469559\n",
            "\tЭпоха 5. Итерация 5250/6774 на обучающей выборке. Loss: 0.05663316324353218\n",
            "\tЭпоха 5. Итерация 5300/6774 на обучающей выборке. Loss: 0.058873001486063004\n",
            "\tЭпоха 5. Итерация 5350/6774 на обучающей выборке. Loss: 0.04628685861825943\n",
            "\tЭпоха 5. Итерация 5400/6774 на обучающей выборке. Loss: 0.07482394576072693\n",
            "\tЭпоха 5. Итерация 5450/6774 на обучающей выборке. Loss: 0.06350859999656677\n",
            "\tЭпоха 5. Итерация 5500/6774 на обучающей выборке. Loss: 0.042495932430028915\n",
            "\tЭпоха 5. Итерация 5550/6774 на обучающей выборке. Loss: 0.05258315056562424\n",
            "\tЭпоха 5. Итерация 5600/6774 на обучающей выборке. Loss: 0.09714306145906448\n",
            "\tЭпоха 5. Итерация 5650/6774 на обучающей выборке. Loss: 0.06977097690105438\n",
            "\tЭпоха 5. Итерация 5700/6774 на обучающей выборке. Loss: 0.06993535906076431\n",
            "\tЭпоха 5. Итерация 5750/6774 на обучающей выборке. Loss: 0.05755966901779175\n",
            "\tЭпоха 5. Итерация 5800/6774 на обучающей выборке. Loss: 0.08114583790302277\n",
            "\tЭпоха 5. Итерация 5850/6774 на обучающей выборке. Loss: 0.07262448221445084\n",
            "\tЭпоха 5. Итерация 5900/6774 на обучающей выборке. Loss: 0.07276643067598343\n",
            "\tЭпоха 5. Итерация 5950/6774 на обучающей выборке. Loss: 0.042536091059446335\n",
            "\tЭпоха 5. Итерация 6000/6774 на обучающей выборке. Loss: 0.08995989710092545\n",
            "\tЭпоха 5. Итерация 6050/6774 на обучающей выборке. Loss: 0.049794506281614304\n",
            "\tЭпоха 5. Итерация 6100/6774 на обучающей выборке. Loss: 0.051206398755311966\n",
            "\tЭпоха 5. Итерация 6150/6774 на обучающей выборке. Loss: 0.05146120861172676\n",
            "\tЭпоха 5. Итерация 6200/6774 на обучающей выборке. Loss: 0.061023250222206116\n",
            "\tЭпоха 5. Итерация 6250/6774 на обучающей выборке. Loss: 0.05461113527417183\n",
            "\tЭпоха 5. Итерация 6300/6774 на обучающей выборке. Loss: 0.04675300791859627\n",
            "\tЭпоха 5. Итерация 6350/6774 на обучающей выборке. Loss: 0.0377560593187809\n",
            "\tЭпоха 5. Итерация 6400/6774 на обучающей выборке. Loss: 0.0840221494436264\n",
            "\tЭпоха 5. Итерация 6450/6774 на обучающей выборке. Loss: 0.07281583547592163\n",
            "\tЭпоха 5. Итерация 6500/6774 на обучающей выборке. Loss: 0.05295175686478615\n",
            "\tЭпоха 5. Итерация 6550/6774 на обучающей выборке. Loss: 0.03601367771625519\n",
            "\tЭпоха 5. Итерация 6600/6774 на обучающей выборке. Loss: 0.07510345429182053\n",
            "\tЭпоха 5. Итерация 6650/6774 на обучающей выборке. Loss: 0.04702796787023544\n",
            "\tЭпоха 5. Итерация 6700/6774 на обучающей выборке. Loss: 0.12236608564853668\n",
            "\tЭпоха 5. Итерация 6750/6774 на обучающей выборке. Loss: 0.06447900831699371\n",
            "\tЭпоха 5. Итерация 0/625 на тестовой выборке. Loss: 0.07431674748659134\n",
            "\tЭпоха 5. Итерация 50/625 на тестовой выборке. Loss: 0.09199691563844681\n",
            "\tЭпоха 5. Итерация 100/625 на тестовой выборке. Loss: 0.050141554325819016\n",
            "\tЭпоха 5. Итерация 150/625 на тестовой выборке. Loss: 0.05181317403912544\n",
            "\tЭпоха 5. Итерация 200/625 на тестовой выборке. Loss: 0.09361755102872849\n",
            "\tЭпоха 5. Итерация 250/625 на тестовой выборке. Loss: 0.0782565101981163\n",
            "\tЭпоха 5. Итерация 300/625 на тестовой выборке. Loss: 0.1719636172056198\n",
            "\tЭпоха 5. Итерация 350/625 на тестовой выборке. Loss: 0.16349723935127258\n",
            "\tЭпоха 5. Итерация 400/625 на тестовой выборке. Loss: 0.1128716990351677\n",
            "\tЭпоха 5. Итерация 450/625 на тестовой выборке. Loss: 0.09195592254400253\n",
            "\tЭпоха 5. Итерация 500/625 на тестовой выборке. Loss: 0.08109372109174728\n",
            "\tЭпоха 5. Итерация 550/625 на тестовой выборке. Loss: 0.05339757353067398\n",
            "\tЭпоха 5. Итерация 600/625 на тестовой выборке. Loss: 0.13265445828437805\n",
            "Эпоха #5 train_loss: 0.007611670604170484, val_loss: 0.010762068482115864\n",
            "Потрачено 87.6 минут на 5 эпоху\n",
            "\tЭпоха 6. Итерация 0/6774 на обучающей выборке. Loss: 0.04120368883013725\n",
            "\tЭпоха 6. Итерация 50/6774 на обучающей выборке. Loss: 0.08373283594846725\n",
            "\tЭпоха 6. Итерация 100/6774 на обучающей выборке. Loss: 0.04129161313176155\n",
            "\tЭпоха 6. Итерация 150/6774 на обучающей выборке. Loss: 0.05843096226453781\n",
            "\tЭпоха 6. Итерация 200/6774 на обучающей выборке. Loss: 0.062468271702528\n",
            "\tЭпоха 6. Итерация 250/6774 на обучающей выборке. Loss: 0.047106239944696426\n",
            "\tЭпоха 6. Итерация 300/6774 на обучающей выборке. Loss: 0.06812487542629242\n",
            "\tЭпоха 6. Итерация 350/6774 на обучающей выборке. Loss: 0.07912660390138626\n",
            "\tЭпоха 6. Итерация 400/6774 на обучающей выборке. Loss: 0.04291698336601257\n",
            "\tЭпоха 6. Итерация 450/6774 на обучающей выборке. Loss: 0.03941936418414116\n",
            "\tЭпоха 6. Итерация 500/6774 на обучающей выборке. Loss: 0.05066259577870369\n",
            "\tЭпоха 6. Итерация 550/6774 на обучающей выборке. Loss: 0.04726019501686096\n",
            "\tЭпоха 6. Итерация 600/6774 на обучающей выборке. Loss: 0.07289610058069229\n",
            "\tЭпоха 6. Итерация 650/6774 на обучающей выборке. Loss: 0.07219242304563522\n",
            "\tЭпоха 6. Итерация 700/6774 на обучающей выборке. Loss: 0.04313355311751366\n",
            "\tЭпоха 6. Итерация 750/6774 на обучающей выборке. Loss: 0.06250583380460739\n",
            "\tЭпоха 6. Итерация 800/6774 на обучающей выборке. Loss: 0.07408153265714645\n",
            "\tЭпоха 6. Итерация 850/6774 на обучающей выборке. Loss: 0.03506544232368469\n",
            "\tЭпоха 6. Итерация 900/6774 на обучающей выборке. Loss: 0.09151823818683624\n",
            "\tЭпоха 6. Итерация 950/6774 на обучающей выборке. Loss: 0.049420904368162155\n",
            "\tЭпоха 6. Итерация 1000/6774 на обучающей выборке. Loss: 0.05013111233711243\n",
            "\tЭпоха 6. Итерация 1050/6774 на обучающей выборке. Loss: 0.05370313674211502\n",
            "\tЭпоха 6. Итерация 1100/6774 на обучающей выборке. Loss: 0.07072705775499344\n",
            "\tЭпоха 6. Итерация 1150/6774 на обучающей выборке. Loss: 0.11198865622282028\n",
            "\tЭпоха 6. Итерация 1200/6774 на обучающей выборке. Loss: 0.06089240312576294\n",
            "\tЭпоха 6. Итерация 1250/6774 на обучающей выборке. Loss: 0.05626894161105156\n",
            "\tЭпоха 6. Итерация 1300/6774 на обучающей выборке. Loss: 0.06505071371793747\n",
            "\tЭпоха 6. Итерация 1350/6774 на обучающей выборке. Loss: 0.02730315737426281\n",
            "\tЭпоха 6. Итерация 1400/6774 на обучающей выборке. Loss: 0.060615744441747665\n",
            "\tЭпоха 6. Итерация 1450/6774 на обучающей выборке. Loss: 0.04744260013103485\n",
            "\tЭпоха 6. Итерация 1500/6774 на обучающей выборке. Loss: 0.0850708857178688\n",
            "\tЭпоха 6. Итерация 1550/6774 на обучающей выборке. Loss: 0.07694010436534882\n",
            "\tЭпоха 6. Итерация 1600/6774 на обучающей выборке. Loss: 0.03653200343251228\n",
            "\tЭпоха 6. Итерация 1650/6774 на обучающей выборке. Loss: 0.08424687385559082\n",
            "\tЭпоха 6. Итерация 1700/6774 на обучающей выборке. Loss: 0.03247298672795296\n",
            "\tЭпоха 6. Итерация 1750/6774 на обучающей выборке. Loss: 0.045030299574136734\n",
            "\tЭпоха 6. Итерация 1800/6774 на обучающей выборке. Loss: 0.06246934458613396\n",
            "\tЭпоха 6. Итерация 1850/6774 на обучающей выборке. Loss: 0.03570456802845001\n",
            "\tЭпоха 6. Итерация 1900/6774 на обучающей выборке. Loss: 0.036927469074726105\n",
            "\tЭпоха 6. Итерация 1950/6774 на обучающей выборке. Loss: 0.07106250524520874\n",
            "\tЭпоха 6. Итерация 2000/6774 на обучающей выборке. Loss: 0.06016331911087036\n",
            "\tЭпоха 6. Итерация 2050/6774 на обучающей выборке. Loss: 0.045179642736911774\n",
            "\tЭпоха 6. Итерация 2100/6774 на обучающей выборке. Loss: 0.11737405508756638\n",
            "\tЭпоха 6. Итерация 2150/6774 на обучающей выборке. Loss: 0.06424516439437866\n",
            "\tЭпоха 6. Итерация 2200/6774 на обучающей выборке. Loss: 0.052844543009996414\n",
            "\tЭпоха 6. Итерация 2250/6774 на обучающей выборке. Loss: 0.06676122546195984\n",
            "\tЭпоха 6. Итерация 2300/6774 на обучающей выборке. Loss: 0.10791584849357605\n",
            "\tЭпоха 6. Итерация 2350/6774 на обучающей выборке. Loss: 0.0595717616379261\n",
            "\tЭпоха 6. Итерация 2400/6774 на обучающей выборке. Loss: 0.056508008390665054\n",
            "\tЭпоха 6. Итерация 2450/6774 на обучающей выборке. Loss: 0.0416431799530983\n",
            "\tЭпоха 6. Итерация 2500/6774 на обучающей выборке. Loss: 0.047772664576768875\n",
            "\tЭпоха 6. Итерация 2550/6774 на обучающей выборке. Loss: 0.031585343182086945\n",
            "\tЭпоха 6. Итерация 2600/6774 на обучающей выборке. Loss: 0.025073671713471413\n",
            "\tЭпоха 6. Итерация 2650/6774 на обучающей выборке. Loss: 0.04323393851518631\n",
            "\tЭпоха 6. Итерация 2700/6774 на обучающей выборке. Loss: 0.07182417809963226\n",
            "\tЭпоха 6. Итерация 2750/6774 на обучающей выборке. Loss: 0.07224414497613907\n",
            "\tЭпоха 6. Итерация 2800/6774 на обучающей выборке. Loss: 0.051166463643312454\n",
            "\tЭпоха 6. Итерация 2850/6774 на обучающей выборке. Loss: 0.032402120530605316\n",
            "\tЭпоха 6. Итерация 2900/6774 на обучающей выборке. Loss: 0.03938707336783409\n",
            "\tЭпоха 6. Итерация 2950/6774 на обучающей выборке. Loss: 0.0723639652132988\n",
            "\tЭпоха 6. Итерация 3000/6774 на обучающей выборке. Loss: 0.06016593798995018\n",
            "\tЭпоха 6. Итерация 3050/6774 на обучающей выборке. Loss: 0.05813024938106537\n",
            "\tЭпоха 6. Итерация 3100/6774 на обучающей выборке. Loss: 0.05463191121816635\n",
            "\tЭпоха 6. Итерация 3150/6774 на обучающей выборке. Loss: 0.07745344191789627\n",
            "\tЭпоха 6. Итерация 3200/6774 на обучающей выборке. Loss: 0.05028008669614792\n",
            "\tЭпоха 6. Итерация 3250/6774 на обучающей выборке. Loss: 0.07534002512693405\n",
            "\tЭпоха 6. Итерация 3300/6774 на обучающей выборке. Loss: 0.04209808260202408\n",
            "\tЭпоха 6. Итерация 3350/6774 на обучающей выборке. Loss: 0.06030214577913284\n",
            "\tЭпоха 6. Итерация 3400/6774 на обучающей выборке. Loss: 0.05237474665045738\n",
            "\tЭпоха 6. Итерация 3450/6774 на обучающей выборке. Loss: 0.06829211115837097\n",
            "\tЭпоха 6. Итерация 3500/6774 на обучающей выборке. Loss: 0.040941763669252396\n",
            "\tЭпоха 6. Итерация 3550/6774 на обучающей выборке. Loss: 0.05970708653330803\n",
            "\tЭпоха 6. Итерация 3600/6774 на обучающей выборке. Loss: 0.0439874529838562\n",
            "\tЭпоха 6. Итерация 3650/6774 на обучающей выборке. Loss: 0.05106167867779732\n",
            "\tЭпоха 6. Итерация 3700/6774 на обучающей выборке. Loss: 0.03543659299612045\n",
            "\tЭпоха 6. Итерация 3750/6774 на обучающей выборке. Loss: 0.05998333543539047\n",
            "\tЭпоха 6. Итерация 3800/6774 на обучающей выборке. Loss: 0.05811573192477226\n",
            "\tЭпоха 6. Итерация 3850/6774 на обучающей выборке. Loss: 0.06412970274686813\n",
            "\tЭпоха 6. Итерация 3900/6774 на обучающей выборке. Loss: 0.05674508959054947\n",
            "\tЭпоха 6. Итерация 3950/6774 на обучающей выборке. Loss: 0.06422779709100723\n",
            "\tЭпоха 6. Итерация 4000/6774 на обучающей выборке. Loss: 0.04476044699549675\n",
            "\tЭпоха 6. Итерация 4050/6774 на обучающей выборке. Loss: 0.033637963235378265\n",
            "\tЭпоха 6. Итерация 4100/6774 на обучающей выборке. Loss: 0.05462116748094559\n",
            "\tЭпоха 6. Итерация 4150/6774 на обучающей выборке. Loss: 0.061972714960575104\n",
            "\tЭпоха 6. Итерация 4200/6774 на обучающей выборке. Loss: 0.07604669034481049\n",
            "\tЭпоха 6. Итерация 4250/6774 на обучающей выборке. Loss: 0.06277529150247574\n",
            "\tЭпоха 6. Итерация 4300/6774 на обучающей выборке. Loss: 0.06785358488559723\n",
            "\tЭпоха 6. Итерация 4350/6774 на обучающей выборке. Loss: 0.05852995812892914\n",
            "\tЭпоха 6. Итерация 4400/6774 на обучающей выборке. Loss: 0.05706613138318062\n",
            "\tЭпоха 6. Итерация 4450/6774 на обучающей выборке. Loss: 0.04545510187745094\n",
            "\tЭпоха 6. Итерация 4500/6774 на обучающей выборке. Loss: 0.0583978109061718\n",
            "\tЭпоха 6. Итерация 4550/6774 на обучающей выборке. Loss: 0.04503441974520683\n",
            "\tЭпоха 6. Итерация 4600/6774 на обучающей выборке. Loss: 0.04197118431329727\n",
            "\tЭпоха 6. Итерация 4650/6774 на обучающей выборке. Loss: 0.06335976719856262\n",
            "\tЭпоха 6. Итерация 4700/6774 на обучающей выборке. Loss: 0.04244410991668701\n",
            "\tЭпоха 6. Итерация 4750/6774 на обучающей выборке. Loss: 0.05198824033141136\n",
            "\tЭпоха 6. Итерация 4800/6774 на обучающей выборке. Loss: 0.09337490797042847\n",
            "\tЭпоха 6. Итерация 4850/6774 на обучающей выборке. Loss: 0.044407229870557785\n",
            "\tЭпоха 6. Итерация 4900/6774 на обучающей выборке. Loss: 0.05572524294257164\n",
            "\tЭпоха 6. Итерация 4950/6774 на обучающей выборке. Loss: 0.05127980187535286\n",
            "\tЭпоха 6. Итерация 5000/6774 на обучающей выборке. Loss: 0.07184787094593048\n",
            "\tЭпоха 6. Итерация 5050/6774 на обучающей выборке. Loss: 0.06029067188501358\n",
            "\tЭпоха 6. Итерация 5100/6774 на обучающей выборке. Loss: 0.03368404880166054\n",
            "\tЭпоха 6. Итерация 5150/6774 на обучающей выборке. Loss: 0.031326115131378174\n",
            "\tЭпоха 6. Итерация 5200/6774 на обучающей выборке. Loss: 0.036507803946733475\n",
            "\tЭпоха 6. Итерация 5250/6774 на обучающей выборке. Loss: 0.04261951893568039\n",
            "\tЭпоха 6. Итерация 5300/6774 на обучающей выборке. Loss: 0.061588943004608154\n",
            "\tЭпоха 6. Итерация 5350/6774 на обучающей выборке. Loss: 0.0413370244204998\n",
            "\tЭпоха 6. Итерация 5400/6774 на обучающей выборке. Loss: 0.029905548319220543\n",
            "\tЭпоха 6. Итерация 5450/6774 на обучающей выборке. Loss: 0.04327436536550522\n",
            "\tЭпоха 6. Итерация 5500/6774 на обучающей выборке. Loss: 0.0423644557595253\n",
            "\tЭпоха 6. Итерация 5550/6774 на обучающей выборке. Loss: 0.03830459341406822\n",
            "\tЭпоха 6. Итерация 5600/6774 на обучающей выборке. Loss: 0.07565300911664963\n",
            "\tЭпоха 6. Итерация 5650/6774 на обучающей выборке. Loss: 0.05941032990813255\n",
            "\tЭпоха 6. Итерация 5700/6774 на обучающей выборке. Loss: 0.05506132170557976\n",
            "\tЭпоха 6. Итерация 5750/6774 на обучающей выборке. Loss: 0.06906616687774658\n",
            "\tЭпоха 6. Итерация 5800/6774 на обучающей выборке. Loss: 0.05895034596323967\n",
            "\tЭпоха 6. Итерация 5850/6774 на обучающей выборке. Loss: 0.04202435538172722\n",
            "\tЭпоха 6. Итерация 5900/6774 на обучающей выборке. Loss: 0.07633326947689056\n",
            "\tЭпоха 6. Итерация 5950/6774 на обучающей выборке. Loss: 0.05281364545226097\n",
            "\tЭпоха 6. Итерация 6000/6774 на обучающей выборке. Loss: 0.08220351487398148\n",
            "\tЭпоха 6. Итерация 6050/6774 на обучающей выборке. Loss: 0.059788282960653305\n",
            "\tЭпоха 6. Итерация 6100/6774 на обучающей выборке. Loss: 0.08634782582521439\n",
            "\tЭпоха 6. Итерация 6150/6774 на обучающей выборке. Loss: 0.04058396443724632\n",
            "\tЭпоха 6. Итерация 6200/6774 на обучающей выборке. Loss: 0.05743071436882019\n",
            "\tЭпоха 6. Итерация 6250/6774 на обучающей выборке. Loss: 0.04362424835562706\n",
            "\tЭпоха 6. Итерация 6300/6774 на обучающей выборке. Loss: 0.06936027854681015\n",
            "\tЭпоха 6. Итерация 6350/6774 на обучающей выборке. Loss: 0.04370318353176117\n",
            "\tЭпоха 6. Итерация 6400/6774 на обучающей выборке. Loss: 0.08629132062196732\n",
            "\tЭпоха 6. Итерация 6450/6774 на обучающей выборке. Loss: 0.041146960109472275\n",
            "\tЭпоха 6. Итерация 6500/6774 на обучающей выборке. Loss: 0.04755615442991257\n",
            "\tЭпоха 6. Итерация 6550/6774 на обучающей выборке. Loss: 0.05697918310761452\n",
            "\tЭпоха 6. Итерация 6600/6774 на обучающей выборке. Loss: 0.09058596938848495\n",
            "\tЭпоха 6. Итерация 6650/6774 на обучающей выборке. Loss: 0.06678027659654617\n",
            "\tЭпоха 6. Итерация 6700/6774 на обучающей выборке. Loss: 0.061494871973991394\n",
            "\tЭпоха 6. Итерация 6750/6774 на обучающей выборке. Loss: 0.07031995058059692\n",
            "\tЭпоха 6. Итерация 0/625 на тестовой выборке. Loss: 0.07551062107086182\n",
            "\tЭпоха 6. Итерация 50/625 на тестовой выборке. Loss: 0.08289753645658493\n",
            "\tЭпоха 6. Итерация 100/625 на тестовой выборке. Loss: 0.05067263916134834\n",
            "\tЭпоха 6. Итерация 150/625 на тестовой выборке. Loss: 0.044922079890966415\n",
            "\tЭпоха 6. Итерация 200/625 на тестовой выборке. Loss: 0.09473511576652527\n",
            "\tЭпоха 6. Итерация 250/625 на тестовой выборке. Loss: 0.07363113015890121\n",
            "\tЭпоха 6. Итерация 300/625 на тестовой выборке. Loss: 0.18739187717437744\n",
            "\tЭпоха 6. Итерация 350/625 на тестовой выборке. Loss: 0.16968108713626862\n",
            "\tЭпоха 6. Итерация 400/625 на тестовой выборке. Loss: 0.11350935697555542\n",
            "\tЭпоха 6. Итерация 450/625 на тестовой выборке. Loss: 0.08924756944179535\n",
            "\tЭпоха 6. Итерация 500/625 на тестовой выборке. Loss: 0.07847263664007187\n",
            "\tЭпоха 6. Итерация 550/625 на тестовой выборке. Loss: 0.052139874547719955\n",
            "\tЭпоха 6. Итерация 600/625 на тестовой выборке. Loss: 0.1325257271528244\n",
            "Эпоха #6 train_loss: 0.007217701735447826, val_loss: 0.010662495788559318\n",
            "Потрачено 87.9 минут на 6 эпоху\n",
            "\tЭпоха 7. Итерация 0/6774 на обучающей выборке. Loss: 0.05575041100382805\n",
            "\tЭпоха 7. Итерация 50/6774 на обучающей выборке. Loss: 0.048760659992694855\n",
            "\tЭпоха 7. Итерация 100/6774 на обучающей выборке. Loss: 0.07487813383340836\n",
            "\tЭпоха 7. Итерация 150/6774 на обучающей выборке. Loss: 0.06707369536161423\n",
            "\tЭпоха 7. Итерация 200/6774 на обучающей выборке. Loss: 0.049097295850515366\n",
            "\tЭпоха 7. Итерация 250/6774 на обучающей выборке. Loss: 0.054593104869127274\n",
            "\tЭпоха 7. Итерация 300/6774 на обучающей выборке. Loss: 0.03660815209150314\n",
            "\tЭпоха 7. Итерация 350/6774 на обучающей выборке. Loss: 0.06129099801182747\n",
            "\tЭпоха 7. Итерация 400/6774 на обучающей выборке. Loss: 0.05769244581460953\n",
            "\tЭпоха 7. Итерация 450/6774 на обучающей выборке. Loss: 0.038366593420505524\n",
            "\tЭпоха 7. Итерация 500/6774 на обучающей выборке. Loss: 0.042199231684207916\n",
            "\tЭпоха 7. Итерация 550/6774 на обучающей выборке. Loss: 0.07087376713752747\n",
            "\tЭпоха 7. Итерация 600/6774 на обучающей выборке. Loss: 0.049492835998535156\n",
            "\tЭпоха 7. Итерация 650/6774 на обучающей выборке. Loss: 0.04573160782456398\n",
            "\tЭпоха 7. Итерация 700/6774 на обучающей выборке. Loss: 0.05857823044061661\n",
            "\tЭпоха 7. Итерация 750/6774 на обучающей выборке. Loss: 0.04912438616156578\n",
            "\tЭпоха 7. Итерация 800/6774 на обучающей выборке. Loss: 0.04335620626807213\n",
            "\tЭпоха 7. Итерация 850/6774 на обучающей выборке. Loss: 0.101676806807518\n",
            "\tЭпоха 7. Итерация 900/6774 на обучающей выборке. Loss: 0.06361619383096695\n",
            "\tЭпоха 7. Итерация 950/6774 на обучающей выборке. Loss: 0.09051813185214996\n",
            "\tЭпоха 7. Итерация 1000/6774 на обучающей выборке. Loss: 0.06702617555856705\n",
            "\tЭпоха 7. Итерация 1050/6774 на обучающей выборке. Loss: 0.08663816004991531\n",
            "\tЭпоха 7. Итерация 1100/6774 на обучающей выборке. Loss: 0.04462381824851036\n",
            "\tЭпоха 7. Итерация 1150/6774 на обучающей выборке. Loss: 0.04775455966591835\n",
            "\tЭпоха 7. Итерация 1200/6774 на обучающей выборке. Loss: 0.03571801260113716\n",
            "\tЭпоха 7. Итерация 1250/6774 на обучающей выборке. Loss: 0.1131817176938057\n",
            "\tЭпоха 7. Итерация 1300/6774 на обучающей выборке. Loss: 0.07070289552211761\n",
            "\tЭпоха 7. Итерация 1350/6774 на обучающей выборке. Loss: 0.04304926469922066\n",
            "\tЭпоха 7. Итерация 1400/6774 на обучающей выборке. Loss: 0.062157224863767624\n",
            "\tЭпоха 7. Итерация 1450/6774 на обучающей выборке. Loss: 0.026468705385923386\n",
            "\tЭпоха 7. Итерация 1500/6774 на обучающей выборке. Loss: 0.07873289287090302\n",
            "\tЭпоха 7. Итерация 1550/6774 на обучающей выборке. Loss: 0.09344422072172165\n",
            "\tЭпоха 7. Итерация 1600/6774 на обучающей выборке. Loss: 0.055885400623083115\n",
            "\tЭпоха 7. Итерация 1650/6774 на обучающей выборке. Loss: 0.07499366998672485\n",
            "\tЭпоха 7. Итерация 1700/6774 на обучающей выборке. Loss: 0.057373832911252975\n",
            "\tЭпоха 7. Итерация 1750/6774 на обучающей выборке. Loss: 0.05840379372239113\n",
            "\tЭпоха 7. Итерация 1800/6774 на обучающей выборке. Loss: 0.09800214320421219\n",
            "\tЭпоха 7. Итерация 1850/6774 на обучающей выборке. Loss: 0.032774582505226135\n",
            "\tЭпоха 7. Итерация 1900/6774 на обучающей выборке. Loss: 0.06412296742200851\n",
            "\tЭпоха 7. Итерация 1950/6774 на обучающей выборке. Loss: 0.04516804590821266\n",
            "\tЭпоха 7. Итерация 2000/6774 на обучающей выборке. Loss: 0.044132210314273834\n",
            "\tЭпоха 7. Итерация 2050/6774 на обучающей выборке. Loss: 0.07348743826150894\n",
            "\tЭпоха 7. Итерация 2100/6774 на обучающей выборке. Loss: 0.06697695702314377\n",
            "\tЭпоха 7. Итерация 2150/6774 на обучающей выборке. Loss: 0.0476442314684391\n",
            "\tЭпоха 7. Итерация 2200/6774 на обучающей выборке. Loss: 0.0529305636882782\n",
            "\tЭпоха 7. Итерация 2250/6774 на обучающей выборке. Loss: 0.035441868007183075\n",
            "\tЭпоха 7. Итерация 2300/6774 на обучающей выборке. Loss: 0.07858074456453323\n",
            "\tЭпоха 7. Итерация 2350/6774 на обучающей выборке. Loss: 0.08960109204053879\n",
            "\tЭпоха 7. Итерация 2400/6774 на обучающей выборке. Loss: 0.06037212163209915\n",
            "\tЭпоха 7. Итерация 2450/6774 на обучающей выборке. Loss: 0.056819986552000046\n",
            "\tЭпоха 7. Итерация 2500/6774 на обучающей выборке. Loss: 0.05718269944190979\n",
            "\tЭпоха 7. Итерация 2550/6774 на обучающей выборке. Loss: 0.07623949646949768\n",
            "\tЭпоха 7. Итерация 2600/6774 на обучающей выборке. Loss: 0.055875327438116074\n",
            "\tЭпоха 7. Итерация 2650/6774 на обучающей выборке. Loss: 0.048757195472717285\n",
            "\tЭпоха 7. Итерация 2700/6774 на обучающей выборке. Loss: 0.06313157081604004\n",
            "\tЭпоха 7. Итерация 2750/6774 на обучающей выборке. Loss: 0.0447615347802639\n",
            "\tЭпоха 7. Итерация 2800/6774 на обучающей выборке. Loss: 0.04641180485486984\n",
            "\tЭпоха 7. Итерация 2850/6774 на обучающей выборке. Loss: 0.054174985736608505\n",
            "\tЭпоха 7. Итерация 2900/6774 на обучающей выборке. Loss: 0.054412730038166046\n",
            "\tЭпоха 7. Итерация 2950/6774 на обучающей выборке. Loss: 0.04752775654196739\n",
            "\tЭпоха 7. Итерация 3000/6774 на обучающей выборке. Loss: 0.08789452165365219\n",
            "\tЭпоха 7. Итерация 3050/6774 на обучающей выборке. Loss: 0.03823862597346306\n",
            "\tЭпоха 7. Итерация 3100/6774 на обучающей выборке. Loss: 0.0731828436255455\n",
            "\tЭпоха 7. Итерация 3150/6774 на обучающей выборке. Loss: 0.0632987916469574\n",
            "\tЭпоха 7. Итерация 3200/6774 на обучающей выборке. Loss: 0.04179061949253082\n",
            "\tЭпоха 7. Итерация 3250/6774 на обучающей выборке. Loss: 0.04285789653658867\n",
            "\tЭпоха 7. Итерация 3300/6774 на обучающей выборке. Loss: 0.055320192128419876\n",
            "\tЭпоха 7. Итерация 3350/6774 на обучающей выборке. Loss: 0.08226989954710007\n",
            "\tЭпоха 7. Итерация 3400/6774 на обучающей выборке. Loss: 0.07801009714603424\n",
            "\tЭпоха 7. Итерация 3450/6774 на обучающей выборке. Loss: 0.046824656426906586\n",
            "\tЭпоха 7. Итерация 3500/6774 на обучающей выборке. Loss: 0.04197398200631142\n",
            "\tЭпоха 7. Итерация 3550/6774 на обучающей выборке. Loss: 0.04019063711166382\n",
            "\tЭпоха 7. Итерация 3600/6774 на обучающей выборке. Loss: 0.030039984732866287\n",
            "\tЭпоха 7. Итерация 3650/6774 на обучающей выборке. Loss: 0.050845589488744736\n",
            "\tЭпоха 7. Итерация 3700/6774 на обучающей выборке. Loss: 0.0700044333934784\n",
            "\tЭпоха 7. Итерация 3750/6774 на обучающей выборке. Loss: 0.059540726244449615\n",
            "\tЭпоха 7. Итерация 3800/6774 на обучающей выборке. Loss: 0.04425789788365364\n",
            "\tЭпоха 7. Итерация 3850/6774 на обучающей выборке. Loss: 0.058322686702013016\n",
            "\tЭпоха 7. Итерация 3900/6774 на обучающей выборке. Loss: 0.04170336201786995\n",
            "\tЭпоха 7. Итерация 3950/6774 на обучающей выборке. Loss: 0.04761052504181862\n",
            "\tЭпоха 7. Итерация 4000/6774 на обучающей выборке. Loss: 0.05589602142572403\n",
            "\tЭпоха 7. Итерация 4050/6774 на обучающей выборке. Loss: 0.0715562030673027\n",
            "\tЭпоха 7. Итерация 4100/6774 на обучающей выборке. Loss: 0.057192184031009674\n",
            "\tЭпоха 7. Итерация 4150/6774 на обучающей выборке. Loss: 0.03805218264460564\n",
            "\tЭпоха 7. Итерация 4200/6774 на обучающей выборке. Loss: 0.0475175641477108\n",
            "\tЭпоха 7. Итерация 4250/6774 на обучающей выборке. Loss: 0.028610290959477425\n",
            "\tЭпоха 7. Итерация 4300/6774 на обучающей выборке. Loss: 0.08157568424940109\n",
            "\tЭпоха 7. Итерация 4350/6774 на обучающей выборке. Loss: 0.05723882094025612\n",
            "\tЭпоха 7. Итерация 4400/6774 на обучающей выборке. Loss: 0.07282043248414993\n",
            "\tЭпоха 7. Итерация 4450/6774 на обучающей выборке. Loss: 0.03043495863676071\n",
            "\tЭпоха 7. Итерация 4500/6774 на обучающей выборке. Loss: 0.03686487302184105\n",
            "\tЭпоха 7. Итерация 4550/6774 на обучающей выборке. Loss: 0.07344473898410797\n",
            "\tЭпоха 7. Итерация 4600/6774 на обучающей выборке. Loss: 0.05219960957765579\n",
            "\tЭпоха 7. Итерация 4650/6774 на обучающей выборке. Loss: 0.05184362456202507\n",
            "\tЭпоха 7. Итерация 4700/6774 на обучающей выборке. Loss: 0.0775698646903038\n",
            "\tЭпоха 7. Итерация 4750/6774 на обучающей выборке. Loss: 0.05641544982790947\n",
            "\tЭпоха 7. Итерация 4800/6774 на обучающей выборке. Loss: 0.05127149075269699\n",
            "\tЭпоха 7. Итерация 4850/6774 на обучающей выборке. Loss: 0.0430171862244606\n",
            "\tЭпоха 7. Итерация 4900/6774 на обучающей выборке. Loss: 0.06320314854383469\n",
            "\tЭпоха 7. Итерация 4950/6774 на обучающей выборке. Loss: 0.05928253382444382\n",
            "\tЭпоха 7. Итерация 5000/6774 на обучающей выборке. Loss: 0.06353031098842621\n",
            "\tЭпоха 7. Итерация 5050/6774 на обучающей выборке. Loss: 0.06608957797288895\n",
            "\tЭпоха 7. Итерация 5100/6774 на обучающей выборке. Loss: 0.07427641749382019\n",
            "\tЭпоха 7. Итерация 5150/6774 на обучающей выборке. Loss: 0.0323336198925972\n",
            "\tЭпоха 7. Итерация 5200/6774 на обучающей выборке. Loss: 0.03491560369729996\n",
            "\tЭпоха 7. Итерация 5250/6774 на обучающей выборке. Loss: 0.0749678760766983\n",
            "\tЭпоха 7. Итерация 5300/6774 на обучающей выборке. Loss: 0.06879051774740219\n",
            "\tЭпоха 7. Итерация 5350/6774 на обучающей выборке. Loss: 0.0439329594373703\n",
            "\tЭпоха 7. Итерация 5400/6774 на обучающей выборке. Loss: 0.05427039414644241\n",
            "\tЭпоха 7. Итерация 5450/6774 на обучающей выборке. Loss: 0.041981905698776245\n",
            "\tЭпоха 7. Итерация 5500/6774 на обучающей выборке. Loss: 0.04523202031850815\n",
            "\tЭпоха 7. Итерация 5550/6774 на обучающей выборке. Loss: 0.040830790996551514\n",
            "\tЭпоха 7. Итерация 5600/6774 на обучающей выборке. Loss: 0.07105523347854614\n",
            "\tЭпоха 7. Итерация 5650/6774 на обучающей выборке. Loss: 0.04206937178969383\n",
            "\tЭпоха 7. Итерация 5700/6774 на обучающей выборке. Loss: 0.041555240750312805\n",
            "\tЭпоха 7. Итерация 5750/6774 на обучающей выборке. Loss: 0.036017514765262604\n",
            "\tЭпоха 7. Итерация 5800/6774 на обучающей выборке. Loss: 0.058045852929353714\n",
            "\tЭпоха 7. Итерация 5850/6774 на обучающей выборке. Loss: 0.043953053653240204\n",
            "\tЭпоха 7. Итерация 5900/6774 на обучающей выборке. Loss: 0.07939451932907104\n",
            "\tЭпоха 7. Итерация 5950/6774 на обучающей выборке. Loss: 0.05609651282429695\n",
            "\tЭпоха 7. Итерация 6000/6774 на обучающей выборке. Loss: 0.06578611582517624\n",
            "\tЭпоха 7. Итерация 6050/6774 на обучающей выборке. Loss: 0.06537505239248276\n",
            "\tЭпоха 7. Итерация 6100/6774 на обучающей выборке. Loss: 0.0802023783326149\n",
            "\tЭпоха 7. Итерация 6150/6774 на обучающей выборке. Loss: 0.07389959692955017\n",
            "\tЭпоха 7. Итерация 6200/6774 на обучающей выборке. Loss: 0.05165593698620796\n",
            "\tЭпоха 7. Итерация 6250/6774 на обучающей выборке. Loss: 0.05776587873697281\n",
            "\tЭпоха 7. Итерация 6300/6774 на обучающей выборке. Loss: 0.042644910514354706\n",
            "\tЭпоха 7. Итерация 6350/6774 на обучающей выборке. Loss: 0.05254022032022476\n",
            "\tЭпоха 7. Итерация 6400/6774 на обучающей выборке. Loss: 0.047069251537323\n",
            "\tЭпоха 7. Итерация 6450/6774 на обучающей выборке. Loss: 0.07325253635644913\n",
            "\tЭпоха 7. Итерация 6500/6774 на обучающей выборке. Loss: 0.09109023213386536\n",
            "\tЭпоха 7. Итерация 6550/6774 на обучающей выборке. Loss: 0.054831363260746\n",
            "\tЭпоха 7. Итерация 6600/6774 на обучающей выборке. Loss: 0.040340762585401535\n",
            "\tЭпоха 7. Итерация 6650/6774 на обучающей выборке. Loss: 0.06986109167337418\n",
            "\tЭпоха 7. Итерация 6700/6774 на обучающей выборке. Loss: 0.046600401401519775\n",
            "\tЭпоха 7. Итерация 6750/6774 на обучающей выборке. Loss: 0.05664239078760147\n",
            "\tЭпоха 7. Итерация 0/625 на тестовой выборке. Loss: 0.07594555616378784\n",
            "\tЭпоха 7. Итерация 50/625 на тестовой выборке. Loss: 0.08011985570192337\n",
            "\tЭпоха 7. Итерация 100/625 на тестовой выборке. Loss: 0.050140488892793655\n",
            "\tЭпоха 7. Итерация 150/625 на тестовой выборке. Loss: 0.04450439289212227\n",
            "\tЭпоха 7. Итерация 200/625 на тестовой выборке. Loss: 0.09455717355012894\n",
            "\tЭпоха 7. Итерация 250/625 на тестовой выборке. Loss: 0.0768856629729271\n",
            "\tЭпоха 7. Итерация 300/625 на тестовой выборке. Loss: 0.18831288814544678\n",
            "\tЭпоха 7. Итерация 350/625 на тестовой выборке. Loss: 0.16640031337738037\n",
            "\tЭпоха 7. Итерация 400/625 на тестовой выборке. Loss: 0.11581334471702576\n",
            "\tЭпоха 7. Итерация 450/625 на тестовой выборке. Loss: 0.09099801629781723\n",
            "\tЭпоха 7. Итерация 500/625 на тестовой выборке. Loss: 0.07777847349643707\n",
            "\tЭпоха 7. Итерация 550/625 на тестовой выборке. Loss: 0.05100151151418686\n",
            "\tЭпоха 7. Итерация 600/625 на тестовой выборке. Loss: 0.127971351146698\n",
            "Эпоха #7 train_loss: 0.007136038387567025, val_loss: 0.010716843140125274\n",
            "Потрачено 87.5 минут на 7 эпоху\n",
            "\tЭпоха 8. Итерация 0/6774 на обучающей выборке. Loss: 0.05679996311664581\n",
            "\tЭпоха 8. Итерация 50/6774 на обучающей выборке. Loss: 0.05370589718222618\n",
            "\tЭпоха 8. Итерация 100/6774 на обучающей выборке. Loss: 0.026429392397403717\n",
            "\tЭпоха 8. Итерация 150/6774 на обучающей выборке. Loss: 0.042991481721401215\n",
            "\tЭпоха 8. Итерация 200/6774 на обучающей выборке. Loss: 0.02812006324529648\n",
            "\tЭпоха 8. Итерация 250/6774 на обучающей выборке. Loss: 0.07371170073747635\n",
            "\tЭпоха 8. Итерация 300/6774 на обучающей выборке. Loss: 0.06936664879322052\n",
            "\tЭпоха 8. Итерация 350/6774 на обучающей выборке. Loss: 0.04841829836368561\n",
            "\tЭпоха 8. Итерация 400/6774 на обучающей выборке. Loss: 0.08254233002662659\n",
            "\tЭпоха 8. Итерация 450/6774 на обучающей выборке. Loss: 0.08765154331922531\n",
            "\tЭпоха 8. Итерация 500/6774 на обучающей выборке. Loss: 0.04549279808998108\n",
            "\tЭпоха 8. Итерация 550/6774 на обучающей выборке. Loss: 0.028552770614624023\n",
            "\tЭпоха 8. Итерация 600/6774 на обучающей выборке. Loss: 0.0463828518986702\n",
            "\tЭпоха 8. Итерация 650/6774 на обучающей выборке. Loss: 0.08824677765369415\n",
            "\tЭпоха 8. Итерация 700/6774 на обучающей выборке. Loss: 0.04968925565481186\n",
            "\tЭпоха 8. Итерация 750/6774 на обучающей выборке. Loss: 0.0571068674325943\n",
            "\tЭпоха 8. Итерация 800/6774 на обучающей выборке. Loss: 0.03972460702061653\n",
            "\tЭпоха 8. Итерация 850/6774 на обучающей выборке. Loss: 0.04647866263985634\n",
            "\tЭпоха 8. Итерация 900/6774 на обучающей выборке. Loss: 0.054435402154922485\n",
            "\tЭпоха 8. Итерация 950/6774 на обучающей выборке. Loss: 0.13795870542526245\n",
            "\tЭпоха 8. Итерация 1000/6774 на обучающей выборке. Loss: 0.03918314352631569\n",
            "\tЭпоха 8. Итерация 1050/6774 на обучающей выборке. Loss: 0.03984885290265083\n",
            "\tЭпоха 8. Итерация 1100/6774 на обучающей выборке. Loss: 0.07533413916826248\n",
            "\tЭпоха 8. Итерация 1150/6774 на обучающей выборке. Loss: 0.06426947563886642\n",
            "\tЭпоха 8. Итерация 1200/6774 на обучающей выборке. Loss: 0.06196612864732742\n",
            "\tЭпоха 8. Итерация 1250/6774 на обучающей выборке. Loss: 0.05524148792028427\n",
            "\tЭпоха 8. Итерация 1300/6774 на обучающей выборке. Loss: 0.06574185937643051\n",
            "\tЭпоха 8. Итерация 1350/6774 на обучающей выборке. Loss: 0.03620503842830658\n",
            "\tЭпоха 8. Итерация 1400/6774 на обучающей выборке. Loss: 0.06514056026935577\n",
            "\tЭпоха 8. Итерация 1450/6774 на обучающей выборке. Loss: 0.10568144172430038\n",
            "\tЭпоха 8. Итерация 1500/6774 на обучающей выборке. Loss: 0.05279313772916794\n",
            "\tЭпоха 8. Итерация 1550/6774 на обучающей выборке. Loss: 0.04803623631596565\n",
            "\tЭпоха 8. Итерация 1600/6774 на обучающей выборке. Loss: 0.04508358985185623\n",
            "\tЭпоха 8. Итерация 1650/6774 на обучающей выборке. Loss: 0.053907860070466995\n",
            "\tЭпоха 8. Итерация 1700/6774 на обучающей выборке. Loss: 0.0700652226805687\n",
            "\tЭпоха 8. Итерация 1750/6774 на обучающей выборке. Loss: 0.06400951743125916\n",
            "\tЭпоха 8. Итерация 1800/6774 на обучающей выборке. Loss: 0.05271507054567337\n",
            "\tЭпоха 8. Итерация 1850/6774 на обучающей выборке. Loss: 0.07307187467813492\n",
            "\tЭпоха 8. Итерация 1900/6774 на обучающей выборке. Loss: 0.03238128125667572\n",
            "\tЭпоха 8. Итерация 1950/6774 на обучающей выборке. Loss: 0.08815134316682816\n",
            "\tЭпоха 8. Итерация 2000/6774 на обучающей выборке. Loss: 0.07249411940574646\n",
            "\tЭпоха 8. Итерация 2050/6774 на обучающей выборке. Loss: 0.057227544486522675\n",
            "\tЭпоха 8. Итерация 2100/6774 на обучающей выборке. Loss: 0.07887481898069382\n",
            "\tЭпоха 8. Итерация 2150/6774 на обучающей выборке. Loss: 0.07133406400680542\n",
            "\tЭпоха 8. Итерация 2200/6774 на обучающей выборке. Loss: 0.060771048069000244\n",
            "\tЭпоха 8. Итерация 2250/6774 на обучающей выборке. Loss: 0.05705680698156357\n",
            "\tЭпоха 8. Итерация 2300/6774 на обучающей выборке. Loss: 0.03830549493432045\n",
            "\tЭпоха 8. Итерация 2350/6774 на обучающей выборке. Loss: 0.10393548011779785\n",
            "\tЭпоха 8. Итерация 2400/6774 на обучающей выборке. Loss: 0.05605827271938324\n",
            "\tЭпоха 8. Итерация 2450/6774 на обучающей выборке. Loss: 0.05715695768594742\n",
            "\tЭпоха 8. Итерация 2500/6774 на обучающей выборке. Loss: 0.07936552911996841\n",
            "\tЭпоха 8. Итерация 2550/6774 на обучающей выборке. Loss: 0.08267706632614136\n",
            "\tЭпоха 8. Итерация 2600/6774 на обучающей выборке. Loss: 0.0775105357170105\n",
            "\tЭпоха 8. Итерация 2650/6774 на обучающей выборке. Loss: 0.08681410551071167\n",
            "\tЭпоха 8. Итерация 2700/6774 на обучающей выборке. Loss: 0.04355659708380699\n",
            "\tЭпоха 8. Итерация 2750/6774 на обучающей выборке. Loss: 0.03579133003950119\n",
            "\tЭпоха 8. Итерация 2800/6774 на обучающей выборке. Loss: 0.04557255282998085\n",
            "\tЭпоха 8. Итерация 2850/6774 на обучающей выборке. Loss: 0.031093532219529152\n",
            "\tЭпоха 8. Итерация 2900/6774 на обучающей выборке. Loss: 0.049161799252033234\n",
            "\tЭпоха 8. Итерация 2950/6774 на обучающей выборке. Loss: 0.05489972606301308\n",
            "\tЭпоха 8. Итерация 3000/6774 на обучающей выборке. Loss: 0.03923261910676956\n",
            "\tЭпоха 8. Итерация 3050/6774 на обучающей выборке. Loss: 0.050963856279850006\n",
            "\tЭпоха 8. Итерация 3100/6774 на обучающей выборке. Loss: 0.07075611501932144\n",
            "\tЭпоха 8. Итерация 3150/6774 на обучающей выборке. Loss: 0.05688080936670303\n",
            "\tЭпоха 8. Итерация 3200/6774 на обучающей выборке. Loss: 0.04675925523042679\n",
            "\tЭпоха 8. Итерация 3250/6774 на обучающей выборке. Loss: 0.05315413698554039\n",
            "\tЭпоха 8. Итерация 3300/6774 на обучающей выборке. Loss: 0.042756181210279465\n",
            "\tЭпоха 8. Итерация 3350/6774 на обучающей выборке. Loss: 0.05418025329709053\n",
            "\tЭпоха 8. Итерация 3400/6774 на обучающей выборке. Loss: 0.03372126445174217\n",
            "\tЭпоха 8. Итерация 3450/6774 на обучающей выборке. Loss: 0.09494849294424057\n",
            "\tЭпоха 8. Итерация 3500/6774 на обучающей выборке. Loss: 0.03256578370928764\n",
            "\tЭпоха 8. Итерация 3550/6774 на обучающей выборке. Loss: 0.04771341755986214\n",
            "\tЭпоха 8. Итерация 3600/6774 на обучающей выборке. Loss: 0.06642046570777893\n",
            "\tЭпоха 8. Итерация 3650/6774 на обучающей выборке. Loss: 0.07070109993219376\n",
            "\tЭпоха 8. Итерация 3700/6774 на обучающей выборке. Loss: 0.0475437231361866\n",
            "\tЭпоха 8. Итерация 3750/6774 на обучающей выборке. Loss: 0.04326390475034714\n",
            "\tЭпоха 8. Итерация 3800/6774 на обучающей выборке. Loss: 0.0533783994615078\n",
            "\tЭпоха 8. Итерация 3850/6774 на обучающей выборке. Loss: 0.07464272528886795\n",
            "\tЭпоха 8. Итерация 3900/6774 на обучающей выборке. Loss: 0.05126794055104256\n",
            "\tЭпоха 8. Итерация 3950/6774 на обучающей выборке. Loss: 0.050256263464689255\n",
            "\tЭпоха 8. Итерация 4000/6774 на обучающей выборке. Loss: 0.06501342356204987\n",
            "\tЭпоха 8. Итерация 4050/6774 на обучающей выборке. Loss: 0.04584001377224922\n",
            "\tЭпоха 8. Итерация 4100/6774 на обучающей выборке. Loss: 0.09843765199184418\n",
            "\tЭпоха 8. Итерация 4150/6774 на обучающей выборке. Loss: 0.030826617032289505\n",
            "\tЭпоха 8. Итерация 4200/6774 на обучающей выборке. Loss: 0.04663810878992081\n",
            "\tЭпоха 8. Итерация 4250/6774 на обучающей выборке. Loss: 0.05233458802103996\n",
            "\tЭпоха 8. Итерация 4300/6774 на обучающей выборке. Loss: 0.04072147235274315\n",
            "\tЭпоха 8. Итерация 4350/6774 на обучающей выборке. Loss: 0.09592317044734955\n",
            "\tЭпоха 8. Итерация 4400/6774 на обучающей выборке. Loss: 0.10686018317937851\n",
            "\tЭпоха 8. Итерация 4450/6774 на обучающей выборке. Loss: 0.045840367674827576\n",
            "\tЭпоха 8. Итерация 4500/6774 на обучающей выборке. Loss: 0.06309887766838074\n",
            "\tЭпоха 8. Итерация 4550/6774 на обучающей выборке. Loss: 0.07627537846565247\n",
            "\tЭпоха 8. Итерация 4600/6774 на обучающей выборке. Loss: 0.08269140869379044\n",
            "\tЭпоха 8. Итерация 4650/6774 на обучающей выборке. Loss: 0.052271485328674316\n",
            "\tЭпоха 8. Итерация 4700/6774 на обучающей выборке. Loss: 0.0439022071659565\n",
            "\tЭпоха 8. Итерация 4750/6774 на обучающей выборке. Loss: 0.04856675863265991\n",
            "\tЭпоха 8. Итерация 4800/6774 на обучающей выборке. Loss: 0.06264452636241913\n",
            "\tЭпоха 8. Итерация 4850/6774 на обучающей выборке. Loss: 0.06852944940328598\n",
            "\tЭпоха 8. Итерация 4900/6774 на обучающей выборке. Loss: 0.05707627534866333\n",
            "\tЭпоха 8. Итерация 4950/6774 на обучающей выборке. Loss: 0.05935710668563843\n",
            "\tЭпоха 8. Итерация 5000/6774 на обучающей выборке. Loss: 0.05744771286845207\n",
            "\tЭпоха 8. Итерация 5050/6774 на обучающей выборке. Loss: 0.05170687288045883\n",
            "\tЭпоха 8. Итерация 5100/6774 на обучающей выборке. Loss: 0.0502365343272686\n",
            "\tЭпоха 8. Итерация 5150/6774 на обучающей выборке. Loss: 0.0652959793806076\n",
            "\tЭпоха 8. Итерация 5200/6774 на обучающей выборке. Loss: 0.052388861775398254\n",
            "\tЭпоха 8. Итерация 5250/6774 на обучающей выборке. Loss: 0.04957941547036171\n",
            "\tЭпоха 8. Итерация 5300/6774 на обучающей выборке. Loss: 0.061469666659832\n",
            "\tЭпоха 8. Итерация 5350/6774 на обучающей выборке. Loss: 0.06356067955493927\n",
            "\tЭпоха 8. Итерация 5400/6774 на обучающей выборке. Loss: 0.07249055057764053\n",
            "\tЭпоха 8. Итерация 5450/6774 на обучающей выборке. Loss: 0.12067845463752747\n",
            "\tЭпоха 8. Итерация 5500/6774 на обучающей выборке. Loss: 0.08268832415342331\n",
            "\tЭпоха 8. Итерация 5550/6774 на обучающей выборке. Loss: 0.08386711031198502\n",
            "\tЭпоха 8. Итерация 5600/6774 на обучающей выборке. Loss: 0.06516262143850327\n",
            "\tЭпоха 8. Итерация 5650/6774 на обучающей выборке. Loss: 0.0647035613656044\n",
            "\tЭпоха 8. Итерация 5700/6774 на обучающей выборке. Loss: 0.04910407215356827\n",
            "\tЭпоха 8. Итерация 5750/6774 на обучающей выборке. Loss: 0.07158128172159195\n",
            "\tЭпоха 8. Итерация 5800/6774 на обучающей выборке. Loss: 0.035785380750894547\n",
            "\tЭпоха 8. Итерация 5850/6774 на обучающей выборке. Loss: 0.049830954521894455\n",
            "\tЭпоха 8. Итерация 5900/6774 на обучающей выборке. Loss: 0.055616188794374466\n",
            "\tЭпоха 8. Итерация 5950/6774 на обучающей выборке. Loss: 0.05045485496520996\n",
            "\tЭпоха 8. Итерация 6000/6774 на обучающей выборке. Loss: 0.054595835506916046\n",
            "\tЭпоха 8. Итерация 6050/6774 на обучающей выборке. Loss: 0.054017629474401474\n",
            "\tЭпоха 8. Итерация 6100/6774 на обучающей выборке. Loss: 0.06648781150579453\n",
            "\tЭпоха 8. Итерация 6150/6774 на обучающей выборке. Loss: 0.05061671510338783\n",
            "\tЭпоха 8. Итерация 6200/6774 на обучающей выборке. Loss: 0.055028337985277176\n",
            "\tЭпоха 8. Итерация 6250/6774 на обучающей выборке. Loss: 0.04286499321460724\n",
            "\tЭпоха 8. Итерация 6300/6774 на обучающей выборке. Loss: 0.045373573899269104\n",
            "\tЭпоха 8. Итерация 6350/6774 на обучающей выборке. Loss: 0.03256116062402725\n",
            "\tЭпоха 8. Итерация 6400/6774 на обучающей выборке. Loss: 0.03696100041270256\n",
            "\tЭпоха 8. Итерация 6450/6774 на обучающей выборке. Loss: 0.049383744597435\n",
            "\tЭпоха 8. Итерация 6500/6774 на обучающей выборке. Loss: 0.06110900640487671\n",
            "\tЭпоха 8. Итерация 6550/6774 на обучающей выборке. Loss: 0.07529311627149582\n",
            "\tЭпоха 8. Итерация 6600/6774 на обучающей выборке. Loss: 0.11498040705919266\n",
            "\tЭпоха 8. Итерация 6650/6774 на обучающей выборке. Loss: 0.052689328789711\n",
            "\tЭпоха 8. Итерация 6700/6774 на обучающей выборке. Loss: 0.06464456766843796\n",
            "\tЭпоха 8. Итерация 6750/6774 на обучающей выборке. Loss: 0.10545649379491806\n",
            "\tЭпоха 8. Итерация 0/625 на тестовой выборке. Loss: 0.08138638734817505\n",
            "\tЭпоха 8. Итерация 50/625 на тестовой выборке. Loss: 0.0838857889175415\n",
            "\tЭпоха 8. Итерация 100/625 на тестовой выборке. Loss: 0.050275951623916626\n",
            "\tЭпоха 8. Итерация 150/625 на тестовой выборке. Loss: 0.046894997358322144\n",
            "\tЭпоха 8. Итерация 200/625 на тестовой выборке. Loss: 0.09161864966154099\n",
            "\tЭпоха 8. Итерация 250/625 на тестовой выборке. Loss: 0.07609555125236511\n",
            "\tЭпоха 8. Итерация 300/625 на тестовой выборке. Loss: 0.18650592863559723\n",
            "\tЭпоха 8. Итерация 350/625 на тестовой выборке. Loss: 0.1722235083580017\n",
            "\tЭпоха 8. Итерация 400/625 на тестовой выборке. Loss: 0.1095125824213028\n",
            "\tЭпоха 8. Итерация 450/625 на тестовой выборке. Loss: 0.09077061712741852\n",
            "\tЭпоха 8. Итерация 500/625 на тестовой выборке. Loss: 0.07605110108852386\n",
            "\tЭпоха 8. Итерация 550/625 на тестовой выборке. Loss: 0.04841981828212738\n",
            "\tЭпоха 8. Итерация 600/625 на тестовой выборке. Loss: 0.13030575215816498\n",
            "Эпоха #8 train_loss: 0.007087748875320255, val_loss: 0.010721479135751725\n",
            "Потрачено 90.2 минут на 8 эпоху\n",
            "\tЭпоха 9. Итерация 0/6774 на обучающей выборке. Loss: 0.056072529405355453\n",
            "\tЭпоха 9. Итерация 50/6774 на обучающей выборке. Loss: 0.023933952674269676\n",
            "\tЭпоха 9. Итерация 100/6774 на обучающей выборке. Loss: 0.04729044437408447\n",
            "\tЭпоха 9. Итерация 150/6774 на обучающей выборке. Loss: 0.04052868112921715\n",
            "\tЭпоха 9. Итерация 200/6774 на обучающей выборке. Loss: 0.03805015981197357\n",
            "\tЭпоха 9. Итерация 250/6774 на обучающей выборке. Loss: 0.04756850004196167\n",
            "\tЭпоха 9. Итерация 300/6774 на обучающей выборке. Loss: 0.08517827838659286\n",
            "\tЭпоха 9. Итерация 350/6774 на обучающей выборке. Loss: 0.07319871336221695\n",
            "\tЭпоха 9. Итерация 400/6774 на обучающей выборке. Loss: 0.04969155788421631\n",
            "\tЭпоха 9. Итерация 450/6774 на обучающей выборке. Loss: 0.020686959847807884\n",
            "\tЭпоха 9. Итерация 500/6774 на обучающей выборке. Loss: 0.039438147097826004\n",
            "\tЭпоха 9. Итерация 550/6774 на обучающей выборке. Loss: 0.05808302387595177\n",
            "\tЭпоха 9. Итерация 600/6774 на обучающей выборке. Loss: 0.02471773512661457\n",
            "\tЭпоха 9. Итерация 650/6774 на обучающей выборке. Loss: 0.03179840371012688\n",
            "\tЭпоха 9. Итерация 700/6774 на обучающей выборке. Loss: 0.04971165210008621\n",
            "\tЭпоха 9. Итерация 750/6774 на обучающей выборке. Loss: 0.07186438888311386\n",
            "\tЭпоха 9. Итерация 800/6774 на обучающей выборке. Loss: 0.044928766787052155\n",
            "\tЭпоха 9. Итерация 850/6774 на обучающей выборке. Loss: 0.08502589911222458\n",
            "\tЭпоха 9. Итерация 900/6774 на обучающей выборке. Loss: 0.04187897965312004\n",
            "\tЭпоха 9. Итерация 950/6774 на обучающей выборке. Loss: 0.04999355599284172\n",
            "\tЭпоха 9. Итерация 1000/6774 на обучающей выборке. Loss: 0.049895815551280975\n",
            "\tЭпоха 9. Итерация 1050/6774 на обучающей выборке. Loss: 0.04572923853993416\n",
            "\tЭпоха 9. Итерация 1100/6774 на обучающей выборке. Loss: 0.07249092310667038\n",
            "\tЭпоха 9. Итерация 1150/6774 на обучающей выборке. Loss: 0.039930276572704315\n",
            "\tЭпоха 9. Итерация 1200/6774 на обучающей выборке. Loss: 0.07726795226335526\n",
            "\tЭпоха 9. Итерация 1250/6774 на обучающей выборке. Loss: 0.0592135488986969\n",
            "\tЭпоха 9. Итерация 1300/6774 на обучающей выборке. Loss: 0.06945325434207916\n",
            "\tЭпоха 9. Итерация 1350/6774 на обучающей выборке. Loss: 0.0644761174917221\n",
            "\tЭпоха 9. Итерация 1400/6774 на обучающей выборке. Loss: 0.08176245540380478\n",
            "\tЭпоха 9. Итерация 1450/6774 на обучающей выборке. Loss: 0.06858699768781662\n",
            "\tЭпоха 9. Итерация 1500/6774 на обучающей выборке. Loss: 0.059977784752845764\n",
            "\tЭпоха 9. Итерация 1550/6774 на обучающей выборке. Loss: 0.05001218616962433\n",
            "\tЭпоха 9. Итерация 1600/6774 на обучающей выборке. Loss: 0.05261882022023201\n",
            "\tЭпоха 9. Итерация 1650/6774 на обучающей выборке. Loss: 0.059101805090904236\n",
            "\tЭпоха 9. Итерация 1700/6774 на обучающей выборке. Loss: 0.03453855589032173\n",
            "\tЭпоха 9. Итерация 1750/6774 на обучающей выборке. Loss: 0.06034324690699577\n",
            "\tЭпоха 9. Итерация 1800/6774 на обучающей выборке. Loss: 0.026493975892663002\n",
            "\tЭпоха 9. Итерация 1850/6774 на обучающей выборке. Loss: 0.0831177607178688\n",
            "\tЭпоха 9. Итерация 1900/6774 на обучающей выборке. Loss: 0.12948934733867645\n",
            "\tЭпоха 9. Итерация 1950/6774 на обучающей выборке. Loss: 0.05483946576714516\n",
            "\tЭпоха 9. Итерация 2000/6774 на обучающей выборке. Loss: 0.06284468621015549\n",
            "\tЭпоха 9. Итерация 2050/6774 на обучающей выборке. Loss: 0.043070610612630844\n",
            "\tЭпоха 9. Итерация 2100/6774 на обучающей выборке. Loss: 0.03994016721844673\n",
            "\tЭпоха 9. Итерация 2150/6774 на обучающей выборке. Loss: 0.05724106356501579\n",
            "\tЭпоха 9. Итерация 2200/6774 на обучающей выборке. Loss: 0.09755495190620422\n",
            "\tЭпоха 9. Итерация 2250/6774 на обучающей выборке. Loss: 0.04545367509126663\n",
            "\tЭпоха 9. Итерация 2300/6774 на обучающей выборке. Loss: 0.035520412027835846\n",
            "\tЭпоха 9. Итерация 2350/6774 на обучающей выборке. Loss: 0.09804299473762512\n",
            "\tЭпоха 9. Итерация 2400/6774 на обучающей выборке. Loss: 0.060214996337890625\n",
            "\tЭпоха 9. Итерация 2450/6774 на обучающей выборке. Loss: 0.04551054537296295\n",
            "\tЭпоха 9. Итерация 2500/6774 на обучающей выборке. Loss: 0.05018125846982002\n",
            "\tЭпоха 9. Итерация 2550/6774 на обучающей выборке. Loss: 0.0396861769258976\n",
            "\tЭпоха 9. Итерация 2600/6774 на обучающей выборке. Loss: 0.050453487783670425\n",
            "\tЭпоха 9. Итерация 2650/6774 на обучающей выборке. Loss: 0.04182012751698494\n",
            "\tЭпоха 9. Итерация 2700/6774 на обучающей выборке. Loss: 0.05440104380249977\n",
            "\tЭпоха 9. Итерация 2750/6774 на обучающей выборке. Loss: 0.04928942397236824\n",
            "\tЭпоха 9. Итерация 2800/6774 на обучающей выборке. Loss: 0.05602116137742996\n",
            "\tЭпоха 9. Итерация 2850/6774 на обучающей выборке. Loss: 0.05146443471312523\n",
            "\tЭпоха 9. Итерация 2900/6774 на обучающей выборке. Loss: 0.11616180092096329\n",
            "\tЭпоха 9. Итерация 2950/6774 на обучающей выборке. Loss: 0.06154606491327286\n",
            "\tЭпоха 9. Итерация 3000/6774 на обучающей выборке. Loss: 0.08555314689874649\n",
            "\tЭпоха 9. Итерация 3050/6774 на обучающей выборке. Loss: 0.030081044882535934\n",
            "\tЭпоха 9. Итерация 3100/6774 на обучающей выборке. Loss: 0.05608159676194191\n",
            "\tЭпоха 9. Итерация 3150/6774 на обучающей выборке. Loss: 0.050409674644470215\n",
            "\tЭпоха 9. Итерация 3200/6774 на обучающей выборке. Loss: 0.06425418704748154\n",
            "\tЭпоха 9. Итерация 3250/6774 на обучающей выборке. Loss: 0.12253069132566452\n",
            "\tЭпоха 9. Итерация 3300/6774 на обучающей выборке. Loss: 0.041661471128463745\n",
            "\tЭпоха 9. Итерация 3350/6774 на обучающей выборке. Loss: 0.07115047425031662\n",
            "\tЭпоха 9. Итерация 3400/6774 на обучающей выборке. Loss: 0.07363568246364594\n",
            "\tЭпоха 9. Итерация 3450/6774 на обучающей выборке. Loss: 0.04125312715768814\n",
            "\tЭпоха 9. Итерация 3500/6774 на обучающей выборке. Loss: 0.0589163564145565\n",
            "\tЭпоха 9. Итерация 3550/6774 на обучающей выборке. Loss: 0.06734602153301239\n",
            "\tЭпоха 9. Итерация 3600/6774 на обучающей выборке. Loss: 0.05699937790632248\n",
            "\tЭпоха 9. Итерация 3650/6774 на обучающей выборке. Loss: 0.056179746985435486\n",
            "\tЭпоха 9. Итерация 3700/6774 на обучающей выборке. Loss: 0.04722319170832634\n",
            "\tЭпоха 9. Итерация 3750/6774 на обучающей выборке. Loss: 0.03860485181212425\n",
            "\tЭпоха 9. Итерация 3800/6774 на обучающей выборке. Loss: 0.054849475622177124\n",
            "\tЭпоха 9. Итерация 3850/6774 на обучающей выборке. Loss: 0.05850996449589729\n",
            "\tЭпоха 9. Итерация 3900/6774 на обучающей выборке. Loss: 0.04979860782623291\n",
            "\tЭпоха 9. Итерация 3950/6774 на обучающей выборке. Loss: 0.04399919509887695\n",
            "\tЭпоха 9. Итерация 4000/6774 на обучающей выборке. Loss: 0.04583859071135521\n",
            "\tЭпоха 9. Итерация 4050/6774 на обучающей выборке. Loss: 0.050150055438280106\n",
            "\tЭпоха 9. Итерация 4100/6774 на обучающей выборке. Loss: 0.03723888471722603\n",
            "\tЭпоха 9. Итерация 4150/6774 на обучающей выборке. Loss: 0.04169300198554993\n",
            "\tЭпоха 9. Итерация 4200/6774 на обучающей выборке. Loss: 0.06791358441114426\n",
            "\tЭпоха 9. Итерация 4250/6774 на обучающей выборке. Loss: 0.03811110556125641\n",
            "\tЭпоха 9. Итерация 4300/6774 на обучающей выборке. Loss: 0.044915009289979935\n",
            "\tЭпоха 9. Итерация 4350/6774 на обучающей выборке. Loss: 0.05059173330664635\n",
            "\tЭпоха 9. Итерация 4400/6774 на обучающей выборке. Loss: 0.044433481991291046\n",
            "\tЭпоха 9. Итерация 4450/6774 на обучающей выборке. Loss: 0.04277654364705086\n",
            "\tЭпоха 9. Итерация 4500/6774 на обучающей выборке. Loss: 0.057227492332458496\n",
            "\tЭпоха 9. Итерация 4550/6774 на обучающей выборке. Loss: 0.0510740764439106\n",
            "\tЭпоха 9. Итерация 4600/6774 на обучающей выборке. Loss: 0.05717802047729492\n",
            "\tЭпоха 9. Итерация 4650/6774 на обучающей выборке. Loss: 0.05749284476041794\n",
            "\tЭпоха 9. Итерация 4700/6774 на обучающей выборке. Loss: 0.03843226283788681\n",
            "\tЭпоха 9. Итерация 4750/6774 на обучающей выборке. Loss: 0.07340262830257416\n",
            "\tЭпоха 9. Итерация 4800/6774 на обучающей выборке. Loss: 0.04314935952425003\n",
            "\tЭпоха 9. Итерация 4850/6774 на обучающей выборке. Loss: 0.05718620866537094\n",
            "\tЭпоха 9. Итерация 4900/6774 на обучающей выборке. Loss: 0.05186203122138977\n",
            "\tЭпоха 9. Итерация 4950/6774 на обучающей выборке. Loss: 0.06193031743168831\n",
            "\tЭпоха 9. Итерация 5000/6774 на обучающей выборке. Loss: 0.0515170693397522\n",
            "\tЭпоха 9. Итерация 5050/6774 на обучающей выборке. Loss: 0.06348683685064316\n",
            "\tЭпоха 9. Итерация 5100/6774 на обучающей выборке. Loss: 0.050114795565605164\n",
            "\tЭпоха 9. Итерация 5150/6774 на обучающей выборке. Loss: 0.06505167484283447\n",
            "\tЭпоха 9. Итерация 5200/6774 на обучающей выборке. Loss: 0.05128642916679382\n",
            "\tЭпоха 9. Итерация 5250/6774 на обучающей выборке. Loss: 0.06540558487176895\n",
            "\tЭпоха 9. Итерация 5300/6774 на обучающей выборке. Loss: 0.04666590318083763\n",
            "\tЭпоха 9. Итерация 5350/6774 на обучающей выборке. Loss: 0.07382050901651382\n",
            "\tЭпоха 9. Итерация 5400/6774 на обучающей выборке. Loss: 0.046387579292058945\n",
            "\tЭпоха 9. Итерация 5450/6774 на обучающей выборке. Loss: 0.04596279188990593\n",
            "\tЭпоха 9. Итерация 5500/6774 на обучающей выборке. Loss: 0.058304280042648315\n",
            "\tЭпоха 9. Итерация 5550/6774 на обучающей выборке. Loss: 0.05869417265057564\n",
            "\tЭпоха 9. Итерация 5600/6774 на обучающей выборке. Loss: 0.051663998514413834\n",
            "\tЭпоха 9. Итерация 5650/6774 на обучающей выборке. Loss: 0.04610218107700348\n",
            "\tЭпоха 9. Итерация 5700/6774 на обучающей выборке. Loss: 0.055328771471977234\n",
            "\tЭпоха 9. Итерация 5750/6774 на обучающей выборке. Loss: 0.04607212170958519\n",
            "\tЭпоха 9. Итерация 5800/6774 на обучающей выборке. Loss: 0.05296972766518593\n",
            "\tЭпоха 9. Итерация 5850/6774 на обучающей выборке. Loss: 0.035615842789411545\n",
            "\tЭпоха 9. Итерация 5900/6774 на обучающей выборке. Loss: 0.05259915441274643\n",
            "\tЭпоха 9. Итерация 5950/6774 на обучающей выборке. Loss: 0.07481224089860916\n",
            "\tЭпоха 9. Итерация 6000/6774 на обучающей выборке. Loss: 0.04711763188242912\n",
            "\tЭпоха 9. Итерация 6050/6774 на обучающей выборке. Loss: 0.04737593233585358\n",
            "\tЭпоха 9. Итерация 6100/6774 на обучающей выборке. Loss: 0.054324451833963394\n",
            "\tЭпоха 9. Итерация 6150/6774 на обучающей выборке. Loss: 0.0549241378903389\n",
            "\tЭпоха 9. Итерация 6200/6774 на обучающей выборке. Loss: 0.030344558879733086\n",
            "\tЭпоха 9. Итерация 6250/6774 на обучающей выборке. Loss: 0.07097005844116211\n",
            "\tЭпоха 9. Итерация 6300/6774 на обучающей выборке. Loss: 0.08038952946662903\n",
            "\tЭпоха 9. Итерация 6350/6774 на обучающей выборке. Loss: 0.0636642724275589\n",
            "\tЭпоха 9. Итерация 6400/6774 на обучающей выборке. Loss: 0.04408685117959976\n",
            "\tЭпоха 9. Итерация 6450/6774 на обучающей выборке. Loss: 0.028100816532969475\n",
            "\tЭпоха 9. Итерация 6500/6774 на обучающей выборке. Loss: 0.05064089223742485\n",
            "\tЭпоха 9. Итерация 6550/6774 на обучающей выборке. Loss: 0.1254570335149765\n",
            "\tЭпоха 9. Итерация 6600/6774 на обучающей выборке. Loss: 0.062019579112529755\n",
            "\tЭпоха 9. Итерация 6650/6774 на обучающей выборке. Loss: 0.05082132667303085\n",
            "\tЭпоха 9. Итерация 6700/6774 на обучающей выборке. Loss: 0.0510871484875679\n",
            "\tЭпоха 9. Итерация 6750/6774 на обучающей выборке. Loss: 0.07331264019012451\n",
            "\tЭпоха 9. Итерация 0/625 на тестовой выборке. Loss: 0.07876267284154892\n",
            "\tЭпоха 9. Итерация 50/625 на тестовой выборке. Loss: 0.08169717341661453\n",
            "\tЭпоха 9. Итерация 100/625 на тестовой выборке. Loss: 0.04947083070874214\n",
            "\tЭпоха 9. Итерация 150/625 на тестовой выборке. Loss: 0.04498042166233063\n",
            "\tЭпоха 9. Итерация 200/625 на тестовой выборке. Loss: 0.09129702299833298\n",
            "\tЭпоха 9. Итерация 250/625 на тестовой выборке. Loss: 0.07430299371480942\n",
            "\tЭпоха 9. Итерация 300/625 на тестовой выборке. Loss: 0.1896899938583374\n",
            "\tЭпоха 9. Итерация 350/625 на тестовой выборке. Loss: 0.1697290986776352\n",
            "\tЭпоха 9. Итерация 400/625 на тестовой выборке. Loss: 0.11003327369689941\n",
            "\tЭпоха 9. Итерация 450/625 на тестовой выборке. Loss: 0.0889723151922226\n",
            "\tЭпоха 9. Итерация 500/625 на тестовой выборке. Loss: 0.08135291188955307\n",
            "\tЭпоха 9. Итерация 550/625 на тестовой выборке. Loss: 0.048526961356401443\n",
            "\tЭпоха 9. Итерация 600/625 на тестовой выборке. Loss: 0.12947921454906464\n",
            "Эпоха #9 train_loss: 0.007029368037768624, val_loss: 0.010741106372699141\n",
            "Потрачено 90.2 минут на 9 эпоху\n"
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "try:\n",
        "    torch.save(model, os.path.join(checkpoints_path, f'model_{model_name}.pth'))\n",
        "    for epoch in range(n_epochs):\n",
        "        start = time.time()\n",
        "        train_loss = train(train_data_loader, epoch)\n",
        "        val_loss = val(val_data_loader, epoch)\n",
        "        lr_scheduler.step()\n",
        "        print(f\"Эпоха #{epoch} train_loss: {train_loss}, val_loss: {val_loss}\")  \n",
        "        end = time.time()\n",
        "        print(f\"Потрачено {round((end - start) / 60, 1)} минут на {epoch} эпоху\")\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        torch.save({'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "                    'losses_train': train_losses,\n",
        "                    'losses_val': val_losses,\n",
        "                    }, os.path.join(checkpoints_path, f'chkpt_{model_name}_{epoch}.pth'))\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print('Прервано пользователем')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Графики лоссов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hgfXJF_9J28a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "fig, ax  = plt.subplots()\n",
        "ax.plot(train_losses, label='Train')\n",
        "ax.plot(val_losses, label='Val')\n",
        "ax.set(xlabel='Epoch', ylabel='Loss')\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Загрузка весов модели с наименьшим лоссом на валидации (с помощью библиотеки FiftyOne)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Минимальный loss на валидации: 0.0103 на 4 эпохе\n",
            "Для модели resnet50v2_all_classes загружены веса эпохи 4\n"
          ]
        }
      ],
      "source": [
        "# выбираем эпоху с наименьшем лоссом на валидации для загрузки весов\n",
        "epoch = val_losses.index(min(val_losses))\n",
        "print(f'Минимальный loss на валидации: {min(val_losses):.4f} на {epoch} эпохе')\n",
        "\n",
        "# загружаем веса модели с наименьшем лоссом на валидации\n",
        "checkpoint = torch.load(os.path.join(checkpoints_path, f'chkpt_{model_name}_{epoch}.pth'), map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "print(f\"Для модели {model_name} загружены веса эпохи {epoch}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Рассчет метрик модели на валидационной выборке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Загрузка валидационной выборки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |███████████████| 5000/5000 [4.0s elapsed, 0s remaining, 1.3K samples/s]      \n"
          ]
        }
      ],
      "source": [
        "val_dataset = fo.Dataset.from_dir(\n",
        "    dataset_type=fo.types.COCODetectionDataset,\n",
        "    data_path=dataset_path,\n",
        "    labels_path=os.path.join(dataset_path, 'val_anno.json')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tОбработано 5000 сэмплов.        \n"
          ]
        }
      ],
      "source": [
        "# Добавление и оценка детекций Faster-RCNN\n",
        "# Faster-RCNN могут быть вычислены и добавлены к каждом сэмпле набора данных в новом поле\n",
        "classes = val_dataset.default_classes\n",
        "# Добавление предсказаний\n",
        "model.eval()\n",
        "for i, sample in enumerate(val_dataset):\n",
        "    image = Image.open(sample.filepath)\n",
        "    image = func.to_tensor(image).to(device)\n",
        "    c,h,w = image.shape\n",
        "    preds = model([image])[0]\n",
        "    labels = preds['labels'].cpu().detach().numpy()\n",
        "    scores = preds['scores'].cpu().detach().numpy()\n",
        "    boxes = preds['boxes'].cpu().detach().numpy()\n",
        "    detections = []\n",
        "    for label, score, box in zip (labels, scores, boxes):\n",
        "        x1, y1, x2, y2 = box\n",
        "        rel_box = [x1/w, y1/h, (x2-x1)/w, (y2-y1)/h]\n",
        "        detections.append(fo.Detection(label=classes[label],\n",
        "                                        bounding_box=rel_box,\n",
        "                                        confidence=score\n",
        "                                        )\n",
        "                            )\n",
        "    sample['faster_rcnn'] = fo.Detections(detections=detections)\n",
        "    sample.save()\n",
        "    if i % 100 == 0:\n",
        "            print(f'\\tОбработано {i} из {val_dataset.__len__()} сэмплов.', end='\\r')\n",
        "print(f'\\tОбработано {val_dataset.__len__()} сэмплов.        ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"800\"\n",
              "            src=\"http://localhost:5151/?notebook=True&subscription=a38b0b74-24cb-435c-802a-a9694b71d8c7\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x1c5feeef750>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "session = fo.launch_app(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating detections...\n",
            " 100% |███████████████| 5000/5000 [11.4s elapsed, 0s remaining, 505.9 samples/s]      \n",
            "Performing IoU sweep...\n",
            " 100% |███████████████| 5000/5000 [11.3s elapsed, 0s remaining, 499.7 samples/s]      \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.6207415907623898,\n",
              " 'precision': 0.6302796387998835,\n",
              " 'recall': 0.976201218136702,\n",
              " 'fscore': 0.765996990884149,\n",
              " 'support': 8866,\n",
              " 'mAP': 0.5578250144069918}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Оценка детекций в поле 'faster_rcnn' нашего 'high_conf_view'\n",
        "# относительно объектов в поле 'ground_truth'\n",
        "\n",
        "results = val_dataset.evaluate_detections(\n",
        "            \"faster_rcnn\",\n",
        "            gt_field=\"detections\",\n",
        "            eval_key=\"eval\",\n",
        "            compute_mAP=True,\n",
        "            )\n",
        "model_metrics = results.metrics()\n",
        "model_metrics['mAP'] = results.mAP()\n",
        "model_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "F1 на слабом baseline составила 0.766"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "37efbb5e22684840aa988c0e23663136": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b0676ddb2f74f5e99fda5eb02efc9c8",
            "placeholder": "​",
            "style": "IPY_MODEL_e767c44bb5a646f9974615703e6ecdda",
            "value": " 160M/160M [00:01&lt;00:00, 155MB/s]"
          }
        },
        "4828f836fb2642f6bafd14ba7b69ae49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b0676ddb2f74f5e99fda5eb02efc9c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53087f1045234fe6bc49e467e9f85f50": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aaa04e028f34953b34a9a8905c99748": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96e5f4f0756d4c699dcb30b5fdf9ec3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d85d0d132b6f416bbef04badf3ea995f",
              "IPY_MODEL_bdfe4cb80a714243bfd74c69cc64be0b",
              "IPY_MODEL_37efbb5e22684840aa988c0e23663136"
            ],
            "layout": "IPY_MODEL_53087f1045234fe6bc49e467e9f85f50"
          }
        },
        "ae54e59833114fb8b4ea13126bc25a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdfe4cb80a714243bfd74c69cc64be0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4828f836fb2642f6bafd14ba7b69ae49",
            "max": 167502836,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae54e59833114fb8b4ea13126bc25a1b",
            "value": 167502836
          }
        },
        "d85d0d132b6f416bbef04badf3ea995f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aaa04e028f34953b34a9a8905c99748",
            "placeholder": "​",
            "style": "IPY_MODEL_fbdc947106b340f28128429aa79e1c2b",
            "value": "100%"
          }
        },
        "e767c44bb5a646f9974615703e6ecdda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbdc947106b340f28128429aa79e1c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
