{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ8-zW_yJ279"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis-R-V/TSR/blob/main/simple_detector_v1.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xtJ8o7tJ27-"
      },
      "source": [
        "# Система распознавания дорожных знаков на датасете RTSD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "colab = False\n",
        "\n",
        "if colab == True:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    !pip install kaggle\n",
        "    !mkdir ~/.kaggle\n",
        "    !cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "    !kaggle datasets download watchman/rtsd-dataset\n",
        "    !unzip rtsd-dataset.zip -d ./data/RTSD\n",
        "    !rm rtsd-dataset.zip\n",
        "    !cp -r data/RTSD/rtsd-frames/rtsd-frames/ data/RTSD/\n",
        "    !rm -r data/RTSD/rtsd-frames/rtsd-frames/\n",
        "    !pip install fiftyone\n",
        "\n",
        "dataset_path = 'data/RTSD'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqBv_YmjJ27_",
        "outputId": "880b1d0c-2b90-4559-b0c7-67e75b309fc2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from pycocotools.coco import COCO\n",
        "import fiftyone as fo\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k69EoY9zJ28Y"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucnN1QnuJ28Y"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rclVCp8kJ28Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "# define the torchvision image transforms\n",
        "#transform = transforms.Compose([\n",
        "#    transforms.ToTensor(),\n",
        "#])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1QNx8AamJ28Y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from pycocotools.coco import COCO\n",
        "import fiftyone as fo\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "import cv2\n",
        "#PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6DuUT7KJ28Y"
      },
      "outputs": [],
      "source": [
        "#from PIL import Image\n",
        "#img = Image.open('data/rtsd-frames/autosave01_02_2012_09_16_49.jpg').convert(\"RGB\")\n",
        "#img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRRoJ7Q4J28Z"
      },
      "source": [
        "### Загрузчик данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MwbfgR4XJ28Z"
      },
      "outputs": [],
      "source": [
        "class RTSD_dataset(Dataset):\n",
        "  \n",
        "    def __init__(self, json_path, img_path):\n",
        "        self.json_path = json_path\n",
        "        self.img_path = img_path\n",
        "        \n",
        "        with open(json_path, 'r') as read_file:\n",
        "            self.anno = json.load(read_file)\n",
        "        read_file.close()\n",
        "\n",
        "        self.df_dataset = pd.DataFrame(self.anno.get('annotations'))\n",
        "        self.test = self.df_dataset.copy()\n",
        "        #self.test['bbox_for_rcnn'] = self.test.bbox[0]\n",
        "        self.df_images = pd.DataFrame(self.anno.get('images'))\n",
        "        self.df_images.rename(columns={'id':'image_id'}, inplace=True)\n",
        "        self.df_dataset = self.df_dataset.merge(self.df_images)\n",
        "        self.df_dataset = self.df_dataset[['file_name', 'bbox', 'category_id']].groupby('file_name', as_index=False).agg(list)\n",
        "\n",
        "    def get_df(self):\n",
        "        #return self.df_dataset\n",
        "        return self.test\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df_dataset.shape[0]\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.df_dataset.loc[index,'file_name']\n",
        "        boxes = []\n",
        "        for box in self.df_dataset.loc[index,'bbox']:\n",
        "            box_for_rcnn = [box[0], box[1], box[0] + box[2], box[1] + box[3]]\n",
        "            boxes.append(box_for_rcnn)\n",
        "        boxes = torch.Tensor(boxes).to(torch.float)            # возможно нужно преобразовать x_max и y_max\n",
        "        #boxes = torch.Tensor(self.df_dataset.loc[index, 'bbox']).to(torch.float)\n",
        "        labels = torch.Tensor(self.df_dataset.loc[index, 'category_id']).to(torch.int64)\n",
        "        #area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 0])\n",
        "        #iscrowd = torch.zeros(labels.shape[0], dtype=torch.int64)\n",
        "\n",
        "        target = {}\n",
        "        target['boxes'] = boxes\n",
        "        target['labels'] = labels\n",
        "\n",
        "        img = cv2.imread(os.path.join(self.img_path, img_name))/255.\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1).to(torch.float)\n",
        "        #return img, target\n",
        "        return img, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "74veX1KrJ28Z"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[0.4902, 0.5255, 0.5255,  ..., 0.8863, 0.8824, 0.9412],\n",
              "          [0.5294, 0.4902, 0.4784,  ..., 0.8549, 0.8667, 0.9294],\n",
              "          [0.5765, 0.5059, 0.4745,  ..., 0.8000, 0.8353, 0.8941],\n",
              "          ...,\n",
              "          [0.2118, 0.2039, 0.2039,  ..., 0.4000, 0.4000, 0.3961],\n",
              "          [0.2157, 0.2157, 0.2118,  ..., 0.3882, 0.3922, 0.3922],\n",
              "          [0.0980, 0.0980, 0.0863,  ..., 0.1451, 0.1529, 0.1529]],\n",
              " \n",
              "         [[0.2353, 0.2706, 0.2824,  ..., 0.6196, 0.5686, 0.6039],\n",
              "          [0.2667, 0.2275, 0.2275,  ..., 0.5922, 0.5647, 0.6078],\n",
              "          [0.2980, 0.2314, 0.2078,  ..., 0.5412, 0.5569, 0.6118],\n",
              "          ...,\n",
              "          [0.1412, 0.1412, 0.1412,  ..., 0.2275, 0.2235, 0.2235],\n",
              "          [0.1529, 0.1529, 0.1490,  ..., 0.2627, 0.2549, 0.2588],\n",
              "          [0.0353, 0.0353, 0.0314,  ..., 0.0431, 0.0392, 0.0392]],\n",
              " \n",
              "         [[0.0824, 0.1176, 0.1216,  ..., 0.0824, 0.1020, 0.1647],\n",
              "          [0.1137, 0.0745, 0.0667,  ..., 0.1020, 0.1059, 0.1686],\n",
              "          [0.1490, 0.0745, 0.0392,  ..., 0.1294, 0.1216, 0.1725],\n",
              "          ...,\n",
              "          [0.0275, 0.0275, 0.0275,  ..., 0.0431, 0.0510, 0.0392],\n",
              "          [0.0392, 0.0392, 0.0353,  ..., 0.0941, 0.0980, 0.0902],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
              " {'boxes': tensor([[706., 319., 734., 346.],\n",
              "          [706., 348., 738., 365.]]),\n",
              "  'labels': tensor([18, 19])})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = RTSD_dataset('data/train_anno_reduced.json', 'data/')\n",
        "test.__getitem__(9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TnfiyYUJ28Z"
      },
      "source": [
        "### Формирование батча"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "del test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ltY8LK2BJ28Z"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J90qxR2RJ28Z"
      },
      "source": [
        "### Гиперпараметры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CI7vlkQPJ28Z"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device_id = 0\n",
        "if torch.cuda.is_available() == True:\n",
        "    device = f'cuda:{device_id}'\n",
        "elif torch.backends.mps.is_available() == True:\n",
        "    device = 'mps'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "n_epochs = 10\n",
        "batch_size = 8\n",
        "num_classes = 156\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo40ASBXJ28Z"
      },
      "source": [
        "### Инициализация модели, задание оптимизатора и функции потерь"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HNRGcfkIJ28Z"
      },
      "outputs": [],
      "source": [
        "def create_model(num_classes, pretrained=False):\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZdWxX5-PJ28Z"
      },
      "outputs": [],
      "source": [
        "model = create_model(num_classes=156, pretrained=True).to(device)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.0005)\n",
        "#ptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "    # and a learning rate scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "\n",
        "train_dataset = RTSD_dataset(os.path.join(dataset_path, 'train_anno.json'),\n",
        "                                          dataset_path)\n",
        "val_dataset = RTSD_dataset(os.path.join(dataset_path, 'val_anno.json'), dataset_path)\n",
        "\n",
        "train_data_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_data_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YimGoL3J28Z"
      },
      "source": [
        "### Трейн луп"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "A7iQ-nA4J28Z"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, epoch): \n",
        "    len_dataloader = len(train_dataloader)\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for i, data in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        images, targets = data[0], data[1]\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        loss_dict = model(images, targets)\n",
        "        loss = sum(loss for loss in loss_dict.values())\n",
        "        running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if i % 50 == 0:\n",
        "            print(f\"\\tЭпоха {epoch}. Итерация {i}/{len_dataloader} на обучающей выборке. Loss: {loss}\")\n",
        "    train_loss = running_loss/len(train_dataloader.dataset)\n",
        "    return train_loss\n",
        "\n",
        "def val(val_dataloader, epoch):\n",
        "    len_dataloader = len(val_dataloader)\n",
        "    running_loss = 0\n",
        "    for i, data in enumerate(val_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        images, targets = data[0], data[1]\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        with torch.no_grad():\n",
        "            loss_dict = model(images, targets)\n",
        "        loss = sum(loss for loss in loss_dict.values())\n",
        "        running_loss += loss.item()\n",
        "        if i % 50 == 0:\n",
        "            print(f\"\\tЭпоха {epoch}. Итерация {i}/{len_dataloader} на тестовой выборке. Loss: {loss}\")\n",
        "    val_loss = running_loss/len(val_dataloader.dataset)\n",
        "    return val_loss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoints_path = 'checkpoints'\n",
        "model_name = 'resnet50_all_classes'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPWlmt4_J28a",
        "outputId": "6907b343-fdc4-4118-d3d1-62247206d21a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tЭпоха 0. Итерация 0/6774 на обучающей выборке. Loss: 5.114344120025635\n",
            "\tЭпоха 0. Итерация 50/6774 на обучающей выборке. Loss: 0.4196016788482666\n",
            "\tЭпоха 0. Итерация 100/6774 на обучающей выборке. Loss: 0.4057539701461792\n",
            "\tЭпоха 0. Итерация 150/6774 на обучающей выборке. Loss: 0.48869940638542175\n",
            "\tЭпоха 0. Итерация 200/6774 на обучающей выборке. Loss: 0.24875342845916748\n",
            "\tЭпоха 0. Итерация 250/6774 на обучающей выборке. Loss: 0.3601597249507904\n",
            "\tЭпоха 0. Итерация 300/6774 на обучающей выборке. Loss: 0.3340436518192291\n",
            "\tЭпоха 0. Итерация 350/6774 на обучающей выборке. Loss: 0.3451211452484131\n",
            "\tЭпоха 0. Итерация 400/6774 на обучающей выборке. Loss: 0.3485730290412903\n",
            "\tЭпоха 0. Итерация 450/6774 на обучающей выборке. Loss: 0.26979395747184753\n",
            "\tЭпоха 0. Итерация 500/6774 на обучающей выборке. Loss: 0.2767212390899658\n",
            "\tЭпоха 0. Итерация 550/6774 на обучающей выборке. Loss: 0.46090176701545715\n",
            "\tЭпоха 0. Итерация 600/6774 на обучающей выборке. Loss: 0.22132660448551178\n",
            "\tЭпоха 0. Итерация 650/6774 на обучающей выборке. Loss: 0.2858211100101471\n",
            "\tЭпоха 0. Итерация 700/6774 на обучающей выборке. Loss: 0.20695261657238007\n",
            "\tЭпоха 0. Итерация 750/6774 на обучающей выборке. Loss: 0.3893871009349823\n",
            "\tЭпоха 0. Итерация 800/6774 на обучающей выборке. Loss: 0.3026541471481323\n",
            "\tЭпоха 0. Итерация 850/6774 на обучающей выборке. Loss: 0.18690738081932068\n",
            "\tЭпоха 0. Итерация 900/6774 на обучающей выборке. Loss: 0.22791199386119843\n",
            "\tЭпоха 0. Итерация 950/6774 на обучающей выборке. Loss: 0.20116057991981506\n",
            "\tЭпоха 0. Итерация 1000/6774 на обучающей выборке. Loss: 0.2501632273197174\n",
            "\tЭпоха 0. Итерация 1050/6774 на обучающей выборке. Loss: 0.22556886076927185\n",
            "\tЭпоха 0. Итерация 1100/6774 на обучающей выборке. Loss: 0.21502883732318878\n",
            "\tЭпоха 0. Итерация 1150/6774 на обучающей выборке. Loss: 0.20976878702640533\n",
            "\tЭпоха 0. Итерация 1200/6774 на обучающей выборке. Loss: 0.10779663175344467\n",
            "\tЭпоха 0. Итерация 1250/6774 на обучающей выборке. Loss: 0.16032174229621887\n",
            "\tЭпоха 0. Итерация 1300/6774 на обучающей выборке. Loss: 0.09397630393505096\n",
            "\tЭпоха 0. Итерация 1350/6774 на обучающей выборке. Loss: 0.21565061807632446\n",
            "\tЭпоха 0. Итерация 1400/6774 на обучающей выборке. Loss: 0.13507921993732452\n",
            "\tЭпоха 0. Итерация 1450/6774 на обучающей выборке. Loss: 0.15326537191867828\n",
            "\tЭпоха 0. Итерация 1500/6774 на обучающей выборке. Loss: 0.23083093762397766\n",
            "\tЭпоха 0. Итерация 1550/6774 на обучающей выборке. Loss: 0.17360596358776093\n",
            "\tЭпоха 0. Итерация 1600/6774 на обучающей выборке. Loss: 0.24677099287509918\n",
            "\tЭпоха 0. Итерация 1650/6774 на обучающей выборке. Loss: 0.12099898606538773\n",
            "\tЭпоха 0. Итерация 1700/6774 на обучающей выборке. Loss: 0.11010179668664932\n",
            "\tЭпоха 0. Итерация 1750/6774 на обучающей выборке. Loss: 0.11302865296602249\n",
            "\tЭпоха 0. Итерация 1800/6774 на обучающей выборке. Loss: 0.14854037761688232\n",
            "\tЭпоха 0. Итерация 1850/6774 на обучающей выборке. Loss: 0.20030216872692108\n",
            "\tЭпоха 0. Итерация 1900/6774 на обучающей выборке. Loss: 0.14795877039432526\n",
            "\tЭпоха 0. Итерация 1950/6774 на обучающей выборке. Loss: 0.17800813913345337\n",
            "\tЭпоха 0. Итерация 2000/6774 на обучающей выборке. Loss: 0.07934491336345673\n",
            "\tЭпоха 0. Итерация 2050/6774 на обучающей выборке. Loss: 0.1770641803741455\n",
            "\tЭпоха 0. Итерация 2100/6774 на обучающей выборке. Loss: 0.315756231546402\n",
            "\tЭпоха 0. Итерация 2150/6774 на обучающей выборке. Loss: 0.08210201561450958\n",
            "\tЭпоха 0. Итерация 2200/6774 на обучающей выборке. Loss: 0.14457297325134277\n",
            "\tЭпоха 0. Итерация 2250/6774 на обучающей выборке. Loss: 0.14575667679309845\n",
            "\tЭпоха 0. Итерация 2300/6774 на обучающей выборке. Loss: 0.13337019085884094\n",
            "\tЭпоха 0. Итерация 2350/6774 на обучающей выборке. Loss: 0.17228569090366364\n",
            "\tЭпоха 0. Итерация 2400/6774 на обучающей выборке. Loss: 0.1329900324344635\n",
            "\tЭпоха 0. Итерация 2450/6774 на обучающей выборке. Loss: 0.26466426253318787\n",
            "\tЭпоха 0. Итерация 2500/6774 на обучающей выборке. Loss: 0.1958719789981842\n",
            "\tЭпоха 0. Итерация 2550/6774 на обучающей выборке. Loss: 0.1287035346031189\n",
            "\tЭпоха 0. Итерация 2600/6774 на обучающей выборке. Loss: 0.13278843462467194\n",
            "\tЭпоха 0. Итерация 2650/6774 на обучающей выборке. Loss: 0.14635010063648224\n",
            "\tЭпоха 0. Итерация 2700/6774 на обучающей выборке. Loss: 0.1783011555671692\n",
            "\tЭпоха 0. Итерация 2750/6774 на обучающей выборке. Loss: 0.17505452036857605\n",
            "\tЭпоха 0. Итерация 2800/6774 на обучающей выборке. Loss: 0.17978918552398682\n",
            "\tЭпоха 0. Итерация 2850/6774 на обучающей выборке. Loss: 0.13365164399147034\n",
            "\tЭпоха 0. Итерация 2900/6774 на обучающей выборке. Loss: 0.07879144698381424\n",
            "\tЭпоха 0. Итерация 2950/6774 на обучающей выборке. Loss: 0.12992383539676666\n",
            "\tЭпоха 0. Итерация 3000/6774 на обучающей выборке. Loss: 0.16854359209537506\n",
            "\tЭпоха 0. Итерация 3050/6774 на обучающей выборке. Loss: 0.20410862565040588\n",
            "\tЭпоха 0. Итерация 3100/6774 на обучающей выборке. Loss: 0.14994704723358154\n",
            "\tЭпоха 0. Итерация 3150/6774 на обучающей выборке. Loss: 0.21213793754577637\n",
            "\tЭпоха 0. Итерация 3200/6774 на обучающей выборке. Loss: 0.22115474939346313\n",
            "\tЭпоха 0. Итерация 3250/6774 на обучающей выборке. Loss: 0.12149735540151596\n",
            "\tЭпоха 0. Итерация 3300/6774 на обучающей выборке. Loss: 0.15137220919132233\n",
            "\tЭпоха 0. Итерация 3350/6774 на обучающей выборке. Loss: 0.16068048775196075\n",
            "\tЭпоха 0. Итерация 3400/6774 на обучающей выборке. Loss: 0.21119220554828644\n",
            "\tЭпоха 0. Итерация 3450/6774 на обучающей выборке. Loss: 0.12628379464149475\n",
            "\tЭпоха 0. Итерация 3500/6774 на обучающей выборке. Loss: 0.20614340901374817\n",
            "\tЭпоха 0. Итерация 3550/6774 на обучающей выборке. Loss: 0.11566513031721115\n",
            "\tЭпоха 0. Итерация 3600/6774 на обучающей выборке. Loss: 0.13410621881484985\n",
            "\tЭпоха 0. Итерация 3650/6774 на обучающей выборке. Loss: 0.1507297158241272\n",
            "\tЭпоха 0. Итерация 3700/6774 на обучающей выборке. Loss: 0.12358646839857101\n",
            "\tЭпоха 0. Итерация 3750/6774 на обучающей выборке. Loss: 0.22024402022361755\n",
            "\tЭпоха 0. Итерация 3800/6774 на обучающей выборке. Loss: 0.14704272150993347\n",
            "\tЭпоха 0. Итерация 3850/6774 на обучающей выборке. Loss: 0.13084031641483307\n",
            "\tЭпоха 0. Итерация 3900/6774 на обучающей выборке. Loss: 0.15483739972114563\n",
            "\tЭпоха 0. Итерация 3950/6774 на обучающей выборке. Loss: 0.11072435975074768\n",
            "\tЭпоха 0. Итерация 4000/6774 на обучающей выборке. Loss: 0.1261139065027237\n",
            "\tЭпоха 0. Итерация 4050/6774 на обучающей выборке. Loss: 0.09835084527730942\n",
            "\tЭпоха 0. Итерация 4100/6774 на обучающей выборке. Loss: 0.12950171530246735\n",
            "\tЭпоха 0. Итерация 4150/6774 на обучающей выборке. Loss: 0.13338108360767365\n",
            "\tЭпоха 0. Итерация 4200/6774 на обучающей выборке. Loss: 0.10357977449893951\n",
            "\tЭпоха 0. Итерация 4250/6774 на обучающей выборке. Loss: 0.19278357923030853\n",
            "\tЭпоха 0. Итерация 4300/6774 на обучающей выборке. Loss: 0.10586006194353104\n",
            "\tЭпоха 0. Итерация 4350/6774 на обучающей выборке. Loss: 0.11205001920461655\n",
            "\tЭпоха 0. Итерация 4400/6774 на обучающей выборке. Loss: 0.1288769692182541\n",
            "\tЭпоха 0. Итерация 4450/6774 на обучающей выборке. Loss: 0.1261102259159088\n",
            "\tЭпоха 0. Итерация 4500/6774 на обучающей выборке. Loss: 0.1367967277765274\n",
            "\tЭпоха 0. Итерация 4550/6774 на обучающей выборке. Loss: 0.16723807156085968\n",
            "\tЭпоха 0. Итерация 4600/6774 на обучающей выборке. Loss: 0.13176478445529938\n",
            "\tЭпоха 0. Итерация 4650/6774 на обучающей выборке. Loss: 0.09900995343923569\n",
            "\tЭпоха 0. Итерация 4700/6774 на обучающей выборке. Loss: 0.10650892555713654\n",
            "\tЭпоха 0. Итерация 4750/6774 на обучающей выборке. Loss: 0.16171501576900482\n",
            "\tЭпоха 0. Итерация 4800/6774 на обучающей выборке. Loss: 0.11775284260511398\n",
            "\tЭпоха 0. Итерация 4850/6774 на обучающей выборке. Loss: 0.07127934694290161\n",
            "\tЭпоха 0. Итерация 4900/6774 на обучающей выборке. Loss: 0.12430766224861145\n",
            "\tЭпоха 0. Итерация 4950/6774 на обучающей выборке. Loss: 0.05662216991186142\n",
            "\tЭпоха 0. Итерация 5000/6774 на обучающей выборке. Loss: 0.21676714718341827\n",
            "\tЭпоха 0. Итерация 5050/6774 на обучающей выборке. Loss: 0.10856200009584427\n",
            "\tЭпоха 0. Итерация 5100/6774 на обучающей выборке. Loss: 0.16973979771137238\n",
            "\tЭпоха 0. Итерация 5150/6774 на обучающей выборке. Loss: 0.0949598029255867\n",
            "\tЭпоха 0. Итерация 5200/6774 на обучающей выборке. Loss: 0.1596747487783432\n",
            "\tЭпоха 0. Итерация 5250/6774 на обучающей выборке. Loss: 0.10597581416368484\n",
            "\tЭпоха 0. Итерация 5300/6774 на обучающей выборке. Loss: 0.1125696673989296\n",
            "\tЭпоха 0. Итерация 5350/6774 на обучающей выборке. Loss: 0.13489177823066711\n",
            "\tЭпоха 0. Итерация 5400/6774 на обучающей выборке. Loss: 0.12835507094860077\n",
            "\tЭпоха 0. Итерация 5450/6774 на обучающей выборке. Loss: 0.1813994199037552\n",
            "\tЭпоха 0. Итерация 5500/6774 на обучающей выборке. Loss: 0.16773535311222076\n",
            "\tЭпоха 0. Итерация 5550/6774 на обучающей выборке. Loss: 0.13147877156734467\n",
            "\tЭпоха 0. Итерация 5600/6774 на обучающей выборке. Loss: 0.11587230116128922\n",
            "\tЭпоха 0. Итерация 5650/6774 на обучающей выборке. Loss: 0.07467436790466309\n",
            "\tЭпоха 0. Итерация 5700/6774 на обучающей выборке. Loss: 0.09296514838933945\n",
            "\tЭпоха 0. Итерация 5750/6774 на обучающей выборке. Loss: 0.09902424365282059\n",
            "\tЭпоха 0. Итерация 5800/6774 на обучающей выборке. Loss: 0.08252933621406555\n",
            "\tЭпоха 0. Итерация 5850/6774 на обучающей выборке. Loss: 0.12166354060173035\n",
            "\tЭпоха 0. Итерация 5900/6774 на обучающей выборке. Loss: 0.0914854034781456\n",
            "\tЭпоха 0. Итерация 5950/6774 на обучающей выборке. Loss: 0.10587546229362488\n",
            "\tЭпоха 0. Итерация 6000/6774 на обучающей выборке. Loss: 0.1504608392715454\n",
            "\tЭпоха 0. Итерация 6050/6774 на обучающей выборке. Loss: 0.08661837875843048\n",
            "\tЭпоха 0. Итерация 6100/6774 на обучающей выборке. Loss: 0.1265636384487152\n",
            "\tЭпоха 0. Итерация 6150/6774 на обучающей выборке. Loss: 0.13064081966876984\n",
            "\tЭпоха 0. Итерация 6200/6774 на обучающей выборке. Loss: 0.18031832575798035\n",
            "\tЭпоха 0. Итерация 6250/6774 на обучающей выборке. Loss: 0.12871888279914856\n",
            "\tЭпоха 0. Итерация 6300/6774 на обучающей выборке. Loss: 0.10999296605587006\n",
            "\tЭпоха 0. Итерация 6350/6774 на обучающей выборке. Loss: 0.07431984692811966\n",
            "\tЭпоха 0. Итерация 6400/6774 на обучающей выборке. Loss: 0.09865817427635193\n",
            "\tЭпоха 0. Итерация 6450/6774 на обучающей выборке. Loss: 0.1532566100358963\n",
            "\tЭпоха 0. Итерация 6500/6774 на обучающей выборке. Loss: 0.13722644746303558\n",
            "\tЭпоха 0. Итерация 6550/6774 на обучающей выборке. Loss: 0.09435360133647919\n",
            "\tЭпоха 0. Итерация 6600/6774 на обучающей выборке. Loss: 0.1629628688097\n",
            "\tЭпоха 0. Итерация 6650/6774 на обучающей выборке. Loss: 0.13167478144168854\n",
            "\tЭпоха 0. Итерация 6700/6774 на обучающей выборке. Loss: 0.1462145447731018\n",
            "\tЭпоха 0. Итерация 6750/6774 на обучающей выборке. Loss: 0.17756280303001404\n",
            "\tЭпоха 0. Итерация 0/625 на тестовой выборке. Loss: 0.09481032937765121\n",
            "\tЭпоха 0. Итерация 50/625 на тестовой выборке. Loss: 0.1251710206270218\n",
            "\tЭпоха 0. Итерация 100/625 на тестовой выборке. Loss: 0.09873524308204651\n",
            "\tЭпоха 0. Итерация 150/625 на тестовой выборке. Loss: 0.06089244410395622\n",
            "\tЭпоха 0. Итерация 200/625 на тестовой выборке. Loss: 0.10947564244270325\n",
            "\tЭпоха 0. Итерация 250/625 на тестовой выборке. Loss: 0.17366807162761688\n",
            "\tЭпоха 0. Итерация 300/625 на тестовой выборке. Loss: 0.19243210554122925\n",
            "\tЭпоха 0. Итерация 350/625 на тестовой выборке. Loss: 0.14588448405265808\n",
            "\tЭпоха 0. Итерация 400/625 на тестовой выборке. Loss: 0.11302347481250763\n",
            "\tЭпоха 0. Итерация 450/625 на тестовой выборке. Loss: 0.08443655073642731\n",
            "\tЭпоха 0. Итерация 500/625 на тестовой выборке. Loss: 0.09341580420732498\n",
            "\tЭпоха 0. Итерация 550/625 на тестовой выборке. Loss: 0.07448267191648483\n",
            "\tЭпоха 0. Итерация 600/625 на тестовой выборке. Loss: 0.1873704493045807\n",
            "Эпоха #0 train_loss: 0.021974471997588733, val_loss: 0.0150245035097003\n",
            "Потрачено 123.9 минут на 0 эпоху\n",
            "\tЭпоха 1. Итерация 0/6774 на обучающей выборке. Loss: 0.1454312801361084\n",
            "\tЭпоха 1. Итерация 50/6774 на обучающей выборке. Loss: 0.18565583229064941\n",
            "\tЭпоха 1. Итерация 100/6774 на обучающей выборке. Loss: 0.0957440659403801\n",
            "\tЭпоха 1. Итерация 150/6774 на обучающей выборке. Loss: 0.16945278644561768\n",
            "\tЭпоха 1. Итерация 200/6774 на обучающей выборке. Loss: 0.15027210116386414\n",
            "\tЭпоха 1. Итерация 250/6774 на обучающей выборке. Loss: 0.08669566363096237\n",
            "\tЭпоха 1. Итерация 300/6774 на обучающей выборке. Loss: 0.08263465017080307\n",
            "\tЭпоха 1. Итерация 350/6774 на обучающей выборке. Loss: 0.11510785669088364\n",
            "\tЭпоха 1. Итерация 400/6774 на обучающей выборке. Loss: 0.18135471642017365\n",
            "\tЭпоха 1. Итерация 450/6774 на обучающей выборке. Loss: 0.18835969269275665\n",
            "\tЭпоха 1. Итерация 500/6774 на обучающей выборке. Loss: 0.13755200803279877\n",
            "\tЭпоха 1. Итерация 550/6774 на обучающей выборке. Loss: 0.09308882802724838\n",
            "\tЭпоха 1. Итерация 600/6774 на обучающей выборке. Loss: 0.12043476104736328\n",
            "\tЭпоха 1. Итерация 650/6774 на обучающей выборке. Loss: 0.10570718348026276\n",
            "\tЭпоха 1. Итерация 700/6774 на обучающей выборке. Loss: 0.10705635696649551\n",
            "\tЭпоха 1. Итерация 750/6774 на обучающей выборке. Loss: 0.10132203996181488\n",
            "\tЭпоха 1. Итерация 800/6774 на обучающей выборке. Loss: 0.14855033159255981\n",
            "\tЭпоха 1. Итерация 850/6774 на обучающей выборке. Loss: 0.11935962736606598\n",
            "\tЭпоха 1. Итерация 900/6774 на обучающей выборке. Loss: 0.08461565524339676\n",
            "\tЭпоха 1. Итерация 950/6774 на обучающей выборке. Loss: 0.15899662673473358\n",
            "\tЭпоха 1. Итерация 1000/6774 на обучающей выборке. Loss: 0.18693986535072327\n",
            "\tЭпоха 1. Итерация 1050/6774 на обучающей выборке. Loss: 0.12097782641649246\n",
            "\tЭпоха 1. Итерация 1100/6774 на обучающей выборке. Loss: 0.11271895468235016\n",
            "\tЭпоха 1. Итерация 1150/6774 на обучающей выборке. Loss: 0.15223295986652374\n",
            "\tЭпоха 1. Итерация 1200/6774 на обучающей выборке. Loss: 0.18982242047786713\n",
            "\tЭпоха 1. Итерация 1250/6774 на обучающей выборке. Loss: 0.06279164552688599\n",
            "\tЭпоха 1. Итерация 1300/6774 на обучающей выборке. Loss: 0.0934387668967247\n",
            "\tЭпоха 1. Итерация 1350/6774 на обучающей выборке. Loss: 0.10021770745515823\n",
            "\tЭпоха 1. Итерация 1400/6774 на обучающей выборке. Loss: 0.09985530376434326\n",
            "\tЭпоха 1. Итерация 1450/6774 на обучающей выборке. Loss: 0.09568899124860764\n",
            "\tЭпоха 1. Итерация 1500/6774 на обучающей выборке. Loss: 0.08506825566291809\n",
            "\tЭпоха 1. Итерация 1550/6774 на обучающей выборке. Loss: 0.1461176574230194\n",
            "\tЭпоха 1. Итерация 1600/6774 на обучающей выборке. Loss: 0.08094805479049683\n",
            "\tЭпоха 1. Итерация 1650/6774 на обучающей выборке. Loss: 0.19270838797092438\n",
            "\tЭпоха 1. Итерация 1700/6774 на обучающей выборке. Loss: 0.15921911597251892\n",
            "\tЭпоха 1. Итерация 1750/6774 на обучающей выборке. Loss: 0.1871730387210846\n",
            "\tЭпоха 1. Итерация 1800/6774 на обучающей выборке. Loss: 0.1532231569290161\n",
            "\tЭпоха 1. Итерация 1850/6774 на обучающей выборке. Loss: 0.12755578756332397\n",
            "\tЭпоха 1. Итерация 1900/6774 на обучающей выборке. Loss: 0.17538900673389435\n",
            "\tЭпоха 1. Итерация 1950/6774 на обучающей выборке. Loss: 0.14125922322273254\n",
            "\tЭпоха 1. Итерация 2000/6774 на обучающей выборке. Loss: 0.14968697726726532\n",
            "\tЭпоха 1. Итерация 2050/6774 на обучающей выборке. Loss: 0.11977113038301468\n",
            "\tЭпоха 1. Итерация 2100/6774 на обучающей выборке. Loss: 0.13225875794887543\n",
            "\tЭпоха 1. Итерация 2150/6774 на обучающей выборке. Loss: 0.13508176803588867\n",
            "\tЭпоха 1. Итерация 2200/6774 на обучающей выборке. Loss: 0.09261057525873184\n",
            "\tЭпоха 1. Итерация 2250/6774 на обучающей выборке. Loss: 0.08807533234357834\n",
            "\tЭпоха 1. Итерация 2300/6774 на обучающей выборке. Loss: 0.08769359439611435\n",
            "\tЭпоха 1. Итерация 2350/6774 на обучающей выборке. Loss: 0.1079372987151146\n",
            "\tЭпоха 1. Итерация 2400/6774 на обучающей выборке. Loss: 0.10412853211164474\n",
            "\tЭпоха 1. Итерация 2450/6774 на обучающей выборке. Loss: 0.1139344573020935\n",
            "\tЭпоха 1. Итерация 2500/6774 на обучающей выборке. Loss: 0.10156390815973282\n",
            "\tЭпоха 1. Итерация 2550/6774 на обучающей выборке. Loss: 0.11627064645290375\n",
            "\tЭпоха 1. Итерация 2600/6774 на обучающей выборке. Loss: 0.06751041114330292\n",
            "\tЭпоха 1. Итерация 2650/6774 на обучающей выборке. Loss: 0.09406602382659912\n",
            "\tЭпоха 1. Итерация 2700/6774 на обучающей выборке. Loss: 0.10947640985250473\n",
            "\tЭпоха 1. Итерация 2750/6774 на обучающей выборке. Loss: 0.11536110937595367\n",
            "\tЭпоха 1. Итерация 2800/6774 на обучающей выборке. Loss: 0.13660697638988495\n",
            "\tЭпоха 1. Итерация 2850/6774 на обучающей выборке. Loss: 0.12450184673070908\n",
            "\tЭпоха 1. Итерация 2900/6774 на обучающей выборке. Loss: 0.10383430868387222\n",
            "\tЭпоха 1. Итерация 2950/6774 на обучающей выборке. Loss: 0.1266692876815796\n",
            "\tЭпоха 1. Итерация 3000/6774 на обучающей выборке. Loss: 0.08620713651180267\n",
            "\tЭпоха 1. Итерация 3050/6774 на обучающей выборке. Loss: 0.07750898599624634\n",
            "\tЭпоха 1. Итерация 3100/6774 на обучающей выборке. Loss: 0.13084480166435242\n",
            "\tЭпоха 1. Итерация 3150/6774 на обучающей выборке. Loss: 0.10509450733661652\n",
            "\tЭпоха 1. Итерация 3200/6774 на обучающей выборке. Loss: 0.07744526118040085\n",
            "\tЭпоха 1. Итерация 3250/6774 на обучающей выборке. Loss: 0.09293105453252792\n",
            "\tЭпоха 1. Итерация 3300/6774 на обучающей выборке. Loss: 0.11720005422830582\n",
            "\tЭпоха 1. Итерация 3350/6774 на обучающей выборке. Loss: 0.1201229989528656\n",
            "\tЭпоха 1. Итерация 3400/6774 на обучающей выборке. Loss: 0.11819913983345032\n",
            "\tЭпоха 1. Итерация 3450/6774 на обучающей выборке. Loss: 0.11091187596321106\n",
            "\tЭпоха 1. Итерация 3500/6774 на обучающей выборке. Loss: 0.13794876635074615\n",
            "\tЭпоха 1. Итерация 3550/6774 на обучающей выборке. Loss: 0.13817739486694336\n",
            "\tЭпоха 1. Итерация 3600/6774 на обучающей выборке. Loss: 0.14899443089962006\n",
            "\tЭпоха 1. Итерация 3650/6774 на обучающей выборке. Loss: 0.10244668275117874\n",
            "\tЭпоха 1. Итерация 3700/6774 на обучающей выборке. Loss: 0.13266786932945251\n",
            "\tЭпоха 1. Итерация 3750/6774 на обучающей выборке. Loss: 0.11815741658210754\n",
            "\tЭпоха 1. Итерация 3800/6774 на обучающей выборке. Loss: 0.12018295377492905\n",
            "\tЭпоха 1. Итерация 3850/6774 на обучающей выборке. Loss: 0.13522766530513763\n",
            "\tЭпоха 1. Итерация 3900/6774 на обучающей выборке. Loss: 0.12867456674575806\n",
            "\tЭпоха 1. Итерация 3950/6774 на обучающей выборке. Loss: 0.11697407811880112\n",
            "\tЭпоха 1. Итерация 4000/6774 на обучающей выборке. Loss: 0.1931876242160797\n",
            "\tЭпоха 1. Итерация 4050/6774 на обучающей выборке. Loss: 0.09285381436347961\n",
            "\tЭпоха 1. Итерация 4100/6774 на обучающей выборке. Loss: 0.2210400402545929\n",
            "\tЭпоха 1. Итерация 4150/6774 на обучающей выборке. Loss: 0.15706318616867065\n",
            "\tЭпоха 1. Итерация 4200/6774 на обучающей выборке. Loss: 0.06661490350961685\n",
            "\tЭпоха 1. Итерация 4250/6774 на обучающей выборке. Loss: 0.09274005144834518\n",
            "\tЭпоха 1. Итерация 4300/6774 на обучающей выборке. Loss: 0.07447290420532227\n",
            "\tЭпоха 1. Итерация 4350/6774 на обучающей выборке. Loss: 0.10204141587018967\n",
            "\tЭпоха 1. Итерация 4400/6774 на обучающей выборке. Loss: 0.11524483561515808\n",
            "\tЭпоха 1. Итерация 4450/6774 на обучающей выборке. Loss: 0.14233025908470154\n",
            "\tЭпоха 1. Итерация 4500/6774 на обучающей выборке. Loss: 0.09076657891273499\n",
            "\tЭпоха 1. Итерация 4550/6774 на обучающей выборке. Loss: 0.09439758211374283\n",
            "\tЭпоха 1. Итерация 4600/6774 на обучающей выборке. Loss: 0.07805616408586502\n",
            "\tЭпоха 1. Итерация 4650/6774 на обучающей выборке. Loss: 0.12278178334236145\n",
            "\tЭпоха 1. Итерация 4700/6774 на обучающей выборке. Loss: 0.050653595477342606\n",
            "\tЭпоха 1. Итерация 4750/6774 на обучающей выборке. Loss: 0.12383401393890381\n",
            "\tЭпоха 1. Итерация 4800/6774 на обучающей выборке. Loss: 0.08440656214952469\n",
            "\tЭпоха 1. Итерация 4850/6774 на обучающей выборке. Loss: 0.11154071241617203\n",
            "\tЭпоха 1. Итерация 4900/6774 на обучающей выборке. Loss: 0.06296125799417496\n",
            "\tЭпоха 1. Итерация 4950/6774 на обучающей выборке. Loss: 0.07532230764627457\n",
            "\tЭпоха 1. Итерация 5000/6774 на обучающей выборке. Loss: 0.15938401222229004\n",
            "\tЭпоха 1. Итерация 5050/6774 на обучающей выборке. Loss: 0.08354762196540833\n",
            "\tЭпоха 1. Итерация 5100/6774 на обучающей выборке. Loss: 0.10517516732215881\n",
            "\tЭпоха 1. Итерация 5150/6774 на обучающей выборке. Loss: 0.07801112532615662\n",
            "\tЭпоха 1. Итерация 5200/6774 на обучающей выборке. Loss: 0.12878164649009705\n",
            "\tЭпоха 1. Итерация 5250/6774 на обучающей выборке. Loss: 0.11083649098873138\n",
            "\tЭпоха 1. Итерация 5300/6774 на обучающей выборке. Loss: 0.08532516658306122\n",
            "\tЭпоха 1. Итерация 5350/6774 на обучающей выборке. Loss: 0.10527851432561874\n",
            "\tЭпоха 1. Итерация 5400/6774 на обучающей выборке. Loss: 0.1299634724855423\n",
            "\tЭпоха 1. Итерация 5450/6774 на обучающей выборке. Loss: 0.15357987582683563\n",
            "\tЭпоха 1. Итерация 5500/6774 на обучающей выборке. Loss: 0.12190310657024384\n",
            "\tЭпоха 1. Итерация 5550/6774 на обучающей выборке. Loss: 0.12424145638942719\n",
            "\tЭпоха 1. Итерация 5600/6774 на обучающей выборке. Loss: 0.10872851312160492\n",
            "\tЭпоха 1. Итерация 5650/6774 на обучающей выборке. Loss: 0.103963203728199\n",
            "\tЭпоха 1. Итерация 5700/6774 на обучающей выборке. Loss: 0.07675657421350479\n",
            "\tЭпоха 1. Итерация 5750/6774 на обучающей выборке. Loss: 0.1571994423866272\n",
            "\tЭпоха 1. Итерация 5800/6774 на обучающей выборке. Loss: 0.14667540788650513\n",
            "\tЭпоха 1. Итерация 5850/6774 на обучающей выборке. Loss: 0.07937908172607422\n",
            "\tЭпоха 1. Итерация 5900/6774 на обучающей выборке. Loss: 0.09689879417419434\n",
            "\tЭпоха 1. Итерация 5950/6774 на обучающей выборке. Loss: 0.10998683422803879\n",
            "\tЭпоха 1. Итерация 6000/6774 на обучающей выборке. Loss: 0.13241371512413025\n",
            "\tЭпоха 1. Итерация 6050/6774 на обучающей выборке. Loss: 0.1038069799542427\n",
            "\tЭпоха 1. Итерация 6100/6774 на обучающей выборке. Loss: 0.11346368491649628\n",
            "\tЭпоха 1. Итерация 6150/6774 на обучающей выборке. Loss: 0.06997950375080109\n",
            "\tЭпоха 1. Итерация 6200/6774 на обучающей выборке. Loss: 0.11383822560310364\n",
            "\tЭпоха 1. Итерация 6250/6774 на обучающей выборке. Loss: 0.0813201367855072\n",
            "\tЭпоха 1. Итерация 6300/6774 на обучающей выборке. Loss: 0.13074654340744019\n",
            "\tЭпоха 1. Итерация 6350/6774 на обучающей выборке. Loss: 0.09131840616464615\n",
            "\tЭпоха 1. Итерация 6400/6774 на обучающей выборке. Loss: 0.10831823945045471\n",
            "\tЭпоха 1. Итерация 6450/6774 на обучающей выборке. Loss: 0.14883537590503693\n",
            "\tЭпоха 1. Итерация 6500/6774 на обучающей выборке. Loss: 0.050718244165182114\n",
            "\tЭпоха 1. Итерация 6550/6774 на обучающей выборке. Loss: 0.11489826440811157\n",
            "\tЭпоха 1. Итерация 6600/6774 на обучающей выборке. Loss: 0.12226181477308273\n",
            "\tЭпоха 1. Итерация 6650/6774 на обучающей выборке. Loss: 0.07365724444389343\n",
            "\tЭпоха 1. Итерация 6700/6774 на обучающей выборке. Loss: 0.132497638463974\n",
            "\tЭпоха 1. Итерация 6750/6774 на обучающей выборке. Loss: 0.10390575975179672\n",
            "\tЭпоха 1. Итерация 0/625 на тестовой выборке. Loss: 0.08426707237958908\n",
            "\tЭпоха 1. Итерация 50/625 на тестовой выборке. Loss: 0.12486280500888824\n",
            "\tЭпоха 1. Итерация 100/625 на тестовой выборке. Loss: 0.07156871259212494\n",
            "\tЭпоха 1. Итерация 150/625 на тестовой выборке. Loss: 0.05507940426468849\n",
            "\tЭпоха 1. Итерация 200/625 на тестовой выборке. Loss: 0.12150124460458755\n",
            "\tЭпоха 1. Итерация 250/625 на тестовой выборке. Loss: 0.15848341584205627\n",
            "\tЭпоха 1. Итерация 300/625 на тестовой выборке. Loss: 0.18420836329460144\n",
            "\tЭпоха 1. Итерация 350/625 на тестовой выборке. Loss: 0.15189087390899658\n",
            "\tЭпоха 1. Итерация 400/625 на тестовой выборке. Loss: 0.11990197002887726\n",
            "\tЭпоха 1. Итерация 450/625 на тестовой выборке. Loss: 0.08430980890989304\n",
            "\tЭпоха 1. Итерация 500/625 на тестовой выборке. Loss: 0.08221696317195892\n",
            "\tЭпоха 1. Итерация 550/625 на тестовой выборке. Loss: 0.08566216379404068\n",
            "\tЭпоха 1. Итерация 600/625 на тестовой выборке. Loss: 0.1282559633255005\n",
            "Эпоха #1 train_loss: 0.014330347371578102, val_loss: 0.014167357668280601\n",
            "Потрачено 122.1 минут на 1 эпоху\n",
            "\tЭпоха 2. Итерация 0/6774 на обучающей выборке. Loss: 0.08618078380823135\n",
            "\tЭпоха 2. Итерация 50/6774 на обучающей выборке. Loss: 0.0871487706899643\n",
            "\tЭпоха 2. Итерация 100/6774 на обучающей выборке. Loss: 0.09333164989948273\n",
            "\tЭпоха 2. Итерация 150/6774 на обучающей выборке. Loss: 0.10440289229154587\n",
            "\tЭпоха 2. Итерация 200/6774 на обучающей выборке. Loss: 0.08311875909566879\n",
            "\tЭпоха 2. Итерация 250/6774 на обучающей выборке. Loss: 0.07679838687181473\n",
            "\tЭпоха 2. Итерация 300/6774 на обучающей выборке. Loss: 0.05558635666966438\n",
            "\tЭпоха 2. Итерация 350/6774 на обучающей выборке. Loss: 0.10475859045982361\n",
            "\tЭпоха 2. Итерация 400/6774 на обучающей выборке. Loss: 0.09883315861225128\n",
            "\tЭпоха 2. Итерация 450/6774 на обучающей выборке. Loss: 0.12147270888090134\n",
            "\tЭпоха 2. Итерация 500/6774 на обучающей выборке. Loss: 0.0761633962392807\n",
            "\tЭпоха 2. Итерация 550/6774 на обучающей выборке. Loss: 0.12691420316696167\n",
            "\tЭпоха 2. Итерация 600/6774 на обучающей выборке. Loss: 0.1332179307937622\n",
            "\tЭпоха 2. Итерация 650/6774 на обучающей выборке. Loss: 0.08490642160177231\n",
            "\tЭпоха 2. Итерация 700/6774 на обучающей выборке. Loss: 0.10551586747169495\n",
            "\tЭпоха 2. Итерация 750/6774 на обучающей выборке. Loss: 0.09332229942083359\n",
            "\tЭпоха 2. Итерация 800/6774 на обучающей выборке. Loss: 0.09883014112710953\n",
            "\tЭпоха 2. Итерация 850/6774 на обучающей выборке. Loss: 0.08599293977022171\n",
            "\tЭпоха 2. Итерация 900/6774 на обучающей выборке. Loss: 0.1074676588177681\n",
            "\tЭпоха 2. Итерация 950/6774 на обучающей выборке. Loss: 0.10661789774894714\n",
            "\tЭпоха 2. Итерация 1000/6774 на обучающей выборке. Loss: 0.08709526062011719\n",
            "\tЭпоха 2. Итерация 1050/6774 на обучающей выборке. Loss: 0.1822342872619629\n",
            "\tЭпоха 2. Итерация 1100/6774 на обучающей выборке. Loss: 0.0976305678486824\n",
            "\tЭпоха 2. Итерация 1150/6774 на обучающей выборке. Loss: 0.08691909909248352\n",
            "\tЭпоха 2. Итерация 1200/6774 на обучающей выборке. Loss: 0.10337226092815399\n",
            "\tЭпоха 2. Итерация 1250/6774 на обучающей выборке. Loss: 0.08813406527042389\n",
            "\tЭпоха 2. Итерация 1300/6774 на обучающей выборке. Loss: 0.060765381902456284\n",
            "\tЭпоха 2. Итерация 1350/6774 на обучающей выборке. Loss: 0.07098107039928436\n",
            "\tЭпоха 2. Итерация 1400/6774 на обучающей выборке. Loss: 0.06519395858049393\n",
            "\tЭпоха 2. Итерация 1450/6774 на обучающей выборке. Loss: 0.09219852089881897\n",
            "\tЭпоха 2. Итерация 1500/6774 на обучающей выборке. Loss: 0.08807007968425751\n",
            "\tЭпоха 2. Итерация 1550/6774 на обучающей выборке. Loss: 0.11958184838294983\n",
            "\tЭпоха 2. Итерация 1600/6774 на обучающей выборке. Loss: 0.09331982582807541\n",
            "\tЭпоха 2. Итерация 1650/6774 на обучающей выборке. Loss: 0.046265747398138046\n",
            "\tЭпоха 2. Итерация 1700/6774 на обучающей выборке. Loss: 0.08478646725416183\n",
            "\tЭпоха 2. Итерация 1750/6774 на обучающей выборке. Loss: 0.10065414756536484\n",
            "\tЭпоха 2. Итерация 1800/6774 на обучающей выборке. Loss: 0.12636926770210266\n",
            "\tЭпоха 2. Итерация 1850/6774 на обучающей выборке. Loss: 0.0775204598903656\n",
            "\tЭпоха 2. Итерация 1900/6774 на обучающей выборке. Loss: 0.10222060978412628\n",
            "\tЭпоха 2. Итерация 1950/6774 на обучающей выборке. Loss: 0.09873457998037338\n",
            "\tЭпоха 2. Итерация 2000/6774 на обучающей выборке. Loss: 0.13894523680210114\n",
            "\tЭпоха 2. Итерация 2050/6774 на обучающей выборке. Loss: 0.12539465725421906\n",
            "\tЭпоха 2. Итерация 2100/6774 на обучающей выборке. Loss: 0.1334097981452942\n",
            "\tЭпоха 2. Итерация 2150/6774 на обучающей выборке. Loss: 0.14237691462039948\n",
            "\tЭпоха 2. Итерация 2200/6774 на обучающей выборке. Loss: 0.13937608897686005\n",
            "\tЭпоха 2. Итерация 2250/6774 на обучающей выборке. Loss: 0.06558165699243546\n",
            "\tЭпоха 2. Итерация 2300/6774 на обучающей выборке. Loss: 0.09776566922664642\n",
            "\tЭпоха 2. Итерация 2350/6774 на обучающей выборке. Loss: 0.09244354814291\n",
            "\tЭпоха 2. Итерация 2400/6774 на обучающей выборке. Loss: 0.12532390654087067\n",
            "\tЭпоха 2. Итерация 2450/6774 на обучающей выборке. Loss: 0.09055145829916\n",
            "\tЭпоха 2. Итерация 2500/6774 на обучающей выборке. Loss: 0.10514797270298004\n",
            "\tЭпоха 2. Итерация 2550/6774 на обучающей выборке. Loss: 0.1359817236661911\n",
            "\tЭпоха 2. Итерация 2600/6774 на обучающей выборке. Loss: 0.1934737265110016\n",
            "\tЭпоха 2. Итерация 2650/6774 на обучающей выборке. Loss: 0.11390852928161621\n",
            "\tЭпоха 2. Итерация 2700/6774 на обучающей выборке. Loss: 0.07192335277795792\n",
            "\tЭпоха 2. Итерация 2750/6774 на обучающей выборке. Loss: 0.0645458772778511\n",
            "\tЭпоха 2. Итерация 2800/6774 на обучающей выборке. Loss: 0.10017138719558716\n",
            "\tЭпоха 2. Итерация 2850/6774 на обучающей выборке. Loss: 0.05370704084634781\n",
            "\tЭпоха 2. Итерация 2900/6774 на обучающей выборке. Loss: 0.06466048955917358\n",
            "\tЭпоха 2. Итерация 2950/6774 на обучающей выборке. Loss: 0.10336507856845856\n",
            "\tЭпоха 2. Итерация 3000/6774 на обучающей выборке. Loss: 0.07747101783752441\n",
            "\tЭпоха 2. Итерация 3050/6774 на обучающей выборке. Loss: 0.06925207376480103\n",
            "\tЭпоха 2. Итерация 3100/6774 на обучающей выборке. Loss: 0.08453099429607391\n",
            "\tЭпоха 2. Итерация 3150/6774 на обучающей выборке. Loss: 0.07529301196336746\n",
            "\tЭпоха 2. Итерация 3200/6774 на обучающей выборке. Loss: 0.21414729952812195\n",
            "\tЭпоха 2. Итерация 3250/6774 на обучающей выборке. Loss: 0.10812652856111526\n",
            "\tЭпоха 2. Итерация 3300/6774 на обучающей выборке. Loss: 0.0958012118935585\n",
            "\tЭпоха 2. Итерация 3350/6774 на обучающей выборке. Loss: 0.06857863813638687\n",
            "\tЭпоха 2. Итерация 3400/6774 на обучающей выборке. Loss: 0.0830126404762268\n",
            "\tЭпоха 2. Итерация 3450/6774 на обучающей выборке. Loss: 0.10174618661403656\n",
            "\tЭпоха 2. Итерация 3500/6774 на обучающей выборке. Loss: 0.17812438309192657\n",
            "\tЭпоха 2. Итерация 3550/6774 на обучающей выборке. Loss: 0.08493967354297638\n",
            "\tЭпоха 2. Итерация 3600/6774 на обучающей выборке. Loss: 0.1003444567322731\n",
            "\tЭпоха 2. Итерация 3650/6774 на обучающей выборке. Loss: 0.10772071033716202\n",
            "\tЭпоха 2. Итерация 3700/6774 на обучающей выборке. Loss: 0.11254923790693283\n",
            "\tЭпоха 2. Итерация 3750/6774 на обучающей выборке. Loss: 0.08884420990943909\n",
            "\tЭпоха 2. Итерация 3800/6774 на обучающей выборке. Loss: 0.14596439898014069\n",
            "\tЭпоха 2. Итерация 3850/6774 на обучающей выборке. Loss: 0.07586824148893356\n",
            "\tЭпоха 2. Итерация 3900/6774 на обучающей выборке. Loss: 0.07342756539583206\n",
            "\tЭпоха 2. Итерация 3950/6774 на обучающей выборке. Loss: 0.09607362747192383\n",
            "\tЭпоха 2. Итерация 4000/6774 на обучающей выборке. Loss: 0.11139900982379913\n",
            "\tЭпоха 2. Итерация 4050/6774 на обучающей выборке. Loss: 0.06023860350251198\n",
            "\tЭпоха 2. Итерация 4100/6774 на обучающей выборке. Loss: 0.11930715292692184\n",
            "\tЭпоха 2. Итерация 4150/6774 на обучающей выборке. Loss: 0.08999314159154892\n",
            "\tЭпоха 2. Итерация 4200/6774 на обучающей выборке. Loss: 0.1062912866473198\n",
            "\tЭпоха 2. Итерация 4250/6774 на обучающей выборке. Loss: 0.06346254795789719\n",
            "\tЭпоха 2. Итерация 4300/6774 на обучающей выборке. Loss: 0.08575329929590225\n",
            "\tЭпоха 2. Итерация 4350/6774 на обучающей выборке. Loss: 0.07446648925542831\n",
            "\tЭпоха 2. Итерация 4400/6774 на обучающей выборке. Loss: 0.07014276087284088\n",
            "\tЭпоха 2. Итерация 4450/6774 на обучающей выборке. Loss: 0.10105931758880615\n",
            "\tЭпоха 2. Итерация 4500/6774 на обучающей выборке. Loss: 0.12092634290456772\n",
            "\tЭпоха 2. Итерация 4550/6774 на обучающей выборке. Loss: 0.06946417689323425\n",
            "\tЭпоха 2. Итерация 4600/6774 на обучающей выборке. Loss: 0.07958947122097015\n",
            "\tЭпоха 2. Итерация 4650/6774 на обучающей выборке. Loss: 0.0648704543709755\n",
            "\tЭпоха 2. Итерация 4700/6774 на обучающей выборке. Loss: 0.09748812019824982\n",
            "\tЭпоха 2. Итерация 4750/6774 на обучающей выборке. Loss: 0.07721683382987976\n",
            "\tЭпоха 2. Итерация 4800/6774 на обучающей выборке. Loss: 0.16681154072284698\n",
            "\tЭпоха 2. Итерация 4850/6774 на обучающей выборке. Loss: 0.07841712981462479\n",
            "\tЭпоха 2. Итерация 4900/6774 на обучающей выборке. Loss: 0.10230990499258041\n",
            "\tЭпоха 2. Итерация 4950/6774 на обучающей выборке. Loss: 0.11580777913331985\n",
            "\tЭпоха 2. Итерация 5000/6774 на обучающей выборке. Loss: 0.2598484456539154\n",
            "\tЭпоха 2. Итерация 5050/6774 на обучающей выборке. Loss: 0.08296321332454681\n",
            "\tЭпоха 2. Итерация 5100/6774 на обучающей выборке. Loss: 0.0828121155500412\n",
            "\tЭпоха 2. Итерация 5150/6774 на обучающей выборке. Loss: 0.12185249477624893\n",
            "\tЭпоха 2. Итерация 5200/6774 на обучающей выборке. Loss: 0.11497774720191956\n",
            "\tЭпоха 2. Итерация 5250/6774 на обучающей выборке. Loss: 0.09648613631725311\n",
            "\tЭпоха 2. Итерация 5300/6774 на обучающей выборке. Loss: 0.10285581648349762\n",
            "\tЭпоха 2. Итерация 5350/6774 на обучающей выборке. Loss: 0.0627419576048851\n",
            "\tЭпоха 2. Итерация 5400/6774 на обучающей выборке. Loss: 0.06860514730215073\n",
            "\tЭпоха 2. Итерация 5450/6774 на обучающей выборке. Loss: 0.09841711819171906\n",
            "\tЭпоха 2. Итерация 5500/6774 на обучающей выборке. Loss: 0.09574161469936371\n",
            "\tЭпоха 2. Итерация 5550/6774 на обучающей выборке. Loss: 0.05500342696905136\n",
            "\tЭпоха 2. Итерация 5600/6774 на обучающей выборке. Loss: 0.07922809571027756\n",
            "\tЭпоха 2. Итерация 5650/6774 на обучающей выборке. Loss: 0.09890617430210114\n",
            "\tЭпоха 2. Итерация 5700/6774 на обучающей выборке. Loss: 0.05760209634900093\n",
            "\tЭпоха 2. Итерация 5750/6774 на обучающей выборке. Loss: 0.07472363114356995\n",
            "\tЭпоха 2. Итерация 5800/6774 на обучающей выборке. Loss: 0.07644142955541611\n",
            "\tЭпоха 2. Итерация 5850/6774 на обучающей выборке. Loss: 0.0992945060133934\n",
            "\tЭпоха 2. Итерация 5900/6774 на обучающей выборке. Loss: 0.12886029481887817\n",
            "\tЭпоха 2. Итерация 5950/6774 на обучающей выборке. Loss: 0.07777582108974457\n",
            "\tЭпоха 2. Итерация 6000/6774 на обучающей выборке. Loss: 0.09433125704526901\n",
            "\tЭпоха 2. Итерация 6050/6774 на обучающей выборке. Loss: 0.09874240309000015\n",
            "\tЭпоха 2. Итерация 6100/6774 на обучающей выборке. Loss: 0.0768711194396019\n",
            "\tЭпоха 2. Итерация 6150/6774 на обучающей выборке. Loss: 0.06971053034067154\n",
            "\tЭпоха 2. Итерация 6200/6774 на обучающей выборке. Loss: 0.07701505720615387\n",
            "\tЭпоха 2. Итерация 6250/6774 на обучающей выборке. Loss: 0.1430690586566925\n",
            "\tЭпоха 2. Итерация 6300/6774 на обучающей выборке. Loss: 0.0983893871307373\n",
            "\tЭпоха 2. Итерация 6350/6774 на обучающей выборке. Loss: 0.20819121599197388\n",
            "\tЭпоха 2. Итерация 6400/6774 на обучающей выборке. Loss: 0.07255583256483078\n",
            "\tЭпоха 2. Итерация 6450/6774 на обучающей выборке. Loss: 0.13985882699489594\n",
            "\tЭпоха 2. Итерация 6500/6774 на обучающей выборке. Loss: 0.07239162176847458\n",
            "\tЭпоха 2. Итерация 6550/6774 на обучающей выборке. Loss: 0.08694832772016525\n",
            "\tЭпоха 2. Итерация 6600/6774 на обучающей выборке. Loss: 0.09431228041648865\n",
            "\tЭпоха 2. Итерация 6650/6774 на обучающей выборке. Loss: 0.13895483314990997\n",
            "\tЭпоха 2. Итерация 6700/6774 на обучающей выборке. Loss: 0.08016318082809448\n",
            "\tЭпоха 2. Итерация 6750/6774 на обучающей выборке. Loss: 0.09897365421056747\n",
            "\tЭпоха 2. Итерация 0/625 на тестовой выборке. Loss: 0.07694488763809204\n",
            "\tЭпоха 2. Итерация 50/625 на тестовой выборке. Loss: 0.09834174066781998\n",
            "\tЭпоха 2. Итерация 100/625 на тестовой выборке. Loss: 0.07531671226024628\n",
            "\tЭпоха 2. Итерация 150/625 на тестовой выборке. Loss: 0.05124225839972496\n",
            "\tЭпоха 2. Итерация 200/625 на тестовой выборке. Loss: 0.1066727265715599\n",
            "\tЭпоха 2. Итерация 250/625 на тестовой выборке. Loss: 0.12639778852462769\n",
            "\tЭпоха 2. Итерация 300/625 на тестовой выборке. Loss: 0.17935910820960999\n",
            "\tЭпоха 2. Итерация 350/625 на тестовой выборке. Loss: 0.12948815524578094\n",
            "\tЭпоха 2. Итерация 400/625 на тестовой выборке. Loss: 0.10347569733858109\n",
            "\tЭпоха 2. Итерация 450/625 на тестовой выборке. Loss: 0.08119040727615356\n",
            "\tЭпоха 2. Итерация 500/625 на тестовой выборке. Loss: 0.08085646480321884\n",
            "\tЭпоха 2. Итерация 550/625 на тестовой выборке. Loss: 0.05643380805850029\n",
            "\tЭпоха 2. Итерация 600/625 на тестовой выборке. Loss: 0.13939693570137024\n",
            "Эпоха #2 train_loss: 0.012778415708261116, val_loss: 0.01265344179943204\n",
            "Потрачено 123.8 минут на 2 эпоху\n",
            "\tЭпоха 3. Итерация 0/6774 на обучающей выборке. Loss: 0.17687436938285828\n",
            "\tЭпоха 3. Итерация 50/6774 на обучающей выборке. Loss: 0.17940405011177063\n",
            "\tЭпоха 3. Итерация 100/6774 на обучающей выборке. Loss: 0.08770940452814102\n",
            "\tЭпоха 3. Итерация 150/6774 на обучающей выборке. Loss: 0.08108256757259369\n",
            "\tЭпоха 3. Итерация 200/6774 на обучающей выборке. Loss: 0.09347839653491974\n",
            "\tЭпоха 3. Итерация 250/6774 на обучающей выборке. Loss: 0.060413215309381485\n",
            "\tЭпоха 3. Итерация 300/6774 на обучающей выборке. Loss: 0.09731367975473404\n",
            "\tЭпоха 3. Итерация 350/6774 на обучающей выборке. Loss: 0.07619825750589371\n",
            "\tЭпоха 3. Итерация 400/6774 на обучающей выборке. Loss: 0.08659449964761734\n",
            "\tЭпоха 3. Итерация 450/6774 на обучающей выборке. Loss: 0.07041943073272705\n",
            "\tЭпоха 3. Итерация 500/6774 на обучающей выборке. Loss: 0.05828945338726044\n",
            "\tЭпоха 3. Итерация 550/6774 на обучающей выборке. Loss: 0.11978976428508759\n",
            "\tЭпоха 3. Итерация 600/6774 на обучающей выборке. Loss: 0.05237586423754692\n",
            "\tЭпоха 3. Итерация 650/6774 на обучающей выборке. Loss: 0.07909242808818817\n",
            "\tЭпоха 3. Итерация 700/6774 на обучающей выборке. Loss: 0.08974266797304153\n",
            "\tЭпоха 3. Итерация 750/6774 на обучающей выборке. Loss: 0.13410475850105286\n",
            "\tЭпоха 3. Итерация 800/6774 на обучающей выборке. Loss: 0.11518044769763947\n",
            "\tЭпоха 3. Итерация 850/6774 на обучающей выборке. Loss: 0.06975886970758438\n",
            "\tЭпоха 3. Итерация 900/6774 на обучающей выборке. Loss: 0.10672954469919205\n",
            "\tЭпоха 3. Итерация 950/6774 на обучающей выборке. Loss: 0.11766493320465088\n",
            "\tЭпоха 3. Итерация 1000/6774 на обучающей выборке. Loss: 0.0992392748594284\n",
            "\tЭпоха 3. Итерация 1050/6774 на обучающей выборке. Loss: 0.07477044314146042\n",
            "\tЭпоха 3. Итерация 1100/6774 на обучающей выборке. Loss: 0.07391608506441116\n",
            "\tЭпоха 3. Итерация 1150/6774 на обучающей выборке. Loss: 0.10931767523288727\n",
            "\tЭпоха 3. Итерация 1200/6774 на обучающей выборке. Loss: 0.09997923672199249\n",
            "\tЭпоха 3. Итерация 1250/6774 на обучающей выборке. Loss: 0.05811392515897751\n",
            "\tЭпоха 3. Итерация 1300/6774 на обучающей выборке. Loss: 0.08125019818544388\n",
            "\tЭпоха 3. Итерация 1350/6774 на обучающей выборке. Loss: 0.08614923059940338\n",
            "\tЭпоха 3. Итерация 1400/6774 на обучающей выборке. Loss: 0.08685855567455292\n",
            "\tЭпоха 3. Итерация 1450/6774 на обучающей выборке. Loss: 0.06554923206567764\n",
            "\tЭпоха 3. Итерация 1500/6774 на обучающей выборке. Loss: 0.10363133996725082\n",
            "\tЭпоха 3. Итерация 1550/6774 на обучающей выборке. Loss: 0.06226082518696785\n",
            "\tЭпоха 3. Итерация 1600/6774 на обучающей выборке. Loss: 0.08771470934152603\n",
            "\tЭпоха 3. Итерация 1650/6774 на обучающей выборке. Loss: 0.10421149432659149\n",
            "\tЭпоха 3. Итерация 1700/6774 на обучающей выборке. Loss: 0.10487775504589081\n",
            "\tЭпоха 3. Итерация 1750/6774 на обучающей выборке. Loss: 0.06438648700714111\n",
            "\tЭпоха 3. Итерация 1800/6774 на обучающей выборке. Loss: 0.06105663627386093\n",
            "\tЭпоха 3. Итерация 1850/6774 на обучающей выборке. Loss: 0.08423537015914917\n",
            "\tЭпоха 3. Итерация 1900/6774 на обучающей выборке. Loss: 0.20421892404556274\n",
            "\tЭпоха 3. Итерация 1950/6774 на обучающей выборке. Loss: 0.07648837566375732\n",
            "\tЭпоха 3. Итерация 2000/6774 на обучающей выборке. Loss: 0.14361412823200226\n",
            "\tЭпоха 3. Итерация 2050/6774 на обучающей выборке. Loss: 0.07472488284111023\n",
            "\tЭпоха 3. Итерация 2100/6774 на обучающей выборке. Loss: 0.06257804483175278\n",
            "\tЭпоха 3. Итерация 2150/6774 на обучающей выборке. Loss: 0.10039941966533661\n",
            "\tЭпоха 3. Итерация 2200/6774 на обучающей выборке. Loss: 0.0936078429222107\n",
            "\tЭпоха 3. Итерация 2250/6774 на обучающей выборке. Loss: 0.0883496105670929\n",
            "\tЭпоха 3. Итерация 2300/6774 на обучающей выборке. Loss: 0.06686806678771973\n",
            "\tЭпоха 3. Итерация 2350/6774 на обучающей выборке. Loss: 0.07884333282709122\n",
            "\tЭпоха 3. Итерация 2400/6774 на обучающей выборке. Loss: 0.09830004721879959\n",
            "\tЭпоха 3. Итерация 2450/6774 на обучающей выборке. Loss: 0.10038743913173676\n",
            "\tЭпоха 3. Итерация 2500/6774 на обучающей выборке. Loss: 0.11977566033601761\n",
            "\tЭпоха 3. Итерация 2550/6774 на обучающей выборке. Loss: 0.15111449360847473\n",
            "\tЭпоха 3. Итерация 2600/6774 на обучающей выборке. Loss: 0.10770291090011597\n",
            "\tЭпоха 3. Итерация 2650/6774 на обучающей выборке. Loss: 0.12098105996847153\n",
            "\tЭпоха 3. Итерация 2700/6774 на обучающей выборке. Loss: 0.11023936420679092\n",
            "\tЭпоха 3. Итерация 2750/6774 на обучающей выборке. Loss: 0.13624191284179688\n",
            "\tЭпоха 3. Итерация 2800/6774 на обучающей выборке. Loss: 0.12904669344425201\n",
            "\tЭпоха 3. Итерация 2850/6774 на обучающей выборке. Loss: 0.16182176768779755\n",
            "\tЭпоха 3. Итерация 2900/6774 на обучающей выборке. Loss: 0.09547114372253418\n",
            "\tЭпоха 3. Итерация 2950/6774 на обучающей выборке. Loss: 0.1145014539361\n",
            "\tЭпоха 3. Итерация 3000/6774 на обучающей выборке. Loss: 0.10032616555690765\n",
            "\tЭпоха 3. Итерация 3050/6774 на обучающей выборке. Loss: 0.16025006771087646\n",
            "\tЭпоха 3. Итерация 3100/6774 на обучающей выборке. Loss: 0.06849489361047745\n",
            "\tЭпоха 3. Итерация 3150/6774 на обучающей выборке. Loss: 0.11728563159704208\n",
            "\tЭпоха 3. Итерация 3200/6774 на обучающей выборке. Loss: 0.10273397713899612\n",
            "\tЭпоха 3. Итерация 3250/6774 на обучающей выборке. Loss: 0.0998929813504219\n",
            "\tЭпоха 3. Итерация 3300/6774 на обучающей выборке. Loss: 0.06477344036102295\n",
            "\tЭпоха 3. Итерация 3350/6774 на обучающей выборке. Loss: 0.09705144912004471\n",
            "\tЭпоха 3. Итерация 3400/6774 на обучающей выборке. Loss: 0.09001531451940536\n",
            "\tЭпоха 3. Итерация 3450/6774 на обучающей выборке. Loss: 0.10935380309820175\n",
            "\tЭпоха 3. Итерация 3500/6774 на обучающей выборке. Loss: 0.08368916064500809\n",
            "\tЭпоха 3. Итерация 3550/6774 на обучающей выборке. Loss: 0.06889533251523972\n",
            "\tЭпоха 3. Итерация 3600/6774 на обучающей выборке. Loss: 0.06724891066551208\n",
            "\tЭпоха 3. Итерация 3650/6774 на обучающей выборке. Loss: 0.1189686730504036\n",
            "\tЭпоха 3. Итерация 3700/6774 на обучающей выборке. Loss: 0.0977698415517807\n",
            "\tЭпоха 3. Итерация 3750/6774 на обучающей выборке. Loss: 0.07303189486265182\n",
            "\tЭпоха 3. Итерация 3800/6774 на обучающей выборке. Loss: 0.11777564883232117\n",
            "\tЭпоха 3. Итерация 3850/6774 на обучающей выборке. Loss: 0.05851419270038605\n",
            "\tЭпоха 3. Итерация 3900/6774 на обучающей выборке. Loss: 0.075644850730896\n",
            "\tЭпоха 3. Итерация 3950/6774 на обучающей выборке. Loss: 0.07979467511177063\n",
            "\tЭпоха 3. Итерация 4000/6774 на обучающей выборке. Loss: 0.08149811625480652\n",
            "\tЭпоха 3. Итерация 4050/6774 на обучающей выборке. Loss: 0.10132285207509995\n",
            "\tЭпоха 3. Итерация 4100/6774 на обучающей выборке. Loss: 0.10545104742050171\n",
            "\tЭпоха 3. Итерация 4150/6774 на обучающей выборке. Loss: 0.04700460657477379\n",
            "\tЭпоха 3. Итерация 4200/6774 на обучающей выборке. Loss: 0.06605985760688782\n",
            "\tЭпоха 3. Итерация 4250/6774 на обучающей выборке. Loss: 0.10568050295114517\n",
            "\tЭпоха 3. Итерация 4300/6774 на обучающей выборке. Loss: 0.1104079931974411\n",
            "\tЭпоха 3. Итерация 4350/6774 на обучающей выборке. Loss: 0.08768486976623535\n",
            "\tЭпоха 3. Итерация 4400/6774 на обучающей выборке. Loss: 0.09550800919532776\n",
            "\tЭпоха 3. Итерация 4450/6774 на обучающей выборке. Loss: 0.11832880973815918\n",
            "\tЭпоха 3. Итерация 4500/6774 на обучающей выборке. Loss: 0.07875147461891174\n",
            "\tЭпоха 3. Итерация 4550/6774 на обучающей выборке. Loss: 0.12959328293800354\n",
            "\tЭпоха 3. Итерация 4600/6774 на обучающей выборке. Loss: 0.07163210958242416\n",
            "\tЭпоха 3. Итерация 4650/6774 на обучающей выборке. Loss: 0.14655852317810059\n",
            "\tЭпоха 3. Итерация 4700/6774 на обучающей выборке. Loss: 0.20055940747261047\n",
            "\tЭпоха 3. Итерация 4750/6774 на обучающей выборке. Loss: 0.05785666033625603\n",
            "\tЭпоха 3. Итерация 4800/6774 на обучающей выборке. Loss: 0.10699114203453064\n",
            "\tЭпоха 3. Итерация 4850/6774 на обучающей выборке. Loss: 0.09822965413331985\n",
            "\tЭпоха 3. Итерация 4900/6774 на обучающей выборке. Loss: 0.05119762197136879\n",
            "\tЭпоха 3. Итерация 4950/6774 на обучающей выборке. Loss: 0.07464613020420074\n",
            "\tЭпоха 3. Итерация 5000/6774 на обучающей выборке. Loss: 0.08465590327978134\n",
            "\tЭпоха 3. Итерация 5050/6774 на обучающей выборке. Loss: 0.07335270941257477\n",
            "\tЭпоха 3. Итерация 5100/6774 на обучающей выборке. Loss: 0.06930918991565704\n",
            "\tЭпоха 3. Итерация 5150/6774 на обучающей выборке. Loss: 0.11955179274082184\n",
            "\tЭпоха 3. Итерация 5200/6774 на обучающей выборке. Loss: 0.07208181917667389\n",
            "\tЭпоха 3. Итерация 5250/6774 на обучающей выборке. Loss: 0.08661157637834549\n",
            "\tЭпоха 3. Итерация 5300/6774 на обучающей выборке. Loss: 0.06481286883354187\n",
            "\tЭпоха 3. Итерация 5350/6774 на обучающей выборке. Loss: 0.11572594940662384\n",
            "\tЭпоха 3. Итерация 5400/6774 на обучающей выборке. Loss: 0.1140422597527504\n",
            "\tЭпоха 3. Итерация 5450/6774 на обучающей выборке. Loss: 0.07317858934402466\n",
            "\tЭпоха 3. Итерация 5500/6774 на обучающей выборке. Loss: 0.07956308871507645\n",
            "\tЭпоха 3. Итерация 5550/6774 на обучающей выборке. Loss: 0.07801537960767746\n",
            "\tЭпоха 3. Итерация 5600/6774 на обучающей выборке. Loss: 0.09827888011932373\n",
            "\tЭпоха 3. Итерация 5650/6774 на обучающей выборке. Loss: 0.13001197576522827\n",
            "\tЭпоха 3. Итерация 5700/6774 на обучающей выборке. Loss: 0.08058775216341019\n",
            "\tЭпоха 3. Итерация 5750/6774 на обучающей выборке. Loss: 0.10987221449613571\n",
            "\tЭпоха 3. Итерация 5800/6774 на обучающей выборке. Loss: 0.107596755027771\n",
            "\tЭпоха 3. Итерация 5850/6774 на обучающей выборке. Loss: 0.058850277215242386\n",
            "\tЭпоха 3. Итерация 5900/6774 на обучающей выборке. Loss: 0.06997758895158768\n",
            "\tЭпоха 3. Итерация 5950/6774 на обучающей выборке. Loss: 0.13410834968090057\n",
            "\tЭпоха 3. Итерация 6000/6774 на обучающей выборке. Loss: 0.07331915944814682\n",
            "\tЭпоха 3. Итерация 6050/6774 на обучающей выборке. Loss: 0.05574238672852516\n",
            "\tЭпоха 3. Итерация 6100/6774 на обучающей выборке. Loss: 0.1660856008529663\n",
            "\tЭпоха 3. Итерация 6150/6774 на обучающей выборке. Loss: 0.11435204744338989\n",
            "\tЭпоха 3. Итерация 6200/6774 на обучающей выборке. Loss: 0.08780790120363235\n",
            "\tЭпоха 3. Итерация 6250/6774 на обучающей выборке. Loss: 0.1000218614935875\n",
            "\tЭпоха 3. Итерация 6300/6774 на обучающей выборке. Loss: 0.08485803008079529\n",
            "\tЭпоха 3. Итерация 6350/6774 на обучающей выборке. Loss: 0.10122208297252655\n",
            "\tЭпоха 3. Итерация 6400/6774 на обучающей выборке. Loss: 0.16407912969589233\n",
            "\tЭпоха 3. Итерация 6450/6774 на обучающей выборке. Loss: 0.10856326669454575\n",
            "\tЭпоха 3. Итерация 6500/6774 на обучающей выборке. Loss: 0.0649808943271637\n",
            "\tЭпоха 3. Итерация 6550/6774 на обучающей выборке. Loss: 0.08021926879882812\n",
            "\tЭпоха 3. Итерация 6600/6774 на обучающей выборке. Loss: 0.05646909773349762\n",
            "\tЭпоха 3. Итерация 6650/6774 на обучающей выборке. Loss: 0.08957467973232269\n",
            "\tЭпоха 3. Итерация 6700/6774 на обучающей выборке. Loss: 0.11235994100570679\n",
            "\tЭпоха 3. Итерация 6750/6774 на обучающей выборке. Loss: 0.08325832337141037\n",
            "\tЭпоха 3. Итерация 0/625 на тестовой выборке. Loss: 0.07842781394720078\n",
            "\tЭпоха 3. Итерация 50/625 на тестовой выборке. Loss: 0.1086137518286705\n",
            "\tЭпоха 3. Итерация 100/625 на тестовой выборке. Loss: 0.07400204241275787\n",
            "\tЭпоха 3. Итерация 150/625 на тестовой выборке. Loss: 0.0546787790954113\n",
            "\tЭпоха 3. Итерация 200/625 на тестовой выборке. Loss: 0.10251818597316742\n",
            "\tЭпоха 3. Итерация 250/625 на тестовой выборке. Loss: 0.1648961305618286\n",
            "\tЭпоха 3. Итерация 300/625 на тестовой выборке. Loss: 0.1661166548728943\n",
            "\tЭпоха 3. Итерация 350/625 на тестовой выборке. Loss: 0.13412605226039886\n",
            "\tЭпоха 3. Итерация 400/625 на тестовой выборке. Loss: 0.13884082436561584\n",
            "\tЭпоха 3. Итерация 450/625 на тестовой выборке. Loss: 0.08280850201845169\n",
            "\tЭпоха 3. Итерация 500/625 на тестовой выборке. Loss: 0.07791286706924438\n",
            "\tЭпоха 3. Итерация 550/625 на тестовой выборке. Loss: 0.08624564856290817\n",
            "\tЭпоха 3. Итерация 600/625 на тестовой выборке. Loss: 0.1267847716808319\n",
            "Эпоха #3 train_loss: 0.01214248914301292, val_loss: 0.012724572629481554\n",
            "Потрачено 124.7 минут на 3 эпоху\n",
            "\tЭпоха 4. Итерация 0/6774 на обучающей выборке. Loss: 0.07327323406934738\n",
            "\tЭпоха 4. Итерация 50/6774 на обучающей выборке. Loss: 0.0828620120882988\n",
            "\tЭпоха 4. Итерация 100/6774 на обучающей выборке. Loss: 0.08453477174043655\n",
            "\tЭпоха 4. Итерация 150/6774 на обучающей выборке. Loss: 0.11071205884218216\n",
            "\tЭпоха 4. Итерация 200/6774 на обучающей выборке. Loss: 0.06962481886148453\n",
            "\tЭпоха 4. Итерация 250/6774 на обучающей выборке. Loss: 0.05653177946805954\n",
            "\tЭпоха 4. Итерация 300/6774 на обучающей выборке. Loss: 0.08931207656860352\n",
            "\tЭпоха 4. Итерация 350/6774 на обучающей выборке. Loss: 0.13412973284721375\n",
            "\tЭпоха 4. Итерация 400/6774 на обучающей выборке. Loss: 0.07466334104537964\n",
            "\tЭпоха 4. Итерация 450/6774 на обучающей выборке. Loss: 0.10256035625934601\n",
            "\tЭпоха 4. Итерация 500/6774 на обучающей выборке. Loss: 0.12542477250099182\n",
            "\tЭпоха 4. Итерация 550/6774 на обучающей выборке. Loss: 0.09016533941030502\n",
            "\tЭпоха 4. Итерация 600/6774 на обучающей выборке. Loss: 0.1459996998310089\n",
            "\tЭпоха 4. Итерация 650/6774 на обучающей выборке. Loss: 0.0986761674284935\n",
            "\tЭпоха 4. Итерация 700/6774 на обучающей выборке. Loss: 0.09204238653182983\n",
            "\tЭпоха 4. Итерация 750/6774 на обучающей выборке. Loss: 0.1080600917339325\n",
            "\tЭпоха 4. Итерация 800/6774 на обучающей выборке. Loss: 0.0794391930103302\n",
            "\tЭпоха 4. Итерация 850/6774 на обучающей выборке. Loss: 0.09702340513467789\n",
            "\tЭпоха 4. Итерация 900/6774 на обучающей выборке. Loss: 0.09737060964107513\n",
            "\tЭпоха 4. Итерация 950/6774 на обучающей выборке. Loss: 0.08862446248531342\n",
            "\tЭпоха 4. Итерация 1000/6774 на обучающей выборке. Loss: 0.07234903424978256\n",
            "\tЭпоха 4. Итерация 1050/6774 на обучающей выборке. Loss: 0.053507354110479355\n",
            "\tЭпоха 4. Итерация 1100/6774 на обучающей выборке. Loss: 0.11600583791732788\n",
            "\tЭпоха 4. Итерация 1150/6774 на обучающей выборке. Loss: 0.06914088129997253\n",
            "\tЭпоха 4. Итерация 1200/6774 на обучающей выборке. Loss: 0.11587405204772949\n",
            "\tЭпоха 4. Итерация 1250/6774 на обучающей выборке. Loss: 0.14430858194828033\n",
            "\tЭпоха 4. Итерация 1300/6774 на обучающей выборке. Loss: 0.11905855685472488\n",
            "\tЭпоха 4. Итерация 1350/6774 на обучающей выборке. Loss: 0.1345437467098236\n",
            "\tЭпоха 4. Итерация 1400/6774 на обучающей выборке. Loss: 0.0813976600766182\n",
            "\tЭпоха 4. Итерация 1450/6774 на обучающей выборке. Loss: 0.07274166494607925\n",
            "\tЭпоха 4. Итерация 1500/6774 на обучающей выборке. Loss: 0.10299517214298248\n",
            "\tЭпоха 4. Итерация 1550/6774 на обучающей выборке. Loss: 0.08794763684272766\n",
            "\tЭпоха 4. Итерация 1600/6774 на обучающей выборке. Loss: 0.1626584380865097\n",
            "\tЭпоха 4. Итерация 1650/6774 на обучающей выборке. Loss: 0.12468089908361435\n",
            "\tЭпоха 4. Итерация 1700/6774 на обучающей выборке. Loss: 0.09398768842220306\n",
            "\tЭпоха 4. Итерация 1750/6774 на обучающей выборке. Loss: 0.043281443417072296\n",
            "\tЭпоха 4. Итерация 1800/6774 на обучающей выборке. Loss: 0.06778714805841446\n",
            "\tЭпоха 4. Итерация 1850/6774 на обучающей выборке. Loss: 0.12480002641677856\n",
            "\tЭпоха 4. Итерация 1900/6774 на обучающей выборке. Loss: 0.06464428454637527\n",
            "\tЭпоха 4. Итерация 1950/6774 на обучающей выборке. Loss: 0.08355684578418732\n",
            "\tЭпоха 4. Итерация 2000/6774 на обучающей выборке. Loss: 0.11599943786859512\n",
            "\tЭпоха 4. Итерация 2050/6774 на обучающей выборке. Loss: 0.07565678656101227\n",
            "\tЭпоха 4. Итерация 2100/6774 на обучающей выборке. Loss: 0.09974414855241776\n",
            "\tЭпоха 4. Итерация 2150/6774 на обучающей выборке. Loss: 0.14141416549682617\n",
            "\tЭпоха 4. Итерация 2200/6774 на обучающей выборке. Loss: 0.07747869193553925\n",
            "\tЭпоха 4. Итерация 2250/6774 на обучающей выборке. Loss: 0.07405717670917511\n",
            "\tЭпоха 4. Итерация 2300/6774 на обучающей выборке. Loss: 0.08904805779457092\n",
            "\tЭпоха 4. Итерация 2350/6774 на обучающей выборке. Loss: 0.1330338716506958\n",
            "\tЭпоха 4. Итерация 2400/6774 на обучающей выборке. Loss: 0.14034618437290192\n",
            "\tЭпоха 4. Итерация 2450/6774 на обучающей выборке. Loss: 0.11143732070922852\n",
            "\tЭпоха 4. Итерация 2500/6774 на обучающей выборке. Loss: 0.12690842151641846\n",
            "\tЭпоха 4. Итерация 2550/6774 на обучающей выборке. Loss: 0.07178381830453873\n",
            "\tЭпоха 4. Итерация 2600/6774 на обучающей выборке. Loss: 0.08874482661485672\n",
            "\tЭпоха 4. Итерация 2650/6774 на обучающей выборке. Loss: 0.049803122878074646\n",
            "\tЭпоха 4. Итерация 2700/6774 на обучающей выборке. Loss: 0.1206846609711647\n",
            "\tЭпоха 4. Итерация 2750/6774 на обучающей выборке. Loss: 0.0993209034204483\n",
            "\tЭпоха 4. Итерация 2800/6774 на обучающей выборке. Loss: 0.08204151690006256\n",
            "\tЭпоха 4. Итерация 2850/6774 на обучающей выборке. Loss: 0.10210933536291122\n",
            "\tЭпоха 4. Итерация 2900/6774 на обучающей выборке. Loss: 0.07997128367424011\n",
            "\tЭпоха 4. Итерация 2950/6774 на обучающей выборке. Loss: 0.0941346287727356\n",
            "\tЭпоха 4. Итерация 3000/6774 на обучающей выборке. Loss: 0.08786099404096603\n",
            "\tЭпоха 4. Итерация 3050/6774 на обучающей выборке. Loss: 0.0694199651479721\n",
            "\tЭпоха 4. Итерация 3100/6774 на обучающей выборке. Loss: 0.06796805560588837\n",
            "\tЭпоха 4. Итерация 3150/6774 на обучающей выборке. Loss: 0.09172383695840836\n",
            "\tЭпоха 4. Итерация 3200/6774 на обучающей выборке. Loss: 0.09078018367290497\n",
            "\tЭпоха 4. Итерация 3250/6774 на обучающей выборке. Loss: 0.07515692710876465\n",
            "\tЭпоха 4. Итерация 3300/6774 на обучающей выборке. Loss: 0.07630757987499237\n",
            "\tЭпоха 4. Итерация 3350/6774 на обучающей выборке. Loss: 0.20056860148906708\n",
            "\tЭпоха 4. Итерация 3400/6774 на обучающей выборке. Loss: 0.12051169574260712\n",
            "\tЭпоха 4. Итерация 3450/6774 на обучающей выборке. Loss: 0.07057370245456696\n",
            "\tЭпоха 4. Итерация 3500/6774 на обучающей выборке. Loss: 0.10499987751245499\n",
            "\tЭпоха 4. Итерация 3550/6774 на обучающей выборке. Loss: 0.1616528332233429\n",
            "\tЭпоха 4. Итерация 3600/6774 на обучающей выборке. Loss: 0.08556405454874039\n",
            "\tЭпоха 4. Итерация 3650/6774 на обучающей выборке. Loss: 0.07850676774978638\n",
            "\tЭпоха 4. Итерация 3700/6774 на обучающей выборке. Loss: 0.051827553659677505\n",
            "\tЭпоха 4. Итерация 3750/6774 на обучающей выборке. Loss: 0.07553598284721375\n",
            "\tЭпоха 4. Итерация 3800/6774 на обучающей выборке. Loss: 0.0612497441470623\n",
            "\tЭпоха 4. Итерация 3850/6774 на обучающей выборке. Loss: 0.08046755194664001\n",
            "\tЭпоха 4. Итерация 3900/6774 на обучающей выборке. Loss: 0.08543866872787476\n",
            "\tЭпоха 4. Итерация 3950/6774 на обучающей выборке. Loss: 0.08111660182476044\n",
            "\tЭпоха 4. Итерация 4000/6774 на обучающей выборке. Loss: 0.08340772241353989\n",
            "\tЭпоха 4. Итерация 4050/6774 на обучающей выборке. Loss: 0.0953923761844635\n",
            "\tЭпоха 4. Итерация 4100/6774 на обучающей выборке. Loss: 0.09645591676235199\n",
            "\tЭпоха 4. Итерация 4150/6774 на обучающей выборке. Loss: 0.06485863775014877\n",
            "\tЭпоха 4. Итерация 4200/6774 на обучающей выборке. Loss: 0.08726563304662704\n",
            "\tЭпоха 4. Итерация 4250/6774 на обучающей выборке. Loss: 0.08431537449359894\n",
            "\tЭпоха 4. Итерация 4300/6774 на обучающей выборке. Loss: 0.07134583592414856\n",
            "\tЭпоха 4. Итерация 4350/6774 на обучающей выборке. Loss: 0.06760761886835098\n",
            "\tЭпоха 4. Итерация 4400/6774 на обучающей выборке. Loss: 0.10259240865707397\n",
            "\tЭпоха 4. Итерация 4450/6774 на обучающей выборке. Loss: 0.06689233332872391\n",
            "\tЭпоха 4. Итерация 4500/6774 на обучающей выборке. Loss: 0.10978437215089798\n",
            "\tЭпоха 4. Итерация 4550/6774 на обучающей выборке. Loss: 0.06183111295104027\n",
            "\tЭпоха 4. Итерация 4600/6774 на обучающей выборке. Loss: 0.08136127144098282\n",
            "\tЭпоха 4. Итерация 4650/6774 на обучающей выборке. Loss: 0.05889531224966049\n",
            "\tЭпоха 4. Итерация 4700/6774 на обучающей выборке. Loss: 0.09474070370197296\n",
            "\tЭпоха 4. Итерация 4750/6774 на обучающей выборке. Loss: 0.07210861146450043\n",
            "\tЭпоха 4. Итерация 4800/6774 на обучающей выборке. Loss: 0.09892416000366211\n",
            "\tЭпоха 4. Итерация 4850/6774 на обучающей выборке. Loss: 0.07627613097429276\n",
            "\tЭпоха 4. Итерация 4900/6774 на обучающей выборке. Loss: 0.052584175020456314\n",
            "\tЭпоха 4. Итерация 4950/6774 на обучающей выборке. Loss: 0.07945285737514496\n",
            "\tЭпоха 4. Итерация 5000/6774 на обучающей выборке. Loss: 0.1352202594280243\n",
            "\tЭпоха 4. Итерация 5050/6774 на обучающей выборке. Loss: 0.07547225803136826\n",
            "\tЭпоха 4. Итерация 5100/6774 на обучающей выборке. Loss: 0.08834240585565567\n",
            "\tЭпоха 4. Итерация 5150/6774 на обучающей выборке. Loss: 0.08645567297935486\n",
            "\tЭпоха 4. Итерация 5200/6774 на обучающей выборке. Loss: 0.08871973305940628\n",
            "\tЭпоха 4. Итерация 5250/6774 на обучающей выборке. Loss: 0.07346957176923752\n",
            "\tЭпоха 4. Итерация 5300/6774 на обучающей выборке. Loss: 0.0873185321688652\n",
            "\tЭпоха 4. Итерация 5350/6774 на обучающей выборке. Loss: 0.09926992654800415\n",
            "\tЭпоха 4. Итерация 5400/6774 на обучающей выборке. Loss: 0.10375012457370758\n",
            "\tЭпоха 4. Итерация 5450/6774 на обучающей выборке. Loss: 0.09897101670503616\n",
            "\tЭпоха 4. Итерация 5500/6774 на обучающей выборке. Loss: 0.11401604115962982\n",
            "\tЭпоха 4. Итерация 5550/6774 на обучающей выборке. Loss: 0.09776467084884644\n",
            "\tЭпоха 4. Итерация 5600/6774 на обучающей выборке. Loss: 0.11248453706502914\n",
            "\tЭпоха 4. Итерация 5650/6774 на обучающей выборке. Loss: 0.07832104712724686\n",
            "\tЭпоха 4. Итерация 5700/6774 на обучающей выборке. Loss: 0.0863867998123169\n",
            "\tЭпоха 4. Итерация 5750/6774 на обучающей выборке. Loss: 0.05743439123034477\n",
            "\tЭпоха 4. Итерация 5800/6774 на обучающей выборке. Loss: 0.09679236263036728\n",
            "\tЭпоха 4. Итерация 5850/6774 на обучающей выборке. Loss: 0.07506301999092102\n",
            "\tЭпоха 4. Итерация 5900/6774 на обучающей выборке. Loss: 0.10728422552347183\n",
            "\tЭпоха 4. Итерация 5950/6774 на обучающей выборке. Loss: 0.10343614220619202\n",
            "\tЭпоха 4. Итерация 6000/6774 на обучающей выборке. Loss: 0.08332697302103043\n",
            "\tЭпоха 4. Итерация 6050/6774 на обучающей выборке. Loss: 0.11925271898508072\n",
            "\tЭпоха 4. Итерация 6100/6774 на обучающей выборке. Loss: 0.06934277713298798\n",
            "\tЭпоха 4. Итерация 6150/6774 на обучающей выборке. Loss: 0.07197868078947067\n",
            "\tЭпоха 4. Итерация 6200/6774 на обучающей выборке. Loss: 0.0444253571331501\n",
            "\tЭпоха 4. Итерация 6250/6774 на обучающей выборке. Loss: 0.08311112225055695\n",
            "\tЭпоха 4. Итерация 6300/6774 на обучающей выборке. Loss: 0.07826834172010422\n",
            "\tЭпоха 4. Итерация 6350/6774 на обучающей выборке. Loss: 0.0848245918750763\n",
            "\tЭпоха 4. Итерация 6400/6774 на обучающей выборке. Loss: 0.09072203934192657\n",
            "\tЭпоха 4. Итерация 6450/6774 на обучающей выборке. Loss: 0.07381546497344971\n",
            "\tЭпоха 4. Итерация 6500/6774 на обучающей выборке. Loss: 0.0766061469912529\n",
            "\tЭпоха 4. Итерация 6550/6774 на обучающей выборке. Loss: 0.11162763088941574\n",
            "\tЭпоха 4. Итерация 6600/6774 на обучающей выборке. Loss: 0.13977640867233276\n",
            "\tЭпоха 4. Итерация 6650/6774 на обучающей выборке. Loss: 0.07747194916009903\n",
            "\tЭпоха 4. Итерация 6700/6774 на обучающей выборке. Loss: 0.0601339153945446\n",
            "\tЭпоха 4. Итерация 6750/6774 на обучающей выборке. Loss: 0.08178628236055374\n",
            "\tЭпоха 4. Итерация 0/625 на тестовой выборке. Loss: 0.06564655900001526\n",
            "\tЭпоха 4. Итерация 50/625 на тестовой выборке. Loss: 0.12652626633644104\n",
            "\tЭпоха 4. Итерация 100/625 на тестовой выборке. Loss: 0.06717803329229355\n",
            "\tЭпоха 4. Итерация 150/625 на тестовой выборке. Loss: 0.0551595538854599\n",
            "\tЭпоха 4. Итерация 200/625 на тестовой выборке. Loss: 0.10447017103433609\n",
            "\tЭпоха 4. Итерация 250/625 на тестовой выборке. Loss: 0.1318952441215515\n",
            "\tЭпоха 4. Итерация 300/625 на тестовой выборке. Loss: 0.18940481543540955\n",
            "\tЭпоха 4. Итерация 350/625 на тестовой выборке. Loss: 0.14613935351371765\n",
            "\tЭпоха 4. Итерация 400/625 на тестовой выборке. Loss: 0.11356683075428009\n",
            "\tЭпоха 4. Итерация 450/625 на тестовой выборке. Loss: 0.08567234873771667\n",
            "\tЭпоха 4. Итерация 500/625 на тестовой выборке. Loss: 0.06424640119075775\n",
            "\tЭпоха 4. Итерация 550/625 на тестовой выборке. Loss: 0.08192908763885498\n",
            "\tЭпоха 4. Итерация 600/625 на тестовой выборке. Loss: 0.12136118113994598\n",
            "Эпоха #4 train_loss: 0.011709370148562942, val_loss: 0.012344651445001364\n",
            "Потрачено 124.8 минут на 4 эпоху\n",
            "\tЭпоха 5. Итерация 0/6774 на обучающей выборке. Loss: 0.07210615277290344\n",
            "\tЭпоха 5. Итерация 50/6774 на обучающей выборке. Loss: 0.08511082082986832\n",
            "\tЭпоха 5. Итерация 100/6774 на обучающей выборке. Loss: 0.0954996794462204\n",
            "\tЭпоха 5. Итерация 150/6774 на обучающей выборке. Loss: 0.09069981426000595\n",
            "\tЭпоха 5. Итерация 200/6774 на обучающей выборке. Loss: 0.13818277418613434\n",
            "\tЭпоха 5. Итерация 250/6774 на обучающей выборке. Loss: 0.09316806495189667\n",
            "\tЭпоха 5. Итерация 300/6774 на обучающей выборке. Loss: 0.06153151020407677\n",
            "\tЭпоха 5. Итерация 350/6774 на обучающей выборке. Loss: 0.10097623616456985\n",
            "\tЭпоха 5. Итерация 400/6774 на обучающей выборке. Loss: 0.11096379905939102\n",
            "\tЭпоха 5. Итерация 450/6774 на обучающей выборке. Loss: 0.07238668203353882\n",
            "\tЭпоха 5. Итерация 500/6774 на обучающей выборке. Loss: 0.1069873496890068\n",
            "\tЭпоха 5. Итерация 550/6774 на обучающей выборке. Loss: 0.11260423064231873\n",
            "\tЭпоха 5. Итерация 600/6774 на обучающей выборке. Loss: 0.12875676155090332\n",
            "\tЭпоха 5. Итерация 650/6774 на обучающей выборке. Loss: 0.08745627850294113\n",
            "\tЭпоха 5. Итерация 700/6774 на обучающей выборке. Loss: 0.09210088849067688\n",
            "\tЭпоха 5. Итерация 750/6774 на обучающей выборке. Loss: 0.10497862100601196\n",
            "\tЭпоха 5. Итерация 800/6774 на обучающей выборке. Loss: 0.11405634135007858\n",
            "\tЭпоха 5. Итерация 850/6774 на обучающей выборке. Loss: 0.15399713814258575\n",
            "\tЭпоха 5. Итерация 900/6774 на обучающей выборке. Loss: 0.07647508382797241\n",
            "\tЭпоха 5. Итерация 950/6774 на обучающей выборке. Loss: 0.10735002160072327\n",
            "\tЭпоха 5. Итерация 1000/6774 на обучающей выборке. Loss: 0.1010453999042511\n",
            "\tЭпоха 5. Итерация 1050/6774 на обучающей выборке. Loss: 0.08182401210069656\n",
            "\tЭпоха 5. Итерация 1100/6774 на обучающей выборке. Loss: 0.10875602066516876\n",
            "\tЭпоха 5. Итерация 1150/6774 на обучающей выборке. Loss: 0.17937029898166656\n",
            "\tЭпоха 5. Итерация 1200/6774 на обучающей выборке. Loss: 0.06255066394805908\n",
            "\tЭпоха 5. Итерация 1250/6774 на обучающей выборке. Loss: 0.061735063791275024\n",
            "\tЭпоха 5. Итерация 1300/6774 на обучающей выборке. Loss: 0.17210206389427185\n",
            "\tЭпоха 5. Итерация 1350/6774 на обучающей выборке. Loss: 0.09225159138441086\n",
            "\tЭпоха 5. Итерация 1400/6774 на обучающей выборке. Loss: 0.07469351589679718\n",
            "\tЭпоха 5. Итерация 1450/6774 на обучающей выборке. Loss: 0.08184505999088287\n",
            "\tЭпоха 5. Итерация 1500/6774 на обучающей выборке. Loss: 0.08743996918201447\n",
            "\tЭпоха 5. Итерация 1550/6774 на обучающей выборке. Loss: 0.08690904080867767\n",
            "\tЭпоха 5. Итерация 1600/6774 на обучающей выборке. Loss: 0.1824008822441101\n",
            "\tЭпоха 5. Итерация 1650/6774 на обучающей выборке. Loss: 0.07008402794599533\n",
            "\tЭпоха 5. Итерация 1700/6774 на обучающей выборке. Loss: 0.11048925668001175\n",
            "\tЭпоха 5. Итерация 1750/6774 на обучающей выборке. Loss: 0.1384889781475067\n",
            "\tЭпоха 5. Итерация 1800/6774 на обучающей выборке. Loss: 0.05590697377920151\n",
            "Прервано пользователем\n"
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "try:\n",
        "    for epoch in range(10):\n",
        "        start = time.time()\n",
        "        train_loss = train(train_data_loader, epoch)\n",
        "        val_loss = val(val_data_loader, epoch)\n",
        "        lr_scheduler.step()\n",
        "        print(f\"Эпоха #{epoch} train_loss: {train_loss}, val_loss: {val_loss}\")  \n",
        "        end = time.time()\n",
        "        print(f\"Потрачено {round((end - start) / 60, 1)} минут на {epoch} эпоху\")\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        torch.save({'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "                'losses_train': train_losses,\n",
        "                'losses_val': val_losses,\n",
        "                }, os.path.join(checkpoints_path, f'chkpt_classifier_{model_name}_{epoch}.pth'))\n",
        "    \n",
        "        torch.save(model, os.path.join(checkpoints_path, f'model_classifier_{model_name}_{epoch}.pth'))\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print('Прервано пользователем')\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hgfXJF_9J28a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x245db5fd5a0>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAGwCAYAAABSN5pGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbI0lEQVR4nO3deXxU5d3//9dM9oQsrFkgJGyyCCSsIQEEKxqrVeNSkKKIIlqr/uTm234LrQqt3xat693CLQIKrhVxodyKWMQqW1hDFGRxIQmBkAQMZCXbzPn9MclAQgJJyORkkvfz8ZgHyZnrzHwuhpi317nOdVkMwzAQERERESer2QWIiIiItDYKSCIiIiK1KCCJiIiI1KKAJCIiIlKLApKIiIhILQpIIiIiIrUoIImIiIjU4ml2Ae7KbreTlZVFYGAgFovF7HJERESkAQzDoLCwkIiICKzW+seJFJCaKCsri8jISLPLEBERkSbIzMykR48e9T6vgNREgYGBgOMvOCgoyORqREREpCEKCgqIjIx0/h6vjwJSE1VfVgsKClJAEhERcTOXmh6jSdoiIiIitSggiYiIiNSigCQiIiJSi+YgiYiItCI2m42Kigqzy3BbXl5eeHh4XPbrKCCJiIi0AoZhkJ2dzZkzZ8wuxe2FhIQQFhZ2WesUKiCJiIi0AtXhqFu3bvj7+2sR4iYwDIOSkhJyc3MBCA8Pb/JrKSCJiIiYzGazOcNR586dzS7Hrfn5+QGQm5tLt27dmny5TZO0RURETFY958jf39/kStqG6r/Hy5nLpYAkIiLSSuiyWvNojr/HVhGQFi9eTHR0NL6+vsTFxbFz586Ltl+9ejUDBgzA19eXIUOGsG7dOudzFRUV/P73v2fIkCEEBAQQERHB9OnTycrKcrZJT09n5syZ9OrVCz8/P/r06cP8+fMpLy93WR9FRETEfZgekFatWsWcOXOYP38+KSkpxMTEkJiY6JxgVdu2bduYOnUqM2fOZO/evSQlJZGUlMT+/fsBKCkpISUlhSeeeIKUlBQ+/PBDDh8+zM033+x8jUOHDmG323nllVf49ttvefHFF1myZAl/+MMfWqTPIiIi0rpZDMMwzCwgLi6OUaNGsWjRIgDsdjuRkZE8+uijzJ0794L2U6ZMobi4mI8//th5bMyYMcTGxrJkyZI632PXrl2MHj2ajIwMevbsWWebZ599lpdffpkjR440qO6CggKCg4PJz8/XXmwiInJZSktLSUtLo1evXvj6+ppdjumio6OZPXs2s2fPbtL5F/v7bOjvb1NHkMrLy9mzZw+TJk1yHrNarUyaNInk5OQ6z0lOTq7RHiAxMbHe9gD5+flYLBZCQkIu2qZTp071Pl9WVkZBQUGNhysYhsH2Iz9RWmFzyeuLiIg0F4vFctHHggULmvS6u3bt4oEHHmjeYhvJ1IB06tQpbDYboaGhNY6HhoaSnZ1d5znZ2dmNal9aWsrvf/97pk6dWm9S/OGHH/jHP/7Bgw8+WG+tCxcuJDg42PmIjIy8WNea7KG3Urhz6XY+TDnuktcXERFpLidOnHA+XnrpJYKCgmoc++1vf+tsaxgGlZWVDXrdrl27mn5Hn+lzkFypoqKCyZMnYxgGL7/8cp1tjh8/zvXXX88vf/lLZs2aVe9rzZs3j/z8fOcjMzPTJTWP6uUYxVq++Qh2u6lXP0VExESGYVBSXmnKo6Gzb8LCwpyP4OBgLBaL8/tDhw4RGBjIp59+yogRI/Dx8WHLli38+OOP3HLLLYSGhtKhQwdGjRrF559/XuN1o6Ojeemll5zfWywWli9fzq233oq/vz/9+vVj7dq1zfnXfQFTF4rs0qULHh4e5OTk1Diek5NDWFhYneeEhYU1qH11OMrIyOCLL76oc/QoKyuLq6++moSEBJYuXXrRWn18fPDx8WlIty7LlFGRvPT5dxw5VcwXh3KZNCj00ieJiEibc7bCxqAnPzPlvQ/8ORF/7+aJCHPnzuW5556jd+/edOzYkczMTG644Qb+8pe/4OPjwxtvvMFNN93E4cOH650nDPCnP/2Jv/3tbzz77LP84x//YNq0aWRkZFx0eszlMHUEydvbmxEjRrBx40bnMbvdzsaNG4mPj6/znPj4+BrtATZs2FCjfXU4+v777/n888/rXJX0+PHjTJw4kREjRrBixQqs1tYxmNbBx5NfxTn+gSzb3LAJ4yIiIq3Vn//8Z6699lr69OlDp06diImJ4cEHH2Tw4MH069ePp556ij59+lxyRGjGjBlMnTqVvn378te//pWioqJLLgt0OUzfamTOnDncc889jBw5ktGjR/PSSy9RXFzMvffeC8D06dPp3r07CxcuBOCxxx5jwoQJPP/889x44428++677N692zkCVFFRwR133EFKSgoff/wxNpvNOT+pU6dOeHt7O8NRVFQUzz33HCdPnnTWU9/IVUuakRDNq5vT2JGWxzfHzjC0R4jZJYmISAvz8/LgwJ8TTXvv5jJy5Mga3xcVFbFgwQI++eQTTpw4QWVlJWfPnuXo0aMXfZ2hQ4c6vw4ICCAoKKjeJYGag+kBacqUKZw8eZInn3yS7OxsYmNjWb9+vXMi9tGjR2uM7iQkJPDOO+/w+OOP84c//IF+/fqxZs0aBg8eDDhGhqpTaGxsbI33+s9//sPEiRPZsGEDP/zwAz/88AM9evSo0cbkVQ8ACA/24+aYCD7ce5xlm9P4x9RhZpckIiItzGKxNNtlLjMFBATU+P63v/0tGzZs4LnnnqNv3774+flxxx13XHKxZi8vrxrfWywW7HZ7s9dbrVX8zT/yyCM88sgjdT735ZdfXnDsl7/8Jb/85S/rbB8dHX3JkDNjxgxmzJjR2DJb1P3je/Ph3uOs23eC31/fnx4dtT+PiIi4v61btzJjxgxuvfVWwDGilJ6ebm5RdWgdE2/kAoMighjbtzM2u8GKrelmlyMiItIs+vXrx4cffkhqaipff/01v/rVr1w6EtRUCkit2KzxvQFYtSuTgtKm70gsIiLSWrzwwgt07NiRhIQEbrrpJhITExk+fLjZZV3A9K1G3FVLbDViGAaJL23iu5wi/nDDAB64qo9L3kdERMylrUaal9tvNSIXZ7FYuH+cYxRpxdZ0KmytbwhSRESkLVJAauVuGRZBlw4+nMgv5ZNvTphdjoiISLuggNTK+Xh6MCMhCnAsHKkroiIiIq6ngOQGpsVF4etl5dusApJ//MnsckRERNo8BSQ30DHAm8kjIwFtPyIiItISFJDcxH1je2GxwH8On+T7nEKzyxEREWnTFJDcRHSXAK4b5Nh+ZfnmNJOrERERadsUkNzIA1c5bvn/aO9xThaWmVyNiIhI26WA5EZGRHViWM8Qym123kxON7scERGRyzZx4kRmz55tdhkXUEByM9Xbj7y5PYOz5TaTqxERkfbspptu4vrrr6/zuc2bN2OxWPjmm29auKrmoYDkZhKvDCOykx+nSyp4P+WY2eWIiEg7NnPmTDZs2MCxYxf+PlqxYgUjR45k6NChJlR2+RSQ3IyH1cLMsb0AeG1LGja7Fo4UERFz/OIXv6Br166sXLmyxvGioiJWr15NUlISU6dOpXv37vj7+zNkyBD++c9/mlNsIykguaFfjowkyNeTtFPFfH4wx+xyRETEFQwDyovNeTRw1wZPT0+mT5/OypUra+z0sHr1amw2G3fddRcjRozgk08+Yf/+/TzwwAPcfffd7Ny501V/a83G0+wCpPECfDy5a0wU//PljyzffITEK8PMLklERJpbRQn8NcKc9/5DFngHNKjpfffdx7PPPstXX33FxIkTAcfltdtvv52oqCh++9vfOts++uijfPbZZ7z33nuMHj3aFZU3G40gual7EqLx8rCwK/00e4+eNrscERFppwYMGEBCQgKvvfYaAD/88AObN29m5syZ2Gw2nnrqKYYMGUKnTp3o0KEDn332GUePHjW56kvTCJKbCg3y5eaY7nyQcozlm9NYPK2j2SWJiEhz8vJ3jOSY9d6NMHPmTB599FEWL17MihUr6NOnDxMmTOCZZ57hv//7v3nppZcYMmQIAQEBzJ49m/LychcV3nwUkNzYrKt68UHKMT7df4LMvBIiOzXuH7SIiLRiFkuDL3OZbfLkyTz22GO88847vPHGGzz00ENYLBa2bt3KLbfcwl133QWA3W7nu+++Y9CgQSZXfGm6xObGBoQFMb5fF+wGvLZV24+IiIg5OnTowJQpU5g3bx4nTpxgxowZAPTr148NGzawbds2Dh48yIMPPkhOjnvcXKSA5OaqF45ctSuT/JIKk6sREZH2aubMmZw+fZrExEQiIhyTyx9//HGGDx9OYmIiEydOJCwsjKSkJHMLbSBdYnNz4/t1YUBYIIeyC3ln51EemtjH7JJERKQdio+Pr3GrP0CnTp1Ys2bNRc/78ssvXVfUZdAIkpuzWCzcXzWKtHJbGuWVdpMrEhERcX8KSG3AzTERdAv0IaegjP/92qQ7HkRERNoQBaQ2wNvTyoyx0QAs23zkgiFOERERaRwFpDZi2ugo/L09OJRdyNYffjK7HBEREbemgNRGBPt7MXlkJABLNx8xuRoREWkKXQFoHs3x96iA1IbcN7YXVgts+u4kh7MLzS5HREQayMvLC4CSkhKTK2kbqv8eq/9em0K3+bchPTv7c/3gMNbty2b55iM8+8sYs0sSEZEG8PDwICQkhNzcXAD8/f2xWCwmV+V+DMOgpKSE3NxcQkJC8PDwaPJrKSC1MfeP7826fdmsST3O7xL70y3I1+ySRESkAcLCwgCcIUmaLiQkxPn32VQKSG3M8J4dGRnVkd0Zp3k9OZ3fJQ4wuyQREWkAi8VCeHg43bp1o6JCOyM0lZeX12WNHFVTQGqD7h/fm90Ze3hr+1Eevrov/t76mEVE3IWHh0ez/IKXy6NJ2m3QtYNCiersT/7ZClbvPmZ2OSIiIm5HAakN8rBauH9cLwBe3ZKGza7bRkVERBpDAamNumNEJCH+XhzNK2HDgWyzyxEREXErCkhtlJ+3B3fFRQGwdJMWjhQREWkMBaQ2bHpCFN4eVlKOnmFPxmmzyxEREXEbCkhtWLdAX5KGRQCwXNuPiIiINJgCUht3//jeAKz/NpuMn4pNrkZERMQ9KCC1cVeEBjKxf1cMA17bkmZ2OSIiIm5BAakdmFU1ivTe7mOcKSk3uRoREZHWTwGpHUjo05mB4UGcrbDx9o6jZpcjIiLS6ikgtQMWi4UHrnIsHLlyWzpllTaTKxIREWndFJDaiV8MjSAsyJeThWWsTc0yuxwREZFWTQGpnfDysDJjbDQAyzenYRjafkRERKQ+CkjtyNTRPQnw9uBwTiGbvj9ldjkiIiKtlgJSOxLs58WUUT0BLRwpIiJyMQpI7cy9Y6OxWmDz96c4kFVgdjkiIiKtkgJSOxPZyZ8bhoQDsHyLRpFERETqooDUDlUvHLk2NYvs/FKTqxEREWl9FJDaoZjIEEZHd6LSbrByW7rZ5YiIiLQ6Ckjt1KyrHKNI7+zIoKis0uRqREREWhcFpHbqmgHd6N0lgILSSt7blWl2OSIiIq2KAlI7ZbVauG+cY/uR17amUWmzm1yRiIhI69EqAtLixYuJjo7G19eXuLg4du7cedH2q1evZsCAAfj6+jJkyBDWrVvnfK6iooLf//73DBkyhICAACIiIpg+fTpZWTW318jLy2PatGkEBQUREhLCzJkzKSoqckn/Wqvbh/egU4A3x06f5bNvc8wuR0REpNUwPSCtWrWKOXPmMH/+fFJSUoiJiSExMZHc3Nw622/bto2pU6cyc+ZM9u7dS1JSEklJSezfvx+AkpISUlJSeOKJJ0hJSeHDDz/k8OHD3HzzzTVeZ9q0aXz77bds2LCBjz/+mE2bNvHAAw+4vL+tiZ+3B3eNiQJg6eYj2n5ERESkisUw+bdiXFwco0aNYtGiRQDY7XYiIyN59NFHmTt37gXtp0yZQnFxMR9//LHz2JgxY4iNjWXJkiV1vseuXbsYPXo0GRkZ9OzZk4MHDzJo0CB27drFyJEjAVi/fj033HADx44dIyIi4pJ1FxQUEBwcTH5+PkFBQU3peqtwqqiMhKe/oLzSzupfxzMqupPZJYmIiLhMQ39/mzqCVF5ezp49e5g0aZLzmNVqZdKkSSQnJ9d5TnJyco32AImJifW2B8jPz8disRASEuJ8jZCQEGc4Apg0aRJWq5UdO3bU+RplZWUUFBTUeLQFXTr4cPvw7gAs26SFI0VERMDkgHTq1ClsNhuhoaE1joeGhpKdnV3nOdnZ2Y1qX1payu9//3umTp3qTIrZ2dl069atRjtPT086depU7+ssXLiQ4OBg5yMyMrJBfXQHM8c5bvnfcDCHtFPFJlcjIiJiPtPnILlSRUUFkydPxjAMXn755ct6rXnz5pGfn+98ZGa2nVvj+3brwM8GdMMw4FVtPyIiImJuQOrSpQseHh7k5NS8gyonJ4ewsLA6zwkLC2tQ++pwlJGRwYYNG2pcZwwLC7tgEnhlZSV5eXn1vq+Pjw9BQUE1Hm1J9fYj7+85Rl5xucnViIiImMvUgOTt7c2IESPYuHGj85jdbmfjxo3Ex8fXeU58fHyN9gAbNmyo0b46HH3//fd8/vnndO7c+YLXOHPmDHv27HEe++KLL7Db7cTFxTVH19zOmN6dGNw9iNIKO29tzzC7HBEREVOZfoltzpw5LFu2jNdff52DBw/y0EMPUVxczL333gvA9OnTmTdvnrP9Y489xvr163n++ec5dOgQCxYsYPfu3TzyyCOAIxzdcccd7N69m7fffhubzUZ2djbZ2dmUlztGRgYOHMj111/PrFmz2LlzJ1u3buWRRx7hzjvvbNAdbG2RxWJxjiK9kZxOaYXN5IpERETMY3pAmjJlCs899xxPPvkksbGxpKamsn79eudE7KNHj3LixAln+4SEBN555x2WLl1KTEwM77//PmvWrGHw4MEAHD9+nLVr13Ls2DFiY2MJDw93PrZt2+Z8nbfffpsBAwZwzTXXcMMNNzBu3DiWLl3asp1vZW4YEk5EsC+nisr5V+pxs8sRERExjenrILmrtrIOUm3LNh3hL+sO0rdbB/49+yqsVovZJYmIiDQbt1gHSVqfKaMj6eDjyQ+5RXz13UmzyxERETGFApLUEOTrxdTRjjWelm3WLf8iItI+KSDJBWaM7YWH1cK2H39i//F8s8sRERFpcQpIcoHuIX7cOCQcgOUaRRIRkXZIAUnqVH3L/8ffnCDrzFmTqxEREWlZCkhSpyE9ghnTuxOVdoOV29LNLkdERKRFKSBJvapHkf654yiFpRUmVyMiItJyFJCkXlf370afrgEUllWyalfb2ZxXRETkUhSQpF5Wq4X7q0aRVmxNp9JmN7kiERGRlqGAJBd167DudA7w5viZs6zbn212OSIiIi1CAUkuytfLg+nx0YBjGxLtTCMiIu2BApJc0l1jeuLjaWXf8Xx2pOWZXY6IiIjLKSDJJXXu4MMdI3oAWjhSRETaBwUkaZCZ43phscDnB3P58WSR2eWIiIi4lAKSNEjvrh24ZkAoAMs3p5lcjYiIiGspIEmDPXCV45b/D1OO8VNRmcnViIiIuI4CkjTYqOiOxPQIpqzSzpvbM8wuR0RExGUUkKTBLJZzC0e+kZxBaYXN5IpERERcQwFJGuXng8PoHuJHXnE5H6YcN7scERERl1BAkkbx9LBy37heACzfcgS7XQtHiohI26OAJI02ZVQkgb6eHDlZzBeHcs0uR0REpNkpIEmjdfDx5FdxPQFYpoUjRUSkDVJAkiaZkRCNp9XCjrQ8vjl2xuxyREREmpUCkjRJeLAfN8VEALBMC0eKiEgbo4AkTXb/eMdk7XX7TnD8zFmTqxEREWk+CkjSZFdGBDO2b2dsdoMVWzSKJCIibYcCklyW6oUj392VSUFphcnViIiINA8FJLksE6/oSr9uHSgqq+TdnUfNLkdERKRZKCDJZbFYLMyqGkVasTWdCpvd5IpEREQunwKSXLZbhkXQpYMPJ/JL+eSbE2aXIyIictkUkOSy+Xh6MCMhCnAsHGkY2n5ERETcmwKSNItpcVH4eln5NquA5CM/mV2OiIjIZVFAkmbRMcCbX46IBGDZJm0/IiIi7k0BSZrNzHG9sFjgP4dP8kNuodnliIiINJkCkjSb6C4BXDcoFIDl2n5ERETcmAKSNKvqW/4/TDnOycIyk6sRERFpGgUkaVYjojoyrGcI5TY7byanm12OiIhIkyggSbM6f+HIN7dncLbcZnJFIiIijaeAJM0u8cowIjv5cbqkgvdTjpldjoiISKMpIEmz87BamDm2FwCvbUnDbtfCkSIi4l4UkMQlfjkykiBfT9JOFfP5wRyzyxEREWkUBSRxiQAfT6aNObf9iIiIiDtRQBKXmZEQjZeHhV3pp0nNPGN2OSIiIg2mgCQuExrky80x3QGNIomIiHtRQBKXun+8Y7L2p/tOkJlXYnI1IiIiDaOAJC41MDyI8f26YDfgta3afkRERNyDApK4XPXCkat2ZZJfUmFyNSIiIpemgCQuN75fFwaEBVJSbuOdnUfNLkdEROSSFJDE5SwWC/dXjSKt3JZGeaXd5IpEREQuTgFJWsTNMRF0C/Qhp6CM//06y+xyRERELkoBSVqEt6eVexKiAcct/4ah7UdERKT1UkCSFjMtrif+3h4cyi5k6w8/mV2OiIhIvRSQpMWE+HszeWQkAEu1cKSIiLRiCkjSou4b2wurBTZ9d5LD2YVmlyMiIlIn0wPS4sWLiY6OxtfXl7i4OHbu3HnR9qtXr2bAgAH4+voyZMgQ1q1bV+P5Dz/8kOuuu47OnTtjsVhITU294DWys7O5++67CQsLIyAggOHDh/PBBx80Z7ekHj07+3P94DAAlmsUSUREWilTA9KqVauYM2cO8+fPJyUlhZiYGBITE8nNza2z/bZt25g6dSozZ85k7969JCUlkZSUxP79+51tiouLGTduHM8880y97zt9+nQOHz7M2rVr2bdvH7fddhuTJ09m7969zd5HuVD1Lf9rUo+TW1BqcjUiIiIXshgm3k4UFxfHqFGjWLRoEQB2u53IyEgeffRR5s6de0H7KVOmUFxczMcff+w8NmbMGGJjY1myZEmNtunp6fTq1Yu9e/cSGxtb47kOHTrw8ssvc/fddzuPde7cmWeeeYb777+/QbUXFBQQHBxMfn4+QUFBDe2yVLn95W3syTjNw1f34XeJA8wuR0RE2omG/v42bQSpvLycPXv2MGnSpHPFWK1MmjSJ5OTkOs9JTk6u0R4gMTGx3vb1SUhIYNWqVeTl5WG323n33XcpLS1l4sSJ9Z5TVlZGQUFBjYc0XfX2I29tP0pJeaXJ1YiIiNRkWkA6deoUNpuN0NDQGsdDQ0PJzs6u85zs7OxGta/Pe++9R0VFBZ07d8bHx4cHH3yQjz76iL59+9Z7zsKFCwkODnY+IiMjG/WeUtO1g0KJ6uxP/tkKVu8+ZnY5IiIiNZg+SdsMTzzxBGfOnOHzzz9n9+7dzJkzh8mTJ7Nv3756z5k3bx75+fnOR2ZmZgtW3PZ4WC3MHNcLgFe3pGGza+FIERFpPTzNeuMuXbrg4eFBTk5OjeM5OTmEhYXVeU5YWFij2tflxx9/ZNGiRezfv58rr7wSgJiYGDZv3szixYsvmMtUzcfHBx8fnwa/j1zaHSN68MKG7ziaV8KGA9lcPzjc7JJEREQAE0eQvL29GTFiBBs3bnQes9vtbNy4kfj4+DrPiY+Pr9EeYMOGDfW2r0tJSQngmO90Pg8PD+x2baLakvy9PbkrLgqApZt0y7+IiLQepl5imzNnDsuWLeP111/n4MGDPPTQQxQXF3PvvfcCjtvx582b52z/2GOPsX79ep5//nkOHTrEggUL2L17N4888oizTV5eHqmpqRw4cACAw4cPk5qa6pynNGDAAPr27cuDDz7Izp07+fHHH3n++efZsGEDSUlJLdd5AWB6QhTeHlZSjp5hT8Zps8sREREBTA5IU6ZM4bnnnuPJJ58kNjaW1NRU1q9f75yIffToUU6cOOFsn5CQwDvvvMPSpUuJiYnh/fffZ82aNQwePNjZZu3atQwbNowbb7wRgDvvvJNhw4Y5L515eXmxbt06unbtyk033cTQoUN54403eP3117nhhhtasPcC0C3Ql6RhEYAWjhQRkdbD1HWQ3JnWQWo+3+UUct2Lm7BY4MvfTiSqc4DZJYmISBvV6tdBEql2RWggE67oimHAa1vSzC5HREREAUlahweuciwc+d7uY5wpKTe5GhERae8UkKRVSOjTmYHhQZytsPH2jqNmlyMiIu2cApK0ChaLhVnjHQtHrtyWTlmlzeSKRESkPVNAklbjF0MjCAvy5WRhGWtTs8wuR0RE2jEFJGk1vD2tzBgbDcDyzWnoBksRETGLApK0KlNH9yTA24PDOYVs+v6U2eWIiEg7pYAkrUqwnxdTRvUEtHCkiIiYRwFJWp17x0ZjtcDm709xIKvA7HJERKQdUkCSVieykz8/HxIOwPItGkUSEZGWp4AkrdID4x0LR/7v11lk55eaXI2IiLQ3CkjSKsVEhjA6uhMVNoOV29LNLkdERNoZBSRpte6vWjjynR0ZFJdVmlyNiIi0JwpI0mpNGhhKry4BFJRW8t7uTLPLERGRdkQBSVotq9XCzHGOUaRXt6RRabObXJGIiLQXCkjSqt0+vAcd/b04dvosn32bY3Y5IiLSTiggSavm5+3B3fHRACzdfETbj4iISItQQJJWb3p8FN6eVr7OPMPujNNmlyMiIu2AApK0el06+HDbsO4ALNukhSNFRMT1FJDELVTf8r/hYA5pp4pNrkZERNq6JgWkzMxMjh075vx+586dzJ49m6VLlzZbYSLn69stkJ8N6IZhwKvafkRERFysSQHpV7/6Ff/5z38AyM7O5tprr2Xnzp388Y9/5M9//nOzFihSrXoU6f09xzhdXG5yNSIi0pY1KSDt37+f0aNHA/Dee+8xePBgtm3bxttvv83KlSubsz4Rp/jenRncPYjSCjtvbc8wuxwREWnDmhSQKioq8PHxAeDzzz/n5ptvBmDAgAGcOHGi+aoTOY/FYmFW1Sa2ryenU1phM7kiERFpq5oUkK688kqWLFnC5s2b2bBhA9dffz0AWVlZdO7cuVkLFDnfDUPCCQ/25VRROf9KPW52OSIi0kY1KSA988wzvPLKK0ycOJGpU6cSExMDwNq1a52X3kRcwcvDyn1jHXORlm1Ow27XwpEiItL8LEYTlya22WwUFBTQsWNH57H09HT8/f3p1q1bsxXYWhUUFBAcHEx+fj5BQUFml9OuFJRWkLDwC4rKKlkxYxRXD2j7/95ERKR5NPT3d5NGkM6ePUtZWZkzHGVkZPDSSy9x+PDhdhGOxFxBvl7cOSoSgGWbdcu/iIg0vyYFpFtuuYU33ngDgDNnzhAXF8fzzz9PUlISL7/8crMWKFKXe8f1wsNqYduPP7H/eL7Z5YiISBvTpICUkpLC+PHjAXj//fcJDQ0lIyODN954g7///e/NWqBIXbqH+HHjkHAAlmsUSUREmlmTAlJJSQmBgYEA/Pvf/+a2227DarUyZswYMjK0Po20jOpb/j/+5gQn8s+aXI2IiLQlTQpIffv2Zc2aNWRmZvLZZ59x3XXXAZCbm6sJy9JihvQIZkzvTlTaDVZuTTe7HBERaUOaFJCefPJJfvvb3xIdHc3o0aOJj48HHKNJw4YNa9YCRS6mehTpnR1HKSytMLkaERFpK5oUkO644w6OHj3K7t27+eyzz5zHr7nmGl588cVmK07kUq7u343eXQMoLKtk1a5Ms8sREZE2okkBCSAsLIxhw4aRlZXFsWPHABg9ejQDBgxotuJELsVqPbf9yIqt6VTa7CZXJCIibUGTApLdbufPf/4zwcHBREVFERUVRUhICE899RR2u35BScu6dVh3Ogd4c/zMWdbtzza7HBERaQOaFJD++Mc/smjRIp5++mn27t3L3r17+etf/8o//vEPnnjiieauUeSifL08uDs+CnDc8t/ExeFFREScmrTVSEREBEuWLOHmm2+ucfxf//oXv/nNbzh+vO1vIqqtRlqXn4rKSHj6C8oq7ax6YAxxvbVpsoiIXMilW43k5eXVOddowIAB5OXlNeUlRS5L5w4+3D6iB6DtR0RE5PI1KSDFxMSwaNGiC44vWrSIoUOHXnZRIk0xc1wvAD4/mMuPJ4tMrkZERNyZZ1NO+tvf/saNN97I559/7lwDKTk5mczMTNatW9esBYo0VJ+uHZg0MJTPD+bw6pY0/nrrELNLEhERN9WkEaQJEybw3Xffceutt3LmzBnOnDnDbbfdxrfffsubb77Z3DWKNNis8Y5RpA/2HOOnojKTqxEREXfVpEna9fn6668ZPnw4NputuV6y1dIk7dbJMAySFm/l62P5zJ7Uj9mTrjC7JBERaUVcOklbpLWyWCzcX7Vw5JvJGZRWtP2wLiIizU8BSdqcnw8Oo3uIHz8Vl/NhSttfckJERJqfApK0OZ4eVu6ruqNt+ZYj2O1aOFJERBqnUXex3XbbbRd9/syZM5dTi0izmTIqkpc+/44jJ4v54lAukwaFml2SiIi4kUYFpODg4Es+P3369MsqSKQ5dPDx5Feje/LKpiMs23xEAUlERBqlUQFpxYoVrqpDpNnNGBvNq1vS2JGWxzfHzjC0R4jZJYmIiJvQHCRps8KD/bgpJgKAZZvTTK5GRETciQKStGn3Vy0cuW7fCY6fOWtyNSIi4i4UkKRNuzIimLF9O2OzG6zYolEkERFpGAUkafOqF458d1cmBaUVJlcjIiLuQAFJ2ryJV3SlX7cOFJVV8u7Oo2aXIyIibkABSdo8i8XCrKpRpBVb06mw2U2uSEREWjvTA9LixYuJjo7G19eXuLg4du7cedH2q1evZsCAAfj6+jJkyBDWrVtX4/kPP/yQ6667js6dO2OxWEhNTa3zdZKTk/nZz35GQEAAQUFBXHXVVZw9q0m8bdUtwyLo0sGHE/mlfPLNCbPLERGRVs7UgLRq1SrmzJnD/PnzSUlJISYmhsTERHJzc+tsv23bNqZOncrMmTPZu3cvSUlJJCUlsX//fmeb4uJixo0bxzPPPFPv+yYnJ3P99ddz3XXXsXPnTnbt2sUjjzyC1Wp6XhQX8fH04J74KACWbT6CYWj7ERERqZ/FMPE3RVxcHKNGjWLRokUA2O12IiMjefTRR5k7d+4F7adMmUJxcTEff/yx89iYMWOIjY1lyZIlNdqmp6fTq1cv9u7dS2xsbI3nxowZw7XXXstTTz3V4FrLysooKytzfl9QUEBkZCT5+fkEBQU1+HXEPKeLy4l/eiOlFXbemRVHQp8uZpckIiItrKCggODg4Ev+/jZtyKS8vJw9e/YwadKkc8VYrUyaNInk5OQ6z0lOTq7RHiAxMbHe9nXJzc1lx44ddOvWjYSEBEJDQ5kwYQJbtmy56HkLFy4kODjY+YiMjGzwe0rr0DHAm1+OcHxuyzYdMbkaERFpzUwLSKdOncJmsxEaWnOPrNDQULKzs+s8Jzs7u1Ht63LkiOMX44IFC5g1axbr169n+PDhXHPNNXz//ff1njdv3jzy8/Odj8zMzAa/p7QeM8f1wmKB/xw+yQ+5hWaXIyIirVS7m3RjtzvuYHrwwQe59957GTZsGC+++CL9+/fntddeq/c8Hx8fgoKCajzE/UR3CeC6qo1rl2v7ERERqYdpAalLly54eHiQk5NT43hOTg5hYWF1nhMWFtao9nUJDw8HYNCgQTWODxw4kKNHtUZOe1B9y/+HKcc5WVh2idYiItIemRaQvL29GTFiBBs3bnQes9vtbNy4kfj4+DrPiY+Pr9EeYMOGDfW2r0t0dDQREREcPny4xvHvvvuOqKioRvRA3NWIqI7ERoZQbrPzZnK62eWIiEgrZOoltjlz5rBs2TJef/11Dh48yEMPPURxcTH33nsvANOnT2fevHnO9o899hjr16/n+eef59ChQyxYsIDdu3fzyCOPONvk5eWRmprKgQMHADh8+DCpqanOeUoWi4Xf/e53/P3vf+f999/nhx9+4IknnuDQoUPMnDmzBXsvZrFYLDxwlWMU6c3tGZwtt5lckYiItDaeZr75lClTOHnyJE8++STZ2dnExsayfv1650Tso0eP1libKCEhgXfeeYfHH3+cP/zhD/Tr1481a9YwePBgZ5u1a9c6AxbAnXfeCcD8+fNZsGABALNnz6a0tJT/+q//Ii8vj5iYGDZs2ECfPn1aoNfSGiReGUZkJz8y887yfsox7h6j0UMRETnH1HWQ3FlD11GQ1mvF1jT+9L8H6NUlgI1zJmC1WswuSUREXKzVr4MkYrbJIyMJ8vUk7VQxnx/MufQJIiLSbiggSbsV4OPJtDHnth8RERGppoAk7dqMhGi8PCzsSj9NauYZs8sREZFWQgFJ2rXQIF9ujukOaBRJRETOUUCSdu/+8b0A+HTfCTLzSkyuRkREWgMFJGn3BoYHMb5fF+wGvLZV24+IiIgCkghwbvuRVbsyyS+pMLkaERExmwKSCDC+XxcGhAVSUm7jnZ3ak09EpL1TQBLBsf3IzHGOuUgrt6VRXmk3uSIRETGTApJIlZtjI+gW6ENOQRkff5NldjkiImIiBSSRKj6eHtyTEA3A0k1H0C48IiLtlwKSyHmmxfXEz8uDQ9mFbP3hJ7PLERERkyggiZwnxN+bKaMiAS0cKSLSnikgidRy39heWC3w1XcnOZxdaHY5IiJiAgUkkVp6dvYn8cowAJZrFElEpF1SQBKpw6yrHAtH/is1i9yCUpOrERGRlqaAJFKH4T07MiKqI+U2O68np5tdjoiItDAFJJF6zKraxPat7UcpKa80uRoREWlJCkgi9bh2UBhRnf3JP1vB+3uOmV2OiIi0IAUkkXp4WM9tP7J8cxo2uxaOFBFpLxSQRC7ijhE9CPbz4mheCRsOZJtdjoiItBAFJJGL8Pf25O4xUQAs25xmcjUiItJSFJBELmF6QhTeHlb2ZJxmT8Zps8sREZEWoIDU2ux7H96/D3a/Bqe+B22Yarpugb7cEhsBaOFIEZH2wtPsAqSWw5/C/g8cD4AOoRA1FqLHQfR46NIPLBZza2yHZl3Vm9V7jvHZt9lk/FRMVOcAs0sSEREXUkBqbcY8BF2ugPTNkLkTinLg2w8dD4CAbhB9fmC6QoGpBVwRGsiEK7ry1XcneW1LGn+6ZbDZJYmIiAtZDEPXcJqioKCA4OBg8vPzCQoKcs2bVJTC8T2QsfVcYKqste1FQNfzRpjGQdcBCkwusuX7U9z16g78vDxInvczQvy9zS5JREQaqaG/vxWQmqhFAlJtlWVwPAXSt5wXmM7WbOPfxTHCFHVeYLJqqllzMAyDG/6+hYMnCvhdYn8evrqv2SWJiEgjKSC5mCkBqbbKcshKcYSl9C2OwFRRUrONf+daI0wDFZguw4cpx5jz3td0DfRhy++vxsfTw+ySRESkERSQXKxVBKTaKssha+95gWnHhYHJrxNEJTjmL0WPg26DFJgaobzSzvi/fUFOQRnP3jGUX46MNLskERFpBAUkF2uVAam2ynI4kXouMB3dARXFNdv4daw5wtTtSgWmS1jy1Y88/ekh+ocGsn72eCya8yUi4jYUkFzMLQJSbbYKyEo9LzBtvzAw+YbUDEyhgxWYask/W0HCwo0Ul9t4/b7RTLiiq9kliYhIAykguZhbBqTabBVw4uuqwLQVjiZDeVHNNr7BdQQmzbv50/9+y4qt6Yzv14U3Z8aZXY6IiDSQApKLtYmAVJut8lxgytgKGclQXlizjU9w1RymcY675cKGtsvAlJlXwoRn/4PdgE8fG8/A8Dbyb0BEpI1TQHKxNhmQarNVQvbXjtGl9C2OEaaygpptfIIhKv7cKFPYUPBoH+uPPvxOCp98c4LbhnfnhcmxZpcjIiINoIDkYu0iINVmq4Tsb6oWrtwCGdvqCExB0DP+3GrfYTFtNjClZp4hafFWvDwsbPn9zwgN8jW7JBERuQQFJBdrlwGpNrsNsvdVLVxZHZjya7bxDoSeY85tjRLetgLT5CXJ7EzP46GJffj99QPMLkdERC5BAcnFFJDqYLdBzv7zAtNWKK0dmDrUEZi8zKm3Gfz722weeHMPQb6eJM+7hgCfthP+RETaIgUkF1NAagC7DXK+rRWYztRs490BIuPOBaaIWLcKTHa7wTUvfEXaqWLm3zSIe8f2MrskERG5CAUkF1NAagK7HXJrBaazp2u28QqAnucHpmGtPjC9tT2Dx9fsJ7KTH//5PxPx9NC6USIirZUCkospIDUDux1yD1SFpS2Ou+XO5tVs4+V/3gjTOIgYDp7e5tRbj7PlNhKe3sjpkgoW/2o4Nw4NN7skERGphwKSiykguYDdDicPnhthSt9yYWDy9Ds3whQ1DrqPaBWB6YV/H+bvX/xAbGQIH/0mQduPiIi0UgpILqaA1ALsdjh56LwRpi1Q8lPNNp5+EDn63AhT9xHg6dPipZ4sLGPsM19QXmnn/V/HMzK6U4vXICIil9bQ39+65UZaL6sVQgc5HnEPgGGcC0zVj5JTkPaV4wHg6esITFFVganHyBYJTF0DfbhtWHfe3ZXJ0k1HFJBERNycRpCaSCNIrYBhwMnD50aX0rdA8cmabTx9oceo80aYRoKXaxZ0/CG3kEkvbMJigS/+z0R6dQlwyfuIiEjT6RKbiykgtUKGAae+r9p8tzow5dZs4+FTMzD1GNWsgem+lbv44lAud43pyf9LGtJsrysiIs1DAcnFFJDcgGHATz/UDExFOTXbeHjXEZj8mvyW2348xa+W7cDXy8ofbhjIHSN64O+tK9kiIq2FApKLKSC5IcOAn36sFZiya7bx8HZchose59hPrsdo8PZvxFsY3Ll0OzvSHHffhfh7cVdcFNMTougWqL3aRETMpoDkYgpIbYBhQN6RmoGp8ETNNlYvx0Tv6HEQNdaxJtMlAtPZchvv7c7k1S1pHM0rAcDbw0rSsAjuH9+bK0IDXdUjERG5BAUkF1NAaoOcgalqle+0zVCYVbON1cuxlED0WEdoiowD77onY9vsBv/+Nptlm4+QcvSM8/jE/l2ZNb43CX06a70kEZEWpoDkYgpI7YBhwOm0qtGlrY6RpoLjNdtYPR2BKeq8wOTT4YKX2pORx7JNaXx2IJvqn7hB4UHcP74XvxgagbenticREWkJCkgupoDUDhkGnE53jC6lb3GMMBUcq9nG6unYP67Pz2D4dAjuUePp9FPFvLY1jdW7j3G2wgZAWJAvM8ZGM3V0T4L9Wve+cyIi7k4BycUUkATDgDMZVaNLWxwjTPmZ5563eMCVSTDmYegxosapZ0rKeXvHUVZuS+dkYRkAAd4eTBnVk3vHRhPZqeETw0VEpOEUkFxMAUnqdDrDEZZS33EsYFmtx2iI/w0MuAk8zt32X1Zp41+pWSzffITvcooAsFrghiHhzBrfm5jIkBbugIhI29bQ39+tYuLD4sWLiY6OxtfXl7i4OHbu3HnR9qtXr2bAgAH4+voyZMgQ1q1bV+P5Dz/8kOuuu47OnR2TYFNTU+t9LcMw+PnPf47FYmHNmjXN0Btp1zpGwbBpcO8n8OAmiJnqmNh9bCesngF/j4Wtf4ezZwDw8fRg8shIPpt9Fa/fN5pxfbtgN+Djb05wy+KtTF6SzIYDOdjt+v8YEZGWZHpAWrVqFXPmzGH+/PmkpKQQExNDYmIiubm5dbbftm0bU6dOZebMmezdu5ekpCSSkpLYv3+/s01xcTHjxo3jmWeeueT7v/TSS7qTSFwjPAZuXQL/9S1c9X/Bv7PjEtyGJ+CFQbDud451mQCLxcKEK7ry1v1xrPv/xnPbsO54Wi3sTM9j1hu7mfTCV7y1PYPSqnlLIiLiWqZfYouLi2PUqFEsWrQIALvdTmRkJI8++ihz5869oP2UKVMoLi7m448/dh4bM2YMsbGxLFmypEbb9PR0evXqxd69e4mNjb3gtVJTU/nFL37B7t27CQ8P56OPPiIpKalBdesSmzRaRSnsew+2vwy5B6oOWuCK62HMQ9DrKjgvrGfnl7JyWzpv78igsLQSgE4B3tw1Jorp8VF06eD6TXhFRNoat7jEVl5ezp49e5g0aZLzmNVqZdKkSSQnJ9d5TnJyco32AImJifW2r09JSQm/+tWvWLx4MWFhYZdsX1ZWRkFBQY2HSKN4+TrubHtoG9y9BvpdBxjw3afwxs2wZBzsfcsRpICwYF/m/nwAyfOu4clfDKJ7iB95xeX8feP3JDz9BfM+/IYfcotM7ZKISFtlakA6deoUNpuN0NDQGsdDQ0PJzs6u85zs7OxGta/Pf/3Xf5GQkMAtt9zSoPYLFy4kODjY+YiMjGzU+4k4WSzQ52qYthoe2Q2j7gcvf8jZD/96GF4aDF8+DUWOy8wdfDy5b1wvvvrdRBb9ahgxPYIpr7Tzz52ZTHrhK2au3EXyjz+h+y1ERJqP6XOQzLB27Vq++OILXnrppQafM2/ePPLz852PzMzMS58kcild+sGNzzvmKU1aAEHdofgkfLkQXrwS1jwM2fsA8PSw8ouhEax5eCzvPRjPtYNCsVhg46Fcpi7bzk2LtvCv1ONU2Ozm9klEpA0wNSB16dIFDw8PcnJq7rCek5NT72WvsLCwRrWvyxdffMGPP/5ISEgInp6eeHo6bru+/fbbmThxYp3n+Pj4EBQUVOMh0mz8O8G4/4LHvobbX3Wszm0rh9S3HJfeVv4CDn8KdjsWi4XRvTqxbPpINs6ZwLS4nvh4Wtl/vIDH3k1lwt/+w/LNRygsrTC7VyIibsvUgOTt7c2IESPYuHGj85jdbmfjxo3Ex8fXeU58fHyN9gAbNmyot31d5s6dyzfffENqaqrzAfDiiy+yYsWKxndEpLl4eMGQO2DWFzBzA1x5q2PByfTN8M87YdEI2LEUyhxzj3p37cBfbh1C8rxrmHPtFXTp4E1Wfin/75ODJCz8gr98coCsM2dN7pSIiPsx/S62VatWcc899/DKK68wevRoXnrpJd577z0OHTpEaGgo06dPp3v37ixcuBBw3OY/YcIEnn76aW688Ubeffdd/vrXv5KSksLgwYMByMvL4+jRo2RlZTnb9O/fn7CwsHpHmiwWi+5ik9bpTCbsXAp7XoeyfMcxn2AYMR1GPwgh5+bDlVbYWLP3OMu3pDkncHtaLdw41LHw5ODuwWb0QESk1XCrlbQXLVrEs88+S3Z2NrGxsfz9738nLi4OgIkTJxIdHc3KlSud7VevXs3jjz9Oeno6/fr1429/+xs33HCD8/mVK1dy7733XvA+8+fPZ8GCBXXWoIAkrV5ZEXz9T8cyAXmO9ZOweMDAmyD+YYgc7Wxqtxt8+V0uyzalkXzkJ+fx+N6dmXVVLyZe0Q2rVet/iUj741YByR0pIIlp7Hb4/t+wfTGkbTp3vPtIx3pKg25xXKqrsv94Pss2H+Hjb05gq1qRu2+3Dtw/rhdJw7rj6+XR0j0QETGNApKLKSBJq5C93zGitO89x6RucNwJN3oWDL/HMfm7yvEzZ1m5NY1/7sykqMyx8GSXDt5Mj4/mrjFRdArwNqMHIiItSgHJxRSQpFUpyoXdr8Gu5Y5lAsCxtlLMVMeoUpd+zqaFpRWs2pXJa1vSyMp3LErp62Xl9uE9mDmuF727djCjByIiLUIBycUUkKRVqiiF/R/A9v9xLDxZrd91MOY30HuiczuTCpuddftOsGzzEfYfd6wMb7HApIGhzBrfm1HRHbVPoYi0OQpILqaAJK2aYTiWBkj+H/huPVD1Y95tkGNEacgvwcuvqqnB9iN5LN98hI2Hzm0SHRMZwqzxvbj+yjA8PdrlmrIi0gYpILmYApK4jZ9+hB1LYO/bUFHsOObfGUbOdGxzEnhu654fcot4dcsRPkg5TnmlY0XuHh39uG9sLyaPiqSDj6cZPRARaTYKSC6mgCRu5+wZSHnDsaZSftVWOdaqhSnHPAThMc6mp4rKeDM5gze3Z5BX7Jj8HejrybS4KGYkRBMW7GtCB0RELp8CkospIInbslXCof913P2WuePc8ahxjqDU/+dgddz6X1ph44OUY7y6OY0jpxyjT55WCzfHRHD/+N4MitC/fRFxLwpILqaAJG3CsT2O9ZS+XQOGzXGsYy+I+zUMmwY+gYBj4cmNh3JZtvkIO9PynKeP69uF+8f3YsIVXTWhW0TcggKSiykgSZuSfxx2LYPdK6D0jOOYTxAMnw6jH4COUc6mX2eeYdnmI3y6P9u58GT/0EBmju/FLbER+Hhq4UkRab0UkFxMAUnapPJi+Ppdx+W3n753HLNYYcAvHMsE9BzjXCYgM6+EFVvTWbXrKMXljtGnroE+zEiIZlpcT0L8tfCkiLQ+CkgupoAkbZrdDj9uhOTFcOQ/545HDHMEpUFJ4OkIQPlnK3h351FWbE0nu8Cx8KSflweTR/bgvnG9iOocYEIHRETqpoDkYgpI0m7kHIAdL8PXq8BW5jgWGO7YzmTEvc7tTMor7XyyL4tlm9I4cOLcwpOJg8KYdVVvRkR1NKsHIiJOCkgupoAk7U7xKcccpV3LoCjHcczTD2KmOEaVuvYHHAtPbvvxJ5ZtPsKXh086Tx/eM4QHrurNtYPC8LBqQreImEMBycUUkKTdqiyDbz9yXH7L/ubc8b6THMsE9LnGOU/pu5xClm8+wpq9WZTbHAtPRnX2576xvfjlyB74e2vhSRFpWQpILqaAJO2eYUDGNse+b4c+wbmdSZf+jqAUc6dzO5PcwlLnwpNnSioACPbz4q4xPbknPppuQVp4UkRahgKSiykgiZwnLw12vAJ734TyIscxv04w8l4YNQuCwgEoKa/kgz3HWL4ljYyfSgDw9rByS6xj4cn+YYFm9UBE2gkFJBdTQBKpQ2k+7H3LsffbmaOOY1ZPuPI2iP+N4y44wGY32HAgh+Wbj7A747Tz9AlXdGXW+N6M7dtZC0+KiEsoILmYApLIRdhtjstu2/8HjiafO94z3jGhe8CNzu1MUo6eZvnmI6zfn03VupMMDA/i/nG9uCkmAm9PqwkdEJG2SgHJxRSQRBroeIpjRGn/B2CvdBwL6Vm1ncnd4Ov4+Tn6UwmvbU3jvd2ZlFQtPBka5MOMhF78Kq4nwX5eZvVARNoQBSQXU0ASaaSCE1XbmbwGZ6suq3kHwrC7IO5B6NQLgPySCt7emcHKrenkFjrWXfL39mDKqEjuG9uLyE7+ZvVARNoABSQXU0ASaaLyEvhmlWM7k1OHqw5aHJfdxvwGohLAYqG80s7ar7NYvvkIh7ILAbBa4OdDwpk1vjexkSGmdUFE3JcCkospIIlcJsNwbGey/WX44fNzx8OGQvzDjondnt4YhsHm70+xbPMRNn9/ytlsVHRHZo3vzaSBoVi18KSINJACkospIIk0o9xDjnlKX78LlWcdxzqEOpYIGHkvBHQB4OCJApZvTmPt18epsDn+09WrSwAzx/Xi9uE98PP2MKsHIuImFJBcTAFJxAVK8mDPCti5DApPOI55+sLQyRD3EIQOAiCnoJSV29J5e3sGBaWOid8d/b24e0wUd8dH0zXQx6weiEgrp4DkYgpIIi5UWQ4H/gXbF0PW3nPHe1/tuPzW5xqwWikuq2T17kxe3ZpGZp5j5Mnb08ptw7pz//he9O2mhSdFpCYFJBdTQBJpAYYBmTsc+74d+hgMx35udLnCsUxAzJ3gHYDNbvDZt9ks3XSE1MwzztN/NqAb94/vRXxvLTwpIg4KSC6mgCTSwk5nwM6lkPIGlBU4jvmGnNvOJLg7hmGwJ+M0yzYf4d8Hcqj+r9vg7kHMGt+bG4aE4+WhhSdF2jMFJBdTQBIxSVkh7H0bdrwMp9Mdx6yeMCjJsUxAjxEApJ0q5rUtaazek0lphWPkKSLYl3vH9mLK6EiCfLXwpEh7pIDkYgpIIiaz2+C79ZD8P5Cx5dzxyDgY8xAMuAk8PDldXM7bOzJYuS2DU0WOhSc7+Hhy56hI7h3Xi+4hfiZ1QETMoIDkYgpIIq3Iia8d6yntex/sFY5jwZEw+gEYPh38QiitsLE2NYtlm4/wfW4RAB5WCzdWLTw5pEewiR0QkZaigORiCkgirVBhDuxaDrtfhZKfHMe8As5tZ9K5D4Zh8OV3J1m++Qhbf/jJeeqY3p2YNb43V/fvpoUnRdowBSQXU0ASacUqSmHfe45RpdwDVQctcMX1EP8biB4PFgvfZuWzfHMa//t1FpV2x38K+3QN4P7xvUmK7a6FJ0XaIAUkF1NAEnEDhgFHvoTt/wPf//vc8dAhjnlKQ+4ATx9O5J9l5dZ03tlxlMIyx8KTVgv07tqBgeFBDAwPZFB4EIPCg+ga6KMlA0TcmAKSiykgibiZU987tjNJfQcqShzHArrCqPth5Ezo0JWiskpW7cpk5bZzC0/W1jnAm0ERQc7gNDA8iD5dO2j5gOZkGGCvBFuFY06ZraJhX9srwVbu+NqwgX9nCOoOQRHgHWB2r6SVUEByMQUkETdVkgcprzu2Myk47jjm4Q1DJjtGlcIGYxgGJwvLOHCigAMnCjh4opCDJwo4crIIex3/xfT2sNIvtHq0Kcg52hTsb9JSAnZ7VWgoPy84VH1f19fOtpV1fH2xQFL7WFVAqevrxrxH9UT75uQbDEE9HGEpKMIRnIK7n/s6KAJ8tPJ6e6CA5GIKSCJuzlZRtZ3J/8DxPeeO97oKxjzs+LPWL/qysjLSck6TnptPxskzHD1ZQNZPBZRXlOGFDS8q8cSGFzY8qaSrv4UeQV50D/YivIOV0ABPQnzAalReIoTUDi+NDCTVK463JRYPR5D18HKse+Xh5fi+rq+tXmCxQvFJRwguL2rYe/gEnxegIiC4VqAK6g6++u+9u1NAcjEFJJE2JHOnIygdWOu4NNMWWatChIdn1dde58JE7a8v9bzza8+qYFL76+oQ413P1171nOdZR51Vwcd6GZcwSwugIAsKjlX9meUITvnHz31flt+w1/IOPC9AdT83+hR03te+waB5aq2WApKLKSCJtEFnMqu2M3kdSs/7hWmx1v2L+yJhoxJPCiugoBzOlEFeqUHeWYNSuwcVeFCJB5V4Ul71Z6C/H52CAuga3IFuIR0I6xhIcAd/LM6RkUuFjTqChzNgeOgX9qWUFZ4LTnWGqONQeqZhr+UVUEeAqhWi/DrqMzGJApKLKSCJtGG2Sqg8e95oSPPc7l9ps5P+UzEHThRyIKuAgyccj9zCsjrbh/h7MTDs3ITwQRFB9O3WAR9PLT9givLiWiGq1ihUwXE4m9ew1/L0qydE9TgXpvw7KUS5gAKSiykgiUhzOVVU5gxL1RPCf8gtcq7NdD5Pq4W+3To4J4NXh6fOHXxMqFwuUF4ChSfOhaj8Wpf1Co6fW8T0Ujx9a04irz0KFdQdArooRDWSApKLKSCJiCuVVdr4PqeIg8476RzhKf9s3Xd4dQv0OW/5gSAGhQfSq0sHPLQqeOtTUQqFVaEp/3ity3pVgar4ZMNey8O7VoiqNSIV3AP8u1zeHK42RgHJxRSQRKSlGYbBifzSc5fnsh2hKf2nYur6L7mvl5X+oY61mqrD04CwQAJ9TVp+QBqusqxqJKp2iDrv66JcoAG/wq1eEBR+4ejT+Zf4Aro226Xk1k4BycUUkESktSguq+RQdmGN0abD2YWUlNd9R15kJ7/zLs85LtX16OinFcLdTWU5FGXXPwpVkAWF2TQsRHlCYHgdo1HnLXfQIbRNhCgFJBdTQBKR1sxuN8jIK6kxGfzgiQKy8kvrbB/o61k1ITzQOdp0RWggvl7u/wuxXbNVOEJS7cnl5weqwhMNWzvL4gGBYfWPQgVFQIcwxx2UrZgCkospIImIOzpdXO68NFcdnn7ILaLcduEvyOr96M6fDK796NogWyUU5dQRno6fu8RXeKJha4RZrI6QdLEVywPDHXeHmkQBycUUkESkraiw2fnxZNF5o02FHDhRQF5xeZ3tu3Twdl6ec4SmYHp3DdB+dG2Z3eaY81QjRJ03CpV/3DHx3F7ZgBezOC7XXRCizptcHhgBnt4u6YoCkospIIlIW2YYBrlV+9E5Q1NWPmmnii+6H13tuU2m7UcnLc9uP7e9S12jUNVfN3SvvYBucM2TMPzuZi2zob+/W/eFQhERMYXFYiE0yJfQIF+u7t/NefxsuY3vcgrPC06O8FRUVsm3WQV8m1VQ43W6h/gxMDywRmjq2ckfq5YfaHusVggMdTy6D6+7jd3uWAeq3m1fqv60lUFxrqmX4jSC1EQaQRIRcbDbDY6dPusMTdV/Hjt9ts72Ad4e9A+7cPkBf2/9P7sAhgEleY4QFdQDAjo368vrEpuLKSCJiFxcQWkFh6ouzR08UcjBbMfyA2WVF04It1ggunNA1SW6c+EpLMhXE8KlWSkguZgCkohI41Xa7KSdKq4aZTq3dtPJBuxH5xhtCqRft0C8PTUhXJpGAcnFFJBERJpP9X50599J98PJImwX2Y/u/Anh2o9OGkoBycUUkEREXKu0wsYPuUU1JoQfyCqgoLTuW8lDg3zOC0xB9OocQGQnP4L9vHSZTpwUkFxMAUlEpOUZhkFWfikHswpqBKf0n0rqPaeDjyc9OvpVPfxr/BnZ0Z8gP08FqHZEAcnFFJBERFqPorJKDmcXcKBqXtOhEwVknj5b79ym8wX6eNKjk/8FISqyoz89OvkRpM192xS3CkiLFy/m2WefJTs7m5iYGP7xj38wevToetuvXr2aJ554gvT0dPr168czzzzDDTfc4Hz+ww8/ZMmSJezZs4e8vDz27t1LbGys8/m8vDzmz5/Pv//9b44ePUrXrl1JSkriqaeeIjg4uEE1KyCJiLR+pRU2jp85y7HTZ8nMK+HY6bMcO13951lOFV06QAX5etYYeYrsdP5IlB+BClBuxW0Wily1ahVz5sxhyZIlxMXF8dJLL5GYmMjhw4fp1q3bBe23bdvG1KlTWbhwIb/4xS945513SEpKIiUlhcGDBwNQXFzMuHHjmDx5MrNmzbrgNbKyssjKyuK5555j0KBBZGRk8Otf/5qsrCzef/99l/dZRERahq+XB326dqBP1w51Pn+23MbxMyVkVgWmY6dLOJZ3LkT9VFxOQWklB6rutqtLiL+XIyyFnAtNkZ38nSEqwMf0X7XSBKaPIMXFxTFq1CgWLVoEgN1uJzIykkcffZS5c+de0H7KlCkUFxfz8ccfO4+NGTOG2NhYlixZUqNteno6vXr1umAEqS6rV6/mrrvuori4GE/PC/8xl5WVUVZ27v80CgoKiIyM1AiSiEgbVlJeyfHTZ8k8b9SpOjxl5pVwuuTS22Z09Peqc+Sp+mstkNmy3GIEqby8nD179jBv3jznMavVyqRJk0hOTq7znOTkZObMmVPjWGJiImvWrLmsWqr/ouoKRwALFy7kT3/602W9h4iIuBd/b0/6hQbSLzSwzueLyhwB6vzQdOz0WY6dcfx5pqSC0yUVnC7JZ9/x/Dpfo3OAd60J5H706ORPZEc/uof44+ft4couSj1MDUinTp3CZrMRGhpa43hoaCiHDh2q85zs7Ow622dnZ19WHU899RQPPPBAvW3mzZtXI5hVjyCJiEj71cHHk/5hgfQPqztAFZZWXDDydOx0CZlVl/EKSiv5qbicn4rL+fpY3QGqSwfvC+6+q76M1z3ED18vBShXaPfjegUFBdx4440MGjSIBQsW1NvOx8cHHx8tQiYiIg0X6OvFwHAvBobXfSkn/2yFcwQqs9YE8mN5JRSWVXKqqJxTReWkZp6p8zW6BvpcePddVYiKUIBqMlMDUpcuXfDw8CAnJ6fG8ZycHMLCwuo8JywsrFHtL6awsJDrr7+ewMBAPvroI7y8dCeCiIi0nGA/L4L9vBgUUU+AKqk4b/5TyQVzoIrLbZwsLONkYRl7j56p8zW6BfpUTRq/cBmD8BBffDwVoOpiakDy9vZmxIgRbNy4kaSkJMAxSXvjxo088sgjdZ4THx/Pxo0bmT17tvPYhg0biI+Pb9R7FxQUkJiYiI+PD2vXrsXX17ep3RAREXGJYH8vgv2DGdz9wiVoDMMg/2xFvUsYZJ4uoaTcRm5hGbmFZezJOH3Ba1gsEBroW+vuu3MhKjzYr93ue2f6JbY5c+Zwzz33MHLkSEaPHs1LL71EcXEx9957LwDTp0+ne/fuLFy4EIDHHnuMCRMm8Pzzz3PjjTfy7rvvsnv3bpYuXep8zby8PI4ePUpWVhYAhw8fBhyjT2FhYRQUFHDddddRUlLCW2+9RUFBAQUFjts3u3btioeH0rSIiLRuFouFEH9vQvy96w1Qp0sq6pz7VB2izlbYyC4oJbuglN11BCirBcKCfC+8+66TYwQqLNgXL4+2GaBMD0hTpkzh5MmTPPnkk2RnZxMbG8v69eudE7GPHj2K1XruLz8hIYF33nmHxx9/nD/84Q/069ePNWvWONdAAli7dq0zYAHceeedAMyfP58FCxaQkpLCjh07AOjbt2+NetLS0oiOjnZVd0VERFqExWKhU4A3nQK8Gdoj5ILnDcMgr7i81tynmnfjlVXaycovJSu/lJ3pF76H1QLhwX50rzX36dwIlC+ebhqgTF8HyV1pJW0REWnLDMPgVFH5udBUx1pQ5ZX2i76Gh9VCeLBv3ZPIO/kTFuSLh7Vl98Fzi3WQREREpHWyWCx0DfSha6APw3p2vOB5u93gVFHZhXffVX19/PRZym1253HIu+A1PK0WwkN8zxt9qrmlS7fAlg9QztpMeVcRERFxa1arhW5BvnQL8mVEVN0B6mRRWZ1zn46dLuH4mbNU2Awy886SmXe2zveY9/MBPDihj6u7UicFJBEREWl2VquF0CBfQoN8GRF14fM2u0FuYWmNPfDOv4yXdeYsPTr6t3zhVRSQREREpMU55ic5lhIYFd3pgudtdgO7idOkFZBERESk1fGwWvDAnPlHAO55752IiIiICykgiYiIiNSigCQiIiJSiwKSiIiISC0KSCIiIiK1KCCJiIiI1KKAJCIiIlKLApKIiIhILQpIIiIiIrUoIImIiIjUooAkIiIiUosCkoiIiEgtCkgiIiIitXiaXYC7MgwDgIKCApMrERERkYaq/r1d/Xu8PgpITVRYWAhAZGSkyZWIiIhIYxUWFhIcHFzv8xbjUhFK6mS328nKyiIwMBCLxdJsr1tQUEBkZCSZmZkEBQU12+u2Jm29j229f9D2+6j+ub+23kf1r+kMw6CwsJCIiAis1vpnGmkEqYmsVis9evRw2esHBQW1yX/052vrfWzr/YO230f1z/219T6qf01zsZGjapqkLSIiIlKLApKIiIhILQpIrYyPjw/z58/Hx8fH7FJcpq33sa33D9p+H9U/99fW+6j+uZ4maYuIiIjUohEkERERkVoUkERERERqUUASERERqUUBSURERKQWBSQTLF68mOjoaHx9fYmLi2Pnzp0Xbb969WoGDBiAr68vQ4YMYd26dS1UadM1po8rV67EYrHUePj6+rZgtY2zadMmbrrpJiIiIrBYLKxZs+aS53z55ZcMHz4cHx8f+vbty8qVK11eZ1M1tn9ffvnlBZ+fxWIhOzu7ZQpupIULFzJq1CgCAwPp1q0bSUlJHD58+JLnucvPYVP6524/gy+//DJDhw51LiIYHx/Pp59+etFz3OXzg8b3z90+v9qefvppLBYLs2fPvmi7lv4MFZBa2KpVq5gzZw7z588nJSWFmJgYEhMTyc3NrbP9tm3bmDp1KjNnzmTv3r0kJSWRlJTE/v37W7jyhmtsH8GxWuqJEyecj4yMjBasuHGKi4uJiYlh8eLFDWqflpbGjTfeyNVXX01qaiqzZ8/m/vvv57PPPnNxpU3T2P5VO3z4cI3PsFu3bi6q8PJ89dVXPPzww2zfvp0NGzZQUVHBddddR3Fxcb3nuNPPYVP6B+71M9ijRw+efvpp9uzZw+7du/nZz37GLbfcwrfffltne3f6/KDx/QP3+vzOt2vXLl555RWGDh160XamfIaGtKjRo0cbDz/8sPN7m81mREREGAsXLqyz/eTJk40bb7yxxrG4uDjjwQcfdGmdl6OxfVyxYoURHBzcQtU1L8D46KOPLtrm//7f/2tceeWVNY5NmTLFSExMdGFlzaMh/fvPf/5jAMbp06dbpKbmlpubawDGV199VW8bd/w5rNaQ/rnzz2C1jh07GsuXL6/zOXf+/KpdrH/u+vkVFhYa/fr1MzZs2GBMmDDBeOyxx+pta8ZnqBGkFlReXs6ePXuYNGmS85jVamXSpEkkJyfXeU5ycnKN9gCJiYn1tjdbU/oIUFRURFRUFJGRkZf8PyV3426fYVPFxsYSHh7Otddey9atW80up8Hy8/MB6NSpU71t3PkzbEj/wH1/Bm02G++++y7FxcXEx8fX2cadP7+G9A/c8/N7+OGHufHGGy/4bOpixmeogNSCTp06hc1mIzQ0tMbx0NDQeudrZGdnN6q92ZrSx/79+/Paa6/xr3/9i7feegu73U5CQgLHjh1riZJdrr7PsKCggLNnz5pUVfMJDw9nyZIlfPDBB3zwwQdERkYyceJEUlJSzC7tkux2O7Nnz2bs2LEMHjy43nbu9nNYraH9c8efwX379tGhQwd8fHz49a9/zUcffcSgQYPqbOuOn19j+ueOn9+7775LSkoKCxcubFB7Mz5DT5e9skgDxcfH1/g/o4SEBAYOHMgrr7zCU089ZWJl0hD9+/enf//+zu8TEhL48ccfefHFF3nzzTdNrOzSHn74Yfbv38+WLVvMLsUlGto/d/wZ7N+/P6mpqeTn5/P+++9zzz338NVXX9UbItxNY/rnbp9fZmYmjz32GBs2bGjVk8kVkFpQly5d8PDwICcnp8bxnJwcwsLC6jwnLCysUe3N1pQ+1ubl5cWwYcP44YcfXFFii6vvMwwKCsLPz8+kqlxr9OjRrT50PPLII3z88cds2rSJHj16XLStu/0cQuP6V5s7/Ax6e3vTt29fAEaMGMGuXbv47//+b1555ZUL2rrj59eY/tXW2j+/PXv2kJuby/Dhw53HbDYbmzZtYtGiRZSVleHh4VHjHDM+Q11ia0He3t6MGDGCjRs3Oo/Z7XY2btxY77Xl+Pj4Gu0BNmzYcNFr0WZqSh9rs9ls7Nu3j/DwcFeV2aLc7TNsDqmpqa328zMMg0ceeYSPPvqIL774gl69el3yHHf6DJvSv9rc8WfQbrdTVlZW53Pu9PnV52L9q621f37XXHMN+/btIzU11fkYOXIk06ZNIzU19YJwBCZ9hi6b/i11evfddw0fHx9j5cqVxoEDB4wHHnjACAkJMbKzsw3DMIy7777bmDt3rrP91q1bDU9PT+O5554zDh48aMyfP9/w8vIy9u3bZ1YXLqmxffzTn/5kfPbZZ8aPP/5o7Nmzx7jzzjsNX19f49tvvzWrCxdVWFho7N2719i7d68BGC+88IKxd+9eIyMjwzAMw5g7d65x9913O9sfOXLE8Pf3N373u98ZBw8eNBYvXmx4eHgY69evN6sLF9XY/r344ovGmjVrjO+//97Yt2+f8dhjjxlWq9X4/PPPzerCRT300ENGcHCw8eWXXxonTpxwPkpKSpxt3PnnsCn9c7efwblz5xpfffWVkZaWZnzzzTfG3LlzDYvFYvz73/82DMO9Pz/DaHz/3O3zq0vtu9haw2eogGSCf/zjH0bPnj0Nb29vY/To0cb27dudz02YMMG45557arR/7733jCuuuMLw9vY2rrzySuOTTz5p4YobrzF9nD17trNtaGioccMNNxgpKSkmVN0w1be1135U9+mee+4xJkyYcME5sbGxhre3t9G7d29jxYoVLV53QzW2f88884zRp08fw9fX1+jUqZMxceJE44svvjCn+Aaoq29Ajc/EnX8Om9I/d/sZvO+++4yoqCjD29vb6Nq1q3HNNdc4w4NhuPfnZxiN75+7fX51qR2QWsNnaDEMw3Dd+JSIiIiI+9EcJBEREZFaFJBEREREalFAEhEREalFAUlERESkFgUkERERkVoUkERERERqUUASERERqUUBSURERKQWBSQRkWZisVhYs2aN2WWISDNQQBKRNmHGjBlYLJYLHtdff73ZpYmIG/I0uwARkeZy/fXXs2LFihrHfHx8TKpGRNyZRpBEpM3w8fEhLCysxqNjx46A4/LXyy+/zM9//nP8/Pzo3bs377//fo3z9+3bx89+9jP8/Pzo3LkzDzzwAEVFRTXavPbaa1x55ZX4+PgQHh7OI488UuP5U6dOceutt+Lv70+/fv1Yu3atazstIi6hgCQi7cYTTzzB7bffztdff820adO48847OXjwIADFxcUkJibSsWNHdu3axerVq/n8889rBKCXX36Zhx9+mAceeIB9+/axdu1a+vbtW+M9/vSnPzF58mS++eYbbrjhBqZNm0ZeXl6L9lNEmoEhItIG3HPPPYaHh4cREBBQ4/GXv/zFMAzDAIxf//rXNc6Ji4szHnroIcMwDGPp0qVGx44djaKiIufzn3zyiWG1Wo3s7GzDMAwjIiLC+OMf/1hvDYDx+OOPO78vKioyAOPTTz9ttn6KSMvQHCQRaTOuvvpqXn755RrHOnXq5Pw6Pj6+xnPx8fGkpqYCcPDgQWJiYggICHA+P3bsWOx2O4cPH8ZisZCVlcU111xz0RqGDh3q/DogIICgoCByc3Ob2iURMYkCkoi0GQEBARdc8moufn5+DWrn5eVV43uLxYLdbndFSSLiQpqDJCLtxvbt2y/4fuDAgQAMHDiQr7/+muLiYufzW7duxWq10r9/fwIDA4mOjmbjxo0tWrOImEMjSCLSZpSVlZGdnV3jmKenJ126dAFg9erVjBw5knHjxvH222+zc+dOXn31VQCmTZvG/Pnzueeee1iwYAEnT57k0Ucf5e677yY0NBSABQsW8Otf/5pu3brx85//nMLCQrZu3cqjjz7ash0VEZdTQBKRNmP9+vWEh4fXONa/f38OHToEOO4we/fdd/nNb35DeHg4//znPxk0aBAA/v7+fPbZZzz22GOMGjUKf39/br/9dl544QXna91zzz2Ulpby4osv8tvf/pYuXbpwxx13tFwHRaTFWAzDMMwuQkTE1SwWCx999BFJSUlmlyIibkBzkERERERqUUASERERqUVzkESkXdBsAhFpDI0giYiIiNSigCQiIiJSiwKSiIiISC0KSCIiIiK1KCCJiIiI1KKAJCIiIlKLApKIiIhILQpIIiIiIrX8/7wZCsv9BJoNAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "fig, ax  = plt.subplots()\n",
        "ax.plot(train_losses, label='Train')\n",
        "ax.plot(val_losses, label='Val')\n",
        "ax.set(xlabel='Epoch', ylabel='Loss')\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "37efbb5e22684840aa988c0e23663136": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b0676ddb2f74f5e99fda5eb02efc9c8",
            "placeholder": "​",
            "style": "IPY_MODEL_e767c44bb5a646f9974615703e6ecdda",
            "value": " 160M/160M [00:01&lt;00:00, 155MB/s]"
          }
        },
        "4828f836fb2642f6bafd14ba7b69ae49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b0676ddb2f74f5e99fda5eb02efc9c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53087f1045234fe6bc49e467e9f85f50": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aaa04e028f34953b34a9a8905c99748": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96e5f4f0756d4c699dcb30b5fdf9ec3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d85d0d132b6f416bbef04badf3ea995f",
              "IPY_MODEL_bdfe4cb80a714243bfd74c69cc64be0b",
              "IPY_MODEL_37efbb5e22684840aa988c0e23663136"
            ],
            "layout": "IPY_MODEL_53087f1045234fe6bc49e467e9f85f50"
          }
        },
        "ae54e59833114fb8b4ea13126bc25a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdfe4cb80a714243bfd74c69cc64be0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4828f836fb2642f6bafd14ba7b69ae49",
            "max": 167502836,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae54e59833114fb8b4ea13126bc25a1b",
            "value": 167502836
          }
        },
        "d85d0d132b6f416bbef04badf3ea995f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aaa04e028f34953b34a9a8905c99748",
            "placeholder": "​",
            "style": "IPY_MODEL_fbdc947106b340f28128429aa79e1c2b",
            "value": "100%"
          }
        },
        "e767c44bb5a646f9974615703e6ecdda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbdc947106b340f28128429aa79e1c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
