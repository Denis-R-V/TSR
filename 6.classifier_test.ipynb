{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Denis-R-V/TSR/blob/main/sign_detector_augmentated_v1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ8-zW_yJ279"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Denis-R-V/TSR/blob/main/sign_detector.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xtJ8o7tJ27-"
      },
      "source": [
        "# Система распознавания дорожных знаков на датасете RTSD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "colab = False\n",
        "\n",
        "if colab == True:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    !pip install kaggle\n",
        "    !mkdir ~/.kaggle\n",
        "    !cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
        "    !kaggle datasets download watchman/rtsd-dataset\n",
        "    !unzip rtsd-dataset.zip\n",
        "    !rm rtsd-dataset.zip\n",
        "    !cp -r rtsd-frames/rtsd-frames/ .\n",
        "    !rm -r rtsd-frames/rtsd-frames/\n",
        "    !pip install fiftyone\n",
        "if colab == True:\n",
        "    dataset_path = '.'\n",
        "    checkpoints_path = '../content/drive/MyDrive/TSR/checkpoints'\n",
        "else:\n",
        "    dataset_path = 'data'\n",
        "    checkpoints_path = 'checkpoints'\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "#import matplotlib.patches as patches\n",
        "#%matplotlib inline\n",
        "\n",
        "#from pycocotools.coco import COCO\n",
        "#import fiftyone as fo\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "#from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "#from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models import resnet152\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from sklearn import metrics\n",
        "from torchvision import models\n",
        "#import cv2\n",
        "#PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k69EoY9zJ28Y"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRRoJ7Q4J28Z"
      },
      "source": [
        "### Загрузчик данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RTSD_dataset_classifier(Dataset):\n",
        "    def __init__(self, dataset_path, background_anno_file, dataset_anno_file, transforms):\n",
        "        \n",
        "        self.dataset_path = dataset_path\n",
        "        self.background_anno_file = background_anno_file\n",
        "        self.dataset_anno_file = dataset_anno_file\n",
        "        self.transforms = transforms\n",
        "        self.transforms_lib = None\n",
        "        try:\n",
        "            self.transforms.additional_targets == {}\n",
        "            self.transforms_lib = 'albumentations'\n",
        "        except:\n",
        "            self.transforms_lib = 'torchvision'\n",
        "        \n",
        "        with open(os.path.join(dataset_path, background_anno_file), 'r') as read_file:\n",
        "            self.background_anno = json.load(read_file)\n",
        "        read_file.close()\n",
        "\n",
        "        #self.df_backgrnd_anno = pd.DataFrame(self.background_anno.get('annotations'))[['image_id','bbox','category_id']]\n",
        "        #self.df_backgrnd_images = pd.DataFrame(self.background_anno.get('images'))[['id','file_name']]\n",
        "        #self.df_backgrnd = self.df_backgrnd_anno.merge(self.df_backgrnd_images, left_on='image_id', right_on='id',)[['file_name','bbox','category_id']]\n",
        "        df_backgrnd_anno = pd.DataFrame(self.background_anno.get('annotations'))[['image_id','bbox','category_id']]\n",
        "        df_backgrnd_images = pd.DataFrame(self.background_anno.get('images'))[['id','file_name']]\n",
        "        df_backgrnd = df_backgrnd_anno.merge(df_backgrnd_images, left_on='image_id', right_on='id',)[['file_name','bbox','category_id']]\n",
        "\n",
        "        with open(os.path.join(dataset_path, dataset_anno_file), 'r') as read_file:\n",
        "            self.anno = json.load(read_file)\n",
        "        read_file.close()\n",
        "\n",
        "        #self.df_anno = pd.DataFrame(self.anno.get('annotations'))[['image_id','bbox','category_id']]\n",
        "        #self.df_images = pd.DataFrame(self.anno.get('images'))[['id','file_name']]\n",
        "        #self.df_dataset = self.df_anno.merge(self.df_images, left_on='image_id', right_on='id',)[['file_name','bbox','category_id']]\n",
        "\n",
        "        df_anno = pd.DataFrame(self.anno.get('annotations'))[['image_id','bbox','category_id']]\n",
        "        df_images = pd.DataFrame(self.anno.get('images'))[['id','file_name']]\n",
        "        self.df_dataset = df_anno.merge(df_images, left_on='image_id', right_on='id',)[['file_name','bbox','category_id']]\n",
        "        \n",
        "        self.df_dataset = pd.concat((df_backgrnd, self.df_dataset), axis=0)\n",
        "        self.df_dataset.reset_index(inplace=True)\n",
        "        del self.df_dataset['index']    \n",
        "        #self.labels = torch.eye(156)[self.df_dataset['category_id']]'''\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df_dataset.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.df_dataset.loc[index,'file_name']\n",
        "        bbox = self.df_dataset.loc[index,'bbox']\n",
        "        bbox = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]\n",
        "        img = Image.open(os.path.join(self.dataset_path, img_name))\n",
        "        img = img.crop(bbox)\n",
        "        \n",
        "        if self.transforms_lib == 'torchvision':\n",
        "            img = self.transforms(img)\n",
        "        elif self.transforms_lib == 'albumentations':\n",
        "            img = np.array(img).astype(np.float32)/255.\n",
        "            img = self.transforms(image=img)['image']\n",
        "            img = img.float()\n",
        "        else:\n",
        "            print('Ошибка выбора библиотеки аугментации')\n",
        "\n",
        "        label = torch.tensor(self.df_dataset.loc[index,'category_id'])\n",
        "    \n",
        "        \n",
        "        #from PIL import ImageOps\n",
        "        #old_img = Image.open(image_path)\n",
        "        # создание нового изображения с белым фоном\n",
        "        #new_image = ImageOps.expand(old_img, border=25, fill=(255,255,255))\n",
        "\n",
        "        return {'images':img, 'labels':label}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Send train=True fro training transforms and False for val/test transforms\n",
        "def get_transform(augmentation_lib = 'torchvision', train=False):\n",
        "    if augmentation_lib =='torchvision':\n",
        "        if train == True:\n",
        "            return transforms.Compose([transforms.Resize((224,224)),\n",
        "                                    transforms.RandomPerspective(distortion_scale=0.4,p=0.3),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.ColorJitter(brightness=(0.5), contrast=(0.4), saturation=(0.4)),\n",
        "                                    transforms.GaussianBlur(11, sigma=(0.1, 2.0)),\n",
        "                                    transforms.RandomAdjustSharpness(5),\n",
        "                                    transforms.RandomRotation(10),\n",
        "                                    transforms.RandomResizedCrop((224,224), scale=(0.85, 1)), # Случайная обрезка изображения в диапахоне 85 - 100% и resize в исходный размер\n",
        "                                    #transforms.Normalize([0.485, 0.456, 0.406],      # 1 496\n",
        "                                    #                        [0.229, 0.224, 0.225]),\n",
        "                                    transforms.RandomErasing(p = 0.4, scale = (0.003, 0.1)),\n",
        "                                    transforms.RandomErasing(p = 0.6, scale = (0.003, 0.05)),\n",
        "                                    transforms.RandomErasing(p = 0.6, scale = (0.003, 0.05)),\n",
        "                                    transforms.RandomErasing(p = 0.6, scale = (0.003, 0.02)),\n",
        "                                    transforms.RandomErasing(p = 0.6, scale = (0.003, 0.02)),\n",
        "                                    transforms.RandomErasing(p = 0.6, scale = (0.001, 0.01)),\n",
        "                                    transforms.RandomErasing(p = 0.6, scale = (0.001, 0.01)),\n",
        "                                    transforms.RandomErasing(p = 0.6, scale = (0.001, 0.01)),\n",
        "                                    transforms.RandomErasing(p = 0.6, scale = (0.001, 0.01)),\n",
        "                                    transforms.RandomErasing(p = 0.6, scale = (0.001, 0.01)),\n",
        "                                    ])\n",
        "        else:\n",
        "            return transforms.Compose([transforms.Resize((224,224)),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    #transforms.Normalize([0.485, 0.456, 0.406],      # 1 496\n",
        "                                    #                     [0.229, 0.224, 0.225])\n",
        "                                    ])   \n",
        "    \n",
        "    elif augmentation_lib =='albumentations':\n",
        "        if train==True:\n",
        "            return A.Compose([A.augmentations.geometric.resize.Resize (224, 224, interpolation=1, always_apply=False, p=1),\n",
        "                              A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
        "                              A.RandomFog(fog_coef_lower=0.2, fog_coef_upper=0.3, alpha_coef=0.1, p=0.05), #Туман\n",
        "                              A.RandomRain(brightness_coefficient=0.9, drop_width=1, blur_value=5, p=0.05),\n",
        "                              A.Rotate(limit=10, p=0.5),\n",
        "                              ToTensorV2(p=1.0)\n",
        "                              ])\n",
        "            \n",
        "        else:\n",
        "            return A.Compose([A.augmentations.geometric.resize.Resize (224, 224, interpolation=1, always_apply=False, p=1),\n",
        "                              ToTensorV2(p=1.0)\n",
        "                            ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_tvs = RTSD_dataset_classifier(dataset_path,\n",
        "                               background_anno_file = 'train_anno_reduced_background.json',\n",
        "                               dataset_anno_file = 'train_anno_reduced.json',\n",
        "                               transforms = get_transform(augmentation_lib = 'torchvision', train=True)\n",
        "                               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_sign(dataset, index):\n",
        "    item = dataset.__getitem__(index)\n",
        "    img = item['images']\n",
        "    target = item['labels']\n",
        "    #img, target = test.__getitem__(index)\n",
        "    img = img.permute(1, 2, 0).detach().numpy()\n",
        "    img = img*255\n",
        "    img = img.astype(np.uint8)\n",
        "    fig, a = plt.subplots(1,1)\n",
        "    #fig.set_size_inches(10,10)\n",
        "    display(int(target.cpu().detach().numpy()))\n",
        "    a.imshow(img)\n",
        "    return None\n",
        "plot_sign(test_tvs, 904)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_alb = RTSD_dataset_classifier(dataset_path,\n",
        "                               background_anno_file = 'train_anno_reduced_background.json',\n",
        "                               dataset_anno_file = 'train_anno_reduced.json',\n",
        "                               transforms = get_transform(augmentation_lib = 'albumentations', train=True)\n",
        "                               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_sign(dataset, index):\n",
        "    item = dataset.__getitem__(index)\n",
        "    img = item['images']\n",
        "    target = item['labels']\n",
        "    #img, target = test.__getitem__(index)\n",
        "    img = img.permute(1, 2, 0).detach().numpy()\n",
        "    img = img*255\n",
        "    img = img.astype(np.uint8)\n",
        "    fig, a = plt.subplots(1,1)\n",
        "    #fig.set_size_inches(10,10)\n",
        "    display(int(target.cpu().detach().numpy()))\n",
        "    a.imshow(img)\n",
        "    return None\n",
        "plot_sign(test_alb, 904)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J90qxR2RJ28Z"
      },
      "source": [
        "### Гиперпараметры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "CI7vlkQPJ28Z"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device_id = 0\n",
        "if torch.cuda.is_available() == True:\n",
        "    device = f'cuda:{device_id}'\n",
        "elif torch.backends.mps.is_available() == True:\n",
        "    device = 'mps'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "\n",
        "model_name = 'resnet152_test_adam_01_sh_1_08'\n",
        "#model_name = 'resnet152_augmented_alb_adam_001'\n",
        "last_epoch = None\n",
        "n_epochs = 10\n",
        "batch_size = 32\n",
        "num_classes = 156\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo40ASBXJ28Z"
      },
      "source": [
        "### Инициализация модели, задание оптимизатора и функции потерь"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "TNQ4zYcHtHId"
      },
      "outputs": [],
      "source": [
        "def create_model(num_classes):\n",
        "    model = resnet152(weights='ResNet152_Weights.IMAGENET1K_V2')\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    #model.fc = nn.Sequential(nn.Linear(2048, 1024), nn.Linear(1024, num_classes))\n",
        "    #model.fc = nn.Sequential(nn.Linear(2048, num_classes))\n",
        "    for param in model.fc.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    #torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='FasterRCNN_ResNet50_FPN_Weights.COCO_V1')\n",
        "    #in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    #model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint = torch.load(os.path.join(checkpoints_path, f'chkpt_classifier_{model_name}_{last_epoch}.pth'), map_location=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'losses_train', 'losses_val'])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "242586dd62d544a39c122c7b1ed6efc9",
            "78cb1778f71b45b88ffdb20bfe0cd66e",
            "6d83c78727204f529982e56c3bfe32c1",
            "55191ea6a8eb4574aff8a9bc21fdd55a",
            "ae7f4e349b634abd8b36184774421f7a",
            "e012c54a3a9f48b38c500c17227f67b8",
            "91eb94ac4f6347c6b7d860b73e3742da",
            "4146164713eb4c2db70cf52335398a3e",
            "e66226838c994913b2d58fd0db3f4282",
            "b17d80f4da05457781be26c19a1dca17",
            "8e403bce502349d28da4553899f80c33"
          ]
        },
        "id": "ZdWxX5-PJ28Z",
        "outputId": "d572c5f8-341f-46c4-adb3-14866216da69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\User/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62bd80c77b624a6886e268482975eb91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = create_model(num_classes).to(device)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# parameters\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "#optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
        "#params = [p for p in model.parameters() if p.requires_grad]\n",
        "#optimizer = torch.optim.SGD(params, lr=0.003, momentum=0.9, weight_decay=0.0005)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.0005)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)\n",
        "\n",
        "\n",
        "#optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "    # and a learning rate scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.8)\n",
        "\n",
        "\n",
        "# Загрузка весов модели, состояния оптимизатора и шедулера\n",
        "if last_epoch is not None:\n",
        "    checkpoint = torch.load(os.path.join(checkpoints_path, f'chkpt_classifier_{model_name}_{last_epoch}.pth'), map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
        "\n",
        "train_dataset = RTSD_dataset_classifier(dataset_path,\n",
        "                                        background_anno_file = 'train_anno_reduced_background.json',\n",
        "                                        dataset_anno_file = 'train_anno.json',\n",
        "                                        transforms = get_transform(augmentation_lib = 'torchvision', train=True)\n",
        "                                        )\n",
        "\n",
        "val_dataset = RTSD_dataset_classifier(dataset_path,\n",
        "                                      background_anno_file = 'val_anno_background.json',\n",
        "                                      dataset_anno_file = 'val_anno.json',\n",
        "                                      transforms = get_transform(augmentation_lib = 'torchvision', train=False)\n",
        "                                      )\n",
        "\n",
        "train_data_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    #sampler=SubsetRandomSampler(),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    #num_workers=4,\n",
        "    #collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_data_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    #sampler=SubsetRandomSampler(),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    #num_workers=4,\n",
        "    #collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YimGoL3J28Z"
      },
      "source": [
        "### Трейн луп"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(train_dataloader, epoch): \n",
        "    len_dataloader = len(train_dataloader)\n",
        "\n",
        "    training_loss=0\n",
        "    # для текущего accuracy\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    # для вывода метрик\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0        # training_loss\n",
        "    \n",
        "    for batch_idx, data in enumerate(train_dataloader):\n",
        "        \n",
        "        \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        #images, targets = data[0], data[1]\n",
        "        #images = images.to(device)\n",
        "        #targets = targets.to(device)\n",
        "        images = data['images'].to(device)\n",
        "        targets = data['labels'].to(device)\n",
        "        output = model(images)\n",
        "        loss = loss_function(output, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "       \n",
        "        running_loss = running_loss + ((1/(batch_idx+1))*(loss.data-running_loss))\n",
        "        if batch_idx%20 == 0:\n",
        "            print(f\"Batch Id {batch_idx} is having training loss of {running_loss}\")\n",
        "            print(loss.item())\n",
        "\n",
        "        pred = output.data.max(1,keepdim=True)[1]\n",
        "\n",
        "        # для текущего accuracy\n",
        "        correct += np.sum(np.squeeze(pred.eq(targets.data.view_as(pred))).cpu().numpy())\n",
        "        total += images.size(0)\n",
        "        print(f\"Epoch #{epoch}. Accuracy on batch {batch_idx} on Training is {(100*correct/total)}\")\n",
        "        \n",
        "        # для вывода метрик\n",
        "        y_true.extend([int(item) for item in targets])\n",
        "        y_pred.extend([int(item) for item in pred])\n",
        "\n",
        "        #images = list(image.to(device) for image in images)\n",
        "        #targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        #loss_dict = model(images, targets)\n",
        "        #loss = sum(loss for loss in loss_dict.values())\n",
        "        #running_loss += loss.item()\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "        #if batch_idx % 50 == 0:\n",
        "        #    print(f\"\\tЭпоха {epoch}. Итерация {batch_idx}/{len_dataloader}. Loss: {loss}\")\n",
        "    train_loss = running_loss/len(train_dataloader.dataset)\n",
        "    train_accuracy = metrics.accuracy_score(y_true, y_pred)\n",
        "    train_f1_micro = metrics.f1_score(y_true, y_pred, average=\"micro\")\n",
        "    train_f1_macro =  metrics.f1_score(y_true, y_pred, average=\"macro\")\n",
        "    train_f1_weighted = metrics.f1_score(y_true, y_pred, average=\"weighted\")\n",
        "    return train_loss, train_accuracy, train_f1_micro, train_f1_macro, train_f1_weighted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def val (val_dataloader, epoch):\n",
        "    #len_dataloader = len(train_dataloader)\n",
        "\n",
        "    validation_loss=0\n",
        "    # для текущего accuracy\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    # для вывода метрик\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for batch_idx, data in enumerate(val_dataloader):\n",
        "        \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        #images, targets = data[0], data[1]\n",
        "        #images = images.to(device)\n",
        "        #targets = targets.to(device)\n",
        "        images = data['images'].to(device)\n",
        "        targets = data['labels'].to(device)\n",
        "        #with torch.no_grad():\n",
        "            \n",
        "        output = model(images)\n",
        "        loss = loss_function(output, targets)\n",
        "        \n",
        "        validation_loss = validation_loss + ((1/(batch_idx+1))*(loss.data-validation_loss))\n",
        "        #if batch_idx%20 == 0:\n",
        "        print(f\"Epoch #{epoch}. Batch Id {batch_idx} is having validation loss of {validation_loss}\")\n",
        "        print(loss.item())\n",
        "        pred = output.data.max(1,keepdim=True)[1]\n",
        "\n",
        "        # для текущего accuracy\n",
        "        correct += np.sum(np.squeeze(pred.eq(targets.data.view_as(pred))).cpu().numpy())\n",
        "        total += images.size(0)\n",
        "        print(f\"Epoch #{epoch}. Batch Id {batch_idx} is having validation accuracy of {(100*correct/total)}\")\n",
        "\n",
        "        # для вывода метрик\n",
        "        y_true.extend([int(item) for item in targets])\n",
        "        y_pred.extend([int(item) for item in pred])\n",
        "        #images = list(image.to(device) for image in images)\n",
        "        #targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        #loss_dict = model(images, targets)\n",
        "        #loss = sum(loss for loss in loss_dict.values())\n",
        "        #running_loss += loss.item()\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "        #if batch_idx % 50 == 0:\n",
        "        #    print(f\"\\tЭпоха {epoch}. Итерация {batch_idx}/{len_dataloader}. Loss: {loss}\")\n",
        "    val_loss = validation_loss/len(val_dataloader.dataset)\n",
        "    val_accuracy = metrics.accuracy_score(y_true, y_pred)\n",
        "    val_f1_micro = metrics.f1_score(y_true, y_pred, average=\"micro\")\n",
        "    val_f1_macro =  metrics.f1_score(y_true, y_pred, average=\"macro\")\n",
        "    val_f1_weighted = metrics.f1_score(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "\n",
        "    return val_loss, val_accuracy, val_f1_micro, val_f1_macro, val_f1_weighted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Id 0 is having training loss of 8.903411865234375\n",
            "8.903411865234375\n",
            "Epoch #0. Accuracy on batch 0 on Training is 0.0\n",
            "Epoch #0. Accuracy on batch 1 on Training is 9.375\n",
            "Epoch #0. Accuracy on batch 2 on Training is 16.666666666666668\n",
            "Epoch #0. Accuracy on batch 3 on Training is 18.75\n",
            "Epoch #0. Accuracy on batch 4 on Training is 15.625\n",
            "Epoch #0. Accuracy on batch 5 on Training is 13.020833333333334\n",
            "Epoch #0. Accuracy on batch 6 on Training is 12.946428571428571\n",
            "Epoch #0. Accuracy on batch 7 on Training is 15.234375\n",
            "Epoch #0. Accuracy on batch 8 on Training is 18.40277777777778\n",
            "Epoch #0. Accuracy on batch 9 on Training is 20.0\n",
            "Epoch #0. Accuracy on batch 10 on Training is 21.022727272727273\n",
            "Epoch #0. Accuracy on batch 11 on Training is 20.833333333333332\n",
            "Epoch #0. Accuracy on batch 12 on Training is 21.875\n",
            "Epoch #0. Accuracy on batch 13 on Training is 22.098214285714285\n",
            "Epoch #0. Accuracy on batch 14 on Training is 22.291666666666668\n",
            "Epoch #0. Accuracy on batch 15 on Training is 22.4609375\n",
            "Epoch #0. Accuracy on batch 16 on Training is 22.794117647058822\n",
            "Epoch #0. Accuracy on batch 17 on Training is 22.916666666666668\n",
            "Epoch #0. Accuracy on batch 18 on Training is 23.026315789473685\n",
            "Epoch #0. Accuracy on batch 19 on Training is 23.28125\n",
            "Batch Id 20 is having training loss of 8.002220153808594\n",
            "3.2287068367004395\n",
            "Epoch #0. Accuracy on batch 20 on Training is 24.107142857142858\n",
            "Epoch #0. Accuracy on batch 21 on Training is 24.005681818181817\n",
            "Epoch #0. Accuracy on batch 22 on Training is 24.184782608695652\n",
            "Epoch #0. Accuracy on batch 23 on Training is 24.869791666666668\n",
            "Epoch #0. Accuracy on batch 24 on Training is 24.875\n",
            "Epoch #0. Accuracy on batch 25 on Training is 24.879807692307693\n",
            "Epoch #0. Accuracy on batch 26 on Training is 25.578703703703702\n",
            "Epoch #0. Accuracy on batch 27 on Training is 25.78125\n",
            "Epoch #0. Accuracy on batch 28 on Training is 25.862068965517242\n",
            "Epoch #0. Accuracy on batch 29 on Training is 26.041666666666668\n",
            "Epoch #0. Accuracy on batch 30 on Training is 26.108870967741936\n",
            "Epoch #0. Accuracy on batch 31 on Training is 26.5625\n",
            "Epoch #0. Accuracy on batch 32 on Training is 26.799242424242426\n",
            "Epoch #0. Accuracy on batch 33 on Training is 27.113970588235293\n",
            "Epoch #0. Accuracy on batch 34 on Training is 26.696428571428573\n",
            "Epoch #0. Accuracy on batch 35 on Training is 26.475694444444443\n",
            "Epoch #0. Accuracy on batch 36 on Training is 26.85810810810811\n",
            "Epoch #0. Accuracy on batch 37 on Training is 27.05592105263158\n",
            "Epoch #0. Accuracy on batch 38 on Training is 27.243589743589745\n",
            "Epoch #0. Accuracy on batch 39 on Training is 27.34375\n",
            "Batch Id 40 is having training loss of 8.404165267944336\n",
            "4.270766735076904\n",
            "Epoch #0. Accuracy on batch 40 on Training is 27.286585365853657\n",
            "Epoch #0. Accuracy on batch 41 on Training is 27.827380952380953\n",
            "Epoch #0. Accuracy on batch 42 on Training is 27.54360465116279\n",
            "Epoch #0. Accuracy on batch 43 on Training is 27.556818181818183\n",
            "Epoch #0. Accuracy on batch 44 on Training is 27.708333333333332\n",
            "Epoch #0. Accuracy on batch 45 on Training is 27.85326086956522\n",
            "Epoch #0. Accuracy on batch 46 on Training is 28.05851063829787\n",
            "Epoch #0. Accuracy on batch 47 on Training is 27.799479166666668\n",
            "Epoch #0. Accuracy on batch 48 on Training is 27.933673469387756\n",
            "Epoch #0. Accuracy on batch 49 on Training is 28.125\n",
            "Epoch #0. Accuracy on batch 50 on Training is 28.247549019607842\n",
            "Epoch #0. Accuracy on batch 51 on Training is 28.30528846153846\n",
            "Epoch #0. Accuracy on batch 52 on Training is 28.30188679245283\n",
            "Epoch #0. Accuracy on batch 53 on Training is 28.53009259259259\n",
            "Epoch #0. Accuracy on batch 54 on Training is 28.920454545454547\n",
            "Epoch #0. Accuracy on batch 55 on Training is 28.683035714285715\n",
            "Epoch #0. Accuracy on batch 56 on Training is 28.728070175438596\n",
            "Epoch #0. Accuracy on batch 57 on Training is 28.825431034482758\n",
            "Epoch #0. Accuracy on batch 58 on Training is 29.13135593220339\n",
            "Epoch #0. Accuracy on batch 59 on Training is 29.322916666666668\n",
            "Batch Id 60 is having training loss of 15.698651313781738\n",
            "308.5998229980469\n",
            "Epoch #0. Accuracy on batch 60 on Training is 29.354508196721312\n",
            "Epoch #0. Accuracy on batch 61 on Training is 29.586693548387096\n",
            "Epoch #0. Accuracy on batch 62 on Training is 29.71230158730159\n",
            "Epoch #0. Accuracy on batch 63 on Training is 29.931640625\n",
            "Epoch #0. Accuracy on batch 64 on Training is 30.048076923076923\n",
            "Epoch #0. Accuracy on batch 65 on Training is 30.06628787878788\n",
            "Epoch #0. Accuracy on batch 66 on Training is 30.130597014925375\n",
            "Epoch #0. Accuracy on batch 67 on Training is 30.19301470588235\n",
            "Epoch #0. Accuracy on batch 68 on Training is 30.07246376811594\n",
            "Epoch #0. Accuracy on batch 69 on Training is 29.910714285714285\n",
            "Epoch #0. Accuracy on batch 70 on Training is 29.70950704225352\n",
            "Epoch #0. Accuracy on batch 71 on Training is 29.774305555555557\n",
            "Epoch #0. Accuracy on batch 72 on Training is 29.708904109589042\n",
            "Epoch #0. Accuracy on batch 73 on Training is 29.81418918918919\n",
            "Epoch #0. Accuracy on batch 74 on Training is 29.875\n",
            "Epoch #0. Accuracy on batch 75 on Training is 29.893092105263158\n",
            "Epoch #0. Accuracy on batch 76 on Training is 30.113636363636363\n",
            "Epoch #0. Accuracy on batch 77 on Training is 30.048076923076923\n",
            "Epoch #0. Accuracy on batch 78 on Training is 30.14240506329114\n",
            "Epoch #0. Accuracy on batch 79 on Training is 30.1171875\n",
            "Batch Id 80 is having training loss of 23.197738647460938\n",
            "259.8569641113281\n",
            "Epoch #0. Accuracy on batch 80 on Training is 29.89969135802469\n",
            "Epoch #0. Accuracy on batch 81 on Training is 30.259146341463413\n",
            "Epoch #0. Accuracy on batch 82 on Training is 30.308734939759034\n",
            "Epoch #0. Accuracy on batch 83 on Training is 30.43154761904762\n",
            "Epoch #0. Accuracy on batch 84 on Training is 30.441176470588236\n",
            "Epoch #0. Accuracy on batch 85 on Training is 30.305232558139537\n",
            "Epoch #0. Accuracy on batch 86 on Training is 30.280172413793103\n",
            "Epoch #0. Accuracy on batch 87 on Training is 30.291193181818183\n",
            "Epoch #0. Accuracy on batch 88 on Training is 30.372191011235955\n",
            "Epoch #0. Accuracy on batch 89 on Training is 30.555555555555557\n",
            "Epoch #0. Accuracy on batch 90 on Training is 30.528846153846153\n",
            "Epoch #0. Accuracy on batch 91 on Training is 30.434782608695652\n",
            "Epoch #0. Accuracy on batch 92 on Training is 30.443548387096776\n",
            "Epoch #0. Accuracy on batch 93 on Training is 30.45212765957447\n",
            "Epoch #0. Accuracy on batch 94 on Training is 30.657894736842106\n",
            "Epoch #0. Accuracy on batch 95 on Training is 30.794270833333332\n",
            "Epoch #0. Accuracy on batch 96 on Training is 30.734536082474225\n",
            "Epoch #0. Accuracy on batch 97 on Training is 30.803571428571427\n",
            "Epoch #0. Accuracy on batch 98 on Training is 30.744949494949495\n",
            "Epoch #0. Accuracy on batch 99 on Training is 30.6875\n",
            "Batch Id 100 is having training loss of 26.650949478149414\n",
            "18.710813522338867\n",
            "Epoch #0. Accuracy on batch 100 on Training is 30.693069306930692\n",
            "Epoch #0. Accuracy on batch 101 on Training is 30.698529411764707\n",
            "Epoch #0. Accuracy on batch 102 on Training is 30.734223300970875\n",
            "Epoch #0. Accuracy on batch 103 on Training is 30.76923076923077\n",
            "Epoch #0. Accuracy on batch 104 on Training is 30.68452380952381\n",
            "Epoch #0. Accuracy on batch 105 on Training is 30.660377358490567\n",
            "Epoch #0. Accuracy on batch 106 on Training is 30.66588785046729\n",
            "Epoch #0. Accuracy on batch 107 on Training is 30.729166666666668\n",
            "Epoch #0. Accuracy on batch 108 on Training is 30.647935779816514\n",
            "Epoch #0. Accuracy on batch 109 on Training is 30.767045454545453\n",
            "Epoch #0. Accuracy on batch 110 on Training is 30.771396396396398\n",
            "Epoch #0. Accuracy on batch 111 on Training is 30.691964285714285\n",
            "Epoch #0. Accuracy on batch 112 on Training is 30.696902654867255\n",
            "Epoch #0. Accuracy on batch 113 on Training is 30.646929824561404\n",
            "Epoch #0. Accuracy on batch 114 on Training is 30.679347826086957\n",
            "Epoch #0. Accuracy on batch 115 on Training is 30.657327586206897\n",
            "Epoch #0. Accuracy on batch 116 on Training is 30.555555555555557\n",
            "Epoch #0. Accuracy on batch 117 on Training is 30.640889830508474\n",
            "Epoch #0. Accuracy on batch 118 on Training is 30.751050420168067\n",
            "Epoch #0. Accuracy on batch 119 on Training is 30.807291666666668\n",
            "Batch Id 120 is having training loss of 37.77532196044922\n",
            "17.868741989135742\n",
            "Epoch #0. Accuracy on batch 120 on Training is 30.888429752066116\n",
            "Epoch #0. Accuracy on batch 121 on Training is 30.942622950819672\n",
            "Epoch #0. Accuracy on batch 122 on Training is 30.91971544715447\n",
            "Epoch #0. Accuracy on batch 123 on Training is 30.922379032258064\n",
            "Epoch #0. Accuracy on batch 124 on Training is 30.95\n",
            "Epoch #0. Accuracy on batch 125 on Training is 30.927579365079364\n",
            "Epoch #0. Accuracy on batch 126 on Training is 31.003937007874015\n",
            "Epoch #0. Accuracy on batch 127 on Training is 31.0791015625\n",
            "Epoch #0. Accuracy on batch 128 on Training is 31.1046511627907\n",
            "Epoch #0. Accuracy on batch 129 on Training is 31.25\n",
            "Epoch #0. Accuracy on batch 130 on Training is 31.27385496183206\n",
            "Epoch #0. Accuracy on batch 131 on Training is 31.178977272727273\n",
            "Epoch #0. Accuracy on batch 132 on Training is 31.226503759398497\n",
            "Epoch #0. Accuracy on batch 133 on Training is 31.25\n",
            "Epoch #0. Accuracy on batch 134 on Training is 31.296296296296298\n",
            "Epoch #0. Accuracy on batch 135 on Training is 31.25\n",
            "Epoch #0. Accuracy on batch 136 on Training is 31.318430656934307\n",
            "Epoch #0. Accuracy on batch 137 on Training is 31.38586956521739\n",
            "Epoch #0. Accuracy on batch 138 on Training is 31.429856115107913\n",
            "Epoch #0. Accuracy on batch 139 on Training is 31.339285714285715\n",
            "Batch Id 140 is having training loss of 87.17981719970703\n",
            "67.06665802001953\n",
            "Epoch #0. Accuracy on batch 140 on Training is 31.338652482269502\n",
            "Epoch #0. Accuracy on batch 141 on Training is 31.360035211267604\n",
            "Epoch #0. Accuracy on batch 142 on Training is 31.25\n",
            "Epoch #0. Accuracy on batch 143 on Training is 31.29340277777778\n",
            "Epoch #0. Accuracy on batch 144 on Training is 31.271551724137932\n",
            "Epoch #0. Accuracy on batch 145 on Training is 31.25\n",
            "Epoch #0. Accuracy on batch 146 on Training is 31.18622448979592\n",
            "Epoch #0. Accuracy on batch 147 on Training is 31.186655405405407\n",
            "Epoch #0. Accuracy on batch 148 on Training is 31.166107382550337\n",
            "Epoch #0. Accuracy on batch 149 on Training is 31.145833333333332\n",
            "Epoch #0. Accuracy on batch 150 on Training is 31.167218543046356\n",
            "Epoch #0. Accuracy on batch 151 on Training is 31.167763157894736\n",
            "Epoch #0. Accuracy on batch 152 on Training is 31.16830065359477\n",
            "Epoch #0. Accuracy on batch 153 on Training is 31.128246753246753\n",
            "Epoch #0. Accuracy on batch 154 on Training is 31.129032258064516\n",
            "Epoch #0. Accuracy on batch 155 on Training is 31.109775641025642\n",
            "Epoch #0. Accuracy on batch 156 on Training is 31.110668789808916\n",
            "Epoch #0. Accuracy on batch 157 on Training is 31.111550632911392\n",
            "Epoch #0. Accuracy on batch 158 on Training is 31.1124213836478\n",
            "Epoch #0. Accuracy on batch 159 on Training is 31.09375\n",
            "Batch Id 160 is having training loss of 97.75285339355469\n",
            "30.896892547607422\n",
            "Epoch #0. Accuracy on batch 160 on Training is 31.075310559006212\n",
            "Epoch #0. Accuracy on batch 161 on Training is 31.07638888888889\n",
            "Epoch #0. Accuracy on batch 162 on Training is 31.039110429447852\n",
            "Epoch #0. Accuracy on batch 163 on Training is 31.078506097560975\n",
            "Epoch #0. Accuracy on batch 164 on Training is 31.117424242424242\n",
            "Epoch #0. Accuracy on batch 165 on Training is 31.118222891566266\n",
            "Epoch #0. Accuracy on batch 166 on Training is 31.100299401197606\n",
            "Epoch #0. Accuracy on batch 167 on Training is 31.063988095238095\n",
            "Epoch #0. Accuracy on batch 168 on Training is 31.120562130177515\n",
            "Epoch #0. Accuracy on batch 169 on Training is 31.029411764705884\n",
            "Epoch #0. Accuracy on batch 170 on Training is 31.067251461988302\n",
            "Epoch #0. Accuracy on batch 171 on Training is 31.06831395348837\n",
            "Epoch #0. Accuracy on batch 172 on Training is 31.08742774566474\n",
            "Epoch #0. Accuracy on batch 173 on Training is 31.124281609195403\n",
            "Epoch #0. Accuracy on batch 174 on Training is 31.160714285714285\n",
            "Epoch #0. Accuracy on batch 175 on Training is 31.196732954545453\n",
            "Epoch #0. Accuracy on batch 176 on Training is 31.12641242937853\n",
            "Epoch #0. Accuracy on batch 177 on Training is 31.144662921348313\n",
            "Epoch #0. Accuracy on batch 178 on Training is 31.110335195530727\n",
            "Epoch #0. Accuracy on batch 179 on Training is 31.09375\n",
            "Batch Id 180 is having training loss of 112.26400756835938\n",
            "22.782379150390625\n",
            "Epoch #0. Accuracy on batch 180 on Training is 31.07734806629834\n",
            "Epoch #0. Accuracy on batch 181 on Training is 31.043956043956044\n",
            "Epoch #0. Accuracy on batch 182 on Training is 31.028005464480874\n",
            "Epoch #0. Accuracy on batch 183 on Training is 31.046195652173914\n",
            "Epoch #0. Accuracy on batch 184 on Training is 31.030405405405407\n",
            "Epoch #0. Accuracy on batch 185 on Training is 31.048387096774192\n",
            "Epoch #0. Accuracy on batch 186 on Training is 31.08288770053476\n",
            "Epoch #0. Accuracy on batch 187 on Training is 31.06715425531915\n",
            "Epoch #0. Accuracy on batch 188 on Training is 30.985449735449734\n",
            "Epoch #0. Accuracy on batch 189 on Training is 31.019736842105264\n",
            "Epoch #0. Accuracy on batch 190 on Training is 31.037303664921467\n",
            "Epoch #0. Accuracy on batch 191 on Training is 31.070963541666668\n",
            "Epoch #0. Accuracy on batch 192 on Training is 31.088082901554404\n",
            "Epoch #0. Accuracy on batch 193 on Training is 31.056701030927837\n",
            "Epoch #0. Accuracy on batch 194 on Training is 31.137820512820515\n",
            "Epoch #0. Accuracy on batch 195 on Training is 31.18622448979592\n",
            "Epoch #0. Accuracy on batch 196 on Training is 31.107233502538072\n",
            "Epoch #0. Accuracy on batch 197 on Training is 31.07638888888889\n",
            "Epoch #0. Accuracy on batch 198 on Training is 31.030150753768844\n",
            "Epoch #0. Accuracy on batch 199 on Training is 31.0625\n",
            "Batch Id 200 is having training loss of 135.6846923828125\n",
            "76.25273132324219\n",
            "Epoch #0. Accuracy on batch 200 on Training is 31.078980099502488\n",
            "Epoch #0. Accuracy on batch 201 on Training is 31.064356435643564\n",
            "Epoch #0. Accuracy on batch 202 on Training is 31.09605911330049\n",
            "Epoch #0. Accuracy on batch 203 on Training is 31.096813725490197\n",
            "Epoch #0. Accuracy on batch 204 on Training is 31.067073170731707\n",
            "Epoch #0. Accuracy on batch 205 on Training is 31.067961165048544\n",
            "Epoch #0. Accuracy on batch 206 on Training is 31.09903381642512\n",
            "Epoch #0. Accuracy on batch 207 on Training is 31.084735576923077\n",
            "Epoch #0. Accuracy on batch 208 on Training is 31.160287081339714\n",
            "Epoch #0. Accuracy on batch 209 on Training is 31.175595238095237\n",
            "Epoch #0. Accuracy on batch 210 on Training is 31.17594786729858\n",
            "Epoch #0. Accuracy on batch 211 on Training is 31.14681603773585\n",
            "Epoch #0. Accuracy on batch 212 on Training is 31.13262910798122\n",
            "Epoch #0. Accuracy on batch 213 on Training is 31.11857476635514\n",
            "Epoch #0. Accuracy on batch 214 on Training is 31.13372093023256\n",
            "Epoch #0. Accuracy on batch 215 on Training is 31.119791666666668\n",
            "Epoch #0. Accuracy on batch 216 on Training is 31.10599078341014\n",
            "Epoch #0. Accuracy on batch 217 on Training is 31.10665137614679\n",
            "Epoch #0. Accuracy on batch 218 on Training is 31.121575342465754\n",
            "Epoch #0. Accuracy on batch 219 on Training is 31.136363636363637\n",
            "Batch Id 220 is having training loss of 148.1184539794922\n",
            "209.01316833496094\n",
            "Epoch #0. Accuracy on batch 220 on Training is 31.15101809954751\n",
            "Epoch #0. Accuracy on batch 221 on Training is 31.05292792792793\n",
            "Epoch #0. Accuracy on batch 222 on Training is 31.053811659192824\n",
            "Epoch #0. Accuracy on batch 223 on Training is 31.068638392857142\n",
            "Epoch #0. Accuracy on batch 224 on Training is 31.083333333333332\n",
            "Epoch #0. Accuracy on batch 225 on Training is 31.07024336283186\n",
            "Epoch #0. Accuracy on batch 226 on Training is 31.098568281938327\n",
            "Epoch #0. Accuracy on batch 227 on Training is 31.071820175438596\n",
            "Epoch #0. Accuracy on batch 228 on Training is 31.127183406113538\n",
            "Epoch #0. Accuracy on batch 229 on Training is 31.168478260869566\n",
            "Epoch #0. Accuracy on batch 230 on Training is 31.15530303030303\n",
            "Epoch #0. Accuracy on batch 231 on Training is 31.169181034482758\n",
            "Epoch #0. Accuracy on batch 232 on Training is 31.142703862660944\n",
            "Epoch #0. Accuracy on batch 233 on Training is 31.156517094017094\n",
            "Epoch #0. Accuracy on batch 234 on Training is 31.170212765957448\n",
            "Epoch #0. Accuracy on batch 235 on Training is 31.170550847457626\n",
            "Epoch #0. Accuracy on batch 236 on Training is 31.210443037974684\n",
            "Epoch #0. Accuracy on batch 237 on Training is 31.21060924369748\n",
            "Epoch #0. Accuracy on batch 238 on Training is 31.132322175732217\n",
            "Epoch #0. Accuracy on batch 239 on Training is 31.119791666666668\n",
            "Batch Id 240 is having training loss of 150.34927368164062\n",
            "35.80009841918945\n",
            "Epoch #0. Accuracy on batch 240 on Training is 31.12033195020747\n",
            "Epoch #0. Accuracy on batch 241 on Training is 31.082128099173552\n",
            "Epoch #0. Accuracy on batch 242 on Training is 31.031378600823047\n",
            "Epoch #0. Accuracy on batch 243 on Training is 30.993852459016395\n",
            "Epoch #0. Accuracy on batch 244 on Training is 30.994897959183675\n",
            "Epoch #0. Accuracy on batch 245 on Training is 30.932418699186993\n",
            "Epoch #0. Accuracy on batch 246 on Training is 30.9084008097166\n",
            "Epoch #0. Accuracy on batch 247 on Training is 30.922379032258064\n",
            "Epoch #0. Accuracy on batch 248 on Training is 30.923694779116467\n",
            "Epoch #0. Accuracy on batch 249 on Training is 31.0\n",
            "Epoch #0. Accuracy on batch 250 on Training is 31.038346613545816\n",
            "Epoch #0. Accuracy on batch 251 on Training is 31.0515873015873\n",
            "Epoch #0. Accuracy on batch 252 on Training is 31.027667984189723\n",
            "Epoch #0. Accuracy on batch 253 on Training is 31.05314960629921\n",
            "Epoch #0. Accuracy on batch 254 on Training is 31.090686274509803\n",
            "Epoch #0. Accuracy on batch 255 on Training is 31.103515625\n",
            "Epoch #0. Accuracy on batch 256 on Training is 31.09192607003891\n",
            "Epoch #0. Accuracy on batch 257 on Training is 31.06831395348837\n",
            "Epoch #0. Accuracy on batch 258 on Training is 31.069015444015445\n",
            "Epoch #0. Accuracy on batch 259 on Training is 31.141826923076923\n",
            "Batch Id 260 is having training loss of 147.13613891601562\n",
            "51.18435287475586\n",
            "Epoch #0. Accuracy on batch 260 on Training is 31.142241379310345\n",
            "Epoch #0. Accuracy on batch 261 on Training is 31.166507633587788\n",
            "Epoch #0. Accuracy on batch 262 on Training is 31.131178707224336\n",
            "Epoch #0. Accuracy on batch 263 on Training is 31.072443181818183\n",
            "Epoch #0. Accuracy on batch 264 on Training is 31.07311320754717\n",
            "Epoch #0. Accuracy on batch 265 on Training is 31.050281954887218\n",
            "Epoch #0. Accuracy on batch 266 on Training is 31.051029962546817\n",
            "Epoch #0. Accuracy on batch 267 on Training is 31.086753731343283\n",
            "Epoch #0. Accuracy on batch 268 on Training is 31.098977695167285\n",
            "Epoch #0. Accuracy on batch 269 on Training is 31.087962962962962\n",
            "Epoch #0. Accuracy on batch 270 on Training is 31.077029520295202\n",
            "Epoch #0. Accuracy on batch 271 on Training is 31.089154411764707\n",
            "Epoch #0. Accuracy on batch 272 on Training is 31.101190476190474\n",
            "Epoch #0. Accuracy on batch 273 on Training is 31.14735401459854\n",
            "Epoch #0. Accuracy on batch 274 on Training is 31.15909090909091\n",
            "Epoch #0. Accuracy on batch 275 on Training is 31.170742753623188\n",
            "Epoch #0. Accuracy on batch 276 on Training is 31.15974729241877\n",
            "Epoch #0. Accuracy on batch 277 on Training is 31.17131294964029\n",
            "Epoch #0. Accuracy on batch 278 on Training is 31.216397849462364\n",
            "Epoch #0. Accuracy on batch 279 on Training is 31.216517857142858\n",
            "Batch Id 280 is having training loss of 169.52064514160156\n",
            "151.83790588378906\n",
            "Epoch #0. Accuracy on batch 280 on Training is 31.216637010676155\n",
            "Epoch #0. Accuracy on batch 281 on Training is 31.172429078014183\n",
            "Epoch #0. Accuracy on batch 282 on Training is 31.16166077738516\n",
            "Epoch #0. Accuracy on batch 283 on Training is 31.22799295774648\n",
            "Epoch #0. Accuracy on batch 284 on Training is 31.162280701754387\n",
            "Epoch #0. Accuracy on batch 285 on Training is 31.15166083916084\n",
            "Epoch #0. Accuracy on batch 286 on Training is 31.141114982578397\n",
            "Epoch #0. Accuracy on batch 287 on Training is 31.119791666666668\n",
            "Epoch #0. Accuracy on batch 288 on Training is 31.152681660899653\n",
            "Epoch #0. Accuracy on batch 289 on Training is 31.15301724137931\n",
            "Epoch #0. Accuracy on batch 290 on Training is 31.164089347079038\n",
            "Epoch #0. Accuracy on batch 291 on Training is 31.132277397260275\n",
            "Epoch #0. Accuracy on batch 292 on Training is 31.15401023890785\n",
            "Epoch #0. Accuracy on batch 293 on Training is 31.22874149659864\n",
            "Epoch #0. Accuracy on batch 294 on Training is 31.218220338983052\n",
            "Epoch #0. Accuracy on batch 295 on Training is 31.271114864864863\n",
            "Epoch #0. Accuracy on batch 296 on Training is 31.27104377104377\n",
            "Epoch #0. Accuracy on batch 297 on Training is 31.270973154362416\n",
            "Epoch #0. Accuracy on batch 298 on Training is 31.281354515050168\n",
            "Epoch #0. Accuracy on batch 299 on Training is 31.3125\n",
            "Batch Id 300 is having training loss of 167.50953674316406\n",
            "32.394676208496094\n",
            "Epoch #0. Accuracy on batch 300 on Training is 31.30191029900332\n",
            "Epoch #0. Accuracy on batch 301 on Training is 31.27069536423841\n",
            "Epoch #0. Accuracy on batch 302 on Training is 31.291254125412543\n",
            "Epoch #0. Accuracy on batch 303 on Training is 31.29111842105263\n",
            "Epoch #0. Accuracy on batch 304 on Training is 31.28073770491803\n",
            "Epoch #0. Accuracy on batch 305 on Training is 31.28063725490196\n",
            "Epoch #0. Accuracy on batch 306 on Training is 31.280537459283387\n",
            "Epoch #0. Accuracy on batch 307 on Training is 31.270292207792206\n",
            "Epoch #0. Accuracy on batch 308 on Training is 31.25\n",
            "Epoch #0. Accuracy on batch 309 on Training is 31.25\n",
            "Epoch #0. Accuracy on batch 310 on Training is 31.189710610932476\n",
            "Epoch #0. Accuracy on batch 311 on Training is 31.189903846153847\n",
            "Epoch #0. Accuracy on batch 312 on Training is 31.200079872204473\n",
            "Epoch #0. Accuracy on batch 313 on Training is 31.230095541401273\n",
            "Epoch #0. Accuracy on batch 314 on Training is 31.21031746031746\n",
            "Epoch #0. Accuracy on batch 315 on Training is 31.190664556962027\n",
            "Epoch #0. Accuracy on batch 316 on Training is 31.20070977917981\n",
            "Epoch #0. Accuracy on batch 317 on Training is 31.200864779874212\n",
            "Epoch #0. Accuracy on batch 318 on Training is 31.171630094043888\n",
            "Epoch #0. Accuracy on batch 319 on Training is 31.181640625\n",
            "Batch Id 320 is having training loss of 167.9972381591797\n",
            "194.17222595214844\n",
            "Epoch #0. Accuracy on batch 320 on Training is 31.19158878504673\n",
            "Epoch #0. Accuracy on batch 321 on Training is 31.191770186335404\n",
            "Epoch #0. Accuracy on batch 322 on Training is 31.211300309597522\n",
            "Epoch #0. Accuracy on batch 323 on Training is 31.19212962962963\n",
            "Epoch #0. Accuracy on batch 324 on Training is 31.192307692307693\n",
            "Epoch #0. Accuracy on batch 325 on Training is 31.182898773006134\n",
            "Epoch #0. Accuracy on batch 326 on Training is 31.192660550458715\n",
            "Epoch #0. Accuracy on batch 327 on Training is 31.164253048780488\n",
            "Epoch #0. Accuracy on batch 328 on Training is 31.14551671732523\n",
            "Epoch #0. Accuracy on batch 329 on Training is 31.126893939393938\n",
            "Epoch #0. Accuracy on batch 330 on Training is 31.117824773413897\n",
            "Epoch #0. Accuracy on batch 331 on Training is 31.108810240963855\n",
            "Epoch #0. Accuracy on batch 332 on Training is 31.09984984984985\n",
            "Epoch #0. Accuracy on batch 333 on Training is 31.119011976047904\n",
            "Epoch #0. Accuracy on batch 334 on Training is 31.100746268656717\n",
            "Epoch #0. Accuracy on batch 335 on Training is 31.110491071428573\n",
            "Epoch #0. Accuracy on batch 336 on Training is 31.101632047477747\n",
            "Epoch #0. Accuracy on batch 337 on Training is 31.10207100591716\n",
            "Epoch #0. Accuracy on batch 338 on Training is 31.148598820058996\n",
            "Epoch #0. Accuracy on batch 339 on Training is 31.14889705882353\n",
            "Batch Id 340 is having training loss of 162.66622924804688\n",
            "121.63903045654297\n",
            "Epoch #0. Accuracy on batch 340 on Training is 31.158357771261\n",
            "Epoch #0. Accuracy on batch 341 on Training is 31.158625730994153\n",
            "Epoch #0. Accuracy on batch 342 on Training is 31.18622448979592\n",
            "Epoch #0. Accuracy on batch 343 on Training is 31.231831395348838\n",
            "Epoch #0. Accuracy on batch 344 on Training is 31.259057971014492\n",
            "Epoch #0. Accuracy on batch 345 on Training is 31.268063583815028\n",
            "Epoch #0. Accuracy on batch 346 on Training is 31.25\n",
            "Epoch #0. Accuracy on batch 347 on Training is 31.25\n",
            "Epoch #0. Accuracy on batch 348 on Training is 31.241045845272208\n",
            "Epoch #0. Accuracy on batch 349 on Training is 31.267857142857142\n",
            "Epoch #0. Accuracy on batch 350 on Training is 31.285612535612536\n",
            "Epoch #0. Accuracy on batch 351 on Training is 31.312144886363637\n",
            "Epoch #0. Accuracy on batch 352 on Training is 31.311968838526912\n",
            "Epoch #0. Accuracy on batch 353 on Training is 31.34710451977401\n",
            "Epoch #0. Accuracy on batch 354 on Training is 31.302816901408452\n",
            "Epoch #0. Accuracy on batch 355 on Training is 31.337780898876403\n",
            "Epoch #0. Accuracy on batch 356 on Training is 31.32878151260504\n",
            "Epoch #0. Accuracy on batch 357 on Training is 31.363477653631286\n",
            "Epoch #0. Accuracy on batch 358 on Training is 31.38057103064067\n",
            "Epoch #0. Accuracy on batch 359 on Training is 31.40625\n",
            "Batch Id 360 is having training loss of 162.66656494140625\n",
            "103.7140884399414\n",
            "Epoch #0. Accuracy on batch 360 on Training is 31.388504155124654\n",
            "Epoch #0. Accuracy on batch 361 on Training is 31.379488950276244\n",
            "Epoch #0. Accuracy on batch 362 on Training is 31.35330578512397\n",
            "Epoch #0. Accuracy on batch 363 on Training is 31.37877747252747\n",
            "Epoch #0. Accuracy on batch 364 on Training is 31.335616438356166\n",
            "Epoch #0. Accuracy on batch 365 on Training is 31.343920765027324\n",
            "Epoch #0. Accuracy on batch 366 on Training is 31.33514986376022\n",
            "Epoch #0. Accuracy on batch 367 on Training is 31.343410326086957\n",
            "Epoch #0. Accuracy on batch 368 on Training is 31.377032520325205\n",
            "Epoch #0. Accuracy on batch 369 on Training is 31.368243243243242\n",
            "Epoch #0. Accuracy on batch 370 on Training is 31.367924528301888\n",
            "Epoch #0. Accuracy on batch 371 on Training is 31.376008064516128\n",
            "Epoch #0. Accuracy on batch 372 on Training is 31.400804289544237\n",
            "Epoch #0. Accuracy on batch 373 on Training is 31.38368983957219\n",
            "Epoch #0. Accuracy on batch 374 on Training is 31.408333333333335\n",
            "Epoch #0. Accuracy on batch 375 on Training is 31.407912234042552\n",
            "Epoch #0. Accuracy on batch 376 on Training is 31.43236074270557\n",
            "Epoch #0. Accuracy on batch 377 on Training is 31.42361111111111\n",
            "Epoch #0. Accuracy on batch 378 on Training is 31.40666226912929\n",
            "Epoch #0. Accuracy on batch 379 on Training is 31.414473684210527\n",
            "Batch Id 380 is having training loss of 168.46315002441406\n",
            "20.912273406982422\n",
            "Epoch #0. Accuracy on batch 380 on Training is 31.414041994750654\n",
            "Epoch #0. Accuracy on batch 381 on Training is 31.397251308900522\n",
            "Epoch #0. Accuracy on batch 382 on Training is 31.39686684073107\n",
            "Epoch #0. Accuracy on batch 383 on Training is 31.380208333333332\n",
            "Epoch #0. Accuracy on batch 384 on Training is 31.38798701298701\n",
            "Epoch #0. Accuracy on batch 385 on Training is 31.379533678756477\n",
            "Epoch #0. Accuracy on batch 386 on Training is 31.363049095607234\n",
            "Epoch #0. Accuracy on batch 387 on Training is 31.346649484536083\n",
            "Epoch #0. Accuracy on batch 388 on Training is 31.346401028277636\n",
            "Epoch #0. Accuracy on batch 389 on Training is 31.370192307692307\n",
            "Epoch #0. Accuracy on batch 390 on Training is 31.377877237851663\n",
            "Epoch #0. Accuracy on batch 391 on Training is 31.385522959183675\n",
            "Epoch #0. Accuracy on batch 392 on Training is 31.353371501272264\n",
            "Epoch #0. Accuracy on batch 393 on Training is 31.313451776649746\n",
            "Epoch #0. Accuracy on batch 394 on Training is 31.305379746835442\n",
            "Epoch #0. Accuracy on batch 395 on Training is 31.3052398989899\n",
            "Epoch #0. Accuracy on batch 396 on Training is 31.28935768261965\n",
            "Epoch #0. Accuracy on batch 397 on Training is 31.320665829145728\n",
            "Epoch #0. Accuracy on batch 398 on Training is 31.320488721804512\n",
            "Epoch #0. Accuracy on batch 399 on Training is 31.3125\n",
            "Batch Id 400 is having training loss of 166.1466064453125\n",
            "27.091197967529297\n",
            "Epoch #0. Accuracy on batch 400 on Training is 31.320137157107233\n",
            "Epoch #0. Accuracy on batch 401 on Training is 31.34328358208955\n",
            "Epoch #0. Accuracy on batch 402 on Training is 31.33529776674938\n",
            "Epoch #0. Accuracy on batch 403 on Training is 31.288675742574256\n",
            "Epoch #0. Accuracy on batch 404 on Training is 31.280864197530864\n",
            "Epoch #0. Accuracy on batch 405 on Training is 31.25\n",
            "Epoch #0. Accuracy on batch 406 on Training is 31.288390663390665\n",
            "Epoch #0. Accuracy on batch 407 on Training is 31.28829656862745\n",
            "Epoch #0. Accuracy on batch 408 on Training is 31.295843520782395\n",
            "Epoch #0. Accuracy on batch 409 on Training is 31.28048780487805\n",
            "Epoch #0. Accuracy on batch 410 on Training is 31.280413625304135\n",
            "Epoch #0. Accuracy on batch 411 on Training is 31.272754854368934\n",
            "Epoch #0. Accuracy on batch 412 on Training is 31.265133171912833\n",
            "Epoch #0. Accuracy on batch 413 on Training is 31.257548309178745\n",
            "Epoch #0. Accuracy on batch 414 on Training is 31.212349397590362\n",
            "Epoch #0. Accuracy on batch 415 on Training is 31.24248798076923\n",
            "Epoch #0. Accuracy on batch 416 on Training is 31.257494004796165\n",
            "Epoch #0. Accuracy on batch 417 on Training is 31.242523923444978\n",
            "Epoch #0. Accuracy on batch 418 on Training is 31.25\n",
            "Epoch #0. Accuracy on batch 419 on Training is 31.25\n",
            "Batch Id 420 is having training loss of 173.97422790527344\n",
            "3498.1669921875\n",
            "Epoch #0. Accuracy on batch 420 on Training is 31.264845605700714\n",
            "Epoch #0. Accuracy on batch 421 on Training is 31.301836492890995\n",
            "Epoch #0. Accuracy on batch 422 on Training is 31.29432624113475\n",
            "Epoch #0. Accuracy on batch 423 on Training is 31.31633254716981\n",
            "Epoch #0. Accuracy on batch 424 on Training is 31.272058823529413\n",
            "Epoch #0. Accuracy on batch 425 on Training is 31.301349765258216\n",
            "Epoch #0. Accuracy on batch 426 on Training is 31.31586651053864\n",
            "Epoch #0. Accuracy on batch 427 on Training is 31.31571261682243\n",
            "Epoch #0. Accuracy on batch 428 on Training is 31.308275058275058\n",
            "Epoch #0. Accuracy on batch 429 on Training is 31.29360465116279\n",
            "Epoch #0. Accuracy on batch 430 on Training is 31.29350348027842\n",
            "Epoch #0. Accuracy on batch 431 on Training is 31.300636574074073\n",
            "Epoch #0. Accuracy on batch 432 on Training is 31.329387990762125\n",
            "Epoch #0. Accuracy on batch 433 on Training is 31.314804147465438\n",
            "Epoch #0. Accuracy on batch 434 on Training is 31.314655172413794\n",
            "Epoch #0. Accuracy on batch 435 on Training is 31.285837155963304\n",
            "Epoch #0. Accuracy on batch 436 on Training is 31.26430205949657\n",
            "Epoch #0. Accuracy on batch 437 on Training is 31.25\n",
            "Epoch #0. Accuracy on batch 438 on Training is 31.25\n",
            "Epoch #0. Accuracy on batch 439 on Training is 31.228693181818183\n",
            "Batch Id 440 is having training loss of 171.62631225585938\n",
            "85.26708984375\n",
            "Epoch #0. Accuracy on batch 440 on Training is 31.22874149659864\n",
            "Epoch #0. Accuracy on batch 441 on Training is 31.22878959276018\n",
            "Epoch #0. Accuracy on batch 442 on Training is 31.271162528216703\n",
            "Epoch #0. Accuracy on batch 443 on Training is 31.25703828828829\n",
            "Epoch #0. Accuracy on batch 444 on Training is 31.228932584269664\n",
            "Epoch #0. Accuracy on batch 445 on Training is 31.221973094170405\n",
            "Epoch #0. Accuracy on batch 446 on Training is 31.229026845637584\n",
            "Epoch #0. Accuracy on batch 447 on Training is 31.215122767857142\n",
            "Epoch #0. Accuracy on batch 448 on Training is 31.222160356347437\n",
            "Epoch #0. Accuracy on batch 449 on Training is 31.180555555555557\n",
            "Epoch #0. Accuracy on batch 450 on Training is 31.187638580931264\n",
            "Epoch #0. Accuracy on batch 451 on Training is 31.194690265486727\n",
            "Epoch #0. Accuracy on batch 452 on Training is 31.20171081677704\n",
            "Epoch #0. Accuracy on batch 453 on Training is 31.20181718061674\n",
            "Epoch #0. Accuracy on batch 454 on Training is 31.167582417582416\n",
            "Epoch #0. Accuracy on batch 455 on Training is 31.126644736842106\n",
            "Epoch #0. Accuracy on batch 456 on Training is 31.147428884026258\n",
            "Epoch #0. Accuracy on batch 457 on Training is 31.14765283842795\n",
            "Epoch #0. Accuracy on batch 458 on Training is 31.175108932461875\n",
            "Epoch #0. Accuracy on batch 459 on Training is 31.168478260869566\n",
            "Batch Id 460 is having training loss of 172.5104217529297\n",
            "28.701074600219727\n",
            "Epoch #0. Accuracy on batch 460 on Training is 31.161876355748372\n",
            "Epoch #0. Accuracy on batch 461 on Training is 31.128246753246753\n",
            "Epoch #0. Accuracy on batch 462 on Training is 31.142008639308855\n",
            "Epoch #0. Accuracy on batch 463 on Training is 31.14897629310345\n",
            "Epoch #0. Accuracy on batch 464 on Training is 31.129032258064516\n",
            "Epoch #0. Accuracy on batch 465 on Training is 31.089055793991417\n",
            "Epoch #0. Accuracy on batch 466 on Training is 31.089400428265524\n",
            "Epoch #0. Accuracy on batch 467 on Training is 31.08306623931624\n",
            "Epoch #0. Accuracy on batch 468 on Training is 31.103411513859275\n",
            "Epoch #0. Accuracy on batch 469 on Training is 31.10372340425532\n",
            "Epoch #0. Accuracy on batch 470 on Training is 31.10403397027601\n",
            "Epoch #0. Accuracy on batch 471 on Training is 31.110963983050848\n",
            "Epoch #0. Accuracy on batch 472 on Training is 31.13107822410148\n",
            "Epoch #0. Accuracy on batch 473 on Training is 31.157700421940927\n",
            "Epoch #0. Accuracy on batch 474 on Training is 31.151315789473685\n",
            "Epoch #0. Accuracy on batch 475 on Training is 31.151523109243698\n",
            "Epoch #0. Accuracy on batch 476 on Training is 31.125524109014677\n",
            "Epoch #0. Accuracy on batch 477 on Training is 31.119246861924687\n",
            "Epoch #0. Accuracy on batch 478 on Training is 31.126043841336116\n",
            "Epoch #0. Accuracy on batch 479 on Training is 31.09375\n",
            "Batch Id 480 is having training loss of 168.45114135742188\n",
            "50.269412994384766\n",
            "Epoch #0. Accuracy on batch 480 on Training is 31.06808731808732\n",
            "Epoch #0. Accuracy on batch 481 on Training is 31.06198132780083\n",
            "Epoch #0. Accuracy on batch 482 on Training is 31.068840579710145\n",
            "Epoch #0. Accuracy on batch 483 on Training is 31.06275826446281\n",
            "Epoch #0. Accuracy on batch 484 on Training is 31.063144329896907\n",
            "Epoch #0. Accuracy on batch 485 on Training is 31.082818930041153\n",
            "Epoch #0. Accuracy on batch 486 on Training is 31.070328542094455\n",
            "Epoch #0. Accuracy on batch 487 on Training is 31.077100409836067\n",
            "Epoch #0. Accuracy on batch 488 on Training is 31.064672801635993\n",
            "Epoch #0. Accuracy on batch 489 on Training is 31.039540816326532\n",
            "Epoch #0. Accuracy on batch 490 on Training is 31.020875763747455\n",
            "Epoch #0. Accuracy on batch 491 on Training is 31.008638211382113\n",
            "Epoch #0. Accuracy on batch 492 on Training is 31.01546653144016\n",
            "Epoch #0. Accuracy on batch 493 on Training is 31.009615384615383\n",
            "Epoch #0. Accuracy on batch 494 on Training is 31.022727272727273\n",
            "Epoch #0. Accuracy on batch 495 on Training is 31.029485887096776\n",
            "Epoch #0. Accuracy on batch 496 on Training is 31.036217303822937\n",
            "Epoch #0. Accuracy on batch 497 on Training is 31.080572289156628\n",
            "Epoch #0. Accuracy on batch 498 on Training is 31.062124248496993\n",
            "Epoch #0. Accuracy on batch 499 on Training is 31.0625\n",
            "Batch Id 500 is having training loss of 169.02322387695312\n",
            "14.52043342590332\n",
            "Epoch #0. Accuracy on batch 500 on Training is 31.075349301397207\n",
            "Epoch #0. Accuracy on batch 501 on Training is 31.069472111553786\n",
            "Epoch #0. Accuracy on batch 502 on Training is 31.057405566600398\n",
            "Epoch #0. Accuracy on batch 503 on Training is 31.0515873015873\n",
            "Epoch #0. Accuracy on batch 504 on Training is 31.014851485148515\n",
            "Epoch #0. Accuracy on batch 505 on Training is 31.015316205533598\n",
            "Epoch #0. Accuracy on batch 506 on Training is 31.021942800788956\n",
            "Epoch #0. Accuracy on batch 507 on Training is 31.040846456692915\n",
            "Epoch #0. Accuracy on batch 508 on Training is 31.05967583497053\n",
            "Epoch #0. Accuracy on batch 509 on Training is 31.07843137254902\n",
            "Epoch #0. Accuracy on batch 510 on Training is 31.054305283757337\n",
            "Epoch #0. Accuracy on batch 511 on Training is 31.06689453125\n",
            "Epoch #0. Accuracy on batch 512 on Training is 31.061159844054583\n",
            "Epoch #0. Accuracy on batch 513 on Training is 31.05544747081712\n",
            "Epoch #0. Accuracy on batch 514 on Training is 31.0376213592233\n",
            "Epoch #0. Accuracy on batch 515 on Training is 31.05014534883721\n",
            "Epoch #0. Accuracy on batch 516 on Training is 31.062620889748548\n",
            "Epoch #0. Accuracy on batch 517 on Training is 31.026785714285715\n",
            "Epoch #0. Accuracy on batch 518 on Training is 31.015173410404625\n",
            "Epoch #0. Accuracy on batch 519 on Training is 31.03966346153846\n",
            "Batch Id 520 is having training loss of 183.4346923828125\n",
            "50.99528121948242\n",
            "Epoch #0. Accuracy on batch 520 on Training is 31.04006717850288\n",
            "Epoch #0. Accuracy on batch 521 on Training is 31.03448275862069\n",
            "Epoch #0. Accuracy on batch 522 on Training is 31.02891969407266\n",
            "Epoch #0. Accuracy on batch 523 on Training is 31.029341603053435\n",
            "Epoch #0. Accuracy on batch 524 on Training is 31.017857142857142\n",
            "Epoch #0. Accuracy on batch 525 on Training is 31.01235741444867\n",
            "Epoch #0. Accuracy on batch 526 on Training is 31.006878557874764\n",
            "Epoch #0. Accuracy on batch 527 on Training is 31.001420454545453\n",
            "Epoch #0. Accuracy on batch 528 on Training is 30.995982986767487\n",
            "Epoch #0. Accuracy on batch 529 on Training is 31.00235849056604\n",
            "Epoch #0. Accuracy on batch 530 on Training is 31.0204802259887\n",
            "Epoch #0. Accuracy on batch 531 on Training is 30.997415413533833\n",
            "Epoch #0. Accuracy on batch 532 on Training is 30.997889305816134\n",
            "Epoch #0. Accuracy on batch 533 on Training is 30.99250936329588\n",
            "Epoch #0. Accuracy on batch 534 on Training is 30.992990654205606\n",
            "Epoch #0. Accuracy on batch 535 on Training is 30.964319029850746\n",
            "Epoch #0. Accuracy on batch 536 on Training is 30.970670391061454\n",
            "Epoch #0. Accuracy on batch 537 on Training is 30.971189591078065\n",
            "Epoch #0. Accuracy on batch 538 on Training is 30.95431354359926\n",
            "Epoch #0. Accuracy on batch 539 on Training is 30.96064814814815\n",
            "Batch Id 540 is having training loss of 201.09458923339844\n",
            "45.34355545043945\n",
            "Epoch #0. Accuracy on batch 540 on Training is 30.961182994454713\n",
            "Epoch #0. Accuracy on batch 541 on Training is 30.973247232472325\n",
            "Epoch #0. Accuracy on batch 542 on Training is 30.956491712707184\n",
            "Epoch #0. Accuracy on batch 543 on Training is 30.95703125\n",
            "Epoch #0. Accuracy on batch 544 on Training is 30.946100917431192\n",
            "Epoch #0. Accuracy on batch 545 on Training is 30.958104395604394\n",
            "Epoch #0. Accuracy on batch 546 on Training is 30.981489945155392\n",
            "Epoch #0. Accuracy on batch 547 on Training is 30.9819799270073\n",
            "Epoch #0. Accuracy on batch 548 on Training is 30.954007285974498\n",
            "Epoch #0. Accuracy on batch 549 on Training is 30.954545454545453\n",
            "Epoch #0. Accuracy on batch 550 on Training is 30.95508166969147\n",
            "Epoch #0. Accuracy on batch 551 on Training is 30.938632246376812\n",
            "Epoch #0. Accuracy on batch 552 on Training is 30.94484629294756\n",
            "Epoch #0. Accuracy on batch 553 on Training is 30.94539711191336\n",
            "Epoch #0. Accuracy on batch 554 on Training is 30.96283783783784\n",
            "Epoch #0. Accuracy on batch 555 on Training is 30.946492805755394\n",
            "Epoch #0. Accuracy on batch 556 on Training is 30.9245960502693\n",
            "Epoch #0. Accuracy on batch 557 on Training is 30.919578853046595\n",
            "Epoch #0. Accuracy on batch 558 on Training is 30.931350626118068\n",
            "Epoch #0. Accuracy on batch 559 on Training is 30.943080357142858\n",
            "Batch Id 560 is having training loss of 195.20068359375\n",
            "27.20071792602539\n",
            "Epoch #0. Accuracy on batch 560 on Training is 30.943627450980394\n",
            "Epoch #0. Accuracy on batch 561 on Training is 30.95529359430605\n",
            "Epoch #0. Accuracy on batch 562 on Training is 30.966918294849023\n",
            "Epoch #0. Accuracy on batch 563 on Training is 30.989583333333332\n",
            "Epoch #0. Accuracy on batch 564 on Training is 30.995575221238937\n",
            "Epoch #0. Accuracy on batch 565 on Training is 30.973939929328623\n",
            "Epoch #0. Accuracy on batch 566 on Training is 30.963403880070548\n",
            "Epoch #0. Accuracy on batch 567 on Training is 30.969410211267604\n",
            "Epoch #0. Accuracy on batch 568 on Training is 30.964411247803163\n",
            "Epoch #0. Accuracy on batch 569 on Training is 30.948464912280702\n",
            "Epoch #0. Accuracy on batch 570 on Training is 30.97088441330998\n",
            "Epoch #0. Accuracy on batch 571 on Training is 30.993225524475523\n",
            "Epoch #0. Accuracy on batch 572 on Training is 30.98821989528796\n",
            "Epoch #0. Accuracy on batch 573 on Training is 30.988675958188153\n",
            "Epoch #0. Accuracy on batch 574 on Training is 31.016304347826086\n",
            "Epoch #0. Accuracy on batch 575 on Training is 31.03298611111111\n",
            "Epoch #0. Accuracy on batch 576 on Training is 31.038778162911612\n",
            "Epoch #0. Accuracy on batch 577 on Training is 31.044550173010382\n",
            "Epoch #0. Accuracy on batch 578 on Training is 31.01252158894646\n",
            "Epoch #0. Accuracy on batch 579 on Training is 31.018318965517242\n",
            "Batch Id 580 is having training loss of 197.9913787841797\n",
            "17.63081169128418\n",
            "Epoch #0. Accuracy on batch 580 on Training is 31.013339070567987\n",
            "Epoch #0. Accuracy on batch 581 on Training is 31.024484536082475\n",
            "Epoch #0. Accuracy on batch 582 on Training is 31.024871355060036\n",
            "Epoch #0. Accuracy on batch 583 on Training is 31.01990582191781\n",
            "Epoch #0. Accuracy on batch 584 on Training is 31.030982905982906\n",
            "Epoch #0. Accuracy on batch 585 on Training is 31.04202218430034\n",
            "Epoch #0. Accuracy on batch 586 on Training is 31.04770017035775\n",
            "Epoch #0. Accuracy on batch 587 on Training is 31.048044217687075\n",
            "Epoch #0. Accuracy on batch 588 on Training is 31.05369269949066\n",
            "Epoch #0. Accuracy on batch 589 on Training is 31.064618644067796\n",
            "Epoch #0. Accuracy on batch 590 on Training is 31.06493231810491\n",
            "Epoch #0. Accuracy on batch 591 on Training is 31.075802364864863\n",
            "Epoch #0. Accuracy on batch 592 on Training is 31.055016863406408\n",
            "Epoch #0. Accuracy on batch 593 on Training is 31.050084175084177\n",
            "Epoch #0. Accuracy on batch 594 on Training is 31.024159663865547\n",
            "Epoch #0. Accuracy on batch 595 on Training is 31.035025167785236\n",
            "Epoch #0. Accuracy on batch 596 on Training is 31.03538525963149\n",
            "Epoch #0. Accuracy on batch 597 on Training is 31.025292642140467\n",
            "Epoch #0. Accuracy on batch 598 on Training is 31.041318864774624\n",
            "Epoch #0. Accuracy on batch 599 on Training is 31.072916666666668\n",
            "Batch Id 600 is having training loss of 207.41371154785156\n",
            "8983.314453125\n",
            "Epoch #0. Accuracy on batch 600 on Training is 31.062811980033278\n",
            "Epoch #0. Accuracy on batch 601 on Training is 31.06831395348837\n",
            "Epoch #0. Accuracy on batch 602 on Training is 31.078980099502488\n",
            "Epoch #0. Accuracy on batch 603 on Training is 31.07926324503311\n",
            "Epoch #0. Accuracy on batch 604 on Training is 31.074380165289256\n",
            "Epoch #0. Accuracy on batch 605 on Training is 31.074669966996698\n",
            "Epoch #0. Accuracy on batch 606 on Training is 31.069810543657333\n",
            "Epoch #0. Accuracy on batch 607 on Training is 31.0546875\n",
            "Epoch #0. Accuracy on batch 608 on Training is 31.044745484400657\n",
            "Epoch #0. Accuracy on batch 609 on Training is 31.0297131147541\n",
            "Epoch #0. Accuracy on batch 610 on Training is 31.030073649754502\n",
            "Epoch #0. Accuracy on batch 611 on Training is 31.035539215686274\n",
            "Epoch #0. Accuracy on batch 612 on Training is 31.040986949429037\n",
            "Epoch #0. Accuracy on batch 613 on Training is 31.082043973941367\n",
            "Epoch #0. Accuracy on batch 614 on Training is 31.08739837398374\n",
            "Epoch #0. Accuracy on batch 615 on Training is 31.087662337662337\n",
            "Epoch #0. Accuracy on batch 616 on Training is 31.07273095623987\n",
            "Epoch #0. Accuracy on batch 617 on Training is 31.052791262135923\n",
            "Epoch #0. Accuracy on batch 618 on Training is 31.04806138933764\n",
            "Epoch #0. Accuracy on batch 619 on Training is 31.05342741935484\n",
            "Batch Id 620 is having training loss of 245.0367889404297\n",
            "7794.02978515625\n",
            "Epoch #0. Accuracy on batch 620 on Training is 31.05877616747182\n",
            "Epoch #0. Accuracy on batch 621 on Training is 31.054059485530548\n",
            "Epoch #0. Accuracy on batch 622 on Training is 31.044341894060995\n",
            "Epoch #0. Accuracy on batch 623 on Training is 31.059695512820515\n",
            "Epoch #0. Accuracy on batch 624 on Training is 31.075\n",
            "Epoch #0. Accuracy on batch 625 on Training is 31.05031948881789\n",
            "Epoch #0. Accuracy on batch 626 on Training is 31.030701754385966\n",
            "Epoch #0. Accuracy on batch 627 on Training is 31.045979299363058\n",
            "Epoch #0. Accuracy on batch 628 on Training is 31.046303656597775\n",
            "Epoch #0. Accuracy on batch 629 on Training is 31.041666666666668\n",
            "Epoch #0. Accuracy on batch 630 on Training is 31.046949286846274\n",
            "Epoch #0. Accuracy on batch 631 on Training is 31.047270569620252\n",
            "Epoch #0. Accuracy on batch 632 on Training is 31.04759083728278\n",
            "Epoch #0. Accuracy on batch 633 on Training is 31.01833596214511\n",
            "Epoch #0. Accuracy on batch 634 on Training is 31.003937007874015\n",
            "Epoch #0. Accuracy on batch 635 on Training is 31.00432389937107\n",
            "Epoch #0. Accuracy on batch 636 on Training is 31.004709576138147\n",
            "Epoch #0. Accuracy on batch 637 on Training is 31.03448275862069\n",
            "Epoch #0. Accuracy on batch 638 on Training is 31.010367762128325\n",
            "Epoch #0. Accuracy on batch 639 on Training is 30.9912109375\n",
            "Batch Id 640 is having training loss of 272.79510498046875\n",
            "17.936424255371094\n",
            "Epoch #0. Accuracy on batch 640 on Training is 31.006240249609984\n",
            "Epoch #0. Accuracy on batch 641 on Training is 30.992017133956388\n",
            "Epoch #0. Accuracy on batch 642 on Training is 30.982698289269052\n",
            "Epoch #0. Accuracy on batch 643 on Training is 30.96370341614907\n",
            "Epoch #0. Accuracy on batch 644 on Training is 30.949612403100776\n",
            "Epoch #0. Accuracy on batch 645 on Training is 30.925890092879257\n",
            "Epoch #0. Accuracy on batch 646 on Training is 30.921561051004637\n",
            "Epoch #0. Accuracy on batch 647 on Training is 30.912422839506174\n",
            "Epoch #0. Accuracy on batch 648 on Training is 30.893682588597844\n",
            "Epoch #0. Accuracy on batch 649 on Training is 30.870192307692307\n",
            "Epoch #0. Accuracy on batch 650 on Training is 30.85157450076805\n",
            "Epoch #0. Accuracy on batch 651 on Training is 30.84739263803681\n",
            "Epoch #0. Accuracy on batch 652 on Training is 30.824081163859113\n",
            "Epoch #0. Accuracy on batch 653 on Training is 30.81995412844037\n",
            "Epoch #0. Accuracy on batch 654 on Training is 30.825381679389313\n",
            "Epoch #0. Accuracy on batch 655 on Training is 30.84984756097561\n",
            "Epoch #0. Accuracy on batch 656 on Training is 30.85521308980213\n",
            "Epoch #0. Accuracy on batch 657 on Training is 30.836816109422493\n",
            "Epoch #0. Accuracy on batch 658 on Training is 30.842185128983306\n",
            "Epoch #0. Accuracy on batch 659 on Training is 30.84753787878788\n",
            "Batch Id 660 is having training loss of 271.91546630859375\n",
            "113.86167907714844\n",
            "Epoch #0. Accuracy on batch 660 on Training is 30.87178517397882\n",
            "Epoch #0. Accuracy on batch 661 on Training is 30.867635951661633\n",
            "Epoch #0. Accuracy on batch 662 on Training is 30.868212669683256\n",
            "Epoch #0. Accuracy on batch 663 on Training is 30.84996234939759\n",
            "Epoch #0. Accuracy on batch 664 on Training is 30.827067669172934\n",
            "Epoch #0. Accuracy on batch 665 on Training is 30.832394894894893\n",
            "Epoch #0. Accuracy on batch 666 on Training is 30.837706146926536\n",
            "Epoch #0. Accuracy on batch 667 on Training is 30.857035928143713\n",
            "Epoch #0. Accuracy on batch 668 on Training is 30.86229446935725\n",
            "Epoch #0. Accuracy on batch 669 on Training is 30.867537313432837\n",
            "Epoch #0. Accuracy on batch 670 on Training is 30.844821162444113\n",
            "Epoch #0. Accuracy on batch 671 on Training is 30.826822916666668\n",
            "Epoch #0. Accuracy on batch 672 on Training is 30.818164933135215\n",
            "Epoch #0. Accuracy on batch 673 on Training is 30.828078635014837\n",
            "Epoch #0. Accuracy on batch 674 on Training is 30.84259259259259\n",
            "Epoch #0. Accuracy on batch 675 on Training is 30.84319526627219\n",
            "Epoch #0. Accuracy on batch 676 on Training is 30.834564254062037\n",
            "Epoch #0. Accuracy on batch 677 on Training is 30.835176991150444\n",
            "Epoch #0. Accuracy on batch 678 on Training is 30.84499263622975\n",
            "Epoch #0. Accuracy on batch 679 on Training is 30.859375\n",
            "Batch Id 680 is having training loss of 286.3672180175781\n",
            "24.396276473999023\n",
            "Epoch #0. Accuracy on batch 680 on Training is 30.87830396475771\n",
            "Epoch #0. Accuracy on batch 681 on Training is 30.860520527859236\n",
            "Epoch #0. Accuracy on batch 682 on Training is 30.87024158125915\n",
            "Epoch #0. Accuracy on batch 683 on Training is 30.87079678362573\n",
            "Epoch #0. Accuracy on batch 684 on Training is 30.875912408759124\n",
            "Epoch #0. Accuracy on batch 685 on Training is 30.89012390670554\n",
            "Epoch #0. Accuracy on batch 686 on Training is 30.877001455604077\n",
            "Epoch #0. Accuracy on batch 687 on Training is 30.882085755813954\n",
            "Epoch #0. Accuracy on batch 688 on Training is 30.887155297532654\n",
            "Epoch #0. Accuracy on batch 689 on Training is 30.89673913043478\n",
            "Epoch #0. Accuracy on batch 690 on Training is 30.88820549927641\n",
            "Epoch #0. Accuracy on batch 691 on Training is 30.88872832369942\n",
            "Epoch #0. Accuracy on batch 692 on Training is 30.889249639249638\n",
            "Epoch #0. Accuracy on batch 693 on Training is 30.88076368876081\n",
            "Epoch #0. Accuracy on batch 694 on Training is 30.863309352517987\n",
            "Epoch #0. Accuracy on batch 695 on Training is 30.859375\n",
            "Epoch #0. Accuracy on batch 696 on Training is 30.85545193687231\n",
            "Epoch #0. Accuracy on batch 697 on Training is 30.873925501432666\n",
            "Epoch #0. Accuracy on batch 698 on Training is 30.87893419170243\n",
            "Epoch #0. Accuracy on batch 699 on Training is 30.883928571428573\n",
            "Batch Id 700 is having training loss of 303.78173828125\n",
            "89.73249053955078\n",
            "Epoch #0. Accuracy on batch 700 on Training is 30.87107703281027\n",
            "Epoch #0. Accuracy on batch 701 on Training is 30.858262108262107\n",
            "Epoch #0. Accuracy on batch 702 on Training is 30.863264580369844\n",
            "Epoch #0. Accuracy on batch 703 on Training is 30.854936079545453\n",
            "Epoch #0. Accuracy on batch 704 on Training is 30.877659574468087\n",
            "Epoch #0. Accuracy on batch 705 on Training is 30.878186968838527\n",
            "Epoch #0. Accuracy on batch 706 on Training is 30.8742927864215\n",
            "Epoch #0. Accuracy on batch 707 on Training is 30.870409604519775\n",
            "Epoch #0. Accuracy on batch 708 on Training is 30.8577221438646\n",
            "Epoch #0. Accuracy on batch 709 on Training is 30.85387323943662\n",
            "Epoch #0. Accuracy on batch 710 on Training is 30.854430379746834\n",
            "Epoch #0. Accuracy on batch 711 on Training is 30.84620786516854\n",
            "Epoch #0. Accuracy on batch 712 on Training is 30.855539971949508\n",
            "Epoch #0. Accuracy on batch 713 on Training is 30.83858543417367\n",
            "Epoch #0. Accuracy on batch 714 on Training is 30.847902097902097\n",
            "Epoch #0. Accuracy on batch 715 on Training is 30.83973463687151\n",
            "Epoch #0. Accuracy on batch 716 on Training is 30.82287308228731\n",
            "Epoch #0. Accuracy on batch 717 on Training is 30.827820334261837\n",
            "Epoch #0. Accuracy on batch 718 on Training is 30.806675938803895\n",
            "Epoch #0. Accuracy on batch 719 on Training is 30.811631944444443\n",
            "Batch Id 720 is having training loss of 320.5793762207031\n",
            "36.310604095458984\n",
            "Epoch #0. Accuracy on batch 720 on Training is 30.816574202496533\n",
            "Epoch #0. Accuracy on batch 721 on Training is 30.81284626038781\n",
            "Epoch #0. Accuracy on batch 722 on Training is 30.81777316735823\n",
            "Epoch #0. Accuracy on batch 723 on Training is 30.79678867403315\n",
            "Epoch #0. Accuracy on batch 724 on Training is 30.79310344827586\n",
            "Epoch #0. Accuracy on batch 725 on Training is 30.78081955922865\n",
            "Epoch #0. Accuracy on batch 726 on Training is 30.798658872077027\n",
            "Epoch #0. Accuracy on batch 727 on Training is 30.80786401098901\n",
            "Epoch #0. Accuracy on batch 728 on Training is 30.80418381344307\n",
            "Epoch #0. Accuracy on batch 729 on Training is 30.804794520547944\n",
            "Epoch #0. Accuracy on batch 730 on Training is 30.792578659370726\n",
            "Epoch #0. Accuracy on batch 731 on Training is 30.78893442622951\n",
            "Epoch #0. Accuracy on batch 732 on Training is 30.78956343792633\n",
            "Epoch #0. Accuracy on batch 733 on Training is 30.815735694822887\n",
            "Epoch #0. Accuracy on batch 734 on Training is 30.812074829931973\n",
            "Epoch #0. Accuracy on batch 735 on Training is 30.78719429347826\n",
            "Epoch #0. Accuracy on batch 736 on Training is 30.78782225237449\n",
            "Epoch #0. Accuracy on batch 737 on Training is 30.801151761517616\n",
            "Epoch #0. Accuracy on batch 738 on Training is 30.793301759133964\n",
            "Epoch #0. Accuracy on batch 739 on Training is 30.789695945945947\n",
            "Batch Id 740 is having training loss of 313.8100891113281\n",
            "13.9186429977417\n",
            "Epoch #0. Accuracy on batch 740 on Training is 30.798751686909583\n",
            "Epoch #0. Accuracy on batch 741 on Training is 30.79935983827493\n",
            "Epoch #0. Accuracy on batch 742 on Training is 30.804172274562585\n",
            "Epoch #0. Accuracy on batch 743 on Training is 30.787970430107528\n",
            "Epoch #0. Accuracy on batch 744 on Training is 30.784395973154364\n",
            "Epoch #0. Accuracy on batch 745 on Training is 30.759886058981234\n",
            "Epoch #0. Accuracy on batch 746 on Training is 30.7605421686747\n",
            "Epoch #0. Accuracy on batch 747 on Training is 30.74866310160428\n",
            "Epoch #0. Accuracy on batch 748 on Training is 30.753504672897197\n",
            "Epoch #0. Accuracy on batch 749 on Training is 30.754166666666666\n",
            "Epoch #0. Accuracy on batch 750 on Training is 30.758988015978694\n",
            "Epoch #0. Accuracy on batch 751 on Training is 30.75132978723404\n",
            "Epoch #0. Accuracy on batch 752 on Training is 30.747841965471448\n",
            "Epoch #0. Accuracy on batch 753 on Training is 30.74850795755968\n",
            "Epoch #0. Accuracy on batch 754 on Training is 30.72433774834437\n",
            "Epoch #0. Accuracy on batch 755 on Training is 30.712632275132275\n",
            "Epoch #0. Accuracy on batch 756 on Training is 30.688573315719946\n",
            "Epoch #0. Accuracy on batch 757 on Training is 30.681068601583114\n",
            "Epoch #0. Accuracy on batch 758 on Training is 30.702404479578394\n",
            "Epoch #0. Accuracy on batch 759 on Training is 30.699013157894736\n",
            "Batch Id 760 is having training loss of 320.03839111328125\n",
            "33.2659912109375\n",
            "Epoch #0. Accuracy on batch 760 on Training is 30.707950065703024\n",
            "Epoch #0. Accuracy on batch 761 on Training is 30.729166666666668\n",
            "Epoch #0. Accuracy on batch 762 on Training is 30.7175622542595\n",
            "Epoch #0. Accuracy on batch 763 on Training is 30.722349476439792\n",
            "Epoch #0. Accuracy on batch 764 on Training is 30.731209150326798\n",
            "Epoch #0. Accuracy on batch 765 on Training is 30.715567885117494\n",
            "Epoch #0. Accuracy on batch 766 on Training is 30.704041720990872\n",
            "Epoch #0. Accuracy on batch 767 on Training is 30.692545572916668\n",
            "Epoch #0. Accuracy on batch 768 on Training is 30.689206762028608\n",
            "Epoch #0. Accuracy on batch 769 on Training is 30.693993506493506\n",
            "Epoch #0. Accuracy on batch 770 on Training is 30.70282101167315\n",
            "Epoch #0. Accuracy on batch 771 on Training is 30.715673575129532\n",
            "Epoch #0. Accuracy on batch 772 on Training is 30.69210866752911\n",
            "Epoch #0. Accuracy on batch 773 on Training is 30.708979328165373\n",
            "Epoch #0. Accuracy on batch 774 on Training is 30.705645161290324\n",
            "Epoch #0. Accuracy on batch 775 on Training is 30.702319587628867\n",
            "Epoch #0. Accuracy on batch 776 on Training is 30.707046332046332\n",
            "Epoch #0. Accuracy on batch 777 on Training is 30.703727506426734\n",
            "Epoch #0. Accuracy on batch 778 on Training is 30.716463414634145\n",
            "Epoch #0. Accuracy on batch 779 on Training is 30.733173076923077\n",
            "Batch Id 780 is having training loss of 333.8913269042969\n",
            "65.71615600585938\n",
            "Epoch #0. Accuracy on batch 780 on Training is 30.729833546734955\n",
            "Epoch #0. Accuracy on batch 781 on Training is 30.74648337595908\n",
            "Epoch #0. Accuracy on batch 782 on Training is 30.74712643678161\n",
            "Epoch #0. Accuracy on batch 783 on Training is 30.735809948979593\n",
            "Epoch #0. Accuracy on batch 784 on Training is 30.71656050955414\n",
            "Epoch #0. Accuracy on batch 785 on Training is 30.721215012722645\n",
            "Epoch #0. Accuracy on batch 786 on Training is 30.729828462515883\n",
            "Epoch #0. Accuracy on batch 787 on Training is 30.722557106598984\n",
            "Epoch #0. Accuracy on batch 788 on Training is 30.746989860583017\n",
            "Epoch #0. Accuracy on batch 789 on Training is 30.74367088607595\n",
            "Epoch #0. Accuracy on batch 790 on Training is 30.748261694058154\n",
            "Epoch #0. Accuracy on batch 791 on Training is 30.76073232323232\n",
            "Epoch #0. Accuracy on batch 792 on Training is 30.757408575031526\n",
            "Epoch #0. Accuracy on batch 793 on Training is 30.75015743073048\n",
            "Epoch #0. Accuracy on batch 794 on Training is 30.738993710691823\n",
            "Epoch #0. Accuracy on batch 795 on Training is 30.759265075376884\n",
            "Epoch #0. Accuracy on batch 796 on Training is 30.752038895859474\n",
            "Epoch #0. Accuracy on batch 797 on Training is 30.729166666666668\n",
            "Epoch #0. Accuracy on batch 798 on Training is 30.721996245306634\n",
            "Epoch #0. Accuracy on batch 799 on Training is 30.7109375\n",
            "Batch Id 800 is having training loss of 343.785888671875\n",
            "27.745771408081055\n",
            "Epoch #0. Accuracy on batch 800 on Training is 30.70770911360799\n",
            "Epoch #0. Accuracy on batch 801 on Training is 30.71228179551122\n",
            "Epoch #0. Accuracy on batch 802 on Training is 30.705168119551683\n",
            "Epoch #0. Accuracy on batch 803 on Training is 30.70195895522388\n",
            "Epoch #0. Accuracy on batch 804 on Training is 30.710403726708076\n",
            "Epoch #0. Accuracy on batch 805 on Training is 30.722704714640198\n",
            "Epoch #0. Accuracy on batch 806 on Training is 30.727230483271377\n",
            "Epoch #0. Accuracy on batch 807 on Training is 30.75108292079208\n",
            "Epoch #0. Accuracy on batch 808 on Training is 30.751699629171817\n",
            "Epoch #0. Accuracy on batch 809 on Training is 30.736882716049383\n",
            "Epoch #0. Accuracy on batch 810 on Training is 30.733662145499384\n",
            "Epoch #0. Accuracy on batch 811 on Training is 30.726600985221676\n",
            "Epoch #0. Accuracy on batch 812 on Training is 30.727244772447726\n",
            "Epoch #0. Accuracy on batch 813 on Training is 30.735565110565112\n",
            "Epoch #0. Accuracy on batch 814 on Training is 30.736196319018404\n",
            "Epoch #0. Accuracy on batch 815 on Training is 30.732996323529413\n",
            "Epoch #0. Accuracy on batch 816 on Training is 30.725979192166463\n",
            "Epoch #0. Accuracy on batch 817 on Training is 30.718979217603913\n",
            "Epoch #0. Accuracy on batch 818 on Training is 30.70818070818071\n",
            "Epoch #0. Accuracy on batch 819 on Training is 30.708841463414632\n",
            "Batch Id 820 is having training loss of 341.7250671386719\n",
            "56.65129089355469\n",
            "Epoch #0. Accuracy on batch 820 on Training is 30.690468940316688\n",
            "Epoch #0. Accuracy on batch 821 on Training is 30.691149635036496\n",
            "Epoch #0. Accuracy on batch 822 on Training is 30.688031591737545\n",
            "Epoch #0. Accuracy on batch 823 on Training is 30.6811286407767\n",
            "Epoch #0. Accuracy on batch 824 on Training is 30.666666666666668\n",
            "Epoch #0. Accuracy on batch 825 on Training is 30.67115617433414\n",
            "Epoch #0. Accuracy on batch 826 on Training is 30.671856106408708\n",
            "Epoch #0. Accuracy on batch 827 on Training is 30.661231884057973\n",
            "Epoch #0. Accuracy on batch 828 on Training is 30.673250904704464\n",
            "Epoch #0. Accuracy on batch 829 on Training is 30.677710843373493\n",
            "Epoch #0. Accuracy on batch 830 on Training is 30.667117930204572\n",
            "Epoch #0. Accuracy on batch 831 on Training is 30.682842548076923\n",
            "Epoch #0. Accuracy on batch 832 on Training is 30.661014405762305\n",
            "Epoch #0. Accuracy on batch 833 on Training is 30.646732613908874\n",
            "Epoch #0. Accuracy on batch 834 on Training is 30.625\n",
            "Epoch #0. Accuracy on batch 835 on Training is 30.610795454545453\n",
            "Epoch #0. Accuracy on batch 836 on Training is 30.600358422939067\n",
            "Epoch #0. Accuracy on batch 837 on Training is 30.60486276849642\n",
            "Epoch #0. Accuracy on batch 838 on Training is 30.62053039332539\n",
            "Epoch #0. Accuracy on batch 839 on Training is 30.617559523809526\n",
            "Batch Id 840 is having training loss of 361.3940124511719\n",
            "9.321191787719727\n",
            "Epoch #0. Accuracy on batch 840 on Training is 30.636890606420927\n",
            "Epoch #0. Accuracy on batch 841 on Training is 30.62648456057007\n",
            "Epoch #0. Accuracy on batch 842 on Training is 30.612396204033214\n",
            "Epoch #0. Accuracy on batch 843 on Training is 30.616854265402843\n",
            "Epoch #0. Accuracy on batch 844 on Training is 30.632396449704142\n",
            "Epoch #0. Accuracy on batch 845 on Training is 30.640514184397162\n",
            "Epoch #0. Accuracy on batch 846 on Training is 30.633854781582055\n",
            "Epoch #0. Accuracy on batch 847 on Training is 30.623525943396228\n",
            "Epoch #0. Accuracy on batch 848 on Training is 30.609540636042404\n",
            "Epoch #0. Accuracy on batch 849 on Training is 30.59926470588235\n",
            "Epoch #0. Accuracy on batch 850 on Training is 30.585340775558166\n",
            "Epoch #0. Accuracy on batch 851 on Training is 30.593456572769952\n",
            "Epoch #0. Accuracy on batch 852 on Training is 30.590562719812425\n",
            "Epoch #0. Accuracy on batch 853 on Training is 30.591334894613585\n",
            "Epoch #0. Accuracy on batch 854 on Training is 30.58845029239766\n",
            "Epoch #0. Accuracy on batch 855 on Training is 30.578271028037385\n",
            "Epoch #0. Accuracy on batch 856 on Training is 30.57176196032672\n",
            "Epoch #0. Accuracy on batch 857 on Training is 30.572552447552447\n",
            "Epoch #0. Accuracy on batch 858 on Training is 30.57697904540163\n",
            "Epoch #0. Accuracy on batch 859 on Training is 30.59956395348837\n",
            "Batch Id 860 is having training loss of 382.2426452636719\n",
            "398.30780029296875\n",
            "Epoch #0. Accuracy on batch 860 on Training is 30.607578397212542\n",
            "Epoch #0. Accuracy on batch 861 on Training is 30.590197215777263\n",
            "Epoch #0. Accuracy on batch 862 on Training is 30.58734067207416\n",
            "Epoch #0. Accuracy on batch 863 on Training is 30.58449074074074\n",
            "Epoch #0. Accuracy on batch 864 on Training is 30.585260115606935\n",
            "Epoch #0. Accuracy on batch 865 on Training is 30.582419168591223\n",
            "Epoch #0. Accuracy on batch 866 on Training is 30.579584775086506\n",
            "Epoch #0. Accuracy on batch 867 on Training is 30.58395737327189\n",
            "Epoch #0. Accuracy on batch 868 on Training is 30.584723820483315\n",
            "Epoch #0. Accuracy on batch 869 on Training is 30.58189655172414\n",
            "Epoch #0. Accuracy on batch 870 on Training is 30.58625143513203\n",
            "Epoch #0. Accuracy on batch 871 on Training is 30.587012614678898\n",
            "Epoch #0. Accuracy on batch 872 on Training is 30.577033218785797\n",
            "Epoch #0. Accuracy on batch 873 on Training is 30.574227688787186\n",
            "Epoch #0. Accuracy on batch 874 on Training is 30.560714285714287\n",
            "Epoch #0. Accuracy on batch 875 on Training is 30.568635844748858\n",
            "Epoch #0. Accuracy on batch 876 on Training is 30.580102622576966\n",
            "Epoch #0. Accuracy on batch 877 on Training is 30.56662870159453\n",
            "Epoch #0. Accuracy on batch 878 on Training is 30.560295790671216\n",
            "Epoch #0. Accuracy on batch 879 on Training is 30.550426136363637\n",
            "Batch Id 880 is having training loss of 406.8853759765625\n",
            "10.204049110412598\n",
            "Epoch #0. Accuracy on batch 880 on Training is 30.55122020431328\n",
            "Epoch #0. Accuracy on batch 881 on Training is 30.555555555555557\n",
            "Epoch #0. Accuracy on batch 882 on Training is 30.552802944507363\n",
            "Epoch #0. Accuracy on batch 883 on Training is 30.54652149321267\n",
            "Epoch #0. Accuracy on batch 884 on Training is 30.536723163841806\n",
            "Epoch #0. Accuracy on batch 885 on Training is 30.54810948081264\n",
            "Epoch #0. Accuracy on batch 886 on Training is 30.538331454340472\n",
            "Epoch #0. Accuracy on batch 887 on Training is 30.532094594594593\n",
            "Epoch #0. Accuracy on batch 888 on Training is 30.529386951631047\n",
            "Epoch #0. Accuracy on batch 889 on Training is 30.53370786516854\n",
            "Epoch #0. Accuracy on batch 890 on Training is 30.52749719416386\n",
            "Epoch #0. Accuracy on batch 891 on Training is 30.53531390134529\n",
            "Epoch #0. Accuracy on batch 892 on Training is 30.543113101903696\n",
            "Epoch #0. Accuracy on batch 893 on Training is 30.54390380313199\n",
            "Epoch #0. Accuracy on batch 894 on Training is 30.544692737430168\n",
            "Epoch #0. Accuracy on batch 895 on Training is 30.545479910714285\n",
            "Epoch #0. Accuracy on batch 896 on Training is 30.546265328874025\n",
            "Epoch #0. Accuracy on batch 897 on Training is 30.56444877505568\n",
            "Epoch #0. Accuracy on batch 898 on Training is 30.554783092324804\n",
            "Epoch #0. Accuracy on batch 899 on Training is 30.55902777777778\n",
            "Batch Id 900 is having training loss of 415.0913391113281\n",
            "70.8207015991211\n",
            "Epoch #0. Accuracy on batch 900 on Training is 30.56673140954495\n",
            "Epoch #0. Accuracy on batch 901 on Training is 30.567488913525498\n",
            "Epoch #0. Accuracy on batch 902 on Training is 30.57516611295681\n",
            "Epoch #0. Accuracy on batch 903 on Training is 30.56554203539823\n",
            "Epoch #0. Accuracy on batch 904 on Training is 30.566298342541437\n",
            "Epoch #0. Accuracy on batch 905 on Training is 30.567052980132452\n",
            "Epoch #0. Accuracy on batch 906 on Training is 30.581587651598678\n",
            "Epoch #0. Accuracy on batch 907 on Training is 30.585765418502202\n",
            "Epoch #0. Accuracy on batch 908 on Training is 30.579620462046204\n",
            "Epoch #0. Accuracy on batch 909 on Training is 30.570054945054945\n",
            "Epoch #0. Accuracy on batch 910 on Training is 30.55708013172338\n",
            "Epoch #0. Accuracy on batch 911 on Training is 30.557839912280702\n",
            "Epoch #0. Accuracy on batch 912 on Training is 30.572289156626507\n",
            "Epoch #0. Accuracy on batch 913 on Training is 30.55593544857768\n",
            "Epoch #0. Accuracy on batch 914 on Training is 30.560109289617486\n",
            "Epoch #0. Accuracy on batch 915 on Training is 30.554039301310045\n",
            "Epoch #0. Accuracy on batch 916 on Training is 30.554798255179936\n",
            "Epoch #0. Accuracy on batch 917 on Training is 30.558959694989106\n",
            "Epoch #0. Accuracy on batch 918 on Training is 30.569912948857453\n",
            "Epoch #0. Accuracy on batch 919 on Training is 30.56046195652174\n",
            "Batch Id 920 is having training loss of 409.2686767578125\n",
            "64.98172760009766\n",
            "Epoch #0. Accuracy on batch 920 on Training is 30.561210640608035\n",
            "Epoch #0. Accuracy on batch 921 on Training is 30.565347071583513\n",
            "Epoch #0. Accuracy on batch 922 on Training is 30.572860238353197\n",
            "Epoch #0. Accuracy on batch 923 on Training is 30.58373917748918\n",
            "Epoch #0. Accuracy on batch 924 on Training is 30.58445945945946\n",
            "Epoch #0. Accuracy on batch 925 on Training is 30.56830453563715\n",
            "Epoch #0. Accuracy on batch 926 on Training is 30.55218446601942\n",
            "Epoch #0. Accuracy on batch 927 on Training is 30.549568965517242\n",
            "Epoch #0. Accuracy on batch 928 on Training is 30.55032292787944\n",
            "Epoch #0. Accuracy on batch 929 on Training is 30.561155913978496\n",
            "Epoch #0. Accuracy on batch 930 on Training is 30.56860902255639\n",
            "Epoch #0. Accuracy on batch 931 on Training is 30.57269313304721\n",
            "Epoch #0. Accuracy on batch 932 on Training is 30.556672025723472\n",
            "Epoch #0. Accuracy on batch 933 on Training is 30.56076017130621\n",
            "Epoch #0. Accuracy on batch 934 on Training is 30.568181818181817\n",
            "Epoch #0. Accuracy on batch 935 on Training is 30.555555555555557\n",
            "Epoch #0. Accuracy on batch 936 on Training is 30.5596318036286\n",
            "Epoch #0. Accuracy on batch 937 on Training is 30.570362473347547\n",
            "Epoch #0. Accuracy on batch 938 on Training is 30.56775825346113\n",
            "Epoch #0. Accuracy on batch 939 on Training is 30.5718085106383\n",
            "Batch Id 940 is having training loss of 406.2796325683594\n",
            "21.806976318359375\n",
            "Epoch #0. Accuracy on batch 940 on Training is 30.579171094580232\n",
            "Epoch #0. Accuracy on batch 941 on Training is 30.56329617834395\n",
            "Epoch #0. Accuracy on batch 942 on Training is 30.557396606574763\n",
            "Epoch #0. Accuracy on batch 943 on Training is 30.551509533898304\n",
            "Epoch #0. Accuracy on batch 944 on Training is 30.558862433862434\n",
            "Epoch #0. Accuracy on batch 945 on Training is 30.576109936575055\n",
            "Epoch #0. Accuracy on batch 946 on Training is 30.583421330517425\n",
            "Epoch #0. Accuracy on batch 947 on Training is 30.557753164556964\n",
            "Epoch #0. Accuracy on batch 948 on Training is 30.551896733403584\n",
            "Epoch #0. Accuracy on batch 949 on Training is 30.57236842105263\n",
            "Epoch #0. Accuracy on batch 950 on Training is 30.563222923238698\n",
            "Epoch #0. Accuracy on batch 951 on Training is 30.554096638655462\n",
            "Epoch #0. Accuracy on batch 952 on Training is 30.558105981112277\n",
            "Epoch #0. Accuracy on batch 953 on Training is 30.562106918238992\n",
            "Epoch #0. Accuracy on batch 954 on Training is 30.56282722513089\n",
            "Epoch #0. Accuracy on batch 955 on Training is 30.570083682008367\n",
            "Epoch #0. Accuracy on batch 956 on Training is 30.564263322884013\n",
            "Epoch #0. Accuracy on batch 957 on Training is 30.571503131524008\n",
            "Epoch #0. Accuracy on batch 958 on Training is 30.565693430656935\n",
            "Epoch #0. Accuracy on batch 959 on Training is 30.576171875\n",
            "Batch Id 960 is having training loss of 420.3805236816406\n",
            "19.93903923034668\n",
            "Epoch #0. Accuracy on batch 960 on Training is 30.580124869927158\n",
            "Epoch #0. Accuracy on batch 961 on Training is 30.590566528066528\n",
            "Epoch #0. Accuracy on batch 962 on Training is 30.58476116303219\n",
            "Epoch #0. Accuracy on batch 963 on Training is 30.582209543568464\n",
            "Epoch #0. Accuracy on batch 964 on Training is 30.582901554404145\n",
            "Epoch #0. Accuracy on batch 965 on Training is 30.59976708074534\n",
            "Epoch #0. Accuracy on batch 966 on Training is 30.603671147880043\n",
            "Epoch #0. Accuracy on batch 967 on Training is 30.588197314049587\n",
            "Epoch #0. Accuracy on batch 968 on Training is 30.57598039215686\n",
            "Epoch #0. Accuracy on batch 969 on Training is 30.57667525773196\n",
            "Epoch #0. Accuracy on batch 970 on Training is 30.561277033985583\n",
            "Epoch #0. Accuracy on batch 971 on Training is 30.56520061728395\n",
            "Epoch #0. Accuracy on batch 972 on Training is 30.562692702980474\n",
            "Epoch #0. Accuracy on batch 973 on Training is 30.5666067761807\n",
            "Epoch #0. Accuracy on batch 974 on Training is 30.564102564102566\n",
            "Epoch #0. Accuracy on batch 975 on Training is 30.564805327868854\n",
            "Epoch #0. Accuracy on batch 976 on Training is 30.565506653019447\n",
            "Epoch #0. Accuracy on batch 977 on Training is 30.556620654396728\n",
            "Epoch #0. Accuracy on batch 978 on Training is 30.560520939734424\n",
            "Epoch #0. Accuracy on batch 979 on Training is 30.564413265306122\n",
            "Batch Id 980 is having training loss of 417.97149658203125\n",
            "56.20603942871094\n",
            "Epoch #0. Accuracy on batch 980 on Training is 30.56829765545362\n",
            "Epoch #0. Accuracy on batch 981 on Training is 30.59126782077393\n",
            "Epoch #0. Accuracy on batch 982 on Training is 30.58557985757884\n",
            "Epoch #0. Accuracy on batch 983 on Training is 30.576727642276424\n",
            "Epoch #0. Accuracy on batch 984 on Training is 30.59010152284264\n",
            "Epoch #0. Accuracy on batch 985 on Training is 30.59077079107505\n",
            "Epoch #0. Accuracy on batch 986 on Training is 30.59143870314083\n",
            "Epoch #0. Accuracy on batch 987 on Training is 30.588942307692307\n",
            "Epoch #0. Accuracy on batch 988 on Training is 30.583291203235593\n",
            "Epoch #0. Accuracy on batch 989 on Training is 30.58712121212121\n",
            "Epoch #0. Accuracy on batch 990 on Training is 30.578329969727548\n",
            "Epoch #0. Accuracy on batch 991 on Training is 30.572706653225808\n",
            "Epoch #0. Accuracy on batch 992 on Training is 30.57338872104733\n",
            "Epoch #0. Accuracy on batch 993 on Training is 30.574069416498993\n",
            "Epoch #0. Accuracy on batch 994 on Training is 30.58103015075377\n",
            "Epoch #0. Accuracy on batch 995 on Training is 30.58483935742972\n",
            "Epoch #0. Accuracy on batch 996 on Training is 30.585506519558677\n",
            "Epoch #0. Accuracy on batch 997 on Training is 30.592434869739478\n",
            "Epoch #0. Accuracy on batch 998 on Training is 30.586836836836838\n",
            "Epoch #0. Accuracy on batch 999 on Training is 30.578125\n",
            "Batch Id 1000 is having training loss of 412.2281799316406\n",
            "10.430826187133789\n",
            "Epoch #0. Accuracy on batch 1000 on Training is 30.58503996003996\n",
            "Epoch #0. Accuracy on batch 1001 on Training is 30.60129740518962\n",
            "Epoch #0. Accuracy on batch 1002 on Training is 30.58636590229312\n",
            "Epoch #0. Accuracy on batch 1003 on Training is 30.590139442231077\n",
            "Epoch #0. Accuracy on batch 1004 on Training is 30.58768656716418\n",
            "Epoch #0. Accuracy on batch 1005 on Training is 30.594557654075548\n",
            "Epoch #0. Accuracy on batch 1006 on Training is 30.582795431976166\n",
            "Epoch #0. Accuracy on batch 1007 on Training is 30.567956349206348\n",
            "Epoch #0. Accuracy on batch 1008 on Training is 30.568632309217048\n",
            "Epoch #0. Accuracy on batch 1009 on Training is 30.57549504950495\n",
            "Epoch #0. Accuracy on batch 1010 on Training is 30.554525222551927\n",
            "Epoch #0. Accuracy on batch 1011 on Training is 30.56756422924901\n",
            "Epoch #0. Accuracy on batch 1012 on Training is 30.580577492596248\n",
            "Epoch #0. Accuracy on batch 1013 on Training is 30.581237672583825\n",
            "Epoch #0. Accuracy on batch 1014 on Training is 30.572660098522167\n",
            "Epoch #0. Accuracy on batch 1015 on Training is 30.567175196850393\n",
            "Epoch #0. Accuracy on batch 1016 on Training is 30.561701081612586\n",
            "Epoch #0. Accuracy on batch 1017 on Training is 30.547028487229863\n",
            "Epoch #0. Accuracy on batch 1018 on Training is 30.553851815505396\n",
            "Epoch #0. Accuracy on batch 1019 on Training is 30.55453431372549\n",
            "Batch Id 1020 is having training loss of 415.9439697265625\n",
            "25.018707275390625\n",
            "Epoch #0. Accuracy on batch 1020 on Training is 30.564397649363368\n",
            "Epoch #0. Accuracy on batch 1021 on Training is 30.552837573385517\n",
            "Epoch #0. Accuracy on batch 1022 on Training is 30.562683284457478\n",
            "Epoch #0. Accuracy on batch 1023 on Training is 30.560302734375\n",
            "Epoch #0. Accuracy on batch 1024 on Training is 30.554878048780488\n",
            "Epoch #0. Accuracy on batch 1025 on Training is 30.558601364522417\n",
            "Epoch #0. Accuracy on batch 1026 on Training is 30.556231742940604\n",
            "Epoch #0. Accuracy on batch 1027 on Training is 30.55386673151751\n",
            "Epoch #0. Accuracy on batch 1028 on Training is 30.542395529640427\n",
            "Epoch #0. Accuracy on batch 1029 on Training is 30.527912621359224\n",
            "Epoch #0. Accuracy on batch 1030 on Training is 30.51042677012609\n",
            "Epoch #0. Accuracy on batch 1031 on Training is 30.514171511627907\n",
            "Epoch #0. Accuracy on batch 1032 on Training is 30.51185866408519\n",
            "Epoch #0. Accuracy on batch 1033 on Training is 30.491416827852998\n",
            "Epoch #0. Accuracy on batch 1034 on Training is 30.504227053140095\n",
            "Epoch #0. Accuracy on batch 1035 on Training is 30.501930501930502\n",
            "Epoch #0. Accuracy on batch 1036 on Training is 30.49963837994214\n",
            "Epoch #0. Accuracy on batch 1037 on Training is 30.491329479768787\n",
            "Epoch #0. Accuracy on batch 1038 on Training is 30.471005774783446\n",
            "Epoch #0. Accuracy on batch 1039 on Training is 30.474759615384617\n",
            "Batch Id 1040 is having training loss of 428.2257385253906\n",
            "192.0832061767578\n",
            "Epoch #0. Accuracy on batch 1040 on Training is 30.478506243996158\n",
            "Epoch #0. Accuracy on batch 1041 on Training is 30.47024952015355\n",
            "Epoch #0. Accuracy on batch 1042 on Training is 30.47998561840844\n",
            "Epoch #0. Accuracy on batch 1043 on Training is 30.480723180076627\n",
            "Epoch #0. Accuracy on batch 1044 on Training is 30.4694976076555\n",
            "Epoch #0. Accuracy on batch 1045 on Training is 30.47323135755258\n",
            "Epoch #0. Accuracy on batch 1046 on Training is 30.46800382043935\n",
            "Epoch #0. Accuracy on batch 1047 on Training is 30.462786259541986\n",
            "Epoch #0. Accuracy on batch 1048 on Training is 30.45757864632984\n",
            "Epoch #0. Accuracy on batch 1049 on Training is 30.461309523809526\n",
            "Epoch #0. Accuracy on batch 1050 on Training is 30.456113225499525\n",
            "Epoch #0. Accuracy on batch 1051 on Training is 30.456867870722434\n",
            "Epoch #0. Accuracy on batch 1052 on Training is 30.472459639126306\n",
            "Epoch #0. Accuracy on batch 1053 on Training is 30.47319734345351\n",
            "Epoch #0. Accuracy on batch 1054 on Training is 30.488744075829384\n",
            "Epoch #0. Accuracy on batch 1055 on Training is 30.492424242424242\n",
            "Epoch #0. Accuracy on batch 1056 on Training is 30.48131504257332\n",
            "Epoch #0. Accuracy on batch 1057 on Training is 30.487948960302457\n",
            "Epoch #0. Accuracy on batch 1058 on Training is 30.485717658168085\n",
            "Epoch #0. Accuracy on batch 1059 on Training is 30.47759433962264\n",
            "Batch Id 1060 is having training loss of 425.1685485839844\n",
            "76.01972198486328\n",
            "Epoch #0. Accuracy on batch 1060 on Training is 30.48126767200754\n",
            "Epoch #0. Accuracy on batch 1061 on Training is 30.487876647834273\n",
            "Epoch #0. Accuracy on batch 1062 on Training is 30.48565380997178\n",
            "Epoch #0. Accuracy on batch 1063 on Training is 30.48343515037594\n",
            "Epoch #0. Accuracy on batch 1064 on Training is 30.469483568075116\n",
            "Epoch #0. Accuracy on batch 1065 on Training is 30.473147279549718\n",
            "Epoch #0. Accuracy on batch 1066 on Training is 30.47680412371134\n",
            "Epoch #0. Accuracy on batch 1067 on Training is 30.474602059925093\n",
            "Epoch #0. Accuracy on batch 1068 on Training is 30.46948082319925\n",
            "Epoch #0. Accuracy on batch 1069 on Training is 30.47897196261682\n",
            "Epoch #0. Accuracy on batch 1070 on Training is 30.491363211951448\n",
            "Epoch #0. Accuracy on batch 1071 on Training is 30.48915578358209\n",
            "Epoch #0. Accuracy on batch 1072 on Training is 30.478215284249767\n",
            "Epoch #0. Accuracy on batch 1073 on Training is 30.490572625698324\n",
            "Epoch #0. Accuracy on batch 1074 on Training is 30.49418604651163\n",
            "Epoch #0. Accuracy on batch 1075 on Training is 30.491984200743495\n",
            "Epoch #0. Accuracy on batch 1076 on Training is 30.48688486536676\n",
            "Epoch #0. Accuracy on batch 1077 on Training is 30.490491651205936\n",
            "Epoch #0. Accuracy on batch 1078 on Training is 30.494091751621873\n",
            "Epoch #0. Accuracy on batch 1079 on Training is 30.500578703703702\n",
            "Batch Id 1080 is having training loss of 457.5485534667969\n",
            "2459.70263671875\n",
            "Epoch #0. Accuracy on batch 1080 on Training is 30.489708603145235\n",
            "Epoch #0. Accuracy on batch 1081 on Training is 30.496187615526804\n",
            "Epoch #0. Accuracy on batch 1082 on Training is 30.49111265004617\n",
            "Epoch #0. Accuracy on batch 1083 on Training is 30.49757841328413\n",
            "Epoch #0. Accuracy on batch 1084 on Training is 30.49827188940092\n",
            "Epoch #0. Accuracy on batch 1085 on Training is 30.507596685082873\n",
            "Epoch #0. Accuracy on batch 1086 on Training is 30.50827966881325\n",
            "Epoch #0. Accuracy on batch 1087 on Training is 30.503216911764707\n",
            "Epoch #0. Accuracy on batch 1088 on Training is 30.518250688705233\n",
            "Epoch #0. Accuracy on batch 1089 on Training is 30.51605504587156\n",
            "Epoch #0. Accuracy on batch 1090 on Training is 30.510999083409715\n",
            "Epoch #0. Accuracy on batch 1091 on Training is 30.508814102564102\n",
            "Epoch #0. Accuracy on batch 1092 on Training is 30.503774016468437\n",
            "Epoch #0. Accuracy on batch 1093 on Training is 30.510169104204753\n",
            "Epoch #0. Accuracy on batch 1094 on Training is 30.516552511415526\n",
            "Epoch #0. Accuracy on batch 1095 on Training is 30.514370437956206\n",
            "Epoch #0. Accuracy on batch 1096 on Training is 30.51219234275296\n",
            "Epoch #0. Accuracy on batch 1097 on Training is 30.512864298724953\n",
            "Epoch #0. Accuracy on batch 1098 on Training is 30.516378525932666\n",
            "Epoch #0. Accuracy on batch 1099 on Training is 30.519886363636363\n",
            "Batch Id 1100 is having training loss of 480.20635986328125\n",
            "27.99911880493164\n",
            "Epoch #0. Accuracy on batch 1100 on Training is 30.509196185286104\n",
            "Epoch #0. Accuracy on batch 1101 on Training is 30.507032667876587\n",
            "Epoch #0. Accuracy on batch 1102 on Training is 30.510539437896647\n",
            "Epoch #0. Accuracy on batch 1103 on Training is 30.511209239130434\n",
            "Epoch #0. Accuracy on batch 1104 on Training is 30.5118778280543\n",
            "Epoch #0. Accuracy on batch 1105 on Training is 30.509719710669078\n",
            "Epoch #0. Accuracy on batch 1106 on Training is 30.50191960252936\n",
            "Epoch #0. Accuracy on batch 1107 on Training is 30.50259476534296\n",
            "Epoch #0. Accuracy on batch 1108 on Training is 30.51735798016231\n",
            "Epoch #0. Accuracy on batch 1109 on Training is 30.520833333333332\n",
            "Epoch #0. Accuracy on batch 1110 on Training is 30.521489648964895\n",
            "Epoch #0. Accuracy on batch 1111 on Training is 30.505283273381295\n",
            "Epoch #0. Accuracy on batch 1112 on Training is 30.50033692722372\n",
            "Epoch #0. Accuracy on batch 1113 on Training is 30.50942549371634\n",
            "Epoch #0. Accuracy on batch 1114 on Training is 30.507286995515695\n",
            "Epoch #0. Accuracy on batch 1115 on Training is 30.516353046594983\n",
            "Epoch #0. Accuracy on batch 1116 on Training is 30.511414503133395\n",
            "Epoch #0. Accuracy on batch 1117 on Training is 30.517665474060824\n",
            "Epoch #0. Accuracy on batch 1118 on Training is 30.509941912421805\n",
            "Epoch #0. Accuracy on batch 1119 on Training is 30.493861607142858\n",
            "Batch Id 1120 is having training loss of 480.01727294921875\n",
            "128.50735473632812\n",
            "Epoch #0. Accuracy on batch 1120 on Training is 30.497323818019627\n",
            "Epoch #0. Accuracy on batch 1121 on Training is 30.492424242424242\n",
            "Epoch #0. Accuracy on batch 1122 on Training is 30.495881567230633\n",
            "Epoch #0. Accuracy on batch 1123 on Training is 30.49933274021352\n",
            "Epoch #0. Accuracy on batch 1124 on Training is 30.488888888888887\n",
            "Epoch #0. Accuracy on batch 1125 on Training is 30.492340142095916\n",
            "Epoch #0. Accuracy on batch 1126 on Training is 30.49578527062999\n",
            "Epoch #0. Accuracy on batch 1127 on Training is 30.4936835106383\n",
            "Epoch #0. Accuracy on batch 1128 on Training is 30.469441984056687\n",
            "Epoch #0. Accuracy on batch 1129 on Training is 30.47842920353982\n",
            "Epoch #0. Accuracy on batch 1130 on Training is 30.479111405835543\n",
            "Epoch #0. Accuracy on batch 1131 on Training is 30.471510600706715\n",
            "Epoch #0. Accuracy on batch 1132 on Training is 30.466681376875552\n",
            "Epoch #0. Accuracy on batch 1133 on Training is 30.464616402116402\n",
            "Epoch #0. Accuracy on batch 1134 on Training is 30.479074889867842\n",
            "Epoch #0. Accuracy on batch 1135 on Training is 30.47425176056338\n",
            "Epoch #0. Accuracy on batch 1136 on Training is 30.472185576077397\n",
            "Epoch #0. Accuracy on batch 1137 on Training is 30.4728690685413\n",
            "Epoch #0. Accuracy on batch 1138 on Training is 30.479038630377524\n",
            "Epoch #0. Accuracy on batch 1139 on Training is 30.476973684210527\n",
            "Batch Id 1140 is having training loss of 480.0050964355469\n",
            "16.173742294311523\n",
            "Epoch #0. Accuracy on batch 1140 on Training is 30.485867659947413\n",
            "Epoch #0. Accuracy on batch 1141 on Training is 30.483800350262698\n",
            "Epoch #0. Accuracy on batch 1142 on Training is 30.487204724409448\n",
            "Epoch #0. Accuracy on batch 1143 on Training is 30.48513986013986\n",
            "Epoch #0. Accuracy on batch 1144 on Training is 30.46943231441048\n",
            "Epoch #0. Accuracy on batch 1145 on Training is 30.470113438045374\n",
            "Epoch #0. Accuracy on batch 1146 on Training is 30.46806887532694\n",
            "Epoch #0. Accuracy on batch 1147 on Training is 30.44697299651568\n",
            "Epoch #0. Accuracy on batch 1148 on Training is 30.439512619669276\n",
            "Epoch #0. Accuracy on batch 1149 on Training is 30.440217391304348\n",
            "Epoch #0. Accuracy on batch 1150 on Training is 30.43006081668115\n",
            "Epoch #0. Accuracy on batch 1151 on Training is 30.42263454861111\n",
            "Epoch #0. Accuracy on batch 1152 on Training is 30.426062445793583\n",
            "Epoch #0. Accuracy on batch 1153 on Training is 30.432192374350088\n",
            "Epoch #0. Accuracy on batch 1154 on Training is 30.42748917748918\n",
            "Epoch #0. Accuracy on batch 1155 on Training is 30.43901384083045\n",
            "Epoch #0. Accuracy on batch 1156 on Training is 30.43971477960242\n",
            "Epoch #0. Accuracy on batch 1157 on Training is 30.443113126079446\n",
            "Epoch #0. Accuracy on batch 1158 on Training is 30.446505608283\n",
            "Epoch #0. Accuracy on batch 1159 on Training is 30.447198275862068\n",
            "Batch Id 1160 is having training loss of 490.5029602050781\n",
            "3114.932861328125\n",
            "Epoch #0. Accuracy on batch 1160 on Training is 30.431739879414298\n",
            "Epoch #0. Accuracy on batch 1161 on Training is 30.437822719449226\n",
            "Epoch #0. Accuracy on batch 1162 on Training is 30.41702493551161\n",
            "Epoch #0. Accuracy on batch 1163 on Training is 30.40700171821306\n",
            "Epoch #0. Accuracy on batch 1164 on Training is 30.415772532188843\n",
            "Epoch #0. Accuracy on batch 1165 on Training is 30.413807890222984\n",
            "Epoch #0. Accuracy on batch 1166 on Training is 30.40916880891174\n",
            "Epoch #0. Accuracy on batch 1167 on Training is 30.399186643835616\n",
            "Epoch #0. Accuracy on batch 1168 on Training is 30.391894781864842\n",
            "Epoch #0. Accuracy on batch 1169 on Training is 30.392628205128204\n",
            "Epoch #0. Accuracy on batch 1170 on Training is 30.393360375747225\n",
            "Epoch #0. Accuracy on batch 1171 on Training is 30.399424061433447\n",
            "Epoch #0. Accuracy on batch 1172 on Training is 30.400149190110827\n",
            "Epoch #0. Accuracy on batch 1173 on Training is 30.398211243611584\n",
            "Epoch #0. Accuracy on batch 1174 on Training is 30.39095744680851\n",
            "Epoch #0. Accuracy on batch 1175 on Training is 30.4156037414966\n",
            "Epoch #0. Accuracy on batch 1176 on Training is 30.42162276975361\n",
            "Epoch #0. Accuracy on batch 1177 on Training is 30.4223259762309\n",
            "Epoch #0. Accuracy on batch 1178 on Training is 30.42037743850721\n",
            "Epoch #0. Accuracy on batch 1179 on Training is 30.423728813559322\n",
            "Batch Id 1180 is having training loss of 488.5312805175781\n",
            "2747.00244140625\n",
            "Epoch #0. Accuracy on batch 1180 on Training is 30.403259949195597\n",
            "Epoch #0. Accuracy on batch 1181 on Training is 30.411907783417934\n",
            "Epoch #0. Accuracy on batch 1182 on Training is 30.40733305156382\n",
            "Epoch #0. Accuracy on batch 1183 on Training is 30.41068412162162\n",
            "Epoch #0. Accuracy on batch 1184 on Training is 30.419303797468356\n",
            "Epoch #0. Accuracy on batch 1185 on Training is 30.41736930860034\n",
            "Epoch #0. Accuracy on batch 1186 on Training is 30.423336141533277\n",
            "Epoch #0. Accuracy on batch 1187 on Training is 30.434553872053872\n",
            "Epoch #0. Accuracy on batch 1188 on Training is 30.43523969722456\n",
            "Epoch #0. Accuracy on batch 1189 on Training is 30.435924369747898\n",
            "Epoch #0. Accuracy on batch 1190 on Training is 30.44185558354324\n",
            "Epoch #0. Accuracy on batch 1191 on Training is 30.43204697986577\n",
            "Epoch #0. Accuracy on batch 1192 on Training is 30.43797150041911\n",
            "Epoch #0. Accuracy on batch 1193 on Training is 30.425565326633166\n",
            "Epoch #0. Accuracy on batch 1194 on Training is 30.415794979079497\n",
            "Epoch #0. Accuracy on batch 1195 on Training is 30.421718227424748\n",
            "Epoch #0. Accuracy on batch 1196 on Training is 30.422410192147034\n",
            "Epoch #0. Accuracy on batch 1197 on Training is 30.4152754590985\n",
            "Epoch #0. Accuracy on batch 1198 on Training is 30.426396997497914\n",
            "Epoch #0. Accuracy on batch 1199 on Training is 30.424479166666668\n",
            "Batch Id 1200 is having training loss of 481.294677734375\n",
            "26.098337173461914\n",
            "Epoch #0. Accuracy on batch 1200 on Training is 30.432972522897586\n",
            "Epoch #0. Accuracy on batch 1201 on Training is 30.43365224625624\n",
            "Epoch #0. Accuracy on batch 1202 on Training is 30.4369285120532\n",
            "Epoch #0. Accuracy on batch 1203 on Training is 30.437603820598007\n",
            "Epoch #0. Accuracy on batch 1204 on Training is 30.435684647302903\n",
            "Epoch #0. Accuracy on batch 1205 on Training is 30.444133499170814\n",
            "Epoch #0. Accuracy on batch 1206 on Training is 30.439623032311516\n",
            "Epoch #0. Accuracy on batch 1207 on Training is 30.437706953642383\n",
            "Epoch #0. Accuracy on batch 1208 on Training is 30.433209263854426\n",
            "Epoch #0. Accuracy on batch 1209 on Training is 30.43388429752066\n",
            "Epoch #0. Accuracy on batch 1210 on Training is 30.429397192402973\n",
            "Epoch #0. Accuracy on batch 1211 on Training is 30.432652640264028\n",
            "Epoch #0. Accuracy on batch 1212 on Training is 30.441055234954657\n",
            "Epoch #0. Accuracy on batch 1213 on Training is 30.42885090609555\n",
            "Epoch #0. Accuracy on batch 1214 on Training is 30.424382716049383\n",
            "Epoch #0. Accuracy on batch 1215 on Training is 30.419921875\n",
            "Epoch #0. Accuracy on batch 1216 on Training is 30.428307313064913\n",
            "Epoch #0. Accuracy on batch 1217 on Training is 30.416153530377667\n",
            "Epoch #0. Accuracy on batch 1218 on Training is 30.409146841673504\n",
            "Epoch #0. Accuracy on batch 1219 on Training is 30.407274590163933\n",
            "Batch Id 1220 is having training loss of 477.01922607421875\n",
            "33.79329299926758\n",
            "Epoch #0. Accuracy on batch 1220 on Training is 30.39260851760852\n",
            "Epoch #0. Accuracy on batch 1221 on Training is 30.37796644844517\n",
            "Epoch #0. Accuracy on batch 1222 on Training is 30.35823793949305\n",
            "Epoch #0. Accuracy on batch 1223 on Training is 30.35386029411765\n",
            "Epoch #0. Accuracy on batch 1224 on Training is 30.346938775510203\n",
            "Epoch #0. Accuracy on batch 1225 on Training is 30.360420065252853\n",
            "Epoch #0. Accuracy on batch 1226 on Training is 30.356051344743275\n",
            "Epoch #0. Accuracy on batch 1227 on Training is 30.344055374592834\n",
            "Epoch #0. Accuracy on batch 1228 on Training is 30.34479251423922\n",
            "Epoch #0. Accuracy on batch 1229 on Training is 30.340447154471544\n",
            "Epoch #0. Accuracy on batch 1230 on Training is 30.333570268074737\n",
            "Epoch #0. Accuracy on batch 1231 on Training is 30.329241071428573\n",
            "Epoch #0. Accuracy on batch 1232 on Training is 30.340125709651257\n",
            "Epoch #0. Accuracy on batch 1233 on Training is 30.335798217179903\n",
            "Epoch #0. Accuracy on batch 1234 on Training is 30.33400809716599\n",
            "Epoch #0. Accuracy on batch 1235 on Training is 30.329692556634303\n",
            "Epoch #0. Accuracy on batch 1236 on Training is 30.335489086499596\n",
            "Epoch #0. Accuracy on batch 1237 on Training is 30.33370355411955\n",
            "Epoch #0. Accuracy on batch 1238 on Training is 30.334443099273606\n",
            "Epoch #0. Accuracy on batch 1239 on Training is 30.322580645161292\n",
            "Batch Id 1240 is having training loss of 489.1168212890625\n",
            "50.763187408447266\n",
            "Epoch #0. Accuracy on batch 1240 on Training is 30.32836422240129\n",
            "Epoch #0. Accuracy on batch 1241 on Training is 30.326590177133657\n",
            "Epoch #0. Accuracy on batch 1242 on Training is 30.31476267095736\n",
            "Epoch #0. Accuracy on batch 1243 on Training is 30.310490353697748\n",
            "Epoch #0. Accuracy on batch 1244 on Training is 30.316265060240966\n",
            "Epoch #0. Accuracy on batch 1245 on Training is 30.306982343499197\n",
            "Epoch #0. Accuracy on batch 1246 on Training is 30.31525661587811\n",
            "Epoch #0. Accuracy on batch 1247 on Training is 30.310997596153847\n",
            "Epoch #0. Accuracy on batch 1248 on Training is 30.29423538831065\n",
            "Epoch #0. Accuracy on batch 1249 on Training is 30.2925\n",
            "Epoch #0. Accuracy on batch 1250 on Training is 30.29576338928857\n",
            "Epoch #0. Accuracy on batch 1251 on Training is 30.29153354632588\n",
            "Epoch #0. Accuracy on batch 1252 on Training is 30.297286512370313\n",
            "Epoch #0. Accuracy on batch 1253 on Training is 30.29306220095694\n",
            "Epoch #0. Accuracy on batch 1254 on Training is 30.291334661354583\n",
            "Epoch #0. Accuracy on batch 1255 on Training is 30.30453821656051\n",
            "Epoch #0. Accuracy on batch 1256 on Training is 30.300318217979317\n",
            "Epoch #0. Accuracy on batch 1257 on Training is 30.308525437201908\n",
            "Epoch #0. Accuracy on batch 1258 on Training is 30.316719618745037\n",
            "Epoch #0. Accuracy on batch 1259 on Training is 30.322420634920636\n",
            "Batch Id 1260 is having training loss of 484.21734619140625\n",
            "16.600011825561523\n",
            "Epoch #0. Accuracy on batch 1260 on Training is 30.325634417129262\n",
            "Epoch #0. Accuracy on batch 1261 on Training is 30.33379556259905\n",
            "Epoch #0. Accuracy on batch 1262 on Training is 30.339469517022962\n",
            "Epoch #0. Accuracy on batch 1263 on Training is 30.335245253164558\n",
            "Epoch #0. Accuracy on batch 1264 on Training is 30.333498023715414\n",
            "Epoch #0. Accuracy on batch 1265 on Training is 30.329285150078988\n",
            "Epoch #0. Accuracy on batch 1266 on Training is 30.322612470402525\n",
            "Epoch #0. Accuracy on batch 1267 on Training is 30.323343848580443\n",
            "Epoch #0. Accuracy on batch 1268 on Training is 30.333924349881798\n",
            "Epoch #0. Accuracy on batch 1269 on Training is 30.32972440944882\n",
            "Epoch #0. Accuracy on batch 1270 on Training is 30.323072383949647\n",
            "Epoch #0. Accuracy on batch 1271 on Training is 30.32134433962264\n",
            "Epoch #0. Accuracy on batch 1272 on Training is 30.326983503534958\n",
            "Epoch #0. Accuracy on batch 1273 on Training is 30.325255102040817\n",
            "Epoch #0. Accuracy on batch 1274 on Training is 30.330882352941178\n",
            "Epoch #0. Accuracy on batch 1275 on Training is 30.334051724137932\n",
            "Epoch #0. Accuracy on batch 1276 on Training is 30.32987470634299\n",
            "Epoch #0. Accuracy on batch 1277 on Training is 30.330594679186227\n",
            "Epoch #0. Accuracy on batch 1278 on Training is 30.32642689601251\n",
            "Epoch #0. Accuracy on batch 1279 on Training is 30.322265625\n",
            "Batch Id 1280 is having training loss of 485.4373474121094\n",
            "40.41792297363281\n",
            "Epoch #0. Accuracy on batch 1280 on Training is 30.327868852459016\n",
            "Epoch #0. Accuracy on batch 1281 on Training is 30.33102574102964\n",
            "Epoch #0. Accuracy on batch 1282 on Training is 30.329306313328136\n",
            "Epoch #0. Accuracy on batch 1283 on Training is 30.342192367601246\n",
            "Epoch #0. Accuracy on batch 1284 on Training is 30.35019455252918\n",
            "Epoch #0. Accuracy on batch 1285 on Training is 30.36304432348367\n",
            "Epoch #0. Accuracy on batch 1286 on Training is 30.361305361305362\n",
            "Epoch #0. Accuracy on batch 1287 on Training is 30.37897903726708\n",
            "Epoch #0. Accuracy on batch 1288 on Training is 30.384503491078355\n",
            "Epoch #0. Accuracy on batch 1289 on Training is 30.385174418604652\n",
            "Epoch #0. Accuracy on batch 1290 on Training is 30.388264910921766\n",
            "Epoch #0. Accuracy on batch 1291 on Training is 30.386513157894736\n",
            "Epoch #0. Accuracy on batch 1292 on Training is 30.377513534416085\n",
            "Epoch #0. Accuracy on batch 1293 on Training is 30.37818778979907\n",
            "Epoch #0. Accuracy on batch 1294 on Training is 30.366795366795365\n",
            "Epoch #0. Accuracy on batch 1295 on Training is 30.357831790123456\n",
            "Epoch #0. Accuracy on batch 1296 on Training is 30.363338473400155\n",
            "Epoch #0. Accuracy on batch 1297 on Training is 30.366429121725734\n",
            "Epoch #0. Accuracy on batch 1298 on Training is 30.371920708237106\n",
            "Epoch #0. Accuracy on batch 1299 on Training is 30.370192307692307\n",
            "Batch Id 1300 is having training loss of 479.4543151855469\n",
            "13.508238792419434\n",
            "Epoch #0. Accuracy on batch 1300 on Training is 30.387682551883167\n",
            "Epoch #0. Accuracy on batch 1301 on Training is 30.38594470046083\n",
            "Epoch #0. Accuracy on batch 1302 on Training is 30.3794128933231\n",
            "Epoch #0. Accuracy on batch 1303 on Training is 30.375287576687118\n",
            "Epoch #0. Accuracy on batch 1304 on Training is 30.37595785440613\n",
            "Epoch #0. Accuracy on batch 1305 on Training is 30.383805513016846\n",
            "Epoch #0. Accuracy on batch 1306 on Training is 30.374904361132366\n",
            "Epoch #0. Accuracy on batch 1307 on Training is 30.38512996941896\n",
            "Epoch #0. Accuracy on batch 1308 on Training is 30.38101604278075\n",
            "Epoch #0. Accuracy on batch 1309 on Training is 30.37929389312977\n",
            "Epoch #0. Accuracy on batch 1310 on Training is 30.379958047292142\n",
            "Epoch #0. Accuracy on batch 1311 on Training is 30.38062118902439\n",
            "Epoch #0. Accuracy on batch 1312 on Training is 30.376523229246\n",
            "Epoch #0. Accuracy on batch 1313 on Training is 30.362918569254187\n",
            "Epoch #0. Accuracy on batch 1314 on Training is 30.370722433460077\n",
            "Epoch #0. Accuracy on batch 1315 on Training is 30.359517477203646\n",
            "Epoch #0. Accuracy on batch 1316 on Training is 30.362566438876232\n",
            "Epoch #0. Accuracy on batch 1317 on Training is 30.360868740515933\n",
            "Epoch #0. Accuracy on batch 1318 on Training is 30.352065959059892\n",
            "Epoch #0. Accuracy on batch 1319 on Training is 30.355113636363637\n",
            "Batch Id 1320 is having training loss of 494.1936340332031\n",
            "21.086137771606445\n",
            "Epoch #0. Accuracy on batch 1320 on Training is 30.358156699470097\n",
            "Epoch #0. Accuracy on batch 1321 on Training is 30.363559001512858\n",
            "Epoch #0. Accuracy on batch 1322 on Training is 30.36422902494331\n",
            "Epoch #0. Accuracy on batch 1323 on Training is 30.3672583081571\n",
            "Epoch #0. Accuracy on batch 1324 on Training is 30.36320754716981\n",
            "Epoch #0. Accuracy on batch 1325 on Training is 30.352092760180994\n",
            "Epoch #0. Accuracy on batch 1326 on Training is 30.357479276563677\n",
            "Epoch #0. Accuracy on batch 1327 on Training is 30.353445030120483\n",
            "Epoch #0. Accuracy on batch 1328 on Training is 30.349416854778028\n",
            "Epoch #0. Accuracy on batch 1329 on Training is 30.347744360902254\n",
            "Epoch #0. Accuracy on batch 1330 on Training is 30.34607438016529\n",
            "Epoch #0. Accuracy on batch 1331 on Training is 30.33502252252252\n",
            "Epoch #0. Accuracy on batch 1332 on Training is 30.342741935483872\n",
            "Epoch #0. Accuracy on batch 1333 on Training is 30.345764617691156\n",
            "Epoch #0. Accuracy on batch 1334 on Training is 30.344101123595507\n",
            "Epoch #0. Accuracy on batch 1335 on Training is 30.351796407185628\n",
            "Epoch #0. Accuracy on batch 1336 on Training is 30.357142857142858\n",
            "Epoch #0. Accuracy on batch 1337 on Training is 30.353139013452914\n",
            "Epoch #0. Accuracy on batch 1338 on Training is 30.346807318894697\n",
            "Epoch #0. Accuracy on batch 1339 on Training is 30.33582089552239\n",
            "Batch Id 1340 is having training loss of 488.7124328613281\n",
            "27.84876823425293\n",
            "Epoch #0. Accuracy on batch 1340 on Training is 30.338832960477255\n",
            "Epoch #0. Accuracy on batch 1341 on Training is 30.337183308494783\n",
            "Epoch #0. Accuracy on batch 1342 on Training is 30.337862993298586\n",
            "Epoch #0. Accuracy on batch 1343 on Training is 30.331566220238095\n",
            "Epoch #0. Accuracy on batch 1344 on Training is 30.33224907063197\n",
            "Epoch #0. Accuracy on batch 1345 on Training is 30.330609212481427\n",
            "Epoch #0. Accuracy on batch 1346 on Training is 30.326651818856718\n",
            "Epoch #0. Accuracy on batch 1347 on Training is 30.336609792284868\n",
            "Epoch #0. Accuracy on batch 1348 on Training is 30.325704225352112\n",
            "Epoch #0. Accuracy on batch 1349 on Training is 30.32175925925926\n",
            "Epoch #0. Accuracy on batch 1350 on Training is 30.32475943745374\n",
            "Epoch #0. Accuracy on batch 1351 on Training is 30.323132396449704\n",
            "Epoch #0. Accuracy on batch 1352 on Training is 30.323817442719882\n",
            "Epoch #0. Accuracy on batch 1353 on Training is 30.336041358936484\n",
            "Epoch #0. Accuracy on batch 1354 on Training is 30.348247232472325\n",
            "Epoch #0. Accuracy on batch 1355 on Training is 30.344303097345133\n",
            "Epoch #0. Accuracy on batch 1356 on Training is 30.34957627118644\n",
            "Epoch #0. Accuracy on batch 1357 on Training is 30.354841678939618\n",
            "Epoch #0. Accuracy on batch 1358 on Training is 30.362398822663724\n",
            "Epoch #0. Accuracy on batch 1359 on Training is 30.363051470588236\n",
            "Batch Id 1360 is having training loss of 531.6806640625\n",
            "22.036396026611328\n",
            "Epoch #0. Accuracy on batch 1360 on Training is 30.365999265246142\n",
            "Epoch #0. Accuracy on batch 1361 on Training is 30.36894273127753\n",
            "Epoch #0. Accuracy on batch 1362 on Training is 30.36271093176816\n",
            "Epoch #0. Accuracy on batch 1363 on Training is 30.370234604105573\n",
            "Epoch #0. Accuracy on batch 1364 on Training is 30.359432234432234\n",
            "Epoch #0. Accuracy on batch 1365 on Training is 30.364659590043924\n",
            "Epoch #0. Accuracy on batch 1366 on Training is 30.35844915874177\n",
            "Epoch #0. Accuracy on batch 1367 on Training is 30.34767909356725\n",
            "Epoch #0. Accuracy on batch 1368 on Training is 30.35518626734843\n",
            "Epoch #0. Accuracy on batch 1369 on Training is 30.348996350364963\n",
            "Epoch #0. Accuracy on batch 1370 on Training is 30.34965353756382\n",
            "Epoch #0. Accuracy on batch 1371 on Training is 30.354865160349853\n",
            "Epoch #0. Accuracy on batch 1372 on Training is 30.341860888565186\n",
            "Epoch #0. Accuracy on batch 1373 on Training is 30.328875545851528\n",
            "Epoch #0. Accuracy on batch 1374 on Training is 30.327272727272728\n",
            "Epoch #0. Accuracy on batch 1375 on Training is 30.3234011627907\n",
            "Epoch #0. Accuracy on batch 1376 on Training is 30.31045751633987\n",
            "Epoch #0. Accuracy on batch 1377 on Training is 30.313407111756167\n",
            "Epoch #0. Accuracy on batch 1378 on Training is 30.31861856417694\n",
            "Epoch #0. Accuracy on batch 1379 on Training is 30.310235507246375\n",
            "Batch Id 1380 is having training loss of 551.2064208984375\n",
            "702.715576171875\n",
            "Epoch #0. Accuracy on batch 1380 on Training is 30.304127443881246\n",
            "Epoch #0. Accuracy on batch 1381 on Training is 30.309334298118667\n",
            "Epoch #0. Accuracy on batch 1382 on Training is 30.31001446131598\n",
            "Epoch #0. Accuracy on batch 1383 on Training is 30.310693641618496\n",
            "Epoch #0. Accuracy on batch 1384 on Training is 30.29783393501805\n",
            "Epoch #0. Accuracy on batch 1385 on Training is 30.300775613275615\n",
            "Epoch #0. Accuracy on batch 1386 on Training is 30.303713049747657\n",
            "Epoch #0. Accuracy on batch 1387 on Training is 30.306646253602306\n",
            "Epoch #0. Accuracy on batch 1388 on Training is 30.29607631389489\n",
            "Epoch #0. Accuracy on batch 1389 on Training is 30.303507194244606\n",
            "Epoch #0. Accuracy on batch 1390 on Training is 30.319913731128686\n",
            "Epoch #0. Accuracy on batch 1391 on Training is 30.309357040229884\n",
            "Epoch #0. Accuracy on batch 1392 on Training is 30.31227566403446\n",
            "Epoch #0. Accuracy on batch 1393 on Training is 30.308464849354376\n",
            "Epoch #0. Accuracy on batch 1394 on Training is 30.31137992831541\n",
            "Epoch #0. Accuracy on batch 1395 on Training is 30.307575214899714\n",
            "Epoch #0. Accuracy on batch 1396 on Training is 30.301539012168934\n",
            "Epoch #0. Accuracy on batch 1397 on Training is 30.313394134477825\n",
            "Epoch #0. Accuracy on batch 1398 on Training is 30.307362401715512\n",
            "Epoch #0. Accuracy on batch 1399 on Training is 30.303571428571427\n",
            "Batch Id 1400 is having training loss of 550.5928955078125\n",
            "106.38643646240234\n",
            "Epoch #0. Accuracy on batch 1400 on Training is 30.304246966452535\n",
            "Epoch #0. Accuracy on batch 1401 on Training is 30.30046362339515\n",
            "Epoch #0. Accuracy on batch 1402 on Training is 30.301140413399857\n",
            "Epoch #0. Accuracy on batch 1403 on Training is 30.299590455840455\n",
            "Epoch #0. Accuracy on batch 1404 on Training is 30.302491103202847\n",
            "Epoch #0. Accuracy on batch 1405 on Training is 30.296497155049785\n",
            "Epoch #0. Accuracy on batch 1406 on Training is 30.299395877754087\n",
            "Epoch #0. Accuracy on batch 1407 on Training is 30.2978515625\n",
            "Epoch #0. Accuracy on batch 1408 on Training is 30.307398864442867\n",
            "Epoch #0. Accuracy on batch 1409 on Training is 30.308067375886523\n",
            "Epoch #0. Accuracy on batch 1410 on Training is 30.306520198440822\n",
            "Epoch #0. Accuracy on batch 1411 on Training is 30.313827903682718\n",
            "Epoch #0. Accuracy on batch 1412 on Training is 30.31449044585987\n",
            "Epoch #0. Accuracy on batch 1413 on Training is 30.321782178217823\n",
            "Epoch #0. Accuracy on batch 1414 on Training is 30.32685512367491\n",
            "Epoch #0. Accuracy on batch 1415 on Training is 30.336334745762713\n",
            "Epoch #0. Accuracy on batch 1416 on Training is 30.339184897671135\n",
            "Epoch #0. Accuracy on batch 1417 on Training is 30.333215796897036\n",
            "Epoch #0. Accuracy on batch 1418 on Training is 30.33386187455955\n",
            "Epoch #0. Accuracy on batch 1419 on Training is 30.336707746478872\n",
            "Batch Id 1420 is having training loss of 548.4931640625\n",
            "3690.36572265625\n",
            "Epoch #0. Accuracy on batch 1420 on Training is 30.328553835327234\n",
            "Epoch #0. Accuracy on batch 1421 on Training is 30.32920182841069\n",
            "Epoch #0. Accuracy on batch 1422 on Training is 30.34082923401265\n",
            "Epoch #0. Accuracy on batch 1423 on Training is 30.33488412921348\n",
            "Epoch #0. Accuracy on batch 1424 on Training is 30.335526315789473\n",
            "Epoch #0. Accuracy on batch 1425 on Training is 30.33397615708275\n",
            "Epoch #0. Accuracy on batch 1426 on Training is 30.338997897687456\n",
            "Epoch #0. Accuracy on batch 1427 on Training is 30.330882352941178\n",
            "Epoch #0. Accuracy on batch 1428 on Training is 30.3315255423373\n",
            "Epoch #0. Accuracy on batch 1429 on Training is 30.33653846153846\n",
            "Epoch #0. Accuracy on batch 1430 on Training is 30.345911949685533\n",
            "Epoch #0. Accuracy on batch 1431 on Training is 30.33126745810056\n",
            "Epoch #0. Accuracy on batch 1432 on Training is 30.334089323098397\n",
            "Epoch #0. Accuracy on batch 1433 on Training is 30.328190376569037\n",
            "Epoch #0. Accuracy on batch 1434 on Training is 30.335365853658537\n",
            "Epoch #0. Accuracy on batch 1435 on Training is 30.33817896935933\n",
            "Epoch #0. Accuracy on batch 1436 on Training is 30.338813500347946\n",
            "Epoch #0. Accuracy on batch 1437 on Training is 30.350312934631432\n",
            "Epoch #0. Accuracy on batch 1438 on Training is 30.34442321056289\n",
            "Epoch #0. Accuracy on batch 1439 on Training is 30.342881944444443\n",
            "Batch Id 1440 is having training loss of 547.2815551757812\n",
            "20.466585159301758\n",
            "Epoch #0. Accuracy on batch 1440 on Training is 30.347848716169327\n",
            "Epoch #0. Accuracy on batch 1441 on Training is 30.34630721220527\n",
            "Epoch #0. Accuracy on batch 1442 on Training is 30.338270963270965\n",
            "Epoch #0. Accuracy on batch 1443 on Training is 30.34106648199446\n",
            "Epoch #0. Accuracy on batch 1444 on Training is 30.33304498269896\n",
            "Epoch #0. Accuracy on batch 1445 on Training is 30.338001383125864\n",
            "Epoch #0. Accuracy on batch 1446 on Training is 30.340791292328955\n",
            "Epoch #0. Accuracy on batch 1447 on Training is 30.334944751381215\n",
            "Epoch #0. Accuracy on batch 1448 on Training is 30.329106280193237\n",
            "Epoch #0. Accuracy on batch 1449 on Training is 30.33189655172414\n",
            "Epoch #0. Accuracy on batch 1450 on Training is 30.332529290144727\n",
            "Epoch #0. Accuracy on batch 1451 on Training is 30.33746556473829\n",
            "Epoch #0. Accuracy on batch 1452 on Training is 30.331641431520993\n",
            "Epoch #0. Accuracy on batch 1453 on Training is 30.33872077028886\n",
            "Epoch #0. Accuracy on batch 1454 on Training is 30.337199312714777\n",
            "Epoch #0. Accuracy on batch 1455 on Training is 30.329241071428573\n",
            "Epoch #0. Accuracy on batch 1456 on Training is 30.342741935483872\n",
            "Epoch #0. Accuracy on batch 1457 on Training is 30.334790809327846\n",
            "Epoch #0. Accuracy on batch 1458 on Training is 30.328992460589443\n",
            "Epoch #0. Accuracy on batch 1459 on Training is 30.340325342465754\n",
            "Batch Id 1460 is having training loss of 544.3287963867188\n",
            "270.923583984375\n",
            "Epoch #0. Accuracy on batch 1460 on Training is 30.33667008898015\n",
            "Epoch #0. Accuracy on batch 1461 on Training is 30.345844733242135\n",
            "Epoch #0. Accuracy on batch 1462 on Training is 30.34646274777854\n",
            "Epoch #0. Accuracy on batch 1463 on Training is 30.347079918032787\n",
            "Epoch #0. Accuracy on batch 1464 on Training is 30.34769624573379\n",
            "Epoch #0. Accuracy on batch 1465 on Training is 30.337653478854026\n",
            "Epoch #0. Accuracy on batch 1466 on Training is 30.336145194274028\n",
            "Epoch #0. Accuracy on batch 1467 on Training is 30.330381471389646\n",
            "Epoch #0. Accuracy on batch 1468 on Training is 30.339516678012252\n",
            "Epoch #0. Accuracy on batch 1469 on Training is 30.335884353741495\n",
            "Epoch #0. Accuracy on batch 1470 on Training is 30.3343813732155\n",
            "Epoch #0. Accuracy on batch 1471 on Training is 30.34349524456522\n",
            "Epoch #0. Accuracy on batch 1472 on Training is 30.344110658520027\n",
            "Epoch #0. Accuracy on batch 1473 on Training is 30.34472523744912\n",
            "Epoch #0. Accuracy on batch 1474 on Training is 30.347457627118644\n",
            "Epoch #0. Accuracy on batch 1475 on Training is 30.34595189701897\n",
            "Epoch #0. Accuracy on batch 1476 on Training is 30.348679756262694\n",
            "Epoch #0. Accuracy on batch 1477 on Training is 30.35140392422192\n",
            "Epoch #0. Accuracy on batch 1478 on Training is 30.347785665990536\n",
            "Epoch #0. Accuracy on batch 1479 on Training is 30.350506756756758\n",
            "Batch Id 1480 is having training loss of 547.6199951171875\n",
            "126.94143676757812\n",
            "Epoch #0. Accuracy on batch 1480 on Training is 30.342673869007427\n",
            "Epoch #0. Accuracy on batch 1481 on Training is 30.347503373819162\n",
            "Epoch #0. Accuracy on batch 1482 on Training is 30.354433580579904\n",
            "Epoch #0. Accuracy on batch 1483 on Training is 30.357142857142858\n",
            "Epoch #0. Accuracy on batch 1484 on Training is 30.357744107744107\n",
            "Epoch #0. Accuracy on batch 1485 on Training is 30.352035666218036\n",
            "Epoch #0. Accuracy on batch 1486 on Training is 30.35474108944183\n",
            "Epoch #0. Accuracy on batch 1487 on Training is 30.357442876344088\n",
            "Epoch #0. Accuracy on batch 1488 on Training is 30.360141034251175\n",
            "Epoch #0. Accuracy on batch 1489 on Training is 30.360738255033556\n",
            "Epoch #0. Accuracy on batch 1490 on Training is 30.369718309859156\n",
            "Epoch #0. Accuracy on batch 1491 on Training is 30.36821380697051\n",
            "Epoch #0. Accuracy on batch 1492 on Training is 30.372990622906897\n",
            "Epoch #0. Accuracy on batch 1493 on Training is 30.381944444444443\n",
            "Epoch #0. Accuracy on batch 1494 on Training is 30.37834448160535\n",
            "Epoch #0. Accuracy on batch 1495 on Training is 30.383104946524064\n",
            "Epoch #0. Accuracy on batch 1496 on Training is 30.381596526386105\n",
            "Epoch #0. Accuracy on batch 1497 on Training is 30.382176234979973\n",
            "Epoch #0. Accuracy on batch 1498 on Training is 30.391094062708472\n",
            "Epoch #0. Accuracy on batch 1499 on Training is 30.395833333333332\n",
            "Batch Id 1500 is having training loss of 541.4736938476562\n",
            "18.626346588134766\n",
            "Epoch #0. Accuracy on batch 1500 on Training is 30.394320453031312\n",
            "Epoch #0. Accuracy on batch 1501 on Training is 30.394890146471372\n",
            "Epoch #0. Accuracy on batch 1502 on Training is 30.397538256819693\n",
            "Epoch #0. Accuracy on batch 1503 on Training is 30.406416223404257\n",
            "Epoch #0. Accuracy on batch 1504 on Training is 30.40905315614618\n",
            "Epoch #0. Accuracy on batch 1505 on Training is 30.4054614873838\n",
            "Epoch #0. Accuracy on batch 1506 on Training is 30.397727272727273\n",
            "Epoch #0. Accuracy on batch 1507 on Training is 30.390003315649867\n",
            "Epoch #0. Accuracy on batch 1508 on Training is 30.388502319416833\n",
            "Epoch #0. Accuracy on batch 1509 on Training is 30.378725165562916\n",
            "Epoch #0. Accuracy on batch 1510 on Training is 30.377233620119128\n",
            "Epoch #0. Accuracy on batch 1511 on Training is 30.375744047619047\n",
            "Epoch #0. Accuracy on batch 1512 on Training is 30.376321877065433\n",
            "Epoch #0. Accuracy on batch 1513 on Training is 30.38102708058124\n",
            "Epoch #0. Accuracy on batch 1514 on Training is 30.385726072607262\n",
            "Epoch #0. Accuracy on batch 1515 on Training is 30.38423482849604\n",
            "Epoch #0. Accuracy on batch 1516 on Training is 30.382745550428478\n",
            "Epoch #0. Accuracy on batch 1517 on Training is 30.383316864295125\n",
            "Epoch #0. Accuracy on batch 1518 on Training is 30.383887425938116\n",
            "Epoch #0. Accuracy on batch 1519 on Training is 30.37417763157895\n",
            "Batch Id 1520 is having training loss of 554.2871704101562\n",
            "46.41735076904297\n",
            "Epoch #0. Accuracy on batch 1520 on Training is 30.366535174227483\n",
            "Epoch #0. Accuracy on batch 1521 on Training is 30.3732752956636\n",
            "Epoch #0. Accuracy on batch 1522 on Training is 30.37795469468155\n",
            "Epoch #0. Accuracy on batch 1523 on Training is 30.38467847769029\n",
            "Epoch #0. Accuracy on batch 1524 on Training is 30.37295081967213\n",
            "Epoch #0. Accuracy on batch 1525 on Training is 30.37762123197903\n",
            "Epoch #0. Accuracy on batch 1526 on Training is 30.37205304518664\n",
            "Epoch #0. Accuracy on batch 1527 on Training is 30.372627617801047\n",
            "Epoch #0. Accuracy on batch 1528 on Training is 30.367069980379334\n",
            "Epoch #0. Accuracy on batch 1529 on Training is 30.37173202614379\n",
            "Epoch #0. Accuracy on batch 1530 on Training is 30.366182233834095\n",
            "Epoch #0. Accuracy on batch 1531 on Training is 30.37287859007833\n",
            "Epoch #0. Accuracy on batch 1532 on Training is 30.375489236790607\n",
            "Epoch #0. Accuracy on batch 1533 on Training is 30.3740221642764\n",
            "Epoch #0. Accuracy on batch 1534 on Training is 30.376628664495115\n",
            "Epoch #0. Accuracy on batch 1535 on Training is 30.379231770833332\n",
            "Epoch #0. Accuracy on batch 1536 on Training is 30.37573194534808\n",
            "Epoch #0. Accuracy on batch 1537 on Training is 30.366141092327698\n",
            "Epoch #0. Accuracy on batch 1538 on Training is 30.362654320987655\n",
            "Epoch #0. Accuracy on batch 1539 on Training is 30.36525974025974\n",
            "Batch Id 1540 is having training loss of 549.453125\n",
            "171.7600860595703\n",
            "Epoch #0. Accuracy on batch 1540 on Training is 30.361778066190784\n",
            "Epoch #0. Accuracy on batch 1541 on Training is 30.364380674448768\n",
            "Epoch #0. Accuracy on batch 1542 on Training is 30.3649546338302\n",
            "Epoch #0. Accuracy on batch 1543 on Training is 30.369575777202073\n",
            "Epoch #0. Accuracy on batch 1544 on Training is 30.37014563106796\n",
            "Epoch #0. Accuracy on batch 1545 on Training is 30.36869340232859\n",
            "Epoch #0. Accuracy on batch 1546 on Training is 30.365223012281835\n",
            "Epoch #0. Accuracy on batch 1547 on Training is 30.355700904392766\n",
            "Epoch #0. Accuracy on batch 1548 on Training is 30.356278244028406\n",
            "Epoch #0. Accuracy on batch 1549 on Training is 30.356854838709676\n",
            "Epoch #0. Accuracy on batch 1550 on Training is 30.351386202450033\n",
            "Epoch #0. Accuracy on batch 1551 on Training is 30.34592461340206\n",
            "Epoch #0. Accuracy on batch 1552 on Training is 30.34449452672247\n",
            "Epoch #0. Accuracy on batch 1553 on Training is 30.34708815958816\n",
            "Epoch #0. Accuracy on batch 1554 on Training is 30.35369774919614\n",
            "Epoch #0. Accuracy on batch 1555 on Training is 30.366323907455012\n",
            "Epoch #0. Accuracy on batch 1556 on Training is 30.356856133590238\n",
            "Epoch #0. Accuracy on batch 1557 on Training is 30.365452503209244\n",
            "Epoch #0. Accuracy on batch 1558 on Training is 30.355997434252725\n",
            "Epoch #0. Accuracy on batch 1559 on Training is 30.356570512820515\n",
            "Batch Id 1560 is having training loss of 547.521728515625\n",
            "151.03616333007812\n",
            "Epoch #0. Accuracy on batch 1560 on Training is 30.351137091607942\n",
            "Epoch #0. Accuracy on batch 1561 on Training is 30.349711907810498\n",
            "Epoch #0. Accuracy on batch 1562 on Training is 30.352287268074218\n",
            "Epoch #0. Accuracy on batch 1563 on Training is 30.348865089514067\n",
            "Epoch #0. Accuracy on batch 1564 on Training is 30.35143769968051\n",
            "Epoch #0. Accuracy on batch 1565 on Training is 30.350015964240104\n",
            "Epoch #0. Accuracy on batch 1566 on Training is 30.352584556477346\n",
            "Epoch #0. Accuracy on batch 1567 on Training is 30.357142857142858\n",
            "Epoch #0. Accuracy on batch 1568 on Training is 30.35970363288719\n",
            "Epoch #0. Accuracy on batch 1569 on Training is 30.366242038216562\n",
            "Epoch #0. Accuracy on batch 1570 on Training is 30.372772119669\n",
            "Epoch #0. Accuracy on batch 1571 on Training is 30.373330152671755\n",
            "Epoch #0. Accuracy on batch 1572 on Training is 30.37984742530197\n",
            "Epoch #0. Accuracy on batch 1573 on Training is 30.392312579415503\n",
            "Epoch #0. Accuracy on batch 1574 on Training is 30.398809523809526\n",
            "Epoch #0. Accuracy on batch 1575 on Training is 30.403315355329948\n",
            "Epoch #0. Accuracy on batch 1576 on Training is 30.40781547241598\n",
            "Epoch #0. Accuracy on batch 1577 on Training is 30.40834917617237\n",
            "Epoch #0. Accuracy on batch 1578 on Training is 30.40492400253325\n",
            "Epoch #0. Accuracy on batch 1579 on Training is 30.40348101265823\n",
            "Batch Id 1580 is having training loss of 542.343017578125\n",
            "109.6660385131836\n",
            "Epoch #0. Accuracy on batch 1580 on Training is 30.40994623655914\n",
            "Epoch #0. Accuracy on batch 1581 on Training is 30.408501896333753\n",
            "Epoch #0. Accuracy on batch 1582 on Training is 30.4070593809223\n",
            "Epoch #0. Accuracy on batch 1583 on Training is 30.40561868686869\n",
            "Epoch #0. Accuracy on batch 1584 on Training is 30.39826498422713\n",
            "Epoch #0. Accuracy on batch 1585 on Training is 30.396831651954603\n",
            "Epoch #0. Accuracy on batch 1586 on Training is 30.391461877756775\n",
            "Epoch #0. Accuracy on batch 1587 on Training is 30.39397040302267\n",
            "Epoch #0. Accuracy on batch 1588 on Training is 30.394509125236\n",
            "Epoch #0. Accuracy on batch 1589 on Training is 30.39701257861635\n",
            "Epoch #0. Accuracy on batch 1590 on Training is 30.399512884978\n",
            "Epoch #0. Accuracy on batch 1591 on Training is 30.38826947236181\n",
            "Epoch #0. Accuracy on batch 1592 on Training is 30.384887005649716\n",
            "Epoch #0. Accuracy on batch 1593 on Training is 30.387390213299874\n",
            "Epoch #0. Accuracy on batch 1594 on Training is 30.399686520376175\n",
            "Epoch #0. Accuracy on batch 1595 on Training is 30.404135338345863\n",
            "Epoch #0. Accuracy on batch 1596 on Training is 30.400751408891672\n",
            "Epoch #0. Accuracy on batch 1597 on Training is 30.405193992490613\n",
            "Epoch #0. Accuracy on batch 1598 on Training is 30.403767979987492\n",
            "Epoch #0. Accuracy on batch 1599 on Training is 30.400390625\n",
            "Batch Id 1600 is having training loss of 545.0987548828125\n",
            "22.60865592956543\n",
            "Epoch #0. Accuracy on batch 1600 on Training is 30.400921299188006\n",
            "Epoch #0. Accuracy on batch 1601 on Training is 30.391697877652934\n",
            "Epoch #0. Accuracy on batch 1602 on Training is 30.3863849033063\n",
            "Epoch #0. Accuracy on batch 1603 on Training is 30.39081982543641\n",
            "Epoch #0. Accuracy on batch 1604 on Training is 30.3952492211838\n",
            "Epoch #0. Accuracy on batch 1605 on Training is 30.393835616438356\n",
            "Epoch #0. Accuracy on batch 1606 on Training is 30.388534536403235\n",
            "Epoch #0. Accuracy on batch 1607 on Training is 30.39295708955224\n",
            "Epoch #0. Accuracy on batch 1608 on Training is 30.393489745183345\n",
            "Epoch #0. Accuracy on batch 1609 on Training is 30.386257763975156\n",
            "Epoch #0. Accuracy on batch 1610 on Training is 30.384854127870888\n",
            "Epoch #0. Accuracy on batch 1611 on Training is 30.38539081885856\n",
            "Epoch #0. Accuracy on batch 1612 on Training is 30.389801611903287\n",
            "Epoch #0. Accuracy on batch 1613 on Training is 30.392270755886\n",
            "Epoch #0. Accuracy on batch 1614 on Training is 30.385061919504643\n",
            "Epoch #0. Accuracy on batch 1615 on Training is 30.38172957920792\n",
            "Epoch #0. Accuracy on batch 1616 on Training is 30.38226654298083\n",
            "Epoch #0. Accuracy on batch 1617 on Training is 30.37894004944376\n",
            "Epoch #0. Accuracy on batch 1618 on Training is 30.383338480543546\n",
            "Epoch #0. Accuracy on batch 1619 on Training is 30.378086419753085\n",
            "Batch Id 1620 is having training loss of 539.397216796875\n",
            "12.288994789123535\n",
            "Epoch #0. Accuracy on batch 1620 on Training is 30.386335595311536\n",
            "Epoch #0. Accuracy on batch 1621 on Training is 30.392647965474723\n",
            "Epoch #0. Accuracy on batch 1622 on Training is 30.389325323475045\n",
            "Epoch #0. Accuracy on batch 1623 on Training is 30.382158251231527\n",
            "Epoch #0. Accuracy on batch 1624 on Training is 30.373076923076923\n",
            "Epoch #0. Accuracy on batch 1625 on Training is 30.375538130381305\n",
            "Epoch #0. Accuracy on batch 1626 on Training is 30.37415488629379\n",
            "Epoch #0. Accuracy on batch 1627 on Training is 30.37277334152334\n",
            "Epoch #0. Accuracy on batch 1628 on Training is 30.361801718845918\n",
            "Epoch #0. Accuracy on batch 1629 on Training is 30.36234662576687\n",
            "Epoch #0. Accuracy on batch 1630 on Training is 30.368638871857755\n",
            "Epoch #0. Accuracy on batch 1631 on Training is 30.374923406862745\n",
            "Epoch #0. Accuracy on batch 1632 on Training is 30.381200244947948\n",
            "Epoch #0. Accuracy on batch 1633 on Training is 30.370257037943695\n",
            "Epoch #0. Accuracy on batch 1634 on Training is 30.37079510703364\n",
            "Epoch #0. Accuracy on batch 1635 on Training is 30.367512224938874\n",
            "Epoch #0. Accuracy on batch 1636 on Training is 30.366142333536956\n",
            "Epoch #0. Accuracy on batch 1637 on Training is 30.368589743589745\n",
            "Epoch #0. Accuracy on batch 1638 on Training is 30.369127516778523\n",
            "Epoch #0. Accuracy on batch 1639 on Training is 30.365853658536587\n",
            "Batch Id 1640 is having training loss of 535.1886596679688\n",
            "545.9342651367188\n",
            "Epoch #0. Accuracy on batch 1640 on Training is 30.362583790371726\n",
            "Epoch #0. Accuracy on batch 1641 on Training is 30.368833739342264\n",
            "Epoch #0. Accuracy on batch 1642 on Training is 30.361762020693853\n",
            "Epoch #0. Accuracy on batch 1643 on Training is 30.360401459854014\n",
            "Epoch #0. Accuracy on batch 1644 on Training is 30.357142857142858\n",
            "Epoch #0. Accuracy on batch 1645 on Training is 30.357685297691372\n",
            "Epoch #0. Accuracy on batch 1646 on Training is 30.356329690346083\n",
            "Epoch #0. Accuracy on batch 1647 on Training is 30.37204186893204\n",
            "Epoch #0. Accuracy on batch 1648 on Training is 30.3763644633111\n",
            "Epoch #0. Accuracy on batch 1649 on Training is 30.373106060606062\n",
            "Epoch #0. Accuracy on batch 1650 on Training is 30.371744397334947\n",
            "Epoch #0. Accuracy on batch 1651 on Training is 30.36660108958838\n",
            "Epoch #0. Accuracy on batch 1652 on Training is 30.367135511191773\n",
            "Epoch #0. Accuracy on batch 1653 on Training is 30.36577992744861\n",
            "Epoch #0. Accuracy on batch 1654 on Training is 30.362537764350453\n",
            "Epoch #0. Accuracy on batch 1655 on Training is 30.359299516908212\n",
            "Epoch #0. Accuracy on batch 1656 on Training is 30.346635485817743\n",
            "Epoch #0. Accuracy on batch 1657 on Training is 30.34906513872135\n",
            "Epoch #0. Accuracy on batch 1658 on Training is 30.351491862567812\n",
            "Epoch #0. Accuracy on batch 1659 on Training is 30.344503012048193\n",
            "Batch Id 1660 is having training loss of 554.7669677734375\n",
            "40.486610412597656\n",
            "Epoch #0. Accuracy on batch 1660 on Training is 30.339403973509935\n",
            "Epoch #0. Accuracy on batch 1661 on Training is 30.341832129963898\n",
            "Epoch #0. Accuracy on batch 1662 on Training is 30.340499098015634\n",
            "Epoch #0. Accuracy on batch 1663 on Training is 30.33728966346154\n",
            "Epoch #0. Accuracy on batch 1664 on Training is 30.33596096096096\n",
            "Epoch #0. Accuracy on batch 1665 on Training is 30.336509603841538\n",
            "Epoch #0. Accuracy on batch 1666 on Training is 30.342681463707258\n",
            "Epoch #0. Accuracy on batch 1667 on Training is 30.34135191846523\n",
            "Epoch #0. Accuracy on batch 1668 on Training is 30.341896345116837\n",
            "Epoch #0. Accuracy on batch 1669 on Training is 30.33869760479042\n",
            "Epoch #0. Accuracy on batch 1670 on Training is 30.32802214242968\n",
            "Epoch #0. Accuracy on batch 1671 on Training is 30.330442583732058\n",
            "Epoch #0. Accuracy on batch 1672 on Training is 30.321652719665273\n",
            "Epoch #0. Accuracy on batch 1673 on Training is 30.324074074074073\n",
            "Epoch #0. Accuracy on batch 1674 on Training is 30.330223880597014\n",
            "Epoch #0. Accuracy on batch 1675 on Training is 30.33636634844869\n",
            "Epoch #0. Accuracy on batch 1676 on Training is 30.333184257602863\n",
            "Epoch #0. Accuracy on batch 1677 on Training is 30.330005959475567\n",
            "Epoch #0. Accuracy on batch 1678 on Training is 30.324970220369266\n",
            "Epoch #0. Accuracy on batch 1679 on Training is 30.325520833333332\n",
            "Batch Id 1680 is having training loss of 559.3565063476562\n",
            "113.19906616210938\n",
            "Epoch #0. Accuracy on batch 1680 on Training is 30.316775728732896\n",
            "Epoch #0. Accuracy on batch 1681 on Training is 30.313614744351963\n",
            "Epoch #0. Accuracy on batch 1682 on Training is 30.317884729649435\n",
            "Epoch #0. Accuracy on batch 1683 on Training is 30.31472684085511\n",
            "Epoch #0. Accuracy on batch 1684 on Training is 30.31528189910979\n",
            "Epoch #0. Accuracy on batch 1685 on Training is 30.312129300118624\n",
            "Epoch #0. Accuracy on batch 1686 on Training is 30.3015708358032\n",
            "Epoch #0. Accuracy on batch 1687 on Training is 30.307686611374407\n",
            "Epoch #0. Accuracy on batch 1688 on Training is 30.31009473060983\n",
            "Epoch #0. Accuracy on batch 1689 on Training is 30.314349112426036\n",
            "Epoch #0. Accuracy on batch 1690 on Training is 30.314902424600827\n",
            "Epoch #0. Accuracy on batch 1691 on Training is 30.309914302600472\n",
            "Epoch #0. Accuracy on batch 1692 on Training is 30.30862374483166\n",
            "Epoch #0. Accuracy on batch 1693 on Training is 30.305489964580875\n",
            "Epoch #0. Accuracy on batch 1694 on Training is 30.3023598820059\n",
            "Epoch #0. Accuracy on batch 1695 on Training is 30.30291863207547\n",
            "Epoch #0. Accuracy on batch 1696 on Training is 30.31452563347083\n",
            "Epoch #0. Accuracy on batch 1697 on Training is 30.318757361601886\n",
            "Epoch #0. Accuracy on batch 1698 on Training is 30.322984108299\n",
            "Epoch #0. Accuracy on batch 1699 on Training is 30.325367647058822\n",
            "Batch Id 1700 is having training loss of 558.3428344726562\n",
            "173.2926788330078\n",
            "Epoch #0. Accuracy on batch 1700 on Training is 30.324074074074073\n",
            "Epoch #0. Accuracy on batch 1701 on Training is 30.322782021151585\n",
            "Epoch #0. Accuracy on batch 1702 on Training is 30.32516147974163\n",
            "Epoch #0. Accuracy on batch 1703 on Training is 30.316534624413144\n",
            "Epoch #0. Accuracy on batch 1704 on Training is 30.31708211143695\n",
            "Epoch #0. Accuracy on batch 1705 on Training is 30.313965416178196\n",
            "Epoch #0. Accuracy on batch 1706 on Training is 30.312683069712946\n",
            "Epoch #0. Accuracy on batch 1707 on Training is 30.305913348946135\n",
            "Epoch #0. Accuracy on batch 1708 on Training is 30.295494441193682\n",
            "Epoch #0. Accuracy on batch 1709 on Training is 30.28874269005848\n",
            "Epoch #0. Accuracy on batch 1710 on Training is 30.28930450029223\n",
            "Epoch #0. Accuracy on batch 1711 on Training is 30.28438960280374\n",
            "Epoch #0. Accuracy on batch 1712 on Training is 30.290426152948044\n",
            "Epoch #0. Accuracy on batch 1713 on Training is 30.287339556592766\n",
            "Epoch #0. Accuracy on batch 1714 on Training is 30.287900874635568\n",
            "Epoch #0. Accuracy on batch 1715 on Training is 30.28481934731935\n",
            "Epoch #0. Accuracy on batch 1716 on Training is 30.283561444379732\n",
            "Epoch #0. Accuracy on batch 1717 on Training is 30.289580908032598\n",
            "Epoch #0. Accuracy on batch 1718 on Training is 30.290139616055846\n",
            "Epoch #0. Accuracy on batch 1719 on Training is 30.296148255813954\n",
            "Batch Id 1720 is having training loss of 560.685302734375\n",
            "765.3665771484375\n",
            "Epoch #0. Accuracy on batch 1720 on Training is 30.28943927948867\n",
            "Epoch #0. Accuracy on batch 1721 on Training is 30.289997096399535\n",
            "Epoch #0. Accuracy on batch 1722 on Training is 30.285113174695297\n",
            "Epoch #0. Accuracy on batch 1723 on Training is 30.280234918793504\n",
            "Epoch #0. Accuracy on batch 1724 on Training is 30.27536231884058\n",
            "Epoch #0. Accuracy on batch 1725 on Training is 30.27592699884125\n",
            "Epoch #0. Accuracy on batch 1726 on Training is 30.26925303995368\n",
            "Epoch #0. Accuracy on batch 1727 on Training is 30.26982060185185\n",
            "Epoch #0. Accuracy on batch 1728 on Training is 30.26858010410642\n",
            "Epoch #0. Accuracy on batch 1729 on Training is 30.26914739884393\n",
            "Epoch #0. Accuracy on batch 1730 on Training is 30.266103408434432\n",
            "Epoch #0. Accuracy on batch 1731 on Training is 30.264867205542725\n",
            "Epoch #0. Accuracy on batch 1732 on Training is 30.26363242931333\n",
            "Epoch #0. Accuracy on batch 1733 on Training is 30.258794694348328\n",
            "Epoch #0. Accuracy on batch 1734 on Training is 30.26837175792507\n",
            "Epoch #0. Accuracy on batch 1735 on Training is 30.272537442396313\n",
            "Epoch #0. Accuracy on batch 1736 on Training is 30.271301093839956\n",
            "Epoch #0. Accuracy on batch 1737 on Training is 30.26647008055236\n",
            "Epoch #0. Accuracy on batch 1738 on Training is 30.270629672225418\n",
            "Epoch #0. Accuracy on batch 1739 on Training is 30.26939655172414\n",
            "Batch Id 1740 is having training loss of 569.0822143554688\n",
            "2987.072021484375\n",
            "Epoch #0. Accuracy on batch 1740 on Training is 30.271754738655943\n",
            "Epoch #0. Accuracy on batch 1741 on Training is 30.27411021814007\n",
            "Epoch #0. Accuracy on batch 1742 on Training is 30.271084337349397\n",
            "Epoch #0. Accuracy on batch 1743 on Training is 30.26627006880734\n",
            "Epoch #0. Accuracy on batch 1744 on Training is 30.263252148997136\n",
            "Epoch #0. Accuracy on batch 1745 on Training is 30.26023768613975\n",
            "Epoch #0. Accuracy on batch 1746 on Training is 30.260804235832858\n",
            "Epoch #0. Accuracy on batch 1747 on Training is 30.25421910755149\n",
            "Epoch #0. Accuracy on batch 1748 on Training is 30.251214979988564\n",
            "Epoch #0. Accuracy on batch 1749 on Training is 30.239285714285714\n",
            "Epoch #0. Accuracy on batch 1750 on Training is 30.232724157624215\n",
            "Epoch #0. Accuracy on batch 1751 on Training is 30.23152111872146\n",
            "Epoch #0. Accuracy on batch 1752 on Training is 30.24101540216771\n",
            "Epoch #0. Accuracy on batch 1753 on Training is 30.246935575826683\n",
            "Epoch #0. Accuracy on batch 1754 on Training is 30.247507122507123\n",
            "Epoch #0. Accuracy on batch 1755 on Training is 30.2498576309795\n",
            "Epoch #0. Accuracy on batch 1756 on Training is 30.25220546385885\n",
            "Epoch #0. Accuracy on batch 1757 on Training is 30.242107508532424\n",
            "Epoch #0. Accuracy on batch 1758 on Training is 30.24268050028425\n",
            "Epoch #0. Accuracy on batch 1759 on Training is 30.248579545454547\n",
            "Batch Id 1760 is having training loss of 566.4859619140625\n",
            "31.042171478271484\n",
            "Epoch #0. Accuracy on batch 1760 on Training is 30.258021010789324\n",
            "Epoch #0. Accuracy on batch 1761 on Training is 30.255036889897845\n",
            "Epoch #0. Accuracy on batch 1762 on Training is 30.250283607487237\n",
            "Epoch #0. Accuracy on batch 1763 on Training is 30.24730725623583\n",
            "Epoch #0. Accuracy on batch 1764 on Training is 30.240793201133144\n",
            "Epoch #0. Accuracy on batch 1765 on Training is 30.239595130237827\n",
            "Epoch #0. Accuracy on batch 1766 on Training is 30.2366298811545\n",
            "Epoch #0. Accuracy on batch 1767 on Training is 30.237203054298643\n",
            "Epoch #0. Accuracy on batch 1768 on Training is 30.23247597512719\n",
            "Epoch #0. Accuracy on batch 1769 on Training is 30.236581920903955\n",
            "Epoch #0. Accuracy on batch 1770 on Training is 30.228331451157537\n",
            "Epoch #0. Accuracy on batch 1771 on Training is 30.230671557562076\n",
            "Epoch #0. Accuracy on batch 1772 on Training is 30.24358432036097\n",
            "Epoch #0. Accuracy on batch 1773 on Training is 30.235343855693348\n",
            "Epoch #0. Accuracy on batch 1774 on Training is 30.2306338028169\n",
            "Epoch #0. Accuracy on batch 1775 on Training is 30.23824605855856\n",
            "Epoch #0. Accuracy on batch 1776 on Training is 30.23178109172763\n",
            "Epoch #0. Accuracy on batch 1777 on Training is 30.232353768278966\n",
            "Epoch #0. Accuracy on batch 1778 on Training is 30.238195615514336\n",
            "Epoch #0. Accuracy on batch 1779 on Training is 30.233497191011235\n",
            "Batch Id 1780 is having training loss of 566.860595703125\n",
            "72.7083969116211\n",
            "Epoch #0. Accuracy on batch 1780 on Training is 30.232313307130827\n",
            "Epoch #0. Accuracy on batch 1781 on Training is 30.23639169472503\n",
            "Epoch #0. Accuracy on batch 1782 on Training is 30.2369601794728\n",
            "Epoch #0. Accuracy on batch 1783 on Training is 30.24103139013453\n",
            "Epoch #0. Accuracy on batch 1784 on Training is 30.241596638655462\n",
            "Epoch #0. Accuracy on batch 1785 on Training is 30.240411534154536\n",
            "Epoch #0. Accuracy on batch 1786 on Training is 30.24447397873531\n",
            "Epoch #0. Accuracy on batch 1787 on Training is 30.253775167785236\n",
            "Epoch #0. Accuracy on batch 1788 on Training is 30.250838457238682\n",
            "Epoch #0. Accuracy on batch 1789 on Training is 30.254888268156424\n",
            "Epoch #0. Accuracy on batch 1790 on Training is 30.2606783919598\n",
            "Epoch #0. Accuracy on batch 1791 on Training is 30.257742745535715\n",
            "Epoch #0. Accuracy on batch 1792 on Training is 30.25829615170106\n",
            "Epoch #0. Accuracy on batch 1793 on Training is 30.25188127090301\n",
            "Epoch #0. Accuracy on batch 1794 on Training is 30.245473537604457\n",
            "Epoch #0. Accuracy on batch 1795 on Training is 30.237332962138083\n",
            "Epoch #0. Accuracy on batch 1796 on Training is 30.234418475236506\n",
            "Epoch #0. Accuracy on batch 1797 on Training is 30.24019744160178\n",
            "Epoch #0. Accuracy on batch 1798 on Training is 30.240758754863812\n",
            "Epoch #0. Accuracy on batch 1799 on Training is 30.24652777777778\n",
            "Batch Id 1800 is having training loss of 570.5071411132812\n",
            "25.481388092041016\n",
            "Epoch #0. Accuracy on batch 1800 on Training is 30.247084952804\n",
            "Epoch #0. Accuracy on batch 1801 on Training is 30.235502219755826\n",
            "Epoch #0. Accuracy on batch 1802 on Training is 30.230865224625624\n",
            "Epoch #0. Accuracy on batch 1803 on Training is 30.229697893569845\n",
            "Epoch #0. Accuracy on batch 1804 on Training is 30.225069252077564\n",
            "Epoch #0. Accuracy on batch 1805 on Training is 30.232558139534884\n",
            "Epoch #0. Accuracy on batch 1806 on Training is 30.233121195351412\n",
            "Epoch #0. Accuracy on batch 1807 on Training is 30.235412057522122\n",
            "Epoch #0. Accuracy on batch 1808 on Training is 30.23251796572692\n",
            "Epoch #0. Accuracy on batch 1809 on Training is 30.224447513812155\n",
            "Epoch #0. Accuracy on batch 1810 on Training is 30.214660408614026\n",
            "Epoch #0. Accuracy on batch 1811 on Training is 30.21523178807947\n",
            "Epoch #0. Accuracy on batch 1812 on Training is 30.208907887479317\n",
            "Epoch #0. Accuracy on batch 1813 on Training is 30.21120452039691\n",
            "Epoch #0. Accuracy on batch 1814 on Training is 30.21177685950413\n",
            "Epoch #0. Accuracy on batch 1815 on Training is 30.21751101321586\n",
            "Epoch #0. Accuracy on batch 1816 on Training is 30.212919647771052\n",
            "Epoch #0. Accuracy on batch 1817 on Training is 30.204895489548957\n",
            "Epoch #0. Accuracy on batch 1818 on Training is 30.208905992303464\n",
            "Epoch #0. Accuracy on batch 1819 on Training is 30.20776098901099\n",
            "Batch Id 1820 is having training loss of 568.8712158203125\n",
            "21.971725463867188\n",
            "Epoch #0. Accuracy on batch 1820 on Training is 30.213481603514552\n",
            "Epoch #0. Accuracy on batch 1821 on Training is 30.21576564215148\n",
            "Epoch #0. Accuracy on batch 1822 on Training is 30.22490400438837\n",
            "Epoch #0. Accuracy on batch 1823 on Training is 30.21861293859649\n",
            "Epoch #0. Accuracy on batch 1824 on Training is 30.222602739726028\n",
            "Epoch #0. Accuracy on batch 1825 on Training is 30.21460843373494\n",
            "Epoch #0. Accuracy on batch 1826 on Training is 30.2185960591133\n",
            "Epoch #0. Accuracy on batch 1827 on Training is 30.220869803063458\n",
            "Epoch #0. Accuracy on batch 1828 on Training is 30.22826681246583\n",
            "Epoch #0. Accuracy on batch 1829 on Training is 30.2271174863388\n",
            "Epoch #0. Accuracy on batch 1830 on Training is 30.227676133260513\n",
            "Epoch #0. Accuracy on batch 1831 on Training is 30.22993995633188\n",
            "Epoch #0. Accuracy on batch 1832 on Training is 30.22708674304419\n",
            "Epoch #0. Accuracy on batch 1833 on Training is 30.23275627044711\n",
            "Epoch #0. Accuracy on batch 1834 on Training is 30.228201634877383\n",
            "Epoch #0. Accuracy on batch 1835 on Training is 30.230460239651418\n",
            "Epoch #0. Accuracy on batch 1836 on Training is 30.22591181273816\n",
            "Epoch #0. Accuracy on batch 1837 on Training is 30.228169205658325\n",
            "Epoch #0. Accuracy on batch 1838 on Training is 30.228724850462207\n",
            "Epoch #0. Accuracy on batch 1839 on Training is 30.237771739130434\n",
            "Batch Id 1840 is having training loss of 602.255126953125\n",
            "595.6549682617188\n",
            "Epoch #0. Accuracy on batch 1840 on Training is 30.23832156436719\n",
            "Epoch #0. Accuracy on batch 1841 on Training is 30.235477741585232\n",
            "Epoch #0. Accuracy on batch 1842 on Training is 30.22755018990776\n",
            "Epoch #0. Accuracy on batch 1843 on Training is 30.221325921908893\n",
            "Epoch #0. Accuracy on batch 1844 on Training is 30.21849593495935\n",
            "Epoch #0. Accuracy on batch 1845 on Training is 30.212283315276274\n",
            "Epoch #0. Accuracy on batch 1846 on Training is 30.217920952896588\n",
            "Epoch #0. Accuracy on batch 1847 on Training is 30.21678841991342\n",
            "Epoch #0. Accuracy on batch 1848 on Training is 30.215657111952407\n",
            "Epoch #0. Accuracy on batch 1849 on Training is 30.216216216216218\n",
            "Epoch #0. Accuracy on batch 1850 on Training is 30.208333333333332\n",
            "Epoch #0. Accuracy on batch 1851 on Training is 30.205521058315334\n",
            "Epoch #0. Accuracy on batch 1852 on Training is 30.211144090663787\n",
            "Epoch #0. Accuracy on batch 1853 on Training is 30.208333333333332\n",
            "Epoch #0. Accuracy on batch 1854 on Training is 30.212264150943398\n",
            "Epoch #0. Accuracy on batch 1855 on Training is 30.211139547413794\n",
            "Epoch #0. Accuracy on batch 1856 on Training is 30.21001615508885\n",
            "Epoch #0. Accuracy on batch 1857 on Training is 30.203848223896664\n",
            "Epoch #0. Accuracy on batch 1858 on Training is 30.207772996234535\n",
            "Epoch #0. Accuracy on batch 1859 on Training is 30.203293010752688\n",
            "Batch Id 1860 is having training loss of 600.3640747070312\n",
            "14.753398895263672\n",
            "Epoch #0. Accuracy on batch 1860 on Training is 30.20889306824288\n",
            "Epoch #0. Accuracy on batch 1861 on Training is 30.2077738990333\n",
            "Epoch #0. Accuracy on batch 1862 on Training is 30.20162372517445\n",
            "Epoch #0. Accuracy on batch 1863 on Training is 30.20050965665236\n",
            "Epoch #0. Accuracy on batch 1864 on Training is 30.20274798927614\n",
            "Epoch #0. Accuracy on batch 1865 on Training is 30.201634512325832\n",
            "Epoch #0. Accuracy on batch 1866 on Training is 30.20052222817354\n",
            "Epoch #0. Accuracy on batch 1867 on Training is 30.196065310492504\n",
            "Epoch #0. Accuracy on batch 1868 on Training is 30.198301230604603\n",
            "Epoch #0. Accuracy on batch 1869 on Training is 30.203877005347593\n",
            "Epoch #0. Accuracy on batch 1870 on Training is 30.194414751469804\n",
            "Epoch #0. Accuracy on batch 1871 on Training is 30.198317307692307\n",
            "Epoch #0. Accuracy on batch 1872 on Training is 30.200547250400426\n",
            "Epoch #0. Accuracy on batch 1873 on Training is 30.19777214514408\n",
            "Epoch #0. Accuracy on batch 1874 on Training is 30.198333333333334\n",
            "Epoch #0. Accuracy on batch 1875 on Training is 30.190565031982942\n",
            "Epoch #0. Accuracy on batch 1876 on Training is 30.186134789557805\n",
            "Epoch #0. Accuracy on batch 1877 on Training is 30.191693290734825\n",
            "Epoch #0. Accuracy on batch 1878 on Training is 30.19890899414582\n",
            "Epoch #0. Accuracy on batch 1879 on Training is 30.20279255319149\n",
            "Batch Id 1880 is having training loss of 606.4263916015625\n",
            "22.37879180908203\n",
            "Epoch #0. Accuracy on batch 1880 on Training is 30.20168793195109\n",
            "Epoch #0. Accuracy on batch 1881 on Training is 30.19892401700319\n",
            "Epoch #0. Accuracy on batch 1882 on Training is 30.196163037705787\n",
            "Epoch #0. Accuracy on batch 1883 on Training is 30.200039808917197\n",
            "Epoch #0. Accuracy on batch 1884 on Training is 30.19893899204244\n",
            "Epoch #0. Accuracy on batch 1885 on Training is 30.202810180275716\n",
            "Epoch #0. Accuracy on batch 1886 on Training is 30.206677265500794\n",
            "Epoch #0. Accuracy on batch 1887 on Training is 30.20557468220339\n",
            "Epoch #0. Accuracy on batch 1888 on Training is 30.201164637374273\n",
            "Epoch #0. Accuracy on batch 1889 on Training is 30.208333333333332\n",
            "Epoch #0. Accuracy on batch 1890 on Training is 30.21053675304072\n",
            "Epoch #0. Accuracy on batch 1891 on Training is 30.214389534883722\n",
            "Epoch #0. Accuracy on batch 1892 on Training is 30.2182382461701\n",
            "Epoch #0. Accuracy on batch 1893 on Training is 30.222082893347412\n",
            "Epoch #0. Accuracy on batch 1894 on Training is 30.216029023746703\n",
            "Epoch #0. Accuracy on batch 1895 on Training is 30.21822257383966\n",
            "Epoch #0. Accuracy on batch 1896 on Training is 30.21547179757512\n",
            "Epoch #0. Accuracy on batch 1897 on Training is 30.217663329820866\n",
            "Epoch #0. Accuracy on batch 1898 on Training is 30.218206951026858\n",
            "Epoch #0. Accuracy on batch 1899 on Training is 30.213815789473685\n",
            "Batch Id 1900 is having training loss of 603.910400390625\n",
            "706.1920776367188\n",
            "Epoch #0. Accuracy on batch 1900 on Training is 30.212716991057338\n",
            "Epoch #0. Accuracy on batch 1901 on Training is 30.2165483701367\n",
            "Epoch #0. Accuracy on batch 1902 on Training is 30.217091434576982\n",
            "Epoch #0. Accuracy on batch 1903 on Training is 30.222557773109244\n",
            "Epoch #0. Accuracy on batch 1904 on Training is 30.224737532808398\n",
            "Epoch #0. Accuracy on batch 1905 on Training is 30.228554564533052\n",
            "Epoch #0. Accuracy on batch 1906 on Training is 30.235644992134244\n",
            "Epoch #0. Accuracy on batch 1907 on Training is 30.236176624737947\n",
            "Epoch #0. Accuracy on batch 1908 on Training is 30.236707700366683\n",
            "Epoch #0. Accuracy on batch 1909 on Training is 30.23887434554974\n",
            "Epoch #0. Accuracy on batch 1910 on Training is 30.23449764521193\n",
            "Epoch #0. Accuracy on batch 1911 on Training is 30.233394351464437\n",
            "Epoch #0. Accuracy on batch 1912 on Training is 30.232292211186618\n",
            "Epoch #0. Accuracy on batch 1913 on Training is 30.231191222570533\n",
            "Epoch #0. Accuracy on batch 1914 on Training is 30.236618798955615\n",
            "Epoch #0. Accuracy on batch 1915 on Training is 30.224099686847598\n",
            "Epoch #0. Accuracy on batch 1916 on Training is 30.22463484611372\n",
            "Epoch #0. Accuracy on batch 1917 on Training is 30.22679874869656\n",
            "Epoch #0. Accuracy on batch 1918 on Training is 30.233845752996352\n",
            "Epoch #0. Accuracy on batch 1919 on Training is 30.240885416666668\n",
            "Batch Id 1920 is having training loss of 600.3811645507812\n",
            "23.12616539001465\n",
            "Epoch #0. Accuracy on batch 1920 on Training is 30.238157209786568\n",
            "Epoch #0. Accuracy on batch 1921 on Training is 30.245187304890738\n",
            "Epoch #0. Accuracy on batch 1922 on Training is 30.239209568382734\n",
            "Epoch #0. Accuracy on batch 1923 on Training is 30.238110706860706\n",
            "Epoch #0. Accuracy on batch 1924 on Training is 30.23701298701299\n",
            "Epoch #0. Accuracy on batch 1925 on Training is 30.235916407061268\n",
            "Epoch #0. Accuracy on batch 1926 on Training is 30.23644265697976\n",
            "Epoch #0. Accuracy on batch 1927 on Training is 30.22886410788382\n",
            "Epoch #0. Accuracy on batch 1928 on Training is 30.229393468118197\n",
            "Epoch #0. Accuracy on batch 1929 on Training is 30.23316062176166\n",
            "Epoch #0. Accuracy on batch 1930 on Training is 30.227213878819263\n",
            "Epoch #0. Accuracy on batch 1931 on Training is 30.2245082815735\n",
            "Epoch #0. Accuracy on batch 1932 on Training is 30.22665545783756\n",
            "Epoch #0. Accuracy on batch 1933 on Training is 30.223952947259566\n",
            "Epoch #0. Accuracy on batch 1934 on Training is 30.227713178294575\n",
            "Epoch #0. Accuracy on batch 1935 on Training is 30.220170454545453\n",
            "Epoch #0. Accuracy on batch 1936 on Training is 30.22554207537429\n",
            "Epoch #0. Accuracy on batch 1937 on Training is 30.218008255933952\n",
            "Epoch #0. Accuracy on batch 1938 on Training is 30.213705518308405\n",
            "Epoch #0. Accuracy on batch 1939 on Training is 30.215850515463917\n",
            "Batch Id 1940 is having training loss of 595.4563598632812\n",
            "7.720015048980713\n",
            "Epoch #0. Accuracy on batch 1940 on Training is 30.2147733127254\n",
            "Epoch #0. Accuracy on batch 1941 on Training is 30.21369721936148\n",
            "Epoch #0. Accuracy on batch 1942 on Training is 30.217447246525992\n",
            "Epoch #0. Accuracy on batch 1943 on Training is 30.216370884773664\n",
            "Epoch #0. Accuracy on batch 1944 on Training is 30.218508997429307\n",
            "Epoch #0. Accuracy on batch 1945 on Training is 30.220644912641315\n",
            "Epoch #0. Accuracy on batch 1946 on Training is 30.224383667180277\n",
            "Epoch #0. Accuracy on batch 1947 on Training is 30.223305954825463\n",
            "Epoch #0. Accuracy on batch 1948 on Training is 30.228642893791687\n",
            "Epoch #0. Accuracy on batch 1949 on Training is 30.22596153846154\n",
            "Epoch #0. Accuracy on batch 1950 on Training is 30.229689902614044\n",
            "Epoch #0. Accuracy on batch 1951 on Training is 30.23501536885246\n",
            "Epoch #0. Accuracy on batch 1952 on Training is 30.237135176651307\n",
            "Epoch #0. Accuracy on batch 1953 on Training is 30.231256397134082\n",
            "Epoch #0. Accuracy on batch 1954 on Training is 30.23177749360614\n",
            "Epoch #0. Accuracy on batch 1955 on Training is 30.23868865030675\n",
            "Epoch #0. Accuracy on batch 1956 on Training is 30.22962442514052\n",
            "Epoch #0. Accuracy on batch 1957 on Training is 30.225357507660878\n",
            "Epoch #0. Accuracy on batch 1958 on Training is 30.217904543134253\n",
            "Epoch #0. Accuracy on batch 1959 on Training is 30.215242346938776\n",
            "Batch Id 1960 is having training loss of 594.9378662109375\n",
            "88.930419921875\n",
            "Epoch #0. Accuracy on batch 1960 on Training is 30.21258286588475\n",
            "Epoch #0. Accuracy on batch 1961 on Training is 30.211518858307848\n",
            "Epoch #0. Accuracy on batch 1962 on Training is 30.213639836984207\n",
            "Epoch #0. Accuracy on batch 1963 on Training is 30.20621181262729\n",
            "Epoch #0. Accuracy on batch 1964 on Training is 30.21469465648855\n",
            "Epoch #0. Accuracy on batch 1965 on Training is 30.215221261444558\n",
            "Epoch #0. Accuracy on batch 1966 on Training is 30.21733604473818\n",
            "Epoch #0. Accuracy on batch 1967 on Training is 30.214684959349594\n",
            "Epoch #0. Accuracy on batch 1968 on Training is 30.215210766886745\n",
            "Epoch #0. Accuracy on batch 1969 on Training is 30.21256345177665\n",
            "Epoch #0. Accuracy on batch 1970 on Training is 30.21943176052765\n",
            "Epoch #0. Accuracy on batch 1971 on Training is 30.223123732251523\n",
            "Epoch #0. Accuracy on batch 1972 on Training is 30.21889254941713\n",
            "Epoch #0. Accuracy on batch 1973 on Training is 30.20991641337386\n",
            "Epoch #0. Accuracy on batch 1974 on Training is 30.20886075949367\n",
            "Epoch #0. Accuracy on batch 1975 on Training is 30.21255060728745\n",
            "Epoch #0. Accuracy on batch 1976 on Training is 30.216236722306526\n",
            "Epoch #0. Accuracy on batch 1977 on Training is 30.21517947421638\n",
            "Epoch #0. Accuracy on batch 1978 on Training is 30.21096513390601\n",
            "Epoch #0. Accuracy on batch 1979 on Training is 30.2114898989899\n",
            "Batch Id 1980 is having training loss of 591.5368041992188\n",
            "14.692971229553223\n",
            "Epoch #0. Accuracy on batch 1980 on Training is 30.21359162039374\n",
            "Epoch #0. Accuracy on batch 1981 on Training is 30.2156912209889\n",
            "Epoch #0. Accuracy on batch 1982 on Training is 30.2130610186586\n",
            "Epoch #0. Accuracy on batch 1983 on Training is 30.21358366935484\n",
            "Epoch #0. Accuracy on batch 1984 on Training is 30.215680100755666\n",
            "Epoch #0. Accuracy on batch 1985 on Training is 30.21620090634441\n",
            "Epoch #0. Accuracy on batch 1986 on Training is 30.218293910417714\n",
            "Epoch #0. Accuracy on batch 1987 on Training is 30.221956740442657\n",
            "Epoch #0. Accuracy on batch 1988 on Training is 30.22404474610357\n",
            "Epoch #0. Accuracy on batch 1989 on Training is 30.21356783919598\n",
            "Epoch #0. Accuracy on batch 1990 on Training is 30.214088397790054\n",
            "Epoch #0. Accuracy on batch 1991 on Training is 30.209902108433734\n",
            "Epoch #0. Accuracy on batch 1992 on Training is 30.20258404415454\n",
            "Epoch #0. Accuracy on batch 1993 on Training is 30.203109327983952\n",
            "Epoch #0. Accuracy on batch 1994 on Training is 30.209899749373434\n",
            "Epoch #0. Accuracy on batch 1995 on Training is 30.207289579158317\n",
            "Epoch #0. Accuracy on batch 1996 on Training is 30.21407110665999\n",
            "Epoch #0. Accuracy on batch 1997 on Training is 30.20364114114114\n",
            "Epoch #0. Accuracy on batch 1998 on Training is 30.208854427213605\n",
            "Epoch #0. Accuracy on batch 1999 on Training is 30.2046875\n",
            "Batch Id 2000 is having training loss of 590.0922241210938\n",
            "14.958189964294434\n",
            "Epoch #0. Accuracy on batch 2000 on Training is 30.202086456771614\n",
            "Epoch #0. Accuracy on batch 2001 on Training is 30.205731768231768\n",
            "Epoch #0. Accuracy on batch 2002 on Training is 30.210933599600597\n",
            "Epoch #0. Accuracy on batch 2003 on Training is 30.20989271457086\n",
            "Epoch #0. Accuracy on batch 2004 on Training is 30.20417705735661\n",
            "Epoch #0. Accuracy on batch 2005 on Training is 30.20781405782652\n",
            "Epoch #0. Accuracy on batch 2006 on Training is 30.2098903836572\n",
            "Epoch #0. Accuracy on batch 2007 on Training is 30.20573954183267\n",
            "Epoch #0. Accuracy on batch 2008 on Training is 30.206259333001494\n",
            "Epoch #0. Accuracy on batch 2009 on Training is 30.208333333333332\n",
            "Epoch #0. Accuracy on batch 2010 on Training is 30.21351317752362\n",
            "Epoch #0. Accuracy on batch 2011 on Training is 30.21247514910537\n",
            "Epoch #0. Accuracy on batch 2012 on Training is 30.212990561351216\n",
            "Epoch #0. Accuracy on batch 2013 on Training is 30.215057100297916\n",
            "Epoch #0. Accuracy on batch 2014 on Training is 30.21712158808933\n",
            "Epoch #0. Accuracy on batch 2015 on Training is 30.21918402777778\n",
            "Epoch #0. Accuracy on batch 2016 on Training is 30.225892414476945\n",
            "Epoch #0. Accuracy on batch 2017 on Training is 30.22175421209118\n",
            "Epoch #0. Accuracy on batch 2018 on Training is 30.22381129271917\n",
            "Epoch #0. Accuracy on batch 2019 on Training is 30.225866336633665\n",
            "Batch Id 2020 is having training loss of 590.7330932617188\n",
            "3170.1923828125\n",
            "Epoch #0. Accuracy on batch 2020 on Training is 30.22637308263236\n",
            "Epoch #0. Accuracy on batch 2021 on Training is 30.233061325420376\n",
            "Epoch #0. Accuracy on batch 2022 on Training is 30.232019278299553\n",
            "Epoch #0. Accuracy on batch 2023 on Training is 30.234066205533598\n",
            "Epoch #0. Accuracy on batch 2024 on Training is 30.237654320987655\n",
            "Epoch #0. Accuracy on batch 2025 on Training is 30.238153998025666\n",
            "Epoch #0. Accuracy on batch 2026 on Training is 30.23711149481993\n",
            "Epoch #0. Accuracy on batch 2027 on Training is 30.22990631163708\n",
            "Epoch #0. Accuracy on batch 2028 on Training is 30.233489403647116\n",
            "Epoch #0. Accuracy on batch 2029 on Training is 30.233990147783253\n",
            "Epoch #0. Accuracy on batch 2030 on Training is 30.234490398818316\n",
            "Epoch #0. Accuracy on batch 2031 on Training is 30.239603838582678\n",
            "Epoch #0. Accuracy on batch 2032 on Training is 30.233952287260205\n",
            "Epoch #0. Accuracy on batch 2033 on Training is 30.232915437561456\n",
            "Epoch #0. Accuracy on batch 2034 on Training is 30.231879606879605\n",
            "Epoch #0. Accuracy on batch 2035 on Training is 30.230844793713164\n",
            "Epoch #0. Accuracy on batch 2036 on Training is 30.223674521354933\n",
            "Epoch #0. Accuracy on batch 2037 on Training is 30.224178115799802\n",
            "Epoch #0. Accuracy on batch 2038 on Training is 30.21855076017656\n",
            "Epoch #0. Accuracy on batch 2039 on Training is 30.21905637254902\n",
            "Batch Id 2040 is having training loss of 592.3761596679688\n",
            "53.39893341064453\n",
            "Epoch #0. Accuracy on batch 2040 on Training is 30.216499265066144\n",
            "Epoch #0. Accuracy on batch 2041 on Training is 30.209353574926542\n",
            "Epoch #0. Accuracy on batch 2042 on Training is 30.211392559960842\n",
            "Epoch #0. Accuracy on batch 2043 on Training is 30.214958414872797\n",
            "Epoch #0. Accuracy on batch 2044 on Training is 30.212408312958434\n",
            "Epoch #0. Accuracy on batch 2045 on Training is 30.21597018572825\n",
            "Epoch #0. Accuracy on batch 2046 on Training is 30.213422081094283\n",
            "Epoch #0. Accuracy on batch 2047 on Training is 30.21697998046875\n",
            "Epoch #0. Accuracy on batch 2048 on Training is 30.217484138604195\n",
            "Epoch #0. Accuracy on batch 2049 on Training is 30.213414634146343\n",
            "Epoch #0. Accuracy on batch 2050 on Training is 30.209349098000974\n",
            "Epoch #0. Accuracy on batch 2051 on Training is 30.208333333333332\n",
            "Epoch #0. Accuracy on batch 2052 on Training is 30.208840720896248\n",
            "Epoch #0. Accuracy on batch 2053 on Training is 30.210869036027265\n",
            "Epoch #0. Accuracy on batch 2054 on Training is 30.203771289537713\n",
            "Epoch #0. Accuracy on batch 2055 on Training is 30.20124027237354\n",
            "Epoch #0. Accuracy on batch 2056 on Training is 30.200230918813805\n",
            "Epoch #0. Accuracy on batch 2057 on Training is 30.20225947521866\n",
            "Epoch #0. Accuracy on batch 2058 on Training is 30.198215152986887\n",
            "Epoch #0. Accuracy on batch 2059 on Training is 30.201759708737864\n",
            "Batch Id 2060 is having training loss of 601.888427734375\n",
            "220.609130859375\n",
            "Epoch #0. Accuracy on batch 2060 on Training is 30.193170790878213\n",
            "Epoch #0. Accuracy on batch 2061 on Training is 30.1936833171678\n",
            "Epoch #0. Accuracy on batch 2062 on Training is 30.18813620940378\n",
            "Epoch #0. Accuracy on batch 2063 on Training is 30.188650678294575\n",
            "Epoch #0. Accuracy on batch 2064 on Training is 30.192191283292978\n",
            "Epoch #0. Accuracy on batch 2065 on Training is 30.198753630203292\n",
            "Epoch #0. Accuracy on batch 2066 on Training is 30.202285921625545\n",
            "Epoch #0. Accuracy on batch 2067 on Training is 30.204303675048354\n",
            "Epoch #0. Accuracy on batch 2068 on Training is 30.2002779120348\n",
            "Epoch #0. Accuracy on batch 2069 on Training is 30.20229468599034\n",
            "Epoch #0. Accuracy on batch 2070 on Training is 30.208836310960887\n",
            "Epoch #0. Accuracy on batch 2071 on Training is 30.206322393822393\n",
            "Epoch #0. Accuracy on batch 2072 on Training is 30.20984081041968\n",
            "Epoch #0. Accuracy on batch 2073 on Training is 30.208835583413695\n",
            "Epoch #0. Accuracy on batch 2074 on Training is 30.20933734939759\n",
            "Epoch #0. Accuracy on batch 2075 on Training is 30.208333333333332\n",
            "Epoch #0. Accuracy on batch 2076 on Training is 30.208834857968224\n",
            "Epoch #0. Accuracy on batch 2077 on Training is 30.209335899903753\n",
            "Epoch #0. Accuracy on batch 2078 on Training is 30.20983645983646\n",
            "Epoch #0. Accuracy on batch 2079 on Training is 30.205829326923077\n",
            "Batch Id 2080 is having training loss of 603.8383178710938\n",
            "40.46492385864258\n",
            "Epoch #0. Accuracy on batch 2080 on Training is 30.20783277270543\n",
            "Epoch #0. Accuracy on batch 2081 on Training is 30.208333333333332\n",
            "Epoch #0. Accuracy on batch 2082 on Training is 30.204332693230917\n",
            "Epoch #0. Accuracy on batch 2083 on Training is 30.20483445297505\n",
            "Epoch #0. Accuracy on batch 2084 on Training is 30.199340527577938\n",
            "Epoch #0. Accuracy on batch 2085 on Training is 30.19684803451582\n",
            "Epoch #0. Accuracy on batch 2086 on Training is 30.198850023957835\n",
            "Epoch #0. Accuracy on batch 2087 on Training is 30.20085009578544\n",
            "Epoch #0. Accuracy on batch 2088 on Training is 30.19686452848253\n",
            "Epoch #0. Accuracy on batch 2089 on Training is 30.192882775119617\n",
            "Epoch #0. Accuracy on batch 2090 on Training is 30.193388330942135\n",
            "Epoch #0. Accuracy on batch 2091 on Training is 30.192399617590823\n",
            "Epoch #0. Accuracy on batch 2092 on Training is 30.191411849020543\n",
            "Epoch #0. Accuracy on batch 2093 on Training is 30.188932664756447\n",
            "Epoch #0. Accuracy on batch 2094 on Training is 30.183472553699286\n",
            "Epoch #0. Accuracy on batch 2095 on Training is 30.180999522900763\n",
            "Epoch #0. Accuracy on batch 2096 on Training is 30.175548402479734\n",
            "Epoch #0. Accuracy on batch 2097 on Training is 30.17903956148713\n",
            "Epoch #0. Accuracy on batch 2098 on Training is 30.178060981419723\n",
            "Epoch #0. Accuracy on batch 2099 on Training is 30.178571428571427\n",
            "Batch Id 2100 is having training loss of 603.0906982421875\n",
            "165.03990173339844\n",
            "Epoch #0. Accuracy on batch 2100 on Training is 30.182056163731556\n",
            "Epoch #0. Accuracy on batch 2101 on Training is 30.173644148430068\n",
            "Epoch #0. Accuracy on batch 2102 on Training is 30.171184022824537\n",
            "Epoch #0. Accuracy on batch 2103 on Training is 30.171696768060837\n",
            "Epoch #0. Accuracy on batch 2104 on Training is 30.170724465558195\n",
            "Epoch #0. Accuracy on batch 2105 on Training is 30.175688509021843\n",
            "Epoch #0. Accuracy on batch 2106 on Training is 30.176198386331276\n",
            "Epoch #0. Accuracy on batch 2107 on Training is 30.173742884250473\n",
            "Epoch #0. Accuracy on batch 2108 on Training is 30.181661925082977\n",
            "Epoch #0. Accuracy on batch 2109 on Training is 30.177725118483412\n",
            "Epoch #0. Accuracy on batch 2110 on Training is 30.17675272382757\n",
            "Epoch #0. Accuracy on batch 2111 on Training is 30.177260890151516\n",
            "Epoch #0. Accuracy on batch 2112 on Training is 30.17037387600568\n",
            "Epoch #0. Accuracy on batch 2113 on Training is 30.175319299905393\n",
            "Epoch #0. Accuracy on batch 2114 on Training is 30.17287234042553\n",
            "Epoch #0. Accuracy on batch 2115 on Training is 30.170427693761816\n",
            "Epoch #0. Accuracy on batch 2116 on Training is 30.16946150212565\n",
            "Epoch #0. Accuracy on batch 2117 on Training is 30.1699716713881\n",
            "Epoch #0. Accuracy on batch 2118 on Training is 30.176380368098158\n",
            "Epoch #0. Accuracy on batch 2119 on Training is 30.1842570754717\n",
            "Batch Id 2120 is having training loss of 602.1012573242188\n",
            "301.97869873046875\n",
            "Epoch #0. Accuracy on batch 2120 on Training is 30.178866100895803\n",
            "Epoch #0. Accuracy on batch 2121 on Training is 30.179370876531575\n",
            "Epoch #0. Accuracy on batch 2122 on Training is 30.17693122939237\n",
            "Epoch #0. Accuracy on batch 2123 on Training is 30.174493879472692\n",
            "Epoch #0. Accuracy on batch 2124 on Training is 30.173529411764704\n",
            "Epoch #0. Accuracy on batch 2125 on Training is 30.175505644402634\n",
            "Epoch #0. Accuracy on batch 2126 on Training is 30.17748001880583\n",
            "Epoch #0. Accuracy on batch 2127 on Training is 30.176515507518797\n",
            "Epoch #0. Accuracy on batch 2128 on Training is 30.17408407703147\n",
            "Epoch #0. Accuracy on batch 2129 on Training is 30.1731220657277\n",
            "Epoch #0. Accuracy on batch 2130 on Training is 30.176560300328486\n",
            "Epoch #0. Accuracy on batch 2131 on Training is 30.174132270168855\n",
            "Epoch #0. Accuracy on batch 2132 on Training is 30.179031879981245\n",
            "Epoch #0. Accuracy on batch 2133 on Training is 30.182462511715087\n",
            "Epoch #0. Accuracy on batch 2134 on Training is 30.184426229508198\n",
            "Epoch #0. Accuracy on batch 2135 on Training is 30.18492509363296\n",
            "Epoch #0. Accuracy on batch 2136 on Training is 30.18542349087506\n",
            "Epoch #0. Accuracy on batch 2137 on Training is 30.197614593077642\n",
            "Epoch #0. Accuracy on batch 2138 on Training is 30.205411407199627\n",
            "Epoch #0. Accuracy on batch 2139 on Training is 30.20589953271028\n",
            "Batch Id 2140 is having training loss of 611.0935668945312\n",
            "16.771331787109375\n",
            "Epoch #0. Accuracy on batch 2140 on Training is 30.20930639887903\n",
            "Epoch #0. Accuracy on batch 2141 on Training is 30.208333333333332\n",
            "Epoch #0. Accuracy on batch 2142 on Training is 30.21027764815679\n",
            "Epoch #0. Accuracy on batch 2143 on Training is 30.21222014925373\n",
            "Epoch #0. Accuracy on batch 2144 on Training is 30.211247086247088\n",
            "Epoch #0. Accuracy on batch 2145 on Training is 30.217555917986953\n",
            "Epoch #0. Accuracy on batch 2146 on Training is 30.222403353516533\n",
            "Epoch #0. Accuracy on batch 2147 on Training is 30.219972067039105\n",
            "Epoch #0. Accuracy on batch 2148 on Training is 30.224813866914843\n",
            "Epoch #0. Accuracy on batch 2149 on Training is 30.228197674418606\n",
            "Epoch #0. Accuracy on batch 2150 on Training is 30.230125523012553\n",
            "Epoch #0. Accuracy on batch 2151 on Training is 30.224790892193308\n",
            "Epoch #0. Accuracy on batch 2152 on Training is 30.235427310729214\n",
            "Epoch #0. Accuracy on batch 2153 on Training is 30.23734911792015\n",
            "Epoch #0. Accuracy on batch 2154 on Training is 30.237819025522043\n",
            "Epoch #0. Accuracy on batch 2155 on Training is 30.244086270871986\n",
            "Epoch #0. Accuracy on batch 2156 on Training is 30.24165507649513\n",
            "Epoch #0. Accuracy on batch 2157 on Training is 30.24212233549583\n",
            "Epoch #0. Accuracy on batch 2158 on Training is 30.24693144974525\n",
            "Epoch #0. Accuracy on batch 2159 on Training is 30.245949074074073\n",
            "Batch Id 2160 is having training loss of 605.783447265625\n",
            "18.936267852783203\n",
            "Epoch #0. Accuracy on batch 2160 on Training is 30.250751966682092\n",
            "Epoch #0. Accuracy on batch 2161 on Training is 30.24976873265495\n",
            "Epoch #0. Accuracy on batch 2162 on Training is 30.250231160425336\n",
            "Epoch #0. Accuracy on batch 2163 on Training is 30.24924907578558\n",
            "Epoch #0. Accuracy on batch 2164 on Training is 30.24826789838337\n",
            "Epoch #0. Accuracy on batch 2165 on Training is 30.248730378578024\n",
            "Epoch #0. Accuracy on batch 2166 on Training is 30.2477503461006\n",
            "Epoch #0. Accuracy on batch 2167 on Training is 30.24965405904059\n",
            "Epoch #0. Accuracy on batch 2168 on Training is 30.257319041032734\n",
            "Epoch #0. Accuracy on batch 2169 on Training is 30.257776497695854\n",
            "Epoch #0. Accuracy on batch 2170 on Training is 30.263991248272685\n",
            "Epoch #0. Accuracy on batch 2171 on Training is 30.263006445672193\n",
            "Epoch #0. Accuracy on batch 2172 on Training is 30.266336861481822\n",
            "Epoch #0. Accuracy on batch 2173 on Training is 30.265351885924563\n",
            "Epoch #0. Accuracy on batch 2174 on Training is 30.261494252873565\n",
            "Epoch #0. Accuracy on batch 2175 on Training is 30.264820772058822\n",
            "Epoch #0. Accuracy on batch 2176 on Training is 30.26096692696371\n",
            "Epoch #0. Accuracy on batch 2177 on Training is 30.261421028466483\n",
            "Epoch #0. Accuracy on batch 2178 on Training is 30.267611289582376\n",
            "Epoch #0. Accuracy on batch 2179 on Training is 30.266628440366972\n",
            "Batch Id 2180 is having training loss of 610.4139404296875\n",
            "537.9568481445312\n",
            "Epoch #0. Accuracy on batch 2180 on Training is 30.261348005502064\n",
            "Epoch #0. Accuracy on batch 2181 on Training is 30.25750458295142\n",
            "Epoch #0. Accuracy on batch 2182 on Training is 30.25652771415483\n",
            "Epoch #0. Accuracy on batch 2183 on Training is 30.251259157509157\n",
            "Epoch #0. Accuracy on batch 2184 on Training is 30.25028604118993\n",
            "Epoch #0. Accuracy on batch 2185 on Training is 30.253602470265324\n",
            "Epoch #0. Accuracy on batch 2186 on Training is 30.25262917238226\n",
            "Epoch #0. Accuracy on batch 2187 on Training is 30.25308500914077\n",
            "Epoch #0. Accuracy on batch 2188 on Training is 30.253540429419825\n",
            "Epoch #0. Accuracy on batch 2189 on Training is 30.245433789954337\n",
            "Epoch #0. Accuracy on batch 2190 on Training is 30.24303970789594\n",
            "Epoch #0. Accuracy on batch 2191 on Training is 30.240647810218977\n",
            "Epoch #0. Accuracy on batch 2192 on Training is 30.233983128134977\n",
            "Epoch #0. Accuracy on batch 2193 on Training is 30.234446216955334\n",
            "Epoch #0. Accuracy on batch 2194 on Training is 30.230637813211846\n",
            "Epoch #0. Accuracy on batch 2195 on Training is 30.23252504553734\n",
            "Epoch #0. Accuracy on batch 2196 on Training is 30.24010013654984\n",
            "Epoch #0. Accuracy on batch 2197 on Training is 30.2419813466788\n",
            "Epoch #0. Accuracy on batch 2198 on Training is 30.24243974533879\n",
            "Epoch #0. Accuracy on batch 2199 on Training is 30.24715909090909\n",
            "Batch Id 2200 is having training loss of 618.2421875\n",
            "30.796499252319336\n",
            "Epoch #0. Accuracy on batch 2200 on Training is 30.246194911403908\n",
            "Epoch #0. Accuracy on batch 2201 on Training is 30.243812443233423\n",
            "Epoch #0. Accuracy on batch 2202 on Training is 30.25136177939174\n",
            "Epoch #0. Accuracy on batch 2203 on Training is 30.250397005444647\n",
            "Epoch #0. Accuracy on batch 2204 on Training is 30.250850340136054\n",
            "Epoch #0. Accuracy on batch 2205 on Training is 30.24847008159565\n",
            "Epoch #0. Accuracy on batch 2206 on Training is 30.253171726325327\n",
            "Epoch #0. Accuracy on batch 2207 on Training is 30.25079257246377\n",
            "Epoch #0. Accuracy on batch 2208 on Training is 30.25690357627886\n",
            "Epoch #0. Accuracy on batch 2209 on Training is 30.251696832579185\n",
            "Epoch #0. Accuracy on batch 2210 on Training is 30.257801899592945\n",
            "Epoch #0. Accuracy on batch 2211 on Training is 30.259663200723327\n",
            "Epoch #0. Accuracy on batch 2212 on Training is 30.260110709444195\n",
            "Epoch #0. Accuracy on batch 2213 on Training is 30.260557813911472\n",
            "Epoch #0. Accuracy on batch 2214 on Training is 30.256772009029344\n",
            "Epoch #0. Accuracy on batch 2215 on Training is 30.255810018050543\n",
            "Epoch #0. Accuracy on batch 2216 on Training is 30.264715832205685\n",
            "Epoch #0. Accuracy on batch 2217 on Training is 30.266568981064022\n",
            "Epoch #0. Accuracy on batch 2218 on Training is 30.264195583596216\n",
            "Epoch #0. Accuracy on batch 2219 on Training is 30.25760135135135\n",
            "Batch Id 2220 is having training loss of 637.3001098632812\n",
            "49.22317886352539\n",
            "Epoch #0. Accuracy on batch 2220 on Training is 30.25664115263395\n",
            "Epoch #0. Accuracy on batch 2221 on Training is 30.255681818181817\n",
            "Epoch #0. Accuracy on batch 2222 on Training is 30.26034637876743\n",
            "Epoch #0. Accuracy on batch 2223 on Training is 30.262196492805757\n",
            "Epoch #0. Accuracy on batch 2224 on Training is 30.26123595505618\n",
            "Epoch #0. Accuracy on batch 2225 on Training is 30.26589173405211\n",
            "Epoch #0. Accuracy on batch 2226 on Training is 30.27334979793444\n",
            "Epoch #0. Accuracy on batch 2227 on Training is 30.277995960502693\n",
            "Epoch #0. Accuracy on batch 2228 on Training is 30.27703005832212\n",
            "Epoch #0. Accuracy on batch 2229 on Training is 30.277466367713004\n",
            "Epoch #0. Accuracy on batch 2230 on Training is 30.275100851636036\n",
            "Epoch #0. Accuracy on batch 2231 on Training is 30.279737903225808\n",
            "Epoch #0. Accuracy on batch 2232 on Training is 30.280172413793103\n",
            "Epoch #0. Accuracy on batch 2233 on Training is 30.27920769919427\n",
            "Epoch #0. Accuracy on batch 2234 on Training is 30.281040268456376\n",
            "Epoch #0. Accuracy on batch 2235 on Training is 30.28426878354204\n",
            "Epoch #0. Accuracy on batch 2236 on Training is 30.284700491729996\n",
            "Epoch #0. Accuracy on batch 2237 on Training is 30.283735478105452\n",
            "Epoch #0. Accuracy on batch 2238 on Training is 30.285562751228227\n",
            "Epoch #0. Accuracy on batch 2239 on Training is 30.281808035714285\n",
            "Batch Id 2240 is having training loss of 637.0089721679688\n",
            "13.247248649597168\n",
            "Epoch #0. Accuracy on batch 2240 on Training is 30.285029004908523\n",
            "Epoch #0. Accuracy on batch 2241 on Training is 30.288247100802856\n",
            "Epoch #0. Accuracy on batch 2242 on Training is 30.284496210432458\n",
            "Epoch #0. Accuracy on batch 2243 on Training is 30.279356060606062\n",
            "Epoch #0. Accuracy on batch 2244 on Training is 30.277004454342986\n",
            "Epoch #0. Accuracy on batch 2245 on Training is 30.276046304541406\n",
            "Epoch #0. Accuracy on batch 2246 on Training is 30.275089007565644\n",
            "Epoch #0. Accuracy on batch 2247 on Training is 30.27830293594306\n",
            "Epoch #0. Accuracy on batch 2248 on Training is 30.281514006224988\n",
            "Epoch #0. Accuracy on batch 2249 on Training is 30.283333333333335\n",
            "Epoch #0. Accuracy on batch 2250 on Training is 30.280986228342957\n",
            "Epoch #0. Accuracy on batch 2251 on Training is 30.280028863232683\n",
            "Epoch #0. Accuracy on batch 2252 on Training is 30.27352418996893\n",
            "Epoch #0. Accuracy on batch 2253 on Training is 30.283662377994677\n",
            "Epoch #0. Accuracy on batch 2254 on Training is 30.289634146341463\n",
            "Epoch #0. Accuracy on batch 2255 on Training is 30.28451906028369\n",
            "Epoch #0. Accuracy on batch 2256 on Training is 30.283562250775365\n",
            "Epoch #0. Accuracy on batch 2257 on Training is 30.279838352524358\n",
            "Epoch #0. Accuracy on batch 2258 on Training is 30.283034528552456\n",
            "Epoch #0. Accuracy on batch 2259 on Training is 30.2820796460177\n",
            "Batch Id 2260 is having training loss of 636.9475708007812\n",
            "8.98487663269043\n",
            "Epoch #0. Accuracy on batch 2260 on Training is 30.286654135338345\n",
            "Epoch #0. Accuracy on batch 2261 on Training is 30.291224580017683\n",
            "Epoch #0. Accuracy on batch 2262 on Training is 30.290267344233317\n",
            "Epoch #0. Accuracy on batch 2263 on Training is 30.287930653710248\n",
            "Epoch #0. Accuracy on batch 2264 on Training is 30.291114790286976\n",
            "Epoch #0. Accuracy on batch 2265 on Training is 30.291537952338924\n",
            "Epoch #0. Accuracy on batch 2266 on Training is 30.28920379355977\n",
            "Epoch #0. Accuracy on batch 2267 on Training is 30.288249559082892\n",
            "Epoch #0. Accuracy on batch 2268 on Training is 30.28316438959894\n",
            "Epoch #0. Accuracy on batch 2269 on Training is 30.28772026431718\n",
            "Epoch #0. Accuracy on batch 2270 on Training is 30.28539189784236\n",
            "Epoch #0. Accuracy on batch 2271 on Training is 30.276188380281692\n",
            "Epoch #0. Accuracy on batch 2272 on Training is 30.269742630884295\n",
            "Epoch #0. Accuracy on batch 2273 on Training is 30.271547933157432\n",
            "Epoch #0. Accuracy on batch 2274 on Training is 30.267857142857142\n",
            "Epoch #0. Accuracy on batch 2275 on Training is 30.264169595782075\n",
            "Epoch #0. Accuracy on batch 2276 on Training is 30.265974967061922\n",
            "Epoch #0. Accuracy on batch 2277 on Training is 30.27189420544337\n",
            "Epoch #0. Accuracy on batch 2278 on Training is 30.27506581834138\n",
            "Epoch #0. Accuracy on batch 2279 on Training is 30.274122807017545\n",
            "Batch Id 2280 is having training loss of 647.4148559570312\n",
            "28.37687873840332\n",
            "Epoch #0. Accuracy on batch 2280 on Training is 30.27181060938185\n",
            "Epoch #0. Accuracy on batch 2281 on Training is 30.270869851007888\n",
            "Epoch #0. Accuracy on batch 2282 on Training is 30.275405168637757\n",
            "Epoch #0. Accuracy on batch 2283 on Training is 30.275831873905428\n",
            "Epoch #0. Accuracy on batch 2284 on Training is 30.280361050328228\n",
            "Epoch #0. Accuracy on batch 2285 on Training is 30.28215223097113\n",
            "Epoch #0. Accuracy on batch 2286 on Training is 30.282575426322694\n",
            "Epoch #0. Accuracy on batch 2287 on Training is 30.278900786713287\n",
            "Epoch #0. Accuracy on batch 2288 on Training is 30.2793250327654\n",
            "Epoch #0. Accuracy on batch 2289 on Training is 30.278384279475983\n",
            "Epoch #0. Accuracy on batch 2290 on Training is 30.27335224792667\n",
            "Epoch #0. Accuracy on batch 2291 on Training is 30.264234293193716\n",
            "Epoch #0. Accuracy on batch 2292 on Training is 30.267389882250328\n",
            "Epoch #0. Accuracy on batch 2293 on Training is 30.269180470793373\n",
            "Epoch #0. Accuracy on batch 2294 on Training is 30.270969498910674\n",
            "Epoch #0. Accuracy on batch 2295 on Training is 30.275479094076655\n",
            "Epoch #0. Accuracy on batch 2296 on Training is 30.27182194166304\n",
            "Epoch #0. Accuracy on batch 2297 on Training is 30.272247606614446\n",
            "Epoch #0. Accuracy on batch 2298 on Training is 30.27131361461505\n",
            "Epoch #0. Accuracy on batch 2299 on Training is 30.26766304347826\n",
            "Batch Id 2300 is having training loss of 645.5592041015625\n",
            "820.5458984375\n",
            "Epoch #0. Accuracy on batch 2300 on Training is 30.26401564537158\n",
            "Epoch #0. Accuracy on batch 2301 on Training is 30.25901390095569\n",
            "Epoch #0. Accuracy on batch 2302 on Training is 30.2594442032132\n",
            "Epoch #0. Accuracy on batch 2303 on Training is 30.25580512152778\n",
            "Epoch #0. Accuracy on batch 2304 on Training is 30.258947939262473\n",
            "Epoch #0. Accuracy on batch 2305 on Training is 30.256667389418908\n",
            "Epoch #0. Accuracy on batch 2306 on Training is 30.25709796272215\n",
            "Epoch #0. Accuracy on batch 2307 on Training is 30.26294410745234\n",
            "Epoch #0. Accuracy on batch 2308 on Training is 30.2647249891728\n",
            "Epoch #0. Accuracy on batch 2309 on Training is 30.265151515151516\n",
            "Epoch #0. Accuracy on batch 2310 on Training is 30.26422544353094\n",
            "Epoch #0. Accuracy on batch 2311 on Training is 30.259245242214533\n",
            "Epoch #0. Accuracy on batch 2312 on Training is 30.259673584089928\n",
            "Epoch #0. Accuracy on batch 2313 on Training is 30.254699654278305\n",
            "Epoch #0. Accuracy on batch 2314 on Training is 30.260529157667385\n",
            "Epoch #0. Accuracy on batch 2315 on Training is 30.26095639032815\n",
            "Epoch #0. Accuracy on batch 2316 on Training is 30.262731981009928\n",
            "Epoch #0. Accuracy on batch 2317 on Training is 30.26046160483175\n",
            "Epoch #0. Accuracy on batch 2318 on Training is 30.266278568348426\n",
            "Epoch #0. Accuracy on batch 2319 on Training is 30.262661637931036\n",
            "Batch Id 2320 is having training loss of 644.6078491210938\n",
            "34.866416931152344\n",
            "Epoch #0. Accuracy on batch 2320 on Training is 30.26308703145196\n",
            "Epoch #0. Accuracy on batch 2321 on Training is 30.2635120585702\n",
            "Epoch #0. Accuracy on batch 2322 on Training is 30.25990099009901\n",
            "Epoch #0. Accuracy on batch 2323 on Training is 30.254948364888126\n",
            "Epoch #0. Accuracy on batch 2324 on Training is 30.258064516129032\n",
            "Epoch #0. Accuracy on batch 2325 on Training is 30.262521496130695\n",
            "Epoch #0. Accuracy on batch 2326 on Training is 30.266974645466266\n",
            "Epoch #0. Accuracy on batch 2327 on Training is 30.274108676975946\n",
            "Epoch #0. Accuracy on batch 2328 on Training is 30.27721124946329\n",
            "Epoch #0. Accuracy on batch 2329 on Training is 30.272263948497855\n",
            "Epoch #0. Accuracy on batch 2330 on Training is 30.265980265980264\n",
            "Epoch #0. Accuracy on batch 2331 on Training is 30.26506217838765\n",
            "Epoch #0. Accuracy on batch 2332 on Training is 30.266823831975998\n",
            "Epoch #0. Accuracy on batch 2333 on Training is 30.26590616966581\n",
            "Epoch #0. Accuracy on batch 2334 on Training is 30.264989293361886\n",
            "Epoch #0. Accuracy on batch 2335 on Training is 30.26808647260274\n",
            "Epoch #0. Accuracy on batch 2336 on Training is 30.267169448010268\n",
            "Epoch #0. Accuracy on batch 2337 on Training is 30.26357998289136\n",
            "Epoch #0. Accuracy on batch 2338 on Training is 30.261329628046173\n",
            "Epoch #0. Accuracy on batch 2339 on Training is 30.268429487179485\n",
            "Batch Id 2340 is having training loss of 654.65234375\n",
            "62.096920013427734\n",
            "Epoch #0. Accuracy on batch 2340 on Training is 30.276858180264846\n",
            "Epoch #0. Accuracy on batch 2341 on Training is 30.269267719897524\n",
            "Epoch #0. Accuracy on batch 2342 on Training is 30.265685019206146\n",
            "Epoch #0. Accuracy on batch 2343 on Training is 30.26743813993174\n",
            "Epoch #0. Accuracy on batch 2344 on Training is 30.26918976545842\n",
            "Epoch #0. Accuracy on batch 2345 on Training is 30.266943734015346\n",
            "Epoch #0. Accuracy on batch 2346 on Training is 30.268694077545803\n",
            "Epoch #0. Accuracy on batch 2347 on Training is 30.26645017035775\n",
            "Epoch #0. Accuracy on batch 2348 on Training is 30.269529587058322\n",
            "Epoch #0. Accuracy on batch 2349 on Training is 30.273936170212767\n",
            "Epoch #0. Accuracy on batch 2350 on Training is 30.273022118247553\n",
            "Epoch #0. Accuracy on batch 2351 on Training is 30.280080782312925\n",
            "Epoch #0. Accuracy on batch 2352 on Training is 30.279164895877603\n",
            "Epoch #0. Accuracy on batch 2353 on Training is 30.27824978759558\n",
            "Epoch #0. Accuracy on batch 2354 on Training is 30.277335456475583\n",
            "Epoch #0. Accuracy on batch 2355 on Training is 30.269789898132426\n",
            "Epoch #0. Accuracy on batch 2356 on Training is 30.274183283835384\n",
            "Epoch #0. Accuracy on batch 2357 on Training is 30.273271840542833\n",
            "Epoch #0. Accuracy on batch 2358 on Training is 30.271036456125476\n",
            "Epoch #0. Accuracy on batch 2359 on Training is 30.266154661016948\n",
            "Batch Id 2360 is having training loss of 670.35498046875\n",
            "38.91351318359375\n",
            "Epoch #0. Accuracy on batch 2360 on Training is 30.259953409572216\n",
            "Epoch #0. Accuracy on batch 2361 on Training is 30.25772650296359\n",
            "Epoch #0. Accuracy on batch 2362 on Training is 30.264758781210325\n",
            "Epoch #0. Accuracy on batch 2363 on Training is 30.262531725888326\n",
            "Epoch #0. Accuracy on batch 2364 on Training is 30.264270613107822\n",
            "Epoch #0. Accuracy on batch 2365 on Training is 30.26468723584108\n",
            "Epoch #0. Accuracy on batch 2366 on Training is 30.269064216307562\n",
            "Epoch #0. Accuracy on batch 2367 on Training is 30.26419974662162\n",
            "Epoch #0. Accuracy on batch 2368 on Training is 30.260658505698608\n",
            "Epoch #0. Accuracy on batch 2369 on Training is 30.258438818565402\n",
            "Epoch #0. Accuracy on batch 2370 on Training is 30.25490299451708\n",
            "Epoch #0. Accuracy on batch 2371 on Training is 30.25927487352445\n",
            "Epoch #0. Accuracy on batch 2372 on Training is 30.261009270965022\n",
            "Epoch #0. Accuracy on batch 2373 on Training is 30.254844144903117\n",
            "Epoch #0. Accuracy on batch 2374 on Training is 30.25263157894737\n",
            "Epoch #0. Accuracy on batch 2375 on Training is 30.25436658249158\n",
            "Epoch #0. Accuracy on batch 2376 on Training is 30.249526714345816\n",
            "Epoch #0. Accuracy on batch 2377 on Training is 30.252575693860386\n",
            "Epoch #0. Accuracy on batch 2378 on Training is 30.254308532997058\n",
            "Epoch #0. Accuracy on batch 2379 on Training is 30.25078781512605\n",
            "Batch Id 2380 is having training loss of 665.447998046875\n",
            "248.25657653808594\n",
            "Epoch #0. Accuracy on batch 2380 on Training is 30.248582528349434\n",
            "Epoch #0. Accuracy on batch 2381 on Training is 30.25556255247691\n",
            "Epoch #0. Accuracy on batch 2382 on Training is 30.254668485102812\n",
            "Epoch #0. Accuracy on batch 2383 on Training is 30.25639681208054\n",
            "Epoch #0. Accuracy on batch 2384 on Training is 30.2541928721174\n",
            "Epoch #0. Accuracy on batch 2385 on Training is 30.24937133277452\n",
            "Epoch #0. Accuracy on batch 2386 on Training is 30.24324465856724\n",
            "Epoch #0. Accuracy on batch 2387 on Training is 30.24628350083752\n",
            "Epoch #0. Accuracy on batch 2388 on Training is 30.248011720385097\n",
            "Epoch #0. Accuracy on batch 2389 on Training is 30.24581589958159\n",
            "Epoch #0. Accuracy on batch 2390 on Training is 30.24754286909243\n",
            "Epoch #0. Accuracy on batch 2391 on Training is 30.24665551839465\n",
            "Epoch #0. Accuracy on batch 2392 on Training is 30.244463017133306\n",
            "Epoch #0. Accuracy on batch 2393 on Training is 30.240967000835422\n",
            "Epoch #0. Accuracy on batch 2394 on Training is 30.24399791231733\n",
            "Epoch #0. Accuracy on batch 2395 on Training is 30.24441777963272\n",
            "Epoch #0. Accuracy on batch 2396 on Training is 30.24222987067167\n",
            "Epoch #0. Accuracy on batch 2397 on Training is 30.246559633027523\n",
            "Epoch #0. Accuracy on batch 2398 on Training is 30.24437265527303\n",
            "Epoch #0. Accuracy on batch 2399 on Training is 30.243489583333332\n",
            "Batch Id 2400 is having training loss of 660.4896240234375\n",
            "18.78152084350586\n",
            "Epoch #0. Accuracy on batch 2400 on Training is 30.241305705955853\n",
            "Epoch #0. Accuracy on batch 2401 on Training is 30.243026644462947\n",
            "Epoch #0. Accuracy on batch 2402 on Training is 30.244746150645028\n",
            "Epoch #0. Accuracy on batch 2403 on Training is 30.245164309484192\n",
            "Epoch #0. Accuracy on batch 2404 on Training is 30.250779625779625\n",
            "Epoch #0. Accuracy on batch 2405 on Training is 30.256390274314214\n",
            "Epoch #0. Accuracy on batch 2406 on Training is 30.258101371001246\n",
            "Epoch #0. Accuracy on batch 2407 on Training is 30.25981104651163\n",
            "Epoch #0. Accuracy on batch 2408 on Training is 30.257627646326277\n",
            "Epoch #0. Accuracy on batch 2409 on Training is 30.252852697095435\n",
            "Epoch #0. Accuracy on batch 2410 on Training is 30.255858564910824\n",
            "Epoch #0. Accuracy on batch 2411 on Training is 30.25627072968491\n",
            "Epoch #0. Accuracy on batch 2412 on Training is 30.260567757977622\n",
            "Epoch #0. Accuracy on batch 2413 on Training is 30.264861226180614\n",
            "Epoch #0. Accuracy on batch 2414 on Training is 30.269151138716357\n",
            "Epoch #0. Accuracy on batch 2415 on Training is 30.2695571192053\n",
            "Epoch #0. Accuracy on batch 2416 on Training is 30.27513446421183\n",
            "Epoch #0. Accuracy on batch 2417 on Training is 30.274245244003307\n",
            "Epoch #0. Accuracy on batch 2418 on Training is 30.28239975196362\n",
            "Epoch #0. Accuracy on batch 2419 on Training is 30.28279958677686\n",
            "Batch Id 2420 is having training loss of 655.9502563476562\n",
            "24.216440200805664\n",
            "Epoch #0. Accuracy on batch 2420 on Training is 30.28578066914498\n",
            "Epoch #0. Accuracy on batch 2421 on Training is 30.28617877786953\n",
            "Epoch #0. Accuracy on batch 2422 on Training is 30.282707387536114\n",
            "Epoch #0. Accuracy on batch 2423 on Training is 30.28052805280528\n",
            "Epoch #0. Accuracy on batch 2424 on Training is 30.27963917525773\n",
            "Epoch #0. Accuracy on batch 2425 on Training is 30.281327287716405\n",
            "Epoch #0. Accuracy on batch 2426 on Training is 30.285589204779562\n",
            "Epoch #0. Accuracy on batch 2427 on Training is 30.283412273476113\n",
            "Epoch #0. Accuracy on batch 2428 on Training is 30.283810209962947\n",
            "Epoch #0. Accuracy on batch 2429 on Training is 30.284207818930042\n",
            "Epoch #0. Accuracy on batch 2430 on Training is 30.28589058000823\n",
            "Epoch #0. Accuracy on batch 2431 on Training is 30.287571957236842\n",
            "Epoch #0. Accuracy on batch 2432 on Training is 30.289251952322235\n",
            "Epoch #0. Accuracy on batch 2433 on Training is 30.29478225143796\n",
            "Epoch #0. Accuracy on batch 2434 on Training is 30.286190965092402\n",
            "Epoch #0. Accuracy on batch 2435 on Training is 30.285303776683087\n",
            "Epoch #0. Accuracy on batch 2436 on Training is 30.28826425933525\n",
            "Epoch #0. Accuracy on batch 2437 on Training is 30.28994052502051\n",
            "Epoch #0. Accuracy on batch 2438 on Training is 30.289052890528904\n",
            "Epoch #0. Accuracy on batch 2439 on Training is 30.292008196721312\n",
            "Batch Id 2440 is having training loss of 660.3507080078125\n",
            "8.877880096435547\n",
            "Epoch #0. Accuracy on batch 2440 on Training is 30.29240065546907\n",
            "Epoch #0. Accuracy on batch 2441 on Training is 30.290233415233416\n",
            "Epoch #0. Accuracy on batch 2442 on Training is 30.288067949242734\n",
            "Epoch #0. Accuracy on batch 2443 on Training is 30.28334697217676\n",
            "Epoch #0. Accuracy on batch 2444 on Training is 30.279907975460123\n",
            "Epoch #0. Accuracy on batch 2445 on Training is 30.277749386753882\n",
            "Epoch #0. Accuracy on batch 2446 on Training is 30.283255006129956\n",
            "Epoch #0. Accuracy on batch 2447 on Training is 30.282373366013072\n",
            "Epoch #0. Accuracy on batch 2448 on Training is 30.27766435279706\n",
            "Epoch #0. Accuracy on batch 2449 on Training is 30.272959183673468\n",
            "Epoch #0. Accuracy on batch 2450 on Training is 30.274632802937578\n",
            "Epoch #0. Accuracy on batch 2451 on Training is 30.27375611745514\n",
            "Epoch #0. Accuracy on batch 2452 on Training is 30.2639624949042\n",
            "Epoch #0. Accuracy on batch 2453 on Training is 30.259270578647108\n",
            "Epoch #0. Accuracy on batch 2454 on Training is 30.25840122199593\n",
            "Epoch #0. Accuracy on batch 2455 on Training is 30.254987785016286\n",
            "Epoch #0. Accuracy on batch 2456 on Training is 30.259208384208385\n",
            "Epoch #0. Accuracy on batch 2457 on Training is 30.254526037428803\n",
            "Epoch #0. Accuracy on batch 2458 on Training is 30.252389182594552\n",
            "Epoch #0. Accuracy on batch 2459 on Training is 30.246443089430894\n",
            "Batch Id 2460 is having training loss of 656.7385864257812\n",
            "66.91475677490234\n",
            "Epoch #0. Accuracy on batch 2460 on Training is 30.250660300690775\n",
            "Epoch #0. Accuracy on batch 2461 on Training is 30.248527619821285\n",
            "Epoch #0. Accuracy on batch 2462 on Training is 30.248934226552983\n",
            "Epoch #0. Accuracy on batch 2463 on Training is 30.246803977272727\n",
            "Epoch #0. Accuracy on batch 2464 on Training is 30.249746450304258\n",
            "Epoch #0. Accuracy on batch 2465 on Training is 30.251419302514194\n",
            "Epoch #0. Accuracy on batch 2466 on Training is 30.24422375354682\n",
            "Epoch #0. Accuracy on batch 2467 on Training is 30.24209886547812\n",
            "Epoch #0. Accuracy on batch 2468 on Training is 30.24124139327663\n",
            "Epoch #0. Accuracy on batch 2469 on Training is 30.24418016194332\n",
            "Epoch #0. Accuracy on batch 2470 on Training is 30.24332254148118\n",
            "Epoch #0. Accuracy on batch 2471 on Training is 30.24752224919094\n",
            "Epoch #0. Accuracy on batch 2472 on Training is 30.24919126566923\n",
            "Epoch #0. Accuracy on batch 2473 on Training is 30.250858932902183\n",
            "Epoch #0. Accuracy on batch 2474 on Training is 30.25\n",
            "Epoch #0. Accuracy on batch 2475 on Training is 30.242831179321485\n",
            "Epoch #0. Accuracy on batch 2476 on Training is 30.238191360516755\n",
            "Epoch #0. Accuracy on batch 2477 on Training is 30.239860774818403\n",
            "Epoch #0. Accuracy on batch 2478 on Training is 30.241528842275113\n",
            "Epoch #0. Accuracy on batch 2479 on Training is 30.245715725806452\n",
            "Batch Id 2480 is having training loss of 653.1666870117188\n",
            "30.682838439941406\n",
            "Epoch #0. Accuracy on batch 2480 on Training is 30.24738008867392\n",
            "Epoch #0. Accuracy on batch 2481 on Training is 30.242747784045125\n",
            "Epoch #0. Accuracy on batch 2482 on Training is 30.244412001610954\n",
            "Epoch #0. Accuracy on batch 2483 on Training is 30.247332930756844\n",
            "Epoch #0. Accuracy on batch 2484 on Training is 30.240191146881287\n",
            "Epoch #0. Accuracy on batch 2485 on Training is 30.240597345132745\n",
            "Epoch #0. Accuracy on batch 2486 on Training is 30.23849014877362\n",
            "Epoch #0. Accuracy on batch 2487 on Training is 30.232616559485532\n",
            "Epoch #0. Accuracy on batch 2488 on Training is 30.229258738449175\n",
            "Epoch #0. Accuracy on batch 2489 on Training is 30.229668674698797\n",
            "Epoch #0. Accuracy on batch 2490 on Training is 30.233841830590123\n",
            "Epoch #0. Accuracy on batch 2491 on Training is 30.238011637239165\n",
            "Epoch #0. Accuracy on batch 2492 on Training is 30.242178098676295\n",
            "Epoch #0. Accuracy on batch 2493 on Training is 30.242582197273457\n",
            "Epoch #0. Accuracy on batch 2494 on Training is 30.244238476953907\n",
            "Epoch #0. Accuracy on batch 2495 on Training is 30.243389423076923\n",
            "Epoch #0. Accuracy on batch 2496 on Training is 30.241289547456947\n",
            "Epoch #0. Accuracy on batch 2497 on Training is 30.240442353883108\n",
            "Epoch #0. Accuracy on batch 2498 on Training is 30.239595838335333\n",
            "Epoch #0. Accuracy on batch 2499 on Training is 30.23\n",
            "Batch Id 2500 is having training loss of 652.177734375\n",
            "25.137298583984375\n",
            "Epoch #0. Accuracy on batch 2500 on Training is 30.231657337065172\n",
            "Epoch #0. Accuracy on batch 2501 on Training is 30.22956634692246\n",
            "Epoch #0. Accuracy on batch 2502 on Training is 30.23247103475829\n",
            "Epoch #0. Accuracy on batch 2503 on Training is 30.22913338658147\n",
            "Epoch #0. Accuracy on batch 2504 on Training is 30.22579840319361\n",
            "Epoch #0. Accuracy on batch 2505 on Training is 30.22496009577015\n",
            "Epoch #0. Accuracy on batch 2506 on Training is 30.226615476665337\n",
            "Epoch #0. Accuracy on batch 2507 on Training is 30.232007575757574\n",
            "Epoch #0. Accuracy on batch 2508 on Training is 30.231167795934635\n",
            "Epoch #0. Accuracy on batch 2509 on Training is 30.23530876494024\n",
            "Epoch #0. Accuracy on batch 2510 on Training is 30.233223815213062\n",
            "Epoch #0. Accuracy on batch 2511 on Training is 30.231140525477706\n",
            "Epoch #0. Accuracy on batch 2512 on Training is 30.230302427377637\n",
            "Epoch #0. Accuracy on batch 2513 on Training is 30.23692322991249\n",
            "Epoch #0. Accuracy on batch 2514 on Training is 30.239811133200796\n",
            "Epoch #0. Accuracy on batch 2515 on Training is 30.23772853736089\n",
            "Epoch #0. Accuracy on batch 2516 on Training is 30.235647596344855\n",
            "Epoch #0. Accuracy on batch 2517 on Training is 30.236050436854647\n",
            "Epoch #0. Accuracy on batch 2518 on Training is 30.23273124255657\n",
            "Epoch #0. Accuracy on batch 2519 on Training is 30.236855158730158\n",
            "Batch Id 2520 is having training loss of 652.2169799804688\n",
            "24.757884979248047\n",
            "Epoch #0. Accuracy on batch 2520 on Training is 30.232298690995638\n",
            "Epoch #0. Accuracy on batch 2521 on Training is 30.232702220459952\n",
            "Epoch #0. Accuracy on batch 2522 on Training is 30.231866825208087\n",
            "Epoch #0. Accuracy on batch 2523 on Training is 30.235984548335974\n",
            "Epoch #0. Accuracy on batch 2524 on Training is 30.242574257425744\n",
            "Epoch #0. Accuracy on batch 2525 on Training is 30.24421021377672\n",
            "Epoch #0. Accuracy on batch 2526 on Training is 30.247081519588445\n",
            "Epoch #0. Accuracy on batch 2527 on Training is 30.24995055379747\n",
            "Epoch #0. Accuracy on batch 2528 on Training is 30.255288651640964\n",
            "Epoch #0. Accuracy on batch 2529 on Training is 30.249505928853754\n",
            "Epoch #0. Accuracy on batch 2530 on Training is 30.25607467404188\n",
            "Epoch #0. Accuracy on batch 2531 on Training is 30.25770142180095\n",
            "Epoch #0. Accuracy on batch 2532 on Training is 30.258093170153966\n",
            "Epoch #0. Accuracy on batch 2533 on Training is 30.263417521704813\n",
            "Epoch #0. Accuracy on batch 2534 on Training is 30.261341222879686\n",
            "Epoch #0. Accuracy on batch 2535 on Training is 30.2604988170347\n",
            "Epoch #0. Accuracy on batch 2536 on Training is 30.263352384706344\n",
            "Epoch #0. Accuracy on batch 2537 on Training is 30.260047281323878\n",
            "Epoch #0. Accuracy on batch 2538 on Training is 30.257975580937376\n",
            "Epoch #0. Accuracy on batch 2539 on Training is 30.264517716535433\n",
            "Batch Id 2540 is having training loss of 656.9920654296875\n",
            "2916.177978515625\n",
            "Epoch #0. Accuracy on batch 2540 on Training is 30.268595041322314\n",
            "Epoch #0. Accuracy on batch 2541 on Training is 30.266522423288748\n",
            "Epoch #0. Accuracy on batch 2542 on Training is 30.26936688950059\n",
            "Epoch #0. Accuracy on batch 2543 on Training is 30.274665880503143\n",
            "Epoch #0. Accuracy on batch 2544 on Training is 30.27136542239686\n",
            "Epoch #0. Accuracy on batch 2545 on Training is 30.270522388059703\n",
            "Epoch #0. Accuracy on batch 2546 on Training is 30.26968001570475\n",
            "Epoch #0. Accuracy on batch 2547 on Training is 30.26761185243328\n",
            "Epoch #0. Accuracy on batch 2548 on Training is 30.266771282856023\n",
            "Epoch #0. Accuracy on batch 2549 on Training is 30.25980392156863\n",
            "Epoch #0. Accuracy on batch 2550 on Training is 30.266317130537043\n",
            "Epoch #0. Accuracy on batch 2551 on Training is 30.26792711598746\n",
            "Epoch #0. Accuracy on batch 2552 on Training is 30.270759890325106\n",
            "Epoch #0. Accuracy on batch 2553 on Training is 30.263801879404856\n",
            "Epoch #0. Accuracy on batch 2554 on Training is 30.25807240704501\n",
            "Epoch #0. Accuracy on batch 2555 on Training is 30.262128325508606\n",
            "Epoch #0. Accuracy on batch 2556 on Training is 30.26251466562378\n",
            "Epoch #0. Accuracy on batch 2557 on Training is 30.2641223612197\n",
            "Epoch #0. Accuracy on batch 2558 on Training is 30.265728800312623\n",
            "Epoch #0. Accuracy on batch 2559 on Training is 30.263671875\n",
            "Batch Id 2560 is having training loss of 661.5992431640625\n",
            "2252.138427734375\n",
            "Epoch #0. Accuracy on batch 2560 on Training is 30.266497461928935\n",
            "Epoch #0. Accuracy on batch 2561 on Training is 30.264441842310696\n",
            "Epoch #0. Accuracy on batch 2562 on Training is 30.264826375341396\n",
            "Epoch #0. Accuracy on batch 2563 on Training is 30.25911661466459\n",
            "Epoch #0. Accuracy on batch 2564 on Training is 30.26803118908382\n",
            "Epoch #0. Accuracy on batch 2565 on Training is 30.26354247856586\n",
            "Epoch #0. Accuracy on batch 2566 on Training is 30.26270938839112\n",
            "Epoch #0. Accuracy on batch 2567 on Training is 30.260660046728972\n",
            "Epoch #0. Accuracy on batch 2568 on Training is 30.258612300506034\n",
            "Epoch #0. Accuracy on batch 2569 on Training is 30.25535019455253\n",
            "Epoch #0. Accuracy on batch 2570 on Training is 30.25330610657332\n",
            "Epoch #0. Accuracy on batch 2571 on Training is 30.25369362363919\n",
            "Epoch #0. Accuracy on batch 2572 on Training is 30.258938981733387\n",
            "Epoch #0. Accuracy on batch 2573 on Training is 30.261752136752136\n",
            "Epoch #0. Accuracy on batch 2574 on Training is 30.25728155339806\n",
            "Epoch #0. Accuracy on batch 2575 on Training is 30.260093167701864\n",
            "Epoch #0. Accuracy on batch 2576 on Training is 30.25441404734187\n",
            "Epoch #0. Accuracy on batch 2577 on Training is 30.253588052754072\n",
            "Epoch #0. Accuracy on batch 2578 on Training is 30.253974408685536\n",
            "Epoch #0. Accuracy on batch 2579 on Training is 30.2531492248062\n",
            "Batch Id 2580 is having training loss of 684.2882690429688\n",
            "49.8466796875\n",
            "Epoch #0. Accuracy on batch 2580 on Training is 30.25958930647036\n",
            "Epoch #0. Accuracy on batch 2581 on Training is 30.257552285050348\n",
            "Epoch #0. Accuracy on batch 2582 on Training is 30.259146341463413\n",
            "Epoch #0. Accuracy on batch 2583 on Training is 30.258320433436534\n",
            "Epoch #0. Accuracy on batch 2584 on Training is 30.253868471953577\n",
            "Epoch #0. Accuracy on batch 2585 on Training is 30.254253673627222\n",
            "Epoch #0. Accuracy on batch 2586 on Training is 30.25343061461152\n",
            "Epoch #0. Accuracy on batch 2587 on Training is 30.25502318392581\n",
            "Epoch #0. Accuracy on batch 2588 on Training is 30.24937234453457\n",
            "Epoch #0. Accuracy on batch 2589 on Training is 30.252171814671815\n",
            "Epoch #0. Accuracy on batch 2590 on Training is 30.252556927827094\n",
            "Epoch #0. Accuracy on batch 2591 on Training is 30.25414737654321\n",
            "Epoch #0. Accuracy on batch 2592 on Training is 30.250915927497108\n",
            "Epoch #0. Accuracy on batch 2593 on Training is 30.252505782575174\n",
            "Epoch #0. Accuracy on batch 2594 on Training is 30.254094412331405\n",
            "Epoch #0. Accuracy on batch 2595 on Training is 30.261700693374422\n",
            "Epoch #0. Accuracy on batch 2596 on Training is 30.258471313053523\n",
            "Epoch #0. Accuracy on batch 2597 on Training is 30.25524441878368\n",
            "Epoch #0. Accuracy on batch 2598 on Training is 30.260436706425548\n",
            "Epoch #0. Accuracy on batch 2599 on Training is 30.259615384615383\n",
            "Batch Id 2600 is having training loss of 691.983642578125\n",
            "94.85588073730469\n",
            "Epoch #0. Accuracy on batch 2600 on Training is 30.25759323337178\n",
            "Epoch #0. Accuracy on batch 2601 on Training is 30.256773635664874\n",
            "Epoch #0. Accuracy on batch 2602 on Training is 30.25715520553208\n",
            "Epoch #0. Accuracy on batch 2603 on Training is 30.250336021505376\n",
            "Epoch #0. Accuracy on batch 2604 on Training is 30.24832053742802\n",
            "Epoch #0. Accuracy on batch 2605 on Training is 30.247505755947813\n",
            "Epoch #0. Accuracy on batch 2606 on Training is 30.2466915995397\n",
            "Epoch #0. Accuracy on batch 2607 on Training is 30.244679831288344\n",
            "Epoch #0. Accuracy on batch 2608 on Training is 30.242669605212726\n",
            "Epoch #0. Accuracy on batch 2609 on Training is 30.24185823754789\n",
            "Epoch #0. Accuracy on batch 2610 on Training is 30.24224435082344\n",
            "Epoch #0. Accuracy on batch 2611 on Training is 30.242630168453292\n",
            "Epoch #0. Accuracy on batch 2612 on Training is 30.243015690776886\n",
            "Epoch #0. Accuracy on batch 2613 on Training is 30.242205432287683\n",
            "Epoch #0. Accuracy on batch 2614 on Training is 30.239005736137667\n",
            "Epoch #0. Accuracy on batch 2615 on Training is 30.241781345565748\n",
            "Epoch #0. Accuracy on batch 2616 on Training is 30.23977837218189\n",
            "Epoch #0. Accuracy on batch 2617 on Training is 30.237776928953398\n",
            "Epoch #0. Accuracy on batch 2618 on Training is 30.235777014127528\n",
            "Epoch #0. Accuracy on batch 2619 on Training is 30.234971374045802\n",
            "Batch Id 2620 is having training loss of 695.298583984375\n",
            "27.99818992614746\n",
            "Epoch #0. Accuracy on batch 2620 on Training is 30.23297405570393\n",
            "Epoch #0. Accuracy on batch 2621 on Training is 30.233361937452326\n",
            "Epoch #0. Accuracy on batch 2622 on Training is 30.22898398780023\n",
            "Epoch #0. Accuracy on batch 2623 on Training is 30.228182164634145\n",
            "Epoch #0. Accuracy on batch 2624 on Training is 30.232142857142858\n",
            "Epoch #0. Accuracy on batch 2625 on Training is 30.228960396039604\n",
            "Epoch #0. Accuracy on batch 2626 on Training is 30.22578035782261\n",
            "Epoch #0. Accuracy on batch 2627 on Training is 30.222602739726028\n",
            "Epoch #0. Accuracy on batch 2628 on Training is 30.225370863446177\n",
            "Epoch #0. Accuracy on batch 2629 on Training is 30.228136882129277\n",
            "Epoch #0. Accuracy on batch 2630 on Training is 30.228525275560624\n",
            "Epoch #0. Accuracy on batch 2631 on Training is 30.228913373860184\n",
            "Epoch #0. Accuracy on batch 2632 on Training is 30.229301177364224\n",
            "Epoch #0. Accuracy on batch 2633 on Training is 30.22731586940015\n",
            "Epoch #0. Accuracy on batch 2634 on Training is 30.231261859582542\n",
            "Epoch #0. Accuracy on batch 2635 on Training is 30.231648330804248\n",
            "Epoch #0. Accuracy on batch 2636 on Training is 30.22492415623815\n",
            "Epoch #0. Accuracy on batch 2637 on Training is 30.22412812736922\n",
            "Epoch #0. Accuracy on batch 2638 on Training is 30.22214854111406\n",
            "Epoch #0. Accuracy on batch 2639 on Training is 30.226089015151516\n",
            "Batch Id 2640 is having training loss of 694.2616577148438\n",
            "22.92526626586914\n",
            "Epoch #0. Accuracy on batch 2640 on Training is 30.22647671336615\n",
            "Epoch #0. Accuracy on batch 2641 on Training is 30.22213285389856\n",
            "Epoch #0. Accuracy on batch 2642 on Training is 30.22133938706016\n",
            "Epoch #0. Accuracy on batch 2643 on Training is 30.2205465204236\n",
            "Epoch #0. Accuracy on batch 2644 on Training is 30.222117202268432\n",
            "Epoch #0. Accuracy on batch 2645 on Training is 30.226048752834465\n",
            "Epoch #0. Accuracy on batch 2646 on Training is 30.225255005666792\n",
            "Epoch #0. Accuracy on batch 2647 on Training is 30.22328172205438\n",
            "Epoch #0. Accuracy on batch 2648 on Training is 30.216591166477915\n",
            "Epoch #0. Accuracy on batch 2649 on Training is 30.212264150943398\n",
            "Epoch #0. Accuracy on batch 2650 on Training is 30.21265560165975\n",
            "Epoch #0. Accuracy on batch 2651 on Training is 30.21540346907994\n",
            "Epoch #0. Accuracy on batch 2652 on Training is 30.209903882397285\n",
            "Epoch #0. Accuracy on batch 2653 on Training is 30.207940844009045\n",
            "Epoch #0. Accuracy on batch 2654 on Training is 30.207156308851225\n",
            "Epoch #0. Accuracy on batch 2655 on Training is 30.213431852409638\n",
            "Epoch #0. Accuracy on batch 2656 on Training is 30.212645841174258\n",
            "Epoch #0. Accuracy on batch 2657 on Training is 30.216563205417607\n",
            "Epoch #0. Accuracy on batch 2658 on Training is 30.211075592327944\n",
            "Epoch #0. Accuracy on batch 2659 on Training is 30.206766917293233\n",
            "Batch Id 2660 is having training loss of 697.20556640625\n",
            "19.1881103515625\n",
            "Epoch #0. Accuracy on batch 2660 on Training is 30.203635851183765\n",
            "Epoch #0. Accuracy on batch 2661 on Training is 30.20755071374906\n",
            "Epoch #0. Accuracy on batch 2662 on Training is 30.209115659031166\n",
            "Epoch #0. Accuracy on batch 2663 on Training is 30.20950638138138\n",
            "Epoch #0. Accuracy on batch 2664 on Training is 30.204033771106943\n",
            "Epoch #0. Accuracy on batch 2665 on Training is 30.198565266316578\n",
            "Epoch #0. Accuracy on batch 2666 on Training is 30.19544431946007\n",
            "Epoch #0. Accuracy on batch 2667 on Training is 30.192325712143926\n",
            "Epoch #0. Accuracy on batch 2668 on Training is 30.195063694267517\n",
            "Epoch #0. Accuracy on batch 2669 on Training is 30.19428838951311\n",
            "Epoch #0. Accuracy on batch 2670 on Training is 30.19234369150131\n",
            "Epoch #0. Accuracy on batch 2671 on Training is 30.192739520958085\n",
            "Epoch #0. Accuracy on batch 2672 on Training is 30.194304152637486\n",
            "Epoch #0. Accuracy on batch 2673 on Training is 30.201710919970083\n",
            "Epoch #0. Accuracy on batch 2674 on Training is 30.20677570093458\n",
            "Epoch #0. Accuracy on batch 2675 on Training is 30.211836696562035\n",
            "Epoch #0. Accuracy on batch 2676 on Training is 30.214559208068735\n",
            "Epoch #0. Accuracy on batch 2677 on Training is 30.220780433159074\n",
            "Epoch #0. Accuracy on batch 2678 on Training is 30.21883165360209\n",
            "Epoch #0. Accuracy on batch 2679 on Training is 30.22038246268657\n",
            "Batch Id 2680 is having training loss of 696.3671875\n",
            "23.838703155517578\n",
            "Epoch #0. Accuracy on batch 2680 on Training is 30.220766505035435\n",
            "Epoch #0. Accuracy on batch 2681 on Training is 30.217654735272184\n",
            "Epoch #0. Accuracy on batch 2682 on Training is 30.214545285128587\n",
            "Epoch #0. Accuracy on batch 2683 on Training is 30.214931073025337\n",
            "Epoch #0. Accuracy on batch 2684 on Training is 30.21415270018622\n",
            "Epoch #0. Accuracy on batch 2685 on Training is 30.2168652271035\n",
            "Epoch #0. Accuracy on batch 2686 on Training is 30.21259769259397\n",
            "Epoch #0. Accuracy on batch 2687 on Training is 30.215308779761905\n",
            "Epoch #0. Accuracy on batch 2688 on Training is 30.2168557084418\n",
            "Epoch #0. Accuracy on batch 2689 on Training is 30.22188661710037\n",
            "Epoch #0. Accuracy on batch 2690 on Training is 30.22226867335563\n",
            "Epoch #0. Accuracy on batch 2691 on Training is 30.22265044576523\n",
            "Epoch #0. Accuracy on batch 2692 on Training is 30.224192350538434\n",
            "Epoch #0. Accuracy on batch 2693 on Training is 30.219933184855233\n",
            "Epoch #0. Accuracy on batch 2694 on Training is 30.216836734693878\n",
            "Epoch #0. Accuracy on batch 2695 on Training is 30.219538204747774\n",
            "Epoch #0. Accuracy on batch 2696 on Training is 30.217602892102335\n",
            "Epoch #0. Accuracy on batch 2697 on Training is 30.216827279466273\n",
            "Epoch #0. Accuracy on batch 2698 on Training is 30.216052241570953\n",
            "Epoch #0. Accuracy on batch 2699 on Training is 30.21759259259259\n",
            "Batch Id 2700 is having training loss of 692.673583984375\n",
            "25.334575653076172\n",
            "Epoch #0. Accuracy on batch 2700 on Training is 30.220288781932616\n",
            "Epoch #0. Accuracy on batch 2701 on Training is 30.217200222057734\n",
            "Epoch #0. Accuracy on batch 2702 on Training is 30.218738438771734\n",
            "Epoch #0. Accuracy on batch 2703 on Training is 30.21565273668639\n",
            "Epoch #0. Accuracy on batch 2704 on Training is 30.218345656192238\n",
            "Epoch #0. Accuracy on batch 2705 on Training is 30.21757206208426\n",
            "Epoch #0. Accuracy on batch 2706 on Training is 30.219107868489104\n",
            "Epoch #0. Accuracy on batch 2707 on Training is 30.21833456425406\n",
            "Epoch #0. Accuracy on batch 2708 on Training is 30.215254706533777\n",
            "Epoch #0. Accuracy on batch 2709 on Training is 30.220249077490774\n",
            "Epoch #0. Accuracy on batch 2710 on Training is 30.218323496864624\n",
            "Epoch #0. Accuracy on batch 2711 on Training is 30.22216076696165\n",
            "Epoch #0. Accuracy on batch 2712 on Training is 30.223691485440472\n",
            "Epoch #0. Accuracy on batch 2713 on Training is 30.22291820191599\n",
            "Epoch #0. Accuracy on batch 2714 on Training is 30.22099447513812\n",
            "Epoch #0. Accuracy on batch 2715 on Training is 30.221373343151694\n",
            "Epoch #0. Accuracy on batch 2716 on Training is 30.222902097902097\n",
            "Epoch #0. Accuracy on batch 2717 on Training is 30.21868101545254\n",
            "Epoch #0. Accuracy on batch 2718 on Training is 30.21791099668996\n",
            "Epoch #0. Accuracy on batch 2719 on Training is 30.221737132352942\n",
            "Batch Id 2720 is having training loss of 688.4020385742188\n",
            "54.138084411621094\n",
            "Epoch #0. Accuracy on batch 2720 on Training is 30.223263506063947\n",
            "Epoch #0. Accuracy on batch 2721 on Training is 30.22938096987509\n",
            "Epoch #0. Accuracy on batch 2722 on Training is 30.228608152772676\n",
            "Epoch #0. Accuracy on batch 2723 on Training is 30.226688693098385\n",
            "Epoch #0. Accuracy on batch 2724 on Training is 30.224770642201836\n",
            "Epoch #0. Accuracy on batch 2725 on Training is 30.225146735143067\n",
            "Epoch #0. Accuracy on batch 2726 on Training is 30.231252291895856\n",
            "Epoch #0. Accuracy on batch 2727 on Training is 30.230480205278592\n",
            "Epoch #0. Accuracy on batch 2728 on Training is 30.22741846830341\n",
            "Epoch #0. Accuracy on batch 2729 on Training is 30.230082417582416\n",
            "Epoch #0. Accuracy on batch 2730 on Training is 30.231600146466494\n",
            "Epoch #0. Accuracy on batch 2731 on Training is 30.234260614934115\n",
            "Epoch #0. Accuracy on batch 2732 on Training is 30.233488840102453\n",
            "Epoch #0. Accuracy on batch 2733 on Training is 30.233860643745427\n",
            "Epoch #0. Accuracy on batch 2734 on Training is 30.238802559414992\n",
            "Epoch #0. Accuracy on batch 2735 on Training is 30.241456505847953\n",
            "Epoch #0. Accuracy on batch 2736 on Training is 30.24182499086591\n",
            "Epoch #0. Accuracy on batch 2737 on Training is 30.236486486486488\n",
            "Epoch #0. Accuracy on batch 2738 on Training is 30.241420226359985\n",
            "Epoch #0. Accuracy on batch 2739 on Training is 30.24292883211679\n",
            "Batch Id 2740 is having training loss of 684.7193603515625\n",
            "14.48281478881836\n",
            "Epoch #0. Accuracy on batch 2740 on Training is 30.247856621670923\n",
            "Epoch #0. Accuracy on batch 2741 on Training is 30.24936177972283\n",
            "Epoch #0. Accuracy on batch 2742 on Training is 30.24744804958075\n",
            "Epoch #0. Accuracy on batch 2743 on Training is 30.248952259475217\n",
            "Epoch #0. Accuracy on batch 2744 on Training is 30.243624772313296\n",
            "Epoch #0. Accuracy on batch 2745 on Training is 30.241715222141295\n",
            "Epoch #0. Accuracy on batch 2746 on Training is 30.239807062249728\n",
            "Epoch #0. Accuracy on batch 2747 on Training is 30.241311863173216\n",
            "Epoch #0. Accuracy on batch 2748 on Training is 30.243952346307747\n",
            "Epoch #0. Accuracy on batch 2749 on Training is 30.239772727272726\n",
            "Epoch #0. Accuracy on batch 2750 on Training is 30.237868047982552\n",
            "Epoch #0. Accuracy on batch 2751 on Training is 30.237100290697676\n",
            "Epoch #0. Accuracy on batch 2752 on Training is 30.23292771521976\n",
            "Epoch #0. Accuracy on batch 2753 on Training is 30.235566448801745\n",
            "Epoch #0. Accuracy on batch 2754 on Training is 30.23253176043557\n",
            "Epoch #0. Accuracy on batch 2755 on Training is 30.236302612481857\n",
            "Epoch #0. Accuracy on batch 2756 on Training is 30.22873594486761\n",
            "Epoch #0. Accuracy on batch 2757 on Training is 30.225707034082667\n",
            "Epoch #0. Accuracy on batch 2758 on Training is 30.224945632475535\n",
            "Epoch #0. Accuracy on batch 2759 on Training is 30.22758152173913\n",
            "Batch Id 2760 is having training loss of 711.6990356445312\n",
            "38.86605453491211\n",
            "Epoch #0. Accuracy on batch 2760 on Training is 30.230215501629843\n",
            "Epoch #0. Accuracy on batch 2761 on Training is 30.23058472121651\n",
            "Epoch #0. Accuracy on batch 2762 on Training is 30.226429605501266\n",
            "Epoch #0. Accuracy on batch 2763 on Training is 30.221146888567294\n",
            "Epoch #0. Accuracy on batch 2764 on Training is 30.22151898734177\n",
            "Epoch #0. Accuracy on batch 2765 on Training is 30.220761026753433\n",
            "Epoch #0. Accuracy on batch 2766 on Training is 30.221132996024576\n",
            "Epoch #0. Accuracy on batch 2767 on Training is 30.22263367052023\n",
            "Epoch #0. Accuracy on batch 2768 on Training is 30.226390393643914\n",
            "Epoch #0. Accuracy on batch 2769 on Training is 30.229016245487365\n",
            "Epoch #0. Accuracy on batch 2770 on Training is 30.22487369180801\n",
            "Epoch #0. Accuracy on batch 2771 on Training is 30.224116161616163\n",
            "Epoch #0. Accuracy on batch 2772 on Training is 30.224486116119724\n",
            "Epoch #0. Accuracy on batch 2773 on Training is 30.221476207642393\n",
            "Epoch #0. Accuracy on batch 2774 on Training is 30.219594594594593\n",
            "Epoch #0. Accuracy on batch 2775 on Training is 30.214337175792508\n",
            "Epoch #0. Accuracy on batch 2776 on Training is 30.212459488656823\n",
            "Epoch #0. Accuracy on batch 2777 on Training is 30.21058315334773\n",
            "Epoch #0. Accuracy on batch 2778 on Training is 30.207583663188196\n",
            "Epoch #0. Accuracy on batch 2779 on Training is 30.207958633093526\n",
            "Batch Id 2780 is having training loss of 725.803955078125\n",
            "59.95537567138672\n",
            "Epoch #0. Accuracy on batch 2780 on Training is 30.207209636821286\n",
            "Epoch #0. Accuracy on batch 2781 on Training is 30.206461179007906\n",
            "Epoch #0. Accuracy on batch 2782 on Training is 30.207959037010422\n",
            "Epoch #0. Accuracy on batch 2783 on Training is 30.206088362068964\n",
            "Epoch #0. Accuracy on batch 2784 on Training is 30.207585278276483\n",
            "Epoch #0. Accuracy on batch 2785 on Training is 30.20683776022972\n",
            "Epoch #0. Accuracy on batch 2786 on Training is 30.20496950125583\n",
            "Epoch #0. Accuracy on batch 2787 on Training is 30.20086083213773\n",
            "Epoch #0. Accuracy on batch 2788 on Training is 30.20459842237361\n",
            "Epoch #0. Accuracy on batch 2789 on Training is 30.19937275985663\n",
            "Epoch #0. Accuracy on batch 2790 on Training is 30.199749193837334\n",
            "Epoch #0. Accuracy on batch 2791 on Training is 30.203483166189113\n",
            "Epoch #0. Accuracy on batch 2792 on Training is 30.202738990332975\n",
            "Epoch #0. Accuracy on batch 2793 on Training is 30.209824624194702\n",
            "Epoch #0. Accuracy on batch 2794 on Training is 30.207960644007155\n",
            "Epoch #0. Accuracy on batch 2795 on Training is 30.208333333333332\n",
            "Epoch #0. Accuracy on batch 2796 on Training is 30.20647121916339\n",
            "Epoch #0. Accuracy on batch 2797 on Training is 30.201259828448894\n",
            "Epoch #0. Accuracy on batch 2798 on Training is 30.207216863165417\n",
            "Epoch #0. Accuracy on batch 2799 on Training is 30.196428571428573\n",
            "Batch Id 2800 is having training loss of 735.0036010742188\n",
            "207.1361541748047\n",
            "Epoch #0. Accuracy on batch 2800 on Training is 30.19234202070689\n",
            "Epoch #0. Accuracy on batch 2801 on Training is 30.19271948608137\n",
            "Epoch #0. Accuracy on batch 2802 on Training is 30.194211559043882\n",
            "Epoch #0. Accuracy on batch 2803 on Training is 30.193473609129814\n",
            "Epoch #0. Accuracy on batch 2804 on Training is 30.19162210338681\n",
            "Epoch #0. Accuracy on batch 2805 on Training is 30.18865823235923\n",
            "Epoch #0. Accuracy on batch 2806 on Training is 30.186809761311007\n",
            "Epoch #0. Accuracy on batch 2807 on Training is 30.178285256410255\n",
            "Epoch #0. Accuracy on batch 2808 on Training is 30.180891776432894\n",
            "Epoch #0. Accuracy on batch 2809 on Training is 30.18238434163701\n",
            "Epoch #0. Accuracy on batch 2810 on Training is 30.18054073283529\n",
            "Epoch #0. Accuracy on batch 2811 on Training is 30.176475817923187\n",
            "Epoch #0. Accuracy on batch 2812 on Training is 30.170191965872732\n",
            "Epoch #0. Accuracy on batch 2813 on Training is 30.165023098791757\n",
            "Epoch #0. Accuracy on batch 2814 on Training is 30.16873889875666\n",
            "Epoch #0. Accuracy on batch 2815 on Training is 30.173561789772727\n",
            "Epoch #0. Accuracy on batch 2816 on Training is 30.175053248136315\n",
            "Epoch #0. Accuracy on batch 2817 on Training is 30.178761533002127\n",
            "Epoch #0. Accuracy on batch 2818 on Training is 30.181358637814828\n",
            "Epoch #0. Accuracy on batch 2819 on Training is 30.18395390070922\n",
            "Batch Id 2820 is having training loss of 733.8983154296875\n",
            "2000.2965087890625\n",
            "Epoch #0. Accuracy on batch 2820 on Training is 30.185439560439562\n",
            "Epoch #0. Accuracy on batch 2821 on Training is 30.186924167257263\n",
            "Epoch #0. Accuracy on batch 2822 on Training is 30.189514700673044\n",
            "Epoch #0. Accuracy on batch 2823 on Training is 30.186570467422097\n",
            "Epoch #0. Accuracy on batch 2824 on Training is 30.184734513274336\n",
            "Epoch #0. Accuracy on batch 2825 on Training is 30.185111464968152\n",
            "Epoch #0. Accuracy on batch 2826 on Training is 30.18769897417757\n",
            "Epoch #0. Accuracy on batch 2827 on Training is 30.184759547383308\n",
            "Epoch #0. Accuracy on batch 2828 on Training is 30.182926829268293\n",
            "Epoch #0. Accuracy on batch 2829 on Training is 30.18219964664311\n",
            "Epoch #0. Accuracy on batch 2830 on Training is 30.18036912751678\n",
            "Epoch #0. Accuracy on batch 2831 on Training is 30.182953742937855\n",
            "Epoch #0. Accuracy on batch 2832 on Training is 30.182227320861276\n",
            "Epoch #0. Accuracy on batch 2833 on Training is 30.180398729710657\n",
            "Epoch #0. Accuracy on batch 2834 on Training is 30.180776014109348\n",
            "Epoch #0. Accuracy on batch 2835 on Training is 30.18005112834979\n",
            "Epoch #0. Accuracy on batch 2836 on Training is 30.187037363412056\n",
            "Epoch #0. Accuracy on batch 2837 on Training is 30.18741190979563\n",
            "Epoch #0. Accuracy on batch 2838 on Training is 30.18558471292709\n",
            "Epoch #0. Accuracy on batch 2839 on Training is 30.190360915492956\n",
            "Batch Id 2840 is having training loss of 741.8203125\n",
            "33.566856384277344\n",
            "Epoch #0. Accuracy on batch 2840 on Training is 30.19073389651531\n",
            "Epoch #0. Accuracy on batch 2841 on Training is 30.18670830401126\n",
            "Epoch #0. Accuracy on batch 2842 on Training is 30.183784734435456\n",
            "Epoch #0. Accuracy on batch 2843 on Training is 30.18745604781997\n",
            "Epoch #0. Accuracy on batch 2844 on Training is 30.185632688927942\n",
            "Epoch #0. Accuracy on batch 2845 on Training is 30.187104708362615\n",
            "Epoch #0. Accuracy on batch 2846 on Training is 30.18308746048472\n",
            "Epoch #0. Accuracy on batch 2847 on Training is 30.179073033707866\n",
            "Epoch #0. Accuracy on batch 2848 on Training is 30.180545805545805\n",
            "Epoch #0. Accuracy on batch 2849 on Training is 30.176535087719298\n",
            "Epoch #0. Accuracy on batch 2850 on Training is 30.18239214310768\n",
            "Epoch #0. Accuracy on batch 2851 on Training is 30.182766479663393\n",
            "Epoch #0. Accuracy on batch 2852 on Training is 30.184235892043464\n",
            "Epoch #0. Accuracy on batch 2853 on Training is 30.18679922915207\n",
            "Epoch #0. Accuracy on batch 2854 on Training is 30.191549912434326\n",
            "Epoch #0. Accuracy on batch 2855 on Training is 30.191920518207283\n",
            "Epoch #0. Accuracy on batch 2856 on Training is 30.194478473923695\n",
            "Epoch #0. Accuracy on batch 2857 on Training is 30.193754373687895\n",
            "Epoch #0. Accuracy on batch 2858 on Training is 30.194123819517312\n",
            "Epoch #0. Accuracy on batch 2859 on Training is 30.191215034965033\n",
            "Batch Id 2860 is having training loss of 745.1751098632812\n",
            "10.872092247009277\n",
            "Epoch #0. Accuracy on batch 2860 on Training is 30.192677385529535\n",
            "Epoch #0. Accuracy on batch 2861 on Training is 30.187587351502447\n",
            "Epoch #0. Accuracy on batch 2862 on Training is 30.186866922808242\n",
            "Epoch #0. Accuracy on batch 2863 on Training is 30.186146997206706\n",
            "Epoch #0. Accuracy on batch 2864 on Training is 30.18760907504363\n",
            "Epoch #0. Accuracy on batch 2865 on Training is 30.183618283321703\n",
            "Epoch #0. Accuracy on batch 2866 on Training is 30.187260202302056\n",
            "Epoch #0. Accuracy on batch 2867 on Training is 30.195258019525802\n",
            "Epoch #0. Accuracy on batch 2868 on Training is 30.1934471941443\n",
            "Epoch #0. Accuracy on batch 2869 on Training is 30.198170731707318\n",
            "Epoch #0. Accuracy on batch 2870 on Training is 30.19744862417276\n",
            "Epoch #0. Accuracy on batch 2871 on Training is 30.196727019498606\n",
            "Epoch #0. Accuracy on batch 2872 on Training is 30.19709363035155\n",
            "Epoch #0. Accuracy on batch 2873 on Training is 30.196372651356995\n",
            "Epoch #0. Accuracy on batch 2874 on Training is 30.196739130434782\n",
            "Epoch #0. Accuracy on batch 2875 on Training is 30.196018776077885\n",
            "Epoch #0. Accuracy on batch 2876 on Training is 30.19855752519986\n",
            "Epoch #0. Accuracy on batch 2877 on Training is 30.20109451007644\n",
            "Epoch #0. Accuracy on batch 2878 on Training is 30.20254428621049\n",
            "Epoch #0. Accuracy on batch 2879 on Training is 30.19748263888889\n",
            "Batch Id 2880 is having training loss of 742.8742065429688\n",
            "186.0561065673828\n",
            "Epoch #0. Accuracy on batch 2880 on Training is 30.19784796945505\n",
            "Epoch #0. Accuracy on batch 2881 on Training is 30.196044413601665\n",
            "Epoch #0. Accuracy on batch 2882 on Training is 30.194242108914324\n",
            "Epoch #0. Accuracy on batch 2883 on Training is 30.196775312066574\n",
            "Epoch #0. Accuracy on batch 2884 on Training is 30.198223570190642\n",
            "Epoch #0. Accuracy on batch 2885 on Training is 30.197505197505198\n",
            "Epoch #0. Accuracy on batch 2886 on Training is 30.20003463803256\n",
            "Epoch #0. Accuracy on batch 2887 on Training is 30.197152008310248\n",
            "Epoch #0. Accuracy on batch 2888 on Training is 30.199679820006924\n",
            "Epoch #0. Accuracy on batch 2889 on Training is 30.20112456747405\n",
            "Epoch #0. Accuracy on batch 2890 on Training is 30.20473019716361\n",
            "Epoch #0. Accuracy on batch 2891 on Training is 30.204011065006917\n",
            "Epoch #0. Accuracy on batch 2892 on Training is 30.203292430003458\n",
            "Epoch #0. Accuracy on batch 2893 on Training is 30.20365411195577\n",
            "Epoch #0. Accuracy on batch 2894 on Training is 30.209412780656304\n",
            "Epoch #0. Accuracy on batch 2895 on Training is 30.211930248618785\n",
            "Epoch #0. Accuracy on batch 2896 on Training is 30.21120987228167\n",
            "Epoch #0. Accuracy on batch 2897 on Training is 30.21048999309869\n",
            "Epoch #0. Accuracy on batch 2898 on Training is 30.209770610555363\n",
            "Epoch #0. Accuracy on batch 2899 on Training is 30.21228448275862\n",
            "Batch Id 2900 is having training loss of 757.6238403320312\n",
            "8.85316276550293\n",
            "Epoch #0. Accuracy on batch 2900 on Training is 30.219105480868667\n",
            "Epoch #0. Accuracy on batch 2901 on Training is 30.22053756030324\n",
            "Epoch #0. Accuracy on batch 2902 on Training is 30.22089218050293\n",
            "Epoch #0. Accuracy on batch 2903 on Training is 30.220170454545453\n",
            "Epoch #0. Accuracy on batch 2904 on Training is 30.221600688468158\n",
            "Epoch #0. Accuracy on batch 2905 on Training is 30.224105299380593\n",
            "Epoch #0. Accuracy on batch 2906 on Training is 30.222308221534227\n",
            "Epoch #0. Accuracy on batch 2907 on Training is 30.222661623108667\n",
            "Epoch #0. Accuracy on batch 2908 on Training is 30.22086627707116\n",
            "Epoch #0. Accuracy on batch 2909 on Training is 30.220146048109967\n",
            "Epoch #0. Accuracy on batch 2910 on Training is 30.22049982823772\n",
            "Epoch #0. Accuracy on batch 2911 on Training is 30.220853365384617\n",
            "Epoch #0. Accuracy on batch 2912 on Training is 30.22120665980089\n",
            "Epoch #0. Accuracy on batch 2913 on Training is 30.220487302676734\n",
            "Epoch #0. Accuracy on batch 2914 on Training is 30.21869639794168\n",
            "Epoch #0. Accuracy on batch 2915 on Training is 30.219050068587105\n",
            "Epoch #0. Accuracy on batch 2916 on Training is 30.218332190606787\n",
            "Epoch #0. Accuracy on batch 2917 on Training is 30.217614804660727\n",
            "Epoch #0. Accuracy on batch 2918 on Training is 30.212615621788284\n",
            "Epoch #0. Accuracy on batch 2919 on Training is 30.214041095890412\n",
            "Batch Id 2920 is having training loss of 753.0567626953125\n",
            "811.7857055664062\n",
            "Epoch #0. Accuracy on batch 2920 on Training is 30.215465593974667\n",
            "Epoch #0. Accuracy on batch 2921 on Training is 30.217958590006845\n",
            "Epoch #0. Accuracy on batch 2922 on Training is 30.21938077317824\n",
            "Epoch #0. Accuracy on batch 2923 on Training is 30.217595759233927\n",
            "Epoch #0. Accuracy on batch 2924 on Training is 30.212606837606838\n",
            "Epoch #0. Accuracy on batch 2925 on Training is 30.211893369788108\n",
            "Epoch #0. Accuracy on batch 2926 on Training is 30.218653911855142\n",
            "Epoch #0. Accuracy on batch 2927 on Training is 30.215804303278688\n",
            "Epoch #0. Accuracy on batch 2928 on Training is 30.215090474564697\n",
            "Epoch #0. Accuracy on batch 2929 on Training is 30.213310580204777\n",
            "Epoch #0. Accuracy on batch 2930 on Training is 30.213664278403275\n",
            "Epoch #0. Accuracy on batch 2931 on Training is 30.21401773533424\n",
            "Epoch #0. Accuracy on batch 2932 on Training is 30.213305489260144\n",
            "Epoch #0. Accuracy on batch 2933 on Training is 30.212593728698025\n",
            "Epoch #0. Accuracy on batch 2934 on Training is 30.218270868824533\n",
            "Epoch #0. Accuracy on batch 2935 on Training is 30.223944141689373\n",
            "Epoch #0. Accuracy on batch 2936 on Training is 30.227485529451823\n",
            "Epoch #0. Accuracy on batch 2937 on Training is 30.226769911504423\n",
            "Epoch #0. Accuracy on batch 2938 on Training is 30.230307927866622\n",
            "Epoch #0. Accuracy on batch 2939 on Training is 30.22746598639456\n",
            "Batch Id 2940 is having training loss of 748.297119140625\n",
            "32.604515075683594\n",
            "Epoch #0. Accuracy on batch 2940 on Training is 30.224625977558652\n",
            "Epoch #0. Accuracy on batch 2941 on Training is 30.221787899388172\n",
            "Epoch #0. Accuracy on batch 2942 on Training is 30.218951749915053\n",
            "Epoch #0. Accuracy on batch 2943 on Training is 30.224609375\n",
            "Epoch #0. Accuracy on batch 2944 on Training is 30.227079796264857\n",
            "Epoch #0. Accuracy on batch 2945 on Training is 30.228487780040734\n",
            "Epoch #0. Accuracy on batch 2946 on Training is 30.232015609093995\n",
            "Epoch #0. Accuracy on batch 2947 on Training is 30.233420963364992\n",
            "Epoch #0. Accuracy on batch 2948 on Training is 30.23164632078671\n",
            "Epoch #0. Accuracy on batch 2949 on Training is 30.235169491525422\n",
            "Epoch #0. Accuracy on batch 2950 on Training is 30.242926126736698\n",
            "Epoch #0. Accuracy on batch 2951 on Training is 30.240091463414632\n",
            "Epoch #0. Accuracy on batch 2952 on Training is 30.241491703352523\n",
            "Epoch #0. Accuracy on batch 2953 on Training is 30.243948882870683\n",
            "Epoch #0. Accuracy on batch 2954 on Training is 30.240059221658207\n",
            "Epoch #0. Accuracy on batch 2955 on Training is 30.243572395128552\n",
            "Epoch #0. Accuracy on batch 2956 on Training is 30.246026378085897\n",
            "Epoch #0. Accuracy on batch 2957 on Training is 30.247422244759974\n",
            "Epoch #0. Accuracy on batch 2958 on Training is 30.24670496789456\n",
            "Epoch #0. Accuracy on batch 2959 on Training is 30.24704391891892\n",
            "Batch Id 2960 is having training loss of 744.687255859375\n",
            "17.032535552978516\n",
            "Epoch #0. Accuracy on batch 2960 on Training is 30.247382640999664\n",
            "Epoch #0. Accuracy on batch 2961 on Training is 30.24561107359892\n",
            "Epoch #0. Accuracy on batch 2962 on Training is 30.244895376307795\n",
            "Epoch #0. Accuracy on batch 2963 on Training is 30.245234480431847\n",
            "Epoch #0. Accuracy on batch 2964 on Training is 30.245573355817875\n",
            "Epoch #0. Accuracy on batch 2965 on Training is 30.245912002697235\n",
            "Epoch #0. Accuracy on batch 2966 on Training is 30.25046343107516\n",
            "Epoch #0. Accuracy on batch 2967 on Training is 30.24974730458221\n",
            "Epoch #0. Accuracy on batch 2968 on Training is 30.24903166049175\n",
            "Epoch #0. Accuracy on batch 2969 on Training is 30.252525252525253\n",
            "Epoch #0. Accuracy on batch 2970 on Training is 30.25075732076742\n",
            "Epoch #0. Accuracy on batch 2971 on Training is 30.250042059219382\n",
            "Epoch #0. Accuracy on batch 2972 on Training is 30.251429532458797\n",
            "Epoch #0. Accuracy on batch 2973 on Training is 30.248612979152657\n",
            "Epoch #0. Accuracy on batch 2974 on Training is 30.248949579831933\n",
            "Epoch #0. Accuracy on batch 2975 on Training is 30.256636424731184\n",
            "Epoch #0. Accuracy on batch 2976 on Training is 30.250671817265705\n",
            "Epoch #0. Accuracy on batch 2977 on Training is 30.25730355943586\n",
            "Epoch #0. Accuracy on batch 2978 on Training is 30.25973481033904\n",
            "Epoch #0. Accuracy on batch 2979 on Training is 30.265310402684563\n",
            "Batch Id 2980 is having training loss of 758.0889282226562\n",
            "43353.59765625\n",
            "Epoch #0. Accuracy on batch 2980 on Training is 30.26459241865146\n",
            "Epoch #0. Accuracy on batch 2981 on Training is 30.261779007377598\n",
            "Epoch #0. Accuracy on batch 2982 on Training is 30.25687227623198\n",
            "Epoch #0. Accuracy on batch 2983 on Training is 30.254063337801608\n",
            "Epoch #0. Accuracy on batch 2984 on Training is 30.253350083752093\n",
            "Epoch #0. Accuracy on batch 2985 on Training is 30.252637307434696\n",
            "Epoch #0. Accuracy on batch 2986 on Training is 30.2519250083696\n",
            "Epoch #0. Accuracy on batch 2987 on Training is 30.256442436412318\n",
            "Epoch #0. Accuracy on batch 2988 on Training is 30.254683840749415\n",
            "Epoch #0. Accuracy on batch 2989 on Training is 30.255016722408026\n",
            "Epoch #0. Accuracy on batch 2990 on Training is 30.253259779338013\n",
            "Epoch #0. Accuracy on batch 2991 on Training is 30.248370655080215\n",
            "Epoch #0. Accuracy on batch 2992 on Training is 30.247661209488808\n",
            "Epoch #0. Accuracy on batch 2993 on Training is 30.245908483633933\n",
            "Epoch #0. Accuracy on batch 2994 on Training is 30.245200333889816\n",
            "Epoch #0. Accuracy on batch 2995 on Training is 30.241363484646193\n",
            "Epoch #0. Accuracy on batch 2996 on Training is 30.24587087087087\n",
            "Epoch #0. Accuracy on batch 2997 on Training is 30.246205803869245\n",
            "Epoch #0. Accuracy on batch 2998 on Training is 30.244456485495164\n",
            "Epoch #0. Accuracy on batch 2999 on Training is 30.245833333333334\n",
            "Batch Id 3000 is having training loss of 757.775390625\n",
            "15.207456588745117\n",
            "Epoch #0. Accuracy on batch 3000 on Training is 30.245126624458514\n",
            "Epoch #0. Accuracy on batch 3001 on Training is 30.246502331778814\n",
            "Epoch #0. Accuracy on batch 3002 on Training is 30.244755244755243\n",
            "Epoch #0. Accuracy on batch 3003 on Training is 30.240928761651134\n",
            "Epoch #0. Accuracy on batch 3004 on Training is 30.23814475873544\n",
            "Epoch #0. Accuracy on batch 3005 on Training is 30.236402195608783\n",
            "Epoch #0. Accuracy on batch 3006 on Training is 30.234660791486533\n",
            "Epoch #0. Accuracy on batch 3007 on Training is 30.232920545212767\n",
            "Epoch #0. Accuracy on batch 3008 on Training is 30.227027251578598\n",
            "Epoch #0. Accuracy on batch 3009 on Training is 30.227367109634553\n",
            "Epoch #0. Accuracy on batch 3010 on Training is 30.230820325473264\n",
            "Epoch #0. Accuracy on batch 3011 on Training is 30.22389608233732\n",
            "Epoch #0. Accuracy on batch 3012 on Training is 30.224910264124322\n",
            "Epoch #0. Batch Id 0 is having validation loss of 6.900413513183594\n",
            "6.900413513183594\n",
            "Epoch #0. Batch Id 0 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 1 is having validation loss of 31.416128158569336\n",
            "55.93184280395508\n",
            "Epoch #0. Batch Id 1 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 2 is having validation loss of 1344.8018798828125\n",
            "3971.572998046875\n",
            "Epoch #0. Batch Id 2 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 3 is having validation loss of 1010.936767578125\n",
            "9.341604232788086\n",
            "Epoch #0. Batch Id 3 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 4 is having validation loss of 835.4221801757812\n",
            "133.36373901367188\n",
            "Epoch #0. Batch Id 4 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 5 is having validation loss of 711.028076171875\n",
            "89.05750274658203\n",
            "Epoch #0. Batch Id 5 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 6 is having validation loss of 615.3988037109375\n",
            "41.62335968017578\n",
            "Epoch #0. Batch Id 6 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 7 is having validation loss of 1793.6883544921875\n",
            "10041.71484375\n",
            "Epoch #0. Batch Id 7 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 8 is having validation loss of 1605.3975830078125\n",
            "99.07101440429688\n",
            "Epoch #0. Batch Id 8 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 9 is having validation loss of 12946.5810546875\n",
            "115017.234375\n",
            "Epoch #0. Batch Id 9 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 10 is having validation loss of 13771.73828125\n",
            "22023.30859375\n",
            "Epoch #0. Batch Id 10 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 11 is having validation loss of 14309.7255859375\n",
            "20227.58984375\n",
            "Epoch #0. Batch Id 11 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 12 is having validation loss of 13229.5712890625\n",
            "267.71533203125\n",
            "Epoch #0. Batch Id 12 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 13 is having validation loss of 12286.392578125\n",
            "25.075868606567383\n",
            "Epoch #0. Batch Id 13 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 14 is having validation loss of 11477.7763671875\n",
            "157.1523895263672\n",
            "Epoch #0. Batch Id 14 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 15 is having validation loss of 10760.7333984375\n",
            "5.091198921203613\n",
            "Epoch #0. Batch Id 15 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 16 is having validation loss of 20593.826171875\n",
            "177923.3125\n",
            "Epoch #0. Batch Id 16 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 17 is having validation loss of 21915.248046875\n",
            "44379.40625\n",
            "Epoch #0. Batch Id 17 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 18 is having validation loss of 23516.36328125\n",
            "52336.4375\n",
            "Epoch #0. Batch Id 18 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 19 is having validation loss of 22344.39453125\n",
            "76.98101043701172\n",
            "Epoch #0. Batch Id 19 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 20 is having validation loss of 21595.83984375\n",
            "6624.7255859375\n",
            "Epoch #0. Batch Id 20 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 21 is having validation loss of 20626.5703125\n",
            "271.8915100097656\n",
            "Epoch #0. Batch Id 21 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 22 is having validation loss of 19732.287109375\n",
            "58.04975128173828\n",
            "Epoch #0. Batch Id 22 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 23 is having validation loss of 18914.912109375\n",
            "115.2796630859375\n",
            "Epoch #0. Batch Id 23 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 24 is having validation loss of 18161.21875\n",
            "72.59797668457031\n",
            "Epoch #0. Batch Id 24 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 25 is having validation loss of 17464.490234375\n",
            "46.28346633911133\n",
            "Epoch #0. Batch Id 25 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 26 is having validation loss of 16819.294921875\n",
            "44.19685745239258\n",
            "Epoch #0. Batch Id 26 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 27 is having validation loss of 16305.0400390625\n",
            "2420.160400390625\n",
            "Epoch #0. Batch Id 27 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 28 is having validation loss of 15749.2109375\n",
            "186.00059509277344\n",
            "Epoch #0. Batch Id 28 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 29 is having validation loss of 15226.099609375\n",
            "55.85643005371094\n",
            "Epoch #0. Batch Id 29 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 30 is having validation loss of 14735.6513671875\n",
            "22.196508407592773\n",
            "Epoch #0. Batch Id 30 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 31 is having validation loss of 14279.7802734375\n",
            "147.77908325195312\n",
            "Epoch #0. Batch Id 31 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 32 is having validation loss of 13848.9453125\n",
            "62.24183654785156\n",
            "Epoch #0. Batch Id 32 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 33 is having validation loss of 13467.2197265625\n",
            "870.2831420898438\n",
            "Epoch #0. Batch Id 33 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 34 is having validation loss of 13083.673828125\n",
            "43.10886001586914\n",
            "Epoch #0. Batch Id 34 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 35 is having validation loss of 12721.18359375\n",
            "34.03685760498047\n",
            "Epoch #0. Batch Id 35 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 36 is having validation loss of 12381.5009765625\n",
            "152.93670654296875\n",
            "Epoch #0. Batch Id 36 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 37 is having validation loss of 12057.822265625\n",
            "81.70601654052734\n",
            "Epoch #0. Batch Id 37 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 38 is having validation loss of 11753.3193359375\n",
            "182.19393920898438\n",
            "Epoch #0. Batch Id 38 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 39 is having validation loss of 11462.2939453125\n",
            "112.31950378417969\n",
            "Epoch #0. Batch Id 39 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 40 is having validation loss of 11182.8212890625\n",
            "3.8983254432678223\n",
            "Epoch #0. Batch Id 40 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 41 is having validation loss of 10918.025390625\n",
            "61.392730712890625\n",
            "Epoch #0. Batch Id 41 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 42 is having validation loss of 10674.2255859375\n",
            "434.62408447265625\n",
            "Epoch #0. Batch Id 42 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 43 is having validation loss of 10442.541015625\n",
            "480.1104736328125\n",
            "Epoch #0. Batch Id 43 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 44 is having validation loss of 13104.62109375\n",
            "130236.1171875\n",
            "Epoch #0. Batch Id 44 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 45 is having validation loss of 12823.05078125\n",
            "152.40408325195312\n",
            "Epoch #0. Batch Id 45 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 46 is having validation loss of 12552.1513671875\n",
            "90.7906723022461\n",
            "Epoch #0. Batch Id 46 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 47 is having validation loss of 12290.7177734375\n",
            "3.3201076984405518\n",
            "Epoch #0. Batch Id 47 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 48 is having validation loss of 12164.86328125\n",
            "6123.84423828125\n",
            "Epoch #0. Batch Id 48 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 49 is having validation loss of 12882.2353515625\n",
            "48033.4609375\n",
            "Epoch #0. Batch Id 49 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 50 is having validation loss of 13668.3271484375\n",
            "52972.8984375\n",
            "Epoch #0. Batch Id 50 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 51 is having validation loss of 13406.6416015625\n",
            "60.6930046081543\n",
            "Epoch #0. Batch Id 51 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 52 is having validation loss of 14815.4169921875\n",
            "88071.7421875\n",
            "Epoch #0. Batch Id 52 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 53 is having validation loss of 14542.126953125\n",
            "57.75693130493164\n",
            "Epoch #0. Batch Id 53 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 54 is having validation loss of 14278.9716796875\n",
            "68.58564758300781\n",
            "Epoch #0. Batch Id 54 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 55 is having validation loss of 14025.384765625\n",
            "78.12335205078125\n",
            "Epoch #0. Batch Id 55 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 56 is having validation loss of 13785.37890625\n",
            "345.0787658691406\n",
            "Epoch #0. Batch Id 56 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 57 is having validation loss of 13549.86328125\n",
            "125.44683074951172\n",
            "Epoch #0. Batch Id 57 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 58 is having validation loss of 13320.630859375\n",
            "25.12433433532715\n",
            "Epoch #0. Batch Id 58 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 59 is having validation loss of 13101.4765625\n",
            "171.37844848632812\n",
            "Epoch #0. Batch Id 59 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 60 is having validation loss of 12886.763671875\n",
            "4.019965648651123\n",
            "Epoch #0. Batch Id 60 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 61 is having validation loss of 12685.2568359375\n",
            "393.3245849609375\n",
            "Epoch #0. Batch Id 61 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 62 is having validation loss of 12484.1748046875\n",
            "17.114992141723633\n",
            "Epoch #0. Batch Id 62 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 63 is having validation loss of 12488.9248046875\n",
            "12788.1923828125\n",
            "Epoch #0. Batch Id 63 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 64 is having validation loss of 12296.97265625\n",
            "12.05457878112793\n",
            "Epoch #0. Batch Id 64 is having validation accuracy of 0.0\n",
            "Epoch #0. Batch Id 65 is having validation loss of 12110.9599609375\n",
            "20.12979507446289\n",
            "Epoch #0. Batch Id 65 is having validation accuracy of 0.3314393939393939\n",
            "Epoch #0. Batch Id 66 is having validation loss of 11970.8544921875\n",
            "2723.886474609375\n",
            "Epoch #0. Batch Id 66 is having validation accuracy of 0.792910447761194\n",
            "Epoch #0. Batch Id 67 is having validation loss of 11794.9599609375\n",
            "10.054126739501953\n",
            "Epoch #0. Batch Id 67 is having validation accuracy of 1.0110294117647058\n",
            "Epoch #0. Batch Id 68 is having validation loss of 11624.12109375\n",
            "7.0821332931518555\n",
            "Epoch #0. Batch Id 68 is having validation accuracy of 1.4945652173913044\n",
            "Epoch #0. Batch Id 69 is having validation loss of 11458.478515625\n",
            "29.11157989501953\n",
            "Epoch #0. Batch Id 69 is having validation accuracy of 1.9196428571428572\n",
            "Epoch #0. Batch Id 70 is having validation loss of 11324.9892578125\n",
            "1980.76025390625\n",
            "Epoch #0. Batch Id 70 is having validation accuracy of 2.464788732394366\n",
            "Epoch #0. Batch Id 71 is having validation loss of 11168.1015625\n",
            "29.08794403076172\n",
            "Epoch #0. Batch Id 71 is having validation accuracy of 2.907986111111111\n",
            "Epoch #0. Batch Id 72 is having validation loss of 11020.58203125\n",
            "399.1437683105469\n",
            "Epoch #0. Batch Id 72 is having validation accuracy of 3.4246575342465753\n",
            "Epoch #0. Batch Id 73 is having validation loss of 10871.912109375\n",
            "18.98356819152832\n",
            "Epoch #0. Batch Id 73 is having validation accuracy of 3.927364864864865\n",
            "Epoch #0. Batch Id 74 is having validation loss of 10727.4404296875\n",
            "36.51955032348633\n",
            "Epoch #0. Batch Id 74 is having validation accuracy of 4.375\n",
            "Epoch #0. Batch Id 75 is having validation loss of 10586.50390625\n",
            "16.236988067626953\n",
            "Epoch #0. Batch Id 75 is having validation accuracy of 4.810855263157895\n",
            "Epoch #0. Batch Id 76 is having validation loss of 10449.6083984375\n",
            "45.56367492675781\n",
            "Epoch #0. Batch Id 76 is having validation accuracy of 5.316558441558442\n",
            "Epoch #0. Batch Id 77 is having validation loss of 10319.1328125\n",
            "272.53656005859375\n",
            "Epoch #0. Batch Id 77 is having validation accuracy of 5.568910256410256\n",
            "Epoch #0. Batch Id 78 is having validation loss of 10189.0947265625\n",
            "46.090736389160156\n",
            "Epoch #0. Batch Id 78 is having validation accuracy of 5.735759493670886\n",
            "Epoch #0. Batch Id 79 is having validation loss of 10061.953125\n",
            "17.79766845703125\n",
            "Epoch #0. Batch Id 79 is having validation accuracy of 6.015625\n",
            "Epoch #0. Batch Id 80 is having validation loss of 9938.001953125\n",
            "21.935314178466797\n",
            "Epoch #0. Batch Id 80 is having validation accuracy of 6.442901234567901\n",
            "Epoch #0. Batch Id 81 is having validation loss of 9817.2138671875\n",
            "33.41691970825195\n",
            "Epoch #0. Batch Id 81 is having validation accuracy of 6.6692073170731705\n",
            "Epoch #0. Batch Id 82 is having validation loss of 9701.4755859375\n",
            "210.9486846923828\n",
            "Epoch #0. Batch Id 82 is having validation accuracy of 7.0406626506024095\n",
            "Epoch #0. Batch Id 83 is having validation loss of 9586.2158203125\n",
            "19.64814567565918\n",
            "Epoch #0. Batch Id 83 is having validation accuracy of 7.5148809523809526\n",
            "Epoch #0. Batch Id 84 is having validation loss of 9473.572265625\n",
            "11.474924087524414\n",
            "Epoch #0. Batch Id 84 is having validation accuracy of 7.867647058823529\n",
            "Epoch #0. Batch Id 85 is having validation loss of 9363.6533203125\n",
            "20.578161239624023\n",
            "Epoch #0. Batch Id 85 is having validation accuracy of 8.321220930232558\n",
            "Epoch #0. Batch Id 86 is having validation loss of 9256.1513671875\n",
            "10.978389739990234\n",
            "Epoch #0. Batch Id 86 is having validation accuracy of 8.72844827586207\n",
            "Epoch #0. Batch Id 87 is having validation loss of 9151.1865234375\n",
            "19.261817932128906\n",
            "Epoch #0. Batch Id 87 is having validation accuracy of 8.984375\n",
            "Epoch #0. Batch Id 88 is having validation loss of 9049.6953125\n",
            "118.43473815917969\n",
            "Epoch #0. Batch Id 88 is having validation accuracy of 9.164325842696629\n",
            "Epoch #0. Batch Id 89 is having validation loss of 8949.3076171875\n",
            "14.83790397644043\n",
            "Epoch #0. Batch Id 89 is having validation accuracy of 9.409722222222221\n",
            "Epoch #0. Batch Id 90 is having validation loss of 8851.6171875\n",
            "59.506080627441406\n",
            "Epoch #0. Batch Id 90 is having validation accuracy of 9.649725274725276\n",
            "Epoch #0. Batch Id 91 is having validation loss of 8755.6474609375\n",
            "22.400936126708984\n",
            "Epoch #0. Batch Id 91 is having validation accuracy of 9.918478260869565\n",
            "Epoch #0. Batch Id 92 is having validation loss of 8662.5126953125\n",
            "94.07270050048828\n",
            "Epoch #0. Batch Id 92 is having validation accuracy of 10.147849462365592\n",
            "Epoch #0. Batch Id 93 is having validation loss of 8570.6787109375\n",
            "30.151248931884766\n",
            "Epoch #0. Batch Id 93 is having validation accuracy of 10.40558510638298\n",
            "Epoch #0. Batch Id 94 is having validation loss of 8480.6962890625\n",
            "22.341018676757812\n",
            "Epoch #0. Batch Id 94 is having validation accuracy of 10.756578947368421\n",
            "Epoch #0. Batch Id 95 is having validation loss of 8392.4462890625\n",
            "8.67629337310791\n",
            "Epoch #0. Batch Id 95 is having validation accuracy of 11.1328125\n",
            "Epoch #0. Batch Id 96 is having validation loss of 8310.1044921875\n",
            "405.3061218261719\n",
            "Epoch #0. Batch Id 96 is having validation accuracy of 11.37242268041237\n",
            "Epoch #0. Batch Id 97 is having validation loss of 8225.7275390625\n",
            "41.118255615234375\n",
            "Epoch #0. Batch Id 97 is having validation accuracy of 11.73469387755102\n",
            "Epoch #0. Batch Id 98 is having validation loss of 8142.8466796875\n",
            "20.515769958496094\n",
            "Epoch #0. Batch Id 98 is having validation accuracy of 11.900252525252526\n",
            "Epoch #0. Batch Id 99 is having validation loss of 8061.64111328125\n",
            "22.293689727783203\n",
            "Epoch #0. Batch Id 99 is having validation accuracy of 12.1875\n",
            "Epoch #0. Batch Id 100 is having validation loss of 7982.1787109375\n",
            "35.94548416137695\n",
            "Epoch #0. Batch Id 100 is having validation accuracy of 12.314356435643564\n",
            "Epoch #0. Batch Id 101 is having validation loss of 7904.123046875\n",
            "20.48727035522461\n",
            "Epoch #0. Batch Id 101 is having validation accuracy of 12.622549019607844\n",
            "Epoch #0. Batch Id 102 is having validation loss of 7827.5771484375\n",
            "19.88980484008789\n",
            "Epoch #0. Batch Id 102 is having validation accuracy of 12.924757281553399\n",
            "Epoch #0. Batch Id 103 is having validation loss of 7752.5322265625\n",
            "22.900299072265625\n",
            "Epoch #0. Batch Id 103 is having validation accuracy of 13.010817307692308\n",
            "Epoch #0. Batch Id 104 is having validation loss of 7678.888671875\n",
            "19.937685012817383\n",
            "Epoch #0. Batch Id 104 is having validation accuracy of 13.392857142857142\n",
            "Epoch #0. Batch Id 105 is having validation loss of 7606.697265625\n",
            "26.618484497070312\n",
            "Epoch #0. Batch Id 105 is having validation accuracy of 13.649764150943396\n",
            "Epoch #0. Batch Id 106 is having validation loss of 7536.2373046875\n",
            "67.46095275878906\n",
            "Epoch #0. Batch Id 106 is having validation accuracy of 13.843457943925234\n",
            "Epoch #0. Batch Id 107 is having validation loss of 7466.73388671875\n",
            "29.86510467529297\n",
            "Epoch #0. Batch Id 107 is having validation accuracy of 14.033564814814815\n",
            "Epoch #0. Batch Id 108 is having validation loss of 7398.67333984375\n",
            "48.13886260986328\n",
            "Epoch #0. Batch Id 108 is having validation accuracy of 14.105504587155963\n",
            "Epoch #0. Batch Id 109 is having validation loss of 7331.92626953125\n",
            "56.51932907104492\n",
            "Epoch #0. Batch Id 109 is having validation accuracy of 14.176136363636363\n",
            "Epoch #0. Batch Id 110 is having validation loss of 7266.1279296875\n",
            "28.296354293823242\n",
            "Epoch #0. Batch Id 110 is having validation accuracy of 14.27364864864865\n",
            "Epoch #0. Batch Id 111 is having validation loss of 7201.40234375\n",
            "16.880111694335938\n",
            "Epoch #0. Batch Id 111 is having validation accuracy of 14.508928571428571\n",
            "Epoch #0. Batch Id 112 is having validation loss of 7137.77880859375\n",
            "11.957616806030273\n",
            "Epoch #0. Batch Id 112 is having validation accuracy of 14.74004424778761\n",
            "Epoch #0. Batch Id 113 is having validation loss of 7075.33251953125\n",
            "18.925758361816406\n",
            "Epoch #0. Batch Id 113 is having validation accuracy of 14.967105263157896\n",
            "Epoch #0. Batch Id 114 is having validation loss of 7014.12890625\n",
            "36.92178726196289\n",
            "Epoch #0. Batch Id 114 is having validation accuracy of 15.190217391304348\n",
            "Epoch #0. Batch Id 115 is having validation loss of 6954.02587890625\n",
            "42.187896728515625\n",
            "Epoch #0. Batch Id 115 is having validation accuracy of 15.167025862068966\n",
            "Epoch #0. Batch Id 116 is having validation loss of 6894.7490234375\n",
            "18.636613845825195\n",
            "Epoch #0. Batch Id 116 is having validation accuracy of 15.277777777777779\n",
            "Epoch #0. Batch Id 117 is having validation loss of 6836.5439453125\n",
            "26.548978805541992\n",
            "Epoch #0. Batch Id 117 is having validation accuracy of 15.439618644067796\n",
            "Epoch #0. Batch Id 118 is having validation loss of 6779.45361328125\n",
            "42.77317810058594\n",
            "Epoch #0. Batch Id 118 is having validation accuracy of 15.572478991596638\n",
            "Epoch #0. Batch Id 119 is having validation loss of 6778.77685546875\n",
            "6698.248046875\n",
            "Epoch #0. Batch Id 119 is having validation accuracy of 15.78125\n",
            "Epoch #0. Batch Id 120 is having validation loss of 6722.94580078125\n",
            "23.215309143066406\n",
            "Epoch #0. Batch Id 120 is having validation accuracy of 16.115702479338843\n",
            "Epoch #0. Batch Id 121 is having validation loss of 6820.71533203125\n",
            "18650.83203125\n",
            "Epoch #0. Batch Id 121 is having validation accuracy of 16.137295081967213\n",
            "Epoch #0. Batch Id 122 is having validation loss of 6793.98046875\n",
            "3532.302001953125\n",
            "Epoch #0. Batch Id 122 is having validation accuracy of 16.3109756097561\n",
            "Epoch #0. Batch Id 123 is having validation loss of 6739.32763671875\n",
            "17.048620223999023\n",
            "Epoch #0. Batch Id 123 is having validation accuracy of 16.507056451612904\n",
            "Epoch #0. Batch Id 124 is having validation loss of 6685.595703125\n",
            "22.84516716003418\n",
            "Epoch #0. Batch Id 124 is having validation accuracy of 16.775\n",
            "Epoch #0. Batch Id 125 is having validation loss of 6632.7138671875\n",
            "22.512603759765625\n",
            "Epoch #0. Batch Id 125 is having validation accuracy of 16.9890873015873\n",
            "Epoch #0. Batch Id 126 is having validation loss of 6580.64208984375\n",
            "19.579917907714844\n",
            "Epoch #0. Batch Id 126 is having validation accuracy of 17.00295275590551\n",
            "Epoch #0. Batch Id 127 is having validation loss of 6529.35302734375\n",
            "15.625199317932129\n",
            "Epoch #0. Batch Id 127 is having validation accuracy of 17.236328125\n",
            "Epoch #0. Batch Id 128 is having validation loss of 6498.841796875\n",
            "2593.41796875\n",
            "Epoch #0. Batch Id 128 is having validation accuracy of 17.32073643410853\n",
            "Epoch #0. Batch Id 129 is having validation loss of 6448.92138671875\n",
            "9.158506393432617\n",
            "Epoch #0. Batch Id 129 is having validation accuracy of 17.379807692307693\n",
            "Epoch #0. Batch Id 130 is having validation loss of 6399.78369140625\n",
            "11.908027648925781\n",
            "Epoch #0. Batch Id 130 is having validation accuracy of 17.509541984732824\n",
            "Epoch #0. Batch Id 131 is having validation loss of 6351.49462890625\n",
            "25.621318817138672\n",
            "Epoch #0. Batch Id 131 is having validation accuracy of 17.732007575757574\n",
            "Epoch #0. Batch Id 132 is having validation loss of 6303.884765625\n",
            "19.368806838989258\n",
            "Epoch #0. Batch Id 132 is having validation accuracy of 17.69266917293233\n",
            "Epoch #0. Batch Id 133 is having validation loss of 6277.734375\n",
            "2799.718994140625\n",
            "Epoch #0. Batch Id 133 is having validation accuracy of 17.770522388059703\n",
            "Epoch #0. Batch Id 134 is having validation loss of 6231.30029296875\n",
            "9.103860855102539\n",
            "Epoch #0. Batch Id 134 is having validation accuracy of 18.00925925925926\n",
            "Epoch #0. Batch Id 135 is having validation loss of 6185.73388671875\n",
            "34.253173828125\n",
            "Epoch #0. Batch Id 135 is having validation accuracy of 18.060661764705884\n",
            "Epoch #0. Batch Id 136 is having validation loss of 6140.794921875\n",
            "29.079030990600586\n",
            "Epoch #0. Batch Id 136 is having validation accuracy of 18.202554744525546\n",
            "Epoch #0. Batch Id 137 is having validation loss of 6096.42041015625\n",
            "17.10890007019043\n",
            "Epoch #0. Batch Id 137 is having validation accuracy of 18.455615942028984\n",
            "Epoch #0. Batch Id 138 is having validation loss of 6054.0390625\n",
            "205.4268798828125\n",
            "Epoch #0. Batch Id 138 is having validation accuracy of 18.480215827338128\n",
            "Epoch #0. Batch Id 139 is having validation loss of 6010.9931640625\n",
            "27.596210479736328\n",
            "Epoch #0. Batch Id 139 is having validation accuracy of 18.571428571428573\n",
            "Epoch #0. Batch Id 140 is having validation loss of 5968.64697265625\n",
            "40.16902542114258\n",
            "Epoch #0. Batch Id 140 is having validation accuracy of 18.661347517730498\n",
            "Epoch #0. Batch Id 141 is having validation loss of 5944.69482421875\n",
            "2567.43017578125\n",
            "Epoch #0. Batch Id 141 is having validation accuracy of 18.860035211267604\n",
            "Epoch #0. Batch Id 142 is having validation loss of 5903.271484375\n",
            "21.153579711914062\n",
            "Epoch #0. Batch Id 142 is having validation accuracy of 19.03409090909091\n",
            "Epoch #0. Batch Id 143 is having validation loss of 5862.35546875\n",
            "11.359787940979004\n",
            "Epoch #0. Batch Id 143 is having validation accuracy of 19.227430555555557\n",
            "Epoch #0. Batch Id 144 is having validation loss of 5868.0439453125\n",
            "6687.171875\n",
            "Epoch #0. Batch Id 144 is having validation accuracy of 19.461206896551722\n",
            "Epoch #0. Batch Id 145 is having validation loss of 5828.05224609375\n",
            "29.23797035217285\n",
            "Epoch #0. Batch Id 145 is having validation accuracy of 19.456335616438356\n",
            "Epoch #0. Batch Id 146 is having validation loss of 5788.611328125\n",
            "30.25396156311035\n",
            "Epoch #0. Batch Id 146 is having validation accuracy of 19.57908163265306\n",
            "Epoch #0. Batch Id 147 is having validation loss of 5749.740234375\n",
            "35.65922546386719\n",
            "Epoch #0. Batch Id 147 is having validation accuracy of 19.70016891891892\n",
            "Epoch #0. Batch Id 148 is having validation loss of 5711.36279296875\n",
            "31.513376235961914\n",
            "Epoch #0. Batch Id 148 is having validation accuracy of 19.840604026845636\n",
            "Epoch #0. Batch Id 149 is having validation loss of 5676.54736328125\n",
            "489.08331298828125\n",
            "Epoch #0. Batch Id 149 is having validation accuracy of 19.916666666666668\n",
            "Epoch #0. Batch Id 150 is having validation loss of 5639.0712890625\n",
            "17.686677932739258\n",
            "Epoch #0. Batch Id 150 is having validation accuracy of 20.09519867549669\n",
            "Epoch #0. Batch Id 151 is having validation loss of 5603.828125\n",
            "282.135986328125\n",
            "Epoch #0. Batch Id 151 is having validation accuracy of 20.16858552631579\n",
            "Epoch #0. Batch Id 152 is having validation loss of 5567.35693359375\n",
            "23.7110595703125\n",
            "Epoch #0. Batch Id 152 is having validation accuracy of 20.28186274509804\n",
            "Epoch #0. Batch Id 153 is having validation loss of 5531.27685546875\n",
            "11.050186157226562\n",
            "Epoch #0. Batch Id 153 is having validation accuracy of 20.434253246753247\n",
            "Epoch #0. Batch Id 154 is having validation loss of 5495.751953125\n",
            "24.92364501953125\n",
            "Epoch #0. Batch Id 154 is having validation accuracy of 20.524193548387096\n",
            "Epoch #0. Batch Id 155 is having validation loss of 5460.677734375\n",
            "24.211589813232422\n",
            "Epoch #0. Batch Id 155 is having validation accuracy of 20.572916666666668\n",
            "Epoch #0. Batch Id 156 is having validation loss of 5521.861328125\n",
            "15066.46484375\n",
            "Epoch #0. Batch Id 156 is having validation accuracy of 20.720541401273884\n",
            "Epoch #0. Batch Id 157 is having validation loss of 5526.49658203125\n",
            "6254.216796875\n",
            "Epoch #0. Batch Id 157 is having validation accuracy of 20.88607594936709\n",
            "Epoch #0. Batch Id 158 is having validation loss of 5491.8359375\n",
            "15.429986953735352\n",
            "Epoch #0. Batch Id 158 is having validation accuracy of 20.931603773584907\n",
            "Epoch #0. Batch Id 159 is having validation loss of 5458.24853515625\n",
            "117.8558578491211\n",
            "Epoch #0. Batch Id 159 is having validation accuracy of 20.99609375\n",
            "Epoch #0. Batch Id 160 is having validation loss of 5424.51611328125\n",
            "27.32733154296875\n",
            "Epoch #0. Batch Id 160 is having validation accuracy of 20.982142857142858\n",
            "Epoch #0. Batch Id 161 is having validation loss of 5391.1533203125\n",
            "19.778247833251953\n",
            "Epoch #0. Batch Id 161 is having validation accuracy of 21.006944444444443\n",
            "Epoch #0. Batch Id 162 is having validation loss of 5358.14599609375\n",
            "10.989212989807129\n",
            "Epoch #0. Batch Id 162 is having validation accuracy of 21.20398773006135\n",
            "Epoch #0. Batch Id 163 is having validation loss of 5327.46630859375\n",
            "326.7013854980469\n",
            "Epoch #0. Batch Id 163 is having validation accuracy of 21.265243902439025\n",
            "Epoch #0. Batch Id 164 is having validation loss of 5295.38720703125\n",
            "34.44523620605469\n",
            "Epoch #0. Batch Id 164 is having validation accuracy of 21.325757575757574\n",
            "Epoch #0. Batch Id 165 is having validation loss of 5263.5908203125\n",
            "17.17650604248047\n",
            "Epoch #0. Batch Id 165 is having validation accuracy of 21.3855421686747\n",
            "Epoch #0. Batch Id 166 is having validation loss of 5232.1708984375\n",
            "16.45161247253418\n",
            "Epoch #0. Batch Id 166 is having validation accuracy of 21.463323353293415\n",
            "Epoch #0. Batch Id 167 is having validation loss of 5201.27197265625\n",
            "41.13127899169922\n",
            "Epoch #0. Batch Id 167 is having validation accuracy of 21.540178571428573\n",
            "Epoch #0. Batch Id 168 is having validation loss of 5170.5849609375\n",
            "15.201458930969238\n",
            "Epoch #0. Batch Id 168 is having validation accuracy of 21.54215976331361\n",
            "Epoch #0. Batch Id 169 is having validation loss of 5145.50634765625\n",
            "907.196044921875\n",
            "Epoch #0. Batch Id 169 is having validation accuracy of 21.636029411764707\n",
            "Epoch #0. Batch Id 170 is having validation loss of 5115.5302734375\n",
            "19.608768463134766\n",
            "Epoch #0. Batch Id 170 is having validation accuracy of 21.673976608187136\n",
            "Epoch #0. Batch Id 171 is having validation loss of 5088.36962890625\n",
            "443.8624267578125\n",
            "Epoch #0. Batch Id 171 is having validation accuracy of 21.67514534883721\n",
            "Epoch #0. Batch Id 172 is having validation loss of 5059.05517578125\n",
            "16.98394775390625\n",
            "Epoch #0. Batch Id 172 is having validation accuracy of 21.820809248554912\n",
            "Epoch #0. Batch Id 173 is having validation loss of 5030.248046875\n",
            "46.61326599121094\n",
            "Epoch #0. Batch Id 173 is having validation accuracy of 21.92887931034483\n",
            "Epoch #0. Batch Id 174 is having validation loss of 5005.08984375\n",
            "627.5632934570312\n",
            "Epoch #0. Batch Id 174 is having validation accuracy of 21.892857142857142\n",
            "Epoch #0. Batch Id 175 is having validation loss of 4976.78759765625\n",
            "23.90199089050293\n",
            "Epoch #0. Batch Id 175 is having validation accuracy of 21.946022727272727\n",
            "Epoch #0. Batch Id 176 is having validation loss of 4948.91845703125\n",
            "43.97447967529297\n",
            "Epoch #0. Batch Id 176 is having validation accuracy of 21.910310734463277\n",
            "Epoch #0. Batch Id 177 is having validation loss of 4941.78076171875\n",
            "3678.39599609375\n",
            "Epoch #0. Batch Id 177 is having validation accuracy of 21.839887640449437\n",
            "Epoch #0. Batch Id 178 is having validation loss of 4914.212890625\n",
            "7.168808937072754\n",
            "Epoch #0. Batch Id 178 is having validation accuracy of 21.875\n",
            "Epoch #0. Batch Id 179 is having validation loss of 4887.92919921875\n",
            "183.12599182128906\n",
            "Epoch #0. Batch Id 179 is having validation accuracy of 21.961805555555557\n",
            "Epoch #0. Batch Id 180 is having validation loss of 4861.04931640625\n",
            "22.6750545501709\n",
            "Epoch #0. Batch Id 180 is having validation accuracy of 22.11671270718232\n",
            "Epoch #0. Batch Id 181 is having validation loss of 4834.57470703125\n",
            "42.63956832885742\n",
            "Epoch #0. Batch Id 181 is having validation accuracy of 22.201236263736263\n",
            "Epoch #0. Batch Id 182 is having validation loss of 4808.20068359375\n",
            "8.087284088134766\n",
            "Epoch #0. Batch Id 182 is having validation accuracy of 22.370218579234972\n",
            "Epoch #0. Batch Id 183 is having validation loss of 4782.2021484375\n",
            "24.447723388671875\n",
            "Epoch #0. Batch Id 183 is having validation accuracy of 22.418478260869566\n",
            "Epoch #0. Batch Id 184 is having validation loss of 4756.44921875\n",
            "17.886882781982422\n",
            "Epoch #0. Batch Id 184 is having validation accuracy of 22.51689189189189\n",
            "Epoch #0. Batch Id 185 is having validation loss of 4730.978515625\n",
            "18.88678550720215\n",
            "Epoch #0. Batch Id 185 is having validation accuracy of 22.647849462365592\n",
            "Epoch #0. Batch Id 186 is having validation loss of 4706.19384765625\n",
            "96.2664794921875\n",
            "Epoch #0. Batch Id 186 is having validation accuracy of 22.66042780748663\n",
            "Epoch #0. Batch Id 187 is having validation loss of 4681.28076171875\n",
            "22.497167587280273\n",
            "Epoch #0. Batch Id 187 is having validation accuracy of 22.789228723404257\n",
            "Epoch #0. Batch Id 188 is having validation loss of 4682.615234375\n",
            "4933.5361328125\n",
            "Epoch #0. Batch Id 188 is having validation accuracy of 22.8505291005291\n",
            "Epoch #0. Batch Id 189 is having validation loss of 4671.4150390625\n",
            "2554.605224609375\n",
            "Epoch #0. Batch Id 189 is having validation accuracy of 22.82894736842105\n",
            "Epoch #0. Batch Id 190 is having validation loss of 4647.1181640625\n",
            "30.74806022644043\n",
            "Epoch #0. Batch Id 190 is having validation accuracy of 22.85667539267016\n",
            "Epoch #0. Batch Id 191 is having validation loss of 4623.01318359375\n",
            "18.962276458740234\n",
            "Epoch #0. Batch Id 191 is having validation accuracy of 22.916666666666668\n",
            "Epoch #0. Batch Id 192 is having validation loss of 4599.14013671875\n",
            "15.468019485473633\n",
            "Epoch #0. Batch Id 192 is having validation accuracy of 22.95984455958549\n",
            "Epoch #0. Batch Id 193 is having validation loss of 4576.45947265625\n",
            "199.0569610595703\n",
            "Epoch #0. Batch Id 193 is having validation accuracy of 22.986469072164947\n",
            "Epoch #0. Batch Id 194 is having validation loss of 4553.10400390625\n",
            "22.1124324798584\n",
            "Epoch #0. Batch Id 194 is having validation accuracy of 22.96474358974359\n",
            "Epoch #0. Batch Id 195 is having validation loss of 4529.98828125\n",
            "22.420368194580078\n",
            "Epoch #0. Batch Id 195 is having validation accuracy of 22.927295918367346\n",
            "Epoch #0. Batch Id 196 is having validation loss of 4507.08154296875\n",
            "17.38121795654297\n",
            "Epoch #0. Batch Id 196 is having validation accuracy of 23.01713197969543\n",
            "Epoch #0. Batch Id 197 is having validation loss of 4484.5517578125\n",
            "46.2078971862793\n",
            "Epoch #0. Batch Id 197 is having validation accuracy of 23.011363636363637\n",
            "Epoch #0. Batch Id 198 is having validation loss of 4470.7978515625\n",
            "1747.4952392578125\n",
            "Epoch #0. Batch Id 198 is having validation accuracy of 23.037060301507537\n",
            "Epoch #0. Batch Id 199 is having validation loss of 4458.2568359375\n",
            "1962.5887451171875\n",
            "Epoch #0. Batch Id 199 is having validation accuracy of 23.015625\n",
            "Epoch #0. Batch Id 200 is having validation loss of 4436.15966796875\n",
            "16.715787887573242\n",
            "Epoch #0. Batch Id 200 is having validation accuracy of 23.056592039800996\n",
            "Epoch #0. Batch Id 201 is having validation loss of 4414.31298828125\n",
            "23.160951614379883\n",
            "Epoch #0. Batch Id 201 is having validation accuracy of 23.019801980198018\n",
            "Epoch #0. Batch Id 202 is having validation loss of 4392.67626953125\n",
            "22.04024887084961\n",
            "Epoch #0. Batch Id 202 is having validation accuracy of 23.029556650246306\n",
            "Epoch #0. Batch Id 203 is having validation loss of 4371.2880859375\n",
            "29.499832153320312\n",
            "Epoch #0. Batch Id 203 is having validation accuracy of 23.02389705882353\n",
            "Epoch #0. Batch Id 204 is having validation loss of 4350.048828125\n",
            "17.28031349182129\n",
            "Epoch #0. Batch Id 204 is having validation accuracy of 23.140243902439025\n",
            "Epoch #0. Batch Id 205 is having validation loss of 4329.01171875\n",
            "16.371490478515625\n",
            "Epoch #0. Batch Id 205 is having validation accuracy of 23.19478155339806\n",
            "Epoch #0. Batch Id 206 is having validation loss of 4308.32763671875\n",
            "47.415306091308594\n",
            "Epoch #0. Batch Id 206 is having validation accuracy of 23.20350241545894\n",
            "Epoch #0. Batch Id 207 is having validation loss of 4287.92724609375\n",
            "65.07910919189453\n",
            "Epoch #0. Batch Id 207 is having validation accuracy of 23.15204326923077\n",
            "Epoch #0. Batch Id 208 is having validation loss of 4267.5263671875\n",
            "24.10789680480957\n",
            "Epoch #0. Batch Id 208 is having validation accuracy of 23.175837320574164\n",
            "Epoch #0. Batch Id 209 is having validation loss of 4248.337890625\n",
            "237.90138244628906\n",
            "Epoch #0. Batch Id 209 is having validation accuracy of 23.199404761904763\n",
            "Epoch #0. Batch Id 210 is having validation loss of 4228.50048828125\n",
            "62.61515808105469\n",
            "Epoch #0. Batch Id 210 is having validation accuracy of 23.252369668246445\n",
            "Epoch #0. Batch Id 211 is having validation loss of 4208.66015625\n",
            "22.342273712158203\n",
            "Epoch #0. Batch Id 211 is having validation accuracy of 23.29009433962264\n",
            "Epoch #0. Batch Id 212 is having validation loss of 4189.0439453125\n",
            "30.40377426147461\n",
            "Epoch #0. Batch Id 212 is having validation accuracy of 23.371478873239436\n",
            "Epoch #0. Batch Id 213 is having validation loss of 4169.619140625\n",
            "32.099456787109375\n",
            "Epoch #0. Batch Id 213 is having validation accuracy of 23.335280373831775\n",
            "Epoch #0. Batch Id 214 is having validation loss of 4150.2998046875\n",
            "15.976993560791016\n",
            "Epoch #0. Batch Id 214 is having validation accuracy of 23.328488372093023\n",
            "Epoch #0. Batch Id 215 is having validation loss of 4131.2109375\n",
            "27.121171951293945\n",
            "Epoch #0. Batch Id 215 is having validation accuracy of 23.37962962962963\n",
            "Epoch #0. Batch Id 216 is having validation loss of 4112.23193359375\n",
            "12.727459907531738\n",
            "Epoch #0. Batch Id 216 is having validation accuracy of 23.444700460829495\n",
            "Epoch #0. Batch Id 217 is having validation loss of 4093.531982421875\n",
            "35.667545318603516\n",
            "Epoch #0. Batch Id 217 is having validation accuracy of 23.4375\n",
            "Epoch #0. Batch Id 218 is having validation loss of 4155.4345703125\n",
            "17650.1875\n",
            "Epoch #0. Batch Id 218 is having validation accuracy of 23.501712328767123\n",
            "Epoch #0. Batch Id 219 is having validation loss of 4136.65771484375\n",
            "24.534982681274414\n",
            "Epoch #0. Batch Id 219 is having validation accuracy of 23.508522727272727\n",
            "Epoch #0. Batch Id 220 is having validation loss of 4118.01806640625\n",
            "17.29662322998047\n",
            "Epoch #0. Batch Id 220 is having validation accuracy of 23.529411764705884\n",
            "Epoch #0. Batch Id 221 is having validation loss of 4099.60888671875\n",
            "31.184492111206055\n",
            "Epoch #0. Batch Id 221 is having validation accuracy of 23.55011261261261\n",
            "Epoch #0. Batch Id 222 is having validation loss of 4081.349365234375\n",
            "27.721717834472656\n",
            "Epoch #0. Batch Id 222 is having validation accuracy of 23.542600896860986\n",
            "Epoch #0. Batch Id 223 is having validation loss of 4063.240478515625\n",
            "24.938684463500977\n",
            "Epoch #0. Batch Id 223 is having validation accuracy of 23.618861607142858\n",
            "Epoch #0. Batch Id 224 is having validation loss of 4045.30029296875\n",
            "26.68031883239746\n",
            "Epoch #0. Batch Id 224 is having validation accuracy of 23.59722222222222\n",
            "Epoch #0. Batch Id 225 is having validation loss of 4027.509033203125\n",
            "24.494935989379883\n",
            "Epoch #0. Batch Id 225 is having validation accuracy of 23.60342920353982\n",
            "Epoch #0. Batch Id 226 is having validation loss of 4009.8486328125\n",
            "18.611343383789062\n",
            "Epoch #0. Batch Id 226 is having validation accuracy of 23.69218061674009\n",
            "Epoch #0. Batch Id 227 is having validation loss of 4011.748291015625\n",
            "4442.98681640625\n",
            "Epoch #0. Batch Id 227 is having validation accuracy of 23.78015350877193\n",
            "Epoch #0. Batch Id 228 is having validation loss of 3994.328125\n",
            "22.553102493286133\n",
            "Epoch #0. Batch Id 228 is having validation accuracy of 23.758187772925766\n",
            "Epoch #0. Batch Id 229 is having validation loss of 3977.002197265625\n",
            "9.372505187988281\n",
            "Epoch #0. Batch Id 229 is having validation accuracy of 23.817934782608695\n",
            "Epoch #0. Batch Id 230 is having validation loss of 3959.8740234375\n",
            "20.412431716918945\n",
            "Epoch #0. Batch Id 230 is having validation accuracy of 23.836580086580085\n",
            "Epoch #0. Batch Id 231 is having validation loss of 3942.875\n",
            "16.09379005432129\n",
            "Epoch #0. Batch Id 231 is having validation accuracy of 23.935883620689655\n",
            "Epoch #0. Batch Id 232 is having validation loss of 3926.05029296875\n",
            "22.720691680908203\n",
            "Epoch #0. Batch Id 232 is having validation accuracy of 24.020922746781117\n",
            "Epoch #0. Batch Id 233 is having validation loss of 3909.521484375\n",
            "58.3216438293457\n",
            "Epoch #0. Batch Id 233 is having validation accuracy of 24.105235042735043\n",
            "Epoch #0. Batch Id 234 is having validation loss of 3892.90966796875\n",
            "5.722977638244629\n",
            "Epoch #0. Batch Id 234 is having validation accuracy of 24.215425531914892\n",
            "Epoch #0. Batch Id 235 is having validation loss of 3876.47119140625\n",
            "13.403225898742676\n",
            "Epoch #0. Batch Id 235 is having validation accuracy of 24.284957627118644\n",
            "Epoch #0. Batch Id 236 is having validation loss of 3860.4365234375\n",
            "76.27224731445312\n",
            "Epoch #0. Batch Id 236 is having validation accuracy of 24.287974683544302\n",
            "Epoch #0. Batch Id 237 is having validation loss of 3844.274658203125\n",
            "13.890326499938965\n",
            "Epoch #0. Batch Id 237 is having validation accuracy of 24.369747899159663\n",
            "Epoch #0. Batch Id 238 is having validation loss of 3828.26904296875\n",
            "18.906383514404297\n",
            "Epoch #0. Batch Id 238 is having validation accuracy of 24.450836820083683\n",
            "Epoch #0. Batch Id 239 is having validation loss of 3814.576416015625\n",
            "542.0145263671875\n",
            "Epoch #0. Batch Id 239 is having validation accuracy of 24.440104166666668\n",
            "Epoch #0. Batch Id 240 is having validation loss of 3798.99658203125\n",
            "59.84380340576172\n",
            "Epoch #0. Batch Id 240 is having validation accuracy of 24.494294605809127\n",
            "Epoch #0. Batch Id 241 is having validation loss of 3783.347900390625\n",
            "12.0043306350708\n",
            "Epoch #0. Batch Id 241 is having validation accuracy of 24.56095041322314\n",
            "Epoch #0. Batch Id 242 is having validation loss of 3767.860107421875\n",
            "19.81639862060547\n",
            "Epoch #0. Batch Id 242 is having validation accuracy of 24.65277777777778\n",
            "Epoch #0. Batch Id 243 is having validation loss of 3762.081298828125\n",
            "2357.826171875\n",
            "Epoch #0. Batch Id 243 is having validation accuracy of 24.705430327868854\n",
            "Epoch #0. Batch Id 244 is having validation loss of 3766.41455078125\n",
            "4823.7412109375\n",
            "Epoch #0. Batch Id 244 is having validation accuracy of 24.732142857142858\n",
            "Epoch #0. Batch Id 245 is having validation loss of 3751.241943359375\n",
            "33.94109344482422\n",
            "Epoch #0. Batch Id 245 is having validation accuracy of 24.809451219512194\n",
            "Epoch #0. Batch Id 246 is having validation loss of 3736.106201171875\n",
            "12.736063003540039\n",
            "Epoch #0. Batch Id 246 is having validation accuracy of 24.84817813765182\n",
            "Epoch #0. Batch Id 247 is having validation loss of 3721.155029296875\n",
            "28.188919067382812\n",
            "Epoch #0. Batch Id 247 is having validation accuracy of 24.82358870967742\n",
            "Epoch #0. Batch Id 248 is having validation loss of 3706.24951171875\n",
            "9.689957618713379\n",
            "Epoch #0. Batch Id 248 is having validation accuracy of 24.887048192771083\n",
            "Epoch #0. Batch Id 249 is having validation loss of 3739.315673828125\n",
            "11972.7724609375\n",
            "Epoch #0. Batch Id 249 is having validation accuracy of 24.9\n",
            "Epoch #0. Batch Id 250 is having validation loss of 3724.48876953125\n",
            "17.761825561523438\n",
            "Epoch #0. Batch Id 250 is having validation accuracy of 24.95019920318725\n",
            "Epoch #0. Batch Id 251 is having validation loss of 3709.82421875\n",
            "29.002944946289062\n",
            "Epoch #0. Batch Id 251 is having validation accuracy of 24.97519841269841\n",
            "Epoch #0. Batch Id 252 is having validation loss of 3695.328857421875\n",
            "42.485191345214844\n",
            "Epoch #0. Batch Id 252 is having validation accuracy of 25.012351778656125\n",
            "Epoch #0. Batch Id 253 is having validation loss of 3681.0576171875\n",
            "70.40849304199219\n",
            "Epoch #0. Batch Id 253 is having validation accuracy of 25.0246062992126\n",
            "Epoch #0. Batch Id 254 is having validation loss of 3667.5537109375\n",
            "237.53712463378906\n",
            "Epoch #0. Batch Id 254 is having validation accuracy of 25.04901960784314\n",
            "Epoch #0. Batch Id 255 is having validation loss of 3653.355224609375\n",
            "32.734249114990234\n",
            "Epoch #0. Batch Id 255 is having validation accuracy of 25.06103515625\n",
            "Epoch #0. Batch Id 256 is having validation loss of 3694.990966796875\n",
            "14353.71484375\n",
            "Epoch #0. Batch Id 256 is having validation accuracy of 25.06079766536965\n",
            "Epoch #0. Batch Id 257 is having validation loss of 3680.77783203125\n",
            "27.99827766418457\n",
            "Epoch #0. Batch Id 257 is having validation accuracy of 25.109011627906977\n",
            "Epoch #0. Batch Id 258 is having validation loss of 3666.6572265625\n",
            "23.52783203125\n",
            "Epoch #0. Batch Id 258 is having validation accuracy of 25.108590733590734\n",
            "Epoch #0. Batch Id 259 is having validation loss of 3652.61474609375\n",
            "15.623483657836914\n",
            "Epoch #0. Batch Id 259 is having validation accuracy of 25.084134615384617\n",
            "Epoch #0. Batch Id 260 is having validation loss of 3638.906982421875\n",
            "74.89585876464844\n",
            "Epoch #0. Batch Id 260 is having validation accuracy of 25.131704980842912\n",
            "Epoch #0. Batch Id 261 is having validation loss of 3625.152099609375\n",
            "35.109622955322266\n",
            "Epoch #0. Batch Id 261 is having validation accuracy of 25.119274809160306\n",
            "Epoch #0. Batch Id 262 is having validation loss of 3647.555419921875\n",
            "9517.1953125\n",
            "Epoch #0. Batch Id 262 is having validation accuracy of 25.1425855513308\n",
            "Epoch #0. Batch Id 263 is having validation loss of 3633.778076171875\n",
            "10.362432479858398\n",
            "Epoch #0. Batch Id 263 is having validation accuracy of 25.130208333333332\n",
            "Epoch #0. Batch Id 264 is having validation loss of 3620.1533203125\n",
            "23.236759185791016\n",
            "Epoch #0. Batch Id 264 is having validation accuracy of 25.129716981132077\n",
            "Epoch #0. Batch Id 265 is having validation loss of 3606.616455078125\n",
            "19.352487564086914\n",
            "Epoch #0. Batch Id 265 is having validation accuracy of 25.12922932330827\n",
            "Epoch #0. Batch Id 266 is having validation loss of 3593.1962890625\n",
            "23.46308708190918\n",
            "Epoch #0. Batch Id 266 is having validation accuracy of 25.140449438202246\n",
            "Epoch #0. Batch Id 267 is having validation loss of 3579.859375\n",
            "18.900625228881836\n",
            "Epoch #0. Batch Id 267 is having validation accuracy of 25.13992537313433\n",
            "Epoch #0. Batch Id 268 is having validation loss of 3566.607177734375\n",
            "15.044478416442871\n",
            "Epoch #0. Batch Id 268 is having validation accuracy of 25.174256505576206\n",
            "Epoch #0. Batch Id 269 is having validation loss of 3553.484619140625\n",
            "23.529203414916992\n",
            "Epoch #0. Batch Id 269 is having validation accuracy of 25.185185185185187\n",
            "Epoch #0. Batch Id 270 is having validation loss of 3540.77099609375\n",
            "108.06258392333984\n",
            "Epoch #0. Batch Id 270 is having validation accuracy of 25.21909594095941\n",
            "Epoch #0. Batch Id 271 is having validation loss of 3527.86279296875\n",
            "29.718183517456055\n",
            "Epoch #0. Batch Id 271 is having validation accuracy of 25.252757352941178\n",
            "Epoch #0. Batch Id 272 is having validation loss of 3515.003662109375\n",
            "17.32484245300293\n",
            "Epoch #0. Batch Id 272 is having validation accuracy of 25.251831501831504\n",
            "Epoch #0. Batch Id 273 is having validation loss of 3502.271484375\n",
            "26.374122619628906\n",
            "Epoch #0. Batch Id 273 is having validation accuracy of 25.31934306569343\n",
            "Epoch #0. Batch Id 274 is having validation loss of 3489.581787109375\n",
            "12.61487102508545\n",
            "Epoch #0. Batch Id 274 is having validation accuracy of 25.397727272727273\n",
            "Epoch #0. Batch Id 275 is having validation loss of 3478.55322265625\n",
            "445.7135925292969\n",
            "Epoch #0. Batch Id 275 is having validation accuracy of 25.38496376811594\n",
            "Epoch #0. Batch Id 276 is having validation loss of 3466.060546875\n",
            "18.05421257019043\n",
            "Epoch #0. Batch Id 276 is having validation accuracy of 25.49638989169675\n",
            "Epoch #0. Batch Id 277 is having validation loss of 3453.66015625\n",
            "18.760040283203125\n",
            "Epoch #0. Batch Id 277 is having validation accuracy of 25.472122302158272\n",
            "Epoch #0. Batch Id 278 is having validation loss of 3442.921630859375\n",
            "457.5901794433594\n",
            "Epoch #0. Batch Id 278 is having validation accuracy of 25.49283154121864\n",
            "Epoch #0. Batch Id 279 is having validation loss of 3430.680908203125\n",
            "15.523103713989258\n",
            "Epoch #0. Batch Id 279 is having validation accuracy of 25.502232142857142\n",
            "Epoch #0. Batch Id 280 is having validation loss of 3418.52685546875\n",
            "15.388400077819824\n",
            "Epoch #0. Batch Id 280 is having validation accuracy of 25.56717081850534\n",
            "Epoch #0. Batch Id 281 is having validation loss of 3407.3779296875\n",
            "274.5235290527344\n",
            "Epoch #0. Batch Id 281 is having validation accuracy of 25.554078014184398\n",
            "Epoch #0. Batch Id 282 is having validation loss of 3395.44970703125\n",
            "31.705778121948242\n",
            "Epoch #0. Batch Id 282 is having validation accuracy of 25.56316254416961\n",
            "Epoch #0. Batch Id 283 is having validation loss of 3383.597412109375\n",
            "29.394222259521484\n",
            "Epoch #0. Batch Id 283 is having validation accuracy of 25.605193661971832\n",
            "Epoch #0. Batch Id 284 is having validation loss of 3371.822021484375\n",
            "27.61817169189453\n",
            "Epoch #0. Batch Id 284 is having validation accuracy of 25.603070175438596\n",
            "Epoch #0. Batch Id 285 is having validation loss of 3360.075927734375\n",
            "12.462811470031738\n",
            "Epoch #0. Batch Id 285 is having validation accuracy of 25.655594405594407\n",
            "Epoch #0. Batch Id 286 is having validation loss of 3348.48681640625\n",
            "34.011966705322266\n",
            "Epoch #0. Batch Id 286 is having validation accuracy of 25.653310104529616\n",
            "Epoch #0. Batch Id 287 is having validation loss of 3336.97802734375\n",
            "33.95174789428711\n",
            "Epoch #0. Batch Id 287 is having validation accuracy of 25.694444444444443\n",
            "Epoch #0. Batch Id 288 is having validation loss of 3330.826416015625\n",
            "1559.17529296875\n",
            "Epoch #0. Batch Id 288 is having validation accuracy of 25.72448096885813\n",
            "Epoch #0. Batch Id 289 is having validation loss of 3319.38671875\n",
            "13.296162605285645\n",
            "Epoch #0. Batch Id 289 is having validation accuracy of 25.81896551724138\n",
            "Epoch #0. Batch Id 290 is having validation loss of 3308.0556640625\n",
            "22.038686752319336\n",
            "Epoch #0. Batch Id 290 is having validation accuracy of 25.859106529209622\n",
            "Epoch #0. Batch Id 291 is having validation loss of 3296.802490234375\n",
            "22.141260147094727\n",
            "Epoch #0. Batch Id 291 is having validation accuracy of 25.952482876712327\n",
            "Epoch #0. Batch Id 292 is having validation loss of 3285.595703125\n",
            "13.246650695800781\n",
            "Epoch #0. Batch Id 292 is having validation accuracy of 25.97056313993174\n",
            "Epoch #0. Batch Id 293 is having validation loss of 3274.483642578125\n",
            "18.62199592590332\n",
            "Epoch #0. Batch Id 293 is having validation accuracy of 26.009778911564627\n",
            "Epoch #0. Batch Id 294 is having validation loss of 3291.544677734375\n",
            "8307.4853515625\n",
            "Epoch #0. Batch Id 294 is having validation accuracy of 26.03813559322034\n",
            "Epoch #0. Batch Id 295 is having validation loss of 3280.5234375\n",
            "29.29254913330078\n",
            "Epoch #0. Batch Id 295 is having validation accuracy of 26.013513513513512\n",
            "Epoch #0. Batch Id 296 is having validation loss of 3274.24951171875\n",
            "1417.1396484375\n",
            "Epoch #0. Batch Id 296 is having validation accuracy of 26.020622895622896\n",
            "Epoch #0. Batch Id 297 is having validation loss of 3263.30810546875\n",
            "13.726310729980469\n",
            "Epoch #0. Batch Id 297 is having validation accuracy of 26.080117449664428\n",
            "Epoch #0. Batch Id 298 is having validation loss of 3252.42431640625\n",
            "9.044102668762207\n",
            "Epoch #0. Batch Id 298 is having validation accuracy of 26.139214046822744\n",
            "Epoch #0. Batch Id 299 is having validation loss of 3241.653076171875\n",
            "21.025774002075195\n",
            "Epoch #0. Batch Id 299 is having validation accuracy of 26.15625\n",
            "Epoch #0. Batch Id 300 is having validation loss of 3230.935791015625\n",
            "15.75847339630127\n",
            "Epoch #0. Batch Id 300 is having validation accuracy of 26.204318936877076\n",
            "Epoch #0. Batch Id 301 is having validation loss of 3243.24267578125\n",
            "6947.5966796875\n",
            "Epoch #0. Batch Id 301 is having validation accuracy of 26.18998344370861\n",
            "Epoch #0. Batch Id 302 is having validation loss of 3232.615966796875\n",
            "23.333555221557617\n",
            "Epoch #0. Batch Id 302 is having validation accuracy of 26.25825082508251\n",
            "Epoch #0. Batch Id 303 is having validation loss of 3222.114501953125\n",
            "40.17236328125\n",
            "Epoch #0. Batch Id 303 is having validation accuracy of 26.254111842105264\n",
            "Epoch #0. Batch Id 304 is having validation loss of 3211.60546875\n",
            "16.851428985595703\n",
            "Epoch #0. Batch Id 304 is having validation accuracy of 26.331967213114755\n",
            "Epoch #0. Batch Id 305 is having validation loss of 3201.2099609375\n",
            "30.555864334106445\n",
            "Epoch #0. Batch Id 305 is having validation accuracy of 26.36846405228758\n",
            "Epoch #0. Batch Id 306 is having validation loss of 3190.864013671875\n",
            "25.030370712280273\n",
            "Epoch #0. Batch Id 306 is having validation accuracy of 26.384364820846905\n",
            "Epoch #0. Batch Id 307 is having validation loss of 3180.640380859375\n",
            "41.98161315917969\n",
            "Epoch #0. Batch Id 307 is having validation accuracy of 26.349431818181817\n",
            "Epoch #0. Batch Id 308 is having validation loss of 3170.377197265625\n",
            "9.341954231262207\n",
            "Epoch #0. Batch Id 308 is having validation accuracy of 26.35517799352751\n",
            "Epoch #0. Batch Id 309 is having validation loss of 3160.203857421875\n",
            "16.655092239379883\n",
            "Epoch #0. Batch Id 309 is having validation accuracy of 26.320564516129032\n",
            "Epoch #0. Batch Id 310 is having validation loss of 3150.091064453125\n",
            "15.1123628616333\n",
            "Epoch #0. Batch Id 310 is having validation accuracy of 26.326366559485532\n",
            "Epoch #0. Batch Id 311 is having validation loss of 3140.09521484375\n",
            "31.365283966064453\n",
            "Epoch #0. Batch Id 311 is having validation accuracy of 26.362179487179485\n",
            "Epoch #0. Batch Id 312 is having validation loss of 3130.119384765625\n",
            "17.65214729309082\n",
            "Epoch #0. Batch Id 312 is having validation accuracy of 26.407747603833865\n",
            "Epoch #0. Batch Id 313 is having validation loss of 3120.236083984375\n",
            "26.77059555053711\n",
            "Epoch #0. Batch Id 313 is having validation accuracy of 26.43312101910828\n",
            "Epoch #0. Batch Id 314 is having validation loss of 3110.52734375\n",
            "61.96918869018555\n",
            "Epoch #0. Batch Id 314 is having validation accuracy of 26.438492063492063\n",
            "Epoch #0. Batch Id 315 is having validation loss of 3100.708984375\n",
            "7.955882549285889\n",
            "Epoch #0. Batch Id 315 is having validation accuracy of 26.483386075949365\n",
            "Epoch #0. Batch Id 316 is having validation loss of 3091.028076171875\n",
            "31.85373306274414\n",
            "Epoch #0. Batch Id 316 is having validation accuracy of 26.478706624605678\n",
            "Epoch #0. Batch Id 317 is having validation loss of 3081.369873046875\n",
            "19.734455108642578\n",
            "Epoch #0. Batch Id 317 is having validation accuracy of 26.45440251572327\n",
            "Epoch #0. Batch Id 318 is having validation loss of 3071.839599609375\n",
            "41.23832321166992\n",
            "Epoch #0. Batch Id 318 is having validation accuracy of 26.41065830721003\n",
            "Epoch #0. Batch Id 319 is having validation loss of 3062.3662109375\n",
            "40.372291564941406\n",
            "Epoch #0. Batch Id 319 is having validation accuracy of 26.416015625\n",
            "Epoch #0. Batch Id 320 is having validation loss of 3052.854248046875\n",
            "8.988439559936523\n",
            "Epoch #0. Batch Id 320 is having validation accuracy of 26.4797507788162\n",
            "Epoch #0. Batch Id 321 is having validation loss of 3043.443359375\n",
            "22.57725715637207\n",
            "Epoch #0. Batch Id 321 is having validation accuracy of 26.475155279503106\n",
            "Epoch #0. Batch Id 322 is having validation loss of 3051.311279296875\n",
            "5584.7724609375\n",
            "Epoch #0. Batch Id 322 is having validation accuracy of 26.58668730650155\n",
            "Epoch #0. Batch Id 323 is having validation loss of 3078.19091796875\n",
            "11760.333984375\n",
            "Epoch #0. Batch Id 323 is having validation accuracy of 26.630015432098766\n",
            "Epoch #0. Batch Id 324 is having validation loss of 3068.777099609375\n",
            "18.717275619506836\n",
            "Epoch #0. Batch Id 324 is having validation accuracy of 26.64423076923077\n",
            "Epoch #0. Batch Id 325 is having validation loss of 3059.46826171875\n",
            "34.05794906616211\n",
            "Epoch #0. Batch Id 325 is having validation accuracy of 26.658358895705522\n",
            "Epoch #0. Batch Id 326 is having validation loss of 3050.187255859375\n",
            "24.56093406677246\n",
            "Epoch #0. Batch Id 326 is having validation accuracy of 26.634174311926607\n",
            "Epoch #0. Batch Id 327 is having validation loss of 3040.93017578125\n",
            "13.904363632202148\n",
            "Epoch #0. Batch Id 327 is having validation accuracy of 26.705411585365855\n",
            "Epoch #0. Batch Id 328 is having validation loss of 3031.77685546875\n",
            "29.486881256103516\n",
            "Epoch #0. Batch Id 328 is having validation accuracy of 26.757218844984802\n",
            "Epoch #0. Batch Id 329 is having validation loss of 3032.514892578125\n",
            "3275.296142578125\n",
            "Epoch #0. Batch Id 329 is having validation accuracy of 26.818181818181817\n",
            "Epoch #0. Batch Id 330 is having validation loss of 3023.4404296875\n",
            "28.855876922607422\n",
            "Epoch #0. Batch Id 330 is having validation accuracy of 26.812688821752264\n",
            "Epoch #0. Batch Id 331 is having validation loss of 3014.403564453125\n",
            "23.22784423828125\n",
            "Epoch #0. Batch Id 331 is having validation accuracy of 26.82605421686747\n",
            "Epoch #0. Batch Id 332 is having validation loss of 3005.8603515625\n",
            "169.4844512939453\n",
            "Epoch #0. Batch Id 332 is having validation accuracy of 26.82057057057057\n",
            "Epoch #0. Batch Id 333 is having validation loss of 2996.892822265625\n",
            "10.745246887207031\n",
            "Epoch #0. Batch Id 333 is having validation accuracy of 26.88997005988024\n",
            "Epoch #0. Batch Id 334 is having validation loss of 2988.325439453125\n",
            "126.7891616821289\n",
            "Epoch #0. Batch Id 334 is having validation accuracy of 26.884328358208954\n",
            "Epoch #0. Batch Id 335 is having validation loss of 3015.2216796875\n",
            "12025.4609375\n",
            "Epoch #0. Batch Id 335 is having validation accuracy of 26.869419642857142\n",
            "Epoch #0. Batch Id 336 is having validation loss of 3006.31884765625\n",
            "14.954545021057129\n",
            "Epoch #0. Batch Id 336 is having validation accuracy of 26.86387240356083\n",
            "Epoch #0. Batch Id 337 is having validation loss of 2997.475830078125\n",
            "17.38006591796875\n",
            "Epoch #0. Batch Id 337 is having validation accuracy of 26.913831360946745\n",
            "Epoch #0. Batch Id 338 is having validation loss of 2996.1923828125\n",
            "2562.418701171875\n",
            "Epoch #0. Batch Id 338 is having validation accuracy of 26.889749262536874\n",
            "Epoch #0. Batch Id 339 is having validation loss of 2987.444091796875\n",
            "21.739063262939453\n",
            "Epoch #0. Batch Id 339 is having validation accuracy of 26.920955882352942\n",
            "Epoch #0. Batch Id 340 is having validation loss of 2978.71337890625\n",
            "10.280862808227539\n",
            "Epoch #0. Batch Id 340 is having validation accuracy of 26.97030791788856\n",
            "Epoch #0. Batch Id 341 is having validation loss of 2975.06640625\n",
            "1731.413330078125\n",
            "Epoch #0. Batch Id 341 is having validation accuracy of 26.982821637426902\n",
            "Epoch #0. Batch Id 342 is having validation loss of 2966.47509765625\n",
            "28.24238395690918\n",
            "Epoch #0. Batch Id 342 is having validation accuracy of 26.991231275118743\n",
            "Эпоха #0 train_loss: 0.007972109131515026, val_loss: 0.2709604799747467\n",
            "Потрачено 14.2 минут на 0 эпоху\n",
            "Batch Id 0 is having training loss of 856.871337890625\n",
            "856.871337890625\n",
            "Epoch #1. Accuracy on batch 0 on Training is 37.5\n",
            "Epoch #1. Accuracy on batch 1 on Training is 32.8125\n",
            "Epoch #1. Accuracy on batch 2 on Training is 33.333333333333336\n",
            "Epoch #1. Accuracy on batch 3 on Training is 31.25\n",
            "Epoch #1. Accuracy on batch 4 on Training is 31.25\n",
            "Epoch #1. Accuracy on batch 5 on Training is 31.770833333333332\n",
            "Epoch #1. Accuracy on batch 6 on Training is 32.589285714285715\n",
            "Epoch #1. Accuracy on batch 7 on Training is 31.25\n",
            "Epoch #1. Accuracy on batch 8 on Training is 33.68055555555556\n",
            "Epoch #1. Accuracy on batch 9 on Training is 33.4375\n",
            "Epoch #1. Accuracy on batch 10 on Training is 32.67045454545455\n",
            "Epoch #1. Accuracy on batch 11 on Training is 32.291666666666664\n",
            "Epoch #1. Accuracy on batch 12 on Training is 31.971153846153847\n",
            "Epoch #1. Accuracy on batch 13 on Training is 32.36607142857143\n",
            "Epoch #1. Accuracy on batch 14 on Training is 31.458333333333332\n",
            "Epoch #1. Accuracy on batch 15 on Training is 32.2265625\n",
            "Epoch #1. Accuracy on batch 16 on Training is 32.720588235294116\n",
            "Epoch #1. Accuracy on batch 17 on Training is 32.46527777777778\n",
            "Epoch #1. Accuracy on batch 18 on Training is 32.07236842105263\n",
            "Epoch #1. Accuracy on batch 19 on Training is 32.1875\n",
            "Batch Id 20 is having training loss of 2782.312255859375\n",
            "52839.51171875\n",
            "Epoch #1. Accuracy on batch 20 on Training is 31.547619047619047\n",
            "Epoch #1. Accuracy on batch 21 on Training is 31.960227272727273\n",
            "Epoch #1. Accuracy on batch 22 on Training is 31.52173913043478\n",
            "Epoch #1. Accuracy on batch 23 on Training is 31.510416666666668\n",
            "Epoch #1. Accuracy on batch 24 on Training is 31.5\n",
            "Epoch #1. Accuracy on batch 25 on Training is 30.76923076923077\n",
            "Epoch #1. Accuracy on batch 26 on Training is 29.97685185185185\n",
            "Epoch #1. Accuracy on batch 27 on Training is 30.245535714285715\n",
            "Epoch #1. Accuracy on batch 28 on Training is 30.280172413793103\n",
            "Epoch #1. Accuracy on batch 29 on Training is 30.416666666666668\n",
            "Epoch #1. Accuracy on batch 30 on Training is 30.342741935483872\n",
            "Epoch #1. Accuracy on batch 31 on Training is 30.17578125\n",
            "Epoch #1. Accuracy on batch 32 on Training is 30.208333333333332\n",
            "Epoch #1. Accuracy on batch 33 on Training is 30.238970588235293\n",
            "Epoch #1. Accuracy on batch 34 on Training is 30.267857142857142\n",
            "Epoch #1. Accuracy on batch 35 on Training is 30.381944444444443\n",
            "Epoch #1. Accuracy on batch 36 on Training is 30.489864864864863\n",
            "Epoch #1. Accuracy on batch 37 on Training is 30.838815789473685\n",
            "Epoch #1. Accuracy on batch 38 on Training is 30.689102564102566\n",
            "Epoch #1. Accuracy on batch 39 on Training is 31.09375\n",
            "Batch Id 40 is having training loss of 1541.3555908203125\n",
            "25.702363967895508\n",
            "Epoch #1. Accuracy on batch 40 on Training is 31.25\n",
            "Epoch #1. Accuracy on batch 41 on Training is 31.324404761904763\n",
            "Epoch #1. Accuracy on batch 42 on Training is 31.177325581395348\n",
            "Epoch #1. Accuracy on batch 43 on Training is 31.107954545454547\n",
            "Epoch #1. Accuracy on batch 44 on Training is 31.11111111111111\n",
            "Epoch #1. Accuracy on batch 45 on Training is 31.25\n",
            "Epoch #1. Accuracy on batch 46 on Training is 31.25\n",
            "Epoch #1. Accuracy on batch 47 on Training is 31.25\n",
            "Epoch #1. Accuracy on batch 48 on Training is 31.122448979591837\n",
            "Epoch #1. Accuracy on batch 49 on Training is 31.0\n",
            "Epoch #1. Accuracy on batch 50 on Training is 31.066176470588236\n",
            "Epoch #1. Accuracy on batch 51 on Training is 31.370192307692307\n",
            "Epoch #1. Accuracy on batch 52 on Training is 31.367924528301888\n",
            "Epoch #1. Accuracy on batch 53 on Training is 31.30787037037037\n",
            "Epoch #1. Accuracy on batch 54 on Training is 31.53409090909091\n",
            "Epoch #1. Accuracy on batch 55 on Training is 31.529017857142858\n",
            "Epoch #1. Accuracy on batch 56 on Training is 31.853070175438596\n",
            "Epoch #1. Accuracy on batch 57 on Training is 31.68103448275862\n",
            "Epoch #1. Accuracy on batch 58 on Training is 31.408898305084747\n",
            "Epoch #1. Accuracy on batch 59 on Training is 31.40625\n",
            "Batch Id 60 is having training loss of 1989.6907958984375\n",
            "31.225341796875\n",
            "Epoch #1. Accuracy on batch 60 on Training is 31.403688524590162\n",
            "Epoch #1. Accuracy on batch 61 on Training is 31.350806451612904\n",
            "Epoch #1. Accuracy on batch 62 on Training is 31.25\n",
            "Epoch #1. Accuracy on batch 63 on Training is 31.298828125\n",
            "Epoch #1. Accuracy on batch 64 on Training is 31.153846153846153\n",
            "Epoch #1. Accuracy on batch 65 on Training is 31.013257575757574\n",
            "Epoch #1. Accuracy on batch 66 on Training is 31.063432835820894\n",
            "Epoch #1. Accuracy on batch 67 on Training is 31.295955882352942\n",
            "Epoch #1. Accuracy on batch 68 on Training is 31.295289855072465\n",
            "Epoch #1. Accuracy on batch 69 on Training is 31.116071428571427\n",
            "Epoch #1. Accuracy on batch 70 on Training is 31.338028169014084\n",
            "Epoch #1. Accuracy on batch 71 on Training is 31.336805555555557\n",
            "Epoch #1. Accuracy on batch 72 on Training is 31.421232876712327\n",
            "Epoch #1. Accuracy on batch 73 on Training is 31.29222972972973\n",
            "Epoch #1. Accuracy on batch 74 on Training is 31.166666666666668\n",
            "Epoch #1. Accuracy on batch 75 on Training is 31.044407894736842\n",
            "Epoch #1. Accuracy on batch 76 on Training is 30.844155844155843\n",
            "Epoch #1. Accuracy on batch 77 on Training is 30.849358974358974\n",
            "Epoch #1. Accuracy on batch 78 on Training is 30.656645569620252\n",
            "Epoch #1. Accuracy on batch 79 on Training is 30.625\n",
            "Batch Id 80 is having training loss of 2653.671630859375\n",
            "32.51247787475586\n",
            "Epoch #1. Accuracy on batch 80 on Training is 30.632716049382715\n",
            "Epoch #1. Accuracy on batch 81 on Training is 30.716463414634145\n",
            "Epoch #1. Accuracy on batch 82 on Training is 30.72289156626506\n",
            "Epoch #1. Accuracy on batch 83 on Training is 30.729166666666668\n",
            "Epoch #1. Accuracy on batch 84 on Training is 30.772058823529413\n",
            "Epoch #1. Accuracy on batch 85 on Training is 30.77761627906977\n",
            "Epoch #1. Accuracy on batch 86 on Training is 30.74712643678161\n",
            "Epoch #1. Accuracy on batch 87 on Training is 30.681818181818183\n",
            "Epoch #1. Accuracy on batch 88 on Training is 30.582865168539325\n",
            "Epoch #1. Accuracy on batch 89 on Training is 30.45138888888889\n",
            "Epoch #1. Accuracy on batch 90 on Training is 30.59752747252747\n",
            "Epoch #1. Accuracy on batch 91 on Training is 30.60461956521739\n",
            "Epoch #1. Accuracy on batch 92 on Training is 30.577956989247312\n",
            "Epoch #1. Accuracy on batch 93 on Training is 30.65159574468085\n",
            "Epoch #1. Accuracy on batch 94 on Training is 30.789473684210527\n",
            "Epoch #1. Accuracy on batch 95 on Training is 31.022135416666668\n",
            "Epoch #1. Accuracy on batch 96 on Training is 31.088917525773194\n",
            "Epoch #1. Accuracy on batch 97 on Training is 31.058673469387756\n",
            "Epoch #1. Accuracy on batch 98 on Training is 31.123737373737374\n",
            "Epoch #1. Accuracy on batch 99 on Training is 31.15625\n",
            "Batch Id 100 is having training loss of 2370.070068359375\n",
            "22.069217681884766\n",
            "Epoch #1. Accuracy on batch 100 on Training is 31.219059405940595\n",
            "Epoch #1. Accuracy on batch 101 on Training is 31.341911764705884\n",
            "Epoch #1. Accuracy on batch 102 on Training is 31.25\n",
            "Epoch #1. Accuracy on batch 103 on Training is 31.189903846153847\n",
            "Epoch #1. Accuracy on batch 104 on Training is 31.30952380952381\n",
            "Epoch #1. Accuracy on batch 105 on Training is 31.308962264150942\n",
            "Epoch #1. Accuracy on batch 106 on Training is 31.36682242990654\n",
            "Epoch #1. Accuracy on batch 107 on Training is 31.394675925925927\n",
            "Epoch #1. Accuracy on batch 108 on Training is 31.39334862385321\n",
            "Epoch #1. Accuracy on batch 109 on Training is 31.5625\n",
            "Epoch #1. Accuracy on batch 110 on Training is 31.58783783783784\n",
            "Epoch #1. Accuracy on batch 111 on Training is 31.640625\n",
            "Epoch #1. Accuracy on batch 112 on Training is 31.581858407079647\n",
            "Epoch #1. Accuracy on batch 113 on Training is 31.716008771929825\n",
            "Epoch #1. Accuracy on batch 114 on Training is 31.71195652173913\n",
            "Epoch #1. Accuracy on batch 115 on Training is 31.60021551724138\n",
            "Epoch #1. Accuracy on batch 116 on Training is 31.517094017094017\n",
            "Epoch #1. Accuracy on batch 117 on Training is 31.408898305084747\n",
            "Epoch #1. Accuracy on batch 118 on Training is 31.460084033613445\n",
            "Epoch #1. Accuracy on batch 119 on Training is 31.484375\n",
            "Batch Id 120 is having training loss of 2803.56494140625\n",
            "2061.736328125\n",
            "Epoch #1. Accuracy on batch 120 on Training is 31.430785123966942\n",
            "Epoch #1. Accuracy on batch 121 on Training is 31.429303278688526\n",
            "Epoch #1. Accuracy on batch 122 on Training is 31.478658536585368\n",
            "Epoch #1. Accuracy on batch 123 on Training is 31.476814516129032\n",
            "Epoch #1. Accuracy on batch 124 on Training is 31.575\n",
            "Epoch #1. Accuracy on batch 125 on Training is 31.547619047619047\n",
            "Epoch #1. Accuracy on batch 126 on Training is 31.42224409448819\n",
            "Epoch #1. Accuracy on batch 127 on Training is 31.4208984375\n",
            "Epoch #1. Accuracy on batch 128 on Training is 31.4437984496124\n",
            "Epoch #1. Accuracy on batch 129 on Training is 31.370192307692307\n",
            "Epoch #1. Accuracy on batch 130 on Training is 31.22614503816794\n",
            "Epoch #1. Accuracy on batch 131 on Training is 31.202651515151516\n",
            "Epoch #1. Accuracy on batch 132 on Training is 31.273496240601503\n",
            "Epoch #1. Accuracy on batch 133 on Training is 31.36660447761194\n",
            "Epoch #1. Accuracy on batch 134 on Training is 31.296296296296298\n",
            "Epoch #1. Accuracy on batch 135 on Training is 31.341911764705884\n",
            "Epoch #1. Accuracy on batch 136 on Training is 31.2728102189781\n",
            "Epoch #1. Accuracy on batch 137 on Training is 31.408514492753625\n",
            "Epoch #1. Accuracy on batch 138 on Training is 31.452338129496404\n",
            "Epoch #1. Accuracy on batch 139 on Training is 31.339285714285715\n",
            "Batch Id 140 is having training loss of 2813.9541015625\n",
            "51973.58984375\n",
            "Epoch #1. Accuracy on batch 140 on Training is 31.20567375886525\n",
            "Epoch #1. Accuracy on batch 141 on Training is 31.161971830985916\n",
            "Epoch #1. Accuracy on batch 142 on Training is 31.11888111888112\n",
            "Epoch #1. Accuracy on batch 143 on Training is 31.07638888888889\n",
            "Epoch #1. Accuracy on batch 144 on Training is 31.05603448275862\n",
            "Epoch #1. Accuracy on batch 145 on Training is 31.035958904109588\n",
            "Epoch #1. Accuracy on batch 146 on Training is 31.037414965986393\n",
            "Epoch #1. Accuracy on batch 147 on Training is 31.017736486486488\n",
            "Epoch #1. Accuracy on batch 148 on Training is 31.08221476510067\n",
            "Epoch #1. Accuracy on batch 149 on Training is 31.083333333333332\n",
            "Epoch #1. Accuracy on batch 150 on Training is 30.960264900662253\n",
            "Epoch #1. Accuracy on batch 151 on Training is 31.00328947368421\n",
            "Epoch #1. Accuracy on batch 152 on Training is 31.10702614379085\n",
            "Epoch #1. Accuracy on batch 153 on Training is 31.087662337662337\n",
            "Epoch #1. Accuracy on batch 154 on Training is 31.048387096774192\n",
            "Epoch #1. Accuracy on batch 155 on Training is 31.009615384615383\n",
            "Epoch #1. Accuracy on batch 156 on Training is 30.971337579617835\n",
            "Epoch #1. Accuracy on batch 157 on Training is 30.854430379746834\n",
            "Epoch #1. Accuracy on batch 158 on Training is 30.837264150943398\n",
            "Epoch #1. Accuracy on batch 159 on Training is 30.7421875\n",
            "Batch Id 160 is having training loss of 2699.982421875\n",
            "11309.5966796875\n",
            "Epoch #1. Accuracy on batch 160 on Training is 30.76475155279503\n",
            "Epoch #1. Accuracy on batch 161 on Training is 30.767746913580247\n",
            "Epoch #1. Accuracy on batch 162 on Training is 30.8090490797546\n",
            "Epoch #1. Accuracy on batch 163 on Training is 30.754573170731707\n",
            "Epoch #1. Accuracy on batch 164 on Training is 30.757575757575758\n",
            "Epoch #1. Accuracy on batch 165 on Training is 30.74171686746988\n",
            "Epoch #1. Accuracy on batch 166 on Training is 30.763473053892216\n",
            "Epoch #1. Accuracy on batch 167 on Training is 30.766369047619047\n",
            "Epoch #1. Accuracy on batch 168 on Training is 30.806213017751478\n",
            "Epoch #1. Accuracy on batch 169 on Training is 30.753676470588236\n",
            "Epoch #1. Accuracy on batch 170 on Training is 30.77485380116959\n",
            "Epoch #1. Accuracy on batch 171 on Training is 30.813953488372093\n",
            "Epoch #1. Accuracy on batch 172 on Training is 30.870664739884393\n",
            "Epoch #1. Accuracy on batch 173 on Training is 30.836925287356323\n",
            "Epoch #1. Accuracy on batch 174 on Training is 30.803571428571427\n",
            "Epoch #1. Accuracy on batch 175 on Training is 30.859375\n",
            "Epoch #1. Accuracy on batch 176 on Training is 30.87923728813559\n",
            "Epoch #1. Accuracy on batch 177 on Training is 30.84620786516854\n",
            "Epoch #1. Accuracy on batch 178 on Training is 30.81354748603352\n",
            "Epoch #1. Accuracy on batch 179 on Training is 30.78125\n",
            "Batch Id 180 is having training loss of 2409.6787109375\n",
            "32.809444427490234\n",
            "Epoch #1. Accuracy on batch 180 on Training is 30.766574585635357\n",
            "Epoch #1. Accuracy on batch 181 on Training is 30.837912087912088\n",
            "Epoch #1. Accuracy on batch 182 on Training is 30.87431693989071\n",
            "Epoch #1. Accuracy on batch 183 on Training is 30.910326086956523\n",
            "Epoch #1. Accuracy on batch 184 on Training is 30.945945945945947\n",
            "Epoch #1. Accuracy on batch 185 on Training is 30.913978494623656\n",
            "Epoch #1. Accuracy on batch 186 on Training is 30.915775401069517\n",
            "Epoch #1. Accuracy on batch 187 on Training is 30.8843085106383\n",
            "Epoch #1. Accuracy on batch 188 on Training is 30.853174603174605\n",
            "Epoch #1. Accuracy on batch 189 on Training is 30.838815789473685\n",
            "Epoch #1. Accuracy on batch 190 on Training is 30.840968586387433\n",
            "Epoch #1. Accuracy on batch 191 on Training is 30.908203125\n",
            "Epoch #1. Accuracy on batch 192 on Training is 30.958549222797927\n",
            "Epoch #1. Accuracy on batch 193 on Training is 30.94394329896907\n",
            "Epoch #1. Accuracy on batch 194 on Training is 31.009615384615383\n",
            "Epoch #1. Accuracy on batch 195 on Training is 31.058673469387756\n",
            "Epoch #1. Accuracy on batch 196 on Training is 30.98032994923858\n",
            "Epoch #1. Accuracy on batch 197 on Training is 31.029040404040405\n",
            "Epoch #1. Accuracy on batch 198 on Training is 30.951633165829147\n",
            "Epoch #1. Accuracy on batch 199 on Training is 30.96875\n",
            "Batch Id 200 is having training loss of 2222.15283203125\n",
            "22.378440856933594\n",
            "Epoch #1. Accuracy on batch 200 on Training is 30.954601990049753\n",
            "Epoch #1. Accuracy on batch 201 on Training is 30.909653465346533\n",
            "Epoch #1. Accuracy on batch 202 on Training is 30.803571428571427\n",
            "Epoch #1. Accuracy on batch 203 on Training is 30.775122549019606\n",
            "Epoch #1. Accuracy on batch 204 on Training is 30.777439024390244\n",
            "Epoch #1. Accuracy on batch 205 on Training is 30.79490291262136\n",
            "Epoch #1. Accuracy on batch 206 on Training is 30.857487922705314\n",
            "Epoch #1. Accuracy on batch 207 on Training is 30.84435096153846\n",
            "Epoch #1. Accuracy on batch 208 on Training is 30.876196172248804\n",
            "Epoch #1. Accuracy on batch 209 on Training is 30.848214285714285\n",
            "Epoch #1. Accuracy on batch 210 on Training is 30.790876777251185\n",
            "Epoch #1. Accuracy on batch 211 on Training is 30.79304245283019\n",
            "Epoch #1. Accuracy on batch 212 on Training is 30.780516431924884\n",
            "Epoch #1. Accuracy on batch 213 on Training is 30.768107476635514\n",
            "Epoch #1. Accuracy on batch 214 on Training is 30.74127906976744\n",
            "Epoch #1. Accuracy on batch 215 on Training is 30.787037037037038\n",
            "Epoch #1. Accuracy on batch 216 on Training is 30.774769585253456\n",
            "Epoch #1. Accuracy on batch 217 on Training is 30.73394495412844\n",
            "Epoch #1. Accuracy on batch 218 on Training is 30.750570776255707\n",
            "Epoch #1. Accuracy on batch 219 on Training is 30.710227272727273\n",
            "Batch Id 220 is having training loss of 2031.294677734375\n",
            "28.518152236938477\n",
            "Epoch #1. Accuracy on batch 220 on Training is 30.68438914027149\n",
            "Epoch #1. Accuracy on batch 221 on Training is 30.729166666666668\n",
            "Epoch #1. Accuracy on batch 222 on Training is 30.633408071748878\n",
            "Epoch #1. Accuracy on batch 223 on Training is 30.622209821428573\n",
            "Epoch #1. Accuracy on batch 224 on Training is 30.583333333333332\n",
            "Epoch #1. Accuracy on batch 225 on Training is 30.613938053097346\n",
            "Epoch #1. Accuracy on batch 226 on Training is 30.57544052863436\n",
            "Epoch #1. Accuracy on batch 227 on Training is 30.50986842105263\n",
            "Epoch #1. Accuracy on batch 228 on Training is 30.52674672489083\n",
            "Epoch #1. Accuracy on batch 229 on Training is 30.529891304347824\n",
            "Epoch #1. Accuracy on batch 230 on Training is 30.533008658008658\n",
            "Epoch #1. Accuracy on batch 231 on Training is 30.536099137931036\n",
            "Epoch #1. Accuracy on batch 232 on Training is 30.472103004291846\n",
            "Epoch #1. Accuracy on batch 233 on Training is 30.48878205128205\n",
            "Epoch #1. Accuracy on batch 234 on Training is 30.492021276595743\n",
            "Epoch #1. Accuracy on batch 235 on Training is 30.534957627118644\n",
            "Epoch #1. Accuracy on batch 236 on Training is 30.564345991561183\n",
            "Epoch #1. Accuracy on batch 237 on Training is 30.488445378151262\n",
            "Epoch #1. Accuracy on batch 238 on Training is 30.50470711297071\n",
            "Epoch #1. Accuracy on batch 239 on Training is 30.46875\n",
            "Batch Id 240 is having training loss of 2272.539794921875\n",
            "14.829829216003418\n",
            "Epoch #1. Accuracy on batch 240 on Training is 30.446058091286307\n",
            "Epoch #1. Accuracy on batch 241 on Training is 30.462293388429753\n",
            "Epoch #1. Accuracy on batch 242 on Training is 30.465534979423868\n",
            "Epoch #1. Accuracy on batch 243 on Training is 30.48155737704918\n",
            "Epoch #1. Accuracy on batch 244 on Training is 30.471938775510203\n",
            "Epoch #1. Accuracy on batch 245 on Training is 30.44969512195122\n",
            "Epoch #1. Accuracy on batch 246 on Training is 30.452935222672064\n",
            "Epoch #1. Accuracy on batch 247 on Training is 30.443548387096776\n",
            "Epoch #1. Accuracy on batch 248 on Training is 30.446787148594378\n",
            "Epoch #1. Accuracy on batch 249 on Training is 30.4375\n",
            "Epoch #1. Accuracy on batch 250 on Training is 30.366035856573706\n",
            "Epoch #1. Accuracy on batch 251 on Training is 30.40674603174603\n",
            "Epoch #1. Accuracy on batch 252 on Training is 30.447134387351777\n",
            "Epoch #1. Accuracy on batch 253 on Training is 30.499507874015748\n",
            "Epoch #1. Accuracy on batch 254 on Training is 30.465686274509803\n",
            "Epoch #1. Accuracy on batch 255 on Training is 30.43212890625\n",
            "Epoch #1. Accuracy on batch 256 on Training is 30.496108949416342\n",
            "Epoch #1. Accuracy on batch 257 on Training is 30.511143410852714\n",
            "Epoch #1. Accuracy on batch 258 on Training is 30.501930501930502\n",
            "Epoch #1. Accuracy on batch 259 on Training is 30.540865384615383\n",
            "Batch Id 260 is having training loss of 2165.340087890625\n",
            "34.985931396484375\n",
            "Epoch #1. Accuracy on batch 260 on Training is 30.543582375478927\n",
            "Epoch #1. Accuracy on batch 261 on Training is 30.55820610687023\n",
            "Epoch #1. Accuracy on batch 262 on Training is 30.56083650190114\n",
            "Epoch #1. Accuracy on batch 263 on Training is 30.56344696969697\n",
            "Epoch #1. Accuracy on batch 264 on Training is 30.577830188679247\n",
            "Epoch #1. Accuracy on batch 265 on Training is 30.592105263157894\n",
            "Epoch #1. Accuracy on batch 266 on Training is 30.594569288389515\n",
            "Epoch #1. Accuracy on batch 267 on Training is 30.620335820895523\n",
            "Epoch #1. Accuracy on batch 268 on Training is 30.599442379182157\n",
            "Epoch #1. Accuracy on batch 269 on Training is 30.636574074074073\n",
            "Epoch #1. Accuracy on batch 270 on Training is 30.673431734317344\n",
            "Epoch #1. Accuracy on batch 271 on Training is 30.595128676470587\n",
            "Epoch #1. Accuracy on batch 272 on Training is 30.620421245421245\n",
            "Epoch #1. Accuracy on batch 273 on Training is 30.634124087591243\n",
            "Epoch #1. Accuracy on batch 274 on Training is 30.602272727272727\n",
            "Epoch #1. Accuracy on batch 275 on Training is 30.570652173913043\n",
            "Epoch #1. Accuracy on batch 276 on Training is 30.584386281588447\n",
            "Epoch #1. Accuracy on batch 277 on Training is 30.586780575539567\n",
            "Epoch #1. Accuracy on batch 278 on Training is 30.58915770609319\n",
            "Epoch #1. Accuracy on batch 279 on Training is 30.613839285714285\n",
            "Batch Id 280 is having training loss of 2025.345458984375\n",
            "14.747146606445312\n",
            "Epoch #1. Accuracy on batch 280 on Training is 30.660587188612098\n",
            "Epoch #1. Accuracy on batch 281 on Training is 30.673758865248228\n",
            "Epoch #1. Accuracy on batch 282 on Training is 30.631625441696112\n",
            "Epoch #1. Accuracy on batch 283 on Training is 30.589788732394368\n",
            "Epoch #1. Accuracy on batch 284 on Training is 30.592105263157894\n",
            "Epoch #1. Accuracy on batch 285 on Training is 30.58347902097902\n",
            "Epoch #1. Accuracy on batch 286 on Training is 30.58580139372822\n",
            "Epoch #1. Accuracy on batch 287 on Training is 30.577256944444443\n",
            "Epoch #1. Accuracy on batch 288 on Training is 30.60121107266436\n",
            "Epoch #1. Accuracy on batch 289 on Training is 30.57112068965517\n",
            "Epoch #1. Accuracy on batch 290 on Training is 30.605670103092784\n",
            "Epoch #1. Accuracy on batch 291 on Training is 30.66138698630137\n",
            "Epoch #1. Accuracy on batch 292 on Training is 30.631399317406142\n",
            "Epoch #1. Accuracy on batch 293 on Training is 30.665391156462587\n",
            "Epoch #1. Accuracy on batch 294 on Training is 30.646186440677965\n",
            "Epoch #1. Accuracy on batch 295 on Training is 30.584881756756758\n",
            "Epoch #1. Accuracy on batch 296 on Training is 30.58712121212121\n",
            "Epoch #1. Accuracy on batch 297 on Training is 30.589345637583893\n",
            "Epoch #1. Accuracy on batch 298 on Training is 30.5497491638796\n",
            "Epoch #1. Accuracy on batch 299 on Training is 30.5625\n",
            "Batch Id 300 is having training loss of 1993.3433837890625\n",
            "38.452857971191406\n",
            "Epoch #1. Accuracy on batch 300 on Training is 30.627076411960132\n",
            "Epoch #1. Accuracy on batch 301 on Training is 30.691225165562916\n",
            "Epoch #1. Accuracy on batch 302 on Training is 30.682755775577558\n",
            "Epoch #1. Accuracy on batch 303 on Training is 30.694901315789473\n",
            "Epoch #1. Accuracy on batch 304 on Training is 30.686475409836067\n",
            "Epoch #1. Accuracy on batch 305 on Training is 30.73937908496732\n",
            "Epoch #1. Accuracy on batch 306 on Training is 30.700325732899024\n",
            "Epoch #1. Accuracy on batch 307 on Training is 30.67167207792208\n",
            "Epoch #1. Accuracy on batch 308 on Training is 30.683656957928804\n",
            "Epoch #1. Accuracy on batch 309 on Training is 30.64516129032258\n",
            "Epoch #1. Accuracy on batch 310 on Training is 30.606913183279744\n",
            "Epoch #1. Accuracy on batch 311 on Training is 30.62900641025641\n",
            "Epoch #1. Accuracy on batch 312 on Training is 30.611022364217252\n",
            "Epoch #1. Accuracy on batch 313 on Training is 30.583200636942674\n",
            "Epoch #1. Accuracy on batch 314 on Training is 30.60515873015873\n",
            "Epoch #1. Accuracy on batch 315 on Training is 30.557753164556964\n",
            "Epoch #1. Accuracy on batch 316 on Training is 30.579652996845425\n",
            "Epoch #1. Accuracy on batch 317 on Training is 30.591588050314467\n",
            "Epoch #1. Accuracy on batch 318 on Training is 30.554467084639498\n",
            "Epoch #1. Accuracy on batch 319 on Training is 30.546875\n",
            "Batch Id 320 is having training loss of 1956.83740234375\n",
            "314.95831298828125\n",
            "Epoch #1. Accuracy on batch 320 on Training is 30.568535825545172\n",
            "Epoch #1. Accuracy on batch 321 on Training is 30.580357142857142\n",
            "Epoch #1. Accuracy on batch 322 on Training is 30.582430340557277\n",
            "Epoch #1. Accuracy on batch 323 on Training is 30.60378086419753\n",
            "Epoch #1. Accuracy on batch 324 on Training is 30.615384615384617\n",
            "Epoch #1. Accuracy on batch 325 on Training is 30.598159509202453\n",
            "Epoch #1. Accuracy on batch 326 on Training is 30.55237003058104\n",
            "Epoch #1. Accuracy on batch 327 on Training is 30.544969512195124\n",
            "Epoch #1. Accuracy on batch 328 on Training is 30.566109422492403\n",
            "Epoch #1. Accuracy on batch 329 on Training is 30.59659090909091\n",
            "Epoch #1. Accuracy on batch 330 on Training is 30.579682779456192\n",
            "Epoch #1. Accuracy on batch 331 on Training is 30.638177710843372\n",
            "Epoch #1. Accuracy on batch 332 on Training is 30.574324324324323\n",
            "Epoch #1. Accuracy on batch 333 on Training is 30.60441616766467\n",
            "Epoch #1. Accuracy on batch 334 on Training is 30.58768656716418\n",
            "Epoch #1. Accuracy on batch 335 on Training is 30.580357142857142\n",
            "Epoch #1. Accuracy on batch 336 on Training is 30.591617210682493\n",
            "Epoch #1. Accuracy on batch 337 on Training is 30.565828402366865\n",
            "Epoch #1. Accuracy on batch 338 on Training is 30.57706489675516\n",
            "Epoch #1. Accuracy on batch 339 on Training is 30.56985294117647\n",
            "Batch Id 340 is having training loss of 2057.447998046875\n",
            "16.351158142089844\n",
            "Epoch #1. Accuracy on batch 340 on Training is 30.599340175953078\n",
            "Epoch #1. Accuracy on batch 341 on Training is 30.60124269005848\n",
            "Epoch #1. Accuracy on batch 342 on Training is 30.58491253644315\n",
            "Epoch #1. Accuracy on batch 343 on Training is 30.559593023255815\n",
            "Epoch #1. Accuracy on batch 344 on Training is 30.543478260869566\n",
            "Epoch #1. Accuracy on batch 345 on Training is 30.563583815028903\n",
            "Epoch #1. Accuracy on batch 346 on Training is 30.56556195965418\n",
            "Epoch #1. Accuracy on batch 347 on Training is 30.549568965517242\n",
            "Epoch #1. Accuracy on batch 348 on Training is 30.55157593123209\n",
            "Epoch #1. Accuracy on batch 349 on Training is 30.517857142857142\n",
            "Epoch #1. Accuracy on batch 350 on Training is 30.502136752136753\n",
            "Epoch #1. Accuracy on batch 351 on Training is 30.486505681818183\n",
            "Epoch #1. Accuracy on batch 352 on Training is 30.453257790368273\n",
            "Epoch #1. Accuracy on batch 353 on Training is 30.437853107344633\n",
            "Epoch #1. Accuracy on batch 354 on Training is 30.440140845070424\n",
            "Epoch #1. Accuracy on batch 355 on Training is 30.44241573033708\n",
            "Epoch #1. Accuracy on batch 356 on Training is 30.44467787114846\n",
            "Epoch #1. Accuracy on batch 357 on Training is 30.446927374301676\n",
            "Epoch #1. Accuracy on batch 358 on Training is 30.457869080779943\n",
            "Epoch #1. Accuracy on batch 359 on Training is 30.460069444444443\n",
            "Batch Id 360 is having training loss of 2016.2884521484375\n",
            "30.672826766967773\n",
            "Epoch #1. Accuracy on batch 360 on Training is 30.410318559556785\n",
            "Epoch #1. Accuracy on batch 361 on Training is 30.43853591160221\n",
            "Epoch #1. Accuracy on batch 362 on Training is 30.397727272727273\n",
            "Epoch #1. Accuracy on batch 363 on Training is 30.41723901098901\n",
            "Epoch #1. Accuracy on batch 364 on Training is 30.402397260273972\n",
            "Epoch #1. Accuracy on batch 365 on Training is 30.413251366120218\n",
            "Epoch #1. Accuracy on batch 366 on Training is 30.44959128065395\n",
            "Epoch #1. Accuracy on batch 367 on Training is 30.426290760869566\n",
            "Epoch #1. Accuracy on batch 368 on Training is 30.445460704607047\n",
            "Epoch #1. Accuracy on batch 369 on Training is 30.43918918918919\n",
            "Epoch #1. Accuracy on batch 370 on Training is 30.390835579514825\n",
            "Epoch #1. Accuracy on batch 371 on Training is 30.393145161290324\n",
            "Epoch #1. Accuracy on batch 372 on Training is 30.353552278820377\n",
            "Epoch #1. Accuracy on batch 373 on Training is 30.3475935828877\n",
            "Epoch #1. Accuracy on batch 374 on Training is 30.366666666666667\n",
            "Epoch #1. Accuracy on batch 375 on Training is 30.38563829787234\n",
            "Epoch #1. Accuracy on batch 376 on Training is 30.371352785145888\n",
            "Epoch #1. Accuracy on batch 377 on Training is 30.43154761904762\n",
            "Epoch #1. Accuracy on batch 378 on Training is 30.474934036939313\n",
            "Epoch #1. Accuracy on batch 379 on Training is 30.460526315789473\n",
            "Batch Id 380 is having training loss of 1982.4559326171875\n",
            "15.976658821105957\n",
            "Epoch #1. Accuracy on batch 380 on Training is 30.454396325459317\n",
            "Epoch #1. Accuracy on batch 381 on Training is 30.44011780104712\n",
            "Epoch #1. Accuracy on batch 382 on Training is 30.450391644908617\n",
            "Epoch #1. Accuracy on batch 383 on Training is 30.4443359375\n",
            "Epoch #1. Accuracy on batch 384 on Training is 30.430194805194805\n",
            "Epoch #1. Accuracy on batch 385 on Training is 30.43231865284974\n",
            "Epoch #1. Accuracy on batch 386 on Training is 30.426356589147286\n",
            "Epoch #1. Accuracy on batch 387 on Training is 30.412371134020617\n",
            "Epoch #1. Accuracy on batch 388 on Training is 30.414524421593832\n",
            "Epoch #1. Accuracy on batch 389 on Training is 30.408653846153847\n",
            "Epoch #1. Accuracy on batch 390 on Training is 30.402813299232736\n",
            "Epoch #1. Accuracy on batch 391 on Training is 30.40497448979592\n",
            "Epoch #1. Accuracy on batch 392 on Training is 30.423027989821882\n",
            "Epoch #1. Accuracy on batch 393 on Training is 30.409263959390863\n",
            "Epoch #1. Accuracy on batch 394 on Training is 30.395569620253166\n",
            "Epoch #1. Accuracy on batch 395 on Training is 30.40561868686869\n",
            "Epoch #1. Accuracy on batch 396 on Training is 30.3683879093199\n",
            "Epoch #1. Accuracy on batch 397 on Training is 30.378454773869347\n",
            "Epoch #1. Accuracy on batch 398 on Training is 30.396303258145362\n",
            "Epoch #1. Accuracy on batch 399 on Training is 30.3359375\n",
            "Batch Id 400 is having training loss of 2136.501953125\n",
            "165.8726348876953\n",
            "Epoch #1. Accuracy on batch 400 on Training is 30.353802992518702\n",
            "Epoch #1. Accuracy on batch 401 on Training is 30.37157960199005\n",
            "Epoch #1. Accuracy on batch 402 on Training is 30.358250620347395\n",
            "Epoch #1. Accuracy on batch 403 on Training is 30.35272277227723\n",
            "Epoch #1. Accuracy on batch 404 on Training is 30.354938271604937\n",
            "Epoch #1. Accuracy on batch 405 on Training is 30.357142857142858\n",
            "Epoch #1. Accuracy on batch 406 on Training is 30.374692874692876\n",
            "Epoch #1. Accuracy on batch 407 on Training is 30.36917892156863\n",
            "Epoch #1. Accuracy on batch 408 on Training is 30.348410757946212\n",
            "Epoch #1. Accuracy on batch 409 on Training is 30.350609756097562\n",
            "Epoch #1. Accuracy on batch 410 on Training is 30.322384428223845\n",
            "Epoch #1. Accuracy on batch 411 on Training is 30.332220873786408\n",
            "Epoch #1. Accuracy on batch 412 on Training is 30.342009685230025\n",
            "Epoch #1. Accuracy on batch 413 on Training is 30.351751207729468\n",
            "Epoch #1. Accuracy on batch 414 on Training is 30.33132530120482\n",
            "Epoch #1. Accuracy on batch 415 on Training is 30.341045673076923\n",
            "Epoch #1. Accuracy on batch 416 on Training is 30.335731414868107\n",
            "Epoch #1. Accuracy on batch 417 on Training is 30.308014354066987\n",
            "Epoch #1. Accuracy on batch 418 on Training is 30.310262529832936\n",
            "Epoch #1. Accuracy on batch 419 on Training is 30.27529761904762\n",
            "Batch Id 420 is having training loss of 2172.732666015625\n",
            "12.843698501586914\n",
            "Epoch #1. Accuracy on batch 420 on Training is 30.299881235154395\n",
            "Epoch #1. Accuracy on batch 421 on Training is 30.33175355450237\n",
            "Epoch #1. Accuracy on batch 422 on Training is 30.333924349881798\n",
            "Epoch #1. Accuracy on batch 423 on Training is 30.35819575471698\n",
            "Epoch #1. Accuracy on batch 424 on Training is 30.375\n",
            "Epoch #1. Accuracy on batch 425 on Training is 30.355046948356808\n",
            "Epoch #1. Accuracy on batch 426 on Training is 30.335187353629976\n",
            "Epoch #1. Accuracy on batch 427 on Training is 30.366530373831775\n",
            "Epoch #1. Accuracy on batch 428 on Training is 30.332167832167833\n",
            "Epoch #1. Accuracy on batch 429 on Training is 30.35610465116279\n",
            "Epoch #1. Accuracy on batch 430 on Training is 30.32917633410673\n",
            "Epoch #1. Accuracy on batch 431 on Training is 30.324074074074073\n",
            "Epoch #1. Accuracy on batch 432 on Training is 30.297344110854503\n",
            "Epoch #1. Accuracy on batch 433 on Training is 30.306739631336406\n",
            "Epoch #1. Accuracy on batch 434 on Training is 30.272988505747126\n",
            "Epoch #1. Accuracy on batch 435 on Training is 30.260894495412845\n",
            "Epoch #1. Accuracy on batch 436 on Training is 30.270308924485125\n",
            "Epoch #1. Accuracy on batch 437 on Training is 30.201198630136986\n",
            "Epoch #1. Accuracy on batch 438 on Training is 30.18223234624146\n",
            "Epoch #1. Accuracy on batch 439 on Training is 30.170454545454547\n",
            "Batch Id 440 is having training loss of 2233.886474609375\n",
            "20.343807220458984\n",
            "Epoch #1. Accuracy on batch 440 on Training is 30.165816326530614\n",
            "Epoch #1. Accuracy on batch 441 on Training is 30.20361990950226\n",
            "Epoch #1. Accuracy on batch 442 on Training is 30.24125282167043\n",
            "Epoch #1. Accuracy on batch 443 on Training is 30.278716216216218\n",
            "Epoch #1. Accuracy on batch 444 on Training is 30.27387640449438\n",
            "Epoch #1. Accuracy on batch 445 on Training is 30.24803811659193\n",
            "Epoch #1. Accuracy on batch 446 on Training is 30.250279642058164\n",
            "Epoch #1. Accuracy on batch 447 on Training is 30.259486607142858\n",
            "Epoch #1. Accuracy on batch 448 on Training is 30.254732739420934\n",
            "Epoch #1. Accuracy on batch 449 on Training is 30.256944444444443\n",
            "Epoch #1. Accuracy on batch 450 on Training is 30.238359201773836\n",
            "Epoch #1. Accuracy on batch 451 on Training is 30.26825221238938\n",
            "Epoch #1. Accuracy on batch 452 on Training is 30.263520971302427\n",
            "Epoch #1. Accuracy on batch 453 on Training is 30.30011013215859\n",
            "Epoch #1. Accuracy on batch 454 on Training is 30.309065934065934\n",
            "Epoch #1. Accuracy on batch 455 on Training is 30.33168859649123\n",
            "Epoch #1. Accuracy on batch 456 on Training is 30.326859956236323\n",
            "Epoch #1. Accuracy on batch 457 on Training is 30.342521834061134\n",
            "Epoch #1. Accuracy on batch 458 on Training is 30.330882352941178\n",
            "Epoch #1. Accuracy on batch 459 on Training is 30.33288043478261\n",
            "Batch Id 460 is having training loss of 2141.1513671875\n",
            "67.42046356201172\n",
            "Epoch #1. Accuracy on batch 460 on Training is 30.314533622559654\n",
            "Epoch #1. Accuracy on batch 461 on Training is 30.33008658008658\n",
            "Epoch #1. Accuracy on batch 462 on Training is 30.33207343412527\n",
            "Epoch #1. Accuracy on batch 463 on Training is 30.334051724137932\n",
            "Epoch #1. Accuracy on batch 464 on Training is 30.288978494623656\n",
            "Epoch #1. Accuracy on batch 465 on Training is 30.317864806866954\n",
            "Epoch #1. Accuracy on batch 466 on Training is 30.266327623126337\n",
            "Epoch #1. Accuracy on batch 467 on Training is 30.235042735042736\n",
            "Epoch #1. Accuracy on batch 468 on Training is 30.243869936034116\n",
            "Epoch #1. Accuracy on batch 469 on Training is 30.252659574468087\n",
            "Epoch #1. Accuracy on batch 470 on Training is 30.26804670912951\n",
            "Epoch #1. Accuracy on batch 471 on Training is 30.27012711864407\n",
            "Epoch #1. Accuracy on batch 472 on Training is 30.28541226215645\n",
            "Epoch #1. Accuracy on batch 473 on Training is 30.280854430379748\n",
            "Epoch #1. Accuracy on batch 474 on Training is 30.289473684210527\n",
            "Epoch #1. Accuracy on batch 475 on Training is 30.291491596638654\n",
            "Epoch #1. Accuracy on batch 476 on Training is 30.267295597484278\n",
            "Epoch #1. Accuracy on batch 477 on Training is 30.269351464435147\n",
            "Epoch #1. Accuracy on batch 478 on Training is 30.284446764091857\n",
            "Epoch #1. Accuracy on batch 479 on Training is 30.29296875\n",
            "Batch Id 480 is having training loss of 2066.62841796875\n",
            "716.7262573242188\n",
            "Epoch #1. Accuracy on batch 480 on Training is 30.268970893970895\n",
            "Epoch #1. Accuracy on batch 481 on Training is 30.238589211618258\n",
            "Epoch #1. Accuracy on batch 482 on Training is 30.260093167701864\n",
            "Epoch #1. Accuracy on batch 483 on Training is 30.24922520661157\n",
            "Epoch #1. Accuracy on batch 484 on Training is 30.251288659793815\n",
            "Epoch #1. Accuracy on batch 485 on Training is 30.214763374485596\n",
            "Epoch #1. Accuracy on batch 486 on Training is 30.229722792607802\n",
            "Epoch #1. Accuracy on batch 487 on Training is 30.225409836065573\n",
            "Epoch #1. Accuracy on batch 488 on Training is 30.21472392638037\n",
            "Epoch #1. Accuracy on batch 489 on Training is 30.229591836734695\n",
            "Epoch #1. Accuracy on batch 490 on Training is 30.250763747454176\n",
            "Epoch #1. Accuracy on batch 491 on Training is 30.208333333333332\n",
            "Epoch #1. Accuracy on batch 492 on Training is 30.223123732251523\n",
            "Epoch #1. Accuracy on batch 493 on Training is 30.23152834008097\n",
            "Epoch #1. Accuracy on batch 494 on Training is 30.227272727272727\n",
            "Epoch #1. Accuracy on batch 495 on Training is 30.210433467741936\n",
            "Epoch #1. Accuracy on batch 496 on Training is 30.21252515090543\n",
            "Epoch #1. Accuracy on batch 497 on Training is 30.23343373493976\n",
            "Epoch #1. Accuracy on batch 498 on Training is 30.247995991983966\n",
            "Epoch #1. Accuracy on batch 499 on Training is 30.2375\n",
            "Batch Id 500 is having training loss of 1992.1427001953125\n",
            "22.765602111816406\n",
            "Epoch #1. Accuracy on batch 500 on Training is 30.23328343313373\n",
            "Epoch #1. Accuracy on batch 501 on Training is 30.25398406374502\n",
            "Epoch #1. Accuracy on batch 502 on Training is 30.26217693836978\n",
            "Epoch #1. Accuracy on batch 503 on Training is 30.25173611111111\n",
            "Epoch #1. Accuracy on batch 504 on Training is 30.253712871287128\n",
            "Epoch #1. Accuracy on batch 505 on Training is 30.261857707509883\n",
            "Epoch #1. Accuracy on batch 506 on Training is 30.232988165680474\n",
            "Epoch #1. Accuracy on batch 507 on Training is 30.228838582677167\n",
            "Epoch #1. Accuracy on batch 508 on Training is 30.206286836935167\n",
            "Epoch #1. Accuracy on batch 509 on Training is 30.232843137254903\n",
            "Epoch #1. Accuracy on batch 510 on Training is 30.198140900195696\n",
            "Epoch #1. Accuracy on batch 511 on Training is 30.17578125\n",
            "Epoch #1. Accuracy on batch 512 on Training is 30.17787524366472\n",
            "Epoch #1. Accuracy on batch 513 on Training is 30.192120622568094\n",
            "Epoch #1. Accuracy on batch 514 on Training is 30.200242718446603\n",
            "Epoch #1. Accuracy on batch 515 on Training is 30.19622093023256\n",
            "Epoch #1. Accuracy on batch 516 on Training is 30.204303675048354\n",
            "Epoch #1. Accuracy on batch 517 on Training is 30.248552123552123\n",
            "Epoch #1. Accuracy on batch 518 on Training is 30.27456647398844\n",
            "Epoch #1. Accuracy on batch 519 on Training is 30.25841346153846\n",
            "Batch Id 520 is having training loss of 2132.31591796875\n",
            "16.519384384155273\n",
            "Epoch #1. Accuracy on batch 520 on Training is 30.266314779270633\n",
            "Epoch #1. Accuracy on batch 521 on Training is 30.280172413793103\n",
            "Epoch #1. Accuracy on batch 522 on Training is 30.276051625239006\n",
            "Epoch #1. Accuracy on batch 523 on Training is 30.295801526717558\n",
            "Epoch #1. Accuracy on batch 524 on Training is 30.297619047619047\n",
            "Epoch #1. Accuracy on batch 525 on Training is 30.293488593155892\n",
            "Epoch #1. Accuracy on batch 526 on Training is 30.289373814041745\n",
            "Epoch #1. Accuracy on batch 527 on Training is 30.2734375\n",
            "Epoch #1. Accuracy on batch 528 on Training is 30.26937618147448\n",
            "Epoch #1. Accuracy on batch 529 on Training is 30.253537735849058\n",
            "Epoch #1. Accuracy on batch 530 on Training is 30.225988700564972\n",
            "Epoch #1. Accuracy on batch 531 on Training is 30.23966165413534\n",
            "Epoch #1. Accuracy on batch 532 on Training is 30.212242026266416\n",
            "Epoch #1. Accuracy on batch 533 on Training is 30.190777153558052\n",
            "Epoch #1. Accuracy on batch 534 on Training is 30.19859813084112\n",
            "Epoch #1. Accuracy on batch 535 on Training is 30.200559701492537\n",
            "Epoch #1. Accuracy on batch 536 on Training is 30.21415270018622\n",
            "Epoch #1. Accuracy on batch 537 on Training is 30.22188661710037\n",
            "Epoch #1. Accuracy on batch 538 on Training is 30.20640074211503\n",
            "Epoch #1. Accuracy on batch 539 on Training is 30.21990740740741\n",
            "Batch Id 540 is having training loss of 2122.85107421875\n",
            "9.213956832885742\n",
            "Epoch #1. Accuracy on batch 540 on Training is 30.233364140480592\n",
            "Epoch #1. Accuracy on batch 541 on Training is 30.229474169741696\n",
            "Epoch #1. Accuracy on batch 542 on Training is 30.214088397790054\n",
            "Epoch #1. Accuracy on batch 543 on Training is 30.204503676470587\n",
            "Epoch #1. Accuracy on batch 544 on Training is 30.200688073394495\n",
            "Epoch #1. Accuracy on batch 545 on Training is 30.208333333333332\n",
            "Epoch #1. Accuracy on batch 546 on Training is 30.210237659963436\n",
            "Epoch #1. Accuracy on batch 547 on Training is 30.2007299270073\n",
            "Epoch #1. Accuracy on batch 548 on Training is 30.20264116575592\n",
            "Epoch #1. Accuracy on batch 549 on Training is 30.227272727272727\n",
            "Epoch #1. Accuracy on batch 550 on Training is 30.20644283121597\n",
            "Epoch #1. Accuracy on batch 551 on Training is 30.230978260869566\n",
            "Epoch #1. Accuracy on batch 552 on Training is 30.232820976491862\n",
            "Epoch #1. Accuracy on batch 553 on Training is 30.23465703971119\n",
            "Epoch #1. Accuracy on batch 554 on Training is 30.230855855855857\n",
            "Epoch #1. Accuracy on batch 555 on Training is 30.232688848920862\n",
            "Epoch #1. Accuracy on batch 556 on Training is 30.212073608617594\n",
            "Epoch #1. Accuracy on batch 557 on Training is 30.225134408602152\n",
            "Epoch #1. Accuracy on batch 558 on Training is 30.226967799642217\n",
            "Epoch #1. Accuracy on batch 559 on Training is 30.200892857142858\n",
            "Batch Id 560 is having training loss of 2140.5078125\n",
            "22.451818466186523\n",
            "Epoch #1. Accuracy on batch 560 on Training is 30.20276292335116\n",
            "Epoch #1. Accuracy on batch 561 on Training is 30.210186832740213\n",
            "Epoch #1. Accuracy on batch 562 on Training is 30.223134991119004\n",
            "Epoch #1. Accuracy on batch 563 on Training is 30.21941489361702\n",
            "Epoch #1. Accuracy on batch 564 on Training is 30.221238938053098\n",
            "Epoch #1. Accuracy on batch 565 on Training is 30.223056537102472\n",
            "Epoch #1. Accuracy on batch 566 on Training is 30.21384479717813\n",
            "Epoch #1. Accuracy on batch 567 on Training is 30.210167253521128\n",
            "Epoch #1. Accuracy on batch 568 on Training is 30.206502636203865\n",
            "Epoch #1. Accuracy on batch 569 on Training is 30.208333333333332\n",
            "Epoch #1. Accuracy on batch 570 on Training is 30.232049036777582\n",
            "Epoch #1. Accuracy on batch 571 on Training is 30.25021853146853\n",
            "Epoch #1. Accuracy on batch 572 on Training is 30.262870855148343\n",
            "Epoch #1. Accuracy on batch 573 on Training is 30.248257839721255\n",
            "Epoch #1. Accuracy on batch 574 on Training is 30.255434782608695\n",
            "Epoch #1. Accuracy on batch 575 on Training is 30.26801215277778\n",
            "Epoch #1. Accuracy on batch 576 on Training is 30.253466204506065\n",
            "Epoch #1. Accuracy on batch 577 on Training is 30.282223183391004\n",
            "Epoch #1. Accuracy on batch 578 on Training is 30.283894645941277\n",
            "Epoch #1. Accuracy on batch 579 on Training is 30.290948275862068\n",
            "Batch Id 580 is having training loss of 2068.56103515625\n",
            "15.469878196716309\n",
            "Epoch #1. Accuracy on batch 580 on Training is 30.297977624784853\n",
            "Epoch #1. Accuracy on batch 581 on Training is 30.288874570446737\n",
            "Epoch #1. Accuracy on batch 582 on Training is 30.274442538593483\n",
            "Epoch #1. Accuracy on batch 583 on Training is 30.249357876712327\n",
            "Epoch #1. Accuracy on batch 584 on Training is 30.251068376068375\n",
            "Epoch #1. Accuracy on batch 585 on Training is 30.247440273037544\n",
            "Epoch #1. Accuracy on batch 586 on Training is 30.24914821124361\n",
            "Epoch #1. Accuracy on batch 587 on Training is 30.261479591836736\n",
            "Epoch #1. Accuracy on batch 588 on Training is 30.27376910016978\n",
            "Epoch #1. Accuracy on batch 589 on Training is 30.27542372881356\n",
            "Epoch #1. Accuracy on batch 590 on Training is 30.26120981387479\n",
            "Epoch #1. Accuracy on batch 591 on Training is 30.252322635135137\n",
            "Epoch #1. Accuracy on batch 592 on Training is 30.26981450252951\n",
            "Epoch #1. Accuracy on batch 593 on Training is 30.266203703703702\n",
            "Epoch #1. Accuracy on batch 594 on Training is 30.29936974789916\n",
            "Epoch #1. Accuracy on batch 595 on Training is 30.32193791946309\n",
            "Epoch #1. Accuracy on batch 596 on Training is 30.297319932998324\n",
            "Epoch #1. Accuracy on batch 597 on Training is 30.33549331103679\n",
            "Epoch #1. Accuracy on batch 598 on Training is 30.34745409015025\n",
            "Epoch #1. Accuracy on batch 599 on Training is 30.328125\n",
            "Batch Id 600 is having training loss of 2022.91064453125\n",
            "17.244646072387695\n",
            "Epoch #1. Accuracy on batch 600 on Training is 30.345257903494176\n",
            "Epoch #1. Accuracy on batch 601 on Training is 30.351951827242527\n",
            "Epoch #1. Accuracy on batch 602 on Training is 30.353441127694857\n",
            "Epoch #1. Accuracy on batch 603 on Training is 30.349751655629138\n",
            "Epoch #1. Accuracy on batch 604 on Training is 30.356404958677686\n",
            "Epoch #1. Accuracy on batch 605 on Training is 30.373349834983497\n",
            "Epoch #1. Accuracy on batch 606 on Training is 30.364497528830313\n",
            "Epoch #1. Accuracy on batch 607 on Training is 30.355674342105264\n",
            "Epoch #1. Accuracy on batch 608 on Training is 30.352011494252874\n",
            "Epoch #1. Accuracy on batch 609 on Training is 30.36372950819672\n",
            "Epoch #1. Accuracy on batch 610 on Training is 30.38563829787234\n",
            "Epoch #1. Accuracy on batch 611 on Training is 30.381944444444443\n",
            "Epoch #1. Accuracy on batch 612 on Training is 30.38845840130506\n",
            "Epoch #1. Accuracy on batch 613 on Training is 30.40513029315961\n",
            "Epoch #1. Accuracy on batch 614 on Training is 30.396341463414632\n",
            "Epoch #1. Accuracy on batch 615 on Training is 30.397727272727273\n",
            "Epoch #1. Accuracy on batch 616 on Training is 30.373784440842787\n",
            "Epoch #1. Accuracy on batch 617 on Training is 30.380258899676374\n",
            "Epoch #1. Accuracy on batch 618 on Training is 30.38166397415186\n",
            "Epoch #1. Accuracy on batch 619 on Training is 30.378024193548388\n",
            "Batch Id 620 is having training loss of 2034.757568359375\n",
            "8372.0185546875\n",
            "Epoch #1. Accuracy on batch 620 on Training is 30.359299516908212\n",
            "Epoch #1. Accuracy on batch 621 on Training is 30.355707395498392\n",
            "Epoch #1. Accuracy on batch 622 on Training is 30.337078651685392\n",
            "Epoch #1. Accuracy on batch 623 on Training is 30.34354967948718\n",
            "Epoch #1. Accuracy on batch 624 on Training is 30.345\n",
            "Epoch #1. Accuracy on batch 625 on Training is 30.321485623003195\n",
            "Epoch #1. Accuracy on batch 626 on Training is 30.312998405103666\n",
            "Epoch #1. Accuracy on batch 627 on Training is 30.324442675159236\n",
            "Epoch #1. Accuracy on batch 628 on Training is 30.345786963434023\n",
            "Epoch #1. Accuracy on batch 629 on Training is 30.34722222222222\n",
            "Epoch #1. Accuracy on batch 630 on Training is 30.343700475435817\n",
            "Epoch #1. Accuracy on batch 631 on Training is 30.345134493670887\n",
            "Epoch #1. Accuracy on batch 632 on Training is 30.346563981042653\n",
            "Epoch #1. Accuracy on batch 633 on Training is 30.343059936908517\n",
            "Epoch #1. Accuracy on batch 634 on Training is 30.334645669291337\n",
            "Epoch #1. Accuracy on batch 635 on Training is 30.316430817610062\n",
            "Epoch #1. Accuracy on batch 636 on Training is 30.332613814756673\n",
            "Epoch #1. Accuracy on batch 637 on Training is 30.329153605015673\n",
            "Epoch #1. Accuracy on batch 638 on Training is 30.335485133020345\n",
            "Epoch #1. Accuracy on batch 639 on Training is 30.3369140625\n",
            "Batch Id 640 is having training loss of 1974.266357421875\n",
            "451.9079895019531\n",
            "Epoch #1. Accuracy on batch 640 on Training is 30.32371294851794\n",
            "Epoch #1. Accuracy on batch 641 on Training is 30.334890965732086\n",
            "Epoch #1. Accuracy on batch 642 on Training is 30.321734059097977\n",
            "Epoch #1. Accuracy on batch 643 on Training is 30.33288043478261\n",
            "Epoch #1. Accuracy on batch 644 on Training is 30.348837209302324\n",
            "Epoch #1. Accuracy on batch 645 on Training is 30.340557275541794\n",
            "Epoch #1. Accuracy on batch 646 on Training is 30.332302936630605\n",
            "Epoch #1. Accuracy on batch 647 on Training is 30.338541666666668\n",
            "Epoch #1. Accuracy on batch 648 on Training is 30.33513097072419\n",
            "Epoch #1. Accuracy on batch 649 on Training is 30.341346153846153\n",
            "Epoch #1. Accuracy on batch 650 on Training is 30.333141321044547\n",
            "Epoch #1. Accuracy on batch 651 on Training is 30.353719325153374\n",
            "Epoch #1. Accuracy on batch 652 on Training is 30.364663093415007\n",
            "Epoch #1. Accuracy on batch 653 on Training is 30.34690366972477\n",
            "Epoch #1. Accuracy on batch 654 on Training is 30.34828244274809\n",
            "Epoch #1. Accuracy on batch 655 on Training is 30.344893292682926\n",
            "Epoch #1. Accuracy on batch 656 on Training is 30.374809741248097\n",
            "Epoch #1. Accuracy on batch 657 on Training is 30.37613981762918\n",
            "Epoch #1. Accuracy on batch 658 on Training is 30.38220789074355\n",
            "Epoch #1. Accuracy on batch 659 on Training is 30.388257575757574\n",
            "Batch Id 660 is having training loss of 1928.1873779296875\n",
            "9.825392723083496\n",
            "Epoch #1. Accuracy on batch 660 on Training is 30.40374432677761\n",
            "Epoch #1. Accuracy on batch 661 on Training is 30.395581570996978\n",
            "Epoch #1. Accuracy on batch 662 on Training is 30.39687028657617\n",
            "Epoch #1. Accuracy on batch 663 on Training is 30.398155120481928\n",
            "Epoch #1. Accuracy on batch 664 on Training is 30.38533834586466\n",
            "Epoch #1. Accuracy on batch 665 on Training is 30.386636636636638\n",
            "Epoch #1. Accuracy on batch 666 on Training is 30.406671664167916\n",
            "Epoch #1. Accuracy on batch 667 on Training is 30.40325598802395\n",
            "Epoch #1. Accuracy on batch 668 on Training is 30.39050822122571\n",
            "Epoch #1. Accuracy on batch 669 on Training is 30.377798507462686\n",
            "Epoch #1. Accuracy on batch 670 on Training is 30.388412816691506\n",
            "Epoch #1. Accuracy on batch 671 on Training is 30.375744047619047\n",
            "Epoch #1. Accuracy on batch 672 on Training is 30.37704309063893\n",
            "Epoch #1. Accuracy on batch 673 on Training is 30.37370178041543\n",
            "Epoch #1. Accuracy on batch 674 on Training is 30.375\n",
            "Epoch #1. Accuracy on batch 675 on Training is 30.3855399408284\n",
            "Epoch #1. Accuracy on batch 676 on Training is 30.37758493353028\n",
            "Epoch #1. Accuracy on batch 677 on Training is 30.383480825958703\n",
            "Epoch #1. Accuracy on batch 678 on Training is 30.38935935198822\n",
            "Epoch #1. Accuracy on batch 679 on Training is 30.376838235294116\n",
            "Batch Id 680 is having training loss of 1913.65234375\n",
            "1212.021484375\n",
            "Epoch #1. Accuracy on batch 680 on Training is 30.355176211453745\n",
            "Epoch #1. Accuracy on batch 681 on Training is 30.35648826979472\n",
            "Epoch #1. Accuracy on batch 682 on Training is 30.344070278184482\n",
            "Epoch #1. Accuracy on batch 683 on Training is 30.345394736842106\n",
            "Epoch #1. Accuracy on batch 684 on Training is 30.346715328467152\n",
            "Epoch #1. Accuracy on batch 685 on Training is 30.338921282798832\n",
            "Epoch #1. Accuracy on batch 686 on Training is 30.32660116448326\n",
            "Epoch #1. Accuracy on batch 687 on Training is 30.327943313953487\n",
            "Epoch #1. Accuracy on batch 688 on Training is 30.338352685050797\n",
            "Epoch #1. Accuracy on batch 689 on Training is 30.35326086956522\n",
            "Epoch #1. Accuracy on batch 690 on Training is 30.354558610709116\n",
            "Epoch #1. Accuracy on batch 691 on Training is 30.35133670520231\n",
            "Epoch #1. Accuracy on batch 692 on Training is 30.339105339105338\n",
            "Epoch #1. Accuracy on batch 693 on Training is 30.33591498559078\n",
            "Epoch #1. Accuracy on batch 694 on Training is 30.328237410071942\n",
            "Epoch #1. Accuracy on batch 695 on Training is 30.334051724137932\n",
            "Epoch #1. Accuracy on batch 696 on Training is 30.312948350071736\n",
            "Epoch #1. Accuracy on batch 697 on Training is 30.29638252148997\n",
            "Epoch #1. Accuracy on batch 698 on Training is 30.27986409155937\n",
            "Epoch #1. Accuracy on batch 699 on Training is 30.263392857142858\n",
            "Batch Id 700 is having training loss of 1877.621337890625\n",
            "10.04206657409668\n",
            "Epoch #1. Accuracy on batch 700 on Training is 30.255884450784592\n",
            "Epoch #1. Accuracy on batch 701 on Training is 30.239494301994302\n",
            "Epoch #1. Accuracy on batch 702 on Training is 30.236486486486488\n",
            "Epoch #1. Accuracy on batch 703 on Training is 30.237926136363637\n",
            "Epoch #1. Accuracy on batch 704 on Training is 30.243794326241133\n",
            "Epoch #1. Accuracy on batch 705 on Training is 30.24521954674221\n",
            "Epoch #1. Accuracy on batch 706 on Training is 30.242220650636494\n",
            "Epoch #1. Accuracy on batch 707 on Training is 30.26129943502825\n",
            "Epoch #1. Accuracy on batch 708 on Training is 30.27150916784203\n",
            "Epoch #1. Accuracy on batch 709 on Training is 30.277288732394368\n",
            "Epoch #1. Accuracy on batch 710 on Training is 30.27865682137834\n",
            "Epoch #1. Accuracy on batch 711 on Training is 30.284410112359552\n",
            "Epoch #1. Accuracy on batch 712 on Training is 30.28138148667602\n",
            "Epoch #1. Accuracy on batch 713 on Training is 30.265231092436974\n",
            "Epoch #1. Accuracy on batch 714 on Training is 30.26660839160839\n",
            "Epoch #1. Accuracy on batch 715 on Training is 30.26798184357542\n",
            "Epoch #1. Accuracy on batch 716 on Training is 30.278068340306834\n",
            "Epoch #1. Accuracy on batch 717 on Training is 30.275069637883007\n",
            "Epoch #1. Accuracy on batch 718 on Training is 30.285118219749652\n",
            "Epoch #1. Accuracy on batch 719 on Training is 30.286458333333332\n",
            "Batch Id 720 is having training loss of 1849.1453857421875\n",
            "74.50951385498047\n",
            "Epoch #1. Accuracy on batch 720 on Training is 30.305131761442443\n",
            "Epoch #1. Accuracy on batch 721 on Training is 30.289127423822716\n",
            "Epoch #1. Accuracy on batch 722 on Training is 30.294778699861688\n",
            "Epoch #1. Accuracy on batch 723 on Training is 30.278832872928177\n",
            "Epoch #1. Accuracy on batch 724 on Training is 30.28448275862069\n",
            "Epoch #1. Accuracy on batch 725 on Training is 30.290117079889807\n",
            "Epoch #1. Accuracy on batch 726 on Training is 30.28713892709766\n",
            "Epoch #1. Accuracy on batch 727 on Training is 30.297046703296704\n",
            "Epoch #1. Accuracy on batch 728 on Training is 30.29835390946502\n",
            "Epoch #1. Accuracy on batch 729 on Training is 30.28253424657534\n",
            "Epoch #1. Accuracy on batch 730 on Training is 30.279582763337892\n",
            "Epoch #1. Accuracy on batch 731 on Training is 30.276639344262296\n",
            "Epoch #1. Accuracy on batch 732 on Training is 30.260914051841745\n",
            "Epoch #1. Accuracy on batch 733 on Training is 30.26226158038147\n",
            "Epoch #1. Accuracy on batch 734 on Training is 30.2593537414966\n",
            "Epoch #1. Accuracy on batch 735 on Training is 30.25220788043478\n",
            "Epoch #1. Accuracy on batch 736 on Training is 30.257801899592945\n",
            "Epoch #1. Accuracy on batch 737 on Training is 30.237974254742547\n",
            "Epoch #1. Accuracy on batch 738 on Training is 30.243572395128552\n",
            "Epoch #1. Accuracy on batch 739 on Training is 30.249155405405407\n",
            "Batch Id 740 is having training loss of 1841.169189453125\n",
            "23.915794372558594\n",
            "Epoch #1. Accuracy on batch 740 on Training is 30.250506072874494\n",
            "Epoch #1. Accuracy on batch 741 on Training is 30.235006738544474\n",
            "Epoch #1. Accuracy on batch 742 on Training is 30.232166890982505\n",
            "Epoch #1. Accuracy on batch 743 on Training is 30.225134408602152\n",
            "Epoch #1. Accuracy on batch 744 on Training is 30.226510067114095\n",
            "Epoch #1. Accuracy on batch 745 on Training is 30.223693029490615\n",
            "Epoch #1. Accuracy on batch 746 on Training is 30.21251673360107\n",
            "Epoch #1. Accuracy on batch 747 on Training is 30.19301470588235\n",
            "Epoch #1. Accuracy on batch 748 on Training is 30.19859813084112\n",
            "Epoch #1. Accuracy on batch 749 on Training is 30.208333333333332\n",
            "Epoch #1. Accuracy on batch 750 on Training is 30.20972037283622\n",
            "Epoch #1. Accuracy on batch 751 on Training is 30.21941489361702\n",
            "Epoch #1. Accuracy on batch 752 on Training is 30.20003320053121\n",
            "Epoch #1. Accuracy on batch 753 on Training is 30.226293103448278\n",
            "Epoch #1. Accuracy on batch 754 on Training is 30.219370860927153\n",
            "Epoch #1. Accuracy on batch 755 on Training is 30.224867724867725\n",
            "Epoch #1. Accuracy on batch 756 on Training is 30.23860634081902\n",
            "Epoch #1. Accuracy on batch 757 on Training is 30.235817941952508\n",
            "Epoch #1. Accuracy on batch 758 on Training is 30.233036890645586\n",
            "Epoch #1. Accuracy on batch 759 on Training is 30.238486842105264\n",
            "Batch Id 760 is having training loss of 1794.8380126953125\n",
            "16.117626190185547\n",
            "Epoch #1. Accuracy on batch 760 on Training is 30.24392247043364\n",
            "Epoch #1. Accuracy on batch 761 on Training is 30.25754593175853\n",
            "Epoch #1. Accuracy on batch 762 on Training is 30.25475098296199\n",
            "Epoch #1. Accuracy on batch 763 on Training is 30.264234293193716\n",
            "Epoch #1. Accuracy on batch 764 on Training is 30.273692810457515\n",
            "Epoch #1. Accuracy on batch 765 on Training is 30.279046997389035\n",
            "Epoch #1. Accuracy on batch 766 on Training is 30.27623859191656\n",
            "Epoch #1. Accuracy on batch 767 on Training is 30.289713541666668\n",
            "Epoch #1. Accuracy on batch 768 on Training is 30.27064369310793\n",
            "Epoch #1. Accuracy on batch 769 on Training is 30.271915584415584\n",
            "Epoch #1. Accuracy on batch 770 on Training is 30.27318417639429\n",
            "Epoch #1. Accuracy on batch 771 on Training is 30.290641191709845\n",
            "Epoch #1. Accuracy on batch 772 on Training is 30.279754204398447\n",
            "Epoch #1. Accuracy on batch 773 on Training is 30.29312015503876\n",
            "Epoch #1. Accuracy on batch 774 on Training is 30.302419354838708\n",
            "Epoch #1. Accuracy on batch 775 on Training is 30.303640463917525\n",
            "Epoch #1. Accuracy on batch 776 on Training is 30.30888030888031\n",
            "Epoch #1. Accuracy on batch 777 on Training is 30.298039845758353\n",
            "Epoch #1. Accuracy on batch 778 on Training is 30.29926187419769\n",
            "Epoch #1. Accuracy on batch 779 on Training is 30.3125\n",
            "Batch Id 780 is having training loss of 1764.9749755859375\n",
            "62.59348678588867\n",
            "Epoch #1. Accuracy on batch 780 on Training is 30.305697823303458\n",
            "Epoch #1. Accuracy on batch 781 on Training is 30.30690537084399\n",
            "Epoch #1. Accuracy on batch 782 on Training is 30.32008301404853\n",
            "Epoch #1. Accuracy on batch 783 on Training is 30.313297193877553\n",
            "Epoch #1. Accuracy on batch 784 on Training is 30.306528662420384\n",
            "Epoch #1. Accuracy on batch 785 on Training is 30.31568066157761\n",
            "Epoch #1. Accuracy on batch 786 on Training is 30.320838627700127\n",
            "Epoch #1. Accuracy on batch 787 on Training is 30.314086294416242\n",
            "Epoch #1. Accuracy on batch 788 on Training is 30.32319391634981\n",
            "Epoch #1. Accuracy on batch 789 on Training is 30.31645569620253\n",
            "Epoch #1. Accuracy on batch 790 on Training is 30.31763590391909\n",
            "Epoch #1. Accuracy on batch 791 on Training is 30.314867424242426\n",
            "Epoch #1. Accuracy on batch 792 on Training is 30.327868852459016\n",
            "Epoch #1. Accuracy on batch 793 on Training is 30.325094458438286\n",
            "Epoch #1. Accuracy on batch 794 on Training is 30.31446540880503\n",
            "Epoch #1. Accuracy on batch 795 on Training is 30.323492462311556\n",
            "Epoch #1. Accuracy on batch 796 on Training is 30.308971141781683\n",
            "Epoch #1. Accuracy on batch 797 on Training is 30.31015037593985\n",
            "Epoch #1. Accuracy on batch 798 on Training is 30.303504380475594\n",
            "Epoch #1. Accuracy on batch 799 on Training is 30.30859375\n",
            "Batch Id 800 is having training loss of 1743.10400390625\n",
            "38.6712760925293\n",
            "Epoch #1. Accuracy on batch 800 on Training is 30.305867665418226\n",
            "Epoch #1. Accuracy on batch 801 on Training is 30.31873441396509\n",
            "Epoch #1. Accuracy on batch 802 on Training is 30.316002490660026\n",
            "Epoch #1. Accuracy on batch 803 on Training is 30.317164179104477\n",
            "Epoch #1. Accuracy on batch 804 on Training is 30.31832298136646\n",
            "Epoch #1. Accuracy on batch 805 on Training is 30.323356079404466\n",
            "Epoch #1. Accuracy on batch 806 on Training is 30.31675960346964\n",
            "Epoch #1. Accuracy on batch 807 on Training is 30.329517326732674\n",
            "Epoch #1. Accuracy on batch 808 on Training is 30.32679233621755\n",
            "Epoch #1. Accuracy on batch 809 on Training is 30.320216049382715\n",
            "Epoch #1. Accuracy on batch 810 on Training is 30.32521578298397\n",
            "Epoch #1. Accuracy on batch 811 on Training is 30.326354679802957\n",
            "Epoch #1. Accuracy on batch 812 on Training is 30.315959409594097\n",
            "Epoch #1. Accuracy on batch 813 on Training is 30.340141277641276\n",
            "Epoch #1. Accuracy on batch 814 on Training is 30.35659509202454\n",
            "Epoch #1. Accuracy on batch 815 on Training is 30.342371323529413\n",
            "Epoch #1. Accuracy on batch 816 on Training is 30.33200734394125\n",
            "Epoch #1. Accuracy on batch 817 on Training is 30.33312958435208\n",
            "Epoch #1. Accuracy on batch 818 on Training is 30.368589743589745\n",
            "Epoch #1. Accuracy on batch 819 on Training is 30.350609756097562\n",
            "Batch Id 820 is having training loss of 1703.1463623046875\n",
            "64.66751861572266\n",
            "Epoch #1. Accuracy on batch 820 on Training is 30.355511571254567\n",
            "Epoch #1. Accuracy on batch 821 on Training is 30.371806569343065\n",
            "Epoch #1. Accuracy on batch 822 on Training is 30.37667071688943\n",
            "Epoch #1. Accuracy on batch 823 on Training is 30.358768203883496\n",
            "Epoch #1. Accuracy on batch 824 on Training is 30.348484848484848\n",
            "Epoch #1. Accuracy on batch 825 on Training is 30.345792978208234\n",
            "Epoch #1. Accuracy on batch 826 on Training is 30.350665054413543\n",
            "Epoch #1. Accuracy on batch 827 on Training is 30.35552536231884\n",
            "Epoch #1. Accuracy on batch 828 on Training is 30.356604342581424\n",
            "Epoch #1. Accuracy on batch 829 on Training is 30.353915662650603\n",
            "Epoch #1. Accuracy on batch 830 on Training is 30.354993983152827\n",
            "Epoch #1. Accuracy on batch 831 on Training is 30.35606971153846\n",
            "Epoch #1. Accuracy on batch 832 on Training is 30.345888355342137\n",
            "Epoch #1. Accuracy on batch 833 on Training is 30.34697242206235\n",
            "Epoch #1. Accuracy on batch 834 on Training is 30.32934131736527\n",
            "Epoch #1. Accuracy on batch 835 on Training is 30.35287081339713\n",
            "Epoch #1. Accuracy on batch 836 on Training is 30.35394265232975\n",
            "Epoch #1. Accuracy on batch 837 on Training is 30.355011933174225\n",
            "Epoch #1. Accuracy on batch 838 on Training is 30.3411799761621\n",
            "Epoch #1. Accuracy on batch 839 on Training is 30.338541666666668\n",
            "Batch Id 840 is having training loss of 1715.878173828125\n",
            "16.1010799407959\n",
            "Epoch #1. Accuracy on batch 840 on Training is 30.347057074910822\n",
            "Epoch #1. Accuracy on batch 841 on Training is 30.336995249406176\n",
            "Epoch #1. Accuracy on batch 842 on Training is 30.330664294187425\n",
            "Epoch #1. Accuracy on batch 843 on Training is 30.328050947867297\n",
            "Epoch #1. Accuracy on batch 844 on Training is 30.32914201183432\n",
            "Epoch #1. Accuracy on batch 845 on Training is 30.326536643026003\n",
            "Epoch #1. Accuracy on batch 846 on Training is 30.32762691853601\n",
            "Epoch #1. Accuracy on batch 847 on Training is 30.332399764150942\n",
            "Epoch #1. Accuracy on batch 848 on Training is 30.34452296819788\n",
            "Epoch #1. Accuracy on batch 849 on Training is 30.352941176470587\n",
            "Epoch #1. Accuracy on batch 850 on Training is 30.34297884841363\n",
            "Epoch #1. Accuracy on batch 851 on Training is 30.347711267605632\n",
            "Epoch #1. Accuracy on batch 852 on Training is 30.33411488862837\n",
            "Epoch #1. Accuracy on batch 853 on Training is 30.324209601873537\n",
            "Epoch #1. Accuracy on batch 854 on Training is 30.32894736842105\n",
            "Epoch #1. Accuracy on batch 855 on Training is 30.33002336448598\n",
            "Epoch #1. Accuracy on batch 856 on Training is 30.334743290548424\n",
            "Epoch #1. Accuracy on batch 857 on Training is 30.335810023310025\n",
            "Epoch #1. Accuracy on batch 858 on Training is 30.340512223515717\n",
            "Epoch #1. Accuracy on batch 859 on Training is 30.363372093023255\n",
            "Batch Id 860 is having training loss of 1825.058349609375\n",
            "56483.66796875\n",
            "Epoch #1. Accuracy on batch 860 on Training is 30.353513356562136\n",
            "Epoch #1. Accuracy on batch 861 on Training is 30.35455336426914\n",
            "Epoch #1. Accuracy on batch 862 on Training is 30.359212050984937\n",
            "Epoch #1. Accuracy on batch 863 on Training is 30.338541666666668\n",
            "Epoch #1. Accuracy on batch 864 on Training is 30.354046242774565\n",
            "Epoch #1. Accuracy on batch 865 on Training is 30.3659064665127\n",
            "Epoch #1. Accuracy on batch 866 on Training is 30.356113033448672\n",
            "Epoch #1. Accuracy on batch 867 on Training is 30.335541474654377\n",
            "Epoch #1. Accuracy on batch 868 on Training is 30.315017261219793\n",
            "Epoch #1. Accuracy on batch 869 on Training is 30.305316091954023\n",
            "Epoch #1. Accuracy on batch 870 on Training is 30.29922502870264\n",
            "Epoch #1. Accuracy on batch 871 on Training is 30.311066513761467\n",
            "Epoch #1. Accuracy on batch 872 on Training is 30.312142038946163\n",
            "Epoch #1. Accuracy on batch 873 on Training is 30.327517162471395\n",
            "Epoch #1. Accuracy on batch 874 on Training is 30.321428571428573\n",
            "Epoch #1. Accuracy on batch 875 on Training is 30.31892123287671\n",
            "Epoch #1. Accuracy on batch 876 on Training is 30.33067274800456\n",
            "Epoch #1. Accuracy on batch 877 on Training is 30.3246013667426\n",
            "Epoch #1. Accuracy on batch 878 on Training is 30.322098976109213\n",
            "Epoch #1. Accuracy on batch 879 on Training is 30.3125\n",
            "Batch Id 880 is having training loss of 1826.4560546875\n",
            "23.784730911254883\n",
            "Epoch #1. Accuracy on batch 880 on Training is 30.31356413166856\n",
            "Epoch #1. Accuracy on batch 881 on Training is 30.314625850340136\n",
            "Epoch #1. Accuracy on batch 882 on Training is 30.326302378255946\n",
            "Epoch #1. Accuracy on batch 883 on Training is 30.327347285067873\n",
            "Epoch #1. Accuracy on batch 884 on Training is 30.342514124293785\n",
            "Epoch #1. Accuracy on batch 885 on Training is 30.34706546275395\n",
            "Epoch #1. Accuracy on batch 886 on Training is 30.3445603156708\n",
            "Epoch #1. Accuracy on batch 887 on Training is 30.33150337837838\n",
            "Epoch #1. Accuracy on batch 888 on Training is 30.32902137232846\n",
            "Epoch #1. Accuracy on batch 889 on Training is 30.340589887640448\n",
            "Epoch #1. Accuracy on batch 890 on Training is 30.338103254769923\n",
            "Epoch #1. Accuracy on batch 891 on Training is 30.342628923766817\n",
            "Epoch #1. Accuracy on batch 892 on Training is 30.340145576707727\n",
            "Epoch #1. Accuracy on batch 893 on Training is 30.33067673378076\n",
            "Epoch #1. Accuracy on batch 894 on Training is 30.335195530726256\n",
            "Epoch #1. Accuracy on batch 895 on Training is 30.357142857142858\n",
            "Epoch #1. Accuracy on batch 896 on Training is 30.36510590858417\n",
            "Epoch #1. Accuracy on batch 897 on Training is 30.36957126948775\n",
            "Epoch #1. Accuracy on batch 898 on Training is 30.37055061179088\n",
            "Epoch #1. Accuracy on batch 899 on Training is 30.37847222222222\n",
            "Batch Id 900 is having training loss of 1796.4306640625\n",
            "401.9662170410156\n",
            "Epoch #1. Accuracy on batch 900 on Training is 30.393312985571587\n",
            "Epoch #1. Accuracy on batch 901 on Training is 30.40119179600887\n",
            "Epoch #1. Accuracy on batch 902 on Training is 30.395210409745292\n",
            "Epoch #1. Accuracy on batch 903 on Training is 30.385785398230087\n",
            "Epoch #1. Accuracy on batch 904 on Training is 30.400552486187845\n",
            "Epoch #1. Accuracy on batch 905 on Training is 30.398040838852097\n",
            "Epoch #1. Accuracy on batch 906 on Training is 30.402425578831313\n",
            "Epoch #1. Accuracy on batch 907 on Training is 30.417125550660792\n",
            "Epoch #1. Accuracy on batch 908 on Training is 30.41460396039604\n",
            "Epoch #1. Accuracy on batch 909 on Training is 30.42239010989011\n",
            "Epoch #1. Accuracy on batch 910 on Training is 30.43015916575192\n",
            "Epoch #1. Accuracy on batch 911 on Training is 30.42420504385965\n",
            "Epoch #1. Accuracy on batch 912 on Training is 30.425109529025193\n",
            "Epoch #1. Accuracy on batch 913 on Training is 30.412335886214443\n",
            "Epoch #1. Accuracy on batch 914 on Training is 30.396174863387976\n",
            "Epoch #1. Accuracy on batch 915 on Training is 30.380049126637555\n",
            "Epoch #1. Accuracy on batch 916 on Training is 30.37418211559433\n",
            "Epoch #1. Accuracy on batch 917 on Training is 30.388752723311548\n",
            "Epoch #1. Accuracy on batch 918 on Training is 30.406692056583243\n",
            "Epoch #1. Accuracy on batch 919 on Training is 30.39741847826087\n",
            "Batch Id 920 is having training loss of 1790.2457275390625\n",
            "23.39794158935547\n",
            "Epoch #1. Accuracy on batch 920 on Training is 30.40173724212812\n",
            "Epoch #1. Accuracy on batch 921 on Training is 30.399267895878523\n",
            "Epoch #1. Accuracy on batch 922 on Training is 30.40018959913326\n",
            "Epoch #1. Accuracy on batch 923 on Training is 30.401109307359306\n",
            "Epoch #1. Accuracy on batch 924 on Training is 30.405405405405407\n",
            "Epoch #1. Accuracy on batch 925 on Training is 30.396193304535636\n",
            "Epoch #1. Accuracy on batch 926 on Training is 30.40722761596548\n",
            "Epoch #1. Accuracy on batch 927 on Training is 30.404768318965516\n",
            "Epoch #1. Accuracy on batch 928 on Training is 30.41240581270183\n",
            "Epoch #1. Accuracy on batch 929 on Training is 30.399865591397848\n",
            "Epoch #1. Accuracy on batch 930 on Training is 30.377282491944147\n",
            "Epoch #1. Accuracy on batch 931 on Training is 30.38157188841202\n",
            "Epoch #1. Accuracy on batch 932 on Training is 30.385852090032156\n",
            "Epoch #1. Accuracy on batch 933 on Training is 30.37004817987152\n",
            "Epoch #1. Accuracy on batch 934 on Training is 30.377673796791445\n",
            "Epoch #1. Accuracy on batch 935 on Training is 30.388621794871796\n",
            "Epoch #1. Accuracy on batch 936 on Training is 30.39287620064034\n",
            "Epoch #1. Accuracy on batch 937 on Training is 30.40711620469083\n",
            "Epoch #1. Accuracy on batch 938 on Training is 30.401357827476037\n",
            "Epoch #1. Accuracy on batch 939 on Training is 30.398936170212767\n",
            "Batch Id 940 is having training loss of 1754.0709228515625\n",
            "65.87496948242188\n",
            "Epoch #1. Accuracy on batch 940 on Training is 30.386556854410202\n",
            "Epoch #1. Accuracy on batch 941 on Training is 30.387473460721868\n",
            "Epoch #1. Accuracy on batch 942 on Training is 30.391702014846235\n",
            "Epoch #1. Accuracy on batch 943 on Training is 30.385990466101696\n",
            "Epoch #1. Accuracy on batch 944 on Training is 30.39021164021164\n",
            "Epoch #1. Accuracy on batch 945 on Training is 30.394423890063425\n",
            "Epoch #1. Accuracy on batch 946 on Training is 30.405227032734953\n",
            "Epoch #1. Accuracy on batch 947 on Training is 30.402821729957807\n",
            "Epoch #1. Accuracy on batch 948 on Training is 30.403714436248684\n",
            "Epoch #1. Accuracy on batch 949 on Training is 30.394736842105264\n",
            "Epoch #1. Accuracy on batch 950 on Training is 30.392350157728707\n",
            "Epoch #1. Accuracy on batch 951 on Training is 30.383403361344538\n",
            "Epoch #1. Accuracy on batch 952 on Training is 30.367917103882476\n",
            "Epoch #1. Accuracy on batch 953 on Training is 30.36884171907757\n",
            "Epoch #1. Accuracy on batch 954 on Training is 30.373036649214658\n",
            "Epoch #1. Accuracy on batch 955 on Training is 30.38702928870293\n",
            "Epoch #1. Accuracy on batch 956 on Training is 30.397727272727273\n",
            "Epoch #1. Accuracy on batch 957 on Training is 30.405140918580376\n",
            "Epoch #1. Accuracy on batch 958 on Training is 30.415797705943692\n",
            "Epoch #1. Accuracy on batch 959 on Training is 30.4296875\n",
            "Batch Id 960 is having training loss of 1757.4986572265625\n",
            "23.6213436126709\n",
            "Epoch #1. Accuracy on batch 960 on Training is 30.414281997918835\n",
            "Epoch #1. Accuracy on batch 961 on Training is 30.415150727650726\n",
            "Epoch #1. Accuracy on batch 962 on Training is 30.406282450674976\n",
            "Epoch #1. Accuracy on batch 963 on Training is 30.403915975103736\n",
            "Epoch #1. Accuracy on batch 964 on Training is 30.401554404145077\n",
            "Epoch #1. Accuracy on batch 965 on Training is 30.399197722567287\n",
            "Epoch #1. Accuracy on batch 966 on Training is 30.403309203722856\n",
            "Epoch #1. Accuracy on batch 967 on Training is 30.400955578512395\n",
            "Epoch #1. Accuracy on batch 968 on Training is 30.395381836945305\n",
            "Epoch #1. Accuracy on batch 969 on Training is 30.409149484536083\n",
            "Epoch #1. Accuracy on batch 970 on Training is 30.41001544799176\n",
            "Epoch #1. Accuracy on batch 971 on Training is 30.417309670781894\n",
            "Epoch #1. Accuracy on batch 972 on Training is 30.414953751284685\n",
            "Epoch #1. Accuracy on batch 973 on Training is 30.415811088295687\n",
            "Epoch #1. Accuracy on batch 974 on Training is 30.419871794871796\n",
            "Epoch #1. Accuracy on batch 975 on Training is 30.436731557377048\n",
            "Epoch #1. Accuracy on batch 976 on Training is 30.43116683725691\n",
            "Epoch #1. Accuracy on batch 977 on Training is 30.43519938650307\n",
            "Epoch #1. Accuracy on batch 978 on Training is 30.432839632277833\n",
            "Epoch #1. Accuracy on batch 979 on Training is 30.414540816326532\n",
            "Batch Id 980 is having training loss of 1748.110595703125\n",
            "13.226459503173828\n",
            "Epoch #1. Accuracy on batch 980 on Training is 30.421763506625894\n",
            "Epoch #1. Accuracy on batch 981 on Training is 30.425789205702646\n",
            "Epoch #1. Accuracy on batch 982 on Training is 30.43298575788403\n",
            "Epoch #1. Accuracy on batch 983 on Training is 30.427464430894307\n",
            "Epoch #1. Accuracy on batch 984 on Training is 30.440989847715738\n",
            "Epoch #1. Accuracy on batch 985 on Training is 30.448149087221097\n",
            "Epoch #1. Accuracy on batch 986 on Training is 30.45212765957447\n",
            "Epoch #1. Accuracy on batch 987 on Training is 30.449772267206477\n",
            "Epoch #1. Accuracy on batch 988 on Training is 30.450581395348838\n",
            "Epoch #1. Accuracy on batch 989 on Training is 30.44823232323232\n",
            "Epoch #1. Accuracy on batch 990 on Training is 30.452194752774975\n",
            "Epoch #1. Accuracy on batch 991 on Training is 30.446698588709676\n",
            "Epoch #1. Accuracy on batch 992 on Training is 30.45380161127895\n",
            "Epoch #1. Accuracy on batch 993 on Training is 30.448314889336014\n",
            "Epoch #1. Accuracy on batch 994 on Training is 30.464824120603016\n",
            "Epoch #1. Accuracy on batch 995 on Training is 30.453062248995984\n",
            "Epoch #1. Accuracy on batch 996 on Training is 30.447592778335004\n",
            "Epoch #1. Accuracy on batch 997 on Training is 30.442134268537075\n",
            "Epoch #1. Accuracy on batch 998 on Training is 30.4491991991992\n",
            "Epoch #1. Accuracy on batch 999 on Training is 30.45\n",
            "Batch Id 1000 is having training loss of 1721.3271484375\n",
            "47.48988723754883\n",
            "Epoch #1. Accuracy on batch 1000 on Training is 30.441433566433567\n",
            "Epoch #1. Accuracy on batch 1001 on Training is 30.454715568862277\n",
            "Epoch #1. Accuracy on batch 1002 on Training is 30.452392821535394\n",
            "Epoch #1. Accuracy on batch 1003 on Training is 30.45941235059761\n",
            "Epoch #1. Accuracy on batch 1004 on Training is 30.46641791044776\n",
            "Epoch #1. Accuracy on batch 1005 on Training is 30.45787773359841\n",
            "Epoch #1. Accuracy on batch 1006 on Training is 30.467974180734856\n",
            "Epoch #1. Accuracy on batch 1007 on Training is 30.4656498015873\n",
            "Epoch #1. Accuracy on batch 1008 on Training is 30.47571853320119\n",
            "Epoch #1. Accuracy on batch 1009 on Training is 30.485767326732674\n",
            "Epoch #1. Accuracy on batch 1010 on Training is 30.477250247279922\n",
            "Epoch #1. Accuracy on batch 1011 on Training is 30.474925889328063\n",
            "Epoch #1. Accuracy on batch 1012 on Training is 30.497285291214215\n",
            "Epoch #1. Accuracy on batch 1013 on Training is 30.48878205128205\n",
            "Epoch #1. Accuracy on batch 1014 on Training is 30.498768472906406\n",
            "Epoch #1. Accuracy on batch 1015 on Training is 30.490280511811022\n",
            "Epoch #1. Accuracy on batch 1016 on Training is 30.48795476892822\n",
            "Epoch #1. Accuracy on batch 1017 on Training is 30.49791257367387\n",
            "Epoch #1. Accuracy on batch 1018 on Training is 30.49558390578999\n",
            "Epoch #1. Accuracy on batch 1019 on Training is 30.49938725490196\n",
            "Batch Id 1020 is having training loss of 1695.583251953125\n",
            "23.554658889770508\n",
            "Epoch #1. Accuracy on batch 1020 on Training is 30.515426052889325\n",
            "Epoch #1. Accuracy on batch 1021 on Training is 30.51614481409002\n",
            "Epoch #1. Accuracy on batch 1022 on Training is 30.49547898338221\n",
            "Epoch #1. Accuracy on batch 1023 on Training is 30.499267578125\n",
            "Epoch #1. Accuracy on batch 1024 on Training is 30.49390243902439\n",
            "Epoch #1. Accuracy on batch 1025 on Training is 30.50682261208577\n",
            "Epoch #1. Accuracy on batch 1026 on Training is 30.50450340798442\n",
            "Epoch #1. Accuracy on batch 1027 on Training is 30.49306906614786\n",
            "Epoch #1. Accuracy on batch 1028 on Training is 30.512026239067055\n",
            "Epoch #1. Accuracy on batch 1029 on Training is 30.521844660194176\n",
            "Epoch #1. Accuracy on batch 1030 on Training is 30.519519883608147\n",
            "Epoch #1. Accuracy on batch 1031 on Training is 30.526283914728683\n",
            "Epoch #1. Accuracy on batch 1032 on Training is 30.53000968054211\n",
            "Epoch #1. Accuracy on batch 1033 on Training is 30.530705996131527\n",
            "Epoch #1. Accuracy on batch 1034 on Training is 30.528381642512077\n",
            "Epoch #1. Accuracy on batch 1035 on Training is 30.529078185328185\n",
            "Epoch #1. Accuracy on batch 1036 on Training is 30.5327868852459\n",
            "Epoch #1. Accuracy on batch 1037 on Training is 30.533477842003855\n",
            "Epoch #1. Accuracy on batch 1038 on Training is 30.528152069297402\n",
            "Epoch #1. Accuracy on batch 1039 on Training is 30.52283653846154\n",
            "Batch Id 1040 is having training loss of 1663.997314453125\n",
            "31.202892303466797\n",
            "Epoch #1. Accuracy on batch 1040 on Training is 30.51753121998079\n",
            "Epoch #1. Accuracy on batch 1041 on Training is 30.524232245681382\n",
            "Epoch #1. Accuracy on batch 1042 on Training is 30.524928092042185\n",
            "Epoch #1. Accuracy on batch 1043 on Training is 30.52262931034483\n",
            "Epoch #1. Accuracy on batch 1044 on Training is 30.523325358851675\n",
            "Epoch #1. Accuracy on batch 1045 on Training is 30.518044933078393\n",
            "Epoch #1. Accuracy on batch 1046 on Training is 30.518744030563514\n",
            "Epoch #1. Accuracy on batch 1047 on Training is 30.51944179389313\n",
            "Epoch #1. Accuracy on batch 1048 on Training is 30.520138226882747\n",
            "Epoch #1. Accuracy on batch 1049 on Training is 30.526785714285715\n",
            "Epoch #1. Accuracy on batch 1050 on Training is 30.524500475737394\n",
            "Epoch #1. Accuracy on batch 1051 on Training is 30.531131178707223\n",
            "Epoch #1. Accuracy on batch 1052 on Training is 30.522910731244064\n",
            "Epoch #1. Accuracy on batch 1053 on Training is 30.514705882352942\n",
            "Epoch #1. Accuracy on batch 1054 on Training is 30.52132701421801\n",
            "Epoch #1. Accuracy on batch 1055 on Training is 30.516098484848484\n",
            "Epoch #1. Accuracy on batch 1056 on Training is 30.510879848628193\n",
            "Epoch #1. Accuracy on batch 1057 on Training is 30.520439508506616\n",
            "Epoch #1. Accuracy on batch 1058 on Training is 30.529981114258735\n",
            "Epoch #1. Accuracy on batch 1059 on Training is 30.53066037735849\n",
            "Batch Id 1060 is having training loss of 1644.259033203125\n",
            "57.20552444458008\n",
            "Epoch #1. Accuracy on batch 1060 on Training is 30.53722902921772\n",
            "Epoch #1. Accuracy on batch 1061 on Training is 30.543785310734464\n",
            "Epoch #1. Accuracy on batch 1062 on Training is 30.547389463781748\n",
            "Epoch #1. Accuracy on batch 1063 on Training is 30.559797932330827\n",
            "Epoch #1. Accuracy on batch 1064 on Training is 30.572183098591548\n",
            "Epoch #1. Accuracy on batch 1065 on Training is 30.569887429643526\n",
            "Epoch #1. Accuracy on batch 1066 on Training is 30.561738519212746\n",
            "Epoch #1. Accuracy on batch 1067 on Training is 30.556530898876403\n",
            "Epoch #1. Accuracy on batch 1068 on Training is 30.554256314312443\n",
            "Epoch #1. Accuracy on batch 1069 on Training is 30.551985981308412\n",
            "Epoch #1. Accuracy on batch 1070 on Training is 30.54971988795518\n",
            "Epoch #1. Accuracy on batch 1071 on Training is 30.550373134328357\n",
            "Epoch #1. Accuracy on batch 1072 on Training is 30.545200372786578\n",
            "Epoch #1. Accuracy on batch 1073 on Training is 30.542946927374302\n",
            "Epoch #1. Accuracy on batch 1074 on Training is 30.566860465116278\n",
            "Epoch #1. Accuracy on batch 1075 on Training is 30.564591078066915\n",
            "Epoch #1. Accuracy on batch 1076 on Training is 30.576833797585888\n",
            "Epoch #1. Accuracy on batch 1077 on Training is 30.583256029684602\n",
            "Epoch #1. Accuracy on batch 1078 on Training is 30.563600556070437\n",
            "Epoch #1. Accuracy on batch 1079 on Training is 30.56134259259259\n",
            "Batch Id 1080 is having training loss of 1616.8697509765625\n",
            "20.5067138671875\n",
            "Epoch #1. Accuracy on batch 1080 on Training is 30.567761332099906\n",
            "Epoch #1. Accuracy on batch 1081 on Training is 30.577056377079483\n",
            "Epoch #1. Accuracy on batch 1082 on Training is 30.57190674053555\n",
            "Epoch #1. Accuracy on batch 1083 on Training is 30.575415129151292\n",
            "Epoch #1. Accuracy on batch 1084 on Training is 30.590437788018434\n",
            "Epoch #1. Accuracy on batch 1085 on Training is 30.579534990791895\n",
            "Epoch #1. Accuracy on batch 1086 on Training is 30.583026678932843\n",
            "Epoch #1. Accuracy on batch 1087 on Training is 30.595128676470587\n",
            "Epoch #1. Accuracy on batch 1088 on Training is 30.59573002754821\n",
            "Epoch #1. Accuracy on batch 1089 on Training is 30.584862385321102\n",
            "Epoch #1. Accuracy on batch 1090 on Training is 30.591200733272228\n",
            "Epoch #1. Accuracy on batch 1091 on Training is 30.5746336996337\n",
            "Epoch #1. Accuracy on batch 1092 on Training is 30.575251601097897\n",
            "Epoch #1. Accuracy on batch 1093 on Training is 30.578724862888482\n",
            "Epoch #1. Accuracy on batch 1094 on Training is 30.587899543378995\n",
            "Epoch #1. Accuracy on batch 1095 on Training is 30.579949817518248\n",
            "Epoch #1. Accuracy on batch 1096 on Training is 30.563468550592525\n",
            "Epoch #1. Accuracy on batch 1097 on Training is 30.564093806921676\n",
            "Epoch #1. Accuracy on batch 1098 on Training is 30.57040491355778\n",
            "Epoch #1. Accuracy on batch 1099 on Training is 30.55965909090909\n",
            "Batch Id 1100 is having training loss of 1654.2869873046875\n",
            "23.359315872192383\n",
            "Epoch #1. Accuracy on batch 1100 on Training is 30.56312443233424\n",
            "Epoch #1. Accuracy on batch 1101 on Training is 30.56374773139746\n",
            "Epoch #1. Accuracy on batch 1102 on Training is 30.561536718041705\n",
            "Epoch #1. Accuracy on batch 1103 on Training is 30.562160326086957\n",
            "Epoch #1. Accuracy on batch 1104 on Training is 30.559954751131222\n",
            "Epoch #1. Accuracy on batch 1105 on Training is 30.552102169981918\n",
            "Epoch #1. Accuracy on batch 1106 on Training is 30.55273261065944\n",
            "Epoch #1. Accuracy on batch 1107 on Training is 30.56182310469314\n",
            "Epoch #1. Accuracy on batch 1108 on Training is 30.5596257889991\n",
            "Epoch #1. Accuracy on batch 1109 on Training is 30.543355855855857\n",
            "Epoch #1. Accuracy on batch 1110 on Training is 30.552430243024304\n",
            "Epoch #1. Accuracy on batch 1111 on Training is 30.56148830935252\n",
            "Epoch #1. Accuracy on batch 1112 on Training is 30.564914645103325\n",
            "Epoch #1. Accuracy on batch 1113 on Training is 30.56552962298025\n",
            "Epoch #1. Accuracy on batch 1114 on Training is 30.574551569506728\n",
            "Epoch #1. Accuracy on batch 1115 on Training is 30.572356630824373\n",
            "Epoch #1. Accuracy on batch 1116 on Training is 30.57576096687556\n",
            "Epoch #1. Accuracy on batch 1117 on Training is 30.57636404293381\n",
            "Epoch #1. Accuracy on batch 1118 on Training is 30.56858802502234\n",
            "Epoch #1. Accuracy on batch 1119 on Training is 30.56640625\n",
            "Batch Id 1120 is having training loss of 1628.93115234375\n",
            "662.4815673828125\n",
            "Epoch #1. Accuracy on batch 1120 on Training is 30.55865298840321\n",
            "Epoch #1. Accuracy on batch 1121 on Training is 30.55648395721925\n",
            "Epoch #1. Accuracy on batch 1122 on Training is 30.545970614425645\n",
            "Epoch #1. Accuracy on batch 1123 on Training is 30.543816725978647\n",
            "Epoch #1. Accuracy on batch 1124 on Training is 30.53611111111111\n",
            "Epoch #1. Accuracy on batch 1125 on Training is 30.533969804618117\n",
            "Epoch #1. Accuracy on batch 1126 on Training is 30.52628660159716\n",
            "Epoch #1. Accuracy on batch 1127 on Training is 30.529698581560282\n",
            "Epoch #1. Accuracy on batch 1128 on Training is 30.527568644818423\n",
            "Epoch #1. Accuracy on batch 1129 on Training is 30.530973451327434\n",
            "Epoch #1. Accuracy on batch 1130 on Training is 30.517793987621573\n",
            "Epoch #1. Accuracy on batch 1131 on Training is 30.532243816254418\n",
            "Epoch #1. Accuracy on batch 1132 on Training is 30.527360988526038\n",
            "Epoch #1. Accuracy on batch 1133 on Training is 30.519731040564373\n",
            "Epoch #1. Accuracy on batch 1134 on Training is 30.525881057268723\n",
            "Epoch #1. Accuracy on batch 1135 on Training is 30.529269366197184\n",
            "Epoch #1. Accuracy on batch 1136 on Training is 30.52715479331574\n",
            "Epoch #1. Accuracy on batch 1137 on Training is 30.536028119507908\n",
            "Epoch #1. Accuracy on batch 1138 on Training is 30.539398595258998\n",
            "Epoch #1. Accuracy on batch 1139 on Training is 30.54002192982456\n",
            "Batch Id 1140 is having training loss of 1606.605712890625\n",
            "98.98472595214844\n",
            "Epoch #1. Accuracy on batch 1140 on Training is 30.53516652059597\n",
            "Epoch #1. Accuracy on batch 1141 on Training is 30.541265323992995\n",
            "Epoch #1. Accuracy on batch 1142 on Training is 30.53915135608049\n",
            "Epoch #1. Accuracy on batch 1143 on Training is 30.54250437062937\n",
            "Epoch #1. Accuracy on batch 1144 on Training is 30.534934497816593\n",
            "Epoch #1. Accuracy on batch 1145 on Training is 30.541012216404887\n",
            "Epoch #1. Accuracy on batch 1146 on Training is 30.525283347863994\n",
            "Epoch #1. Accuracy on batch 1147 on Training is 30.53408101045296\n",
            "Epoch #1. Accuracy on batch 1148 on Training is 30.537423846823323\n",
            "Epoch #1. Accuracy on batch 1149 on Training is 30.535326086956523\n",
            "Epoch #1. Accuracy on batch 1150 on Training is 30.53594700260643\n",
            "Epoch #1. Accuracy on batch 1151 on Training is 30.53656684027778\n",
            "Epoch #1. Accuracy on batch 1152 on Training is 30.534475281873373\n",
            "Epoch #1. Accuracy on batch 1153 on Training is 30.52426343154246\n",
            "Epoch #1. Accuracy on batch 1154 on Training is 30.503246753246753\n",
            "Epoch #1. Accuracy on batch 1155 on Training is 30.503892733564015\n",
            "Epoch #1. Accuracy on batch 1156 on Training is 30.507238547968885\n",
            "Epoch #1. Accuracy on batch 1157 on Training is 30.510578583765113\n",
            "Epoch #1. Accuracy on batch 1158 on Training is 30.52200172562554\n",
            "Epoch #1. Accuracy on batch 1159 on Training is 30.519935344827587\n",
            "Batch Id 1160 is having training loss of 1664.948974609375\n",
            "10914.9072265625\n",
            "Epoch #1. Accuracy on batch 1160 on Training is 30.512489233419466\n",
            "Epoch #1. Accuracy on batch 1161 on Training is 30.518502581755595\n",
            "Epoch #1. Accuracy on batch 1162 on Training is 30.513757523645744\n",
            "Epoch #1. Accuracy on batch 1163 on Training is 30.5090206185567\n",
            "Epoch #1. Accuracy on batch 1164 on Training is 30.50429184549356\n",
            "Epoch #1. Accuracy on batch 1165 on Training is 30.496891080617495\n",
            "Epoch #1. Accuracy on batch 1166 on Training is 30.492180805484146\n",
            "Epoch #1. Accuracy on batch 1167 on Training is 30.490154109589042\n",
            "Epoch #1. Accuracy on batch 1168 on Training is 30.49347733105218\n",
            "Epoch #1. Accuracy on batch 1169 on Training is 30.49145299145299\n",
            "Epoch #1. Accuracy on batch 1170 on Training is 30.49210076857387\n",
            "Epoch #1. Accuracy on batch 1171 on Training is 30.49008105802048\n",
            "Epoch #1. Accuracy on batch 1172 on Training is 30.490728900255753\n",
            "Epoch #1. Accuracy on batch 1173 on Training is 30.49936115843271\n",
            "Epoch #1. Accuracy on batch 1174 on Training is 30.50531914893617\n",
            "Epoch #1. Accuracy on batch 1175 on Training is 30.492665816326532\n",
            "Epoch #1. Accuracy on batch 1176 on Training is 30.493309260832625\n",
            "Epoch #1. Accuracy on batch 1177 on Training is 30.48599320882852\n",
            "Epoch #1. Accuracy on batch 1178 on Training is 30.47603901611535\n",
            "Epoch #1. Accuracy on batch 1179 on Training is 30.479343220338983\n",
            "Batch Id 1180 is having training loss of 1652.3507080078125\n",
            "2439.318603515625\n",
            "Epoch #1. Accuracy on batch 1180 on Training is 30.477349703640982\n",
            "Epoch #1. Accuracy on batch 1181 on Training is 30.470071912013537\n",
            "Epoch #1. Accuracy on batch 1182 on Training is 30.46808960270499\n",
            "Epoch #1. Accuracy on batch 1183 on Training is 30.474028716216218\n",
            "Epoch #1. Accuracy on batch 1184 on Training is 30.474683544303797\n",
            "Epoch #1. Accuracy on batch 1185 on Training is 30.48060708263069\n",
            "Epoch #1. Accuracy on batch 1186 on Training is 30.489153327716934\n",
            "Epoch #1. Accuracy on batch 1187 on Training is 30.48979377104377\n",
            "Epoch #1. Accuracy on batch 1188 on Training is 30.493061396131203\n",
            "Epoch #1. Accuracy on batch 1189 on Training is 30.501575630252102\n",
            "Epoch #1. Accuracy on batch 1190 on Training is 30.504827875734676\n",
            "Epoch #1. Accuracy on batch 1191 on Training is 30.50545302013423\n",
            "Epoch #1. Accuracy on batch 1192 on Training is 30.50607711651299\n",
            "Epoch #1. Accuracy on batch 1193 on Training is 30.504082914572866\n",
            "Epoch #1. Accuracy on batch 1194 on Training is 30.507322175732217\n",
            "Epoch #1. Accuracy on batch 1195 on Training is 30.502717391304348\n",
            "Epoch #1. Accuracy on batch 1196 on Training is 30.503341687552215\n",
            "Epoch #1. Accuracy on batch 1197 on Training is 30.490922370617696\n",
            "Epoch #1. Accuracy on batch 1198 on Training is 30.486342785654713\n",
            "Epoch #1. Accuracy on batch 1199 on Training is 30.481770833333332\n",
            "Batch Id 1200 is having training loss of 1650.7811279296875\n",
            "39.08916473388672\n",
            "Epoch #1. Accuracy on batch 1200 on Training is 30.479808492922565\n",
            "Epoch #1. Accuracy on batch 1201 on Training is 30.47264975041597\n",
            "Epoch #1. Accuracy on batch 1202 on Training is 30.457709891936826\n",
            "Epoch #1. Accuracy on batch 1203 on Training is 30.447985880398672\n",
            "Epoch #1. Accuracy on batch 1204 on Training is 30.440871369294605\n",
            "Epoch #1. Accuracy on batch 1205 on Training is 30.44931592039801\n",
            "Epoch #1. Accuracy on batch 1206 on Training is 30.447390223695113\n",
            "Epoch #1. Accuracy on batch 1207 on Training is 30.440293874172184\n",
            "Epoch #1. Accuracy on batch 1208 on Training is 30.435794044665013\n",
            "Epoch #1. Accuracy on batch 1209 on Training is 30.43130165289256\n",
            "Epoch #1. Accuracy on batch 1210 on Training is 30.426816680429397\n",
            "Epoch #1. Accuracy on batch 1211 on Training is 30.42233910891089\n",
            "Epoch #1. Accuracy on batch 1212 on Training is 30.423021434460015\n",
            "Epoch #1. Accuracy on batch 1213 on Training is 30.42370263591433\n",
            "Epoch #1. Accuracy on batch 1214 on Training is 30.421810699588477\n",
            "Epoch #1. Accuracy on batch 1215 on Training is 30.42506167763158\n",
            "Epoch #1. Accuracy on batch 1216 on Training is 30.430875102711585\n",
            "Epoch #1. Accuracy on batch 1217 on Training is 30.42898193760263\n",
            "Epoch #1. Accuracy on batch 1218 on Training is 30.429655455291222\n",
            "Epoch #1. Accuracy on batch 1219 on Training is 30.41752049180328\n",
            "Batch Id 1220 is having training loss of 1655.5819091796875\n",
            "37.49118423461914\n",
            "Epoch #1. Accuracy on batch 1220 on Training is 30.41820229320229\n",
            "Epoch #1. Accuracy on batch 1221 on Training is 30.418882978723403\n",
            "Epoch #1. Accuracy on batch 1222 on Training is 30.411896974652493\n",
            "Epoch #1. Accuracy on batch 1223 on Training is 30.397263071895424\n",
            "Epoch #1. Accuracy on batch 1224 on Training is 30.400510204081634\n",
            "Epoch #1. Accuracy on batch 1225 on Training is 30.40884991843393\n",
            "Epoch #1. Accuracy on batch 1226 on Training is 30.399348003259984\n",
            "Epoch #1. Accuracy on batch 1227 on Training is 30.40513029315961\n",
            "Epoch #1. Accuracy on batch 1228 on Training is 30.410903173311635\n",
            "Epoch #1. Accuracy on batch 1229 on Training is 30.411585365853657\n",
            "Epoch #1. Accuracy on batch 1230 on Training is 30.40972786352559\n",
            "Epoch #1. Accuracy on batch 1231 on Training is 30.415482954545453\n",
            "Epoch #1. Accuracy on batch 1232 on Training is 30.42883211678832\n",
            "Epoch #1. Accuracy on batch 1233 on Training is 30.41683549432739\n",
            "Epoch #1. Accuracy on batch 1234 on Training is 30.40991902834008\n",
            "Epoch #1. Accuracy on batch 1235 on Training is 30.41818365695793\n",
            "Epoch #1. Accuracy on batch 1236 on Training is 30.41632983023444\n",
            "Epoch #1. Accuracy on batch 1237 on Training is 30.42205169628433\n",
            "Epoch #1. Accuracy on batch 1238 on Training is 30.425242130750604\n",
            "Epoch #1. Accuracy on batch 1239 on Training is 30.43094758064516\n",
            "Batch Id 1240 is having training loss of 1638.9600830078125\n",
            "25.173011779785156\n",
            "Epoch #1. Accuracy on batch 1240 on Training is 30.424053182917003\n",
            "Epoch #1. Accuracy on batch 1241 on Training is 30.424718196457327\n",
            "Epoch #1. Accuracy on batch 1242 on Training is 30.42538213998391\n",
            "Epoch #1. Accuracy on batch 1243 on Training is 30.431069131832796\n",
            "Epoch #1. Accuracy on batch 1244 on Training is 30.42921686746988\n",
            "Epoch #1. Accuracy on batch 1245 on Training is 30.417335473515248\n",
            "Epoch #1. Accuracy on batch 1246 on Training is 30.418003207698476\n",
            "Epoch #1. Accuracy on batch 1247 on Training is 30.413661858974358\n",
            "Epoch #1. Accuracy on batch 1248 on Training is 30.41683346677342\n",
            "Epoch #1. Accuracy on batch 1249 on Training is 30.41\n",
            "Epoch #1. Accuracy on batch 1250 on Training is 30.405675459632295\n",
            "Epoch #1. Accuracy on batch 1251 on Training is 30.411341853035143\n",
            "Epoch #1. Accuracy on batch 1252 on Training is 30.407023144453312\n",
            "Epoch #1. Accuracy on batch 1253 on Training is 30.405203349282296\n",
            "Epoch #1. Accuracy on batch 1254 on Training is 30.403386454183266\n",
            "Epoch #1. Accuracy on batch 1255 on Training is 30.41152468152866\n",
            "Epoch #1. Accuracy on batch 1256 on Training is 30.409705648369133\n",
            "Epoch #1. Accuracy on batch 1257 on Training is 30.405405405405407\n",
            "Epoch #1. Accuracy on batch 1258 on Training is 30.4035941223193\n",
            "Epoch #1. Accuracy on batch 1259 on Training is 30.394345238095237\n",
            "Batch Id 1260 is having training loss of 1650.1563720703125\n",
            "30.349761962890625\n",
            "Epoch #1. Accuracy on batch 1260 on Training is 30.395023790642348\n",
            "Epoch #1. Accuracy on batch 1261 on Training is 30.383320126782884\n",
            "Epoch #1. Accuracy on batch 1262 on Training is 30.364212193190816\n",
            "Epoch #1. Accuracy on batch 1263 on Training is 30.372329905063292\n",
            "Epoch #1. Accuracy on batch 1264 on Training is 30.365612648221344\n",
            "Epoch #1. Accuracy on batch 1265 on Training is 30.36137440758294\n",
            "Epoch #1. Accuracy on batch 1266 on Training is 30.36454222573007\n",
            "Epoch #1. Accuracy on batch 1267 on Training is 30.37016955835962\n",
            "Epoch #1. Accuracy on batch 1268 on Training is 30.365937746256897\n",
            "Epoch #1. Accuracy on batch 1269 on Training is 30.356791338582678\n",
            "Epoch #1. Accuracy on batch 1270 on Training is 30.350118017309207\n",
            "Epoch #1. Accuracy on batch 1271 on Training is 30.3532822327044\n",
            "Epoch #1. Accuracy on batch 1272 on Training is 30.353986645718773\n",
            "Epoch #1. Accuracy on batch 1273 on Training is 30.349784144427\n",
            "Epoch #1. Accuracy on batch 1274 on Training is 30.345588235294116\n",
            "Epoch #1. Accuracy on batch 1275 on Training is 30.346297021943574\n",
            "Epoch #1. Accuracy on batch 1276 on Training is 30.33966327329679\n",
            "Epoch #1. Accuracy on batch 1277 on Training is 30.337930359937403\n",
            "Epoch #1. Accuracy on batch 1278 on Training is 30.33131352619234\n",
            "Epoch #1. Accuracy on batch 1279 on Training is 30.3369140625\n",
            "Batch Id 1280 is having training loss of 1661.3975830078125\n",
            "48.12070846557617\n",
            "Epoch #1. Accuracy on batch 1280 on Training is 30.337626854020296\n",
            "Epoch #1. Accuracy on batch 1281 on Training is 30.34565132605304\n",
            "Epoch #1. Accuracy on batch 1282 on Training is 30.343920498830865\n",
            "Epoch #1. Accuracy on batch 1283 on Training is 30.349493769470406\n",
            "Epoch #1. Accuracy on batch 1284 on Training is 30.33803501945525\n",
            "Epoch #1. Accuracy on batch 1285 on Training is 30.338744167962673\n",
            "Epoch #1. Accuracy on batch 1286 on Training is 30.33459595959596\n",
            "Epoch #1. Accuracy on batch 1287 on Training is 30.32802795031056\n",
            "Epoch #1. Accuracy on batch 1288 on Training is 30.331167571761053\n",
            "Epoch #1. Accuracy on batch 1289 on Training is 30.329457364341085\n",
            "Epoch #1. Accuracy on batch 1290 on Training is 30.327749806351665\n",
            "Epoch #1. Accuracy on batch 1291 on Training is 30.330882352941178\n",
            "Epoch #1. Accuracy on batch 1292 on Training is 30.31709203402939\n",
            "Epoch #1. Accuracy on batch 1293 on Training is 30.317812982998454\n",
            "Epoch #1. Accuracy on batch 1294 on Training is 30.32335907335907\n",
            "Epoch #1. Accuracy on batch 1295 on Training is 30.326485339506174\n",
            "Epoch #1. Accuracy on batch 1296 on Training is 30.317559753276793\n",
            "Epoch #1. Accuracy on batch 1297 on Training is 30.3182781201849\n",
            "Epoch #1. Accuracy on batch 1298 on Training is 30.318995381062354\n",
            "Epoch #1. Accuracy on batch 1299 on Training is 30.3125\n",
            "Batch Id 1300 is having training loss of 1643.0262451171875\n",
            "79.83758544921875\n",
            "Epoch #1. Accuracy on batch 1300 on Training is 30.310818601076097\n",
            "Epoch #1. Accuracy on batch 1301 on Training is 30.31634024577573\n",
            "Epoch #1. Accuracy on batch 1302 on Training is 30.312260168841135\n",
            "Epoch #1. Accuracy on batch 1303 on Training is 30.312979294478527\n",
            "Epoch #1. Accuracy on batch 1304 on Training is 30.318486590038315\n",
            "Epoch #1. Accuracy on batch 1305 on Training is 30.307235834609493\n",
            "Epoch #1. Accuracy on batch 1306 on Training is 30.30317521040551\n",
            "Epoch #1. Accuracy on batch 1307 on Training is 30.30150993883792\n",
            "Epoch #1. Accuracy on batch 1308 on Training is 30.302234530175706\n",
            "Epoch #1. Accuracy on batch 1309 on Training is 30.30534351145038\n",
            "Epoch #1. Accuracy on batch 1310 on Training is 30.306064073226544\n",
            "Epoch #1. Accuracy on batch 1311 on Training is 30.30201981707317\n",
            "Epoch #1. Accuracy on batch 1312 on Training is 30.307501904036556\n",
            "Epoch #1. Accuracy on batch 1313 on Training is 30.303462709284627\n",
            "Epoch #1. Accuracy on batch 1314 on Training is 30.297053231939163\n",
            "Epoch #1. Accuracy on batch 1315 on Training is 30.29302811550152\n",
            "Epoch #1. Accuracy on batch 1316 on Training is 30.29375474563402\n",
            "Epoch #1. Accuracy on batch 1317 on Training is 30.28973823975721\n",
            "Epoch #1. Accuracy on batch 1318 on Training is 30.29046626231994\n",
            "Epoch #1. Accuracy on batch 1319 on Training is 30.305397727272727\n",
            "Batch Id 1320 is having training loss of 1637.7550048828125\n",
            "2882.85546875\n",
            "Epoch #1. Accuracy on batch 1320 on Training is 30.2942846328539\n",
            "Epoch #1. Accuracy on batch 1321 on Training is 30.28555219364599\n",
            "Epoch #1. Accuracy on batch 1322 on Training is 30.28628117913832\n",
            "Epoch #1. Accuracy on batch 1323 on Training is 30.28700906344411\n",
            "Epoch #1. Accuracy on batch 1324 on Training is 30.28301886792453\n",
            "Epoch #1. Accuracy on batch 1325 on Training is 30.283748114630466\n",
            "Epoch #1. Accuracy on batch 1326 on Training is 30.286831198191408\n",
            "Epoch #1. Accuracy on batch 1327 on Training is 30.278143825301203\n",
            "Epoch #1. Accuracy on batch 1328 on Training is 30.26946952595937\n",
            "Epoch #1. Accuracy on batch 1329 on Training is 30.267857142857142\n",
            "Epoch #1. Accuracy on batch 1330 on Training is 30.268595041322314\n",
            "Epoch #1. Accuracy on batch 1331 on Training is 30.27167792792793\n",
            "Epoch #1. Accuracy on batch 1332 on Training is 30.284133533383347\n",
            "Epoch #1. Accuracy on batch 1333 on Training is 30.270802098950526\n",
            "Epoch #1. Accuracy on batch 1334 on Training is 30.280898876404493\n",
            "Epoch #1. Accuracy on batch 1335 on Training is 30.281624251497007\n",
            "Epoch #1. Accuracy on batch 1336 on Training is 30.275336574420344\n",
            "Epoch #1. Accuracy on batch 1337 on Training is 30.273729446935725\n",
            "Epoch #1. Accuracy on batch 1338 on Training is 30.27445855115758\n",
            "Epoch #1. Accuracy on batch 1339 on Training is 30.268190298507463\n",
            "Batch Id 1340 is having training loss of 1614.14111328125\n",
            "14.744853973388672\n",
            "Epoch #1. Accuracy on batch 1340 on Training is 30.282904548844147\n",
            "Epoch #1. Accuracy on batch 1341 on Training is 30.28362518628912\n",
            "Epoch #1. Accuracy on batch 1342 on Training is 30.275037230081907\n",
            "Epoch #1. Accuracy on batch 1343 on Training is 30.280412946428573\n",
            "Epoch #1. Accuracy on batch 1344 on Training is 30.274163568773233\n",
            "Epoch #1. Accuracy on batch 1345 on Training is 30.279531946508172\n",
            "Epoch #1. Accuracy on batch 1346 on Training is 30.282572383073497\n",
            "Epoch #1. Accuracy on batch 1347 on Training is 30.2763353115727\n",
            "Epoch #1. Accuracy on batch 1348 on Training is 30.284006671608598\n",
            "Epoch #1. Accuracy on batch 1349 on Training is 30.28472222222222\n",
            "Epoch #1. Accuracy on batch 1350 on Training is 30.287749814951887\n",
            "Epoch #1. Accuracy on batch 1351 on Training is 30.281527366863905\n",
            "Epoch #1. Accuracy on batch 1352 on Training is 30.279933481152995\n",
            "Epoch #1. Accuracy on batch 1353 on Training is 30.27141802067947\n",
            "Epoch #1. Accuracy on batch 1354 on Training is 30.267527675276753\n",
            "Epoch #1. Accuracy on batch 1355 on Training is 30.26133849557522\n",
            "Epoch #1. Accuracy on batch 1356 on Training is 30.2689756816507\n",
            "Epoch #1. Accuracy on batch 1357 on Training is 30.271999263622973\n",
            "Epoch #1. Accuracy on batch 1358 on Training is 30.272718910963945\n",
            "Epoch #1. Accuracy on batch 1359 on Training is 30.27573529411765\n",
            "Batch Id 1360 is having training loss of 1596.1170654296875\n",
            "13.638930320739746\n",
            "Epoch #1. Accuracy on batch 1360 on Training is 30.278747244673035\n",
            "Epoch #1. Accuracy on batch 1361 on Training is 30.27946035242291\n",
            "Epoch #1. Accuracy on batch 1362 on Training is 30.28475788701394\n",
            "Epoch #1. Accuracy on batch 1363 on Training is 30.28775659824047\n",
            "Epoch #1. Accuracy on batch 1364 on Training is 30.290750915750916\n",
            "Epoch #1. Accuracy on batch 1365 on Training is 30.2891654465593\n",
            "Epoch #1. Accuracy on batch 1366 on Training is 30.283010241404536\n",
            "Epoch #1. Accuracy on batch 1367 on Training is 30.281432748538013\n",
            "Epoch #1. Accuracy on batch 1368 on Training is 30.284422936449964\n",
            "Epoch #1. Accuracy on batch 1369 on Training is 30.273722627737225\n",
            "Epoch #1. Accuracy on batch 1370 on Training is 30.267596644784827\n",
            "Epoch #1. Accuracy on batch 1371 on Training is 30.263757288629737\n",
            "Epoch #1. Accuracy on batch 1372 on Training is 30.25992352512746\n",
            "Epoch #1. Accuracy on batch 1373 on Training is 30.267467248908297\n",
            "Epoch #1. Accuracy on batch 1374 on Training is 30.259090909090908\n",
            "Epoch #1. Accuracy on batch 1375 on Training is 30.248455668604652\n",
            "Epoch #1. Accuracy on batch 1376 on Training is 30.242374727668846\n",
            "Epoch #1. Accuracy on batch 1377 on Training is 30.24310595065312\n",
            "Epoch #1. Accuracy on batch 1378 on Training is 30.24836838288615\n",
            "Epoch #1. Accuracy on batch 1379 on Training is 30.246829710144926\n",
            "Batch Id 1380 is having training loss of 1593.3480224609375\n",
            "26.93751335144043\n",
            "Epoch #1. Accuracy on batch 1380 on Training is 30.247556118754527\n",
            "Epoch #1. Accuracy on batch 1381 on Training is 30.25506512301013\n",
            "Epoch #1. Accuracy on batch 1382 on Training is 30.262563268257413\n",
            "Epoch #1. Accuracy on batch 1383 on Training is 30.263276734104046\n",
            "Epoch #1. Accuracy on batch 1384 on Training is 30.270758122743683\n",
            "Epoch #1. Accuracy on batch 1385 on Training is 30.273719336219337\n",
            "Epoch #1. Accuracy on batch 1386 on Training is 30.27442321557318\n",
            "Epoch #1. Accuracy on batch 1387 on Training is 30.277377521613833\n",
            "Epoch #1. Accuracy on batch 1388 on Training is 30.278077753779698\n",
            "Epoch #1. Accuracy on batch 1389 on Training is 30.267535971223023\n",
            "Epoch #1. Accuracy on batch 1390 on Training is 30.263749101365924\n",
            "Epoch #1. Accuracy on batch 1391 on Training is 30.259967672413794\n",
            "Epoch #1. Accuracy on batch 1392 on Training is 30.25619167264896\n",
            "Epoch #1. Accuracy on batch 1393 on Training is 30.256904591104735\n",
            "Epoch #1. Accuracy on batch 1394 on Training is 30.253136200716845\n",
            "Epoch #1. Accuracy on batch 1395 on Training is 30.249373209169054\n",
            "Epoch #1. Accuracy on batch 1396 on Training is 30.25008947745168\n",
            "Epoch #1. Accuracy on batch 1397 on Training is 30.250804721030043\n",
            "Epoch #1. Accuracy on batch 1398 on Training is 30.24705146533238\n",
            "Epoch #1. Accuracy on batch 1399 on Training is 30.247767857142858\n",
            "Batch Id 1400 is having training loss of 1591.5413818359375\n",
            "21599.697265625\n",
            "Epoch #1. Accuracy on batch 1400 on Training is 30.237330478229836\n",
            "Epoch #1. Accuracy on batch 1401 on Training is 30.233594864479315\n",
            "Epoch #1. Accuracy on batch 1402 on Training is 30.225409836065573\n",
            "Epoch #1. Accuracy on batch 1403 on Training is 30.2261396011396\n",
            "Epoch #1. Accuracy on batch 1404 on Training is 30.22909252669039\n",
            "Epoch #1. Accuracy on batch 1405 on Training is 30.225373399715505\n",
            "Epoch #1. Accuracy on batch 1406 on Training is 30.23720682302772\n",
            "Epoch #1. Accuracy on batch 1407 on Training is 30.24014559659091\n",
            "Epoch #1. Accuracy on batch 1408 on Training is 30.227555003548616\n",
            "Epoch #1. Accuracy on batch 1409 on Training is 30.23049645390071\n",
            "Epoch #1. Accuracy on batch 1410 on Training is 30.23343373493976\n",
            "Epoch #1. Accuracy on batch 1411 on Training is 30.238580028328613\n",
            "Epoch #1. Accuracy on batch 1412 on Training is 30.243719037508846\n",
            "Epoch #1. Accuracy on batch 1413 on Training is 30.235590523338047\n",
            "Epoch #1. Accuracy on batch 1414 on Training is 30.229681978798588\n",
            "Epoch #1. Accuracy on batch 1415 on Training is 30.228195621468927\n",
            "Epoch #1. Accuracy on batch 1416 on Training is 30.22450599858857\n",
            "Epoch #1. Accuracy on batch 1417 on Training is 30.229636812411847\n",
            "Epoch #1. Accuracy on batch 1418 on Training is 30.23916490486258\n",
            "Epoch #1. Accuracy on batch 1419 on Training is 30.235475352112676\n",
            "Batch Id 1420 is having training loss of 1571.4185791015625\n",
            "1201.554443359375\n",
            "Epoch #1. Accuracy on batch 1420 on Training is 30.2185960591133\n",
            "Epoch #1. Accuracy on batch 1421 on Training is 30.219321378340364\n",
            "Epoch #1. Accuracy on batch 1422 on Training is 30.21784961349262\n",
            "Epoch #1. Accuracy on batch 1423 on Training is 30.227352528089888\n",
            "Epoch #1. Accuracy on batch 1424 on Training is 30.232456140350877\n",
            "Epoch #1. Accuracy on batch 1425 on Training is 30.235361150070126\n",
            "Epoch #1. Accuracy on batch 1426 on Training is 30.242641906096708\n",
            "Epoch #1. Accuracy on batch 1427 on Training is 30.241158963585434\n",
            "Epoch #1. Accuracy on batch 1428 on Training is 30.23311756473058\n",
            "Epoch #1. Accuracy on batch 1429 on Training is 30.23382867132867\n",
            "Epoch #1. Accuracy on batch 1430 on Training is 30.230171208944792\n",
            "Epoch #1. Accuracy on batch 1431 on Training is 30.228701117318437\n",
            "Epoch #1. Accuracy on batch 1432 on Training is 30.229413817166783\n",
            "Epoch #1. Accuracy on batch 1433 on Training is 30.223587866108787\n",
            "Epoch #1. Accuracy on batch 1434 on Training is 30.222125435540068\n",
            "Epoch #1. Accuracy on batch 1435 on Training is 30.21848885793872\n",
            "Epoch #1. Accuracy on batch 1436 on Training is 30.221381350034793\n",
            "Epoch #1. Accuracy on batch 1437 on Training is 30.23296244784423\n",
            "Epoch #1. Accuracy on batch 1438 on Training is 30.224982626824183\n",
            "Epoch #1. Accuracy on batch 1439 on Training is 30.223524305555557\n",
            "Batch Id 1440 is having training loss of 1556.129638671875\n",
            "24.925071716308594\n",
            "Epoch #1. Accuracy on batch 1440 on Training is 30.226405274115198\n",
            "Epoch #1. Accuracy on batch 1441 on Training is 30.22278085991678\n",
            "Epoch #1. Accuracy on batch 1442 on Training is 30.22565835065835\n",
            "Epoch #1. Accuracy on batch 1443 on Training is 30.232860110803323\n",
            "Epoch #1. Accuracy on batch 1444 on Training is 30.2378892733564\n",
            "Epoch #1. Accuracy on batch 1445 on Training is 30.242911479944674\n",
            "Epoch #1. Accuracy on batch 1446 on Training is 30.250086385625433\n",
            "Epoch #1. Accuracy on batch 1447 on Training is 30.25940953038674\n",
            "Epoch #1. Accuracy on batch 1448 on Training is 30.24715320910973\n",
            "Epoch #1. Accuracy on batch 1449 on Training is 30.247844827586206\n",
            "Epoch #1. Accuracy on batch 1450 on Training is 30.246381805651275\n",
            "Epoch #1. Accuracy on batch 1451 on Training is 30.24922520661157\n",
            "Epoch #1. Accuracy on batch 1452 on Training is 30.249913971094287\n",
            "Epoch #1. Accuracy on batch 1453 on Training is 30.239855570839065\n",
            "Epoch #1. Accuracy on batch 1454 on Training is 30.24484536082474\n",
            "Epoch #1. Accuracy on batch 1455 on Training is 30.260559752747252\n",
            "Epoch #1. Accuracy on batch 1456 on Training is 30.25694921070693\n",
            "Epoch #1. Accuracy on batch 1457 on Training is 30.255486968449933\n",
            "Epoch #1. Accuracy on batch 1458 on Training is 30.26045236463331\n",
            "Epoch #1. Accuracy on batch 1459 on Training is 30.26541095890411\n",
            "Batch Id 1460 is having training loss of 1545.551513671875\n",
            "22.15937614440918\n",
            "Epoch #1. Accuracy on batch 1460 on Training is 30.25966803559206\n",
            "Epoch #1. Accuracy on batch 1461 on Training is 30.25393296853625\n",
            "Epoch #1. Accuracy on batch 1462 on Training is 30.252477785372523\n",
            "Epoch #1. Accuracy on batch 1463 on Training is 30.263831967213115\n",
            "Epoch #1. Accuracy on batch 1464 on Training is 30.266638225255974\n",
            "Epoch #1. Accuracy on batch 1465 on Training is 30.26730900409277\n",
            "Epoch #1. Accuracy on batch 1466 on Training is 30.270109066121336\n",
            "Epoch #1. Accuracy on batch 1467 on Training is 30.275034059945504\n",
            "Epoch #1. Accuracy on batch 1468 on Training is 30.26931586113002\n",
            "Epoch #1. Accuracy on batch 1469 on Training is 30.269982993197278\n",
            "Epoch #1. Accuracy on batch 1470 on Training is 30.260027192386133\n",
            "Epoch #1. Accuracy on batch 1471 on Training is 30.269191576086957\n",
            "Epoch #1. Accuracy on batch 1472 on Training is 30.271978954514594\n",
            "Epoch #1. Accuracy on batch 1473 on Training is 30.270522388059703\n",
            "Epoch #1. Accuracy on batch 1474 on Training is 30.26906779661017\n",
            "Epoch #1. Accuracy on batch 1475 on Training is 30.271849593495936\n",
            "Epoch #1. Accuracy on batch 1476 on Training is 30.280974949221395\n",
            "Epoch #1. Accuracy on batch 1477 on Training is 30.283744925575103\n",
            "Epoch #1. Accuracy on batch 1478 on Training is 30.284398242055442\n",
            "Epoch #1. Accuracy on batch 1479 on Training is 30.278716216216218\n",
            "Batch Id 1480 is having training loss of 1528.16943359375\n",
            "25.105730056762695\n",
            "Epoch #1. Accuracy on batch 1480 on Training is 30.281482106684674\n",
            "Epoch #1. Accuracy on batch 1481 on Training is 30.282135627530366\n",
            "Epoch #1. Accuracy on batch 1482 on Training is 30.274359406608227\n",
            "Epoch #1. Accuracy on batch 1483 on Training is 30.275016846361186\n",
            "Epoch #1. Accuracy on batch 1484 on Training is 30.273569023569024\n",
            "Epoch #1. Accuracy on batch 1485 on Training is 30.270020188425303\n",
            "Epoch #1. Accuracy on batch 1486 on Training is 30.268577673167453\n",
            "Epoch #1. Accuracy on batch 1487 on Training is 30.258736559139784\n",
            "Epoch #1. Accuracy on batch 1488 on Training is 30.253106111484218\n",
            "Epoch #1. Accuracy on batch 1489 on Training is 30.253775167785236\n",
            "Epoch #1. Accuracy on batch 1490 on Training is 30.264922870556674\n",
            "Epoch #1. Accuracy on batch 1491 on Training is 30.26558310991957\n",
            "Epoch #1. Accuracy on batch 1492 on Training is 30.27461486939049\n",
            "Epoch #1. Accuracy on batch 1493 on Training is 30.28363453815261\n",
            "Epoch #1. Accuracy on batch 1494 on Training is 30.28010033444816\n",
            "Epoch #1. Accuracy on batch 1495 on Training is 30.28701537433155\n",
            "Epoch #1. Accuracy on batch 1496 on Training is 30.283483633934537\n",
            "Epoch #1. Accuracy on batch 1497 on Training is 30.28412883845127\n",
            "Epoch #1. Accuracy on batch 1498 on Training is 30.291027351567713\n",
            "Epoch #1. Accuracy on batch 1499 on Training is 30.28125\n",
            "Batch Id 1500 is having training loss of 1513.8621826171875\n",
            "20.135038375854492\n",
            "Epoch #1. Accuracy on batch 1500 on Training is 30.288141239173886\n",
            "Epoch #1. Accuracy on batch 1501 on Training is 30.29294274300932\n",
            "Epoch #1. Accuracy on batch 1502 on Training is 30.30813373253493\n",
            "Epoch #1. Accuracy on batch 1503 on Training is 30.308759973404257\n",
            "Epoch #1. Accuracy on batch 1504 on Training is 30.3156146179402\n",
            "Epoch #1. Accuracy on batch 1505 on Training is 30.307934926958833\n",
            "Epoch #1. Accuracy on batch 1506 on Training is 30.3085600530856\n",
            "Epoch #1. Accuracy on batch 1507 on Training is 30.3029675066313\n",
            "Epoch #1. Accuracy on batch 1508 on Training is 30.29945328031809\n",
            "Epoch #1. Accuracy on batch 1509 on Training is 30.29801324503311\n",
            "Epoch #1. Accuracy on batch 1510 on Training is 30.29657511581734\n",
            "Epoch #1. Accuracy on batch 1511 on Training is 30.299272486772487\n",
            "Epoch #1. Accuracy on batch 1512 on Training is 30.30609715796431\n",
            "Epoch #1. Accuracy on batch 1513 on Training is 30.306720607661823\n",
            "Epoch #1. Accuracy on batch 1514 on Training is 30.311468646864686\n",
            "Epoch #1. Accuracy on batch 1515 on Training is 30.320333113456464\n",
            "Epoch #1. Accuracy on batch 1516 on Training is 30.33124588002637\n",
            "Epoch #1. Accuracy on batch 1517 on Training is 30.33390974967062\n",
            "Epoch #1. Accuracy on batch 1518 on Training is 30.3303982883476\n",
            "Epoch #1. Accuracy on batch 1519 on Training is 30.322779605263158\n",
            "Batch Id 1520 is having training loss of 1498.11767578125\n",
            "15.580037117004395\n",
            "Epoch #1. Accuracy on batch 1520 on Training is 30.335716633793556\n",
            "Epoch #1. Accuracy on batch 1521 on Training is 30.33837056504599\n",
            "Epoch #1. Accuracy on batch 1522 on Training is 30.34307288246881\n",
            "Epoch #1. Accuracy on batch 1523 on Training is 30.33956692913386\n",
            "Epoch #1. Accuracy on batch 1524 on Training is 30.3422131147541\n",
            "Epoch #1. Accuracy on batch 1525 on Training is 30.34076015727392\n",
            "Epoch #1. Accuracy on batch 1526 on Training is 30.341355599214147\n",
            "Epoch #1. Accuracy on batch 1527 on Training is 30.341950261780106\n",
            "Epoch #1. Accuracy on batch 1528 on Training is 30.34254414650098\n",
            "Epoch #1. Accuracy on batch 1529 on Training is 30.34722222222222\n",
            "Epoch #1. Accuracy on batch 1530 on Training is 30.35189418680601\n",
            "Epoch #1. Accuracy on batch 1531 on Training is 30.358599869451698\n",
            "Epoch #1. Accuracy on batch 1532 on Training is 30.359181343770384\n",
            "Epoch #1. Accuracy on batch 1533 on Training is 30.36179921773142\n",
            "Epoch #1. Accuracy on batch 1534 on Training is 30.360342019543975\n",
            "Epoch #1. Accuracy on batch 1535 on Training is 30.362955729166668\n",
            "Epoch #1. Accuracy on batch 1536 on Training is 30.367599219258295\n",
            "Epoch #1. Accuracy on batch 1537 on Training is 30.3722366710013\n",
            "Epoch #1. Accuracy on batch 1538 on Training is 30.370776478232617\n",
            "Epoch #1. Accuracy on batch 1539 on Training is 30.367288961038962\n",
            "Batch Id 1540 is having training loss of 1515.6036376953125\n",
            "26.478347778320312\n",
            "Epoch #1. Accuracy on batch 1540 on Training is 30.36988968202466\n",
            "Epoch #1. Accuracy on batch 1541 on Training is 30.364380674448768\n",
            "Epoch #1. Accuracy on batch 1542 on Training is 30.35685353208036\n",
            "Epoch #1. Accuracy on batch 1543 on Training is 30.347312176165804\n",
            "Epoch #1. Accuracy on batch 1544 on Training is 30.34991909385113\n",
            "Epoch #1. Accuracy on batch 1545 on Training is 30.352522639068564\n",
            "Epoch #1. Accuracy on batch 1546 on Training is 30.351082740788623\n",
            "Epoch #1. Accuracy on batch 1547 on Training is 30.353682170542637\n",
            "Epoch #1. Accuracy on batch 1548 on Training is 30.350225952227245\n",
            "Epoch #1. Accuracy on batch 1549 on Training is 30.346774193548388\n",
            "Epoch #1. Accuracy on batch 1550 on Training is 30.345341715022567\n",
            "Epoch #1. Accuracy on batch 1551 on Training is 30.34592461340206\n",
            "Epoch #1. Accuracy on batch 1552 on Training is 30.350531229877657\n",
            "Epoch #1. Accuracy on batch 1553 on Training is 30.359153796653796\n",
            "Epoch #1. Accuracy on batch 1554 on Training is 30.355707395498392\n",
            "Epoch #1. Accuracy on batch 1555 on Training is 30.352265424164525\n",
            "Epoch #1. Accuracy on batch 1556 on Training is 30.36087026332691\n",
            "Epoch #1. Accuracy on batch 1557 on Training is 30.3594351732991\n",
            "Epoch #1. Accuracy on batch 1558 on Training is 30.362010904425915\n",
            "Epoch #1. Accuracy on batch 1559 on Training is 30.362580128205128\n",
            "Batch Id 1560 is having training loss of 1597.3505859375\n",
            "2759.86181640625\n",
            "Epoch #1. Accuracy on batch 1560 on Training is 30.355140935297886\n",
            "Epoch #1. Accuracy on batch 1561 on Training is 30.34571062740077\n",
            "Epoch #1. Accuracy on batch 1562 on Training is 30.34029110684581\n",
            "Epoch #1. Accuracy on batch 1563 on Training is 30.330882352941178\n",
            "Epoch #1. Accuracy on batch 1564 on Training is 30.32747603833866\n",
            "Epoch #1. Accuracy on batch 1565 on Training is 30.326069604086847\n",
            "Epoch #1. Accuracy on batch 1566 on Training is 30.326659221442245\n",
            "Epoch #1. Accuracy on batch 1567 on Training is 30.325255102040817\n",
            "Epoch #1. Accuracy on batch 1568 on Training is 30.327836201402167\n",
            "Epoch #1. Accuracy on batch 1569 on Training is 30.328423566878982\n",
            "Epoch #1. Accuracy on batch 1570 on Training is 30.338956078930618\n",
            "Epoch #1. Accuracy on batch 1571 on Training is 30.333571882951652\n",
            "Epoch #1. Accuracy on batch 1572 on Training is 30.336141131595678\n",
            "Epoch #1. Accuracy on batch 1573 on Training is 30.336721728081322\n",
            "Epoch #1. Accuracy on batch 1574 on Training is 30.331349206349206\n",
            "Epoch #1. Accuracy on batch 1575 on Training is 30.341846446700508\n",
            "Epoch #1. Accuracy on batch 1576 on Training is 30.340440710209258\n",
            "Epoch #1. Accuracy on batch 1577 on Training is 30.33705640050697\n",
            "Epoch #1. Accuracy on batch 1578 on Training is 30.333676377454086\n",
            "Epoch #1. Accuracy on batch 1579 on Training is 30.332278481012658\n",
            "Batch Id 1580 is having training loss of 1621.835205078125\n",
            "18.69944190979004\n",
            "Epoch #1. Accuracy on batch 1580 on Training is 30.332858950031625\n",
            "Epoch #1. Accuracy on batch 1581 on Training is 30.335414032869785\n",
            "Epoch #1. Accuracy on batch 1582 on Training is 30.337965887555274\n",
            "Epoch #1. Accuracy on batch 1583 on Training is 30.33459595959596\n",
            "Epoch #1. Accuracy on batch 1584 on Training is 30.327287066246058\n",
            "Epoch #1. Accuracy on batch 1585 on Training is 30.327868852459016\n",
            "Epoch #1. Accuracy on batch 1586 on Training is 30.310727788279774\n",
            "Epoch #1. Accuracy on batch 1587 on Training is 30.307383501259444\n",
            "Epoch #1. Accuracy on batch 1588 on Training is 30.296176840780365\n",
            "Epoch #1. Accuracy on batch 1589 on Training is 30.28694968553459\n",
            "Epoch #1. Accuracy on batch 1590 on Training is 30.279698302954117\n",
            "Epoch #1. Accuracy on batch 1591 on Training is 30.27834484924623\n",
            "Epoch #1. Accuracy on batch 1592 on Training is 30.282878217200253\n",
            "Epoch #1. Accuracy on batch 1593 on Training is 30.28348494353827\n",
            "Epoch #1. Accuracy on batch 1594 on Training is 30.282131661442005\n",
            "Epoch #1. Accuracy on batch 1595 on Training is 30.28078007518797\n",
            "Epoch #1. Accuracy on batch 1596 on Training is 30.277473387601752\n",
            "Epoch #1. Accuracy on batch 1597 on Training is 30.281993116395494\n",
            "Epoch #1. Accuracy on batch 1598 on Training is 30.28846153846154\n",
            "Epoch #1. Accuracy on batch 1599 on Training is 30.283203125\n",
            "Batch Id 1600 is having training loss of 1671.864013671875\n",
            "76.75373077392578\n",
            "Epoch #1. Accuracy on batch 1600 on Training is 30.293566520924422\n",
            "Epoch #1. Accuracy on batch 1601 on Training is 30.298064918851434\n",
            "Epoch #1. Accuracy on batch 1602 on Training is 30.3006082345602\n",
            "Epoch #1. Accuracy on batch 1603 on Training is 30.305096633416458\n",
            "Epoch #1. Accuracy on batch 1604 on Training is 30.28816199376947\n",
            "Epoch #1. Accuracy on batch 1605 on Training is 30.290706724782066\n",
            "Epoch #1. Accuracy on batch 1606 on Training is 30.2835252022402\n",
            "Epoch #1. Accuracy on batch 1607 on Training is 30.276352611940297\n",
            "Epoch #1. Accuracy on batch 1608 on Training is 30.273073337476692\n",
            "Epoch #1. Accuracy on batch 1609 on Training is 30.275621118012424\n",
            "Epoch #1. Accuracy on batch 1610 on Training is 30.276225946617007\n",
            "Epoch #1. Accuracy on batch 1611 on Training is 30.269075682382134\n",
            "Epoch #1. Accuracy on batch 1612 on Training is 30.263871667699938\n",
            "Epoch #1. Accuracy on batch 1613 on Training is 30.258674101610904\n",
            "Epoch #1. Accuracy on batch 1614 on Training is 30.2515479876161\n",
            "Epoch #1. Accuracy on batch 1615 on Training is 30.257967202970296\n",
            "Epoch #1. Accuracy on batch 1616 on Training is 30.25278293135436\n",
            "Epoch #1. Accuracy on batch 1617 on Training is 30.257262051915944\n",
            "Epoch #1. Accuracy on batch 1618 on Training is 30.252084620135886\n",
            "Epoch #1. Accuracy on batch 1619 on Training is 30.250771604938272\n",
            "Batch Id 1620 is having training loss of 1702.454345703125\n",
            "35.08816146850586\n",
            "Epoch #1. Accuracy on batch 1620 on Training is 30.25524367674275\n",
            "Epoch #1. Accuracy on batch 1621 on Training is 30.25393033292232\n",
            "Epoch #1. Accuracy on batch 1622 on Training is 30.254544054220577\n",
            "Epoch #1. Accuracy on batch 1623 on Training is 30.251308497536947\n",
            "Epoch #1. Accuracy on batch 1624 on Training is 30.24230769230769\n",
            "Epoch #1. Accuracy on batch 1625 on Training is 30.237161746617467\n",
            "Epoch #1. Accuracy on batch 1626 on Training is 30.235863552550708\n",
            "Epoch #1. Accuracy on batch 1627 on Training is 30.228808353808354\n",
            "Epoch #1. Accuracy on batch 1628 on Training is 30.221761817065683\n",
            "Epoch #1. Accuracy on batch 1629 on Training is 30.2204754601227\n",
            "Epoch #1. Accuracy on batch 1630 on Training is 30.223022685469036\n",
            "Epoch #1. Accuracy on batch 1631 on Training is 30.223651960784313\n",
            "Epoch #1. Accuracy on batch 1632 on Training is 30.22236680955297\n",
            "Epoch #1. Accuracy on batch 1633 on Training is 30.226820685434518\n",
            "Epoch #1. Accuracy on batch 1634 on Training is 30.22362385321101\n",
            "Epoch #1. Accuracy on batch 1635 on Training is 30.226161369193154\n",
            "Epoch #1. Accuracy on batch 1636 on Training is 30.226786805131336\n",
            "Epoch #1. Accuracy on batch 1637 on Training is 30.231227106227106\n",
            "Epoch #1. Accuracy on batch 1638 on Training is 30.226128737034777\n",
            "Epoch #1. Accuracy on batch 1639 on Training is 30.226753048780488\n",
            "Batch Id 1640 is having training loss of 1710.16650390625\n",
            "20.74591636657715\n",
            "Epoch #1. Accuracy on batch 1640 on Training is 30.23308957952468\n",
            "Epoch #1. Accuracy on batch 1641 on Training is 30.22419305724726\n",
            "Epoch #1. Accuracy on batch 1642 on Training is 30.224817407181984\n",
            "Epoch #1. Accuracy on batch 1643 on Training is 30.233044403892944\n",
            "Epoch #1. Accuracy on batch 1644 on Training is 30.227963525835865\n",
            "Epoch #1. Accuracy on batch 1645 on Training is 30.224787363304984\n",
            "Epoch #1. Accuracy on batch 1646 on Training is 30.21782027929569\n",
            "Epoch #1. Accuracy on batch 1647 on Training is 30.227927791262136\n",
            "Epoch #1. Accuracy on batch 1648 on Training is 30.228547604608853\n",
            "Epoch #1. Accuracy on batch 1649 on Training is 30.227272727272727\n",
            "Epoch #1. Accuracy on batch 1650 on Training is 30.227892186553603\n",
            "Epoch #1. Accuracy on batch 1651 on Training is 30.226619249394673\n",
            "Epoch #1. Accuracy on batch 1652 on Training is 30.225347852389596\n",
            "Epoch #1. Accuracy on batch 1653 on Training is 30.220299274486095\n",
            "Epoch #1. Accuracy on batch 1654 on Training is 30.222809667673715\n",
            "Epoch #1. Accuracy on batch 1655 on Training is 30.22342995169082\n",
            "Epoch #1. Accuracy on batch 1656 on Training is 30.225935425467714\n",
            "Epoch #1. Accuracy on batch 1657 on Training is 30.217129071170085\n",
            "Epoch #1. Accuracy on batch 1658 on Training is 30.213984327908378\n",
            "Epoch #1. Accuracy on batch 1659 on Training is 30.22402108433735\n",
            "Batch Id 1660 is having training loss of 1702.531005859375\n",
            "385.5712890625\n",
            "Epoch #1. Accuracy on batch 1660 on Training is 30.224638771824203\n",
            "Epoch #1. Accuracy on batch 1661 on Training is 30.229016245487365\n",
            "Epoch #1. Accuracy on batch 1662 on Training is 30.222113650030067\n",
            "Epoch #1. Accuracy on batch 1663 on Training is 30.21521935096154\n",
            "Epoch #1. Accuracy on batch 1664 on Training is 30.21021021021021\n",
            "Epoch #1. Accuracy on batch 1665 on Training is 30.208958583433372\n",
            "Epoch #1. Accuracy on batch 1666 on Training is 30.20395920815837\n",
            "Epoch #1. Accuracy on batch 1667 on Training is 30.208333333333332\n",
            "Epoch #1. Accuracy on batch 1668 on Training is 30.205212702216897\n",
            "Epoch #1. Accuracy on batch 1669 on Training is 30.205838323353294\n",
            "Epoch #1. Accuracy on batch 1670 on Training is 30.206463195691203\n",
            "Epoch #1. Accuracy on batch 1671 on Training is 30.205218301435405\n",
            "Epoch #1. Accuracy on batch 1672 on Training is 30.20397489539749\n",
            "Epoch #1. Accuracy on batch 1673 on Training is 30.21206690561529\n",
            "Epoch #1. Accuracy on batch 1674 on Training is 30.21082089552239\n",
            "Epoch #1. Accuracy on batch 1675 on Training is 30.207711813842483\n",
            "Epoch #1. Accuracy on batch 1676 on Training is 30.213923673226\n",
            "Epoch #1. Accuracy on batch 1677 on Training is 30.197780095351607\n",
            "Epoch #1. Accuracy on batch 1678 on Training is 30.198406789755808\n",
            "Epoch #1. Accuracy on batch 1679 on Training is 30.19717261904762\n",
            "Batch Id 1680 is having training loss of 1713.40869140625\n",
            "48.134765625\n",
            "Epoch #1. Accuracy on batch 1680 on Training is 30.19036287923855\n",
            "Epoch #1. Accuracy on batch 1681 on Training is 30.190992865636147\n",
            "Epoch #1. Accuracy on batch 1682 on Training is 30.189765300059417\n",
            "Epoch #1. Accuracy on batch 1683 on Training is 30.197817695961994\n",
            "Epoch #1. Accuracy on batch 1684 on Training is 30.207715133531156\n",
            "Epoch #1. Accuracy on batch 1685 on Training is 30.210186832740213\n",
            "Epoch #1. Accuracy on batch 1686 on Training is 30.205245998814462\n",
            "Epoch #1. Accuracy on batch 1687 on Training is 30.205864928909953\n",
            "Epoch #1. Accuracy on batch 1688 on Training is 30.197232089994078\n",
            "Epoch #1. Accuracy on batch 1689 on Training is 30.1978550295858\n",
            "Epoch #1. Accuracy on batch 1690 on Training is 30.196629213483146\n",
            "Epoch #1. Accuracy on batch 1691 on Training is 30.20463947990544\n",
            "Epoch #1. Accuracy on batch 1692 on Training is 30.20156526875369\n",
            "Epoch #1. Accuracy on batch 1693 on Training is 30.19849468713105\n",
            "Epoch #1. Accuracy on batch 1694 on Training is 30.200958702064895\n",
            "Epoch #1. Accuracy on batch 1695 on Training is 30.203419811320753\n",
            "Epoch #1. Accuracy on batch 1696 on Training is 30.202195050088392\n",
            "Epoch #1. Accuracy on batch 1697 on Training is 30.200971731448764\n",
            "Epoch #1. Accuracy on batch 1698 on Training is 30.19974985285462\n",
            "Epoch #1. Accuracy on batch 1699 on Training is 30.19485294117647\n",
            "Batch Id 1700 is having training loss of 1702.501708984375\n",
            "60.13502502441406\n",
            "Epoch #1. Accuracy on batch 1700 on Training is 30.18996178718401\n",
            "Epoch #1. Accuracy on batch 1701 on Training is 30.186912455934195\n",
            "Epoch #1. Accuracy on batch 1702 on Training is 30.178361714621257\n",
            "Epoch #1. Accuracy on batch 1703 on Training is 30.18449237089202\n",
            "Epoch #1. Accuracy on batch 1704 on Training is 30.183284457478006\n",
            "Epoch #1. Accuracy on batch 1705 on Training is 30.18207796014068\n",
            "Epoch #1. Accuracy on batch 1706 on Training is 30.17538078500293\n",
            "Epoch #1. Accuracy on batch 1707 on Training is 30.181498829039814\n",
            "Epoch #1. Accuracy on batch 1708 on Training is 30.183952603861908\n",
            "Epoch #1. Accuracy on batch 1709 on Training is 30.179093567251464\n",
            "Epoch #1. Accuracy on batch 1710 on Training is 30.18154587960257\n",
            "Epoch #1. Accuracy on batch 1711 on Training is 30.191296728971963\n",
            "Epoch #1. Accuracy on batch 1712 on Training is 30.191914769410392\n",
            "Epoch #1. Accuracy on batch 1713 on Training is 30.198001750291716\n",
            "Epoch #1. Accuracy on batch 1714 on Training is 30.196793002915452\n",
            "Epoch #1. Accuracy on batch 1715 on Training is 30.199227855477854\n",
            "Epoch #1. Accuracy on batch 1716 on Training is 30.198019801980198\n",
            "Epoch #1. Accuracy on batch 1717 on Training is 30.202270081490106\n",
            "Epoch #1. Accuracy on batch 1718 on Training is 30.202879581151834\n",
            "Epoch #1. Accuracy on batch 1719 on Training is 30.20530523255814\n",
            "Batch Id 1720 is having training loss of 1698.9036865234375\n",
            "9.111139297485352\n",
            "Epoch #1. Accuracy on batch 1720 on Training is 30.209543869843113\n",
            "Epoch #1. Accuracy on batch 1721 on Training is 30.213777584204415\n",
            "Epoch #1. Accuracy on batch 1722 on Training is 30.21437899013349\n",
            "Epoch #1. Accuracy on batch 1723 on Training is 30.21316705336427\n",
            "Epoch #1. Accuracy on batch 1724 on Training is 30.213768115942027\n",
            "Epoch #1. Accuracy on batch 1725 on Training is 30.214368482039397\n",
            "Epoch #1. Accuracy on batch 1726 on Training is 30.21677764910249\n",
            "Epoch #1. Accuracy on batch 1727 on Training is 30.21014178240741\n",
            "Epoch #1. Accuracy on batch 1728 on Training is 30.196283979178716\n",
            "Epoch #1. Accuracy on batch 1729 on Training is 30.19508670520231\n",
            "Epoch #1. Accuracy on batch 1730 on Training is 30.19028018486424\n",
            "Epoch #1. Accuracy on batch 1731 on Training is 30.192696304849886\n",
            "Epoch #1. Accuracy on batch 1732 on Training is 30.18429024812464\n",
            "Epoch #1. Accuracy on batch 1733 on Training is 30.184904844290656\n",
            "Epoch #1. Accuracy on batch 1734 on Training is 30.187319884726225\n",
            "Epoch #1. Accuracy on batch 1735 on Training is 30.186131912442395\n",
            "Epoch #1. Accuracy on batch 1736 on Training is 30.184945308002302\n",
            "Epoch #1. Accuracy on batch 1737 on Training is 30.181962025316455\n",
            "Epoch #1. Accuracy on batch 1738 on Training is 30.18257619321449\n",
            "Epoch #1. Accuracy on batch 1739 on Training is 30.184985632183906\n",
            "Batch Id 1740 is having training loss of 1703.7021484375\n",
            "31.920196533203125\n",
            "Epoch #1. Accuracy on batch 1740 on Training is 30.185597357840322\n",
            "Epoch #1. Accuracy on batch 1741 on Training is 30.1826205510907\n",
            "Epoch #1. Accuracy on batch 1742 on Training is 30.18323293172691\n",
            "Epoch #1. Accuracy on batch 1743 on Training is 30.178469036697248\n",
            "Epoch #1. Accuracy on batch 1744 on Training is 30.173710601719197\n",
            "Epoch #1. Accuracy on batch 1745 on Training is 30.170747422680414\n",
            "Epoch #1. Accuracy on batch 1746 on Training is 30.16599885518031\n",
            "Epoch #1. Accuracy on batch 1747 on Training is 30.16661899313501\n",
            "Epoch #1. Accuracy on batch 1748 on Training is 30.1654516866781\n",
            "Epoch #1. Accuracy on batch 1749 on Training is 30.167857142857144\n",
            "Epoch #1. Accuracy on batch 1750 on Training is 30.168475157053113\n",
            "Epoch #1. Accuracy on batch 1751 on Training is 30.167308789954337\n",
            "Epoch #1. Accuracy on batch 1752 on Training is 30.167926411865373\n",
            "Epoch #1. Accuracy on batch 1753 on Training is 30.170324971493727\n",
            "Epoch #1. Accuracy on batch 1754 on Training is 30.174501424501425\n",
            "Epoch #1. Accuracy on batch 1755 on Training is 30.171554669703873\n",
            "Epoch #1. Accuracy on batch 1756 on Training is 30.175725668753557\n",
            "Epoch #1. Accuracy on batch 1757 on Training is 30.171003981797497\n",
            "Epoch #1. Accuracy on batch 1758 on Training is 30.16451108584423\n",
            "Epoch #1. Accuracy on batch 1759 on Training is 30.161576704545453\n",
            "Batch Id 1760 is having training loss of 1706.7177734375\n",
            "209.60409545898438\n",
            "Epoch #1. Accuracy on batch 1760 on Training is 30.160420215786484\n",
            "Epoch #1. Accuracy on batch 1761 on Training is 30.168132803632236\n",
            "Epoch #1. Accuracy on batch 1762 on Training is 30.168746454906408\n",
            "Epoch #1. Accuracy on batch 1763 on Training is 30.165816326530614\n",
            "Epoch #1. Accuracy on batch 1764 on Training is 30.16643059490085\n",
            "Epoch #1. Accuracy on batch 1765 on Training is 30.16527463193658\n",
            "Epoch #1. Accuracy on batch 1766 on Training is 30.160582908885115\n",
            "Epoch #1. Accuracy on batch 1767 on Training is 30.159431561085974\n",
            "Epoch #1. Accuracy on batch 1768 on Training is 30.161814584511024\n",
            "Epoch #1. Accuracy on batch 1769 on Training is 30.158898305084747\n",
            "Epoch #1. Accuracy on batch 1770 on Training is 30.15422077922078\n",
            "Epoch #1. Accuracy on batch 1771 on Training is 30.15660270880361\n",
            "Epoch #1. Accuracy on batch 1772 on Training is 30.158981951494642\n",
            "Epoch #1. Accuracy on batch 1773 on Training is 30.159596956031567\n",
            "Epoch #1. Accuracy on batch 1774 on Training is 30.154929577464788\n",
            "Epoch #1. Accuracy on batch 1775 on Training is 30.15554617117117\n",
            "Epoch #1. Accuracy on batch 1776 on Training is 30.150886325267304\n",
            "Epoch #1. Accuracy on batch 1777 on Training is 30.14623172103487\n",
            "Epoch #1. Accuracy on batch 1778 on Training is 30.146852164137155\n",
            "Epoch #1. Accuracy on batch 1779 on Training is 30.140449438202246\n",
            "Batch Id 1780 is having training loss of 1695.5230712890625\n",
            "23.74198341369629\n",
            "Epoch #1. Accuracy on batch 1780 on Training is 30.141072431218415\n",
            "Epoch #1. Accuracy on batch 1781 on Training is 30.14344837261504\n",
            "Epoch #1. Accuracy on batch 1782 on Training is 30.152832305103757\n",
            "Epoch #1. Accuracy on batch 1783 on Training is 30.15519899103139\n",
            "Epoch #1. Accuracy on batch 1784 on Training is 30.159313725490197\n",
            "Epoch #1. Accuracy on batch 1785 on Training is 30.1511758118701\n",
            "Epoch #1. Accuracy on batch 1786 on Training is 30.157036933407948\n",
            "Epoch #1. Accuracy on batch 1787 on Training is 30.161143736017898\n",
            "Epoch #1. Accuracy on batch 1788 on Training is 30.158258803801004\n",
            "Epoch #1. Accuracy on batch 1789 on Training is 30.1588687150838\n",
            "Epoch #1. Accuracy on batch 1790 on Training is 30.162967615857063\n",
            "Epoch #1. Accuracy on batch 1791 on Training is 30.161830357142858\n",
            "Epoch #1. Accuracy on batch 1792 on Training is 30.165923034021194\n",
            "Epoch #1. Accuracy on batch 1793 on Training is 30.166527313266442\n",
            "Epoch #1. Accuracy on batch 1794 on Training is 30.15842618384401\n",
            "Epoch #1. Accuracy on batch 1795 on Training is 30.1538140311804\n",
            "Epoch #1. Accuracy on batch 1796 on Training is 30.152685030606566\n",
            "Epoch #1. Accuracy on batch 1797 on Training is 30.151557285873192\n",
            "Epoch #1. Accuracy on batch 1798 on Training is 30.14869371873263\n",
            "Epoch #1. Accuracy on batch 1799 on Training is 30.15277777777778\n",
            "Batch Id 1800 is having training loss of 1682.5447998046875\n",
            "29.24903106689453\n",
            "Epoch #1. Accuracy on batch 1800 on Training is 30.14818156579678\n",
            "Epoch #1. Accuracy on batch 1801 on Training is 30.162666481687015\n",
            "Epoch #1. Accuracy on batch 1802 on Training is 30.161536328341654\n",
            "Epoch #1. Accuracy on batch 1803 on Training is 30.162139689578716\n",
            "Epoch #1. Accuracy on batch 1804 on Training is 30.164473684210527\n",
            "Epoch #1. Accuracy on batch 1805 on Training is 30.165074750830566\n",
            "Epoch #1. Accuracy on batch 1806 on Training is 30.167404537908133\n",
            "Epoch #1. Accuracy on batch 1807 on Training is 30.17146017699115\n",
            "Epoch #1. Accuracy on batch 1808 on Training is 30.170328911000553\n",
            "Epoch #1. Accuracy on batch 1809 on Training is 30.167472375690608\n",
            "Epoch #1. Accuracy on batch 1810 on Training is 30.16461899503037\n",
            "Epoch #1. Accuracy on batch 1811 on Training is 30.166942604856512\n",
            "Epoch #1. Accuracy on batch 1812 on Training is 30.165816326530614\n",
            "Epoch #1. Accuracy on batch 1813 on Training is 30.169859426681366\n",
            "Epoch #1. Accuracy on batch 1814 on Training is 30.173898071625345\n",
            "Epoch #1. Accuracy on batch 1815 on Training is 30.171049008810574\n",
            "Epoch #1. Accuracy on batch 1816 on Training is 30.16648321408916\n",
            "Epoch #1. Accuracy on batch 1817 on Training is 30.161922442244226\n",
            "Epoch #1. Accuracy on batch 1818 on Training is 30.162520615722926\n",
            "Epoch #1. Accuracy on batch 1819 on Training is 30.1510989010989\n",
            "Batch Id 1820 is having training loss of 1669.9158935546875\n",
            "40.180423736572266\n",
            "Epoch #1. Accuracy on batch 1820 on Training is 30.14827018121911\n",
            "Epoch #1. Accuracy on batch 1821 on Training is 30.15059001097695\n",
            "Epoch #1. Accuracy on batch 1822 on Training is 30.158049917718046\n",
            "Epoch #1. Accuracy on batch 1823 on Training is 30.155222039473685\n",
            "Epoch #1. Accuracy on batch 1824 on Training is 30.15582191780822\n",
            "Epoch #1. Accuracy on batch 1825 on Training is 30.156421139101862\n",
            "Epoch #1. Accuracy on batch 1826 on Training is 30.158730158730158\n",
            "Epoch #1. Accuracy on batch 1827 on Training is 30.155908096280086\n",
            "Epoch #1. Accuracy on batch 1828 on Training is 30.15138053581192\n",
            "Epoch #1. Accuracy on batch 1829 on Training is 30.14856557377049\n",
            "Epoch #1. Accuracy on batch 1830 on Training is 30.14746040415074\n",
            "Epoch #1. Accuracy on batch 1831 on Training is 30.15829694323144\n",
            "Epoch #1. Accuracy on batch 1832 on Training is 30.15718767048554\n",
            "Epoch #1. Accuracy on batch 1833 on Training is 30.16119138495093\n",
            "Epoch #1. Accuracy on batch 1834 on Training is 30.15156675749319\n",
            "Epoch #1. Accuracy on batch 1835 on Training is 30.15216503267974\n",
            "Epoch #1. Accuracy on batch 1836 on Training is 30.151061513336963\n",
            "Epoch #1. Accuracy on batch 1837 on Training is 30.143158324265507\n",
            "Epoch #1. Accuracy on batch 1838 on Training is 30.14715878194671\n",
            "Epoch #1. Accuracy on batch 1839 on Training is 30.151154891304348\n",
            "Batch Id 1840 is having training loss of 1652.710693359375\n",
            "16.095396041870117\n",
            "Epoch #1. Accuracy on batch 1840 on Training is 30.146659424225962\n",
            "Epoch #1. Accuracy on batch 1841 on Training is 30.145561889250814\n",
            "Epoch #1. Accuracy on batch 1842 on Training is 30.141074335322845\n",
            "Epoch #1. Accuracy on batch 1843 on Training is 30.13320227765727\n",
            "Epoch #1. Accuracy on batch 1844 on Training is 30.12872628726287\n",
            "Epoch #1. Accuracy on batch 1845 on Training is 30.134412242686892\n",
            "Epoch #1. Accuracy on batch 1846 on Training is 30.133324309691393\n",
            "Epoch #1. Accuracy on batch 1847 on Training is 30.133928571428573\n",
            "Epoch #1. Accuracy on batch 1848 on Training is 30.13960248783126\n",
            "Epoch #1. Accuracy on batch 1849 on Training is 30.14695945945946\n",
            "Epoch #1. Accuracy on batch 1850 on Training is 30.14080226904376\n",
            "Epoch #1. Accuracy on batch 1851 on Training is 30.134651727861772\n",
            "Epoch #1. Accuracy on batch 1852 on Training is 30.14031300593632\n",
            "Epoch #1. Accuracy on batch 1853 on Training is 30.134169363538295\n",
            "Epoch #1. Accuracy on batch 1854 on Training is 30.13814016172507\n",
            "Epoch #1. Accuracy on batch 1855 on Training is 30.138739224137932\n",
            "Epoch #1. Accuracy on batch 1856 on Training is 30.142703284868066\n",
            "Epoch #1. Accuracy on batch 1857 on Training is 30.133207750269108\n",
            "Epoch #1. Accuracy on batch 1858 on Training is 30.13548951048951\n",
            "Epoch #1. Accuracy on batch 1859 on Training is 30.129368279569892\n",
            "Batch Id 1860 is having training loss of 1680.384033203125\n",
            "32.760196685791016\n",
            "Epoch #1. Accuracy on batch 1860 on Training is 30.128291241268137\n",
            "Epoch #1. Accuracy on batch 1861 on Training is 30.12889366272825\n",
            "Epoch #1. Accuracy on batch 1862 on Training is 30.131172839506174\n",
            "Epoch #1. Accuracy on batch 1863 on Training is 30.123390557939913\n",
            "Epoch #1. Accuracy on batch 1864 on Training is 30.125670241286862\n",
            "Epoch #1. Accuracy on batch 1865 on Training is 30.122923365487676\n",
            "Epoch #1. Accuracy on batch 1866 on Training is 30.125200856989824\n",
            "Epoch #1. Accuracy on batch 1867 on Training is 30.12747591006424\n",
            "Epoch #1. Accuracy on batch 1868 on Training is 30.129748528624933\n",
            "Epoch #1. Accuracy on batch 1869 on Training is 30.130347593582886\n",
            "Epoch #1. Accuracy on batch 1870 on Training is 30.129275788348476\n",
            "Epoch #1. Accuracy on batch 1871 on Training is 30.133213141025642\n",
            "Epoch #1. Accuracy on batch 1872 on Training is 30.140483182060866\n",
            "Epoch #1. Accuracy on batch 1873 on Training is 30.13607257203842\n",
            "Epoch #1. Accuracy on batch 1874 on Training is 30.131666666666668\n",
            "Epoch #1. Accuracy on batch 1875 on Training is 30.128931236673775\n",
            "Epoch #1. Accuracy on batch 1876 on Training is 30.13119339371337\n",
            "Epoch #1. Accuracy on batch 1877 on Training is 30.131789137380192\n",
            "Epoch #1. Accuracy on batch 1878 on Training is 30.13571048430016\n",
            "Epoch #1. Accuracy on batch 1879 on Training is 30.12965425531915\n",
            "Batch Id 1880 is having training loss of 1695.9705810546875\n",
            "17.694747924804688\n",
            "Epoch #1. Accuracy on batch 1880 on Training is 30.135233918128655\n",
            "Epoch #1. Accuracy on batch 1881 on Training is 30.13084484590861\n",
            "Epoch #1. Accuracy on batch 1882 on Training is 30.124800849707913\n",
            "Epoch #1. Accuracy on batch 1883 on Training is 30.120421974522294\n",
            "Epoch #1. Accuracy on batch 1884 on Training is 30.119363395225463\n",
            "Epoch #1. Accuracy on batch 1885 on Training is 30.119962884411454\n",
            "Epoch #1. Accuracy on batch 1886 on Training is 30.132154213036564\n",
            "Epoch #1. Accuracy on batch 1887 on Training is 30.126125529661017\n",
            "Epoch #1. Accuracy on batch 1888 on Training is 30.130029115934356\n",
            "Epoch #1. Accuracy on batch 1889 on Training is 30.120701058201057\n",
            "Epoch #1. Accuracy on batch 1890 on Training is 30.117993125330514\n",
            "Epoch #1. Accuracy on batch 1891 on Training is 30.113636363636363\n",
            "Epoch #1. Accuracy on batch 1892 on Training is 30.10268092974115\n",
            "Epoch #1. Accuracy on batch 1893 on Training is 30.098336853220697\n",
            "Epoch #1. Accuracy on batch 1894 on Training is 30.097295514511874\n",
            "Epoch #1. Accuracy on batch 1895 on Training is 30.096255274261605\n",
            "Epoch #1. Accuracy on batch 1896 on Training is 30.093568792830787\n",
            "Epoch #1. Accuracy on batch 1897 on Training is 30.097471022128556\n",
            "Epoch #1. Accuracy on batch 1898 on Training is 30.10466034755134\n",
            "Epoch #1. Accuracy on batch 1899 on Training is 30.11019736842105\n",
            "Batch Id 1900 is having training loss of 1720.1517333984375\n",
            "18.47800064086914\n",
            "Epoch #1. Accuracy on batch 1900 on Training is 30.110796948974222\n",
            "Epoch #1. Accuracy on batch 1901 on Training is 30.108109884332283\n",
            "Epoch #1. Accuracy on batch 1902 on Training is 30.10214135575407\n",
            "Epoch #1. Accuracy on batch 1903 on Training is 30.102744222689076\n",
            "Epoch #1. Accuracy on batch 1904 on Training is 30.103346456692915\n",
            "Epoch #1. Accuracy on batch 1905 on Training is 30.108866736621195\n",
            "Epoch #1. Accuracy on batch 1906 on Training is 30.107826428945987\n",
            "Epoch #1. Accuracy on batch 1907 on Training is 30.11333857442348\n",
            "Epoch #1. Accuracy on batch 1908 on Training is 30.122118910424305\n",
            "Epoch #1. Accuracy on batch 1909 on Training is 30.12107329842932\n",
            "Epoch #1. Accuracy on batch 1910 on Training is 30.111852433281005\n",
            "Epoch #1. Accuracy on batch 1911 on Training is 30.105910041841003\n",
            "Epoch #1. Accuracy on batch 1912 on Training is 30.103240982749607\n",
            "Epoch #1. Accuracy on batch 1913 on Training is 30.103840125391848\n",
            "Epoch #1. Accuracy on batch 1914 on Training is 30.094647519582246\n",
            "Epoch #1. Accuracy on batch 1915 on Training is 30.1017745302714\n",
            "Epoch #1. Accuracy on batch 1916 on Training is 30.100743348982785\n",
            "Epoch #1. Accuracy on batch 1917 on Training is 30.104601147028156\n",
            "Epoch #1. Accuracy on batch 1918 on Training is 30.10194111516415\n",
            "Epoch #1. Accuracy on batch 1919 on Training is 30.100911458333332\n",
            "Batch Id 1920 is having training loss of 1737.5213623046875\n",
            "36.450965881347656\n",
            "Epoch #1. Accuracy on batch 1920 on Training is 30.101509630400834\n",
            "Epoch #1. Accuracy on batch 1921 on Training is 30.093977627471386\n",
            "Epoch #1. Accuracy on batch 1922 on Training is 30.097828913156526\n",
            "Epoch #1. Accuracy on batch 1923 on Training is 30.087058212058214\n",
            "Epoch #1. Accuracy on batch 1924 on Training is 30.089285714285715\n",
            "Epoch #1. Accuracy on batch 1925 on Training is 30.093133437175492\n",
            "Epoch #1. Accuracy on batch 1926 on Training is 30.09211209133368\n",
            "Epoch #1. Accuracy on batch 1927 on Training is 30.08785010373444\n",
            "Epoch #1. Accuracy on batch 1928 on Training is 30.086832555728357\n",
            "Epoch #1. Accuracy on batch 1929 on Training is 30.07933937823834\n",
            "Epoch #1. Accuracy on batch 1930 on Training is 30.07832729155878\n",
            "Epoch #1. Accuracy on batch 1931 on Training is 30.07893374741201\n",
            "Epoch #1. Accuracy on batch 1932 on Training is 30.079539575788928\n",
            "Epoch #1. Accuracy on batch 1933 on Training is 30.076913133402275\n",
            "Epoch #1. Accuracy on batch 1934 on Training is 30.07590439276486\n",
            "Epoch #1. Accuracy on batch 1935 on Training is 30.07651084710744\n",
            "Epoch #1. Accuracy on batch 1936 on Training is 30.06582343830666\n",
            "Epoch #1. Accuracy on batch 1937 on Training is 30.07127192982456\n",
            "Epoch #1. Accuracy on batch 1938 on Training is 30.0589865910263\n",
            "Epoch #1. Accuracy on batch 1939 on Training is 30.062822164948454\n",
            "Batch Id 1940 is having training loss of 1744.2071533203125\n",
            "195.81640625\n",
            "Epoch #1. Accuracy on batch 1940 on Training is 30.052163833075735\n",
            "Epoch #1. Accuracy on batch 1941 on Training is 30.047953141091657\n",
            "Epoch #1. Accuracy on batch 1942 on Training is 30.043746783324757\n",
            "Epoch #1. Accuracy on batch 1943 on Training is 30.042759773662553\n",
            "Epoch #1. Accuracy on batch 1944 on Training is 30.048200514138816\n",
            "Epoch #1. Accuracy on batch 1945 on Training is 30.055241521068858\n",
            "Epoch #1. Accuracy on batch 1946 on Training is 30.06067026194145\n",
            "Epoch #1. Accuracy on batch 1947 on Training is 30.061280800821354\n",
            "Epoch #1. Accuracy on batch 1948 on Training is 30.060287326834274\n",
            "Epoch #1. Accuracy on batch 1949 on Training is 30.064102564102566\n",
            "Epoch #1. Accuracy on batch 1950 on Training is 30.05830343413634\n",
            "Epoch #1. Accuracy on batch 1951 on Training is 30.055712090163933\n",
            "Epoch #1. Accuracy on batch 1952 on Training is 30.054723502304146\n",
            "Epoch #1. Accuracy on batch 1953 on Training is 30.05053735926305\n",
            "Epoch #1. Accuracy on batch 1954 on Training is 30.049552429667518\n",
            "Epoch #1. Accuracy on batch 1955 on Training is 30.046970858895705\n",
            "Epoch #1. Accuracy on batch 1956 on Training is 30.053972917731222\n",
            "Epoch #1. Accuracy on batch 1957 on Training is 30.052987742594485\n",
            "Epoch #1. Accuracy on batch 1958 on Training is 30.05678917815212\n",
            "Epoch #1. Accuracy on batch 1959 on Training is 30.055803571428573\n",
            "Batch Id 1960 is having training loss of 1729.19580078125\n",
            "20.095090866088867\n",
            "Epoch #1. Accuracy on batch 1960 on Training is 30.05641254462009\n",
            "Epoch #1. Accuracy on batch 1961 on Training is 30.05383537206932\n",
            "Epoch #1. Accuracy on batch 1962 on Training is 30.043301069791138\n",
            "Epoch #1. Accuracy on batch 1963 on Training is 30.04232433808554\n",
            "Epoch #1. Accuracy on batch 1964 on Training is 30.036577608142494\n",
            "Epoch #1. Accuracy on batch 1965 on Training is 30.03083672431333\n",
            "Epoch #1. Accuracy on batch 1966 on Training is 30.029867819013727\n",
            "Epoch #1. Accuracy on batch 1967 on Training is 30.03048780487805\n",
            "Epoch #1. Accuracy on batch 1968 on Training is 30.02634586084307\n",
            "Epoch #1. Accuracy on batch 1969 on Training is 30.023794416243653\n",
            "Epoch #1. Accuracy on batch 1970 on Training is 30.018074581430746\n",
            "Epoch #1. Accuracy on batch 1971 on Training is 30.015529918864097\n",
            "Epoch #1. Accuracy on batch 1972 on Training is 30.012987835783072\n",
            "Epoch #1. Accuracy on batch 1973 on Training is 30.010448328267476\n",
            "Epoch #1. Accuracy on batch 1974 on Training is 30.009493670886076\n",
            "Epoch #1. Accuracy on batch 1975 on Training is 30.010121457489877\n",
            "Epoch #1. Accuracy on batch 1976 on Training is 30.006006575619626\n",
            "Epoch #1. Accuracy on batch 1977 on Training is 30.003475733063702\n",
            "Epoch #1. Accuracy on batch 1978 on Training is 30.00568468923699\n",
            "Epoch #1. Accuracy on batch 1979 on Training is 30.004734848484848\n",
            "Batch Id 1980 is having training loss of 1749.3170166015625\n",
            "43.91472244262695\n",
            "Epoch #1. Accuracy on batch 1980 on Training is 30.002208480565372\n",
            "Epoch #1. Accuracy on batch 1981 on Training is 30.007568113017154\n",
            "Epoch #1. Accuracy on batch 1982 on Training is 30.00661875945537\n",
            "Epoch #1. Accuracy on batch 1983 on Training is 30.000945060483872\n",
            "Epoch #1. Accuracy on batch 1984 on Training is 30.0\n",
            "Epoch #1. Accuracy on batch 1985 on Training is 30.0022029204431\n",
            "Epoch #1. Accuracy on batch 1986 on Training is 30.00283090085556\n",
            "Epoch #1. Accuracy on batch 1987 on Training is 30.006602112676056\n",
            "Epoch #1. Accuracy on batch 1988 on Training is 30.00408496732026\n",
            "Epoch #1. Accuracy on batch 1989 on Training is 30.00785175879397\n",
            "Epoch #1. Accuracy on batch 1990 on Training is 30.005336514314415\n",
            "Epoch #1. Accuracy on batch 1991 on Training is 29.996548694779115\n",
            "Epoch #1. Accuracy on batch 1992 on Training is 29.99560963371801\n",
            "Epoch #1. Accuracy on batch 1993 on Training is 29.996238716148444\n",
            "Epoch #1. Accuracy on batch 1994 on Training is 29.9906015037594\n",
            "Epoch #1. Accuracy on batch 1995 on Training is 29.99436372745491\n",
            "Epoch #1. Accuracy on batch 1996 on Training is 29.990297946920382\n",
            "Epoch #1. Accuracy on batch 1997 on Training is 29.99092842842843\n",
            "Epoch #1. Accuracy on batch 1998 on Training is 29.985305152576288\n",
            "Epoch #1. Accuracy on batch 1999 on Training is 29.9859375\n",
            "Batch Id 2000 is having training loss of 1765.2138671875\n",
            "51975.4296875\n",
            "Epoch #1. Accuracy on batch 2000 on Training is 29.985007496251875\n",
            "Epoch #1. Accuracy on batch 2001 on Training is 29.98563936063936\n",
            "Epoch #1. Accuracy on batch 2002 on Training is 29.987830753869197\n",
            "Epoch #1. Accuracy on batch 2003 on Training is 29.988460578842314\n",
            "Epoch #1. Accuracy on batch 2004 on Training is 29.987531172069826\n",
            "Epoch #1. Accuracy on batch 2005 on Training is 29.986602691924226\n",
            "Epoch #1. Accuracy on batch 2006 on Training is 29.99034628799203\n",
            "Epoch #1. Accuracy on batch 2007 on Training is 29.986304780876495\n",
            "Epoch #1. Accuracy on batch 2008 on Training is 29.980711796913887\n",
            "Epoch #1. Accuracy on batch 2009 on Training is 29.989116915422887\n",
            "Epoch #1. Accuracy on batch 2010 on Training is 29.98663600198906\n",
            "Epoch #1. Accuracy on batch 2011 on Training is 29.984157554671967\n",
            "Epoch #1. Accuracy on batch 2012 on Training is 29.984786388474912\n",
            "Epoch #1. Accuracy on batch 2013 on Training is 29.988517874875868\n",
            "Epoch #1. Accuracy on batch 2014 on Training is 29.995347394540943\n",
            "Epoch #1. Accuracy on batch 2015 on Training is 29.991319444444443\n",
            "Epoch #1. Accuracy on batch 2016 on Training is 29.987295488349034\n",
            "Epoch #1. Accuracy on batch 2017 on Training is 29.994115460852328\n",
            "Epoch #1. Accuracy on batch 2018 on Training is 29.993189697870232\n",
            "Epoch #1. Accuracy on batch 2019 on Training is 29.99535891089109\n",
            "Batch Id 2020 is having training loss of 1779.9765625\n",
            "815.4737548828125\n",
            "Epoch #1. Accuracy on batch 2020 on Training is 29.994433448787728\n",
            "Epoch #1. Accuracy on batch 2021 on Training is 29.993508902077153\n",
            "Epoch #1. Accuracy on batch 2022 on Training is 29.99258526940188\n",
            "Epoch #1. Accuracy on batch 2023 on Training is 29.99629446640316\n",
            "Epoch #1. Accuracy on batch 2024 on Training is 29.993827160493826\n",
            "Epoch #1. Accuracy on batch 2025 on Training is 29.986734945705823\n",
            "Epoch #1. Accuracy on batch 2026 on Training is 29.984274790330538\n",
            "Epoch #1. Accuracy on batch 2027 on Training is 29.989521696252467\n",
            "Epoch #1. Accuracy on batch 2028 on Training is 29.99014292755052\n",
            "Epoch #1. Accuracy on batch 2029 on Training is 29.983066502463053\n",
            "Epoch #1. Accuracy on batch 2030 on Training is 29.97138109305761\n",
            "Epoch #1. Accuracy on batch 2031 on Training is 29.976624015748033\n",
            "Epoch #1. Accuracy on batch 2032 on Training is 29.971101819970485\n",
            "Epoch #1. Accuracy on batch 2033 on Training is 29.968657817109143\n",
            "Epoch #1. Accuracy on batch 2034 on Training is 29.975429975429975\n",
            "Epoch #1. Accuracy on batch 2035 on Training is 29.977590864440078\n",
            "Epoch #1. Accuracy on batch 2036 on Training is 29.987420225822287\n",
            "Epoch #1. Accuracy on batch 2037 on Training is 29.98037291462218\n",
            "Epoch #1. Accuracy on batch 2038 on Training is 29.98406081412457\n",
            "Epoch #1. Accuracy on batch 2039 on Training is 29.99234068627451\n",
            "Batch Id 2040 is having training loss of 1813.6361083984375\n",
            "24.57999038696289\n",
            "Epoch #1. Accuracy on batch 2040 on Training is 29.99295688388045\n",
            "Epoch #1. Accuracy on batch 2041 on Training is 29.993572477962783\n",
            "Epoch #1. Accuracy on batch 2042 on Training is 29.99265785609398\n",
            "Epoch #1. Accuracy on batch 2043 on Training is 29.987157534246574\n",
            "Epoch #1. Accuracy on batch 2044 on Training is 29.984718826405867\n",
            "Epoch #1. Accuracy on batch 2045 on Training is 29.98533724340176\n",
            "Epoch #1. Accuracy on batch 2046 on Training is 29.982901807523206\n",
            "Epoch #1. Accuracy on batch 2047 on Training is 29.98199462890625\n",
            "Epoch #1. Accuracy on batch 2048 on Training is 29.98413860419717\n",
            "Epoch #1. Accuracy on batch 2049 on Training is 29.983231707317074\n",
            "Epoch #1. Accuracy on batch 2050 on Training is 29.982325694783032\n",
            "Epoch #1. Accuracy on batch 2051 on Training is 29.984466374269005\n",
            "Epoch #1. Accuracy on batch 2052 on Training is 29.99117145640526\n",
            "Epoch #1. Accuracy on batch 2053 on Training is 29.991784323271666\n",
            "Epoch #1. Accuracy on batch 2054 on Training is 29.989355231143552\n",
            "Epoch #1. Accuracy on batch 2055 on Training is 29.996048151750973\n",
            "Epoch #1. Accuracy on batch 2056 on Training is 29.993619348565872\n",
            "Epoch #1. Accuracy on batch 2057 on Training is 30.00334062196307\n",
            "Epoch #1. Accuracy on batch 2058 on Training is 30.002428363283148\n",
            "Epoch #1. Accuracy on batch 2059 on Training is 29.996966019417474\n",
            "Batch Id 2060 is having training loss of 1828.9879150390625\n",
            "25.359052658081055\n",
            "Epoch #1. Accuracy on batch 2060 on Training is 29.999090247452692\n",
            "Epoch #1. Accuracy on batch 2061 on Training is 29.993634820562562\n",
            "Epoch #1. Accuracy on batch 2062 on Training is 29.986669898206497\n",
            "Epoch #1. Accuracy on batch 2063 on Training is 29.988796027131784\n",
            "Epoch #1. Accuracy on batch 2064 on Training is 29.9909200968523\n",
            "Epoch #1. Accuracy on batch 2065 on Training is 29.99304211035818\n",
            "Epoch #1. Accuracy on batch 2066 on Training is 29.998185776487663\n",
            "Epoch #1. Accuracy on batch 2067 on Training is 29.994257736943908\n",
            "Epoch #1. Accuracy on batch 2068 on Training is 29.99335427742871\n",
            "Epoch #1. Accuracy on batch 2069 on Training is 30.0\n",
            "Epoch #1. Accuracy on batch 2070 on Training is 30.002112506035733\n",
            "Epoch #1. Accuracy on batch 2071 on Training is 30.005731177606176\n",
            "Epoch #1. Accuracy on batch 2072 on Training is 30.00030149541727\n",
            "Epoch #1. Accuracy on batch 2073 on Training is 30.000904050144648\n",
            "Epoch #1. Accuracy on batch 2074 on Training is 30.004518072289155\n",
            "Epoch #1. Accuracy on batch 2075 on Training is 30.002107418111752\n",
            "Epoch #1. Accuracy on batch 2076 on Training is 30.005717380837748\n",
            "Epoch #1. Accuracy on batch 2077 on Training is 30.010827718960538\n",
            "Epoch #1. Accuracy on batch 2078 on Training is 30.00691438191438\n",
            "Epoch #1. Accuracy on batch 2079 on Training is 30.003004807692307\n",
            "Batch Id 2080 is having training loss of 1816.5609130859375\n",
            "240.18609619140625\n",
            "Epoch #1. Accuracy on batch 2080 on Training is 30.003604036520905\n",
            "Epoch #1. Accuracy on batch 2081 on Training is 30.005703650336216\n",
            "Epoch #1. Accuracy on batch 2082 on Training is 30.007801248199712\n",
            "Epoch #1. Accuracy on batch 2083 on Training is 30.002399232245683\n",
            "Epoch #1. Accuracy on batch 2084 on Training is 30.0044964028777\n",
            "Epoch #1. Accuracy on batch 2085 on Training is 30.000599232981784\n",
            "Epoch #1. Accuracy on batch 2086 on Training is 29.999700527072353\n",
            "Epoch #1. Accuracy on batch 2087 on Training is 30.000299329501917\n",
            "Epoch #1. Accuracy on batch 2088 on Training is 30.0008975586405\n",
            "Epoch #1. Accuracy on batch 2089 on Training is 30.00598086124402\n",
            "Epoch #1. Accuracy on batch 2090 on Training is 30.008070301291248\n",
            "Epoch #1. Accuracy on batch 2091 on Training is 30.00268881453155\n",
            "Epoch #1. Accuracy on batch 2092 on Training is 30.00328475871954\n",
            "Epoch #1. Accuracy on batch 2093 on Training is 30.003880133715377\n",
            "Epoch #1. Accuracy on batch 2094 on Training is 30.0\n",
            "Epoch #1. Accuracy on batch 2095 on Training is 30.002087309160306\n",
            "Epoch #1. Accuracy on batch 2096 on Training is 30.007153075822604\n",
            "Epoch #1. Accuracy on batch 2097 on Training is 30.00774547187798\n",
            "Epoch #1. Accuracy on batch 2098 on Training is 30.00387089090043\n",
            "Epoch #1. Accuracy on batch 2099 on Training is 30.001488095238095\n",
            "Batch Id 2100 is having training loss of 1821.9798583984375\n",
            "238.07937622070312\n",
            "Epoch #1. Accuracy on batch 2100 on Training is 30.008031889576394\n",
            "Epoch #1. Accuracy on batch 2101 on Training is 30.01605613701237\n",
            "Epoch #1. Accuracy on batch 2102 on Training is 30.012184973846885\n",
            "Epoch #1. Accuracy on batch 2103 on Training is 30.012773288973385\n",
            "Epoch #1. Accuracy on batch 2104 on Training is 30.017814726840854\n",
            "Epoch #1. Accuracy on batch 2105 on Training is 30.010980531813864\n",
            "Epoch #1. Accuracy on batch 2106 on Training is 30.021950640721403\n",
            "Epoch #1. Accuracy on batch 2107 on Training is 30.024015654648956\n",
            "Epoch #1. Accuracy on batch 2108 on Training is 30.020151730678048\n",
            "Epoch #1. Accuracy on batch 2109 on Training is 30.016291469194314\n",
            "Epoch #1. Accuracy on batch 2110 on Training is 30.018356229275224\n",
            "Epoch #1. Accuracy on batch 2111 on Training is 30.014500473484848\n",
            "Epoch #1. Accuracy on batch 2112 on Training is 30.016564126833885\n",
            "Epoch #1. Accuracy on batch 2113 on Training is 30.01862582781457\n",
            "Epoch #1. Accuracy on batch 2114 on Training is 30.02659574468085\n",
            "Epoch #1. Accuracy on batch 2115 on Training is 30.027173913043477\n",
            "Epoch #1. Accuracy on batch 2116 on Training is 30.02479924421351\n",
            "Epoch #1. Accuracy on batch 2117 on Training is 30.023902266288953\n",
            "Epoch #1. Accuracy on batch 2118 on Training is 30.018581878244454\n",
            "Epoch #1. Accuracy on batch 2119 on Training is 30.019162735849058\n",
            "Batch Id 2120 is having training loss of 1817.1368408203125\n",
            "5481.90966796875\n",
            "Epoch #1. Accuracy on batch 2120 on Training is 30.015322960867515\n",
            "Epoch #1. Accuracy on batch 2121 on Training is 30.01885014137606\n",
            "Epoch #1. Accuracy on batch 2122 on Training is 30.022373999057937\n",
            "Epoch #1. Accuracy on batch 2123 on Training is 30.024423258003768\n",
            "Epoch #1. Accuracy on batch 2124 on Training is 30.03529411764706\n",
            "Epoch #1. Accuracy on batch 2125 on Training is 30.038805268109126\n",
            "Epoch #1. Accuracy on batch 2126 on Training is 30.036436295251526\n",
            "Epoch #1. Accuracy on batch 2127 on Training is 30.038475093984964\n",
            "Epoch #1. Accuracy on batch 2128 on Training is 30.039044152184125\n",
            "Epoch #1. Accuracy on batch 2129 on Training is 30.035211267605632\n",
            "Epoch #1. Accuracy on batch 2130 on Training is 30.043113561708118\n",
            "Epoch #1. Accuracy on batch 2131 on Training is 30.04954268292683\n",
            "Epoch #1. Accuracy on batch 2132 on Training is 30.04424519456165\n",
            "Epoch #1. Accuracy on batch 2133 on Training is 30.040417057169634\n",
            "Epoch #1. Accuracy on batch 2134 on Training is 30.03512880562061\n",
            "Epoch #1. Accuracy on batch 2135 on Training is 30.044475655430713\n",
            "Epoch #1. Accuracy on batch 2136 on Training is 30.04357744501638\n",
            "Epoch #1. Accuracy on batch 2137 on Training is 30.04121842843779\n",
            "Epoch #1. Accuracy on batch 2138 on Training is 30.04032258064516\n",
            "Epoch #1. Accuracy on batch 2139 on Training is 30.037967289719628\n",
            "Batch Id 2140 is having training loss of 1839.473876953125\n",
            "3232.91845703125\n",
            "Epoch #1. Accuracy on batch 2140 on Training is 30.038533395609527\n",
            "Epoch #1. Accuracy on batch 2141 on Training is 30.036181139122316\n",
            "Epoch #1. Accuracy on batch 2142 on Training is 30.0411222585161\n",
            "Epoch #1. Accuracy on batch 2143 on Training is 30.043143656716417\n",
            "Epoch #1. Accuracy on batch 2144 on Training is 30.04079254079254\n",
            "Epoch #1. Accuracy on batch 2145 on Training is 30.044268406337373\n",
            "Epoch #1. Accuracy on batch 2146 on Training is 30.041918956683745\n",
            "Epoch #1. Accuracy on batch 2147 on Training is 30.04102653631285\n",
            "Epoch #1. Accuracy on batch 2148 on Training is 30.04885993485342\n",
            "Epoch #1. Accuracy on batch 2149 on Training is 30.040697674418606\n",
            "Epoch #1. Accuracy on batch 2150 on Training is 30.039807066480705\n",
            "Epoch #1. Accuracy on batch 2151 on Training is 30.036013011152416\n",
            "Epoch #1. Accuracy on batch 2152 on Training is 30.045285647933117\n",
            "Epoch #1. Accuracy on batch 2153 on Training is 30.044394150417826\n",
            "Epoch #1. Accuracy on batch 2154 on Training is 30.04350348027842\n",
            "Epoch #1. Accuracy on batch 2155 on Training is 30.038265306122447\n",
            "Epoch #1. Accuracy on batch 2156 on Training is 30.03592953175707\n",
            "Epoch #1. Accuracy on batch 2157 on Training is 30.04228452270621\n",
            "Epoch #1. Accuracy on batch 2158 on Training is 30.044291338582678\n",
            "Epoch #1. Accuracy on batch 2159 on Training is 30.04340277777778\n",
            "Batch Id 2160 is having training loss of 1835.9371337890625\n",
            "33.553653717041016\n",
            "Epoch #1. Accuracy on batch 2160 on Training is 30.0468533086534\n",
            "Epoch #1. Accuracy on batch 2161 on Training is 30.050300647548568\n",
            "Epoch #1. Accuracy on batch 2162 on Training is 30.049410540915396\n",
            "Epoch #1. Accuracy on batch 2163 on Training is 30.045633086876155\n",
            "Epoch #1. Accuracy on batch 2164 on Training is 30.04618937644342\n",
            "Epoch #1. Accuracy on batch 2165 on Training is 30.049630655586334\n",
            "Epoch #1. Accuracy on batch 2166 on Training is 30.053068758652515\n",
            "Epoch #1. Accuracy on batch 2167 on Training is 30.050738007380073\n",
            "Epoch #1. Accuracy on batch 2168 on Training is 30.057053941908713\n",
            "Epoch #1. Accuracy on batch 2169 on Training is 30.06192396313364\n",
            "Epoch #1. Accuracy on batch 2170 on Training is 30.05815292491939\n",
            "Epoch #1. Accuracy on batch 2171 on Training is 30.061579189686924\n",
            "Epoch #1. Accuracy on batch 2172 on Training is 30.053497468936953\n",
            "Epoch #1. Accuracy on batch 2173 on Training is 30.054047838086476\n",
            "Epoch #1. Accuracy on batch 2174 on Training is 30.058908045977013\n",
            "Epoch #1. Accuracy on batch 2175 on Training is 30.063763786764707\n",
            "Epoch #1. Accuracy on batch 2176 on Training is 30.06574414331649\n",
            "Epoch #1. Accuracy on batch 2177 on Training is 30.064853076216714\n",
            "Epoch #1. Accuracy on batch 2178 on Training is 30.06109453877926\n",
            "Epoch #1. Accuracy on batch 2179 on Training is 30.05447247706422\n",
            "Batch Id 2180 is having training loss of 1831.290283203125\n",
            "19.45490264892578\n",
            "Epoch #1. Accuracy on batch 2180 on Training is 30.05215497478221\n",
            "Epoch #1. Accuracy on batch 2181 on Training is 30.052703941338223\n",
            "Epoch #1. Accuracy on batch 2182 on Training is 30.046094823637198\n",
            "Epoch #1. Accuracy on batch 2183 on Training is 30.042353479853478\n",
            "Epoch #1. Accuracy on batch 2184 on Training is 30.04004576659039\n",
            "Epoch #1. Accuracy on batch 2185 on Training is 30.042028819762123\n",
            "Epoch #1. Accuracy on batch 2186 on Training is 30.032578875171467\n",
            "Epoch #1. Accuracy on batch 2187 on Training is 30.031707038391225\n",
            "Epoch #1. Accuracy on batch 2188 on Training is 30.035118775696667\n",
            "Epoch #1. Accuracy on batch 2189 on Training is 30.032819634703195\n",
            "Epoch #1. Accuracy on batch 2190 on Training is 30.040506617982658\n",
            "Epoch #1. Accuracy on batch 2191 on Training is 30.03678147810219\n",
            "Epoch #1. Accuracy on batch 2192 on Training is 30.03875968992248\n",
            "Epoch #1. Accuracy on batch 2193 on Training is 30.036463081130357\n",
            "Epoch #1. Accuracy on batch 2194 on Training is 30.046981776765374\n",
            "Epoch #1. Accuracy on batch 2195 on Training is 30.046106557377048\n",
            "Epoch #1. Accuracy on batch 2196 on Training is 30.045232134729176\n",
            "Epoch #1. Accuracy on batch 2197 on Training is 30.04578025477707\n",
            "Epoch #1. Accuracy on batch 2198 on Training is 30.046327876307412\n",
            "Epoch #1. Accuracy on batch 2199 on Training is 30.045454545454547\n",
            "Batch Id 2200 is having training loss of 1822.9693603515625\n",
            "34.253902435302734\n",
            "Epoch #1. Accuracy on batch 2200 on Training is 30.0445820081781\n",
            "Epoch #1. Accuracy on batch 2201 on Training is 30.047967756584924\n",
            "Epoch #1. Accuracy on batch 2202 on Training is 30.0442578302315\n",
            "Epoch #1. Accuracy on batch 2203 on Training is 30.04480490018149\n",
            "Epoch #1. Accuracy on batch 2204 on Training is 30.043934240362812\n",
            "Epoch #1. Accuracy on batch 2205 on Training is 30.044480961015413\n",
            "Epoch #1. Accuracy on batch 2206 on Training is 30.04077933846851\n",
            "Epoch #1. Accuracy on batch 2207 on Training is 30.03991168478261\n",
            "Epoch #1. Accuracy on batch 2208 on Training is 30.043288818469897\n",
            "Epoch #1. Accuracy on batch 2209 on Training is 30.04524886877828\n",
            "Epoch #1. Accuracy on batch 2210 on Training is 30.045793758480325\n",
            "Epoch #1. Accuracy on batch 2211 on Training is 30.050576401446655\n",
            "Epoch #1. Accuracy on batch 2212 on Training is 30.049706281066424\n",
            "Epoch #1. Accuracy on batch 2213 on Training is 30.054482836495033\n",
            "Epoch #1. Accuracy on batch 2214 on Training is 30.05502257336343\n",
            "Epoch #1. Accuracy on batch 2215 on Training is 30.055561823104693\n",
            "Epoch #1. Accuracy on batch 2216 on Training is 30.060329273793414\n",
            "Epoch #1. Accuracy on batch 2217 on Training is 30.05945671776375\n",
            "Epoch #1. Accuracy on batch 2218 on Training is 30.05717665615142\n",
            "Epoch #1. Accuracy on batch 2219 on Training is 30.05912162162162\n",
            "Batch Id 2220 is having training loss of 1811.06298828125\n",
            "30.95255470275879\n",
            "Epoch #1. Accuracy on batch 2220 on Training is 30.058250787933364\n",
            "Epoch #1. Accuracy on batch 2221 on Training is 30.055974347434745\n",
            "Epoch #1. Accuracy on batch 2222 on Training is 30.06213450292398\n",
            "Epoch #1. Accuracy on batch 2223 on Training is 30.061263489208635\n",
            "Epoch #1. Accuracy on batch 2224 on Training is 30.060393258426966\n",
            "Epoch #1. Accuracy on batch 2225 on Training is 30.058119946091644\n",
            "Epoch #1. Accuracy on batch 2226 on Training is 30.054445442299055\n",
            "Epoch #1. Accuracy on batch 2227 on Training is 30.061995062836626\n",
            "Epoch #1. Accuracy on batch 2228 on Training is 30.062528039479588\n",
            "Epoch #1. Accuracy on batch 2229 on Training is 30.067264573991032\n",
            "Epoch #1. Accuracy on batch 2230 on Training is 30.070596145226357\n",
            "Epoch #1. Accuracy on batch 2231 on Training is 30.07252464157706\n",
            "Epoch #1. Accuracy on batch 2232 on Training is 30.07165248544559\n",
            "Epoch #1. Accuracy on batch 2233 on Training is 30.067983437779766\n",
            "Epoch #1. Accuracy on batch 2234 on Training is 30.069910514541387\n",
            "Epoch #1. Accuracy on batch 2235 on Training is 30.070438282647586\n",
            "Epoch #1. Accuracy on batch 2236 on Training is 30.076553419758604\n",
            "Epoch #1. Accuracy on batch 2237 on Training is 30.077077747989275\n",
            "Epoch #1. Accuracy on batch 2238 on Training is 30.077601607860654\n",
            "Epoch #1. Accuracy on batch 2239 on Training is 30.075334821428573\n",
            "Batch Id 2240 is having training loss of 1808.036865234375\n",
            "526.915771484375\n",
            "Epoch #1. Accuracy on batch 2240 on Training is 30.07307005800982\n",
            "Epoch #1. Accuracy on batch 2241 on Training is 30.06801962533452\n",
            "Epoch #1. Accuracy on batch 2242 on Training is 30.07411948283549\n",
            "Epoch #1. Accuracy on batch 2243 on Training is 30.073250891265598\n",
            "Epoch #1. Accuracy on batch 2244 on Training is 30.07099109131403\n",
            "Epoch #1. Accuracy on batch 2245 on Training is 30.072907390917187\n",
            "Epoch #1. Accuracy on batch 2246 on Training is 30.070649755229194\n",
            "Epoch #1. Accuracy on batch 2247 on Training is 30.07256450177936\n",
            "Epoch #1. Accuracy on batch 2248 on Training is 30.0730880391285\n",
            "Epoch #1. Accuracy on batch 2249 on Training is 30.069444444444443\n",
            "Epoch #1. Accuracy on batch 2250 on Training is 30.06858063083074\n",
            "Epoch #1. Accuracy on batch 2251 on Training is 30.070492895204264\n",
            "Epoch #1. Accuracy on batch 2252 on Training is 30.072403462050598\n",
            "Epoch #1. Accuracy on batch 2253 on Training is 30.070153061224488\n",
            "Epoch #1. Accuracy on batch 2254 on Training is 30.073447893569845\n",
            "Epoch #1. Accuracy on batch 2255 on Training is 30.07535460992908\n",
            "Epoch #1. Accuracy on batch 2256 on Training is 30.082797961896322\n",
            "Epoch #1. Accuracy on batch 2257 on Training is 30.080546944198407\n",
            "Epoch #1. Accuracy on batch 2258 on Training is 30.07691456396636\n",
            "Epoch #1. Accuracy on batch 2259 on Training is 30.077433628318584\n",
            "Batch Id 2260 is having training loss of 1801.3975830078125\n",
            "20.705400466918945\n",
            "Epoch #1. Accuracy on batch 2260 on Training is 30.071041574524546\n",
            "Epoch #1. Accuracy on batch 2261 on Training is 30.075707338638374\n",
            "Epoch #1. Accuracy on batch 2262 on Training is 30.08036897923111\n",
            "Epoch #1. Accuracy on batch 2263 on Training is 30.076744699646643\n",
            "Epoch #1. Accuracy on batch 2264 on Training is 30.081401766004415\n",
            "Epoch #1. Accuracy on batch 2265 on Training is 30.069505736981466\n",
            "Epoch #1. Accuracy on batch 2266 on Training is 30.067269519188354\n",
            "Epoch #1. Accuracy on batch 2267 on Training is 30.065035273368608\n",
            "Epoch #1. Accuracy on batch 2268 on Training is 30.066934773027764\n",
            "Epoch #1. Accuracy on batch 2269 on Training is 30.064702643171806\n",
            "Epoch #1. Accuracy on batch 2270 on Training is 30.066600616468516\n",
            "Epoch #1. Accuracy on batch 2271 on Training is 30.06161971830986\n",
            "Epoch #1. Accuracy on batch 2272 on Training is 30.06901671799384\n",
            "Epoch #1. Accuracy on batch 2273 on Training is 30.06678759894459\n",
            "Epoch #1. Accuracy on batch 2274 on Training is 30.067307692307693\n",
            "Epoch #1. Accuracy on batch 2275 on Training is 30.069200351493848\n",
            "Epoch #1. Accuracy on batch 2276 on Training is 30.071091348265263\n",
            "Epoch #1. Accuracy on batch 2277 on Training is 30.072980684811238\n",
            "Epoch #1. Accuracy on batch 2278 on Training is 30.06938350153576\n",
            "Epoch #1. Accuracy on batch 2279 on Training is 30.07127192982456\n",
            "Batch Id 2280 is having training loss of 1795.33056640625\n",
            "78.05622863769531\n",
            "Epoch #1. Accuracy on batch 2280 on Training is 30.07041867601929\n",
            "Epoch #1. Accuracy on batch 2281 on Training is 30.0681967572305\n",
            "Epoch #1. Accuracy on batch 2282 on Training is 30.065976784932108\n",
            "Epoch #1. Accuracy on batch 2283 on Training is 30.06512697022767\n",
            "Epoch #1. Accuracy on batch 2284 on Training is 30.068380743982495\n",
            "Epoch #1. Accuracy on batch 2285 on Training is 30.06616360454943\n",
            "Epoch #1. Accuracy on batch 2286 on Training is 30.069414079580238\n",
            "Epoch #1. Accuracy on batch 2287 on Training is 30.074027534965033\n",
            "Epoch #1. Accuracy on batch 2288 on Training is 30.077271734381828\n",
            "Epoch #1. Accuracy on batch 2289 on Training is 30.068231441048034\n",
            "Epoch #1. Accuracy on batch 2290 on Training is 30.076931470973374\n",
            "Epoch #1. Accuracy on batch 2291 on Training is 30.076079842931936\n",
            "Epoch #1. Accuracy on batch 2292 on Training is 30.07250327082425\n",
            "Epoch #1. Accuracy on batch 2293 on Training is 30.07165431560593\n",
            "Epoch #1. Accuracy on batch 2294 on Training is 30.074891067538125\n",
            "Epoch #1. Accuracy on batch 2295 on Training is 30.07948606271777\n",
            "Epoch #1. Accuracy on batch 2296 on Training is 30.07999564649543\n",
            "Epoch #1. Accuracy on batch 2297 on Training is 30.080504786771105\n",
            "Epoch #1. Accuracy on batch 2298 on Training is 30.08101348412353\n",
            "Epoch #1. Accuracy on batch 2299 on Training is 30.081521739130434\n",
            "Batch Id 2300 is having training loss of 1781.81982421875\n",
            "30.951595306396484\n",
            "Epoch #1. Accuracy on batch 2300 on Training is 30.08067144719687\n",
            "Epoch #1. Accuracy on batch 2301 on Training is 30.081179409209383\n",
            "Epoch #1. Accuracy on batch 2302 on Training is 30.08304385584021\n",
            "Epoch #1. Accuracy on batch 2303 on Training is 30.079481336805557\n",
            "Epoch #1. Accuracy on batch 2304 on Training is 30.077277657266812\n",
            "Epoch #1. Accuracy on batch 2305 on Training is 30.07778620988725\n",
            "Epoch #1. Accuracy on batch 2306 on Training is 30.07287602947551\n",
            "Epoch #1. Accuracy on batch 2307 on Training is 30.074740034662046\n",
            "Epoch #1. Accuracy on batch 2308 on Training is 30.067128627111302\n",
            "Epoch #1. Accuracy on batch 2309 on Training is 30.074404761904763\n",
            "Epoch #1. Accuracy on batch 2310 on Training is 30.08167459974037\n",
            "Epoch #1. Accuracy on batch 2311 on Training is 30.088938148788927\n",
            "Epoch #1. Accuracy on batch 2312 on Training is 30.0853869433636\n",
            "Epoch #1. Accuracy on batch 2313 on Training is 30.08724070872947\n",
            "Epoch #1. Accuracy on batch 2314 on Training is 30.090442764578835\n",
            "Epoch #1. Accuracy on batch 2315 on Training is 30.085546200345423\n",
            "Epoch #1. Accuracy on batch 2316 on Training is 30.086048769961156\n",
            "Epoch #1. Accuracy on batch 2317 on Training is 30.08655090595341\n",
            "Epoch #1. Accuracy on batch 2318 on Training is 30.087052608883138\n",
            "Epoch #1. Accuracy on batch 2319 on Training is 30.090247844827587\n",
            "Batch Id 2320 is having training loss of 1774.80224609375\n",
            "45.80474090576172\n",
            "Epoch #1. Accuracy on batch 2320 on Training is 30.090747522619562\n",
            "Epoch #1. Accuracy on batch 2321 on Training is 30.095284237726098\n",
            "Epoch #1. Accuracy on batch 2322 on Training is 30.094436074042186\n",
            "Epoch #1. Accuracy on batch 2323 on Training is 30.092243975903614\n",
            "Epoch #1. Accuracy on batch 2324 on Training is 30.09005376344086\n",
            "Epoch #1. Accuracy on batch 2325 on Training is 30.094582975064487\n",
            "Epoch #1. Accuracy on batch 2326 on Training is 30.096422432316288\n",
            "Epoch #1. Accuracy on batch 2327 on Training is 30.098260309278352\n",
            "Epoch #1. Accuracy on batch 2328 on Training is 30.10009660798626\n",
            "Epoch #1. Accuracy on batch 2329 on Training is 30.1019313304721\n",
            "Epoch #1. Accuracy on batch 2330 on Training is 30.10376447876448\n",
            "Epoch #1. Accuracy on batch 2331 on Training is 30.106936106346485\n",
            "Epoch #1. Accuracy on batch 2332 on Training is 30.099389198456922\n",
            "Epoch #1. Accuracy on batch 2333 on Training is 30.103898886032564\n",
            "Epoch #1. Accuracy on batch 2334 on Training is 30.1017130620985\n",
            "Epoch #1. Accuracy on batch 2335 on Training is 30.111568921232877\n",
            "Epoch #1. Accuracy on batch 2336 on Training is 30.105370132648694\n",
            "Epoch #1. Accuracy on batch 2337 on Training is 30.100513259195893\n",
            "Epoch #1. Accuracy on batch 2338 on Training is 30.105012825994013\n",
            "Epoch #1. Accuracy on batch 2339 on Training is 30.108173076923077\n",
            "Batch Id 2340 is having training loss of 1766.37939453125\n",
            "14.611414909362793\n",
            "Epoch #1. Accuracy on batch 2340 on Training is 30.11133062793678\n",
            "Epoch #1. Accuracy on batch 2341 on Training is 30.1131511528608\n",
            "Epoch #1. Accuracy on batch 2342 on Training is 30.116303883909517\n",
            "Epoch #1. Accuracy on batch 2343 on Training is 30.115454351535835\n",
            "Epoch #1. Accuracy on batch 2344 on Training is 30.11327292110874\n",
            "Epoch #1. Accuracy on batch 2345 on Training is 30.11908567774936\n",
            "Epoch #1. Accuracy on batch 2346 on Training is 30.115573072006818\n",
            "Epoch #1. Accuracy on batch 2347 on Training is 30.110732538330495\n",
            "Epoch #1. Accuracy on batch 2348 on Training is 30.113878246062153\n",
            "Epoch #1. Accuracy on batch 2349 on Training is 30.117021276595743\n",
            "Epoch #1. Accuracy on batch 2350 on Training is 30.12016163334751\n",
            "Epoch #1. Accuracy on batch 2351 on Training is 30.116656037414966\n",
            "Epoch #1. Accuracy on batch 2352 on Training is 30.1211219719507\n",
            "Epoch #1. Accuracy on batch 2353 on Training is 30.122929056924384\n",
            "Epoch #1. Accuracy on batch 2354 on Training is 30.116772823779193\n",
            "Epoch #1. Accuracy on batch 2355 on Training is 30.117253820033955\n",
            "Epoch #1. Accuracy on batch 2356 on Training is 30.123037759864236\n",
            "Epoch #1. Accuracy on batch 2357 on Training is 30.122190415606447\n",
            "Epoch #1. Accuracy on batch 2358 on Training is 30.121343789741417\n",
            "Epoch #1. Accuracy on batch 2359 on Training is 30.123146186440678\n",
            "Batch Id 2360 is having training loss of 1753.0325927734375\n",
            "24.597740173339844\n",
            "Epoch #1. Accuracy on batch 2360 on Training is 30.12362346463363\n",
            "Epoch #1. Accuracy on batch 2361 on Training is 30.126746401354783\n",
            "Epoch #1. Accuracy on batch 2362 on Training is 30.127221752010158\n",
            "Epoch #1. Accuracy on batch 2363 on Training is 30.127696700507613\n",
            "Epoch #1. Accuracy on batch 2364 on Training is 30.132135306553913\n",
            "Epoch #1. Accuracy on batch 2365 on Training is 30.131286982248522\n",
            "Epoch #1. Accuracy on batch 2366 on Training is 30.13440008449514\n",
            "Epoch #1. Accuracy on batch 2367 on Training is 30.134871199324323\n",
            "Epoch #1. Accuracy on batch 2368 on Training is 30.13534191642043\n",
            "Epoch #1. Accuracy on batch 2369 on Training is 30.13581223628692\n",
            "Epoch #1. Accuracy on batch 2370 on Training is 30.12837410375369\n",
            "Epoch #1. Accuracy on batch 2371 on Training is 30.13016441821248\n",
            "Epoch #1. Accuracy on batch 2372 on Training is 30.1293194268858\n",
            "Epoch #1. Accuracy on batch 2373 on Training is 30.132424178601518\n",
            "Epoch #1. Accuracy on batch 2374 on Training is 30.13684210526316\n",
            "Epoch #1. Accuracy on batch 2375 on Training is 30.1333648989899\n",
            "Epoch #1. Accuracy on batch 2376 on Training is 30.12989061842659\n",
            "Epoch #1. Accuracy on batch 2377 on Training is 30.129047518923464\n",
            "Epoch #1. Accuracy on batch 2378 on Training is 30.12557797393863\n",
            "Epoch #1. Accuracy on batch 2379 on Training is 30.118172268907564\n",
            "Batch Id 2380 is having training loss of 1741.9122314453125\n",
            "763.8872680664062\n",
            "Epoch #1. Accuracy on batch 2380 on Training is 30.116022679546408\n",
            "Epoch #1. Accuracy on batch 2381 on Training is 30.109939126784216\n",
            "Epoch #1. Accuracy on batch 2382 on Training is 30.110417540914813\n",
            "Epoch #1. Accuracy on batch 2383 on Training is 30.10565226510067\n",
            "Epoch #1. Accuracy on batch 2384 on Training is 30.11006289308176\n",
            "Epoch #1. Accuracy on batch 2385 on Training is 30.107921207041073\n",
            "Epoch #1. Accuracy on batch 2386 on Training is 30.108399664851277\n",
            "Epoch #1. Accuracy on batch 2387 on Training is 30.102334589614742\n",
            "Epoch #1. Accuracy on batch 2388 on Training is 30.102814985349518\n",
            "Epoch #1. Accuracy on batch 2389 on Training is 30.10067991631799\n",
            "Epoch #1. Accuracy on batch 2390 on Training is 30.094625679631953\n",
            "Epoch #1. Accuracy on batch 2391 on Training is 30.089882943143813\n",
            "Epoch #1. Accuracy on batch 2392 on Training is 30.08906184705391\n",
            "Epoch #1. Accuracy on batch 2393 on Training is 30.086936090225564\n",
            "Epoch #1. Accuracy on batch 2394 on Training is 30.09525052192067\n",
            "Epoch #1. Accuracy on batch 2395 on Training is 30.09051544240401\n",
            "Epoch #1. Accuracy on batch 2396 on Training is 30.0936065915728\n",
            "Epoch #1. Accuracy on batch 2397 on Training is 30.086269808173476\n",
            "Epoch #1. Accuracy on batch 2398 on Training is 30.089360150062525\n",
            "Epoch #1. Accuracy on batch 2399 on Training is 30.092447916666668\n",
            "Batch Id 2400 is having training loss of 1752.157958984375\n",
            "20.04471778869629\n",
            "Epoch #1. Accuracy on batch 2400 on Training is 30.098136193252813\n",
            "Epoch #1. Accuracy on batch 2401 on Training is 30.092110741049126\n",
            "Epoch #1. Accuracy on batch 2402 on Training is 30.093893050353724\n",
            "Epoch #1. Accuracy on batch 2403 on Training is 30.094373960066555\n",
            "Epoch #1. Accuracy on batch 2404 on Training is 30.09485446985447\n",
            "Epoch #1. Accuracy on batch 2405 on Training is 30.0940357439734\n",
            "Epoch #1. Accuracy on batch 2406 on Training is 30.08672621520565\n",
            "Epoch #1. Accuracy on batch 2407 on Training is 30.084613787375414\n",
            "Epoch #1. Accuracy on batch 2408 on Training is 30.083800332088003\n",
            "Epoch #1. Accuracy on batch 2409 on Training is 30.08298755186722\n",
            "Epoch #1. Accuracy on batch 2410 on Training is 30.087360016590626\n",
            "Epoch #1. Accuracy on batch 2411 on Training is 30.090433250414595\n",
            "Epoch #1. Accuracy on batch 2412 on Training is 30.08702859510982\n",
            "Epoch #1. Accuracy on batch 2413 on Training is 30.088804888152445\n",
            "Epoch #1. Accuracy on batch 2414 on Training is 30.093167701863354\n",
            "Epoch #1. Accuracy on batch 2415 on Training is 30.09493998344371\n",
            "Epoch #1. Accuracy on batch 2416 on Training is 30.10188249896566\n",
            "Epoch #1. Accuracy on batch 2417 on Training is 30.106234491315135\n",
            "Epoch #1. Accuracy on batch 2418 on Training is 30.10541546093427\n",
            "Epoch #1. Accuracy on batch 2419 on Training is 30.10201446280992\n",
            "Batch Id 2420 is having training loss of 1738.252197265625\n",
            "34.209293365478516\n",
            "Epoch #1. Accuracy on batch 2420 on Training is 30.102488641057413\n",
            "Epoch #1. Accuracy on batch 2421 on Training is 30.10554293971924\n",
            "Epoch #1. Accuracy on batch 2422 on Training is 30.102146099876187\n",
            "Epoch #1. Accuracy on batch 2423 on Training is 30.102619636963695\n",
            "Epoch #1. Accuracy on batch 2424 on Training is 30.10180412371134\n",
            "Epoch #1. Accuracy on batch 2425 on Training is 30.10098928276999\n",
            "Epoch #1. Accuracy on batch 2426 on Training is 30.0963123197363\n",
            "Epoch #1. Accuracy on batch 2427 on Training is 30.09678747940692\n",
            "Epoch #1. Accuracy on batch 2428 on Training is 30.095975710168794\n",
            "Epoch #1. Accuracy on batch 2429 on Training is 30.095164609053498\n",
            "Epoch #1. Accuracy on batch 2430 on Training is 30.099496092143152\n",
            "Epoch #1. Accuracy on batch 2431 on Training is 30.09739925986842\n",
            "Epoch #1. Accuracy on batch 2432 on Training is 30.101726263871765\n",
            "Epoch #1. Accuracy on batch 2433 on Training is 30.099630238290878\n",
            "Epoch #1. Accuracy on batch 2434 on Training is 30.101386036960985\n",
            "Epoch #1. Accuracy on batch 2435 on Training is 30.10314039408867\n",
            "Epoch #1. Accuracy on batch 2436 on Training is 30.104893311448503\n",
            "Epoch #1. Accuracy on batch 2437 on Training is 30.10151763740771\n",
            "Epoch #1. Accuracy on batch 2438 on Training is 30.103269782697826\n",
            "Epoch #1. Accuracy on batch 2439 on Training is 30.101178278688526\n",
            "Batch Id 2440 is having training loss of 1724.466552734375\n",
            "27.67976188659668\n",
            "Epoch #1. Accuracy on batch 2440 on Training is 30.100368701351904\n",
            "Epoch #1. Accuracy on batch 2441 on Training is 30.100839475839475\n",
            "Epoch #1. Accuracy on batch 2442 on Training is 30.106426524764633\n",
            "Epoch #1. Accuracy on batch 2443 on Training is 30.10945171849427\n",
            "Epoch #1. Accuracy on batch 2444 on Training is 30.11247443762781\n",
            "Epoch #1. Accuracy on batch 2445 on Training is 30.114217089125102\n",
            "Epoch #1. Accuracy on batch 2446 on Training is 30.114681242337557\n",
            "Epoch #1. Accuracy on batch 2447 on Training is 30.11514501633987\n",
            "Epoch #1. Accuracy on batch 2448 on Training is 30.116884442629644\n",
            "Epoch #1. Accuracy on batch 2449 on Training is 30.118622448979593\n",
            "Epoch #1. Accuracy on batch 2450 on Training is 30.11780905752754\n",
            "Epoch #1. Accuracy on batch 2451 on Training is 30.116996329526916\n",
            "Epoch #1. Accuracy on batch 2452 on Training is 30.112362413371383\n",
            "Epoch #1. Accuracy on batch 2453 on Training is 30.109005704971477\n",
            "Epoch #1. Accuracy on batch 2454 on Training is 30.103105906313644\n",
            "Epoch #1. Accuracy on batch 2455 on Training is 30.106117671009773\n",
            "Epoch #1. Accuracy on batch 2456 on Training is 30.105311355311354\n",
            "Epoch #1. Accuracy on batch 2457 on Training is 30.11976200162734\n",
            "Epoch #1. Accuracy on batch 2458 on Training is 30.111325742171616\n",
            "Epoch #1. Accuracy on batch 2459 on Training is 30.109247967479675\n",
            "Batch Id 2460 is having training loss of 1727.4234619140625\n",
            "10998.2431640625\n",
            "Epoch #1. Accuracy on batch 2460 on Training is 30.110981308411215\n",
            "Epoch #1. Accuracy on batch 2461 on Training is 30.10890536149472\n",
            "Epoch #1. Accuracy on batch 2462 on Training is 30.111906211936663\n",
            "Epoch #1. Accuracy on batch 2463 on Training is 30.111099837662337\n",
            "Epoch #1. Accuracy on batch 2464 on Training is 30.11156186612576\n",
            "Epoch #1. Accuracy on batch 2465 on Training is 30.108221816707218\n",
            "Epoch #1. Accuracy on batch 2466 on Training is 30.108684637211187\n",
            "Epoch #1. Accuracy on batch 2467 on Training is 30.112945705024313\n",
            "Epoch #1. Accuracy on batch 2468 on Training is 30.12226609963548\n",
            "Epoch #1. Accuracy on batch 2469 on Training is 30.127783400809715\n",
            "Epoch #1. Accuracy on batch 2470 on Training is 30.130766895993524\n",
            "Epoch #1. Accuracy on batch 2471 on Training is 30.131219660194176\n",
            "Epoch #1. Accuracy on batch 2472 on Training is 30.135463000404368\n",
            "Epoch #1. Accuracy on batch 2473 on Training is 30.135913500404204\n",
            "Epoch #1. Accuracy on batch 2474 on Training is 30.133838383838384\n",
            "Epoch #1. Accuracy on batch 2475 on Training is 30.12797859450727\n",
            "Epoch #1. Accuracy on batch 2476 on Training is 30.12338514331853\n",
            "Epoch #1. Accuracy on batch 2477 on Training is 30.121317594834544\n",
            "Epoch #1. Accuracy on batch 2478 on Training is 30.123033481242437\n",
            "Epoch #1. Accuracy on batch 2479 on Training is 30.122227822580644\n",
            "Batch Id 2480 is having training loss of 1741.6485595703125\n",
            "60.97201919555664\n",
            "Epoch #1. Accuracy on batch 2480 on Training is 30.121422813381702\n",
            "Epoch #1. Accuracy on batch 2481 on Training is 30.123136583400484\n",
            "Epoch #1. Accuracy on batch 2482 on Training is 30.128624647603704\n",
            "Epoch #1. Accuracy on batch 2483 on Training is 30.12781803542673\n",
            "Epoch #1. Accuracy on batch 2484 on Training is 30.12952716297787\n",
            "Epoch #1. Accuracy on batch 2485 on Training is 30.129977876106196\n",
            "Epoch #1. Accuracy on batch 2486 on Training is 30.125402090872537\n",
            "Epoch #1. Accuracy on batch 2487 on Training is 30.127110128617364\n",
            "Epoch #1. Accuracy on batch 2488 on Training is 30.127561269586177\n",
            "Epoch #1. Accuracy on batch 2489 on Training is 30.12550200803213\n",
            "Epoch #1. Accuracy on batch 2490 on Training is 30.132226013649138\n",
            "Epoch #1. Accuracy on batch 2491 on Training is 30.127658507223114\n",
            "Epoch #1. Accuracy on batch 2492 on Training is 30.12936221419976\n",
            "Epoch #1. Accuracy on batch 2493 on Training is 30.128558540497192\n",
            "Epoch #1. Accuracy on batch 2494 on Training is 30.131513026052104\n",
            "Epoch #1. Accuracy on batch 2495 on Training is 30.131961137820515\n",
            "Epoch #1. Accuracy on batch 2496 on Training is 30.132408890668803\n",
            "Epoch #1. Accuracy on batch 2497 on Training is 30.1353582866293\n",
            "Epoch #1. Accuracy on batch 2498 on Training is 30.13205282112845\n",
            "Epoch #1. Accuracy on batch 2499 on Training is 30.1375\n",
            "Batch Id 2500 is having training loss of 1729.4923095703125\n",
            "18.11288833618164\n",
            "Epoch #1. Accuracy on batch 2500 on Training is 30.13919432227109\n",
            "Epoch #1. Accuracy on batch 2501 on Training is 30.138389288569144\n",
            "Epoch #1. Accuracy on batch 2502 on Training is 30.137584898122252\n",
            "Epoch #1. Accuracy on batch 2503 on Training is 30.13303714057508\n",
            "Epoch #1. Accuracy on batch 2504 on Training is 30.129740518962077\n",
            "Epoch #1. Accuracy on batch 2505 on Training is 30.12519952114924\n",
            "Epoch #1. Accuracy on batch 2506 on Training is 30.124401675309134\n",
            "Epoch #1. Accuracy on batch 2507 on Training is 30.12111244019139\n",
            "Epoch #1. Accuracy on batch 2508 on Training is 30.119071343164606\n",
            "Epoch #1. Accuracy on batch 2509 on Training is 30.1195219123506\n",
            "Epoch #1. Accuracy on batch 2510 on Training is 30.12246117084827\n",
            "Epoch #1. Accuracy on batch 2511 on Training is 30.121666003184714\n",
            "Epoch #1. Accuracy on batch 2512 on Training is 30.119627934739356\n",
            "Epoch #1. Accuracy on batch 2513 on Training is 30.117591487669053\n",
            "Epoch #1. Accuracy on batch 2514 on Training is 30.118041749502982\n",
            "Epoch #1. Accuracy on batch 2515 on Training is 30.118491653418126\n",
            "Epoch #1. Accuracy on batch 2516 on Training is 30.11645808502185\n",
            "Epoch #1. Accuracy on batch 2517 on Training is 30.114426131850674\n",
            "Epoch #1. Accuracy on batch 2518 on Training is 30.1161175069472\n",
            "Epoch #1. Accuracy on batch 2519 on Training is 30.1140873015873\n",
            "Batch Id 2520 is having training loss of 1716.54296875\n",
            "14.578747749328613\n",
            "Epoch #1. Accuracy on batch 2520 on Training is 30.11577746925823\n",
            "Epoch #1. Accuracy on batch 2521 on Training is 30.113749008723236\n",
            "Epoch #1. Accuracy on batch 2522 on Training is 30.114199365834324\n",
            "Epoch #1. Accuracy on batch 2523 on Training is 30.11712559429477\n",
            "Epoch #1. Accuracy on batch 2524 on Training is 30.11509900990099\n",
            "Epoch #1. Accuracy on batch 2525 on Training is 30.108125494853525\n",
            "Epoch #1. Accuracy on batch 2526 on Training is 30.109814008705975\n",
            "Epoch #1. Accuracy on batch 2527 on Training is 30.104084256329113\n",
            "Epoch #1. Accuracy on batch 2528 on Training is 30.100830367734282\n",
            "Epoch #1. Accuracy on batch 2529 on Training is 30.10375494071146\n",
            "Epoch #1. Accuracy on batch 2530 on Training is 30.09926906361122\n",
            "Epoch #1. Accuracy on batch 2531 on Training is 30.09231832543444\n",
            "Epoch #1. Accuracy on batch 2532 on Training is 30.091541650217135\n",
            "Epoch #1. Accuracy on batch 2533 on Training is 30.091998816101025\n",
            "Epoch #1. Accuracy on batch 2534 on Training is 30.09122287968442\n",
            "Epoch #1. Accuracy on batch 2535 on Training is 30.087983044164037\n",
            "Epoch #1. Accuracy on batch 2536 on Training is 30.08844107213244\n",
            "Epoch #1. Accuracy on batch 2537 on Training is 30.09136130811663\n",
            "Epoch #1. Accuracy on batch 2538 on Training is 30.090586845214652\n",
            "Epoch #1. Accuracy on batch 2539 on Training is 30.089812992125985\n",
            "Batch Id 2540 is having training loss of 1729.0716552734375\n",
            "21.08081817626953\n",
            "Epoch #1. Accuracy on batch 2540 on Training is 30.086580086580085\n",
            "Epoch #1. Accuracy on batch 2541 on Training is 30.090725806451612\n",
            "Epoch #1. Accuracy on batch 2542 on Training is 30.096097129374755\n",
            "Epoch #1. Accuracy on batch 2543 on Training is 30.09655070754717\n",
            "Epoch #1. Accuracy on batch 2544 on Training is 30.094548133595286\n",
            "Epoch #1. Accuracy on batch 2545 on Training is 30.093774548311075\n",
            "Epoch #1. Accuracy on batch 2546 on Training is 30.09177463682764\n",
            "Epoch #1. Accuracy on batch 2547 on Training is 30.089776295133436\n",
            "Epoch #1. Accuracy on batch 2548 on Training is 30.090231463318947\n",
            "Epoch #1. Accuracy on batch 2549 on Training is 30.09313725490196\n",
            "Epoch #1. Accuracy on batch 2550 on Training is 30.091140729125833\n",
            "Epoch #1. Accuracy on batch 2551 on Training is 30.089145768025077\n",
            "Epoch #1. Accuracy on batch 2552 on Training is 30.083480219349784\n",
            "Epoch #1. Accuracy on batch 2553 on Training is 30.082713390759594\n",
            "Epoch #1. Accuracy on batch 2554 on Training is 30.081947162426616\n",
            "Epoch #1. Accuracy on batch 2555 on Training is 30.08240414710485\n",
            "Epoch #1. Accuracy on batch 2556 on Training is 30.076750097770827\n",
            "Epoch #1. Accuracy on batch 2557 on Training is 30.079652071931196\n",
            "Epoch #1. Accuracy on batch 2558 on Training is 30.075224697147323\n",
            "Epoch #1. Accuracy on batch 2559 on Training is 30.07568359375\n",
            "Batch Id 2560 is having training loss of 1731.957763671875\n",
            "23.610633850097656\n",
            "Epoch #1. Accuracy on batch 2560 on Training is 30.070040999609528\n",
            "Epoch #1. Accuracy on batch 2561 on Training is 30.07050156128025\n",
            "Epoch #1. Accuracy on batch 2562 on Training is 30.077058134998047\n",
            "Epoch #1. Accuracy on batch 2563 on Training is 30.071421606864273\n",
            "Epoch #1. Accuracy on batch 2564 on Training is 30.077972709551656\n",
            "Epoch #1. Accuracy on batch 2565 on Training is 30.077211613406078\n",
            "Epoch #1. Accuracy on batch 2566 on Training is 30.07766848461239\n",
            "Epoch #1. Accuracy on batch 2567 on Training is 30.079341900311526\n",
            "Epoch #1. Accuracy on batch 2568 on Training is 30.082230439859867\n",
            "Epoch #1. Accuracy on batch 2569 on Training is 30.08511673151751\n",
            "Epoch #1. Accuracy on batch 2570 on Training is 30.08800077790743\n",
            "Epoch #1. Accuracy on batch 2571 on Training is 30.08845256609642\n",
            "Epoch #1. Accuracy on batch 2572 on Training is 30.091333074232413\n",
            "Epoch #1. Accuracy on batch 2573 on Training is 30.082070707070706\n",
            "Epoch #1. Accuracy on batch 2574 on Training is 30.08009708737864\n",
            "Epoch #1. Accuracy on batch 2575 on Training is 30.08297748447205\n",
            "Epoch #1. Accuracy on batch 2576 on Training is 30.091918897943344\n",
            "Epoch #1. Accuracy on batch 2577 on Training is 30.09236811481769\n",
            "Epoch #1. Accuracy on batch 2578 on Training is 30.09281698332687\n",
            "Epoch #1. Accuracy on batch 2579 on Training is 30.095687984496124\n",
            "Batch Id 2580 is having training loss of 1734.5899658203125\n",
            "9.554139137268066\n",
            "Epoch #1. Accuracy on batch 2580 on Training is 30.09371367686943\n",
            "Epoch #1. Accuracy on batch 2581 on Training is 30.094161502711078\n",
            "Epoch #1. Accuracy on batch 2582 on Training is 30.087349980642664\n",
            "Epoch #1. Accuracy on batch 2583 on Training is 30.09142801857585\n",
            "Epoch #1. Accuracy on batch 2584 on Training is 30.099129593810446\n",
            "Epoch #1. Accuracy on batch 2585 on Training is 30.101991492652747\n",
            "Epoch #1. Accuracy on batch 2586 on Training is 30.10243525318902\n",
            "Epoch #1. Accuracy on batch 2587 on Training is 30.104086166924265\n",
            "Epoch #1. Accuracy on batch 2588 on Training is 30.10452877558903\n",
            "Epoch #1. Accuracy on batch 2589 on Training is 30.106177606177607\n",
            "Epoch #1. Accuracy on batch 2590 on Training is 30.100588575839446\n",
            "Epoch #1. Accuracy on batch 2591 on Training is 30.09741512345679\n",
            "Epoch #1. Accuracy on batch 2592 on Training is 30.09665445430004\n",
            "Epoch #1. Accuracy on batch 2593 on Training is 30.100713184271395\n",
            "Epoch #1. Accuracy on batch 2594 on Training is 30.09995183044316\n",
            "Epoch #1. Accuracy on batch 2595 on Training is 30.09317218798151\n",
            "Epoch #1. Accuracy on batch 2596 on Training is 30.093617635733537\n",
            "Epoch #1. Accuracy on batch 2597 on Training is 30.088048498845264\n",
            "Epoch #1. Accuracy on batch 2598 on Training is 30.093305117352827\n",
            "Epoch #1. Accuracy on batch 2599 on Training is 30.094951923076923\n",
            "Batch Id 2600 is having training loss of 1722.5235595703125\n",
            "56.17193603515625\n",
            "Epoch #1. Accuracy on batch 2600 on Training is 30.08938869665513\n",
            "Epoch #1. Accuracy on batch 2601 on Training is 30.087432744043046\n",
            "Epoch #1. Accuracy on batch 2602 on Training is 30.085478294275834\n",
            "Epoch #1. Accuracy on batch 2603 on Training is 30.08352534562212\n",
            "Epoch #1. Accuracy on batch 2604 on Training is 30.081573896353166\n",
            "Epoch #1. Accuracy on batch 2605 on Training is 30.083221412125862\n",
            "Epoch #1. Accuracy on batch 2606 on Training is 30.084867663981587\n",
            "Epoch #1. Accuracy on batch 2607 on Training is 30.086512653374232\n",
            "Epoch #1. Accuracy on batch 2608 on Training is 30.08096972019931\n",
            "Epoch #1. Accuracy on batch 2609 on Training is 30.07662835249042\n",
            "Epoch #1. Accuracy on batch 2610 on Training is 30.074684029107623\n",
            "Epoch #1. Accuracy on batch 2611 on Training is 30.077526799387442\n",
            "Epoch #1. Accuracy on batch 2612 on Training is 30.073191733639494\n",
            "Epoch #1. Accuracy on batch 2613 on Training is 30.070055470543227\n",
            "Epoch #1. Accuracy on batch 2614 on Training is 30.07409177820268\n",
            "Epoch #1. Accuracy on batch 2615 on Training is 30.073346712538225\n",
            "Epoch #1. Accuracy on batch 2616 on Training is 30.07260221627818\n",
            "Epoch #1. Accuracy on batch 2617 on Training is 30.06827731092437\n",
            "Epoch #1. Accuracy on batch 2618 on Training is 30.072308132875143\n",
            "Epoch #1. Accuracy on batch 2619 on Training is 30.076335877862597\n",
            "Batch Id 2620 is having training loss of 1709.850830078125\n",
            "59.03627014160156\n",
            "Epoch #1. Accuracy on batch 2620 on Training is 30.075591377336895\n",
            "Epoch #1. Accuracy on batch 2621 on Training is 30.07127192982456\n",
            "Epoch #1. Accuracy on batch 2622 on Training is 30.07291269538696\n",
            "Epoch #1. Accuracy on batch 2623 on Training is 30.07693407012195\n",
            "Epoch #1. Accuracy on batch 2624 on Training is 30.07857142857143\n",
            "Epoch #1. Accuracy on batch 2625 on Training is 30.07782749428789\n",
            "Epoch #1. Accuracy on batch 2626 on Training is 30.0770841263799\n",
            "Epoch #1. Accuracy on batch 2627 on Training is 30.078719558599694\n",
            "Epoch #1. Accuracy on batch 2628 on Training is 30.07441042221377\n",
            "Epoch #1. Accuracy on batch 2629 on Training is 30.07842205323194\n",
            "Epoch #1. Accuracy on batch 2630 on Training is 30.076491828202204\n",
            "Epoch #1. Accuracy on batch 2631 on Training is 30.078125\n",
            "Epoch #1. Accuracy on batch 2632 on Training is 30.077383213064945\n",
            "Epoch #1. Accuracy on batch 2633 on Training is 30.082574031890662\n",
            "Epoch #1. Accuracy on batch 2634 on Training is 30.077087286527515\n",
            "Epoch #1. Accuracy on batch 2635 on Training is 30.081088770864948\n",
            "Epoch #1. Accuracy on batch 2636 on Training is 30.080346985210465\n",
            "Epoch #1. Accuracy on batch 2637 on Training is 30.081974981046248\n",
            "Epoch #1. Accuracy on batch 2638 on Training is 30.088338385752177\n",
            "Epoch #1. Accuracy on batch 2639 on Training is 30.092329545454547\n",
            "Batch Id 2640 is having training loss of 1717.070068359375\n",
            "7331.9111328125\n",
            "Epoch #1. Accuracy on batch 2640 on Training is 30.095134418780766\n",
            "Epoch #1. Accuracy on batch 2641 on Training is 30.092023088569267\n",
            "Epoch #1. Accuracy on batch 2642 on Training is 30.096008323874386\n",
            "Epoch #1. Accuracy on batch 2643 on Training is 30.0964447806354\n",
            "Epoch #1. Accuracy on batch 2644 on Training is 30.098062381852554\n",
            "Epoch #1. Accuracy on batch 2645 on Training is 30.102040816326532\n",
            "Epoch #1. Accuracy on batch 2646 on Training is 30.108377408386854\n",
            "Epoch #1. Accuracy on batch 2647 on Training is 30.111168806646525\n",
            "Epoch #1. Accuracy on batch 2648 on Training is 30.108059645149112\n",
            "Epoch #1. Accuracy on batch 2649 on Training is 30.1061320754717\n",
            "Epoch #1. Accuracy on batch 2650 on Training is 30.10184835910977\n",
            "Epoch #1. Accuracy on batch 2651 on Training is 30.10581636500754\n",
            "Epoch #1. Accuracy on batch 2652 on Training is 30.10506973237844\n",
            "Epoch #1. Accuracy on batch 2653 on Training is 30.106678598342125\n",
            "Epoch #1. Accuracy on batch 2654 on Training is 30.111817325800377\n",
            "Epoch #1. Accuracy on batch 2655 on Training is 30.112245858433734\n",
            "Epoch #1. Accuracy on batch 2656 on Training is 30.112674068498308\n",
            "Epoch #1. Accuracy on batch 2657 on Training is 30.114277652370202\n",
            "Epoch #1. Accuracy on batch 2658 on Training is 30.119405791650998\n",
            "Epoch #1. Accuracy on batch 2659 on Training is 30.116306390977442\n",
            "Batch Id 2660 is having training loss of 1717.0343017578125\n",
            "5694.89990234375\n",
            "Epoch #1. Accuracy on batch 2660 on Training is 30.117906801954152\n",
            "Epoch #1. Accuracy on batch 2661 on Training is 30.123027798647634\n",
            "Epoch #1. Accuracy on batch 2662 on Training is 30.126971460758543\n",
            "Epoch #1. Accuracy on batch 2663 on Training is 30.12621996996997\n",
            "Epoch #1. Accuracy on batch 2664 on Training is 30.12781425891182\n",
            "Epoch #1. Accuracy on batch 2665 on Training is 30.12471867966992\n",
            "Epoch #1. Accuracy on batch 2666 on Training is 30.122797150356206\n",
            "Epoch #1. Accuracy on batch 2667 on Training is 30.12204835082459\n",
            "Epoch #1. Accuracy on batch 2668 on Training is 30.11661671037842\n",
            "Epoch #1. Accuracy on batch 2669 on Training is 30.114700374531836\n",
            "Epoch #1. Accuracy on batch 2670 on Training is 30.110445526020218\n",
            "Epoch #1. Accuracy on batch 2671 on Training is 30.10970247005988\n",
            "Epoch #1. Accuracy on batch 2672 on Training is 30.10545267489712\n",
            "Epoch #1. Accuracy on batch 2673 on Training is 30.103543380703066\n",
            "Epoch #1. Accuracy on batch 2674 on Training is 30.102803738317757\n",
            "Epoch #1. Accuracy on batch 2675 on Training is 30.099729073243648\n",
            "Epoch #1. Accuracy on batch 2676 on Training is 30.10132611131864\n",
            "Epoch #1. Accuracy on batch 2677 on Training is 30.100588125466768\n",
            "Epoch #1. Accuracy on batch 2678 on Training is 30.104516610675624\n",
            "Epoch #1. Accuracy on batch 2679 on Training is 30.104944029850746\n",
            "Batch Id 2680 is having training loss of 1704.91455078125\n",
            "60.068729400634766\n",
            "Epoch #1. Accuracy on batch 2680 on Training is 30.10070869078702\n",
            "Epoch #1. Accuracy on batch 2681 on Training is 30.10696308724832\n",
            "Epoch #1. Accuracy on batch 2682 on Training is 30.107389116660453\n",
            "Epoch #1. Accuracy on batch 2683 on Training is 30.10781482861401\n",
            "Epoch #1. Accuracy on batch 2684 on Training is 30.10707635009311\n",
            "Epoch #1. Accuracy on batch 2685 on Training is 30.107501861504094\n",
            "Epoch #1. Accuracy on batch 2686 on Training is 30.114905098622998\n",
            "Epoch #1. Accuracy on batch 2687 on Training is 30.11416480654762\n",
            "Epoch #1. Accuracy on batch 2688 on Training is 30.115749349200446\n",
            "Epoch #1. Accuracy on batch 2689 on Training is 30.116171003717472\n",
            "Epoch #1. Accuracy on batch 2690 on Training is 30.118914901523596\n",
            "Epoch #1. Accuracy on batch 2691 on Training is 30.117013372956908\n",
            "Epoch #1. Accuracy on batch 2692 on Training is 30.119754920163388\n",
            "Epoch #1. Accuracy on batch 2693 on Training is 30.119014476614698\n",
            "Epoch #1. Accuracy on batch 2694 on Training is 30.11943413729128\n",
            "Epoch #1. Accuracy on batch 2695 on Training is 30.116376112759642\n",
            "Epoch #1. Accuracy on batch 2696 on Training is 30.113320355951057\n",
            "Epoch #1. Accuracy on batch 2697 on Training is 30.10795033358043\n",
            "Epoch #1. Accuracy on batch 2698 on Training is 30.1037421267136\n",
            "Epoch #1. Accuracy on batch 2699 on Training is 30.105324074074073\n",
            "Batch Id 2700 is having training loss of 1721.903564453125\n",
            "5563.64501953125\n",
            "Epoch #1. Accuracy on batch 2700 on Training is 30.10111995557201\n",
            "Epoch #1. Accuracy on batch 2701 on Training is 30.102701702442634\n",
            "Epoch #1. Accuracy on batch 2702 on Training is 30.104282278949317\n",
            "Epoch #1. Accuracy on batch 2703 on Training is 30.102394600591715\n",
            "Epoch #1. Accuracy on batch 2704 on Training is 30.107439926062845\n",
            "Epoch #1. Accuracy on batch 2705 on Training is 30.10208795269771\n",
            "Epoch #1. Accuracy on batch 2706 on Training is 30.10020317694865\n",
            "Epoch #1. Accuracy on batch 2707 on Training is 30.09947378138848\n",
            "Epoch #1. Accuracy on batch 2708 on Training is 30.103359173126616\n",
            "Epoch #1. Accuracy on batch 2709 on Training is 30.104935424354245\n",
            "Epoch #1. Accuracy on batch 2710 on Training is 30.104205090372556\n",
            "Epoch #1. Accuracy on batch 2711 on Training is 30.105779867256636\n",
            "Epoch #1. Accuracy on batch 2712 on Training is 30.102746037596756\n",
            "Epoch #1. Accuracy on batch 2713 on Training is 30.104320191599115\n",
            "Epoch #1. Accuracy on batch 2714 on Training is 30.105893186003684\n",
            "Epoch #1. Accuracy on batch 2715 on Training is 30.10861561119293\n",
            "Epoch #1. Accuracy on batch 2716 on Training is 30.109035701140964\n",
            "Epoch #1. Accuracy on batch 2717 on Training is 30.10715599705666\n",
            "Epoch #1. Accuracy on batch 2718 on Training is 30.109874954027216\n",
            "Epoch #1. Accuracy on batch 2719 on Training is 30.107996323529413\n",
            "Batch Id 2720 is having training loss of 1761.589111328125\n",
            "55.95545959472656\n",
            "Epoch #1. Accuracy on batch 2720 on Training is 30.103822124219036\n",
            "Epoch #1. Accuracy on batch 2721 on Training is 30.105391256429098\n",
            "Epoch #1. Accuracy on batch 2722 on Training is 30.108106867425633\n",
            "Epoch #1. Accuracy on batch 2723 on Training is 30.102790014684288\n",
            "Epoch #1. Accuracy on batch 2724 on Training is 30.099770642201836\n",
            "Epoch #1. Accuracy on batch 2725 on Training is 30.09675348495965\n",
            "Epoch #1. Accuracy on batch 2726 on Training is 30.093738540520718\n",
            "Epoch #1. Accuracy on batch 2727 on Training is 30.0964534457478\n",
            "Epoch #1. Accuracy on batch 2728 on Training is 30.096876145108098\n",
            "Epoch #1. Accuracy on batch 2729 on Training is 30.09271978021978\n",
            "Epoch #1. Accuracy on batch 2730 on Training is 30.09199926766752\n",
            "Epoch #1. Accuracy on batch 2731 on Training is 30.092423133235723\n",
            "Epoch #1. Accuracy on batch 2732 on Training is 30.088272960117088\n",
            "Epoch #1. Accuracy on batch 2733 on Training is 30.07955376737381\n",
            "Epoch #1. Accuracy on batch 2734 on Training is 30.082266910420476\n",
            "Epoch #1. Accuracy on batch 2735 on Training is 30.083835891812864\n",
            "Epoch #1. Accuracy on batch 2736 on Training is 30.08312020460358\n",
            "Epoch #1. Accuracy on batch 2737 on Training is 30.084687728268808\n",
            "Epoch #1. Accuracy on batch 2738 on Training is 30.08397225264695\n",
            "Epoch #1. Accuracy on batch 2739 on Training is 30.08097627737226\n",
            "Batch Id 2740 is having training loss of 1758.73974609375\n",
            "21.393232345581055\n",
            "Epoch #1. Accuracy on batch 2740 on Training is 30.080262677854797\n",
            "Epoch #1. Accuracy on batch 2741 on Training is 30.08182895696572\n",
            "Epoch #1. Accuracy on batch 2742 on Training is 30.08225483047758\n",
            "Epoch #1. Accuracy on batch 2743 on Training is 30.083819241982507\n",
            "Epoch #1. Accuracy on batch 2744 on Training is 30.086520947176684\n",
            "Epoch #1. Accuracy on batch 2745 on Training is 30.08239257101238\n",
            "Epoch #1. Accuracy on batch 2746 on Training is 30.08054240990171\n",
            "Epoch #1. Accuracy on batch 2747 on Training is 30.07414483260553\n",
            "Epoch #1. Accuracy on batch 2748 on Training is 30.07570934885413\n",
            "Epoch #1. Accuracy on batch 2749 on Training is 30.073863636363637\n",
            "Epoch #1. Accuracy on batch 2750 on Training is 30.07429116684842\n",
            "Epoch #1. Accuracy on batch 2751 on Training is 30.07358284883721\n",
            "Epoch #1. Accuracy on batch 2752 on Training is 30.07060479476934\n",
            "Epoch #1. Accuracy on batch 2753 on Training is 30.067628903413215\n",
            "Epoch #1. Accuracy on batch 2754 on Training is 30.066923774954628\n",
            "Epoch #1. Accuracy on batch 2755 on Training is 30.0673530478955\n",
            "Epoch #1. Accuracy on batch 2756 on Training is 30.062114617337684\n",
            "Epoch #1. Accuracy on batch 2757 on Training is 30.056879985496735\n",
            "Epoch #1. Accuracy on batch 2758 on Training is 30.053914461761508\n",
            "Epoch #1. Accuracy on batch 2759 on Training is 30.05774456521739\n",
            "Batch Id 2760 is having training loss of 1747.50537109375\n",
            "28.41164779663086\n",
            "Epoch #1. Accuracy on batch 2760 on Training is 30.054780876494025\n",
            "Epoch #1. Accuracy on batch 2761 on Training is 30.05295076031861\n",
            "Epoch #1. Accuracy on batch 2762 on Training is 30.05225298588491\n",
            "Epoch #1. Accuracy on batch 2763 on Training is 30.053816931982634\n",
            "Epoch #1. Accuracy on batch 2764 on Training is 30.04746835443038\n",
            "Epoch #1. Accuracy on batch 2765 on Training is 30.049032899493852\n",
            "Epoch #1. Accuracy on batch 2766 on Training is 30.05285507770148\n",
            "Epoch #1. Accuracy on batch 2767 on Training is 30.051029624277458\n",
            "Epoch #1. Accuracy on batch 2768 on Training is 30.048076923076923\n",
            "Epoch #1. Accuracy on batch 2769 on Training is 30.04399819494585\n",
            "Epoch #1. Accuracy on batch 2770 on Training is 30.041050162396246\n",
            "Epoch #1. Accuracy on batch 2771 on Training is 30.048250360750362\n",
            "Epoch #1. Accuracy on batch 2772 on Training is 30.044175982690227\n",
            "Epoch #1. Accuracy on batch 2773 on Training is 30.044610670511897\n",
            "Epoch #1. Accuracy on batch 2774 on Training is 30.04391891891892\n",
            "Epoch #1. Accuracy on batch 2775 on Training is 30.047730547550433\n",
            "Epoch #1. Accuracy on batch 2776 on Training is 30.045912855599568\n",
            "Epoch #1. Accuracy on batch 2777 on Training is 30.044096472282217\n",
            "Epoch #1. Accuracy on batch 2778 on Training is 30.046779417056495\n",
            "Epoch #1. Accuracy on batch 2779 on Training is 30.046088129496404\n",
            "Batch Id 2780 is having training loss of 1759.6865234375\n",
            "19.34181785583496\n",
            "Epoch #1. Accuracy on batch 2780 on Training is 30.046521035598705\n",
            "Epoch #1. Accuracy on batch 2781 on Training is 30.050323508267432\n",
            "Epoch #1. Accuracy on batch 2782 on Training is 30.049631692418252\n",
            "Epoch #1. Accuracy on batch 2783 on Training is 30.05230783045977\n",
            "Epoch #1. Accuracy on batch 2784 on Training is 30.05273788150808\n",
            "Epoch #1. Accuracy on batch 2785 on Training is 30.053167623833453\n",
            "Epoch #1. Accuracy on batch 2786 on Training is 30.052475780409043\n",
            "Epoch #1. Accuracy on batch 2787 on Training is 30.05402618364419\n",
            "Epoch #1. Accuracy on batch 2788 on Training is 30.048852635353175\n",
            "Epoch #1. Accuracy on batch 2789 on Training is 30.05152329749104\n",
            "Epoch #1. Accuracy on batch 2790 on Training is 30.04747402364744\n",
            "Epoch #1. Accuracy on batch 2791 on Training is 30.04902399713467\n",
            "Epoch #1. Accuracy on batch 2792 on Training is 30.048335123523092\n",
            "Epoch #1. Accuracy on batch 2793 on Training is 30.051002147458842\n",
            "Epoch #1. Accuracy on batch 2794 on Training is 30.05031305903399\n",
            "Epoch #1. Accuracy on batch 2795 on Training is 30.049624463519315\n",
            "Epoch #1. Accuracy on batch 2796 on Training is 30.050053628888094\n",
            "Epoch #1. Accuracy on batch 2797 on Training is 30.048248749106506\n",
            "Epoch #1. Accuracy on batch 2798 on Training is 30.053143979992853\n",
            "Epoch #1. Accuracy on batch 2799 on Training is 30.0546875\n",
            "Batch Id 2800 is having training loss of 1747.583984375\n",
            "19.554485321044922\n",
            "Epoch #1. Accuracy on batch 2800 on Training is 30.049535880042843\n",
            "Epoch #1. Accuracy on batch 2801 on Training is 30.04884903640257\n",
            "Epoch #1. Accuracy on batch 2802 on Training is 30.048162682839813\n",
            "Epoch #1. Accuracy on batch 2803 on Training is 30.047476818830244\n",
            "Epoch #1. Accuracy on batch 2804 on Training is 30.050133689839573\n",
            "Epoch #1. Accuracy on batch 2805 on Training is 30.05056129722024\n",
            "Epoch #1. Accuracy on batch 2806 on Training is 30.046535447096545\n",
            "Epoch #1. Accuracy on batch 2807 on Training is 30.048076923076923\n",
            "Epoch #1. Accuracy on batch 2808 on Training is 30.042942328230687\n",
            "Epoch #1. Accuracy on batch 2809 on Training is 30.04225978647687\n",
            "Epoch #1. Accuracy on batch 2810 on Training is 30.043801138384918\n",
            "Epoch #1. Accuracy on batch 2811 on Training is 30.0464527027027\n",
            "Epoch #1. Accuracy on batch 2812 on Training is 30.051324209029506\n",
            "Epoch #1. Accuracy on batch 2813 on Training is 30.05397121535181\n",
            "Epoch #1. Accuracy on batch 2814 on Training is 30.05550621669627\n",
            "Epoch #1. Accuracy on batch 2815 on Training is 30.054820667613637\n",
            "Epoch #1. Accuracy on batch 2816 on Training is 30.053026269080583\n",
            "Epoch #1. Accuracy on batch 2817 on Training is 30.051233144073812\n",
            "Epoch #1. Accuracy on batch 2818 on Training is 30.047224192976234\n",
            "Epoch #1. Accuracy on batch 2819 on Training is 30.042109929078013\n",
            "Batch Id 2820 is having training loss of 1744.809326171875\n",
            "12.831755638122559\n",
            "Epoch #1. Accuracy on batch 2820 on Training is 30.044753633463312\n",
            "Epoch #1. Accuracy on batch 2821 on Training is 30.0507175761871\n",
            "Epoch #1. Accuracy on batch 2822 on Training is 30.05335635848388\n",
            "Epoch #1. Accuracy on batch 2823 on Training is 30.050460339943342\n",
            "Epoch #1. Accuracy on batch 2824 on Training is 30.047566371681416\n",
            "Epoch #1. Accuracy on batch 2825 on Training is 30.046886058032555\n",
            "Epoch #1. Accuracy on batch 2826 on Training is 30.048417049876193\n",
            "Epoch #1. Accuracy on batch 2827 on Training is 30.043316831683168\n",
            "Epoch #1. Accuracy on batch 2828 on Training is 30.04374337221633\n",
            "Epoch #1. Accuracy on batch 2829 on Training is 30.04416961130742\n",
            "Epoch #1. Accuracy on batch 2830 on Training is 30.03907629812787\n",
            "Epoch #1. Accuracy on batch 2831 on Training is 30.039503884180792\n",
            "Epoch #1. Accuracy on batch 2832 on Training is 30.04544652312037\n",
            "Epoch #1. Accuracy on batch 2833 on Training is 30.043666196189132\n",
            "Epoch #1. Accuracy on batch 2834 on Training is 30.045194003527335\n",
            "Epoch #1. Accuracy on batch 2835 on Training is 30.04451692524683\n",
            "Epoch #1. Accuracy on batch 2836 on Training is 30.04384032428622\n",
            "Epoch #1. Accuracy on batch 2837 on Training is 30.045366455250175\n",
            "Epoch #1. Accuracy on batch 2838 on Training is 30.03918633321592\n",
            "Epoch #1. Accuracy on batch 2839 on Training is 30.041813380281692\n",
            "Batch Id 2840 is having training loss of 1736.673583984375\n",
            "175.65957641601562\n",
            "Epoch #1. Accuracy on batch 2840 on Training is 30.040038718761\n",
            "Epoch #1. Accuracy on batch 2841 on Training is 30.04156403940887\n",
            "Epoch #1. Accuracy on batch 2842 on Training is 30.03979071403447\n",
            "Epoch #1. Accuracy on batch 2843 on Training is 30.03472222222222\n",
            "Epoch #1. Accuracy on batch 2844 on Training is 30.037346221441126\n",
            "Epoch #1. Accuracy on batch 2845 on Training is 30.038870344342936\n",
            "Epoch #1. Accuracy on batch 2846 on Training is 30.04039339655778\n",
            "Epoch #1. Accuracy on batch 2847 on Training is 30.035331811797754\n",
            "Epoch #1. Accuracy on batch 2848 on Training is 30.03575816075816\n",
            "Epoch #1. Accuracy on batch 2849 on Training is 30.036184210526315\n",
            "Epoch #1. Accuracy on batch 2850 on Training is 30.039898281304804\n",
            "Epoch #1. Accuracy on batch 2851 on Training is 30.042514025245442\n",
            "Epoch #1. Accuracy on batch 2852 on Training is 30.04074658254469\n",
            "Epoch #1. Accuracy on batch 2853 on Training is 30.044455150665733\n",
            "Epoch #1. Accuracy on batch 2854 on Training is 30.044877408056042\n",
            "Epoch #1. Accuracy on batch 2855 on Training is 30.045299369747898\n",
            "Epoch #1. Accuracy on batch 2856 on Training is 30.043533426671335\n",
            "Epoch #1. Accuracy on batch 2857 on Training is 30.040675297410775\n",
            "Epoch #1. Accuracy on batch 2858 on Training is 30.038912207065408\n",
            "Epoch #1. Accuracy on batch 2859 on Training is 30.039335664335663\n",
            "Batch Id 2860 is having training loss of 1736.73876953125\n",
            "186.33763122558594\n",
            "Epoch #1. Accuracy on batch 2860 on Training is 30.040851101013633\n",
            "Epoch #1. Accuracy on batch 2861 on Training is 30.04564116002795\n",
            "Epoch #1. Accuracy on batch 2862 on Training is 30.04169577366399\n",
            "Epoch #1. Accuracy on batch 2863 on Training is 30.044299930167597\n",
            "Epoch #1. Accuracy on batch 2864 on Training is 30.047993019197207\n",
            "Epoch #1. Accuracy on batch 2865 on Training is 30.0429605722261\n",
            "Epoch #1. Accuracy on batch 2866 on Training is 30.042291594000698\n",
            "Epoch #1. Accuracy on batch 2867 on Training is 30.044891910739192\n",
            "Epoch #1. Accuracy on batch 2868 on Training is 30.04640118508191\n",
            "Epoch #1. Accuracy on batch 2869 on Training is 30.04682055749129\n",
            "Epoch #1. Accuracy on batch 2870 on Training is 30.048328108672937\n",
            "Epoch #1. Accuracy on batch 2871 on Training is 30.04874651810585\n",
            "Epoch #1. Accuracy on batch 2872 on Training is 30.04590149669335\n",
            "Epoch #1. Accuracy on batch 2873 on Training is 30.04849512874043\n",
            "Epoch #1. Accuracy on batch 2874 on Training is 30.045652173913044\n",
            "Epoch #1. Accuracy on batch 2875 on Training is 30.049330667593882\n",
            "Epoch #1. Accuracy on batch 2876 on Training is 30.048661800486617\n",
            "Epoch #1. Accuracy on batch 2877 on Training is 30.052336692147325\n",
            "Epoch #1. Accuracy on batch 2878 on Training is 30.057094477249045\n",
            "Epoch #1. Accuracy on batch 2879 on Training is 30.057508680555557\n",
            "Batch Id 2880 is having training loss of 1748.914794921875\n",
            "1423.7401123046875\n",
            "Epoch #1. Accuracy on batch 2880 on Training is 30.054668517875736\n",
            "Epoch #1. Accuracy on batch 2881 on Training is 30.04857737682165\n",
            "Epoch #1. Accuracy on batch 2882 on Training is 30.04574228234478\n",
            "Epoch #1. Accuracy on batch 2883 on Training is 30.047243411927877\n",
            "Epoch #1. Accuracy on batch 2884 on Training is 30.045493934142115\n",
            "Epoch #1. Accuracy on batch 2885 on Training is 30.045911295911296\n",
            "Epoch #1. Accuracy on batch 2886 on Training is 30.041998614478697\n",
            "Epoch #1. Accuracy on batch 2887 on Training is 30.03808864265928\n",
            "Epoch #1. Accuracy on batch 2888 on Training is 30.046079958463135\n",
            "Epoch #1. Accuracy on batch 2889 on Training is 30.045415224913494\n",
            "Epoch #1. Accuracy on batch 2890 on Training is 30.049074714631615\n",
            "Epoch #1. Accuracy on batch 2891 on Training is 30.051651106500692\n",
            "Epoch #1. Accuracy on batch 2892 on Training is 30.04882474939509\n",
            "Epoch #1. Accuracy on batch 2893 on Training is 30.048159986178298\n",
            "Epoch #1. Accuracy on batch 2894 on Training is 30.04965457685665\n",
            "Epoch #1. Accuracy on batch 2895 on Training is 30.04575276243094\n",
            "Epoch #1. Accuracy on batch 2896 on Training is 30.040774939592684\n",
            "Epoch #1. Accuracy on batch 2897 on Training is 30.04011387163561\n",
            "Epoch #1. Accuracy on batch 2898 on Training is 30.03514142807865\n",
            "Epoch #1. Accuracy on batch 2899 on Training is 30.03448275862069\n",
            "Batch Id 2900 is having training loss of 1758.9061279296875\n",
            "95.33370971679688\n",
            "Epoch #1. Accuracy on batch 2900 on Training is 30.03597897276801\n",
            "Epoch #1. Accuracy on batch 2901 on Training is 30.039627842866988\n",
            "Epoch #1. Accuracy on batch 2902 on Training is 30.032509472959006\n",
            "Epoch #1. Accuracy on batch 2903 on Training is 30.02754820936639\n",
            "Epoch #1. Accuracy on batch 2904 on Training is 30.026893287435456\n",
            "Epoch #1. Accuracy on batch 2905 on Training is 30.03054026152787\n",
            "Epoch #1. Accuracy on batch 2906 on Training is 30.027734778121776\n",
            "Epoch #1. Accuracy on batch 2907 on Training is 30.02600584594223\n",
            "Epoch #1. Accuracy on batch 2908 on Training is 30.027500859401858\n",
            "Epoch #1. Accuracy on batch 2909 on Training is 30.027920962199314\n",
            "Epoch #1. Accuracy on batch 2910 on Training is 30.02834077636551\n",
            "Epoch #1. Accuracy on batch 2911 on Training is 30.035199175824175\n",
            "Epoch #1. Accuracy on batch 2912 on Training is 30.037761757638172\n",
            "Epoch #1. Accuracy on batch 2913 on Training is 30.036032944406315\n",
            "Epoch #1. Accuracy on batch 2914 on Training is 30.03644939965695\n",
            "Epoch #1. Accuracy on batch 2915 on Training is 30.042223936899862\n",
            "Epoch #1. Accuracy on batch 2916 on Training is 30.041566678093933\n",
            "Epoch #1. Accuracy on batch 2917 on Training is 30.039838930774504\n",
            "Epoch #1. Accuracy on batch 2918 on Training is 30.040253511476532\n",
            "Epoch #1. Accuracy on batch 2919 on Training is 30.04066780821918\n",
            "Batch Id 2920 is having training loss of 1790.8087158203125\n",
            "28321.16796875\n",
            "Epoch #1. Accuracy on batch 2920 on Training is 30.03573262581308\n",
            "Epoch #1. Accuracy on batch 2921 on Training is 30.034009240246405\n",
            "Epoch #1. Accuracy on batch 2922 on Training is 30.038701676359903\n",
            "Epoch #1. Accuracy on batch 2923 on Training is 30.035909712722297\n",
            "Epoch #1. Accuracy on batch 2924 on Training is 30.034188034188034\n",
            "Epoch #1. Accuracy on batch 2925 on Training is 30.032467532467532\n",
            "Epoch #1. Accuracy on batch 2926 on Training is 30.03181585240861\n",
            "Epoch #1. Accuracy on batch 2927 on Training is 30.03329918032787\n",
            "Epoch #1. Accuracy on batch 2928 on Training is 30.033714578354388\n",
            "Epoch #1. Accuracy on batch 2929 on Training is 30.031996587030715\n",
            "Epoch #1. Accuracy on batch 2930 on Training is 30.02921357898328\n",
            "Epoch #1. Accuracy on batch 2931 on Training is 30.025366643929058\n",
            "Epoch #1. Accuracy on batch 2932 on Training is 30.026849642004773\n",
            "Epoch #1. Accuracy on batch 2933 on Training is 30.02939672801636\n",
            "Epoch #1. Accuracy on batch 2934 on Training is 30.031942078364565\n",
            "Epoch #1. Accuracy on batch 2935 on Training is 30.03129257493188\n",
            "Epoch #1. Accuracy on batch 2936 on Training is 30.03064351378958\n",
            "Epoch #1. Accuracy on batch 2937 on Training is 30.033185840707965\n",
            "Epoch #1. Accuracy on batch 2938 on Training is 30.0357264375638\n",
            "Epoch #1. Accuracy on batch 2939 on Training is 30.035076530612244\n",
            "Batch Id 2940 is having training loss of 1781.2076416015625\n",
            "390.5531921386719\n",
            "Epoch #1. Accuracy on batch 2940 on Training is 30.032301938116287\n",
            "Epoch #1. Accuracy on batch 2941 on Training is 30.029529231815093\n",
            "Epoch #1. Accuracy on batch 2942 on Training is 30.02569656812776\n",
            "Epoch #1. Accuracy on batch 2943 on Training is 30.031419836956523\n",
            "Epoch #1. Accuracy on batch 2944 on Training is 30.030772495755517\n",
            "Epoch #1. Accuracy on batch 2945 on Training is 30.032247114731838\n",
            "Epoch #1. Accuracy on batch 2946 on Training is 30.034781133355956\n",
            "Epoch #1. Accuracy on batch 2947 on Training is 30.030953188602442\n",
            "Epoch #1. Accuracy on batch 2948 on Training is 30.029247202441507\n",
            "Epoch #1. Accuracy on batch 2949 on Training is 30.02542372881356\n",
            "Epoch #1. Accuracy on batch 2950 on Training is 30.023720772619452\n",
            "Epoch #1. Accuracy on batch 2951 on Training is 30.020960365853657\n",
            "Epoch #1. Accuracy on batch 2952 on Training is 30.022434812055536\n",
            "Epoch #1. Accuracy on batch 2953 on Training is 30.020734597156398\n",
            "Epoch #1. Accuracy on batch 2954 on Training is 30.015862944162436\n",
            "Epoch #1. Accuracy on batch 2955 on Training is 30.01628044654939\n",
            "Epoch #1. Accuracy on batch 2956 on Training is 30.015640852215082\n",
            "Epoch #1. Accuracy on batch 2957 on Training is 30.01605814739689\n",
            "Epoch #1. Accuracy on batch 2958 on Training is 30.023867860763772\n",
            "Epoch #1. Accuracy on batch 2959 on Training is 30.024282094594593\n",
            "Batch Id 2960 is having training loss of 1788.116455078125\n",
            "18.871307373046875\n",
            "Epoch #1. Accuracy on batch 2960 on Training is 30.025751435325905\n",
            "Epoch #1. Accuracy on batch 2961 on Training is 30.0261647535449\n",
            "Epoch #1. Accuracy on batch 2962 on Training is 30.02763246709416\n",
            "Epoch #1. Accuracy on batch 2963 on Training is 30.03015350877193\n",
            "Epoch #1. Accuracy on batch 2964 on Training is 30.024241146711635\n",
            "Epoch #1. Accuracy on batch 2965 on Training is 30.027815239379635\n",
            "Epoch #1. Accuracy on batch 2966 on Training is 30.02506740815639\n",
            "Epoch #1. Accuracy on batch 2967 on Training is 30.023374326145554\n",
            "Epoch #1. Accuracy on batch 2968 on Training is 30.0237874705288\n",
            "Epoch #1. Accuracy on batch 2969 on Training is 30.030513468013467\n",
            "Epoch #1. Accuracy on batch 2970 on Training is 30.02987209693706\n",
            "Epoch #1. Accuracy on batch 2971 on Training is 30.032385598923284\n",
            "Epoch #1. Accuracy on batch 2972 on Training is 30.031744029599732\n",
            "Epoch #1. Accuracy on batch 2973 on Training is 30.031102891728313\n",
            "Epoch #1. Accuracy on batch 2974 on Training is 30.032563025210084\n",
            "Epoch #1. Accuracy on batch 2975 on Training is 30.030871975806452\n",
            "Epoch #1. Accuracy on batch 2976 on Training is 30.033380920389654\n",
            "Epoch #1. Accuracy on batch 2977 on Training is 30.027493284083278\n",
            "Epoch #1. Accuracy on batch 2978 on Training is 30.026854649211145\n",
            "Epoch #1. Accuracy on batch 2979 on Training is 30.018875838926174\n",
            "Batch Id 2980 is having training loss of 1807.29931640625\n",
            "22.797182083129883\n",
            "Epoch #1. Accuracy on batch 2980 on Training is 30.021385441127137\n",
            "Epoch #1. Accuracy on batch 2981 on Training is 30.020749496981892\n",
            "Epoch #1. Accuracy on batch 2982 on Training is 30.018018773047267\n",
            "Epoch #1. Accuracy on batch 2983 on Training is 30.020526139410187\n",
            "Epoch #1. Accuracy on batch 2984 on Training is 30.013609715242882\n",
            "Epoch #1. Accuracy on batch 2985 on Training is 30.018209979906228\n",
            "Epoch #1. Accuracy on batch 2986 on Training is 30.017576163374624\n",
            "Epoch #1. Accuracy on batch 2987 on Training is 30.015896921017404\n",
            "Epoch #1. Accuracy on batch 2988 on Training is 30.01630980260957\n",
            "Epoch #1. Accuracy on batch 2989 on Training is 30.011496655518396\n",
            "Epoch #1. Accuracy on batch 2990 on Training is 30.010865931126713\n",
            "Epoch #1. Accuracy on batch 2991 on Training is 30.010235628342247\n",
            "Epoch #1. Accuracy on batch 2992 on Training is 30.016914467089876\n",
            "Epoch #1. Accuracy on batch 2993 on Training is 30.01628256513026\n",
            "Epoch #1. Accuracy on batch 2994 on Training is 30.015651085141904\n",
            "Epoch #1. Accuracy on batch 2995 on Training is 30.01502002670227\n",
            "Epoch #1. Accuracy on batch 2996 on Training is 30.016474808141474\n",
            "Epoch #1. Accuracy on batch 2997 on Training is 30.017928619079385\n",
            "Epoch #1. Accuracy on batch 2998 on Training is 30.021465488496165\n",
            "Epoch #1. Accuracy on batch 2999 on Training is 30.020833333333332\n",
            "Batch Id 3000 is having training loss of 1827.1219482421875\n",
            "19.11050796508789\n",
            "Epoch #1. Accuracy on batch 3000 on Training is 30.021242919026992\n",
            "Epoch #1. Accuracy on batch 3001 on Training is 30.018529313790808\n",
            "Epoch #1. Accuracy on batch 3002 on Training is 30.01998001998002\n",
            "Epoch #1. Accuracy on batch 3003 on Training is 30.019349201065246\n",
            "Epoch #1. Accuracy on batch 3004 on Training is 30.02079866888519\n",
            "Epoch #1. Accuracy on batch 3005 on Training is 30.02224717232202\n",
            "Epoch #1. Accuracy on batch 3006 on Training is 30.022655470568672\n",
            "Epoch #1. Accuracy on batch 3007 on Training is 30.02202460106383\n",
            "Epoch #1. Accuracy on batch 3008 on Training is 30.017239946826187\n",
            "Epoch #1. Accuracy on batch 3009 on Training is 30.02284053156146\n",
            "Epoch #1. Accuracy on batch 3010 on Training is 30.02013450680837\n",
            "Epoch #1. Accuracy on batch 3011 on Training is 30.020542828685258\n",
            "Epoch #1. Accuracy on batch 3012 on Training is 30.0174284706517\n",
            "Epoch #1. Batch Id 0 is having validation loss of 40.5749397277832\n",
            "40.5749397277832\n",
            "Epoch #1. Batch Id 0 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 1 is having validation loss of 46.373130798339844\n",
            "52.17131805419922\n",
            "Epoch #1. Batch Id 1 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 2 is having validation loss of 12079.69921875\n",
            "36146.3515625\n",
            "Epoch #1. Batch Id 2 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 3 is having validation loss of 9062.28515625\n",
            "10.043731689453125\n",
            "Epoch #1. Batch Id 3 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 4 is having validation loss of 7277.86474609375\n",
            "140.18362426757812\n",
            "Epoch #1. Batch Id 4 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 5 is having validation loss of 6079.5009765625\n",
            "87.68241119384766\n",
            "Epoch #1. Batch Id 5 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 6 is having validation loss of 5217.619140625\n",
            "46.3274040222168\n",
            "Epoch #1. Batch Id 6 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 7 is having validation loss of 9020.9736328125\n",
            "35644.45703125\n",
            "Epoch #1. Batch Id 7 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 8 is having validation loss of 8028.26025390625\n",
            "86.55455017089844\n",
            "Epoch #1. Batch Id 8 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 9 is having validation loss of 37112.31640625\n",
            "298868.8125\n",
            "Epoch #1. Batch Id 9 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 10 is having validation loss of 39089.39453125\n",
            "58860.1875\n",
            "Epoch #1. Batch Id 10 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 11 is having validation loss of 40926.05078125\n",
            "61129.25390625\n",
            "Epoch #1. Batch Id 11 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 12 is having validation loss of 37804.94140625\n",
            "351.628662109375\n",
            "Epoch #1. Batch Id 12 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 13 is having validation loss of 35105.546875\n",
            "13.437603950500488\n",
            "Epoch #1. Batch Id 13 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 14 is having validation loss of 32775.6953125\n",
            "157.7542724609375\n",
            "Epoch #1. Batch Id 14 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 15 is having validation loss of 30727.73828125\n",
            "8.382251739501953\n",
            "Epoch #1. Batch Id 15 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 16 is having validation loss of 53291.35546875\n",
            "414309.25\n",
            "Epoch #1. Batch Id 16 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 17 is having validation loss of 56647.625\n",
            "113704.2421875\n",
            "Epoch #1. Batch Id 17 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 18 is having validation loss of 61732.953125\n",
            "153268.875\n",
            "Epoch #1. Batch Id 18 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 19 is having validation loss of 58650.68359375\n",
            "87.56263732910156\n",
            "Epoch #1. Batch Id 19 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 20 is having validation loss of 56792.390625\n",
            "19626.5078125\n",
            "Epoch #1. Batch Id 20 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 21 is having validation loss of 54274.3671875\n",
            "1395.833984375\n",
            "Epoch #1. Batch Id 21 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 22 is having validation loss of 51916.36328125\n",
            "40.25684356689453\n",
            "Epoch #1. Batch Id 22 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 23 is having validation loss of 49758.26953125\n",
            "122.12391662597656\n",
            "Epoch #1. Batch Id 23 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 24 is having validation loss of 47770.2109375\n",
            "56.84767150878906\n",
            "Epoch #1. Batch Id 24 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 25 is having validation loss of 45934.03125\n",
            "29.5180606842041\n",
            "Epoch #1. Batch Id 25 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 26 is having validation loss of 44234.53515625\n",
            "47.61914825439453\n",
            "Epoch #1. Batch Id 26 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 27 is having validation loss of 44142.1171875\n",
            "41646.796875\n",
            "Epoch #1. Batch Id 27 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 28 is having validation loss of 42626.38671875\n",
            "185.96212768554688\n",
            "Epoch #1. Batch Id 28 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 29 is having validation loss of 41206.8984375\n",
            "41.774864196777344\n",
            "Epoch #1. Batch Id 29 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 30 is having validation loss of 39878.34765625\n",
            "21.838977813720703\n",
            "Epoch #1. Batch Id 30 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 31 is having validation loss of 38636.91015625\n",
            "152.3231201171875\n",
            "Epoch #1. Batch Id 31 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 32 is having validation loss of 37468.39453125\n",
            "75.9224624633789\n",
            "Epoch #1. Batch Id 32 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 33 is having validation loss of 36774.24609375\n",
            "13867.341796875\n",
            "Epoch #1. Batch Id 33 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 34 is having validation loss of 35724.59375\n",
            "36.455204010009766\n",
            "Epoch #1. Batch Id 34 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 35 is having validation loss of 34733.15234375\n",
            "32.66358184814453\n",
            "Epoch #1. Batch Id 35 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 36 is having validation loss of 33812.9453125\n",
            "685.5032348632812\n",
            "Epoch #1. Batch Id 36 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 37 is having validation loss of 32925.47265625\n",
            "89.03627014160156\n",
            "Epoch #1. Batch Id 37 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 38 is having validation loss of 32095.263671875\n",
            "547.34375\n",
            "Epoch #1. Batch Id 38 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 39 is having validation loss of 31294.814453125\n",
            "77.3039321899414\n",
            "Epoch #1. Batch Id 39 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 40 is having validation loss of 30531.87109375\n",
            "14.108238220214844\n",
            "Epoch #1. Batch Id 40 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 41 is having validation loss of 29806.240234375\n",
            "55.339393615722656\n",
            "Epoch #1. Batch Id 41 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 42 is having validation loss of 29148.97265625\n",
            "1543.7491455078125\n",
            "Epoch #1. Batch Id 42 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 43 is having validation loss of 28493.994140625\n",
            "329.9117431640625\n",
            "Epoch #1. Batch Id 43 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 44 is having validation loss of 41020.3125\n",
            "592178.25\n",
            "Epoch #1. Batch Id 44 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 45 is having validation loss of 40135.484375\n",
            "318.2867431640625\n",
            "Epoch #1. Batch Id 45 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 46 is having validation loss of 39307.359375\n",
            "1213.5386962890625\n",
            "Epoch #1. Batch Id 46 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 47 is having validation loss of 38488.5703125\n",
            "5.469732761383057\n",
            "Epoch #1. Batch Id 47 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 48 is having validation loss of 38720.1171875\n",
            "49834.28125\n",
            "Epoch #1. Batch Id 48 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 49 is having validation loss of 41757.92578125\n",
            "190610.46875\n",
            "Epoch #1. Batch Id 49 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 50 is having validation loss of 44754.671875\n",
            "194592.0625\n",
            "Epoch #1. Batch Id 50 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 51 is having validation loss of 43895.15234375\n",
            "59.750099182128906\n",
            "Epoch #1. Batch Id 51 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 52 is having validation loss of 49594.26171875\n",
            "345947.9375\n",
            "Epoch #1. Batch Id 52 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 53 is having validation loss of 48677.0078125\n",
            "62.64841842651367\n",
            "Epoch #1. Batch Id 53 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 54 is having validation loss of 47792.74609375\n",
            "42.657928466796875\n",
            "Epoch #1. Batch Id 54 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 55 is having validation loss of 46940.4296875\n",
            "63.00246810913086\n",
            "Epoch #1. Batch Id 55 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 56 is having validation loss of 46226.90625\n",
            "6269.54638671875\n",
            "Epoch #1. Batch Id 56 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 57 is having validation loss of 45431.51171875\n",
            "94.09823608398438\n",
            "Epoch #1. Batch Id 57 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 58 is having validation loss of 44661.828125\n",
            "20.173768997192383\n",
            "Epoch #1. Batch Id 58 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 59 is having validation loss of 43920.76171875\n",
            "197.84336853027344\n",
            "Epoch #1. Batch Id 59 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 60 is having validation loss of 43200.80078125\n",
            "3.2298052310943604\n",
            "Epoch #1. Batch Id 60 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 61 is having validation loss of 42512.375\n",
            "518.44140625\n",
            "Epoch #1. Batch Id 61 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 62 is having validation loss of 41837.8671875\n",
            "18.357860565185547\n",
            "Epoch #1. Batch Id 62 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 63 is having validation loss of 41704.0625\n",
            "33274.328125\n",
            "Epoch #1. Batch Id 63 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 64 is having validation loss of 41062.69921875\n",
            "15.359137535095215\n",
            "Epoch #1. Batch Id 64 is having validation accuracy of 0.0\n",
            "Epoch #1. Batch Id 65 is having validation loss of 40440.92578125\n",
            "25.72812271118164\n",
            "Epoch #1. Batch Id 65 is having validation accuracy of 0.2840909090909091\n",
            "Epoch #1. Batch Id 66 is having validation loss of 39903.21484375\n",
            "4414.201171875\n",
            "Epoch #1. Batch Id 66 is having validation accuracy of 0.6996268656716418\n",
            "Epoch #1. Batch Id 67 is having validation loss of 39316.54296875\n",
            "9.556313514709473\n",
            "Epoch #1. Batch Id 67 is having validation accuracy of 0.9191176470588235\n",
            "Epoch #1. Batch Id 68 is having validation loss of 38746.875\n",
            "9.438035011291504\n",
            "Epoch #1. Batch Id 68 is having validation accuracy of 1.358695652173913\n",
            "Epoch #1. Batch Id 69 is having validation loss of 38193.796875\n",
            "31.42136573791504\n",
            "Epoch #1. Batch Id 69 is having validation accuracy of 1.7857142857142858\n",
            "Epoch #1. Batch Id 70 is having validation loss of 37763.85546875\n",
            "7668.0234375\n",
            "Epoch #1. Batch Id 70 is having validation accuracy of 2.288732394366197\n",
            "Epoch #1. Batch Id 71 is having validation loss of 37239.703125\n",
            "24.92827033996582\n",
            "Epoch #1. Batch Id 71 is having validation accuracy of 2.6909722222222223\n",
            "Epoch #1. Batch Id 72 is having validation loss of 36787.703125\n",
            "4243.599609375\n",
            "Epoch #1. Batch Id 72 is having validation accuracy of 3.2534246575342465\n",
            "Epoch #1. Batch Id 73 is having validation loss of 36291.515625\n",
            "69.7247314453125\n",
            "Epoch #1. Batch Id 73 is having validation accuracy of 3.7162162162162162\n",
            "Epoch #1. Batch Id 74 is having validation loss of 35807.90625\n",
            "20.80852508544922\n",
            "Epoch #1. Batch Id 74 is having validation accuracy of 4.166666666666667\n",
            "Epoch #1. Batch Id 75 is having validation loss of 35336.953125\n",
            "15.498849868774414\n",
            "Epoch #1. Batch Id 75 is having validation accuracy of 4.605263157894737\n",
            "Epoch #1. Batch Id 76 is having validation loss of 34878.6484375\n",
            "47.447444915771484\n",
            "Epoch #1. Batch Id 76 is having validation accuracy of 5.032467532467533\n",
            "Epoch #1. Batch Id 77 is having validation loss of 34458.0625\n",
            "2072.925048828125\n",
            "Epoch #1. Batch Id 77 is having validation accuracy of 5.288461538461538\n",
            "Epoch #1. Batch Id 78 is having validation loss of 34022.73046875\n",
            "66.69113159179688\n",
            "Epoch #1. Batch Id 78 is having validation accuracy of 5.458860759493671\n",
            "Epoch #1. Batch Id 79 is having validation loss of 33597.66015625\n",
            "17.027318954467773\n",
            "Epoch #1. Batch Id 79 is having validation accuracy of 5.7421875\n",
            "Epoch #1. Batch Id 80 is having validation loss of 33183.36328125\n",
            "39.53862762451172\n",
            "Epoch #1. Batch Id 80 is having validation accuracy of 6.095679012345679\n",
            "Epoch #1. Batch Id 81 is having validation loss of 32779.09765625\n",
            "33.57280731201172\n",
            "Epoch #1. Batch Id 81 is having validation accuracy of 6.288109756097561\n",
            "Epoch #1. Batch Id 82 is having validation loss of 32388.70703125\n",
            "376.6266784667969\n",
            "Epoch #1. Batch Id 82 is having validation accuracy of 6.588855421686747\n",
            "Epoch #1. Batch Id 83 is having validation loss of 32003.5703125\n",
            "37.24580383300781\n",
            "Epoch #1. Batch Id 83 is having validation accuracy of 7.03125\n",
            "Epoch #1. Batch Id 84 is having validation loss of 31627.27734375\n",
            "18.693742752075195\n",
            "Epoch #1. Batch Id 84 is having validation accuracy of 7.352941176470588\n",
            "Epoch #1. Batch Id 85 is having validation loss of 31259.873046875\n",
            "30.579683303833008\n",
            "Epoch #1. Batch Id 85 is having validation accuracy of 7.776162790697675\n",
            "Epoch #1. Batch Id 86 is having validation loss of 30900.712890625\n",
            "12.982200622558594\n",
            "Epoch #1. Batch Id 86 is having validation accuracy of 8.153735632183908\n",
            "Epoch #1. Batch Id 87 is having validation loss of 30549.783203125\n",
            "18.98163414001465\n",
            "Epoch #1. Batch Id 87 is having validation accuracy of 8.451704545454545\n",
            "Epoch #1. Batch Id 88 is having validation loss of 30207.826171875\n",
            "115.60709381103516\n",
            "Epoch #1. Batch Id 88 is having validation accuracy of 8.60252808988764\n",
            "Epoch #1. Batch Id 89 is having validation loss of 29872.34765625\n",
            "14.752039909362793\n",
            "Epoch #1. Batch Id 89 is having validation accuracy of 8.854166666666666\n",
            "Epoch #1. Batch Id 90 is having validation loss of 29544.9140625\n",
            "75.90764617919922\n",
            "Epoch #1. Batch Id 90 is having validation accuracy of 9.100274725274724\n",
            "Epoch #1. Batch Id 91 is having validation loss of 29224.01171875\n",
            "21.965343475341797\n",
            "Epoch #1. Batch Id 91 is having validation accuracy of 9.375\n",
            "Epoch #1. Batch Id 92 is having validation loss of 28911.251953125\n",
            "137.29837036132812\n",
            "Epoch #1. Batch Id 92 is having validation accuracy of 9.61021505376344\n",
            "Epoch #1. Batch Id 93 is having validation loss of 28603.990234375\n",
            "28.604164123535156\n",
            "Epoch #1. Batch Id 93 is having validation accuracy of 9.873670212765957\n",
            "Epoch #1. Batch Id 94 is having validation loss of 28303.125\n",
            "21.712621688842773\n",
            "Epoch #1. Batch Id 94 is having validation accuracy of 10.230263157894736\n",
            "Epoch #1. Batch Id 95 is having validation loss of 28008.388671875\n",
            "8.509087562561035\n",
            "Epoch #1. Batch Id 95 is having validation accuracy of 10.611979166666666\n",
            "Epoch #1. Batch Id 96 is having validation loss of 27723.98046875\n",
            "420.7060241699219\n",
            "Epoch #1. Batch Id 96 is having validation accuracy of 10.856958762886597\n",
            "Epoch #1. Batch Id 97 is having validation loss of 27441.41015625\n",
            "32.06819534301758\n",
            "Epoch #1. Batch Id 97 is having validation accuracy of 11.192602040816327\n",
            "Epoch #1. Batch Id 98 is having validation loss of 27164.447265625\n",
            "22.04344940185547\n",
            "Epoch #1. Batch Id 98 is having validation accuracy of 11.363636363636363\n",
            "Epoch #1. Batch Id 99 is having validation loss of 26893.17578125\n",
            "37.3890266418457\n",
            "Epoch #1. Batch Id 99 is having validation accuracy of 11.5625\n",
            "Epoch #1. Batch Id 100 is having validation loss of 26627.53125\n",
            "63.16315841674805\n",
            "Epoch #1. Batch Id 100 is having validation accuracy of 11.66460396039604\n",
            "Epoch #1. Batch Id 101 is having validation loss of 26366.673828125\n",
            "20.016023635864258\n",
            "Epoch #1. Batch Id 101 is having validation accuracy of 11.917892156862745\n",
            "Epoch #1. Batch Id 102 is having validation loss of 26110.884765625\n",
            "20.3101863861084\n",
            "Epoch #1. Batch Id 102 is having validation accuracy of 12.226941747572816\n",
            "Epoch #1. Batch Id 103 is having validation loss of 25860.11328125\n",
            "30.570396423339844\n",
            "Epoch #1. Batch Id 103 is having validation accuracy of 12.289663461538462\n",
            "Epoch #1. Batch Id 104 is having validation loss of 25614.23046875\n",
            "42.38679885864258\n",
            "Epoch #1. Batch Id 104 is having validation accuracy of 12.589285714285714\n",
            "Epoch #1. Batch Id 105 is having validation loss of 25372.783203125\n",
            "20.78158950805664\n",
            "Epoch #1. Batch Id 105 is having validation accuracy of 12.82429245283019\n",
            "Epoch #1. Batch Id 106 is having validation loss of 25136.365234375\n",
            "76.15177917480469\n",
            "Epoch #1. Batch Id 106 is having validation accuracy of 12.996495327102803\n",
            "Epoch #1. Batch Id 107 is having validation loss of 24904.275390625\n",
            "70.73904418945312\n",
            "Epoch #1. Batch Id 107 is having validation accuracy of 13.136574074074074\n",
            "Epoch #1. Batch Id 108 is having validation loss of 24676.150390625\n",
            "38.72629928588867\n",
            "Epoch #1. Batch Id 108 is having validation accuracy of 13.216743119266056\n",
            "Epoch #1. Batch Id 109 is having validation loss of 24452.3359375\n",
            "56.509742736816406\n",
            "Epoch #1. Batch Id 109 is having validation accuracy of 13.295454545454545\n",
            "Epoch #1. Batch Id 110 is having validation loss of 24233.076171875\n",
            "114.55049896240234\n",
            "Epoch #1. Batch Id 110 is having validation accuracy of 13.372747747747749\n",
            "Epoch #1. Batch Id 111 is having validation loss of 24016.85546875\n",
            "16.440584182739258\n",
            "Epoch #1. Batch Id 111 is having validation accuracy of 13.616071428571429\n",
            "Epoch #1. Batch Id 112 is having validation loss of 23804.42578125\n",
            "12.41105842590332\n",
            "Epoch #1. Batch Id 112 is having validation accuracy of 13.827433628318584\n",
            "Epoch #1. Batch Id 113 is having validation loss of 23595.904296875\n",
            "32.97661590576172\n",
            "Epoch #1. Batch Id 113 is having validation accuracy of 14.007675438596491\n",
            "Epoch #1. Batch Id 114 is having validation loss of 23391.0703125\n",
            "40.099979400634766\n",
            "Epoch #1. Batch Id 114 is having validation accuracy of 14.21195652173913\n",
            "Epoch #1. Batch Id 115 is having validation loss of 23189.69140625\n",
            "31.15509796142578\n",
            "Epoch #1. Batch Id 115 is having validation accuracy of 14.224137931034482\n",
            "Epoch #1. Batch Id 116 is having validation loss of 22991.755859375\n",
            "31.206796646118164\n",
            "Epoch #1. Batch Id 116 is having validation accuracy of 14.342948717948717\n",
            "Epoch #1. Batch Id 117 is having validation loss of 22797.134765625\n",
            "26.51882553100586\n",
            "Epoch #1. Batch Id 117 is having validation accuracy of 14.51271186440678\n",
            "Epoch #1. Batch Id 118 is having validation loss of 22605.9140625\n",
            "41.96593475341797\n",
            "Epoch #1. Batch Id 118 is having validation accuracy of 14.653361344537815\n",
            "Epoch #1. Batch Id 119 is having validation loss of 22686.857421875\n",
            "32319.20703125\n",
            "Epoch #1. Batch Id 119 is having validation accuracy of 14.869791666666666\n",
            "Epoch #1. Batch Id 120 is having validation loss of 22499.5625\n",
            "24.132978439331055\n",
            "Epoch #1. Batch Id 120 is having validation accuracy of 15.160123966942148\n",
            "Epoch #1. Batch Id 121 is having validation loss of 22955.84375\n",
            "78165.8984375\n",
            "Epoch #1. Batch Id 121 is having validation accuracy of 15.18954918032787\n",
            "Epoch #1. Batch Id 122 is having validation loss of 22838.0625\n",
            "8468.8271484375\n",
            "Epoch #1. Batch Id 122 is having validation accuracy of 15.320121951219512\n",
            "Epoch #1. Batch Id 123 is having validation loss of 22654.14453125\n",
            "32.29966735839844\n",
            "Epoch #1. Batch Id 123 is having validation accuracy of 15.49899193548387\n",
            "Epoch #1. Batch Id 124 is having validation loss of 22473.130859375\n",
            "27.476791381835938\n",
            "Epoch #1. Batch Id 124 is having validation accuracy of 15.75\n",
            "Epoch #1. Batch Id 125 is having validation loss of 22294.951171875\n",
            "22.520832061767578\n",
            "Epoch #1. Batch Id 125 is having validation accuracy of 15.972222222222221\n",
            "Epoch #1. Batch Id 126 is having validation loss of 22119.55859375\n",
            "20.178882598876953\n",
            "Epoch #1. Batch Id 126 is having validation accuracy of 15.94488188976378\n",
            "Epoch #1. Batch Id 127 is having validation loss of 21947.138671875\n",
            "49.82042694091797\n",
            "Epoch #1. Batch Id 127 is having validation accuracy of 16.0400390625\n",
            "Epoch #1. Batch Id 128 is having validation loss of 21818.423828125\n",
            "5342.849609375\n",
            "Epoch #1. Batch Id 128 is having validation accuracy of 16.109496124031008\n",
            "Epoch #1. Batch Id 129 is having validation loss of 21650.6875\n",
            "12.75710391998291\n",
            "Epoch #1. Batch Id 129 is having validation accuracy of 16.177884615384617\n",
            "Epoch #1. Batch Id 130 is having validation loss of 21485.505859375\n",
            "12.007823944091797\n",
            "Epoch #1. Batch Id 130 is having validation accuracy of 16.31679389312977\n",
            "Epoch #1. Batch Id 131 is having validation loss of 21323.060546875\n",
            "42.680946350097656\n",
            "Epoch #1. Batch Id 131 is having validation accuracy of 16.52462121212121\n",
            "Epoch #1. Batch Id 132 is having validation loss of 21162.87109375\n",
            "17.970876693725586\n",
            "Epoch #1. Batch Id 132 is having validation accuracy of 16.49436090225564\n",
            "Epoch #1. Batch Id 133 is having validation loss of 21117.30859375\n",
            "15057.486328125\n",
            "Epoch #1. Batch Id 133 is having validation accuracy of 16.534514925373134\n",
            "Epoch #1. Batch Id 134 is having validation loss of 20961.017578125\n",
            "18.044221878051758\n",
            "Epoch #1. Batch Id 134 is having validation accuracy of 16.75925925925926\n",
            "Epoch #1. Batch Id 135 is having validation loss of 20807.103515625\n",
            "28.68185043334961\n",
            "Epoch #1. Batch Id 135 is having validation accuracy of 16.81985294117647\n",
            "Epoch #1. Batch Id 136 is having validation loss of 20655.3203125\n",
            "12.769830703735352\n",
            "Epoch #1. Batch Id 136 is having validation accuracy of 16.993613138686133\n",
            "Epoch #1. Batch Id 137 is having validation loss of 20505.763671875\n",
            "16.452566146850586\n",
            "Epoch #1. Batch Id 137 is having validation accuracy of 17.255434782608695\n",
            "Epoch #1. Batch Id 138 is having validation loss of 20382.0\n",
            "3302.62841796875\n",
            "Epoch #1. Batch Id 138 is having validation accuracy of 17.288669064748202\n",
            "Epoch #1. Batch Id 139 is having validation loss of 20236.62109375\n",
            "28.81901741027832\n",
            "Epoch #1. Batch Id 139 is having validation accuracy of 17.366071428571427\n",
            "Epoch #1. Batch Id 140 is having validation loss of 20093.25\n",
            "21.161531448364258\n",
            "Epoch #1. Batch Id 140 is having validation accuracy of 17.4645390070922\n",
            "Epoch #1. Batch Id 141 is having validation loss of 20000.60546875\n",
            "6937.66455078125\n",
            "Epoch #1. Batch Id 141 is having validation accuracy of 17.649647887323944\n",
            "Epoch #1. Batch Id 142 is having validation loss of 19860.888671875\n",
            "21.156475067138672\n",
            "Epoch #1. Batch Id 142 is having validation accuracy of 17.832167832167833\n",
            "Epoch #1. Batch Id 143 is having validation loss of 19723.19140625\n",
            "32.433433532714844\n",
            "Epoch #1. Batch Id 143 is having validation accuracy of 18.01215277777778\n",
            "Epoch #1. Batch Id 144 is having validation loss of 19732.833984375\n",
            "21121.298828125\n",
            "Epoch #1. Batch Id 144 is having validation accuracy of 18.232758620689655\n",
            "Epoch #1. Batch Id 145 is having validation loss of 19597.875\n",
            "28.904069900512695\n",
            "Epoch #1. Batch Id 145 is having validation accuracy of 18.236301369863014\n",
            "Epoch #1. Batch Id 146 is having validation loss of 19464.7578125\n",
            "29.60403060913086\n",
            "Epoch #1. Batch Id 146 is having validation accuracy of 18.367346938775512\n",
            "Epoch #1. Batch Id 147 is having validation loss of 19333.494140625\n",
            "37.62885665893555\n",
            "Epoch #1. Batch Id 147 is having validation accuracy of 18.475506756756758\n",
            "Epoch #1. Batch Id 148 is having validation loss of 19203.94921875\n",
            "31.39911651611328\n",
            "Epoch #1. Batch Id 148 is having validation accuracy of 18.60318791946309\n",
            "Epoch #1. Batch Id 149 is having validation loss of 19083.37890625\n",
            "1118.3270263671875\n",
            "Epoch #1. Batch Id 149 is having validation accuracy of 18.6875\n",
            "Epoch #1. Batch Id 150 is having validation loss of 18957.47265625\n",
            "71.5303955078125\n",
            "Epoch #1. Batch Id 150 is having validation accuracy of 18.832781456953644\n",
            "Epoch #1. Batch Id 151 is having validation loss of 18835.625\n",
            "436.7530517578125\n",
            "Epoch #1. Batch Id 151 is having validation accuracy of 18.914473684210527\n",
            "Epoch #1. Batch Id 152 is having validation loss of 18712.67578125\n",
            "24.379985809326172\n",
            "Epoch #1. Batch Id 152 is having validation accuracy of 19.015522875816995\n",
            "Epoch #1. Batch Id 153 is having validation loss of 18591.265625\n",
            "15.488500595092773\n",
            "Epoch #1. Batch Id 153 is having validation accuracy of 19.155844155844157\n",
            "Epoch #1. Batch Id 154 is having validation loss of 18471.482421875\n",
            "24.85113525390625\n",
            "Epoch #1. Batch Id 154 is having validation accuracy of 19.254032258064516\n",
            "Epoch #1. Batch Id 155 is having validation loss of 18353.26953125\n",
            "30.352924346923828\n",
            "Epoch #1. Batch Id 155 is having validation accuracy of 19.290865384615383\n",
            "Epoch #1. Batch Id 156 is having validation loss of 18823.39453125\n",
            "92163.0078125\n",
            "Epoch #1. Batch Id 156 is having validation accuracy of 19.446656050955415\n",
            "Epoch #1. Batch Id 157 is having validation loss of 18844.009765625\n",
            "22080.732421875\n",
            "Epoch #1. Batch Id 157 is having validation accuracy of 19.580696202531644\n",
            "Epoch #1. Batch Id 158 is having validation loss of 18725.57421875\n",
            "12.74324893951416\n",
            "Epoch #1. Batch Id 158 is having validation accuracy of 19.63443396226415\n",
            "Epoch #1. Batch Id 159 is having validation loss of 18609.576171875\n",
            "165.8343963623047\n",
            "Epoch #1. Batch Id 159 is having validation accuracy of 19.6875\n",
            "Epoch #1. Batch Id 160 is having validation loss of 18494.203125\n",
            "34.43992614746094\n",
            "Epoch #1. Batch Id 160 is having validation accuracy of 19.642857142857142\n",
            "Epoch #1. Batch Id 161 is having validation loss of 18380.2421875\n",
            "32.421356201171875\n",
            "Epoch #1. Batch Id 161 is having validation accuracy of 19.656635802469136\n",
            "Epoch #1. Batch Id 162 is having validation loss of 18267.6875\n",
            "33.7765007019043\n",
            "Epoch #1. Batch Id 162 is having validation accuracy of 19.823619631901842\n",
            "Epoch #1. Batch Id 163 is having validation loss of 18161.7734375\n",
            "897.8564453125\n",
            "Epoch #1. Batch Id 163 is having validation accuracy of 19.85518292682927\n",
            "Epoch #1. Batch Id 164 is having validation loss of 18051.986328125\n",
            "46.836585998535156\n",
            "Epoch #1. Batch Id 164 is having validation accuracy of 19.90530303030303\n",
            "Epoch #1. Batch Id 165 is having validation loss of 17943.39453125\n",
            "25.892515182495117\n",
            "Epoch #1. Batch Id 165 is having validation accuracy of 19.954819277108435\n",
            "Epoch #1. Batch Id 166 is having validation loss of 17836.06640625\n",
            "19.534570693969727\n",
            "Epoch #1. Batch Id 166 is having validation accuracy of 20.022455089820358\n",
            "Epoch #1. Batch Id 167 is having validation loss of 17730.130859375\n",
            "38.782798767089844\n",
            "Epoch #1. Batch Id 167 is having validation accuracy of 20.107886904761905\n",
            "Epoch #1. Batch Id 168 is having validation loss of 17625.296875\n",
            "13.201295852661133\n",
            "Epoch #1. Batch Id 168 is having validation accuracy of 20.136834319526628\n",
            "Epoch #1. Batch Id 169 is having validation loss of 17557.26171875\n",
            "6059.48681640625\n",
            "Epoch #1. Batch Id 169 is having validation accuracy of 20.202205882352942\n",
            "Epoch #1. Batch Id 170 is having validation loss of 17454.703125\n",
            "19.696866989135742\n",
            "Epoch #1. Batch Id 170 is having validation accuracy of 20.248538011695906\n",
            "Epoch #1. Batch Id 171 is having validation loss of 17365.8984375\n",
            "2180.32470703125\n",
            "Epoch #1. Batch Id 171 is having validation accuracy of 20.257994186046513\n",
            "Epoch #1. Batch Id 172 is having validation loss of 17265.671875\n",
            "26.854045867919922\n",
            "Epoch #1. Batch Id 172 is having validation accuracy of 20.3757225433526\n",
            "Epoch #1. Batch Id 173 is having validation loss of 17166.86328125\n",
            "72.9605712890625\n",
            "Epoch #1. Batch Id 173 is having validation accuracy of 20.492097701149426\n",
            "Epoch #1. Batch Id 174 is having validation loss of 17092.673828125\n",
            "4183.73876953125\n",
            "Epoch #1. Batch Id 174 is having validation accuracy of 20.464285714285715\n",
            "Epoch #1. Batch Id 175 is having validation loss of 16995.69140625\n",
            "23.858043670654297\n",
            "Epoch #1. Batch Id 175 is having validation accuracy of 20.525568181818183\n",
            "Epoch #1. Batch Id 176 is having validation loss of 16899.908203125\n",
            "42.03249740600586\n",
            "Epoch #1. Batch Id 176 is having validation accuracy of 20.497881355932204\n",
            "Epoch #1. Batch Id 177 is having validation loss of 16904.876953125\n",
            "17784.294921875\n",
            "Epoch #1. Batch Id 177 is having validation accuracy of 20.435393258426966\n",
            "Epoch #1. Batch Id 178 is having validation loss of 16810.4921875\n",
            "9.955389976501465\n",
            "Epoch #1. Batch Id 178 is having validation accuracy of 20.47835195530726\n",
            "Epoch #1. Batch Id 179 is having validation loss of 16718.337890625\n",
            "222.6062774658203\n",
            "Epoch #1. Batch Id 179 is having validation accuracy of 20.538194444444443\n",
            "Epoch #1. Batch Id 180 is having validation loss of 16626.09375\n",
            "22.241867065429688\n",
            "Epoch #1. Batch Id 180 is having validation accuracy of 20.700966850828728\n",
            "Epoch #1. Batch Id 181 is having validation loss of 16534.916015625\n",
            "31.623937606811523\n",
            "Epoch #1. Batch Id 181 is having validation accuracy of 20.79326923076923\n",
            "Epoch #1. Batch Id 182 is having validation loss of 16444.6953125\n",
            "24.423694610595703\n",
            "Epoch #1. Batch Id 182 is having validation accuracy of 20.918715846994534\n",
            "Epoch #1. Batch Id 183 is having validation loss of 16355.46484375\n",
            "26.357078552246094\n",
            "Epoch #1. Batch Id 183 is having validation accuracy of 20.95788043478261\n",
            "Epoch #1. Batch Id 184 is having validation loss of 16267.15234375\n",
            "17.69070053100586\n",
            "Epoch #1. Batch Id 184 is having validation accuracy of 21.06418918918919\n",
            "Epoch #1. Batch Id 185 is having validation loss of 16179.79296875\n",
            "18.358871459960938\n",
            "Epoch #1. Batch Id 185 is having validation accuracy of 21.202956989247312\n",
            "Epoch #1. Batch Id 186 is having validation loss of 16095.3701171875\n",
            "392.6558532714844\n",
            "Epoch #1. Batch Id 186 is having validation accuracy of 21.239973262032084\n",
            "Epoch #1. Batch Id 187 is having validation loss of 16009.904296875\n",
            "27.756298065185547\n",
            "Epoch #1. Batch Id 187 is having validation accuracy of 21.35970744680851\n",
            "Epoch #1. Batch Id 188 is having validation loss of 16044.9501953125\n",
            "22633.62890625\n",
            "Epoch #1. Batch Id 188 is having validation accuracy of 21.44510582010582\n",
            "Epoch #1. Batch Id 189 is having validation loss of 16024.41796875\n",
            "12143.896484375\n",
            "Epoch #1. Batch Id 189 is having validation accuracy of 21.43092105263158\n",
            "Epoch #1. Batch Id 190 is having validation loss of 15940.6767578125\n",
            "29.888019561767578\n",
            "Epoch #1. Batch Id 190 is having validation accuracy of 21.465968586387433\n",
            "Epoch #1. Batch Id 191 is having validation loss of 15857.84765625\n",
            "37.46702194213867\n",
            "Epoch #1. Batch Id 191 is having validation accuracy of 21.484375\n",
            "Epoch #1. Batch Id 192 is having validation loss of 15775.7626953125\n",
            "15.412309646606445\n",
            "Epoch #1. Batch Id 192 is having validation accuracy of 21.53497409326425\n",
            "Epoch #1. Batch Id 193 is having validation loss of 15695.53515625\n",
            "211.6729278564453\n",
            "Epoch #1. Batch Id 193 is having validation accuracy of 21.56894329896907\n",
            "Epoch #1. Batch Id 194 is having validation loss of 15615.1572265625\n",
            "21.895570755004883\n",
            "Epoch #1. Batch Id 194 is having validation accuracy of 21.55448717948718\n",
            "Epoch #1. Batch Id 195 is having validation loss of 15535.6005859375\n",
            "21.992717742919922\n",
            "Epoch #1. Batch Id 195 is having validation accuracy of 21.524234693877553\n",
            "Epoch #1. Batch Id 196 is having validation loss of 15456.884765625\n",
            "28.580522537231445\n",
            "Epoch #1. Batch Id 196 is having validation accuracy of 21.60532994923858\n",
            "Epoch #1. Batch Id 197 is having validation loss of 15380.8603515625\n",
            "404.0904541015625\n",
            "Epoch #1. Batch Id 197 is having validation accuracy of 21.60669191919192\n",
            "Epoch #1. Batch Id 198 is having validation loss of 15333.6123046875\n",
            "5978.51953125\n",
            "Epoch #1. Batch Id 198 is having validation accuracy of 21.623743718592966\n",
            "Epoch #1. Batch Id 199 is having validation loss of 15340.3291015625\n",
            "16676.9609375\n",
            "Epoch #1. Batch Id 199 is having validation accuracy of 21.609375\n",
            "Epoch #1. Batch Id 200 is having validation loss of 15264.185546875\n",
            "35.51151657104492\n",
            "Epoch #1. Batch Id 200 is having validation accuracy of 21.626243781094526\n",
            "Epoch #1. Batch Id 201 is having validation loss of 15188.73828125\n",
            "23.870555877685547\n",
            "Epoch #1. Batch Id 201 is having validation accuracy of 21.596534653465348\n",
            "Epoch #1. Batch Id 202 is having validation loss of 15114.0595703125\n",
            "28.946102142333984\n",
            "Epoch #1. Batch Id 202 is having validation accuracy of 21.597906403940886\n",
            "Epoch #1. Batch Id 203 is having validation loss of 15040.23046875\n",
            "53.01359558105469\n",
            "Epoch #1. Batch Id 203 is having validation accuracy of 21.58394607843137\n",
            "Epoch #1. Batch Id 204 is having validation loss of 14966.9462890625\n",
            "17.022001266479492\n",
            "Epoch #1. Batch Id 204 is having validation accuracy of 21.70731707317073\n",
            "Epoch #1. Batch Id 205 is having validation loss of 14894.3701171875\n",
            "16.339624404907227\n",
            "Epoch #1. Batch Id 205 is having validation accuracy of 21.76881067961165\n",
            "Epoch #1. Batch Id 206 is having validation loss of 14822.6708984375\n",
            "52.588523864746094\n",
            "Epoch #1. Batch Id 206 is having validation accuracy of 21.784420289855074\n",
            "Epoch #1. Batch Id 207 is having validation loss of 14751.7021484375\n",
            "61.13254928588867\n",
            "Epoch #1. Batch Id 207 is having validation accuracy of 21.69471153846154\n",
            "Epoch #1. Batch Id 208 is having validation loss of 14681.2255859375\n",
            "22.033878326416016\n",
            "Epoch #1. Batch Id 208 is having validation accuracy of 21.72547846889952\n",
            "Epoch #1. Batch Id 209 is having validation loss of 14619.21875\n",
            "1659.71484375\n",
            "Epoch #1. Batch Id 209 is having validation accuracy of 21.741071428571427\n",
            "Epoch #1. Batch Id 210 is having validation loss of 14550.41015625\n",
            "100.56900024414062\n",
            "Epoch #1. Batch Id 210 is having validation accuracy of 21.786137440758292\n",
            "Epoch #1. Batch Id 211 is having validation loss of 14481.880859375\n",
            "22.12408447265625\n",
            "Epoch #1. Batch Id 211 is having validation accuracy of 21.83077830188679\n",
            "Epoch #1. Batch Id 212 is having validation loss of 14414.1064453125\n",
            "45.92110824584961\n",
            "Epoch #1. Batch Id 212 is having validation accuracy of 21.904342723004696\n",
            "Epoch #1. Batch Id 213 is having validation loss of 14346.962890625\n",
            "45.37253189086914\n",
            "Epoch #1. Batch Id 213 is having validation accuracy of 21.860397196261683\n",
            "Epoch #1. Batch Id 214 is having validation loss of 14280.31640625\n",
            "18.018522262573242\n",
            "Epoch #1. Batch Id 214 is having validation accuracy of 21.84593023255814\n",
            "Epoch #1. Batch Id 215 is having validation loss of 14214.40625\n",
            "43.76949691772461\n",
            "Epoch #1. Batch Id 215 is having validation accuracy of 21.88946759259259\n",
            "Epoch #1. Batch Id 216 is having validation loss of 14148.9619140625\n",
            "12.927199363708496\n",
            "Epoch #1. Batch Id 216 is having validation accuracy of 21.961405529953918\n",
            "Epoch #1. Batch Id 217 is having validation loss of 14084.25390625\n",
            "42.623504638671875\n",
            "Epoch #1. Batch Id 217 is having validation accuracy of 21.918004587155963\n",
            "Epoch #1. Batch Id 218 is having validation loss of 14334.35546875\n",
            "68856.4453125\n",
            "Epoch #1. Batch Id 218 is having validation accuracy of 21.960616438356166\n",
            "Epoch #1. Batch Id 219 is having validation loss of 14269.30859375\n",
            "24.141674041748047\n",
            "Epoch #1. Batch Id 219 is having validation accuracy of 21.960227272727273\n",
            "Epoch #1. Batch Id 220 is having validation loss of 14204.8583984375\n",
            "25.827558517456055\n",
            "Epoch #1. Batch Id 220 is having validation accuracy of 21.97398190045249\n",
            "Epoch #1. Batch Id 221 is having validation loss of 14141.0185546875\n",
            "32.445648193359375\n",
            "Epoch #1. Batch Id 221 is having validation accuracy of 21.98761261261261\n",
            "Epoch #1. Batch Id 222 is having validation loss of 14077.8017578125\n",
            "43.71261215209961\n",
            "Epoch #1. Batch Id 222 is having validation accuracy of 22.001121076233183\n",
            "Epoch #1. Batch Id 223 is having validation loss of 14015.06640625\n",
            "25.1351375579834\n",
            "Epoch #1. Batch Id 223 is having validation accuracy of 22.084263392857142\n",
            "Epoch #1. Batch Id 224 is having validation loss of 13952.8828125\n",
            "23.696094512939453\n",
            "Epoch #1. Batch Id 224 is having validation accuracy of 22.069444444444443\n",
            "Epoch #1. Batch Id 225 is having validation loss of 13891.25390625\n",
            "24.741390228271484\n",
            "Epoch #1. Batch Id 225 is having validation accuracy of 22.08241150442478\n",
            "Epoch #1. Batch Id 226 is having validation loss of 13830.201171875\n",
            "32.25954818725586\n",
            "Epoch #1. Batch Id 226 is having validation accuracy of 22.15033039647577\n",
            "Epoch #1. Batch Id 227 is having validation loss of 13839.818359375\n",
            "16023.013671875\n",
            "Epoch #1. Batch Id 227 is having validation accuracy of 22.23135964912281\n",
            "Epoch #1. Batch Id 228 is having validation loss of 13779.4794921875\n",
            "22.30415916442871\n",
            "Epoch #1. Batch Id 228 is having validation accuracy of 22.216157205240176\n",
            "Epoch #1. Batch Id 229 is having validation loss of 13719.6083984375\n",
            "9.159332275390625\n",
            "Epoch #1. Batch Id 229 is having validation accuracy of 22.282608695652176\n",
            "Epoch #1. Batch Id 230 is having validation loss of 13660.3037109375\n",
            "20.130664825439453\n",
            "Epoch #1. Batch Id 230 is having validation accuracy of 22.307900432900432\n",
            "Epoch #1. Batch Id 231 is having validation loss of 13601.55078125\n",
            "29.544815063476562\n",
            "Epoch #1. Batch Id 231 is having validation accuracy of 22.413793103448278\n",
            "Epoch #1. Batch Id 232 is having validation loss of 13543.267578125\n",
            "21.483013153076172\n",
            "Epoch #1. Batch Id 232 is having validation accuracy of 22.505364806866954\n",
            "Epoch #1. Batch Id 233 is having validation loss of 13485.8134765625\n",
            "99.10333251953125\n",
            "Epoch #1. Batch Id 233 is having validation accuracy of 22.60950854700855\n",
            "Epoch #1. Batch Id 234 is having validation loss of 13428.4501953125\n",
            "5.5560994148254395\n",
            "Epoch #1. Batch Id 234 is having validation accuracy of 22.726063829787233\n",
            "Epoch #1. Batch Id 235 is having validation loss of 13371.6064453125\n",
            "13.340217590332031\n",
            "Epoch #1. Batch Id 235 is having validation accuracy of 22.801906779661017\n",
            "Epoch #1. Batch Id 236 is having validation loss of 13315.3037109375\n",
            "27.89873504638672\n",
            "Epoch #1. Batch Id 236 is having validation accuracy of 22.811181434599156\n",
            "Epoch #1. Batch Id 237 is having validation loss of 13259.4638671875\n",
            "25.501625061035156\n",
            "Epoch #1. Batch Id 237 is having validation accuracy of 22.872899159663866\n",
            "Epoch #1. Batch Id 238 is having validation loss of 13204.0966796875\n",
            "26.741369247436523\n",
            "Epoch #1. Batch Id 238 is having validation accuracy of 22.947175732217573\n",
            "Epoch #1. Batch Id 239 is having validation loss of 13174.8525390625\n",
            "6185.42626953125\n",
            "Epoch #1. Batch Id 239 is having validation accuracy of 22.955729166666668\n",
            "Epoch #1. Batch Id 240 is having validation loss of 13120.4697265625\n",
            "68.64137268066406\n",
            "Epoch #1. Batch Id 240 is having validation accuracy of 23.00311203319502\n",
            "Epoch #1. Batch Id 241 is having validation loss of 13066.3291015625\n",
            "18.37512969970703\n",
            "Epoch #1. Batch Id 241 is having validation accuracy of 23.050103305785125\n",
            "Epoch #1. Batch Id 242 is having validation loss of 13012.6337890625\n",
            "18.3636474609375\n",
            "Epoch #1. Batch Id 242 is having validation accuracy of 23.14814814814815\n",
            "Epoch #1. Batch Id 243 is having validation loss of 13001.888671875\n",
            "10390.751953125\n",
            "Epoch #1. Batch Id 243 is having validation accuracy of 23.206967213114755\n",
            "Epoch #1. Batch Id 244 is having validation loss of 13053.416015625\n",
            "25626.1484375\n",
            "Epoch #1. Batch Id 244 is having validation accuracy of 23.227040816326532\n",
            "Epoch #1. Batch Id 245 is having validation loss of 13000.4814453125\n",
            "31.606807708740234\n",
            "Epoch #1. Batch Id 245 is having validation accuracy of 23.297764227642276\n",
            "Epoch #1. Batch Id 246 is having validation loss of 12947.8984375\n",
            "12.487130165100098\n",
            "Epoch #1. Batch Id 246 is having validation accuracy of 23.342611336032387\n",
            "Epoch #1. Batch Id 247 is having validation loss of 12895.80078125\n",
            "27.655990600585938\n",
            "Epoch #1. Batch Id 247 is having validation accuracy of 23.324092741935484\n",
            "Epoch #1. Batch Id 248 is having validation loss of 12844.0576171875\n",
            "11.657366752624512\n",
            "Epoch #1. Batch Id 248 is having validation accuracy of 23.393574297188756\n",
            "Epoch #1. Batch Id 249 is having validation loss of 12999.09765625\n",
            "51604.0859375\n",
            "Epoch #1. Batch Id 249 is having validation accuracy of 23.4125\n",
            "Epoch #1. Batch Id 250 is having validation loss of 12947.400390625\n",
            "23.02621841430664\n",
            "Epoch #1. Batch Id 250 is having validation accuracy of 23.443725099601593\n",
            "Epoch #1. Batch Id 251 is having validation loss of 12896.2216796875\n",
            "50.36111068725586\n",
            "Epoch #1. Batch Id 251 is having validation accuracy of 23.449900793650794\n",
            "Epoch #1. Batch Id 252 is having validation loss of 12845.4228515625\n",
            "44.21629333496094\n",
            "Epoch #1. Batch Id 252 is having validation accuracy of 23.48073122529644\n",
            "Epoch #1. Batch Id 253 is having validation loss of 12795.001953125\n",
            "38.614742279052734\n",
            "Epoch #1. Batch Id 253 is having validation accuracy of 23.499015748031496\n",
            "Epoch #1. Batch Id 254 is having validation loss of 12746.162109375\n",
            "340.91754150390625\n",
            "Epoch #1. Batch Id 254 is having validation accuracy of 23.529411764705884\n",
            "Epoch #1. Batch Id 255 is having validation loss of 12696.544921875\n",
            "44.13377380371094\n",
            "Epoch #1. Batch Id 255 is having validation accuracy of 23.54736328125\n",
            "Epoch #1. Batch Id 256 is having validation loss of 12885.6689453125\n",
            "61301.375\n",
            "Epoch #1. Batch Id 256 is having validation accuracy of 23.553015564202333\n",
            "Epoch #1. Batch Id 257 is having validation loss of 12835.8310546875\n",
            "27.46723747253418\n",
            "Epoch #1. Batch Id 257 is having validation accuracy of 23.607073643410853\n",
            "Epoch #1. Batch Id 258 is having validation loss of 12786.3662109375\n",
            "24.321022033691406\n",
            "Epoch #1. Batch Id 258 is having validation accuracy of 23.6003861003861\n",
            "Epoch #1. Batch Id 259 is having validation loss of 12737.2490234375\n",
            "15.908693313598633\n",
            "Epoch #1. Batch Id 259 is having validation accuracy of 23.58173076923077\n",
            "Epoch #1. Batch Id 260 is having validation loss of 12688.6162109375\n",
            "44.07079315185547\n",
            "Epoch #1. Batch Id 260 is having validation accuracy of 23.62308429118774\n",
            "Epoch #1. Batch Id 261 is having validation loss of 12640.330078125\n",
            "37.64868927001953\n",
            "Epoch #1. Batch Id 261 is having validation accuracy of 23.616412213740457\n",
            "Epoch #1. Batch Id 262 is having validation loss of 12724.8603515625\n",
            "34871.82421875\n",
            "Epoch #1. Batch Id 262 is having validation accuracy of 23.63355513307985\n",
            "Epoch #1. Batch Id 263 is having validation loss of 12676.7734375\n",
            "29.802194595336914\n",
            "Epoch #1. Batch Id 263 is having validation accuracy of 23.615056818181817\n",
            "Epoch #1. Batch Id 264 is having validation loss of 12629.0205078125\n",
            "22.336240768432617\n",
            "Epoch #1. Batch Id 264 is having validation accuracy of 23.620283018867923\n",
            "Epoch #1. Batch Id 265 is having validation loss of 12581.654296875\n",
            "29.616872787475586\n",
            "Epoch #1. Batch Id 265 is having validation accuracy of 23.601973684210527\n",
            "Epoch #1. Batch Id 266 is having validation loss of 12534.6171875\n",
            "22.82140350341797\n",
            "Epoch #1. Batch Id 266 is having validation accuracy of 23.618913857677903\n",
            "Epoch #1. Batch Id 267 is having validation loss of 12487.916015625\n",
            "18.792423248291016\n",
            "Epoch #1. Batch Id 267 is having validation accuracy of 23.624067164179106\n",
            "Epoch #1. Batch Id 268 is having validation loss of 12441.5478515625\n",
            "14.993976593017578\n",
            "Epoch #1. Batch Id 268 is having validation accuracy of 23.664033457249072\n",
            "Epoch #1. Batch Id 269 is having validation loss of 12395.5537109375\n",
            "23.04865264892578\n",
            "Epoch #1. Batch Id 269 is having validation accuracy of 23.66898148148148\n",
            "Epoch #1. Batch Id 270 is having validation loss of 12350.0712890625\n",
            "69.8526840209961\n",
            "Epoch #1. Batch Id 270 is having validation accuracy of 23.696955719557195\n",
            "Epoch #1. Batch Id 271 is having validation loss of 12304.7568359375\n",
            "24.459980010986328\n",
            "Epoch #1. Batch Id 271 is having validation accuracy of 23.736213235294116\n",
            "Epoch #1. Batch Id 272 is having validation loss of 12259.748046875\n",
            "17.25078010559082\n",
            "Epoch #1. Batch Id 272 is having validation accuracy of 23.74084249084249\n",
            "Epoch #1. Batch Id 273 is having validation loss of 12215.1396484375\n",
            "37.12538528442383\n",
            "Epoch #1. Batch Id 273 is having validation accuracy of 23.791058394160583\n",
            "Epoch #1. Batch Id 274 is having validation loss of 12170.8388671875\n",
            "32.41358947753906\n",
            "Epoch #1. Batch Id 274 is having validation accuracy of 23.863636363636363\n",
            "Epoch #1. Batch Id 275 is having validation loss of 12145.3232421875\n",
            "5128.6416015625\n",
            "Epoch #1. Batch Id 275 is having validation accuracy of 23.845108695652176\n",
            "Epoch #1. Batch Id 276 is having validation loss of 12101.6044921875\n",
            "35.18558120727539\n",
            "Epoch #1. Batch Id 276 is having validation accuracy of 23.939530685920577\n",
            "Epoch #1. Batch Id 277 is having validation loss of 12058.1376953125\n",
            "17.792551040649414\n",
            "Epoch #1. Batch Id 277 is having validation accuracy of 23.92086330935252\n",
            "Epoch #1. Batch Id 278 is having validation loss of 12023.09765625\n",
            "2282.07421875\n",
            "Epoch #1. Batch Id 278 is having validation accuracy of 23.935931899641577\n",
            "Epoch #1. Batch Id 279 is having validation loss of 11980.34375\n",
            "51.9528694152832\n",
            "Epoch #1. Batch Id 279 is having validation accuracy of 23.939732142857142\n",
            "Epoch #1. Batch Id 280 is having validation loss of 11937.767578125\n",
            "16.537538528442383\n",
            "Epoch #1. Batch Id 280 is having validation accuracy of 23.999110320284696\n",
            "Epoch #1. Batch Id 281 is having validation loss of 11898.82421875\n",
            "955.8452758789062\n",
            "Epoch #1. Batch Id 281 is having validation accuracy of 23.991578014184398\n",
            "Epoch #1. Batch Id 282 is having validation loss of 11856.8779296875\n",
            "28.078275680541992\n",
            "Epoch #1. Batch Id 282 is having validation accuracy of 24.006183745583037\n",
            "Epoch #1. Batch Id 283 is having validation loss of 11815.2255859375\n",
            "27.626644134521484\n",
            "Epoch #1. Batch Id 283 is having validation accuracy of 24.053697183098592\n",
            "Epoch #1. Batch Id 284 is having validation loss of 11773.87109375\n",
            "29.10609245300293\n",
            "Epoch #1. Batch Id 284 is having validation accuracy of 24.04605263157895\n",
            "Epoch #1. Batch Id 285 is having validation loss of 11732.7470703125\n",
            "12.478219985961914\n",
            "Epoch #1. Batch Id 285 is having validation accuracy of 24.10402097902098\n",
            "Epoch #1. Batch Id 286 is having validation loss of 11692.0498046875\n",
            "52.63920211791992\n",
            "Epoch #1. Batch Id 286 is having validation accuracy of 24.074477351916375\n",
            "Epoch #1. Batch Id 287 is having validation loss of 11651.615234375\n",
            "46.90593719482422\n",
            "Epoch #1. Batch Id 287 is having validation accuracy of 24.110243055555557\n",
            "Epoch #1. Batch Id 288 is having validation loss of 11647.1103515625\n",
            "10349.7705078125\n",
            "Epoch #1. Batch Id 288 is having validation accuracy of 24.134948096885815\n",
            "Epoch #1. Batch Id 289 is having validation loss of 11607.0068359375\n",
            "17.202838897705078\n",
            "Epoch #1. Batch Id 289 is having validation accuracy of 24.213362068965516\n",
            "Epoch #1. Batch Id 290 is having validation loss of 11567.203125\n",
            "24.05099868774414\n",
            "Epoch #1. Batch Id 290 is having validation accuracy of 24.24828178694158\n",
            "Epoch #1. Batch Id 291 is having validation loss of 11527.6650390625\n",
            "22.09625816345215\n",
            "Epoch #1. Batch Id 291 is having validation accuracy of 24.347174657534246\n",
            "Epoch #1. Batch Id 292 is having validation loss of 11488.3642578125\n",
            "12.59619140625\n",
            "Epoch #1. Batch Id 292 is having validation accuracy of 24.370733788395903\n",
            "Epoch #1. Batch Id 293 is having validation loss of 11449.3505859375\n",
            "18.465412139892578\n",
            "Epoch #1. Batch Id 293 is having validation accuracy of 24.415391156462587\n",
            "Epoch #1. Batch Id 294 is having validation loss of 11501.1181640625\n",
            "26720.650390625\n",
            "Epoch #1. Batch Id 294 is having validation accuracy of 24.459745762711865\n",
            "Epoch #1. Batch Id 295 is having validation loss of 11462.359375\n",
            "28.399503707885742\n",
            "Epoch #1. Batch Id 295 is having validation accuracy of 24.44045608108108\n",
            "Epoch #1. Batch Id 296 is having validation loss of 11457.9150390625\n",
            "10142.37109375\n",
            "Epoch #1. Batch Id 296 is having validation accuracy of 24.45286195286195\n",
            "Epoch #1. Batch Id 297 is having validation loss of 11419.5107421875\n",
            "13.556782722473145\n",
            "Epoch #1. Batch Id 297 is having validation accuracy of 24.517617449664428\n",
            "Epoch #1. Batch Id 298 is having validation loss of 11381.353515625\n",
            "10.507329940795898\n",
            "Epoch #1. Batch Id 298 is having validation accuracy of 24.57148829431438\n",
            "Epoch #1. Batch Id 299 is having validation loss of 11343.5947265625\n",
            "53.57167053222656\n",
            "Epoch #1. Batch Id 299 is having validation accuracy of 24.583333333333332\n",
            "Epoch #1. Batch Id 300 is having validation loss of 11306.0224609375\n",
            "34.25788497924805\n",
            "Epoch #1. Batch Id 300 is having validation accuracy of 24.62624584717608\n",
            "Epoch #1. Batch Id 301 is having validation loss of 11408.9306640625\n",
            "42384.4375\n",
            "Epoch #1. Batch Id 301 is having validation accuracy of 24.6067880794702\n",
            "Epoch #1. Batch Id 302 is having validation loss of 11371.5078125\n",
            "69.66432189941406\n",
            "Epoch #1. Batch Id 302 is having validation accuracy of 24.6493399339934\n",
            "Epoch #1. Batch Id 303 is having validation loss of 11334.232421875\n",
            "39.783905029296875\n",
            "Epoch #1. Batch Id 303 is having validation accuracy of 24.66077302631579\n",
            "Epoch #1. Batch Id 304 is having validation loss of 11297.1259765625\n",
            "16.839189529418945\n",
            "Epoch #1. Batch Id 304 is having validation accuracy of 24.743852459016395\n",
            "Epoch #1. Batch Id 305 is having validation loss of 11260.330078125\n",
            "37.56660079956055\n",
            "Epoch #1. Batch Id 305 is having validation accuracy of 24.77532679738562\n",
            "Epoch #1. Batch Id 306 is having validation loss of 11223.7509765625\n",
            "30.5994815826416\n",
            "Epoch #1. Batch Id 306 is having validation accuracy of 24.79641693811075\n",
            "Epoch #1. Batch Id 307 is having validation loss of 11187.5927734375\n",
            "86.90084838867188\n",
            "Epoch #1. Batch Id 307 is having validation accuracy of 24.756493506493506\n",
            "Epoch #1. Batch Id 308 is having validation loss of 11151.416015625\n",
            "9.041600227355957\n",
            "Epoch #1. Batch Id 308 is having validation accuracy of 24.767394822006473\n",
            "Epoch #1. Batch Id 309 is having validation loss of 11115.4951171875\n",
            "16.026596069335938\n",
            "Epoch #1. Batch Id 309 is having validation accuracy of 24.74798387096774\n",
            "Epoch #1. Batch Id 310 is having validation loss of 11079.826171875\n",
            "22.419776916503906\n",
            "Epoch #1. Batch Id 310 is having validation accuracy of 24.748794212218648\n",
            "Epoch #1. Batch Id 311 is having validation loss of 11044.4365234375\n",
            "38.383995056152344\n",
            "Epoch #1. Batch Id 311 is having validation accuracy of 24.779647435897434\n",
            "Epoch #1. Batch Id 312 is having validation loss of 11009.21875\n",
            "21.319093704223633\n",
            "Epoch #1. Batch Id 312 is having validation accuracy of 24.810303514376997\n",
            "Epoch #1. Batch Id 313 is having validation loss of 10974.263671875\n",
            "33.18539047241211\n",
            "Epoch #1. Batch Id 313 is having validation accuracy of 24.840764331210192\n",
            "Epoch #1. Batch Id 314 is having validation loss of 10939.576171875\n",
            "47.58438491821289\n",
            "Epoch #1. Batch Id 314 is having validation accuracy of 24.841269841269842\n",
            "Epoch #1. Batch Id 315 is having validation loss of 10904.9853515625\n",
            "8.964249610900879\n",
            "Epoch #1. Batch Id 315 is having validation accuracy of 24.88132911392405\n",
            "Epoch #1. Batch Id 316 is having validation loss of 10870.7353515625\n",
            "47.78723907470703\n",
            "Epoch #1. Batch Id 316 is having validation accuracy of 24.87184542586751\n",
            "Epoch #1. Batch Id 317 is having validation loss of 10836.619140625\n",
            "21.721435546875\n",
            "Epoch #1. Batch Id 317 is having validation accuracy of 24.842767295597483\n",
            "Epoch #1. Batch Id 318 is having validation loss of 10802.9033203125\n",
            "81.37731170654297\n",
            "Epoch #1. Batch Id 318 is having validation accuracy of 24.804075235109718\n",
            "Epoch #1. Batch Id 319 is having validation loss of 10769.2412109375\n",
            "31.121543884277344\n",
            "Epoch #1. Batch Id 319 is having validation accuracy of 24.814453125\n",
            "Epoch #1. Batch Id 320 is having validation loss of 10735.7197265625\n",
            "8.892881393432617\n",
            "Epoch #1. Batch Id 320 is having validation accuracy of 24.88317757009346\n",
            "Epoch #1. Batch Id 321 is having validation loss of 10702.4609375\n",
            "26.518978118896484\n",
            "Epoch #1. Batch Id 321 is having validation accuracy of 24.883540372670808\n",
            "Epoch #1. Batch Id 322 is having validation loss of 10771.1416015625\n",
            "32886.328125\n",
            "Epoch #1. Batch Id 322 is having validation accuracy of 24.99032507739938\n",
            "Epoch #1. Batch Id 323 is having validation loss of 10897.541015625\n",
            "51724.484375\n",
            "Epoch #1. Batch Id 323 is having validation accuracy of 25.028935185185187\n",
            "Epoch #1. Batch Id 324 is having validation loss of 10864.091796875\n",
            "26.54572868347168\n",
            "Epoch #1. Batch Id 324 is having validation accuracy of 25.03846153846154\n",
            "Epoch #1. Batch Id 325 is having validation loss of 10830.8623046875\n",
            "31.419992446899414\n",
            "Epoch #1. Batch Id 325 is having validation accuracy of 25.057515337423315\n",
            "Epoch #1. Batch Id 326 is having validation loss of 10797.8125\n",
            "23.7135009765625\n",
            "Epoch #1. Batch Id 326 is having validation accuracy of 25.03822629969419\n",
            "Epoch #1. Batch Id 327 is having validation loss of 10764.9423828125\n",
            "16.486949920654297\n",
            "Epoch #1. Batch Id 327 is having validation accuracy of 25.104801829268293\n",
            "Epoch #1. Batch Id 328 is having validation loss of 10732.3203125\n",
            "32.20501708984375\n",
            "Epoch #1. Batch Id 328 is having validation accuracy of 25.151975683890576\n",
            "Epoch #1. Batch Id 329 is having validation loss of 10753.5478515625\n",
            "17737.533203125\n",
            "Epoch #1. Batch Id 329 is having validation accuracy of 25.21780303030303\n",
            "Epoch #1. Batch Id 330 is having validation loss of 10721.1533203125\n",
            "30.956289291381836\n",
            "Epoch #1. Batch Id 330 is having validation accuracy of 25.207703927492446\n",
            "Epoch #1. Batch Id 331 is having validation loss of 10689.009765625\n",
            "49.42128372192383\n",
            "Epoch #1. Batch Id 331 is having validation accuracy of 25.20707831325301\n",
            "Epoch #1. Batch Id 332 is having validation loss of 10657.7919921875\n",
            "293.6288146972656\n",
            "Epoch #1. Batch Id 332 is having validation accuracy of 25.21584084084084\n",
            "Epoch #1. Batch Id 333 is having validation loss of 10625.91796875\n",
            "11.708024024963379\n",
            "Epoch #1. Batch Id 333 is having validation accuracy of 25.28068862275449\n",
            "Epoch #1. Batch Id 334 is having validation loss of 10594.7919921875\n",
            "198.86720275878906\n",
            "Epoch #1. Batch Id 334 is having validation accuracy of 25.270522388059703\n",
            "Epoch #1. Batch Id 335 is having validation loss of 10741.6611328125\n",
            "59942.8046875\n",
            "Epoch #1. Batch Id 335 is having validation accuracy of 25.260416666666668\n",
            "Epoch #1. Batch Id 336 is having validation loss of 10709.83203125\n",
            "15.184370994567871\n",
            "Epoch #1. Batch Id 336 is having validation accuracy of 25.250370919881306\n",
            "Epoch #1. Batch Id 337 is having validation loss of 10678.23828125\n",
            "31.19297218322754\n",
            "Epoch #1. Batch Id 337 is having validation accuracy of 25.286612426035504\n",
            "Epoch #1. Batch Id 338 is having validation loss of 10684.2783203125\n",
            "12725.94140625\n",
            "Epoch #1. Batch Id 338 is having validation accuracy of 25.267330383480825\n",
            "Epoch #1. Batch Id 339 is having validation loss of 10652.919921875\n",
            "22.35946273803711\n",
            "Epoch #1. Batch Id 339 is having validation accuracy of 25.294117647058822\n",
            "Epoch #1. Batch Id 340 is having validation loss of 10621.7060546875\n",
            "9.080170631408691\n",
            "Epoch #1. Batch Id 340 is having validation accuracy of 25.33907624633431\n",
            "Epoch #1. Batch Id 341 is having validation loss of 10625.5791015625\n",
            "11946.255859375\n",
            "Epoch #1. Batch Id 341 is having validation accuracy of 25.35635964912281\n",
            "Epoch #1. Batch Id 342 is having validation loss of 10594.685546875\n",
            "29.16370964050293\n",
            "Epoch #1. Batch Id 342 is having validation accuracy of 25.365363536719034\n",
            "Эпоха #1 train_loss: 0.018897833302617073, val_loss: 0.9677279591560364\n",
            "Потрачено 14.2 минут на 1 эпоху\n",
            "Batch Id 0 is having training loss of 66.04838562011719\n",
            "66.04838562011719\n",
            "Epoch #2. Accuracy on batch 0 on Training is 28.125\n",
            "Epoch #2. Accuracy on batch 1 on Training is 34.375\n",
            "Epoch #2. Accuracy on batch 2 on Training is 36.458333333333336\n",
            "Epoch #2. Accuracy on batch 3 on Training is 35.9375\n",
            "Epoch #2. Accuracy on batch 4 on Training is 35.625\n",
            "Epoch #2. Accuracy on batch 5 on Training is 34.375\n",
            "Epoch #2. Accuracy on batch 6 on Training is 35.267857142857146\n",
            "Epoch #2. Accuracy on batch 7 on Training is 33.984375\n",
            "Epoch #2. Accuracy on batch 8 on Training is 34.02777777777778\n",
            "Epoch #2. Accuracy on batch 9 on Training is 34.0625\n",
            "Epoch #2. Accuracy on batch 10 on Training is 33.52272727272727\n",
            "Epoch #2. Accuracy on batch 11 on Training is 34.635416666666664\n",
            "Epoch #2. Accuracy on batch 12 on Training is 33.89423076923077\n",
            "Epoch #2. Accuracy on batch 13 on Training is 32.8125\n",
            "Epoch #2. Accuracy on batch 14 on Training is 33.333333333333336\n",
            "Epoch #2. Accuracy on batch 15 on Training is 33.203125\n",
            "Epoch #2. Accuracy on batch 16 on Training is 33.088235294117645\n",
            "Epoch #2. Accuracy on batch 17 on Training is 33.333333333333336\n",
            "Epoch #2. Accuracy on batch 18 on Training is 33.223684210526315\n",
            "Epoch #2. Accuracy on batch 19 on Training is 33.4375\n",
            "Batch Id 20 is having training loss of 68.31936645507812\n",
            "12.560579299926758\n",
            "Epoch #2. Accuracy on batch 20 on Training is 33.63095238095238\n",
            "Epoch #2. Accuracy on batch 21 on Training is 32.95454545454545\n",
            "Epoch #2. Accuracy on batch 22 on Training is 32.33695652173913\n",
            "Epoch #2. Accuracy on batch 23 on Training is 32.291666666666664\n",
            "Epoch #2. Accuracy on batch 24 on Training is 32.0\n",
            "Epoch #2. Accuracy on batch 25 on Training is 32.09134615384615\n",
            "Epoch #2. Accuracy on batch 26 on Training is 32.06018518518518\n",
            "Epoch #2. Accuracy on batch 27 on Training is 32.589285714285715\n",
            "Epoch #2. Accuracy on batch 28 on Training is 32.650862068965516\n",
            "Epoch #2. Accuracy on batch 29 on Training is 32.604166666666664\n",
            "Epoch #2. Accuracy on batch 30 on Training is 32.96370967741935\n",
            "Epoch #2. Accuracy on batch 31 on Training is 32.8125\n",
            "Epoch #2. Accuracy on batch 32 on Training is 32.859848484848484\n",
            "Epoch #2. Accuracy on batch 33 on Training is 32.720588235294116\n",
            "Epoch #2. Accuracy on batch 34 on Training is 33.30357142857143\n",
            "Epoch #2. Accuracy on batch 35 on Training is 32.986111111111114\n",
            "Epoch #2. Accuracy on batch 36 on Training is 32.685810810810814\n",
            "Epoch #2. Accuracy on batch 37 on Training is 32.8125\n",
            "Epoch #2. Accuracy on batch 38 on Training is 32.45192307692308\n",
            "Epoch #2. Accuracy on batch 39 on Training is 32.265625\n",
            "Batch Id 40 is having training loss of 57.16817092895508\n",
            "12.535511016845703\n",
            "Epoch #2. Accuracy on batch 40 on Training is 32.31707317073171\n",
            "Epoch #2. Accuracy on batch 41 on Training is 32.142857142857146\n",
            "Epoch #2. Accuracy on batch 42 on Training is 31.83139534883721\n",
            "Epoch #2. Accuracy on batch 43 on Training is 31.53409090909091\n",
            "Epoch #2. Accuracy on batch 44 on Training is 31.458333333333332\n",
            "Epoch #2. Accuracy on batch 45 on Training is 31.182065217391305\n",
            "Epoch #2. Accuracy on batch 46 on Training is 31.18351063829787\n",
            "Epoch #2. Accuracy on batch 47 on Training is 31.0546875\n",
            "Epoch #2. Accuracy on batch 48 on Training is 30.994897959183675\n",
            "Epoch #2. Accuracy on batch 49 on Training is 31.0\n",
            "Epoch #2. Accuracy on batch 50 on Training is 30.698529411764707\n",
            "Epoch #2. Accuracy on batch 51 on Training is 30.348557692307693\n",
            "Epoch #2. Accuracy on batch 52 on Training is 30.36556603773585\n",
            "Epoch #2. Accuracy on batch 53 on Training is 30.324074074074073\n",
            "Epoch #2. Accuracy on batch 54 on Training is 30.34090909090909\n",
            "Epoch #2. Accuracy on batch 55 on Training is 30.245535714285715\n",
            "Epoch #2. Accuracy on batch 56 on Training is 30.208333333333332\n",
            "Epoch #2. Accuracy on batch 57 on Training is 30.280172413793103\n",
            "Epoch #2. Accuracy on batch 58 on Training is 30.13771186440678\n",
            "Epoch #2. Accuracy on batch 59 on Training is 29.84375\n",
            "Batch Id 60 is having training loss of 961.3364868164062\n",
            "18.382001876831055\n",
            "Epoch #2. Accuracy on batch 60 on Training is 29.71311475409836\n",
            "Epoch #2. Accuracy on batch 61 on Training is 29.788306451612904\n",
            "Epoch #2. Accuracy on batch 62 on Training is 29.86111111111111\n",
            "Epoch #2. Accuracy on batch 63 on Training is 29.833984375\n",
            "Epoch #2. Accuracy on batch 64 on Training is 29.951923076923077\n",
            "Epoch #2. Accuracy on batch 65 on Training is 29.97159090909091\n",
            "Epoch #2. Accuracy on batch 66 on Training is 29.850746268656717\n",
            "Epoch #2. Accuracy on batch 67 on Training is 29.6875\n",
            "Epoch #2. Accuracy on batch 68 on Training is 29.755434782608695\n",
            "Epoch #2. Accuracy on batch 69 on Training is 29.821428571428573\n",
            "Epoch #2. Accuracy on batch 70 on Training is 29.973591549295776\n",
            "Epoch #2. Accuracy on batch 71 on Training is 29.947916666666668\n",
            "Epoch #2. Accuracy on batch 72 on Training is 30.008561643835616\n",
            "Epoch #2. Accuracy on batch 73 on Training is 30.194256756756758\n",
            "Epoch #2. Accuracy on batch 74 on Training is 30.25\n",
            "Epoch #2. Accuracy on batch 75 on Training is 30.098684210526315\n",
            "Epoch #2. Accuracy on batch 76 on Training is 30.23538961038961\n",
            "Epoch #2. Accuracy on batch 77 on Training is 30.16826923076923\n",
            "Epoch #2. Accuracy on batch 78 on Training is 30.300632911392405\n",
            "Epoch #2. Accuracy on batch 79 on Training is 30.1171875\n",
            "Batch Id 80 is having training loss of 1672.5301513671875\n",
            "14.094573020935059\n",
            "Epoch #2. Accuracy on batch 80 on Training is 30.285493827160494\n",
            "Epoch #2. Accuracy on batch 81 on Training is 30.259146341463413\n",
            "Epoch #2. Accuracy on batch 82 on Training is 30.308734939759034\n",
            "Epoch #2. Accuracy on batch 83 on Training is 30.171130952380953\n",
            "Epoch #2. Accuracy on batch 84 on Training is 30.220588235294116\n",
            "Epoch #2. Accuracy on batch 85 on Training is 30.34156976744186\n",
            "Epoch #2. Accuracy on batch 86 on Training is 30.352011494252874\n",
            "Epoch #2. Accuracy on batch 87 on Training is 30.36221590909091\n",
            "Epoch #2. Accuracy on batch 88 on Training is 30.372191011235955\n",
            "Epoch #2. Accuracy on batch 89 on Training is 30.34722222222222\n",
            "Epoch #2. Accuracy on batch 90 on Training is 30.425824175824175\n",
            "Epoch #2. Accuracy on batch 91 on Training is 30.400815217391305\n",
            "Epoch #2. Accuracy on batch 92 on Training is 30.275537634408604\n",
            "Epoch #2. Accuracy on batch 93 on Training is 30.252659574468087\n",
            "Epoch #2. Accuracy on batch 94 on Training is 30.19736842105263\n",
            "Epoch #2. Accuracy on batch 95 on Training is 30.208333333333332\n",
            "Epoch #2. Accuracy on batch 96 on Training is 29.99355670103093\n",
            "Epoch #2. Accuracy on batch 97 on Training is 30.006377551020407\n",
            "Epoch #2. Accuracy on batch 98 on Training is 30.018939393939394\n",
            "Epoch #2. Accuracy on batch 99 on Training is 30.09375\n",
            "Batch Id 100 is having training loss of 1770.9970703125\n",
            "23.304237365722656\n",
            "Epoch #2. Accuracy on batch 100 on Training is 30.012376237623762\n",
            "Epoch #2. Accuracy on batch 101 on Training is 30.024509803921568\n",
            "Epoch #2. Accuracy on batch 102 on Training is 30.006067961165048\n",
            "Epoch #2. Accuracy on batch 103 on Training is 30.198317307692307\n",
            "Epoch #2. Accuracy on batch 104 on Training is 30.267857142857142\n",
            "Epoch #2. Accuracy on batch 105 on Training is 30.306603773584907\n",
            "Epoch #2. Accuracy on batch 106 on Training is 30.227803738317757\n",
            "Epoch #2. Accuracy on batch 107 on Training is 30.17939814814815\n",
            "Epoch #2. Accuracy on batch 108 on Training is 30.160550458715598\n",
            "Epoch #2. Accuracy on batch 109 on Training is 30.28409090909091\n",
            "Epoch #2. Accuracy on batch 110 on Training is 30.26463963963964\n",
            "Epoch #2. Accuracy on batch 111 on Training is 30.329241071428573\n",
            "Epoch #2. Accuracy on batch 112 on Training is 30.309734513274336\n",
            "Epoch #2. Accuracy on batch 113 on Training is 30.31798245614035\n",
            "Epoch #2. Accuracy on batch 114 on Training is 30.407608695652176\n",
            "Epoch #2. Accuracy on batch 115 on Training is 30.387931034482758\n",
            "Epoch #2. Accuracy on batch 116 on Training is 30.44871794871795\n",
            "Epoch #2. Accuracy on batch 117 on Training is 30.534957627118644\n",
            "Epoch #2. Accuracy on batch 118 on Training is 30.567226890756302\n",
            "Epoch #2. Accuracy on batch 119 on Training is 30.46875\n",
            "Batch Id 120 is having training loss of 1938.8070068359375\n",
            "138.03477478027344\n",
            "Epoch #2. Accuracy on batch 120 on Training is 30.423553719008265\n",
            "Epoch #2. Accuracy on batch 121 on Training is 30.50717213114754\n",
            "Epoch #2. Accuracy on batch 122 on Training is 30.51321138211382\n",
            "Epoch #2. Accuracy on batch 123 on Training is 30.519153225806452\n",
            "Epoch #2. Accuracy on batch 124 on Training is 30.55\n",
            "Epoch #2. Accuracy on batch 125 on Training is 30.456349206349206\n",
            "Epoch #2. Accuracy on batch 126 on Training is 30.462598425196852\n",
            "Epoch #2. Accuracy on batch 127 on Training is 30.3955078125\n",
            "Epoch #2. Accuracy on batch 128 on Training is 30.281007751937985\n",
            "Epoch #2. Accuracy on batch 129 on Training is 30.33653846153846\n",
            "Epoch #2. Accuracy on batch 130 on Training is 30.34351145038168\n",
            "Epoch #2. Accuracy on batch 131 on Training is 30.35037878787879\n",
            "Epoch #2. Accuracy on batch 132 on Training is 30.333646616541355\n",
            "Epoch #2. Accuracy on batch 133 on Training is 30.317164179104477\n",
            "Epoch #2. Accuracy on batch 134 on Training is 30.324074074074073\n",
            "Epoch #2. Accuracy on batch 135 on Training is 30.35386029411765\n",
            "Epoch #2. Accuracy on batch 136 on Training is 30.246350364963504\n",
            "Epoch #2. Accuracy on batch 137 on Training is 30.253623188405797\n",
            "Epoch #2. Accuracy on batch 138 on Training is 30.283273381294965\n",
            "Epoch #2. Accuracy on batch 139 on Training is 30.245535714285715\n",
            "Batch Id 140 is having training loss of 2680.4609375\n",
            "27.336633682250977\n",
            "Epoch #2. Accuracy on batch 140 on Training is 30.27482269503546\n",
            "Epoch #2. Accuracy on batch 141 on Training is 30.347711267605632\n",
            "Epoch #2. Accuracy on batch 142 on Training is 30.375874125874127\n",
            "Epoch #2. Accuracy on batch 143 on Training is 30.2734375\n",
            "Epoch #2. Accuracy on batch 144 on Training is 30.280172413793103\n",
            "Epoch #2. Accuracy on batch 145 on Training is 30.28681506849315\n",
            "Epoch #2. Accuracy on batch 146 on Training is 30.250850340136054\n",
            "Epoch #2. Accuracy on batch 147 on Training is 30.21537162162162\n",
            "Epoch #2. Accuracy on batch 148 on Training is 30.22231543624161\n",
            "Epoch #2. Accuracy on batch 149 on Training is 30.208333333333332\n",
            "Epoch #2. Accuracy on batch 150 on Training is 30.25662251655629\n",
            "Epoch #2. Accuracy on batch 151 on Training is 30.242598684210527\n",
            "Epoch #2. Accuracy on batch 152 on Training is 30.187908496732025\n",
            "Epoch #2. Accuracy on batch 153 on Training is 30.17451298701299\n",
            "Epoch #2. Accuracy on batch 154 on Training is 30.161290322580644\n",
            "Epoch #2. Accuracy on batch 155 on Training is 30.208333333333332\n",
            "Epoch #2. Accuracy on batch 156 on Training is 30.254777070063696\n",
            "Epoch #2. Accuracy on batch 157 on Training is 30.300632911392405\n",
            "Epoch #2. Accuracy on batch 158 on Training is 30.306603773584907\n",
            "Epoch #2. Accuracy on batch 159 on Training is 30.234375\n",
            "Batch Id 160 is having training loss of 2856.2998046875\n",
            "29.053451538085938\n",
            "Epoch #2. Accuracy on batch 160 on Training is 30.221273291925467\n",
            "Epoch #2. Accuracy on batch 161 on Training is 30.131172839506174\n",
            "Epoch #2. Accuracy on batch 162 on Training is 30.13803680981595\n",
            "Epoch #2. Accuracy on batch 163 on Training is 30.12576219512195\n",
            "Epoch #2. Accuracy on batch 164 on Training is 30.189393939393938\n",
            "Epoch #2. Accuracy on batch 165 on Training is 30.21460843373494\n",
            "Epoch #2. Accuracy on batch 166 on Training is 30.202095808383234\n",
            "Epoch #2. Accuracy on batch 167 on Training is 30.11532738095238\n",
            "Epoch #2. Accuracy on batch 168 on Training is 30.122041420118343\n",
            "Epoch #2. Accuracy on batch 169 on Training is 30.073529411764707\n",
            "Epoch #2. Accuracy on batch 170 on Training is 30.135233918128655\n",
            "Epoch #2. Accuracy on batch 171 on Training is 30.050872093023255\n",
            "Epoch #2. Accuracy on batch 172 on Training is 30.057803468208093\n",
            "Epoch #2. Accuracy on batch 173 on Training is 30.11853448275862\n",
            "Epoch #2. Accuracy on batch 174 on Training is 30.107142857142858\n",
            "Epoch #2. Accuracy on batch 175 on Training is 30.024857954545453\n",
            "Epoch #2. Accuracy on batch 176 on Training is 29.89053672316384\n",
            "Epoch #2. Accuracy on batch 177 on Training is 29.84550561797753\n",
            "Epoch #2. Accuracy on batch 178 on Training is 29.800977653631286\n",
            "Epoch #2. Accuracy on batch 179 on Training is 29.791666666666668\n",
            "Batch Id 180 is having training loss of 2789.886474609375\n",
            "22.207622528076172\n",
            "Epoch #2. Accuracy on batch 180 on Training is 29.799723756906076\n",
            "Epoch #2. Accuracy on batch 181 on Training is 29.756181318681318\n",
            "Epoch #2. Accuracy on batch 182 on Training is 29.832650273224044\n",
            "Epoch #2. Accuracy on batch 183 on Training is 29.789402173913043\n",
            "Epoch #2. Accuracy on batch 184 on Training is 29.695945945945947\n",
            "Epoch #2. Accuracy on batch 185 on Training is 29.653897849462364\n",
            "Epoch #2. Accuracy on batch 186 on Training is 29.67914438502674\n",
            "Epoch #2. Accuracy on batch 187 on Training is 29.6875\n",
            "Epoch #2. Accuracy on batch 188 on Training is 29.71230158730159\n",
            "Epoch #2. Accuracy on batch 189 on Training is 29.6875\n",
            "Epoch #2. Accuracy on batch 190 on Training is 29.712041884816752\n",
            "Epoch #2. Accuracy on batch 191 on Training is 29.671223958333332\n",
            "Epoch #2. Accuracy on batch 192 on Training is 29.582253886010363\n",
            "Epoch #2. Accuracy on batch 193 on Training is 29.558634020618555\n",
            "Epoch #2. Accuracy on batch 194 on Training is 29.53525641025641\n",
            "Epoch #2. Accuracy on batch 195 on Training is 29.528061224489797\n",
            "Epoch #2. Accuracy on batch 196 on Training is 29.53680203045685\n",
            "Epoch #2. Accuracy on batch 197 on Training is 29.482323232323232\n",
            "Epoch #2. Accuracy on batch 198 on Training is 29.569723618090453\n",
            "Epoch #2. Accuracy on batch 199 on Training is 29.59375\n",
            "Batch Id 200 is having training loss of 2590.247802734375\n",
            "29.95501708984375\n",
            "Epoch #2. Accuracy on batch 200 on Training is 29.58644278606965\n",
            "Epoch #2. Accuracy on batch 201 on Training is 29.53279702970297\n",
            "Epoch #2. Accuracy on batch 202 on Training is 29.495073891625616\n",
            "Epoch #2. Accuracy on batch 203 on Training is 29.473039215686274\n",
            "Epoch #2. Accuracy on batch 204 on Training is 29.420731707317074\n",
            "Epoch #2. Accuracy on batch 205 on Training is 29.44478155339806\n",
            "Epoch #2. Accuracy on batch 206 on Training is 29.468599033816425\n",
            "Epoch #2. Accuracy on batch 207 on Training is 29.462139423076923\n",
            "Epoch #2. Accuracy on batch 208 on Training is 29.500598086124402\n",
            "Epoch #2. Accuracy on batch 209 on Training is 29.419642857142858\n",
            "Epoch #2. Accuracy on batch 210 on Training is 29.41350710900474\n",
            "Epoch #2. Accuracy on batch 211 on Training is 29.392688679245282\n",
            "Epoch #2. Accuracy on batch 212 on Training is 29.43075117370892\n",
            "Epoch #2. Accuracy on batch 213 on Training is 29.395443925233646\n",
            "Epoch #2. Accuracy on batch 214 on Training is 29.41860465116279\n",
            "Epoch #2. Accuracy on batch 215 on Training is 29.441550925925927\n",
            "Epoch #2. Accuracy on batch 216 on Training is 29.536290322580644\n",
            "Epoch #2. Accuracy on batch 217 on Training is 29.515481651376145\n",
            "Epoch #2. Accuracy on batch 218 on Training is 29.53767123287671\n",
            "Epoch #2. Accuracy on batch 219 on Training is 29.517045454545453\n",
            "Batch Id 220 is having training loss of 2764.433349609375\n",
            "15.80090045928955\n",
            "Epoch #2. Accuracy on batch 220 on Training is 29.55316742081448\n",
            "Epoch #2. Accuracy on batch 221 on Training is 29.64527027027027\n",
            "Epoch #2. Accuracy on batch 222 on Training is 29.666479820627803\n",
            "Epoch #2. Accuracy on batch 223 on Training is 29.617745535714285\n",
            "Epoch #2. Accuracy on batch 224 on Training is 29.583333333333332\n",
            "Epoch #2. Accuracy on batch 225 on Training is 29.632190265486727\n",
            "Epoch #2. Accuracy on batch 226 on Training is 29.694383259911895\n",
            "Epoch #2. Accuracy on batch 227 on Training is 29.63267543859649\n",
            "Epoch #2. Accuracy on batch 228 on Training is 29.66703056768559\n",
            "Epoch #2. Accuracy on batch 229 on Training is 29.619565217391305\n",
            "Epoch #2. Accuracy on batch 230 on Training is 29.626623376623378\n",
            "Epoch #2. Accuracy on batch 231 on Training is 29.606681034482758\n",
            "Epoch #2. Accuracy on batch 232 on Training is 29.586909871244636\n",
            "Epoch #2. Accuracy on batch 233 on Training is 29.607371794871796\n",
            "Epoch #2. Accuracy on batch 234 on Training is 29.627659574468087\n",
            "Epoch #2. Accuracy on batch 235 on Training is 29.661016949152543\n",
            "Epoch #2. Accuracy on batch 236 on Training is 29.641350210970465\n",
            "Epoch #2. Accuracy on batch 237 on Training is 29.6218487394958\n",
            "Epoch #2. Accuracy on batch 238 on Training is 29.667887029288703\n",
            "Epoch #2. Accuracy on batch 239 on Training is 29.700520833333332\n",
            "Batch Id 240 is having training loss of 2600.986083984375\n",
            "39.389102935791016\n",
            "Epoch #2. Accuracy on batch 240 on Training is 29.681016597510375\n",
            "Epoch #2. Accuracy on batch 241 on Training is 29.6875\n",
            "Epoch #2. Accuracy on batch 242 on Training is 29.758230452674898\n",
            "Epoch #2. Accuracy on batch 243 on Training is 29.71311475409836\n",
            "Epoch #2. Accuracy on batch 244 on Training is 29.706632653061224\n",
            "Epoch #2. Accuracy on batch 245 on Training is 29.712906504065042\n",
            "Epoch #2. Accuracy on batch 246 on Training is 29.769736842105264\n",
            "Epoch #2. Accuracy on batch 247 on Training is 29.813508064516128\n",
            "Epoch #2. Accuracy on batch 248 on Training is 29.84437751004016\n",
            "Epoch #2. Accuracy on batch 249 on Training is 29.8375\n",
            "Epoch #2. Accuracy on batch 250 on Training is 29.855577689243027\n",
            "Epoch #2. Accuracy on batch 251 on Training is 29.836309523809526\n",
            "Epoch #2. Accuracy on batch 252 on Training is 29.841897233201582\n",
            "Epoch #2. Accuracy on batch 253 on Training is 29.822834645669293\n",
            "Epoch #2. Accuracy on batch 254 on Training is 29.80392156862745\n",
            "Epoch #2. Accuracy on batch 255 on Training is 29.82177734375\n",
            "Epoch #2. Accuracy on batch 256 on Training is 29.766536964980546\n",
            "Epoch #2. Accuracy on batch 257 on Training is 29.796511627906977\n",
            "Epoch #2. Accuracy on batch 258 on Training is 29.72972972972973\n",
            "Epoch #2. Accuracy on batch 259 on Training is 29.771634615384617\n",
            "Batch Id 260 is having training loss of 2536.21923828125\n",
            "174.41990661621094\n",
            "Epoch #2. Accuracy on batch 260 on Training is 29.705459770114942\n",
            "Epoch #2. Accuracy on batch 261 on Training is 29.71135496183206\n",
            "Epoch #2. Accuracy on batch 262 on Training is 29.74096958174905\n",
            "Epoch #2. Accuracy on batch 263 on Training is 29.69933712121212\n",
            "Epoch #2. Accuracy on batch 264 on Training is 29.71698113207547\n",
            "Epoch #2. Accuracy on batch 265 on Training is 29.6875\n",
            "Epoch #2. Accuracy on batch 266 on Training is 29.66994382022472\n",
            "Epoch #2. Accuracy on batch 267 on Training is 29.66417910447761\n",
            "Epoch #2. Accuracy on batch 268 on Training is 29.681691449814128\n",
            "Epoch #2. Accuracy on batch 269 on Training is 29.675925925925927\n",
            "Epoch #2. Accuracy on batch 270 on Training is 29.62407749077491\n",
            "Epoch #2. Accuracy on batch 271 on Training is 29.630055147058822\n",
            "Epoch #2. Accuracy on batch 272 on Training is 29.63598901098901\n",
            "Epoch #2. Accuracy on batch 273 on Training is 29.641879562043794\n",
            "Epoch #2. Accuracy on batch 274 on Training is 29.602272727272727\n",
            "Epoch #2. Accuracy on batch 275 on Training is 29.57427536231884\n",
            "Epoch #2. Accuracy on batch 276 on Training is 29.53519855595668\n",
            "Epoch #2. Accuracy on batch 277 on Training is 29.51888489208633\n",
            "Epoch #2. Accuracy on batch 278 on Training is 29.51388888888889\n",
            "Epoch #2. Accuracy on batch 279 on Training is 29.453125\n",
            "Batch Id 280 is having training loss of 2435.76220703125\n",
            "2115.7626953125\n",
            "Epoch #2. Accuracy on batch 280 on Training is 29.448398576512457\n",
            "Epoch #2. Accuracy on batch 281 on Training is 29.43262411347518\n",
            "Epoch #2. Accuracy on batch 282 on Training is 29.450088339222614\n",
            "Epoch #2. Accuracy on batch 283 on Training is 29.467429577464788\n",
            "Epoch #2. Accuracy on batch 284 on Training is 29.407894736842106\n",
            "Epoch #2. Accuracy on batch 285 on Training is 29.40340909090909\n",
            "Epoch #2. Accuracy on batch 286 on Training is 29.398954703832754\n",
            "Epoch #2. Accuracy on batch 287 on Training is 29.41623263888889\n",
            "Epoch #2. Accuracy on batch 288 on Training is 29.487456747404845\n",
            "Epoch #2. Accuracy on batch 289 on Training is 29.461206896551722\n",
            "Epoch #2. Accuracy on batch 290 on Training is 29.467353951890033\n",
            "Epoch #2. Accuracy on batch 291 on Training is 29.473458904109588\n",
            "Epoch #2. Accuracy on batch 292 on Training is 29.50085324232082\n",
            "Epoch #2. Accuracy on batch 293 on Training is 29.474914965986393\n",
            "Epoch #2. Accuracy on batch 294 on Training is 29.52330508474576\n",
            "Epoch #2. Accuracy on batch 295 on Training is 29.50802364864865\n",
            "Epoch #2. Accuracy on batch 296 on Training is 29.492845117845118\n",
            "Epoch #2. Accuracy on batch 297 on Training is 29.488255033557046\n",
            "Epoch #2. Accuracy on batch 298 on Training is 29.441889632107024\n",
            "Epoch #2. Accuracy on batch 299 on Training is 29.458333333333332\n",
            "Batch Id 300 is having training loss of 2367.61376953125\n",
            "24.090694427490234\n",
            "Epoch #2. Accuracy on batch 300 on Training is 29.433139534883722\n",
            "Epoch #2. Accuracy on batch 301 on Training is 29.428807947019866\n",
            "Epoch #2. Accuracy on batch 302 on Training is 29.414191419141915\n",
            "Epoch #2. Accuracy on batch 303 on Training is 29.38939144736842\n",
            "Epoch #2. Accuracy on batch 304 on Training is 29.364754098360656\n",
            "Epoch #2. Accuracy on batch 305 on Training is 29.37091503267974\n",
            "Epoch #2. Accuracy on batch 306 on Training is 29.346498371335503\n",
            "Epoch #2. Accuracy on batch 307 on Training is 29.37297077922078\n",
            "Epoch #2. Accuracy on batch 308 on Training is 29.38915857605178\n",
            "Epoch #2. Accuracy on batch 309 on Training is 29.385080645161292\n",
            "Epoch #2. Accuracy on batch 310 on Training is 29.381028938906752\n",
            "Epoch #2. Accuracy on batch 311 on Training is 29.397035256410255\n",
            "Epoch #2. Accuracy on batch 312 on Training is 29.373003194888177\n",
            "Epoch #2. Accuracy on batch 313 on Training is 29.349124203821656\n",
            "Epoch #2. Accuracy on batch 314 on Training is 29.365079365079364\n",
            "Epoch #2. Accuracy on batch 315 on Training is 29.341376582278482\n",
            "Epoch #2. Accuracy on batch 316 on Training is 29.337539432176655\n",
            "Epoch #2. Accuracy on batch 317 on Training is 29.30424528301887\n",
            "Epoch #2. Accuracy on batch 318 on Training is 29.32014106583072\n",
            "Epoch #2. Accuracy on batch 319 on Training is 29.3359375\n",
            "Batch Id 320 is having training loss of 2522.6396484375\n",
            "32.325199127197266\n",
            "Epoch #2. Accuracy on batch 320 on Training is 29.322429906542055\n",
            "Epoch #2. Accuracy on batch 321 on Training is 29.309006211180126\n",
            "Epoch #2. Accuracy on batch 322 on Training is 29.305340557275542\n",
            "Epoch #2. Accuracy on batch 323 on Training is 29.301697530864196\n",
            "Epoch #2. Accuracy on batch 324 on Training is 29.298076923076923\n",
            "Epoch #2. Accuracy on batch 325 on Training is 29.29447852760736\n",
            "Epoch #2. Accuracy on batch 326 on Training is 29.30045871559633\n",
            "Epoch #2. Accuracy on batch 327 on Training is 29.334984756097562\n",
            "Epoch #2. Accuracy on batch 328 on Training is 29.35030395136778\n",
            "Epoch #2. Accuracy on batch 329 on Training is 29.393939393939394\n",
            "Epoch #2. Accuracy on batch 330 on Training is 29.399546827794563\n",
            "Epoch #2. Accuracy on batch 331 on Training is 29.40512048192771\n",
            "Epoch #2. Accuracy on batch 332 on Training is 29.420045045045047\n",
            "Epoch #2. Accuracy on batch 333 on Training is 29.434880239520957\n",
            "Epoch #2. Accuracy on batch 334 on Training is 29.41231343283582\n",
            "Epoch #2. Accuracy on batch 335 on Training is 29.427083333333332\n",
            "Epoch #2. Accuracy on batch 336 on Training is 29.441765578635014\n",
            "Epoch #2. Accuracy on batch 337 on Training is 29.447115384615383\n",
            "Epoch #2. Accuracy on batch 338 on Training is 29.52617994100295\n",
            "Epoch #2. Accuracy on batch 339 on Training is 29.549632352941178\n",
            "Batch Id 340 is having training loss of 2516.351318359375\n",
            "9750.326171875\n",
            "Epoch #2. Accuracy on batch 340 on Training is 29.517961876832846\n",
            "Epoch #2. Accuracy on batch 341 on Training is 29.51388888888889\n",
            "Epoch #2. Accuracy on batch 342 on Training is 29.518950437317784\n",
            "Epoch #2. Accuracy on batch 343 on Training is 29.523982558139537\n",
            "Epoch #2. Accuracy on batch 344 on Training is 29.565217391304348\n",
            "Epoch #2. Accuracy on batch 345 on Training is 29.561054913294797\n",
            "Epoch #2. Accuracy on batch 346 on Training is 29.56592219020173\n",
            "Epoch #2. Accuracy on batch 347 on Training is 29.597701149425287\n",
            "Epoch #2. Accuracy on batch 348 on Training is 29.611389684813755\n",
            "Epoch #2. Accuracy on batch 349 on Training is 29.571428571428573\n",
            "Epoch #2. Accuracy on batch 350 on Training is 29.594017094017094\n",
            "Epoch #2. Accuracy on batch 351 on Training is 29.625355113636363\n",
            "Epoch #2. Accuracy on batch 352 on Training is 29.629957507082153\n",
            "Epoch #2. Accuracy on batch 353 on Training is 29.625706214689266\n",
            "Epoch #2. Accuracy on batch 354 on Training is 29.60387323943662\n",
            "Epoch #2. Accuracy on batch 355 on Training is 29.582162921348313\n",
            "Epoch #2. Accuracy on batch 356 on Training is 29.578081232493\n",
            "Epoch #2. Accuracy on batch 357 on Training is 29.600209497206706\n",
            "Epoch #2. Accuracy on batch 358 on Training is 29.61350974930362\n",
            "Epoch #2. Accuracy on batch 359 on Training is 29.609375\n",
            "Batch Id 360 is having training loss of 2633.41162109375\n",
            "85.57528686523438\n",
            "Epoch #2. Accuracy on batch 360 on Training is 29.570637119113574\n",
            "Epoch #2. Accuracy on batch 361 on Training is 29.609806629834253\n",
            "Epoch #2. Accuracy on batch 362 on Training is 29.59710743801653\n",
            "Epoch #2. Accuracy on batch 363 on Training is 29.627403846153847\n",
            "Epoch #2. Accuracy on batch 364 on Training is 29.61472602739726\n",
            "Epoch #2. Accuracy on batch 365 on Training is 29.6021174863388\n",
            "Epoch #2. Accuracy on batch 366 on Training is 29.632152588555858\n",
            "Epoch #2. Accuracy on batch 367 on Training is 29.56861413043478\n",
            "Epoch #2. Accuracy on batch 368 on Training is 29.573170731707318\n",
            "Epoch #2. Accuracy on batch 369 on Training is 29.60304054054054\n",
            "Epoch #2. Accuracy on batch 370 on Training is 29.59063342318059\n",
            "Epoch #2. Accuracy on batch 371 on Training is 29.578293010752688\n",
            "Epoch #2. Accuracy on batch 372 on Training is 29.55764075067024\n",
            "Epoch #2. Accuracy on batch 373 on Training is 29.578877005347593\n",
            "Epoch #2. Accuracy on batch 374 on Training is 29.608333333333334\n",
            "Epoch #2. Accuracy on batch 375 on Training is 29.596077127659573\n",
            "Epoch #2. Accuracy on batch 376 on Training is 29.625331564986737\n",
            "Epoch #2. Accuracy on batch 377 on Training is 29.637896825396826\n",
            "Epoch #2. Accuracy on batch 378 on Training is 29.62565963060686\n",
            "Epoch #2. Accuracy on batch 379 on Training is 29.62171052631579\n",
            "Batch Id 380 is having training loss of 2505.447998046875\n",
            "18.72078514099121\n",
            "Epoch #2. Accuracy on batch 380 on Training is 29.625984251968504\n",
            "Epoch #2. Accuracy on batch 381 on Training is 29.61387434554974\n",
            "Epoch #2. Accuracy on batch 382 on Training is 29.650783289817234\n",
            "Epoch #2. Accuracy on batch 383 on Training is 29.654947916666668\n",
            "Epoch #2. Accuracy on batch 384 on Training is 29.667207792207794\n",
            "Epoch #2. Accuracy on batch 385 on Training is 29.70369170984456\n",
            "Epoch #2. Accuracy on batch 386 on Training is 29.683462532299743\n",
            "Epoch #2. Accuracy on batch 387 on Training is 29.67139175257732\n",
            "Epoch #2. Accuracy on batch 388 on Training is 29.675449871465297\n",
            "Epoch #2. Accuracy on batch 389 on Training is 29.67948717948718\n",
            "Epoch #2. Accuracy on batch 390 on Training is 29.65153452685422\n",
            "Epoch #2. Accuracy on batch 391 on Training is 29.67155612244898\n",
            "Epoch #2. Accuracy on batch 392 on Training is 29.68352417302799\n",
            "Epoch #2. Accuracy on batch 393 on Training is 29.711294416243653\n",
            "Epoch #2. Accuracy on batch 394 on Training is 29.707278481012658\n",
            "Epoch #2. Accuracy on batch 395 on Training is 29.7427398989899\n",
            "Epoch #2. Accuracy on batch 396 on Training is 29.778022670025187\n",
            "Epoch #2. Accuracy on batch 397 on Training is 29.797424623115578\n",
            "Epoch #2. Accuracy on batch 398 on Training is 29.793233082706767\n",
            "Epoch #2. Accuracy on batch 399 on Training is 29.8203125\n",
            "Batch Id 400 is having training loss of 2384.715087890625\n",
            "24.661508560180664\n",
            "Epoch #2. Accuracy on batch 400 on Training is 29.831670822942645\n",
            "Epoch #2. Accuracy on batch 401 on Training is 29.874067164179106\n",
            "Epoch #2. Accuracy on batch 402 on Training is 29.846464019851116\n",
            "Epoch #2. Accuracy on batch 403 on Training is 29.84993811881188\n",
            "Epoch #2. Accuracy on batch 404 on Training is 29.853395061728396\n",
            "Epoch #2. Accuracy on batch 405 on Training is 29.849137931034484\n",
            "Epoch #2. Accuracy on batch 406 on Training is 29.852579852579854\n",
            "Epoch #2. Accuracy on batch 407 on Training is 29.863664215686274\n",
            "Epoch #2. Accuracy on batch 408 on Training is 29.85177261613692\n",
            "Epoch #2. Accuracy on batch 409 on Training is 29.86280487804878\n",
            "Epoch #2. Accuracy on batch 410 on Training is 29.850973236009732\n",
            "Epoch #2. Accuracy on batch 411 on Training is 29.87712378640777\n",
            "Epoch #2. Accuracy on batch 412 on Training is 29.850181598062953\n",
            "Epoch #2. Accuracy on batch 413 on Training is 29.83846618357488\n",
            "Epoch #2. Accuracy on batch 414 on Training is 29.826807228915662\n",
            "Epoch #2. Accuracy on batch 415 on Training is 29.837740384615383\n",
            "Epoch #2. Accuracy on batch 416 on Training is 29.83363309352518\n",
            "Epoch #2. Accuracy on batch 417 on Training is 29.829545454545453\n",
            "Epoch #2. Accuracy on batch 418 on Training is 29.855310262529834\n",
            "Epoch #2. Accuracy on batch 419 on Training is 29.813988095238095\n",
            "Batch Id 420 is having training loss of 2287.904296875\n",
            "20.551118850708008\n",
            "Epoch #2. Accuracy on batch 420 on Training is 29.90647268408551\n",
            "Epoch #2. Accuracy on batch 421 on Training is 29.902251184834125\n",
            "Epoch #2. Accuracy on batch 422 on Training is 29.883274231678488\n",
            "Epoch #2. Accuracy on batch 423 on Training is 29.90123820754717\n",
            "Epoch #2. Accuracy on batch 424 on Training is 29.875\n",
            "Epoch #2. Accuracy on batch 425 on Training is 29.856220657276996\n",
            "Epoch #2. Accuracy on batch 426 on Training is 29.852166276346605\n",
            "Epoch #2. Accuracy on batch 427 on Training is 29.855432242990656\n",
            "Epoch #2. Accuracy on batch 428 on Training is 29.873251748251747\n",
            "Epoch #2. Accuracy on batch 429 on Training is 29.8546511627907\n",
            "Epoch #2. Accuracy on batch 430 on Training is 29.8868909512761\n",
            "Epoch #2. Accuracy on batch 431 on Training is 29.86834490740741\n",
            "Epoch #2. Accuracy on batch 432 on Training is 29.87875288683603\n",
            "Epoch #2. Accuracy on batch 433 on Training is 29.87471198156682\n",
            "Epoch #2. Accuracy on batch 434 on Training is 29.849137931034484\n",
            "Epoch #2. Accuracy on batch 435 on Training is 29.82368119266055\n",
            "Epoch #2. Accuracy on batch 436 on Training is 29.834096109839816\n",
            "Epoch #2. Accuracy on batch 437 on Training is 29.85159817351598\n",
            "Epoch #2. Accuracy on batch 438 on Training is 29.854783599088837\n",
            "Epoch #2. Accuracy on batch 439 on Training is 29.857954545454547\n",
            "Batch Id 440 is having training loss of 2190.134033203125\n",
            "17.67715072631836\n",
            "Epoch #2. Accuracy on batch 440 on Training is 29.889455782312925\n",
            "Epoch #2. Accuracy on batch 441 on Training is 29.885463800904976\n",
            "Epoch #2. Accuracy on batch 442 on Training is 29.881489841986458\n",
            "Epoch #2. Accuracy on batch 443 on Training is 29.877533783783782\n",
            "Epoch #2. Accuracy on batch 444 on Training is 29.901685393258425\n",
            "Epoch #2. Accuracy on batch 445 on Training is 29.89770179372197\n",
            "Epoch #2. Accuracy on batch 446 on Training is 29.90771812080537\n",
            "Epoch #2. Accuracy on batch 447 on Training is 29.910714285714285\n",
            "Epoch #2. Accuracy on batch 448 on Training is 29.899777282850778\n",
            "Epoch #2. Accuracy on batch 449 on Training is 29.895833333333332\n",
            "Epoch #2. Accuracy on batch 450 on Training is 29.884977827051\n",
            "Epoch #2. Accuracy on batch 451 on Training is 29.88799778761062\n",
            "Epoch #2. Accuracy on batch 452 on Training is 29.91169977924945\n",
            "Epoch #2. Accuracy on batch 453 on Training is 29.9284140969163\n",
            "Epoch #2. Accuracy on batch 454 on Training is 29.88324175824176\n",
            "Epoch #2. Accuracy on batch 455 on Training is 29.899945175438596\n",
            "Epoch #2. Accuracy on batch 456 on Training is 29.889223194748357\n",
            "Epoch #2. Accuracy on batch 457 on Training is 29.871724890829693\n",
            "Epoch #2. Accuracy on batch 458 on Training is 29.85430283224401\n",
            "Epoch #2. Accuracy on batch 459 on Training is 29.816576086956523\n",
            "Batch Id 460 is having training loss of 2165.986328125\n",
            "180.35812377929688\n",
            "Epoch #2. Accuracy on batch 460 on Training is 29.79934924078091\n",
            "Epoch #2. Accuracy on batch 461 on Training is 29.822781385281385\n",
            "Epoch #2. Accuracy on batch 462 on Training is 29.832613390928724\n",
            "Epoch #2. Accuracy on batch 463 on Training is 29.849137931034484\n",
            "Epoch #2. Accuracy on batch 464 on Training is 29.8252688172043\n",
            "Epoch #2. Accuracy on batch 465 on Training is 29.80820815450644\n",
            "Epoch #2. Accuracy on batch 466 on Training is 29.804603854389722\n",
            "Epoch #2. Accuracy on batch 467 on Training is 29.807692307692307\n",
            "Epoch #2. Accuracy on batch 468 on Training is 29.817430703624733\n",
            "Epoch #2. Accuracy on batch 469 on Training is 29.793882978723403\n",
            "Epoch #2. Accuracy on batch 470 on Training is 29.8036093418259\n",
            "Epoch #2. Accuracy on batch 471 on Training is 29.813294491525422\n",
            "Epoch #2. Accuracy on batch 472 on Training is 29.796511627906977\n",
            "Epoch #2. Accuracy on batch 473 on Training is 29.81935654008439\n",
            "Epoch #2. Accuracy on batch 474 on Training is 29.80921052631579\n",
            "Epoch #2. Accuracy on batch 475 on Training is 29.805672268907564\n",
            "Epoch #2. Accuracy on batch 476 on Training is 29.808700209643607\n",
            "Epoch #2. Accuracy on batch 477 on Training is 29.805177824267783\n",
            "Epoch #2. Accuracy on batch 478 on Training is 29.80819415448852\n",
            "Epoch #2. Accuracy on batch 479 on Training is 29.811197916666668\n",
            "Batch Id 480 is having training loss of 2108.787353515625\n",
            "86.1690902709961\n",
            "Epoch #2. Accuracy on batch 480 on Training is 29.81418918918919\n",
            "Epoch #2. Accuracy on batch 481 on Training is 29.823651452282157\n",
            "Epoch #2. Accuracy on batch 482 on Training is 29.82013457556936\n",
            "Epoch #2. Accuracy on batch 483 on Training is 29.803719008264462\n",
            "Epoch #2. Accuracy on batch 484 on Training is 29.838917525773194\n",
            "Epoch #2. Accuracy on batch 485 on Training is 29.828960905349795\n",
            "Epoch #2. Accuracy on batch 486 on Training is 29.857546201232033\n",
            "Epoch #2. Accuracy on batch 487 on Training is 29.860399590163933\n",
            "Epoch #2. Accuracy on batch 488 on Training is 29.863241308793455\n",
            "Epoch #2. Accuracy on batch 489 on Training is 29.85969387755102\n",
            "Epoch #2. Accuracy on batch 490 on Training is 29.843431771894092\n",
            "Epoch #2. Accuracy on batch 491 on Training is 29.839939024390244\n",
            "Epoch #2. Accuracy on batch 492 on Training is 29.86815415821501\n",
            "Epoch #2. Accuracy on batch 493 on Training is 29.845647773279353\n",
            "Epoch #2. Accuracy on batch 494 on Training is 29.842171717171716\n",
            "Epoch #2. Accuracy on batch 495 on Training is 29.819808467741936\n",
            "Epoch #2. Accuracy on batch 496 on Training is 29.803822937625753\n",
            "Epoch #2. Accuracy on batch 497 on Training is 29.82555220883534\n",
            "Epoch #2. Accuracy on batch 498 on Training is 29.815881763527056\n",
            "Epoch #2. Accuracy on batch 499 on Training is 29.8125\n",
            "Batch Id 500 is having training loss of 2082.15380859375\n",
            "21.217628479003906\n",
            "Epoch #2. Accuracy on batch 500 on Training is 29.815369261477045\n",
            "Epoch #2. Accuracy on batch 501 on Training is 29.799551792828684\n",
            "Epoch #2. Accuracy on batch 502 on Training is 29.7713717693837\n",
            "Epoch #2. Accuracy on batch 503 on Training is 29.768105158730158\n",
            "Epoch #2. Accuracy on batch 504 on Training is 29.764851485148515\n",
            "Epoch #2. Accuracy on batch 505 on Training is 29.761610671936758\n",
            "Epoch #2. Accuracy on batch 506 on Training is 29.75838264299803\n",
            "Epoch #2. Accuracy on batch 507 on Training is 29.755167322834644\n",
            "Epoch #2. Accuracy on batch 508 on Training is 29.79494106090373\n",
            "Epoch #2. Accuracy on batch 509 on Training is 29.77328431372549\n",
            "Epoch #2. Accuracy on batch 510 on Training is 29.776174168297455\n",
            "Epoch #2. Accuracy on batch 511 on Training is 29.791259765625\n",
            "Epoch #2. Accuracy on batch 512 on Training is 29.794103313840157\n",
            "Epoch #2. Accuracy on batch 513 on Training is 29.790856031128406\n",
            "Epoch #2. Accuracy on batch 514 on Training is 29.775485436893202\n",
            "Epoch #2. Accuracy on batch 515 on Training is 29.772286821705425\n",
            "Epoch #2. Accuracy on batch 516 on Training is 29.76305609284333\n",
            "Epoch #2. Accuracy on batch 517 on Training is 29.77799227799228\n",
            "Epoch #2. Accuracy on batch 518 on Training is 29.80491329479769\n",
            "Epoch #2. Accuracy on batch 519 on Training is 29.813701923076923\n",
            "Batch Id 520 is having training loss of 2008.3443603515625\n",
            "2091.16748046875\n",
            "Epoch #2. Accuracy on batch 520 on Training is 29.822456813819578\n",
            "Epoch #2. Accuracy on batch 521 on Training is 29.807231800766285\n",
            "Epoch #2. Accuracy on batch 522 on Training is 29.79206500956023\n",
            "Epoch #2. Accuracy on batch 523 on Training is 29.759064885496183\n",
            "Epoch #2. Accuracy on batch 524 on Training is 29.75\n",
            "Epoch #2. Accuracy on batch 525 on Training is 29.735028517110266\n",
            "Epoch #2. Accuracy on batch 526 on Training is 29.76162239089184\n",
            "Epoch #2. Accuracy on batch 527 on Training is 29.746685606060606\n",
            "Epoch #2. Accuracy on batch 528 on Training is 29.74952741020794\n",
            "Epoch #2. Accuracy on batch 529 on Training is 29.75235849056604\n",
            "Epoch #2. Accuracy on batch 530 on Training is 29.77283427495292\n",
            "Epoch #2. Accuracy on batch 531 on Training is 29.78735902255639\n",
            "Epoch #2. Accuracy on batch 532 on Training is 29.790103189493433\n",
            "Epoch #2. Accuracy on batch 533 on Training is 29.786985018726593\n",
            "Epoch #2. Accuracy on batch 534 on Training is 29.748831775700936\n",
            "Epoch #2. Accuracy on batch 535 on Training is 29.74580223880597\n",
            "Epoch #2. Accuracy on batch 536 on Training is 29.736964618249534\n",
            "Epoch #2. Accuracy on batch 537 on Training is 29.722351301115243\n",
            "Epoch #2. Accuracy on batch 538 on Training is 29.759972170686456\n",
            "Epoch #2. Accuracy on batch 539 on Training is 29.774305555555557\n",
            "Batch Id 540 is having training loss of 1955.0870361328125\n",
            "49.816650390625\n",
            "Epoch #2. Accuracy on batch 540 on Training is 29.777033271719038\n",
            "Epoch #2. Accuracy on batch 541 on Training is 29.773985239852397\n",
            "Epoch #2. Accuracy on batch 542 on Training is 29.78245856353591\n",
            "Epoch #2. Accuracy on batch 543 on Training is 29.80238970588235\n",
            "Epoch #2. Accuracy on batch 544 on Training is 29.81651376146789\n",
            "Epoch #2. Accuracy on batch 545 on Training is 29.819139194139193\n",
            "Epoch #2. Accuracy on batch 546 on Training is 29.810329067641682\n",
            "Epoch #2. Accuracy on batch 547 on Training is 29.835766423357665\n",
            "Epoch #2. Accuracy on batch 548 on Training is 29.832650273224044\n",
            "Epoch #2. Accuracy on batch 549 on Training is 29.829545454545453\n",
            "Epoch #2. Accuracy on batch 550 on Training is 29.826451905626133\n",
            "Epoch #2. Accuracy on batch 551 on Training is 29.817708333333332\n",
            "Epoch #2. Accuracy on batch 552 on Training is 29.825949367088608\n",
            "Epoch #2. Accuracy on batch 553 on Training is 29.83980144404332\n",
            "Epoch #2. Accuracy on batch 554 on Training is 29.847972972972972\n",
            "Epoch #2. Accuracy on batch 555 on Training is 29.8392535971223\n",
            "Epoch #2. Accuracy on batch 556 on Training is 29.84178635547576\n",
            "Epoch #2. Accuracy on batch 557 on Training is 29.838709677419356\n",
            "Epoch #2. Accuracy on batch 558 on Training is 29.8412343470483\n",
            "Epoch #2. Accuracy on batch 559 on Training is 29.860491071428573\n",
            "Batch Id 560 is having training loss of 1983.28076171875\n",
            "396.6231994628906\n",
            "Epoch #2. Accuracy on batch 560 on Training is 29.851827094474153\n",
            "Epoch #2. Accuracy on batch 561 on Training is 29.848754448398576\n",
            "Epoch #2. Accuracy on batch 562 on Training is 29.851243339253998\n",
            "Epoch #2. Accuracy on batch 563 on Training is 29.848182624113477\n",
            "Epoch #2. Accuracy on batch 564 on Training is 29.878318584070797\n",
            "Epoch #2. Accuracy on batch 565 on Training is 29.86969964664311\n",
            "Epoch #2. Accuracy on batch 566 on Training is 29.86111111111111\n",
            "Epoch #2. Accuracy on batch 567 on Training is 29.880061619718308\n",
            "Epoch #2. Accuracy on batch 568 on Training is 29.876977152899823\n",
            "Epoch #2. Accuracy on batch 569 on Training is 29.895833333333332\n",
            "Epoch #2. Accuracy on batch 570 on Training is 29.90915061295972\n",
            "Epoch #2. Accuracy on batch 571 on Training is 29.90603146853147\n",
            "Epoch #2. Accuracy on batch 572 on Training is 29.897469458987782\n",
            "Epoch #2. Accuracy on batch 573 on Training is 29.910714285714285\n",
            "Epoch #2. Accuracy on batch 574 on Training is 29.907608695652176\n",
            "Epoch #2. Accuracy on batch 575 on Training is 29.90993923611111\n",
            "Epoch #2. Accuracy on batch 576 on Training is 29.917677642980937\n",
            "Epoch #2. Accuracy on batch 577 on Training is 29.914576124567475\n",
            "Epoch #2. Accuracy on batch 578 on Training is 29.93307426597582\n",
            "Epoch #2. Accuracy on batch 579 on Training is 29.929956896551722\n",
            "Batch Id 580 is having training loss of 2041.5755615234375\n",
            "27.368703842163086\n",
            "Epoch #2. Accuracy on batch 580 on Training is 29.93760757314974\n",
            "Epoch #2. Accuracy on batch 581 on Training is 29.929123711340207\n",
            "Epoch #2. Accuracy on batch 582 on Training is 29.909948542024015\n",
            "Epoch #2. Accuracy on batch 583 on Training is 29.92294520547945\n",
            "Epoch #2. Accuracy on batch 584 on Training is 29.925213675213676\n",
            "Epoch #2. Accuracy on batch 585 on Training is 29.938139931740615\n",
            "Epoch #2. Accuracy on batch 586 on Training is 29.94037478705281\n",
            "Epoch #2. Accuracy on batch 587 on Training is 29.916028911564627\n",
            "Epoch #2. Accuracy on batch 588 on Training is 29.93421052631579\n",
            "Epoch #2. Accuracy on batch 589 on Training is 29.9364406779661\n",
            "Epoch #2. Accuracy on batch 590 on Training is 29.938663282571913\n",
            "Epoch #2. Accuracy on batch 591 on Training is 29.96727195945946\n",
            "Epoch #2. Accuracy on batch 592 on Training is 29.97470489038786\n",
            "Epoch #2. Accuracy on batch 593 on Training is 29.95054713804714\n",
            "Epoch #2. Accuracy on batch 594 on Training is 29.94747899159664\n",
            "Epoch #2. Accuracy on batch 595 on Training is 29.97588087248322\n",
            "Epoch #2. Accuracy on batch 596 on Training is 29.978015075376884\n",
            "Epoch #2. Accuracy on batch 597 on Training is 29.99059364548495\n",
            "Epoch #2. Accuracy on batch 598 on Training is 29.997913188647747\n",
            "Epoch #2. Accuracy on batch 599 on Training is 29.989583333333332\n",
            "Batch Id 600 is having training loss of 1974.8095703125\n",
            "6.168489456176758\n",
            "Epoch #2. Accuracy on batch 600 on Training is 29.99688019966722\n",
            "Epoch #2. Accuracy on batch 601 on Training is 29.988579734219268\n",
            "Epoch #2. Accuracy on batch 602 on Training is 29.96475953565506\n",
            "Epoch #2. Accuracy on batch 603 on Training is 29.987582781456954\n",
            "Epoch #2. Accuracy on batch 604 on Training is 30.0\n",
            "Epoch #2. Accuracy on batch 605 on Training is 29.99174917491749\n",
            "Epoch #2. Accuracy on batch 606 on Training is 29.98867380560132\n",
            "Epoch #2. Accuracy on batch 607 on Training is 29.97532894736842\n",
            "Epoch #2. Accuracy on batch 608 on Training is 29.98768472906404\n",
            "Epoch #2. Accuracy on batch 609 on Training is 29.984631147540984\n",
            "Epoch #2. Accuracy on batch 610 on Training is 29.966243862520457\n",
            "Epoch #2. Accuracy on batch 611 on Training is 29.922385620915033\n",
            "Epoch #2. Accuracy on batch 612 on Training is 29.94494290375204\n",
            "Epoch #2. Accuracy on batch 613 on Training is 29.947068403908794\n",
            "Epoch #2. Accuracy on batch 614 on Training is 29.964430894308943\n",
            "Epoch #2. Accuracy on batch 615 on Training is 29.9512987012987\n",
            "Epoch #2. Accuracy on batch 616 on Training is 29.948338735818478\n",
            "Epoch #2. Accuracy on batch 617 on Training is 29.945388349514563\n",
            "Epoch #2. Accuracy on batch 618 on Training is 29.947495961227787\n",
            "Epoch #2. Accuracy on batch 619 on Training is 29.95967741935484\n",
            "Batch Id 620 is having training loss of 1913.712646484375\n",
            "13.764768600463867\n",
            "Epoch #2. Accuracy on batch 620 on Training is 29.961755233494365\n",
            "Epoch #2. Accuracy on batch 621 on Training is 29.95880225080386\n",
            "Epoch #2. Accuracy on batch 622 on Training is 29.95585874799358\n",
            "Epoch #2. Accuracy on batch 623 on Training is 29.95292467948718\n",
            "Epoch #2. Accuracy on batch 624 on Training is 29.91\n",
            "Epoch #2. Accuracy on batch 625 on Training is 29.91214057507987\n",
            "Epoch #2. Accuracy on batch 626 on Training is 29.91427432216906\n",
            "Epoch #2. Accuracy on batch 627 on Training is 29.91142515923567\n",
            "Epoch #2. Accuracy on batch 628 on Training is 29.89864864864865\n",
            "Epoch #2. Accuracy on batch 629 on Training is 29.910714285714285\n",
            "Epoch #2. Accuracy on batch 630 on Training is 29.8979793977813\n",
            "Epoch #2. Accuracy on batch 631 on Training is 29.89517405063291\n",
            "Epoch #2. Accuracy on batch 632 on Training is 29.902251184834125\n",
            "Epoch #2. Accuracy on batch 633 on Training is 29.91423501577287\n",
            "Epoch #2. Accuracy on batch 634 on Training is 29.911417322834644\n",
            "Epoch #2. Accuracy on batch 635 on Training is 29.918435534591193\n",
            "Epoch #2. Accuracy on batch 636 on Training is 29.92052590266876\n",
            "Epoch #2. Accuracy on batch 637 on Training is 29.91771159874608\n",
            "Epoch #2. Accuracy on batch 638 on Training is 29.900234741784036\n",
            "Epoch #2. Accuracy on batch 639 on Training is 29.9072265625\n",
            "Batch Id 640 is having training loss of 1888.0169677734375\n",
            "66.43770599365234\n",
            "Epoch #2. Accuracy on batch 640 on Training is 29.904446177847113\n",
            "Epoch #2. Accuracy on batch 641 on Training is 29.91140965732087\n",
            "Epoch #2. Accuracy on batch 642 on Training is 29.913491446345258\n",
            "Epoch #2. Accuracy on batch 643 on Training is 29.925271739130434\n",
            "Epoch #2. Accuracy on batch 644 on Training is 29.93217054263566\n",
            "Epoch #2. Accuracy on batch 645 on Training is 29.9390479876161\n",
            "Epoch #2. Accuracy on batch 646 on Training is 29.92658423493045\n",
            "Epoch #2. Accuracy on batch 647 on Training is 29.933449074074073\n",
            "Epoch #2. Accuracy on batch 648 on Training is 29.949922958397536\n",
            "Epoch #2. Accuracy on batch 649 on Training is 29.947115384615383\n",
            "Epoch #2. Accuracy on batch 650 on Training is 29.953917050691246\n",
            "Epoch #2. Accuracy on batch 651 on Training is 29.960697852760735\n",
            "Epoch #2. Accuracy on batch 652 on Training is 29.986600306278714\n",
            "Epoch #2. Accuracy on batch 653 on Training is 29.959862385321102\n",
            "Epoch #2. Accuracy on batch 654 on Training is 29.952290076335878\n",
            "Epoch #2. Accuracy on batch 655 on Training is 29.968559451219512\n",
            "Epoch #2. Accuracy on batch 656 on Training is 29.989535768645357\n",
            "Epoch #2. Accuracy on batch 657 on Training is 30.000949848024316\n",
            "Epoch #2. Accuracy on batch 658 on Training is 30.02181335356601\n",
            "Epoch #2. Accuracy on batch 659 on Training is 30.033143939393938\n",
            "Batch Id 660 is having training loss of 1833.818359375\n",
            "38.29391098022461\n",
            "Epoch #2. Accuracy on batch 660 on Training is 30.030257186081695\n",
            "Epoch #2. Accuracy on batch 661 on Training is 30.017938066465256\n",
            "Epoch #2. Accuracy on batch 662 on Training is 30.052790346907994\n",
            "Epoch #2. Accuracy on batch 663 on Training is 30.045180722891565\n",
            "Epoch #2. Accuracy on batch 664 on Training is 30.046992481203006\n",
            "Epoch #2. Accuracy on batch 665 on Training is 30.039414414414413\n",
            "Epoch #2. Accuracy on batch 666 on Training is 30.03185907046477\n",
            "Epoch #2. Accuracy on batch 667 on Training is 30.03368263473054\n",
            "Epoch #2. Accuracy on batch 668 on Training is 30.058856502242154\n",
            "Epoch #2. Accuracy on batch 669 on Training is 30.05597014925373\n",
            "Epoch #2. Accuracy on batch 670 on Training is 30.05774962742176\n",
            "Epoch #2. Accuracy on batch 671 on Training is 30.068824404761905\n",
            "Epoch #2. Accuracy on batch 672 on Training is 30.061292719167906\n",
            "Epoch #2. Accuracy on batch 673 on Training is 30.053783382789316\n",
            "Epoch #2. Accuracy on batch 674 on Training is 30.037037037037038\n",
            "Epoch #2. Accuracy on batch 675 on Training is 30.057322485207102\n",
            "Epoch #2. Accuracy on batch 676 on Training is 30.07754800590842\n",
            "Epoch #2. Accuracy on batch 677 on Training is 30.070058997050147\n",
            "Epoch #2. Accuracy on batch 678 on Training is 30.08560382916053\n",
            "Epoch #2. Accuracy on batch 679 on Training is 30.078125\n",
            "Batch Id 680 is having training loss of 1803.231201171875\n",
            "14892.4091796875\n",
            "Epoch #2. Accuracy on batch 680 on Training is 30.075256975036712\n",
            "Epoch #2. Accuracy on batch 681 on Training is 30.054068914956012\n",
            "Epoch #2. Accuracy on batch 682 on Training is 30.0603953147877\n",
            "Epoch #2. Accuracy on batch 683 on Training is 30.057565789473685\n",
            "Epoch #2. Accuracy on batch 684 on Training is 30.063868613138688\n",
            "Epoch #2. Accuracy on batch 685 on Training is 30.070153061224488\n",
            "Epoch #2. Accuracy on batch 686 on Training is 30.062772925764193\n",
            "Epoch #2. Accuracy on batch 687 on Training is 30.055414244186046\n",
            "Epoch #2. Accuracy on batch 688 on Training is 30.07075471698113\n",
            "Epoch #2. Accuracy on batch 689 on Training is 30.06340579710145\n",
            "Epoch #2. Accuracy on batch 690 on Training is 30.08773516642547\n",
            "Epoch #2. Accuracy on batch 691 on Training is 30.102962427745666\n",
            "Epoch #2. Accuracy on batch 692 on Training is 30.118145743145742\n",
            "Epoch #2. Accuracy on batch 693 on Training is 30.1242795389049\n",
            "Epoch #2. Accuracy on batch 694 on Training is 30.12589928057554\n",
            "Epoch #2. Accuracy on batch 695 on Training is 30.114044540229884\n",
            "Epoch #2. Accuracy on batch 696 on Training is 30.120157819225252\n",
            "Epoch #2. Accuracy on batch 697 on Training is 30.121776504297994\n",
            "Epoch #2. Accuracy on batch 698 on Training is 30.127861230329042\n",
            "Epoch #2. Accuracy on batch 699 on Training is 30.116071428571427\n",
            "Batch Id 700 is having training loss of 1843.03369140625\n",
            "34286.35546875\n",
            "Epoch #2. Accuracy on batch 700 on Training is 30.090941512125536\n",
            "Epoch #2. Accuracy on batch 701 on Training is 30.09259259259259\n",
            "Epoch #2. Accuracy on batch 702 on Training is 30.094238975817923\n",
            "Epoch #2. Accuracy on batch 703 on Training is 30.078125\n",
            "Epoch #2. Accuracy on batch 704 on Training is 30.079787234042552\n",
            "Epoch #2. Accuracy on batch 705 on Training is 30.0814447592068\n",
            "Epoch #2. Accuracy on batch 706 on Training is 30.078677510608205\n",
            "Epoch #2. Accuracy on batch 707 on Training is 30.089159604519775\n",
            "Epoch #2. Accuracy on batch 708 on Training is 30.1040197461213\n",
            "Epoch #2. Accuracy on batch 709 on Training is 30.127640845070424\n",
            "Epoch #2. Accuracy on batch 710 on Training is 30.146800281293952\n",
            "Epoch #2. Accuracy on batch 711 on Training is 30.135182584269664\n",
            "Epoch #2. Accuracy on batch 712 on Training is 30.149894810659188\n",
            "Epoch #2. Accuracy on batch 713 on Training is 30.168942577030812\n",
            "Epoch #2. Accuracy on batch 714 on Training is 30.179195804195803\n",
            "Epoch #2. Accuracy on batch 715 on Training is 30.176326815642458\n",
            "Epoch #2. Accuracy on batch 716 on Training is 30.190899581589957\n",
            "Epoch #2. Accuracy on batch 717 on Training is 30.192374651810585\n",
            "Epoch #2. Accuracy on batch 718 on Training is 30.1721140472879\n",
            "Epoch #2. Accuracy on batch 719 on Training is 30.17361111111111\n",
            "Batch Id 720 is having training loss of 1795.619140625\n",
            "1178.063232421875\n",
            "Epoch #2. Accuracy on batch 720 on Training is 30.170769764216367\n",
            "Epoch #2. Accuracy on batch 721 on Training is 30.185249307479225\n",
            "Epoch #2. Accuracy on batch 722 on Training is 30.191044260027663\n",
            "Epoch #2. Accuracy on batch 723 on Training is 30.20113950276243\n",
            "Epoch #2. Accuracy on batch 724 on Training is 30.21551724137931\n",
            "Epoch #2. Accuracy on batch 725 on Training is 30.22124655647383\n",
            "Epoch #2. Accuracy on batch 726 on Training is 30.231258596973866\n",
            "Epoch #2. Accuracy on batch 727 on Training is 30.25412087912088\n",
            "Epoch #2. Accuracy on batch 728 on Training is 30.251200274348424\n",
            "Epoch #2. Accuracy on batch 729 on Training is 30.248287671232877\n",
            "Epoch #2. Accuracy on batch 730 on Training is 30.245383036935703\n",
            "Epoch #2. Accuracy on batch 731 on Training is 30.255293715846996\n",
            "Epoch #2. Accuracy on batch 732 on Training is 30.265177353342427\n",
            "Epoch #2. Accuracy on batch 733 on Training is 30.266519073569484\n",
            "Epoch #2. Accuracy on batch 734 on Training is 30.272108843537413\n",
            "Epoch #2. Accuracy on batch 735 on Training is 30.277683423913043\n",
            "Epoch #2. Accuracy on batch 736 on Training is 30.295963364993217\n",
            "Epoch #2. Accuracy on batch 737 on Training is 30.309959349593495\n",
            "Epoch #2. Accuracy on batch 738 on Training is 30.29008795669824\n",
            "Epoch #2. Accuracy on batch 739 on Training is 30.28716216216216\n",
            "Batch Id 740 is having training loss of 1749.7620849609375\n",
            "205.36907958984375\n",
            "Epoch #2. Accuracy on batch 740 on Training is 30.28846153846154\n",
            "Epoch #2. Accuracy on batch 741 on Training is 30.298180592991915\n",
            "Epoch #2. Accuracy on batch 742 on Training is 30.28684387617766\n",
            "Epoch #2. Accuracy on batch 743 on Training is 30.288138440860216\n",
            "Epoch #2. Accuracy on batch 744 on Training is 30.27265100671141\n",
            "Epoch #2. Accuracy on batch 745 on Training is 30.269772117962468\n",
            "Epoch #2. Accuracy on batch 746 on Training is 30.287817938420346\n",
            "Epoch #2. Accuracy on batch 747 on Training is 30.289104278074866\n",
            "Epoch #2. Accuracy on batch 748 on Training is 30.28204272363151\n",
            "Epoch #2. Accuracy on batch 749 on Training is 30.2875\n",
            "Epoch #2. Accuracy on batch 750 on Training is 30.280459387483354\n",
            "Epoch #2. Accuracy on batch 751 on Training is 30.269281914893618\n",
            "Epoch #2. Accuracy on batch 752 on Training is 30.266434262948206\n",
            "Epoch #2. Accuracy on batch 753 on Training is 30.242871352785144\n",
            "Epoch #2. Accuracy on batch 754 on Training is 30.23592715231788\n",
            "Epoch #2. Accuracy on batch 755 on Training is 30.245535714285715\n",
            "Epoch #2. Accuracy on batch 756 on Training is 30.23447820343461\n",
            "Epoch #2. Accuracy on batch 757 on Training is 30.248186015831134\n",
            "Epoch #2. Accuracy on batch 758 on Training is 30.261857707509883\n",
            "Epoch #2. Accuracy on batch 759 on Training is 30.263157894736842\n",
            "Batch Id 760 is having training loss of 1948.724853515625\n",
            "14.474992752075195\n",
            "Epoch #2. Accuracy on batch 760 on Training is 30.264454664914584\n",
            "Epoch #2. Accuracy on batch 761 on Training is 30.273950131233597\n",
            "Epoch #2. Accuracy on batch 762 on Training is 30.291612057667102\n",
            "Epoch #2. Accuracy on batch 763 on Training is 30.288776178010473\n",
            "Epoch #2. Accuracy on batch 764 on Training is 30.294117647058822\n",
            "Epoch #2. Accuracy on batch 765 on Training is 30.287206266318538\n",
            "Epoch #2. Accuracy on batch 766 on Training is 30.304758800521512\n",
            "Epoch #2. Accuracy on batch 767 on Training is 30.318196614583332\n",
            "Epoch #2. Accuracy on batch 768 on Training is 30.31128088426528\n",
            "Epoch #2. Accuracy on batch 769 on Training is 30.316558441558442\n",
            "Epoch #2. Accuracy on batch 770 on Training is 30.313715953307394\n",
            "Epoch #2. Accuracy on batch 771 on Training is 30.318976683937823\n",
            "Epoch #2. Accuracy on batch 772 on Training is 30.316138421733505\n",
            "Epoch #2. Accuracy on batch 773 on Training is 30.305232558139537\n",
            "Epoch #2. Accuracy on batch 774 on Training is 30.306451612903224\n",
            "Epoch #2. Accuracy on batch 775 on Training is 30.315721649484537\n",
            "Epoch #2. Accuracy on batch 776 on Training is 30.316924066924066\n",
            "Epoch #2. Accuracy on batch 777 on Training is 30.314106683804628\n",
            "Epoch #2. Accuracy on batch 778 on Training is 30.29525032092426\n",
            "Epoch #2. Accuracy on batch 779 on Training is 30.30849358974359\n",
            "Batch Id 780 is having training loss of 1935.193603515625\n",
            "11.964552879333496\n",
            "Epoch #2. Accuracy on batch 780 on Training is 30.325704225352112\n",
            "Epoch #2. Accuracy on batch 781 on Training is 30.330882352941178\n",
            "Epoch #2. Accuracy on batch 782 on Training is 30.336047254150703\n",
            "Epoch #2. Accuracy on batch 783 on Training is 30.333227040816325\n",
            "Epoch #2. Accuracy on batch 784 on Training is 30.326433121019107\n",
            "Epoch #2. Accuracy on batch 785 on Training is 30.31568066157761\n",
            "Epoch #2. Accuracy on batch 786 on Training is 30.31289707750953\n",
            "Epoch #2. Accuracy on batch 787 on Training is 30.314086294416242\n",
            "Epoch #2. Accuracy on batch 788 on Training is 30.303390367553867\n",
            "Epoch #2. Accuracy on batch 789 on Training is 30.30854430379747\n",
            "Epoch #2. Accuracy on batch 790 on Training is 30.30183312262958\n",
            "Epoch #2. Accuracy on batch 791 on Training is 30.310921717171716\n",
            "Epoch #2. Accuracy on batch 792 on Training is 30.316046658259772\n",
            "Epoch #2. Accuracy on batch 793 on Training is 30.317222921914357\n",
            "Epoch #2. Accuracy on batch 794 on Training is 30.31446540880503\n",
            "Epoch #2. Accuracy on batch 795 on Training is 30.30778894472362\n",
            "Epoch #2. Accuracy on batch 796 on Training is 30.308971141781683\n",
            "Epoch #2. Accuracy on batch 797 on Training is 30.306234335839598\n",
            "Epoch #2. Accuracy on batch 798 on Training is 30.29959324155194\n",
            "Epoch #2. Accuracy on batch 799 on Training is 30.296875\n",
            "Batch Id 800 is having training loss of 1888.0164794921875\n",
            "136.04367065429688\n",
            "Epoch #2. Accuracy on batch 800 on Training is 30.290262172284645\n",
            "Epoch #2. Accuracy on batch 801 on Training is 30.268079800498754\n",
            "Epoch #2. Accuracy on batch 802 on Training is 30.27708592777086\n",
            "Epoch #2. Accuracy on batch 803 on Training is 30.286069651741293\n",
            "Epoch #2. Accuracy on batch 804 on Training is 30.279503105590063\n",
            "Epoch #2. Accuracy on batch 805 on Training is 30.280707196029777\n",
            "Epoch #2. Accuracy on batch 806 on Training is 30.2819083023544\n",
            "Epoch #2. Accuracy on batch 807 on Training is 30.290841584158414\n",
            "Epoch #2. Accuracy on batch 808 on Training is 30.288164400494438\n",
            "Epoch #2. Accuracy on batch 809 on Training is 30.27777777777778\n",
            "Epoch #2. Accuracy on batch 810 on Training is 30.263563501849568\n",
            "Epoch #2. Accuracy on batch 811 on Training is 30.280172413793103\n",
            "Epoch #2. Accuracy on batch 812 on Training is 30.304428044280442\n",
            "Epoch #2. Accuracy on batch 813 on Training is 30.313267813267814\n",
            "Epoch #2. Accuracy on batch 814 on Training is 30.302914110429448\n",
            "Epoch #2. Accuracy on batch 815 on Training is 30.292585784313726\n",
            "Epoch #2. Accuracy on batch 816 on Training is 30.2937576499388\n",
            "Epoch #2. Accuracy on batch 817 on Training is 30.31020782396088\n",
            "Epoch #2. Accuracy on batch 818 on Training is 30.307539682539684\n",
            "Epoch #2. Accuracy on batch 819 on Training is 30.30106707317073\n",
            "Batch Id 820 is having training loss of 1843.5673828125\n",
            "58.571807861328125\n",
            "Epoch #2. Accuracy on batch 820 on Training is 30.30983556638246\n",
            "Epoch #2. Accuracy on batch 821 on Training is 30.31478102189781\n",
            "Epoch #2. Accuracy on batch 822 on Training is 30.304526123936817\n",
            "Epoch #2. Accuracy on batch 823 on Training is 30.30567354368932\n",
            "Epoch #2. Accuracy on batch 824 on Training is 30.291666666666668\n",
            "Epoch #2. Accuracy on batch 825 on Training is 30.285260290556902\n",
            "Epoch #2. Accuracy on batch 826 on Training is 30.278869407496977\n",
            "Epoch #2. Accuracy on batch 827 on Training is 30.268719806763286\n",
            "Epoch #2. Accuracy on batch 828 on Training is 30.27367310012063\n",
            "Epoch #2. Accuracy on batch 829 on Training is 30.271084337349397\n",
            "Epoch #2. Accuracy on batch 830 on Training is 30.26850180505415\n",
            "Epoch #2. Accuracy on batch 831 on Training is 30.262169471153847\n",
            "Epoch #2. Accuracy on batch 832 on Training is 30.267106842737096\n",
            "Epoch #2. Accuracy on batch 833 on Training is 30.26828537170264\n",
            "Epoch #2. Accuracy on batch 834 on Training is 30.26571856287425\n",
            "Epoch #2. Accuracy on batch 835 on Training is 30.248205741626794\n",
            "Epoch #2. Accuracy on batch 836 on Training is 30.23820191158901\n",
            "Epoch #2. Accuracy on batch 837 on Training is 30.250596658711217\n",
            "Epoch #2. Accuracy on batch 838 on Training is 30.266686531585222\n",
            "Epoch #2. Accuracy on batch 839 on Training is 30.264136904761905\n",
            "Batch Id 840 is having training loss of 1935.124755859375\n",
            "19.017845153808594\n",
            "Epoch #2. Accuracy on batch 840 on Training is 30.265309155766943\n",
            "Epoch #2. Accuracy on batch 841 on Training is 30.281324228028502\n",
            "Epoch #2. Accuracy on batch 842 on Training is 30.28988730723606\n",
            "Epoch #2. Accuracy on batch 843 on Training is 30.283619668246445\n",
            "Epoch #2. Accuracy on batch 844 on Training is 30.281065088757398\n",
            "Epoch #2. Accuracy on batch 845 on Training is 30.26743498817967\n",
            "Epoch #2. Accuracy on batch 846 on Training is 30.268595041322314\n",
            "Epoch #2. Accuracy on batch 847 on Training is 30.2844929245283\n",
            "Epoch #2. Accuracy on batch 848 on Training is 30.289310954063605\n",
            "Epoch #2. Accuracy on batch 849 on Training is 30.294117647058822\n",
            "Epoch #2. Accuracy on batch 850 on Training is 30.313601645123384\n",
            "Epoch #2. Accuracy on batch 851 on Training is 30.311032863849764\n",
            "Epoch #2. Accuracy on batch 852 on Training is 30.308470105509965\n",
            "Epoch #2. Accuracy on batch 853 on Training is 30.324209601873537\n",
            "Epoch #2. Accuracy on batch 854 on Training is 30.321637426900583\n",
            "Epoch #2. Accuracy on batch 855 on Training is 30.308119158878505\n",
            "Epoch #2. Accuracy on batch 856 on Training is 30.29098599766628\n",
            "Epoch #2. Accuracy on batch 857 on Training is 30.281177156177158\n",
            "Epoch #2. Accuracy on batch 858 on Training is 30.278667054714784\n",
            "Epoch #2. Accuracy on batch 859 on Training is 30.26889534883721\n",
            "Batch Id 860 is having training loss of 1929.748291015625\n",
            "483.19183349609375\n",
            "Epoch #2. Accuracy on batch 860 on Training is 30.255516840882695\n",
            "Epoch #2. Accuracy on batch 861 on Training is 30.25667053364269\n",
            "Epoch #2. Accuracy on batch 862 on Training is 30.25420046349942\n",
            "Epoch #2. Accuracy on batch 863 on Training is 30.244502314814813\n",
            "Epoch #2. Accuracy on batch 864 on Training is 30.24205202312139\n",
            "Epoch #2. Accuracy on batch 865 on Training is 30.225173210161664\n",
            "Epoch #2. Accuracy on batch 866 on Training is 30.23356401384083\n",
            "Epoch #2. Accuracy on batch 867 on Training is 30.23833525345622\n",
            "Epoch #2. Accuracy on batch 868 on Training is 30.243095512082853\n",
            "Epoch #2. Accuracy on batch 869 on Training is 30.24425287356322\n",
            "Epoch #2. Accuracy on batch 870 on Training is 30.238231917336396\n",
            "Epoch #2. Accuracy on batch 871 on Training is 30.239392201834864\n",
            "Epoch #2. Accuracy on batch 872 on Training is 30.23697021764032\n",
            "Epoch #2. Accuracy on batch 873 on Training is 30.230978260869566\n",
            "Epoch #2. Accuracy on batch 874 on Training is 30.225\n",
            "Epoch #2. Accuracy on batch 875 on Training is 30.219035388127853\n",
            "Epoch #2. Accuracy on batch 876 on Training is 30.238027366020525\n",
            "Epoch #2. Accuracy on batch 877 on Training is 30.2249430523918\n",
            "Epoch #2. Accuracy on batch 878 on Training is 30.204778156996586\n",
            "Epoch #2. Accuracy on batch 879 on Training is 30.209517045454547\n",
            "Batch Id 880 is having training loss of 1889.1488037109375\n",
            "82.190673828125\n",
            "Epoch #2. Accuracy on batch 880 on Training is 30.207150964812712\n",
            "Epoch #2. Accuracy on batch 881 on Training is 30.197704081632654\n",
            "Epoch #2. Accuracy on batch 882 on Training is 30.188278595696488\n",
            "Epoch #2. Accuracy on batch 883 on Training is 30.20008484162896\n",
            "Epoch #2. Accuracy on batch 884 on Training is 30.19774011299435\n",
            "Epoch #2. Accuracy on batch 885 on Training is 30.191873589164786\n",
            "Epoch #2. Accuracy on batch 886 on Training is 30.193066516347237\n",
            "Epoch #2. Accuracy on batch 887 on Training is 30.17314189189189\n",
            "Epoch #2. Accuracy on batch 888 on Training is 30.191929133858267\n",
            "Epoch #2. Accuracy on batch 889 on Training is 30.207162921348313\n",
            "Epoch #2. Accuracy on batch 890 on Training is 30.218855218855218\n",
            "Epoch #2. Accuracy on batch 891 on Training is 30.223514573991032\n",
            "Epoch #2. Accuracy on batch 892 on Training is 30.231662933930572\n",
            "Epoch #2. Accuracy on batch 893 on Training is 30.22581096196868\n",
            "Epoch #2. Accuracy on batch 894 on Training is 30.230446927374302\n",
            "Epoch #2. Accuracy on batch 895 on Training is 30.228097098214285\n",
            "Epoch #2. Accuracy on batch 896 on Training is 30.22923634336678\n",
            "Epoch #2. Accuracy on batch 897 on Training is 30.226893095768375\n",
            "Epoch #2. Accuracy on batch 898 on Training is 30.234983314794217\n",
            "Epoch #2. Accuracy on batch 899 on Training is 30.225694444444443\n",
            "Batch Id 900 is having training loss of 1952.638916015625\n",
            "398.9703369140625\n",
            "Epoch #2. Accuracy on batch 900 on Training is 30.233768035516093\n",
            "Epoch #2. Accuracy on batch 901 on Training is 30.21757206208426\n",
            "Epoch #2. Accuracy on batch 902 on Training is 30.215254706533777\n",
            "Epoch #2. Accuracy on batch 903 on Training is 30.209485619469028\n",
            "Epoch #2. Accuracy on batch 904 on Training is 30.214088397790054\n",
            "Epoch #2. Accuracy on batch 905 on Training is 30.229028697571742\n",
            "Epoch #2. Accuracy on batch 906 on Training is 30.230154355016538\n",
            "Epoch #2. Accuracy on batch 907 on Training is 30.224394273127754\n",
            "Epoch #2. Accuracy on batch 908 on Training is 30.232398239823983\n",
            "Epoch #2. Accuracy on batch 909 on Training is 30.250686813186814\n",
            "Epoch #2. Accuracy on batch 910 on Training is 30.248353457738748\n",
            "Epoch #2. Accuracy on batch 911 on Training is 30.252878289473685\n",
            "Epoch #2. Accuracy on batch 912 on Training is 30.274507119386637\n",
            "Epoch #2. Accuracy on batch 913 on Training is 30.265317286652078\n",
            "Epoch #2. Accuracy on batch 914 on Training is 30.276639344262296\n",
            "Epoch #2. Accuracy on batch 915 on Training is 30.267467248908297\n",
            "Epoch #2. Accuracy on batch 916 on Training is 30.271946564885496\n",
            "Epoch #2. Accuracy on batch 917 on Training is 30.276416122004356\n",
            "Epoch #2. Accuracy on batch 918 on Training is 30.28087595212187\n",
            "Epoch #2. Accuracy on batch 919 on Training is 30.281929347826086\n",
            "Batch Id 920 is having training loss of 1929.1800537109375\n",
            "63.160057067871094\n",
            "Epoch #2. Accuracy on batch 920 on Training is 30.279587404994572\n",
            "Epoch #2. Accuracy on batch 921 on Training is 30.28402928416486\n",
            "Epoch #2. Accuracy on batch 922 on Training is 30.295232936078005\n",
            "Epoch #2. Accuracy on batch 923 on Training is 30.309794372294373\n",
            "Epoch #2. Accuracy on batch 924 on Training is 30.2972972972973\n",
            "Epoch #2. Accuracy on batch 925 on Training is 30.29495140388769\n",
            "Epoch #2. Accuracy on batch 926 on Training is 30.285868392664508\n",
            "Epoch #2. Accuracy on batch 927 on Training is 30.286907327586206\n",
            "Epoch #2. Accuracy on batch 928 on Training is 30.284580193756728\n",
            "Epoch #2. Accuracy on batch 929 on Training is 30.282258064516128\n",
            "Epoch #2. Accuracy on batch 930 on Training is 30.273227712137487\n",
            "Epoch #2. Accuracy on batch 931 on Training is 30.277628755364805\n",
            "Epoch #2. Accuracy on batch 932 on Training is 30.278670953912112\n",
            "Epoch #2. Accuracy on batch 933 on Training is 30.29309421841542\n",
            "Epoch #2. Accuracy on batch 934 on Training is 30.300802139037433\n",
            "Epoch #2. Accuracy on batch 935 on Training is 30.305154914529915\n",
            "Epoch #2. Accuracy on batch 936 on Training is 30.299493062966917\n",
            "Epoch #2. Accuracy on batch 937 on Training is 30.303837953091683\n",
            "Epoch #2. Accuracy on batch 938 on Training is 30.304845580404685\n",
            "Epoch #2. Accuracy on batch 939 on Training is 30.299202127659573\n",
            "Batch Id 940 is having training loss of 1889.824462890625\n",
            "57.63739776611328\n",
            "Epoch #2. Accuracy on batch 940 on Training is 30.293570669500532\n",
            "Epoch #2. Accuracy on batch 941 on Training is 30.30453821656051\n",
            "Epoch #2. Accuracy on batch 942 on Training is 30.318796394485684\n",
            "Epoch #2. Accuracy on batch 943 on Training is 30.329713983050848\n",
            "Epoch #2. Accuracy on batch 944 on Training is 30.31084656084656\n",
            "Epoch #2. Accuracy on batch 945 on Training is 30.315142706131077\n",
            "Epoch #2. Accuracy on batch 946 on Training is 30.31282998944034\n",
            "Epoch #2. Accuracy on batch 947 on Training is 30.313818565400844\n",
            "Epoch #2. Accuracy on batch 948 on Training is 30.31809799789252\n",
            "Epoch #2. Accuracy on batch 949 on Training is 30.3125\n",
            "Epoch #2. Accuracy on batch 950 on Training is 30.323343848580443\n",
            "Epoch #2. Accuracy on batch 951 on Training is 30.327599789915965\n",
            "Epoch #2. Accuracy on batch 952 on Training is 30.32200944386149\n",
            "Epoch #2. Accuracy on batch 953 on Training is 30.316430817610062\n",
            "Epoch #2. Accuracy on batch 954 on Training is 30.31086387434555\n",
            "Epoch #2. Accuracy on batch 955 on Training is 30.315115062761507\n",
            "Epoch #2. Accuracy on batch 956 on Training is 30.31935736677116\n",
            "Epoch #2. Accuracy on batch 957 on Training is 30.31054279749478\n",
            "Epoch #2. Accuracy on batch 958 on Training is 30.308263816475495\n",
            "Epoch #2. Accuracy on batch 959 on Training is 30.296223958333332\n",
            "Batch Id 960 is having training loss of 1956.76025390625\n",
            "27.011018753051758\n",
            "Epoch #2. Accuracy on batch 960 on Training is 30.30697190426639\n",
            "Epoch #2. Accuracy on batch 961 on Training is 30.304703742203742\n",
            "Epoch #2. Accuracy on batch 962 on Training is 30.31217549325026\n",
            "Epoch #2. Accuracy on batch 963 on Training is 30.322873443983404\n",
            "Epoch #2. Accuracy on batch 964 on Training is 30.33678756476684\n",
            "Epoch #2. Accuracy on batch 965 on Training is 30.334497929606624\n",
            "Epoch #2. Accuracy on batch 966 on Training is 30.335444674250258\n",
            "Epoch #2. Accuracy on batch 967 on Training is 30.342846074380166\n",
            "Epoch #2. Accuracy on batch 968 on Training is 30.353457172342623\n",
            "Epoch #2. Accuracy on batch 969 on Training is 30.3479381443299\n",
            "Epoch #2. Accuracy on batch 970 on Training is 30.355303810504633\n",
            "Epoch #2. Accuracy on batch 971 on Training is 30.36908436213992\n",
            "Epoch #2. Accuracy on batch 972 on Training is 30.369989722507707\n",
            "Epoch #2. Accuracy on batch 973 on Training is 30.37410164271047\n",
            "Epoch #2. Accuracy on batch 974 on Training is 30.384615384615383\n",
            "Epoch #2. Accuracy on batch 975 on Training is 30.36308913934426\n",
            "Epoch #2. Accuracy on batch 976 on Training is 30.363996929375638\n",
            "Epoch #2. Accuracy on batch 977 on Training is 30.37129345603272\n",
            "Epoch #2. Accuracy on batch 978 on Training is 30.384959141981614\n",
            "Epoch #2. Accuracy on batch 979 on Training is 30.373086734693878\n",
            "Batch Id 980 is having training loss of 1950.9676513671875\n",
            "776.6882934570312\n",
            "Epoch #2. Accuracy on batch 980 on Training is 30.380351681957187\n",
            "Epoch #2. Accuracy on batch 981 on Training is 30.3780549898167\n",
            "Epoch #2. Accuracy on batch 982 on Training is 30.3853001017294\n",
            "Epoch #2. Accuracy on batch 983 on Training is 30.392530487804876\n",
            "Epoch #2. Accuracy on batch 984 on Training is 30.393401015228427\n",
            "Epoch #2. Accuracy on batch 985 on Training is 30.391100405679513\n",
            "Epoch #2. Accuracy on batch 986 on Training is 30.3951367781155\n",
            "Epoch #2. Accuracy on batch 987 on Training is 30.408653846153847\n",
            "Epoch #2. Accuracy on batch 988 on Training is 30.39370576339737\n",
            "Epoch #2. Accuracy on batch 989 on Training is 30.37878787878788\n",
            "Epoch #2. Accuracy on batch 990 on Training is 30.36074672048436\n",
            "Epoch #2. Accuracy on batch 991 on Training is 30.374243951612904\n",
            "Epoch #2. Accuracy on batch 992 on Training is 30.375125881168177\n",
            "Epoch #2. Accuracy on batch 993 on Training is 30.37286217303823\n",
            "Epoch #2. Accuracy on batch 994 on Training is 30.3643216080402\n",
            "Epoch #2. Accuracy on batch 995 on Training is 30.368348393574298\n",
            "Epoch #2. Accuracy on batch 996 on Training is 30.37236710130391\n",
            "Epoch #2. Accuracy on batch 997 on Training is 30.37324649298597\n",
            "Epoch #2. Accuracy on batch 998 on Training is 30.38350850850851\n",
            "Epoch #2. Accuracy on batch 999 on Training is 30.375\n",
            "Batch Id 1000 is having training loss of 1923.6002197265625\n",
            "3096.780517578125\n",
            "Epoch #2. Accuracy on batch 1000 on Training is 30.37275224775225\n",
            "Epoch #2. Accuracy on batch 1001 on Training is 30.37050898203593\n",
            "Epoch #2. Accuracy on batch 1002 on Training is 30.37450149551346\n",
            "Epoch #2. Accuracy on batch 1003 on Training is 30.366035856573706\n",
            "Epoch #2. Accuracy on batch 1004 on Training is 30.35136815920398\n",
            "Epoch #2. Accuracy on batch 1005 on Training is 30.339835984095426\n",
            "Epoch #2. Accuracy on batch 1006 on Training is 30.34384309831182\n",
            "Epoch #2. Accuracy on batch 1007 on Training is 30.33544146825397\n",
            "Epoch #2. Accuracy on batch 1008 on Training is 30.33325074331021\n",
            "Epoch #2. Accuracy on batch 1009 on Training is 30.331064356435643\n",
            "Epoch #2. Accuracy on batch 1010 on Training is 30.344337289812067\n",
            "Epoch #2. Accuracy on batch 1011 on Training is 30.351408102766797\n",
            "Epoch #2. Accuracy on batch 1012 on Training is 30.358464955577492\n",
            "Epoch #2. Accuracy on batch 1013 on Training is 30.359344181459566\n",
            "Epoch #2. Accuracy on batch 1014 on Training is 30.357142857142858\n",
            "Epoch #2. Accuracy on batch 1015 on Training is 30.345718503937007\n",
            "Epoch #2. Accuracy on batch 1016 on Training is 30.337389380530972\n",
            "Epoch #2. Accuracy on batch 1017 on Training is 30.332146365422396\n",
            "Epoch #2. Accuracy on batch 1018 on Training is 30.33304710500491\n",
            "Epoch #2. Accuracy on batch 1019 on Training is 30.321691176470587\n",
            "Batch Id 1020 is having training loss of 1963.3616943359375\n",
            "18.794626235961914\n",
            "Epoch #2. Accuracy on batch 1020 on Training is 30.334843290891282\n",
            "Epoch #2. Accuracy on batch 1021 on Training is 30.329623287671232\n",
            "Epoch #2. Accuracy on batch 1022 on Training is 30.31524926686217\n",
            "Epoch #2. Accuracy on batch 1023 on Training is 30.3131103515625\n",
            "Epoch #2. Accuracy on batch 1024 on Training is 30.3140243902439\n",
            "Epoch #2. Accuracy on batch 1025 on Training is 30.29666179337232\n",
            "Epoch #2. Accuracy on batch 1026 on Training is 30.291504381694256\n",
            "Epoch #2. Accuracy on batch 1027 on Training is 30.289396887159533\n",
            "Epoch #2. Accuracy on batch 1028 on Training is 30.29944120505345\n",
            "Epoch #2. Accuracy on batch 1029 on Training is 30.300364077669904\n",
            "Epoch #2. Accuracy on batch 1030 on Training is 30.298254122211446\n",
            "Epoch #2. Accuracy on batch 1031 on Training is 30.27797965116279\n",
            "Epoch #2. Accuracy on batch 1032 on Training is 30.27287028073572\n",
            "Epoch #2. Accuracy on batch 1033 on Training is 30.291948742746616\n",
            "Epoch #2. Accuracy on batch 1034 on Training is 30.28985507246377\n",
            "Epoch #2. Accuracy on batch 1035 on Training is 30.287765444015445\n",
            "Epoch #2. Accuracy on batch 1036 on Training is 30.285679845708774\n",
            "Epoch #2. Accuracy on batch 1037 on Training is 30.28660886319846\n",
            "Epoch #2. Accuracy on batch 1038 on Training is 30.27851299326275\n",
            "Epoch #2. Accuracy on batch 1039 on Training is 30.279447115384617\n",
            "Batch Id 1040 is having training loss of 1951.831787109375\n",
            "30.74190330505371\n",
            "Epoch #2. Accuracy on batch 1040 on Training is 30.277377521613833\n",
            "Epoch #2. Accuracy on batch 1041 on Training is 30.281309980806142\n",
            "Epoch #2. Accuracy on batch 1042 on Training is 30.27624640460211\n",
            "Epoch #2. Accuracy on batch 1043 on Training is 30.277179118773947\n",
            "Epoch #2. Accuracy on batch 1044 on Training is 30.266148325358852\n",
            "Epoch #2. Accuracy on batch 1045 on Training is 30.273064053537286\n",
            "Epoch #2. Accuracy on batch 1046 on Training is 30.276981852913085\n",
            "Epoch #2. Accuracy on batch 1047 on Training is 30.280892175572518\n",
            "Epoch #2. Accuracy on batch 1048 on Training is 30.287774070543374\n",
            "Epoch #2. Accuracy on batch 1049 on Training is 30.282738095238095\n",
            "Epoch #2. Accuracy on batch 1050 on Training is 30.298525214081828\n",
            "Epoch #2. Accuracy on batch 1051 on Training is 30.302400190114067\n",
            "Epoch #2. Accuracy on batch 1052 on Training is 30.30330009496676\n",
            "Epoch #2. Accuracy on batch 1053 on Training is 30.313092979127134\n",
            "Epoch #2. Accuracy on batch 1054 on Training is 30.313981042654028\n",
            "Epoch #2. Accuracy on batch 1055 on Training is 30.308948863636363\n",
            "Epoch #2. Accuracy on batch 1056 on Training is 30.327578051087986\n",
            "Epoch #2. Accuracy on batch 1057 on Training is 30.3343572778828\n",
            "Epoch #2. Accuracy on batch 1058 on Training is 30.33817280453258\n",
            "Epoch #2. Accuracy on batch 1059 on Training is 30.33608490566038\n",
            "Batch Id 1060 is having training loss of 1916.921875\n",
            "158.28955078125\n",
            "Epoch #2. Accuracy on batch 1060 on Training is 30.339891611687086\n",
            "Epoch #2. Accuracy on batch 1061 on Training is 30.331920903954803\n",
            "Epoch #2. Accuracy on batch 1062 on Training is 30.326904985888994\n",
            "Epoch #2. Accuracy on batch 1063 on Training is 30.333646616541355\n",
            "Epoch #2. Accuracy on batch 1064 on Training is 30.328638497652584\n",
            "Epoch #2. Accuracy on batch 1065 on Training is 30.323639774859288\n",
            "Epoch #2. Accuracy on batch 1066 on Training is 30.33036551077788\n",
            "Epoch #2. Accuracy on batch 1067 on Training is 30.342930711610485\n",
            "Epoch #2. Accuracy on batch 1068 on Training is 30.355472404115996\n",
            "Epoch #2. Accuracy on batch 1069 on Training is 30.359228971962615\n",
            "Epoch #2. Accuracy on batch 1070 on Training is 30.357142857142858\n",
            "Epoch #2. Accuracy on batch 1071 on Training is 30.357975746268657\n",
            "Epoch #2. Accuracy on batch 1072 on Training is 30.35589468779124\n",
            "Epoch #2. Accuracy on batch 1073 on Training is 30.356727188081937\n",
            "Epoch #2. Accuracy on batch 1074 on Training is 30.3546511627907\n",
            "Epoch #2. Accuracy on batch 1075 on Training is 30.352578996282528\n",
            "Epoch #2. Accuracy on batch 1076 on Training is 30.362116991643454\n",
            "Epoch #2. Accuracy on batch 1077 on Training is 30.351345083487942\n",
            "Epoch #2. Accuracy on batch 1078 on Training is 30.360866543095458\n",
            "Epoch #2. Accuracy on batch 1079 on Training is 30.35011574074074\n",
            "Batch Id 1080 is having training loss of 1895.1024169921875\n",
            "115.64250183105469\n",
            "Epoch #2. Accuracy on batch 1080 on Training is 30.350948196114707\n",
            "Epoch #2. Accuracy on batch 1081 on Training is 30.346002772643253\n",
            "Epoch #2. Accuracy on batch 1082 on Training is 30.338180978762697\n",
            "Epoch #2. Accuracy on batch 1083 on Training is 30.339022140221402\n",
            "Epoch #2. Accuracy on batch 1084 on Training is 30.331221198156683\n",
            "Epoch #2. Accuracy on batch 1085 on Training is 30.334944751381215\n",
            "Epoch #2. Accuracy on batch 1086 on Training is 30.338661453541857\n",
            "Epoch #2. Accuracy on batch 1087 on Training is 30.333754595588236\n",
            "Epoch #2. Accuracy on batch 1088 on Training is 30.33746556473829\n",
            "Epoch #2. Accuracy on batch 1089 on Training is 30.321100917431192\n",
            "Epoch #2. Accuracy on batch 1090 on Training is 30.30763061411549\n",
            "Epoch #2. Accuracy on batch 1091 on Training is 30.31135531135531\n",
            "Epoch #2. Accuracy on batch 1092 on Training is 30.326509606587376\n",
            "Epoch #2. Accuracy on batch 1093 on Training is 30.32735374771481\n",
            "Epoch #2. Accuracy on batch 1094 on Training is 30.328196347031962\n",
            "Epoch #2. Accuracy on batch 1095 on Training is 30.320483576642335\n",
            "Epoch #2. Accuracy on batch 1096 on Training is 30.329876937101186\n",
            "Epoch #2. Accuracy on batch 1097 on Training is 30.319330601092897\n",
            "Epoch #2. Accuracy on batch 1098 on Training is 30.340081892629662\n",
            "Epoch #2. Accuracy on batch 1099 on Training is 30.323863636363637\n",
            "Batch Id 1100 is having training loss of 1942.4813232421875\n",
            "29.190231323242188\n",
            "Epoch #2. Accuracy on batch 1100 on Training is 30.321866485013626\n",
            "Epoch #2. Accuracy on batch 1101 on Training is 30.31987295825771\n",
            "Epoch #2. Accuracy on batch 1102 on Training is 30.317883046237533\n",
            "Epoch #2. Accuracy on batch 1103 on Training is 30.32721920289855\n",
            "Epoch #2. Accuracy on batch 1104 on Training is 30.33371040723982\n",
            "Epoch #2. Accuracy on batch 1105 on Training is 30.32606238698011\n",
            "Epoch #2. Accuracy on batch 1106 on Training is 30.32125112917796\n",
            "Epoch #2. Accuracy on batch 1107 on Training is 30.31644855595668\n",
            "Epoch #2. Accuracy on batch 1108 on Training is 30.306018935978358\n",
            "Epoch #2. Accuracy on batch 1109 on Training is 30.315315315315317\n",
            "Epoch #2. Accuracy on batch 1110 on Training is 30.31053105310531\n",
            "Epoch #2. Accuracy on batch 1111 on Training is 30.311375899280577\n",
            "Epoch #2. Accuracy on batch 1112 on Training is 30.32345013477089\n",
            "Epoch #2. Accuracy on batch 1113 on Training is 30.315866247755835\n",
            "Epoch #2. Accuracy on batch 1114 on Training is 30.32230941704036\n",
            "Epoch #2. Accuracy on batch 1115 on Training is 30.325940860215052\n",
            "Epoch #2. Accuracy on batch 1116 on Training is 30.34075649059982\n",
            "Epoch #2. Accuracy on batch 1117 on Training is 30.33877459749553\n",
            "Epoch #2. Accuracy on batch 1118 on Training is 30.3312109025916\n",
            "Epoch #2. Accuracy on batch 1119 on Training is 30.343191964285715\n",
            "Batch Id 1120 is having training loss of 1909.7120361328125\n",
            "15.817399978637695\n",
            "Epoch #2. Accuracy on batch 1120 on Training is 30.34400089206066\n",
            "Epoch #2. Accuracy on batch 1121 on Training is 30.33645276292335\n",
            "Epoch #2. Accuracy on batch 1122 on Training is 30.326135351736422\n",
            "Epoch #2. Accuracy on batch 1123 on Training is 30.326957295373667\n",
            "Epoch #2. Accuracy on batch 1124 on Training is 30.32777777777778\n",
            "Epoch #2. Accuracy on batch 1125 on Training is 30.339698046181173\n",
            "Epoch #2. Accuracy on batch 1126 on Training is 30.334960070984916\n",
            "Epoch #2. Accuracy on batch 1127 on Training is 30.324689716312058\n",
            "Epoch #2. Accuracy on batch 1128 on Training is 30.32827723649247\n",
            "Epoch #2. Accuracy on batch 1129 on Training is 30.31803097345133\n",
            "Epoch #2. Accuracy on batch 1130 on Training is 30.318854995579134\n",
            "Epoch #2. Accuracy on batch 1131 on Training is 30.32243816254417\n",
            "Epoch #2. Accuracy on batch 1132 on Training is 30.323256840247133\n",
            "Epoch #2. Accuracy on batch 1133 on Training is 30.33234126984127\n",
            "Epoch #2. Accuracy on batch 1134 on Training is 30.3386563876652\n",
            "Epoch #2. Accuracy on batch 1135 on Training is 30.344960387323944\n",
            "Epoch #2. Accuracy on batch 1136 on Training is 30.3457563764292\n",
            "Epoch #2. Accuracy on batch 1137 on Training is 30.332820738137084\n",
            "Epoch #2. Accuracy on batch 1138 on Training is 30.333625987708515\n",
            "Epoch #2. Accuracy on batch 1139 on Training is 30.326206140350877\n",
            "Batch Id 1140 is having training loss of 2049.974609375\n",
            "41.38744354248047\n",
            "Epoch #2. Accuracy on batch 1140 on Training is 30.32427695004382\n",
            "Epoch #2. Accuracy on batch 1141 on Training is 30.316878283712786\n",
            "Epoch #2. Accuracy on batch 1142 on Training is 30.32863079615048\n",
            "Epoch #2. Accuracy on batch 1143 on Training is 30.332167832167833\n",
            "Epoch #2. Accuracy on batch 1144 on Training is 30.322052401746724\n",
            "Epoch #2. Accuracy on batch 1145 on Training is 30.31740837696335\n",
            "Epoch #2. Accuracy on batch 1146 on Training is 30.312772449869225\n",
            "Epoch #2. Accuracy on batch 1147 on Training is 30.297256097560975\n",
            "Epoch #2. Accuracy on batch 1148 on Training is 30.298085291557875\n",
            "Epoch #2. Accuracy on batch 1149 on Training is 30.304347826086957\n",
            "Epoch #2. Accuracy on batch 1150 on Training is 30.31602953953084\n",
            "Epoch #2. Accuracy on batch 1151 on Training is 30.31684027777778\n",
            "Epoch #2. Accuracy on batch 1152 on Training is 30.32307025151778\n",
            "Epoch #2. Accuracy on batch 1153 on Training is 30.33199740034662\n",
            "Epoch #2. Accuracy on batch 1154 on Training is 30.338203463203463\n",
            "Epoch #2. Accuracy on batch 1155 on Training is 30.344398788927336\n",
            "Epoch #2. Accuracy on batch 1156 on Training is 30.33977960242005\n",
            "Epoch #2. Accuracy on batch 1157 on Training is 30.33246977547496\n",
            "Epoch #2. Accuracy on batch 1158 on Training is 30.330565142364108\n",
            "Epoch #2. Accuracy on batch 1159 on Training is 30.33135775862069\n",
            "Batch Id 1160 is having training loss of 2021.1658935546875\n",
            "29.393672943115234\n",
            "Epoch #2. Accuracy on batch 1160 on Training is 30.32676571920758\n",
            "Epoch #2. Accuracy on batch 1161 on Training is 30.338317555938037\n",
            "Epoch #2. Accuracy on batch 1162 on Training is 30.344475494411007\n",
            "Epoch #2. Accuracy on batch 1163 on Training is 30.334514604810998\n",
            "Epoch #2. Accuracy on batch 1164 on Training is 30.324570815450645\n",
            "Epoch #2. Accuracy on batch 1165 on Training is 30.32536449399657\n",
            "Epoch #2. Accuracy on batch 1166 on Training is 30.336868037703514\n",
            "Epoch #2. Accuracy on batch 1167 on Training is 30.337649828767123\n",
            "Epoch #2. Accuracy on batch 1168 on Training is 30.338430282292556\n",
            "Epoch #2. Accuracy on batch 1169 on Training is 30.33653846153846\n",
            "Epoch #2. Accuracy on batch 1170 on Training is 30.339987190435526\n",
            "Epoch #2. Accuracy on batch 1171 on Training is 30.346096416382252\n",
            "Epoch #2. Accuracy on batch 1172 on Training is 30.32821824381927\n",
            "Epoch #2. Accuracy on batch 1173 on Training is 30.31835604770017\n",
            "Epoch #2. Accuracy on batch 1174 on Training is 30.3218085106383\n",
            "Epoch #2. Accuracy on batch 1175 on Training is 30.325255102040817\n",
            "Epoch #2. Accuracy on batch 1176 on Training is 30.336661002548855\n",
            "Epoch #2. Accuracy on batch 1177 on Training is 30.345394736842106\n",
            "Epoch #2. Accuracy on batch 1178 on Training is 30.348812553011026\n",
            "Epoch #2. Accuracy on batch 1179 on Training is 30.34957627118644\n",
            "Batch Id 1180 is having training loss of 2024.51708984375\n",
            "55.489864349365234\n",
            "Epoch #2. Accuracy on batch 1180 on Training is 30.35563082133785\n",
            "Epoch #2. Accuracy on batch 1181 on Training is 30.361675126903553\n",
            "Epoch #2. Accuracy on batch 1182 on Training is 30.36770921386306\n",
            "Epoch #2. Accuracy on batch 1183 on Training is 30.37373310810811\n",
            "Epoch #2. Accuracy on batch 1184 on Training is 30.366561181434598\n",
            "Epoch #2. Accuracy on batch 1185 on Training is 30.362036256323776\n",
            "Epoch #2. Accuracy on batch 1186 on Training is 30.368049705139004\n",
            "Epoch #2. Accuracy on batch 1187 on Training is 30.360900673400675\n",
            "Epoch #2. Accuracy on batch 1188 on Training is 30.359020185029436\n",
            "Epoch #2. Accuracy on batch 1189 on Training is 30.36764705882353\n",
            "Epoch #2. Accuracy on batch 1190 on Training is 30.373635600335852\n",
            "Epoch #2. Accuracy on batch 1191 on Training is 30.37961409395973\n",
            "Epoch #2. Accuracy on batch 1192 on Training is 30.38820201173512\n",
            "Epoch #2. Accuracy on batch 1193 on Training is 30.391541038525965\n",
            "Epoch #2. Accuracy on batch 1194 on Training is 30.39225941422594\n",
            "Epoch #2. Accuracy on batch 1195 on Training is 30.400815217391305\n",
            "Epoch #2. Accuracy on batch 1196 on Training is 30.419799498746865\n",
            "Epoch #2. Accuracy on batch 1197 on Training is 30.42049248747913\n",
            "Epoch #2. Accuracy on batch 1198 on Training is 30.4029399499583\n",
            "Epoch #2. Accuracy on batch 1199 on Training is 30.395833333333332\n",
            "Batch Id 1200 is having training loss of 2027.1636962890625\n",
            "18.566675186157227\n",
            "Epoch #2. Accuracy on batch 1200 on Training is 30.39654454621149\n",
            "Epoch #2. Accuracy on batch 1201 on Training is 30.389455074875208\n",
            "Epoch #2. Accuracy on batch 1202 on Training is 30.379779717373232\n",
            "Epoch #2. Accuracy on batch 1203 on Training is 30.377906976744185\n",
            "Epoch #2. Accuracy on batch 1204 on Training is 30.383817427385893\n",
            "Epoch #2. Accuracy on batch 1205 on Training is 30.379353233830845\n",
            "Epoch #2. Accuracy on batch 1206 on Training is 30.36712924606462\n",
            "Epoch #2. Accuracy on batch 1207 on Training is 30.362686258278146\n",
            "Epoch #2. Accuracy on batch 1208 on Training is 30.35308105872622\n",
            "Epoch #2. Accuracy on batch 1209 on Training is 30.356404958677686\n",
            "Epoch #2. Accuracy on batch 1210 on Training is 30.34424029727498\n",
            "Epoch #2. Accuracy on batch 1211 on Training is 30.34240924092409\n",
            "Epoch #2. Accuracy on batch 1212 on Training is 30.34058120362737\n",
            "Epoch #2. Accuracy on batch 1213 on Training is 30.33103377265239\n",
            "Epoch #2. Accuracy on batch 1214 on Training is 30.3369341563786\n",
            "Epoch #2. Accuracy on batch 1215 on Training is 30.332545230263158\n",
            "Epoch #2. Accuracy on batch 1216 on Training is 30.346138044371404\n",
            "Epoch #2. Accuracy on batch 1217 on Training is 30.349445812807883\n",
            "Epoch #2. Accuracy on batch 1218 on Training is 30.3399302707137\n",
            "Epoch #2. Accuracy on batch 1219 on Training is 30.330430327868854\n",
            "Batch Id 1220 is having training loss of 2070.532958984375\n",
            "29.946542739868164\n",
            "Epoch #2. Accuracy on batch 1220 on Training is 30.3490990990991\n",
            "Epoch #2. Accuracy on batch 1221 on Training is 30.362622749590834\n",
            "Epoch #2. Accuracy on batch 1222 on Training is 30.3710139002453\n",
            "Epoch #2. Accuracy on batch 1223 on Training is 30.374285130718953\n",
            "Epoch #2. Accuracy on batch 1224 on Training is 30.375\n",
            "Epoch #2. Accuracy on batch 1225 on Training is 30.3731647634584\n",
            "Epoch #2. Accuracy on batch 1226 on Training is 30.381519967400163\n",
            "Epoch #2. Accuracy on batch 1227 on Training is 30.379682410423452\n",
            "Epoch #2. Accuracy on batch 1228 on Training is 30.38801871440195\n",
            "Epoch #2. Accuracy on batch 1229 on Training is 30.388719512195124\n",
            "Epoch #2. Accuracy on batch 1230 on Training is 30.394496344435417\n",
            "Epoch #2. Accuracy on batch 1231 on Training is 30.4002637987013\n",
            "Epoch #2. Accuracy on batch 1232 on Training is 30.403487429034875\n",
            "Epoch #2. Accuracy on batch 1233 on Training is 30.391511345218802\n",
            "Epoch #2. Accuracy on batch 1234 on Training is 30.399797570850204\n",
            "Epoch #2. Accuracy on batch 1235 on Training is 30.3979571197411\n",
            "Epoch #2. Accuracy on batch 1236 on Training is 30.40369846402587\n",
            "Epoch #2. Accuracy on batch 1237 on Training is 30.386712439418417\n",
            "Epoch #2. Accuracy on batch 1238 on Training is 30.382364810330913\n",
            "Epoch #2. Accuracy on batch 1239 on Training is 30.390625\n",
            "Batch Id 1240 is having training loss of 2127.84375\n",
            "58.82265090942383\n",
            "Epoch #2. Accuracy on batch 1240 on Training is 30.378726833199032\n",
            "Epoch #2. Accuracy on batch 1241 on Training is 30.376912238325282\n",
            "Epoch #2. Accuracy on batch 1242 on Training is 30.38515687851971\n",
            "Epoch #2. Accuracy on batch 1243 on Training is 30.393388263665596\n",
            "Epoch #2. Accuracy on batch 1244 on Training is 30.386546184738958\n",
            "Epoch #2. Accuracy on batch 1245 on Training is 30.38473113964687\n",
            "Epoch #2. Accuracy on batch 1246 on Training is 30.377906976744185\n",
            "Epoch #2. Accuracy on batch 1247 on Training is 30.381109775641026\n",
            "Epoch #2. Accuracy on batch 1248 on Training is 30.374299439551642\n",
            "Epoch #2. Accuracy on batch 1249 on Training is 30.38\n",
            "Epoch #2. Accuracy on batch 1250 on Training is 30.3707034372502\n",
            "Epoch #2. Accuracy on batch 1251 on Training is 30.356429712460063\n",
            "Epoch #2. Accuracy on batch 1252 on Training is 30.362130885873903\n",
            "Epoch #2. Accuracy on batch 1253 on Training is 30.360346889952154\n",
            "Epoch #2. Accuracy on batch 1254 on Training is 30.35109561752988\n",
            "Epoch #2. Accuracy on batch 1255 on Training is 30.349323248407643\n",
            "Epoch #2. Accuracy on batch 1256 on Training is 30.35749801113763\n",
            "Epoch #2. Accuracy on batch 1257 on Training is 30.360691573926868\n",
            "Epoch #2. Accuracy on batch 1258 on Training is 30.363880063542496\n",
            "Epoch #2. Accuracy on batch 1259 on Training is 30.359623015873016\n",
            "Batch Id 1260 is having training loss of 2121.132080078125\n",
            "25.367029190063477\n",
            "Epoch #2. Accuracy on batch 1260 on Training is 30.37024187153053\n",
            "Epoch #2. Accuracy on batch 1261 on Training is 30.36351030110935\n",
            "Epoch #2. Accuracy on batch 1262 on Training is 30.36173792557403\n",
            "Epoch #2. Accuracy on batch 1263 on Training is 30.35007911392405\n",
            "Epoch #2. Accuracy on batch 1264 on Training is 30.35326086956522\n",
            "Epoch #2. Accuracy on batch 1265 on Training is 30.351500789889414\n",
            "Epoch #2. Accuracy on batch 1266 on Training is 30.337411207576952\n",
            "Epoch #2. Accuracy on batch 1267 on Training is 30.347988958990538\n",
            "Epoch #2. Accuracy on batch 1268 on Training is 30.34869976359338\n",
            "Epoch #2. Accuracy on batch 1269 on Training is 30.349409448818896\n",
            "Epoch #2. Accuracy on batch 1270 on Training is 30.35749409913454\n",
            "Epoch #2. Accuracy on batch 1271 on Training is 30.35819575471698\n",
            "Epoch #2. Accuracy on batch 1272 on Training is 30.353986645718773\n",
            "Epoch #2. Accuracy on batch 1273 on Training is 30.357142857142858\n",
            "Epoch #2. Accuracy on batch 1274 on Training is 30.352941176470587\n",
            "Epoch #2. Accuracy on batch 1275 on Training is 30.346297021943574\n",
            "Epoch #2. Accuracy on batch 1276 on Training is 30.354346123727485\n",
            "Epoch #2. Accuracy on batch 1277 on Training is 30.36238262910798\n",
            "Epoch #2. Accuracy on batch 1278 on Training is 30.36307662236122\n",
            "Epoch #2. Accuracy on batch 1279 on Training is 30.3662109375\n",
            "Batch Id 1280 is having training loss of 2112.294677734375\n",
            "68.12334442138672\n",
            "Epoch #2. Accuracy on batch 1280 on Training is 30.36690085870414\n",
            "Epoch #2. Accuracy on batch 1281 on Training is 30.374902496099843\n",
            "Epoch #2. Accuracy on batch 1282 on Training is 30.37314886983632\n",
            "Epoch #2. Accuracy on batch 1283 on Training is 30.368964174454828\n",
            "Epoch #2. Accuracy on batch 1284 on Training is 30.367217898832685\n",
            "Epoch #2. Accuracy on batch 1285 on Training is 30.37276438569207\n",
            "Epoch #2. Accuracy on batch 1286 on Training is 30.385586635586634\n",
            "Epoch #2. Accuracy on batch 1287 on Training is 30.386257763975156\n",
            "Epoch #2. Accuracy on batch 1288 on Training is 30.384503491078355\n",
            "Epoch #2. Accuracy on batch 1289 on Training is 30.385174418604652\n",
            "Epoch #2. Accuracy on batch 1290 on Training is 30.390685515104572\n",
            "Epoch #2. Accuracy on batch 1291 on Training is 30.38409442724458\n",
            "Epoch #2. Accuracy on batch 1292 on Training is 30.382347254447023\n",
            "Epoch #2. Accuracy on batch 1293 on Training is 30.373357805255022\n",
            "Epoch #2. Accuracy on batch 1294 on Training is 30.36438223938224\n",
            "Epoch #2. Accuracy on batch 1295 on Training is 30.360243055555557\n",
            "Epoch #2. Accuracy on batch 1296 on Training is 30.370566692367\n",
            "Epoch #2. Accuracy on batch 1297 on Training is 30.366429121725734\n",
            "Epoch #2. Accuracy on batch 1298 on Training is 30.3598922247883\n",
            "Epoch #2. Accuracy on batch 1299 on Training is 30.348557692307693\n",
            "Batch Id 1300 is having training loss of 2086.419189453125\n",
            "49.102867126464844\n",
            "Epoch #2. Accuracy on batch 1300 on Training is 30.34684857801691\n",
            "Epoch #2. Accuracy on batch 1301 on Training is 30.357142857142858\n",
            "Epoch #2. Accuracy on batch 1302 on Training is 30.365023023791252\n",
            "Epoch #2. Accuracy on batch 1303 on Training is 30.368098159509202\n",
            "Epoch #2. Accuracy on batch 1304 on Training is 30.361590038314176\n",
            "Epoch #2. Accuracy on batch 1305 on Training is 30.35269908116386\n",
            "Epoch #2. Accuracy on batch 1306 on Training is 30.343821729150726\n",
            "Epoch #2. Accuracy on batch 1307 on Training is 30.337347094801224\n",
            "Epoch #2. Accuracy on batch 1308 on Training is 30.338044308632544\n",
            "Epoch #2. Accuracy on batch 1309 on Training is 30.338740458015266\n",
            "Epoch #2. Accuracy on batch 1310 on Training is 30.344202898550726\n",
            "Epoch #2. Accuracy on batch 1311 on Training is 30.347275152439025\n",
            "Epoch #2. Accuracy on batch 1312 on Training is 30.343202589489717\n",
            "Epoch #2. Accuracy on batch 1313 on Training is 30.34389269406393\n",
            "Epoch #2. Accuracy on batch 1314 on Training is 30.335076045627375\n",
            "Epoch #2. Accuracy on batch 1315 on Training is 30.331022036474163\n",
            "Epoch #2. Accuracy on batch 1316 on Training is 30.33883826879271\n",
            "Epoch #2. Accuracy on batch 1317 on Training is 30.339529590288315\n",
            "Epoch #2. Accuracy on batch 1318 on Training is 30.33074298711145\n",
            "Epoch #2. Accuracy on batch 1319 on Training is 30.319602272727273\n",
            "Batch Id 1320 is having training loss of 2074.529296875\n",
            "21.77946662902832\n",
            "Epoch #2. Accuracy on batch 1320 on Training is 30.327403482210446\n",
            "Epoch #2. Accuracy on batch 1321 on Training is 30.33519288956127\n",
            "Epoch #2. Accuracy on batch 1322 on Training is 30.33824640967498\n",
            "Epoch #2. Accuracy on batch 1323 on Training is 30.343655589123866\n",
            "Epoch #2. Accuracy on batch 1324 on Training is 30.337264150943398\n",
            "Epoch #2. Accuracy on batch 1325 on Training is 30.337952488687783\n",
            "Epoch #2. Accuracy on batch 1326 on Training is 30.34805953278071\n",
            "Epoch #2. Accuracy on batch 1327 on Training is 30.33932605421687\n",
            "Epoch #2. Accuracy on batch 1328 on Training is 30.351768246802106\n",
            "Epoch #2. Accuracy on batch 1329 on Training is 30.335996240601503\n",
            "Epoch #2. Accuracy on batch 1330 on Training is 30.331987227648384\n",
            "Epoch #2. Accuracy on batch 1331 on Training is 30.34206081081081\n",
            "Epoch #2. Accuracy on batch 1332 on Training is 30.333364591147788\n",
            "Epoch #2. Accuracy on batch 1333 on Training is 30.336394302848575\n",
            "Epoch #2. Accuracy on batch 1334 on Training is 30.33005617977528\n",
            "Epoch #2. Accuracy on batch 1335 on Training is 30.326066616766468\n",
            "Epoch #2. Accuracy on batch 1336 on Training is 30.333769633507853\n",
            "Epoch #2. Accuracy on batch 1337 on Training is 30.32044095665172\n",
            "Epoch #2. Accuracy on batch 1338 on Training is 30.318801344286783\n",
            "Epoch #2. Accuracy on batch 1339 on Training is 30.324160447761194\n",
            "Batch Id 1340 is having training loss of 2096.8369140625\n",
            "21.335351943969727\n",
            "Epoch #2. Accuracy on batch 1340 on Training is 30.32019015659955\n",
            "Epoch #2. Accuracy on batch 1341 on Training is 30.330197466467958\n",
            "Epoch #2. Accuracy on batch 1342 on Training is 30.326228592702904\n",
            "Epoch #2. Accuracy on batch 1343 on Training is 30.324590773809526\n",
            "Epoch #2. Accuracy on batch 1344 on Training is 30.320631970260223\n",
            "Epoch #2. Accuracy on batch 1345 on Training is 30.319000742942052\n",
            "Epoch #2. Accuracy on batch 1346 on Training is 30.324331848552337\n",
            "Epoch #2. Accuracy on batch 1347 on Training is 30.334291543026705\n",
            "Epoch #2. Accuracy on batch 1348 on Training is 30.321071163825057\n",
            "Epoch #2. Accuracy on batch 1349 on Training is 30.31712962962963\n",
            "Epoch #2. Accuracy on batch 1350 on Training is 30.30856772760918\n",
            "Epoch #2. Accuracy on batch 1351 on Training is 30.30464127218935\n",
            "Epoch #2. Accuracy on batch 1352 on Training is 30.312269031781227\n",
            "Epoch #2. Accuracy on batch 1353 on Training is 30.30834564254062\n",
            "Epoch #2. Accuracy on batch 1354 on Training is 30.306734317343174\n",
            "Epoch #2. Accuracy on batch 1355 on Training is 30.305125368731563\n",
            "Epoch #2. Accuracy on batch 1356 on Training is 30.310427413411936\n",
            "Epoch #2. Accuracy on batch 1357 on Training is 30.308818114874814\n",
            "Epoch #2. Accuracy on batch 1358 on Training is 30.309510669610006\n",
            "Epoch #2. Accuracy on batch 1359 on Training is 30.305606617647058\n",
            "Batch Id 1360 is having training loss of 2125.29931640625\n",
            "25.284761428833008\n",
            "Epoch #2. Accuracy on batch 1360 on Training is 30.313188831741368\n",
            "Epoch #2. Accuracy on batch 1361 on Training is 30.320759911894275\n",
            "Epoch #2. Accuracy on batch 1362 on Training is 30.328319882611886\n",
            "Epoch #2. Accuracy on batch 1363 on Training is 30.32899560117302\n",
            "Epoch #2. Accuracy on batch 1364 on Training is 30.325091575091577\n",
            "Epoch #2. Accuracy on batch 1365 on Training is 30.3326317715959\n",
            "Epoch #2. Accuracy on batch 1366 on Training is 30.33558888076079\n",
            "Epoch #2. Accuracy on batch 1367 on Training is 30.333972953216374\n",
            "Epoch #2. Accuracy on batch 1368 on Training is 30.348338203067932\n",
            "Epoch #2. Accuracy on batch 1369 on Training is 30.346715328467152\n",
            "Epoch #2. Accuracy on batch 1370 on Training is 30.34737417943107\n",
            "Epoch #2. Accuracy on batch 1371 on Training is 30.348032069970845\n",
            "Epoch #2. Accuracy on batch 1372 on Training is 30.341860888565186\n",
            "Epoch #2. Accuracy on batch 1373 on Training is 30.3379730713246\n",
            "Epoch #2. Accuracy on batch 1374 on Training is 30.33409090909091\n",
            "Epoch #2. Accuracy on batch 1375 on Training is 30.332485465116278\n",
            "Epoch #2. Accuracy on batch 1376 on Training is 30.33996005809731\n",
            "Epoch #2. Accuracy on batch 1377 on Training is 30.34288824383164\n",
            "Epoch #2. Accuracy on batch 1378 on Training is 30.34354604786077\n",
            "Epoch #2. Accuracy on batch 1379 on Training is 30.346467391304348\n",
            "Batch Id 1380 is having training loss of 2136.49462890625\n",
            "616.722900390625\n",
            "Epoch #2. Accuracy on batch 1380 on Training is 30.33354453294714\n",
            "Epoch #2. Accuracy on batch 1381 on Training is 30.32968523878437\n",
            "Epoch #2. Accuracy on batch 1382 on Training is 30.33486984815618\n",
            "Epoch #2. Accuracy on batch 1383 on Training is 30.335531069364162\n",
            "Epoch #2. Accuracy on batch 1384 on Training is 30.338447653429604\n",
            "Epoch #2. Accuracy on batch 1385 on Training is 30.32783189033189\n",
            "Epoch #2. Accuracy on batch 1386 on Training is 30.321737563085797\n",
            "Epoch #2. Accuracy on batch 1387 on Training is 30.322406340057636\n",
            "Epoch #2. Accuracy on batch 1388 on Training is 30.325323974082075\n",
            "Epoch #2. Accuracy on batch 1389 on Training is 30.321492805755394\n",
            "Epoch #2. Accuracy on batch 1390 on Training is 30.317667145938174\n",
            "Epoch #2. Accuracy on batch 1391 on Training is 30.31160201149425\n",
            "Epoch #2. Accuracy on batch 1392 on Training is 30.29881550610194\n",
            "Epoch #2. Accuracy on batch 1393 on Training is 30.297256097560975\n",
            "Epoch #2. Accuracy on batch 1394 on Training is 30.293458781362006\n",
            "Epoch #2. Accuracy on batch 1395 on Training is 30.276235673352435\n",
            "Epoch #2. Accuracy on batch 1396 on Training is 30.276932712956334\n",
            "Epoch #2. Accuracy on batch 1397 on Training is 30.286570100143063\n",
            "Epoch #2. Accuracy on batch 1398 on Training is 30.29395997140815\n",
            "Epoch #2. Accuracy on batch 1399 on Training is 30.301339285714285\n",
            "Batch Id 1400 is having training loss of 2183.195556640625\n",
            "254.90960693359375\n",
            "Epoch #2. Accuracy on batch 1400 on Training is 30.29532476802284\n",
            "Epoch #2. Accuracy on batch 1401 on Training is 30.282631954350926\n",
            "Epoch #2. Accuracy on batch 1402 on Training is 30.283321454027085\n",
            "Epoch #2. Accuracy on batch 1403 on Training is 30.290687321937323\n",
            "Epoch #2. Accuracy on batch 1404 on Training is 30.286921708185055\n",
            "Epoch #2. Accuracy on batch 1405 on Training is 30.285384068278805\n",
            "Epoch #2. Accuracy on batch 1406 on Training is 30.286069651741293\n",
            "Epoch #2. Accuracy on batch 1407 on Training is 30.291193181818183\n",
            "Epoch #2. Accuracy on batch 1408 on Training is 30.294091554293825\n",
            "Epoch #2. Accuracy on batch 1409 on Training is 30.296985815602838\n",
            "Epoch #2. Accuracy on batch 1410 on Training is 30.291017009213324\n",
            "Epoch #2. Accuracy on batch 1411 on Training is 30.28726983002833\n",
            "Epoch #2. Accuracy on batch 1412 on Training is 30.294585987261147\n",
            "Epoch #2. Accuracy on batch 1413 on Training is 30.295261669024047\n",
            "Epoch #2. Accuracy on batch 1414 on Training is 30.29814487632509\n",
            "Epoch #2. Accuracy on batch 1415 on Training is 30.305437853107346\n",
            "Epoch #2. Accuracy on batch 1416 on Training is 30.295077628793226\n",
            "Epoch #2. Accuracy on batch 1417 on Training is 30.28252820874471\n",
            "Epoch #2. Accuracy on batch 1418 on Training is 30.28541226215645\n",
            "Epoch #2. Accuracy on batch 1419 on Training is 30.29049295774648\n",
            "Batch Id 1420 is having training loss of 2185.42041015625\n",
            "10.281144142150879\n",
            "Epoch #2. Accuracy on batch 1420 on Training is 30.291168191414496\n",
            "Epoch #2. Accuracy on batch 1421 on Training is 30.28524964838256\n",
            "Epoch #2. Accuracy on batch 1422 on Training is 30.28373155305692\n",
            "Epoch #2. Accuracy on batch 1423 on Training is 30.27782654494382\n",
            "Epoch #2. Accuracy on batch 1424 on Training is 30.274122807017545\n",
            "Epoch #2. Accuracy on batch 1425 on Training is 30.272615708274895\n",
            "Epoch #2. Accuracy on batch 1426 on Training is 30.271110721793974\n",
            "Epoch #2. Accuracy on batch 1427 on Training is 30.269607843137255\n",
            "Epoch #2. Accuracy on batch 1428 on Training is 30.27248075577327\n",
            "Epoch #2. Accuracy on batch 1429 on Training is 30.27534965034965\n",
            "Epoch #2. Accuracy on batch 1430 on Training is 30.273846960167713\n",
            "Epoch #2. Accuracy on batch 1431 on Training is 30.281075418994412\n",
            "Epoch #2. Accuracy on batch 1432 on Training is 30.273028611304955\n",
            "Epoch #2. Accuracy on batch 1433 on Training is 30.267172245467226\n",
            "Epoch #2. Accuracy on batch 1434 on Training is 30.26567944250871\n",
            "Epoch #2. Accuracy on batch 1435 on Training is 30.268541086350975\n",
            "Epoch #2. Accuracy on batch 1436 on Training is 30.28009742519137\n",
            "Epoch #2. Accuracy on batch 1437 on Training is 30.276425591098747\n",
            "Epoch #2. Accuracy on batch 1438 on Training is 30.270587213342598\n",
            "Epoch #2. Accuracy on batch 1439 on Training is 30.2734375\n",
            "Batch Id 1440 is having training loss of 2195.9541015625\n",
            "50.26122283935547\n",
            "Epoch #2. Accuracy on batch 1440 on Training is 30.27411519777932\n",
            "Epoch #2. Accuracy on batch 1441 on Training is 30.261789181692095\n",
            "Epoch #2. Accuracy on batch 1442 on Training is 30.273302148302147\n",
            "Epoch #2. Accuracy on batch 1443 on Training is 30.263157894736842\n",
            "Epoch #2. Accuracy on batch 1444 on Training is 30.261678200692042\n",
            "Epoch #2. Accuracy on batch 1445 on Training is 30.260200553250346\n",
            "Epoch #2. Accuracy on batch 1446 on Training is 30.27384243261921\n",
            "Epoch #2. Accuracy on batch 1447 on Training is 30.26372582872928\n",
            "Epoch #2. Accuracy on batch 1448 on Training is 30.27087646652864\n",
            "Epoch #2. Accuracy on batch 1449 on Training is 30.275862068965516\n",
            "Epoch #2. Accuracy on batch 1450 on Training is 30.276533425223985\n",
            "Epoch #2. Accuracy on batch 1451 on Training is 30.266442837465565\n",
            "Epoch #2. Accuracy on batch 1452 on Training is 30.262818306951136\n",
            "Epoch #2. Accuracy on batch 1453 on Training is 30.257049518569463\n",
            "Epoch #2. Accuracy on batch 1454 on Training is 30.257731958762886\n",
            "Epoch #2. Accuracy on batch 1455 on Training is 30.247682005494507\n",
            "Epoch #2. Accuracy on batch 1456 on Training is 30.25480439258751\n",
            "Epoch #2. Accuracy on batch 1457 on Training is 30.25977366255144\n",
            "Epoch #2. Accuracy on batch 1458 on Training is 30.256168608636052\n",
            "Epoch #2. Accuracy on batch 1459 on Training is 30.252568493150687\n",
            "Batch Id 1460 is having training loss of 2186.45703125\n",
            "11.601187705993652\n",
            "Epoch #2. Accuracy on batch 1460 on Training is 30.25752908966461\n",
            "Epoch #2. Accuracy on batch 1461 on Training is 30.264620383036934\n",
            "Epoch #2. Accuracy on batch 1462 on Training is 30.275974025974026\n",
            "Epoch #2. Accuracy on batch 1463 on Training is 30.283043032786885\n",
            "Epoch #2. Accuracy on batch 1464 on Training is 30.281569965870307\n",
            "Epoch #2. Accuracy on batch 1465 on Training is 30.284362210095498\n",
            "Epoch #2. Accuracy on batch 1466 on Training is 30.278629856850717\n",
            "Epoch #2. Accuracy on batch 1467 on Training is 30.283549046321525\n",
            "Epoch #2. Accuracy on batch 1468 on Training is 30.290588835942817\n",
            "Epoch #2. Accuracy on batch 1469 on Training is 30.286989795918366\n",
            "Epoch #2. Accuracy on batch 1470 on Training is 30.291893269884433\n",
            "Epoch #2. Accuracy on batch 1471 on Training is 30.307404891304348\n",
            "Epoch #2. Accuracy on batch 1472 on Training is 30.301680244399186\n",
            "Epoch #2. Accuracy on batch 1473 on Training is 30.291723202170964\n",
            "Epoch #2. Accuracy on batch 1474 on Training is 30.290254237288135\n",
            "Epoch #2. Accuracy on batch 1475 on Training is 30.288787262872628\n",
            "Epoch #2. Accuracy on batch 1476 on Training is 30.287322274881518\n",
            "Epoch #2. Accuracy on batch 1477 on Training is 30.27528755074425\n",
            "Epoch #2. Accuracy on batch 1478 on Training is 30.275946585530765\n",
            "Epoch #2. Accuracy on batch 1479 on Training is 30.272381756756758\n",
            "Batch Id 1480 is having training loss of 2181.134765625\n",
            "15.149601936340332\n",
            "Epoch #2. Accuracy on batch 1480 on Training is 30.281482106684674\n",
            "Epoch #2. Accuracy on batch 1481 on Training is 30.269483805668017\n",
            "Epoch #2. Accuracy on batch 1482 on Training is 30.27014497639919\n",
            "Epoch #2. Accuracy on batch 1483 on Training is 30.27080525606469\n",
            "Epoch #2. Accuracy on batch 1484 on Training is 30.26304713804714\n",
            "Epoch #2. Accuracy on batch 1485 on Training is 30.26791722745626\n",
            "Epoch #2. Accuracy on batch 1486 on Training is 30.255968392737053\n",
            "Epoch #2. Accuracy on batch 1487 on Training is 30.258736559139784\n",
            "Epoch #2. Accuracy on batch 1488 on Training is 30.26150100738751\n",
            "Epoch #2. Accuracy on batch 1489 on Training is 30.26006711409396\n",
            "Epoch #2. Accuracy on batch 1490 on Training is 30.267018779342724\n",
            "Epoch #2. Accuracy on batch 1491 on Training is 30.267677613941018\n",
            "Epoch #2. Accuracy on batch 1492 on Training is 30.2662424648359\n",
            "Epoch #2. Accuracy on batch 1493 on Training is 30.26480923694779\n",
            "Epoch #2. Accuracy on batch 1494 on Training is 30.265468227424748\n",
            "Epoch #2. Accuracy on batch 1495 on Training is 30.270304144385026\n",
            "Epoch #2. Accuracy on batch 1496 on Training is 30.26678356713427\n",
            "Epoch #2. Accuracy on batch 1497 on Training is 30.25909546061415\n",
            "Epoch #2. Accuracy on batch 1498 on Training is 30.25141761174116\n",
            "Epoch #2. Accuracy on batch 1499 on Training is 30.252083333333335\n",
            "Batch Id 1500 is having training loss of 2176.484375\n",
            "31.208393096923828\n",
            "Epoch #2. Accuracy on batch 1500 on Training is 30.246502331778814\n",
            "Epoch #2. Accuracy on batch 1501 on Training is 30.23676764314248\n",
            "Epoch #2. Accuracy on batch 1502 on Training is 30.239520958083833\n",
            "Epoch #2. Accuracy on batch 1503 on Training is 30.22980385638298\n",
            "Epoch #2. Accuracy on batch 1504 on Training is 30.234634551495017\n",
            "Epoch #2. Accuracy on batch 1505 on Training is 30.224933598937582\n",
            "Epoch #2. Accuracy on batch 1506 on Training is 30.21939283344393\n",
            "Epoch #2. Accuracy on batch 1507 on Training is 30.21593169761273\n",
            "Epoch #2. Accuracy on batch 1508 on Training is 30.218687872763418\n",
            "Epoch #2. Accuracy on batch 1509 on Training is 30.221440397350992\n",
            "Epoch #2. Accuracy on batch 1510 on Training is 30.213848444738584\n",
            "Epoch #2. Accuracy on batch 1511 on Training is 30.208333333333332\n",
            "Epoch #2. Accuracy on batch 1512 on Training is 30.20695637805684\n",
            "Epoch #2. Accuracy on batch 1513 on Training is 30.201453104359313\n",
            "Epoch #2. Accuracy on batch 1514 on Training is 30.206270627062707\n",
            "Epoch #2. Accuracy on batch 1515 on Training is 30.213143139841687\n",
            "Epoch #2. Accuracy on batch 1516 on Training is 30.215886618325644\n",
            "Epoch #2. Accuracy on batch 1517 on Training is 30.224802371541504\n",
            "Epoch #2. Accuracy on batch 1518 on Training is 30.221362738643844\n",
            "Epoch #2. Accuracy on batch 1519 on Training is 30.230263157894736\n",
            "Batch Id 1520 is having training loss of 2184.0498046875\n",
            "18.10863494873047\n",
            "Epoch #2. Accuracy on batch 1520 on Training is 30.22887902695595\n",
            "Epoch #2. Accuracy on batch 1521 on Training is 30.223390275952696\n",
            "Epoch #2. Accuracy on batch 1522 on Training is 30.219960604070913\n",
            "Epoch #2. Accuracy on batch 1523 on Training is 30.21858595800525\n",
            "Epoch #2. Accuracy on batch 1524 on Training is 30.221311475409838\n",
            "Epoch #2. Accuracy on batch 1525 on Training is 30.221985583224114\n",
            "Epoch #2. Accuracy on batch 1526 on Training is 30.216519318926\n",
            "Epoch #2. Accuracy on batch 1527 on Training is 30.217195680628272\n",
            "Epoch #2. Accuracy on batch 1528 on Training is 30.20560824068018\n",
            "Epoch #2. Accuracy on batch 1529 on Training is 30.204248366013072\n",
            "Epoch #2. Accuracy on batch 1530 on Training is 30.204931417374265\n",
            "Epoch #2. Accuracy on batch 1531 on Training is 30.2056135770235\n",
            "Epoch #2. Accuracy on batch 1532 on Training is 30.206294846705806\n",
            "Epoch #2. Accuracy on batch 1533 on Training is 30.221235332464147\n",
            "Epoch #2. Accuracy on batch 1534 on Training is 30.217833876221498\n",
            "Epoch #2. Accuracy on batch 1535 on Training is 30.214436848958332\n",
            "Epoch #2. Accuracy on batch 1536 on Training is 30.209011060507482\n",
            "Epoch #2. Accuracy on batch 1537 on Training is 30.21781534460338\n",
            "Epoch #2. Accuracy on batch 1538 on Training is 30.21848602988954\n",
            "Epoch #2. Accuracy on batch 1539 on Training is 30.2150974025974\n",
            "Batch Id 1540 is having training loss of 2228.1669921875\n",
            "50579.01171875\n",
            "Epoch #2. Accuracy on batch 1540 on Training is 30.213741077222583\n",
            "Epoch #2. Accuracy on batch 1541 on Training is 30.216439688715955\n",
            "Epoch #2. Accuracy on batch 1542 on Training is 30.221160077770577\n",
            "Epoch #2. Accuracy on batch 1543 on Training is 30.223850388601036\n",
            "Epoch #2. Accuracy on batch 1544 on Training is 30.218446601941746\n",
            "Epoch #2. Accuracy on batch 1545 on Training is 30.213049805950842\n",
            "Epoch #2. Accuracy on batch 1546 on Training is 30.217760180995477\n",
            "Epoch #2. Accuracy on batch 1547 on Training is 30.224483204134366\n",
            "Epoch #2. Accuracy on batch 1548 on Training is 30.233214977404778\n",
            "Epoch #2. Accuracy on batch 1549 on Training is 30.245967741935484\n",
            "Epoch #2. Accuracy on batch 1550 on Training is 30.24862991618311\n",
            "Epoch #2. Accuracy on batch 1551 on Training is 30.24122100515464\n",
            "Epoch #2. Accuracy on batch 1552 on Training is 30.243882807469415\n",
            "Epoch #2. Accuracy on batch 1553 on Training is 30.250563063063062\n",
            "Epoch #2. Accuracy on batch 1554 on Training is 30.247186495176848\n",
            "Epoch #2. Accuracy on batch 1555 on Training is 30.247830976863753\n",
            "Epoch #2. Accuracy on batch 1556 on Training is 30.25650289017341\n",
            "Epoch #2. Accuracy on batch 1557 on Training is 30.265163671373557\n",
            "Epoch #2. Accuracy on batch 1558 on Training is 30.269804361770365\n",
            "Epoch #2. Accuracy on batch 1559 on Training is 30.272435897435898\n",
            "Batch Id 1560 is having training loss of 2210.039794921875\n",
            "19.51332664489746\n",
            "Epoch #2. Accuracy on batch 1560 on Training is 30.275064061499037\n",
            "Epoch #2. Accuracy on batch 1561 on Training is 30.271686939820743\n",
            "Epoch #2. Accuracy on batch 1562 on Training is 30.26831413947537\n",
            "Epoch #2. Accuracy on batch 1563 on Training is 30.268941815856778\n",
            "Epoch #2. Accuracy on batch 1564 on Training is 30.27555910543131\n",
            "Epoch #2. Accuracy on batch 1565 on Training is 30.272190293742018\n",
            "Epoch #2. Accuracy on batch 1566 on Training is 30.272814294830887\n",
            "Epoch #2. Accuracy on batch 1567 on Training is 30.279416454081634\n",
            "Epoch #2. Accuracy on batch 1568 on Training is 30.289993626513702\n",
            "Epoch #2. Accuracy on batch 1569 on Training is 30.288614649681527\n",
            "Epoch #2. Accuracy on batch 1570 on Training is 30.285248249522596\n",
            "Epoch #2. Accuracy on batch 1571 on Training is 30.28188613231552\n",
            "Epoch #2. Accuracy on batch 1572 on Training is 30.28250158931977\n",
            "Epoch #2. Accuracy on batch 1573 on Training is 30.273189326556544\n",
            "Epoch #2. Accuracy on batch 1574 on Training is 30.28174603174603\n",
            "Epoch #2. Accuracy on batch 1575 on Training is 30.276411802030456\n",
            "Epoch #2. Accuracy on batch 1576 on Training is 30.280992390615094\n",
            "Epoch #2. Accuracy on batch 1577 on Training is 30.281606463878326\n",
            "Epoch #2. Accuracy on batch 1578 on Training is 30.28024065864471\n",
            "Epoch #2. Accuracy on batch 1579 on Training is 30.280854430379748\n",
            "Batch Id 1580 is having training loss of 2245.142578125\n",
            "2923.97216796875\n",
            "Epoch #2. Accuracy on batch 1580 on Training is 30.28146742567995\n",
            "Epoch #2. Accuracy on batch 1581 on Training is 30.280104298356513\n",
            "Epoch #2. Accuracy on batch 1582 on Training is 30.282691092861654\n",
            "Epoch #2. Accuracy on batch 1583 on Training is 30.281328914141415\n",
            "Epoch #2. Accuracy on batch 1584 on Training is 30.28391167192429\n",
            "Epoch #2. Accuracy on batch 1585 on Training is 30.28846153846154\n",
            "Epoch #2. Accuracy on batch 1586 on Training is 30.291036546943918\n",
            "Epoch #2. Accuracy on batch 1587 on Training is 30.3014798488665\n",
            "Epoch #2. Accuracy on batch 1588 on Training is 30.29224354940214\n",
            "Epoch #2. Accuracy on batch 1589 on Training is 30.292845911949687\n",
            "Epoch #2. Accuracy on batch 1590 on Training is 30.303268384663735\n",
            "Epoch #2. Accuracy on batch 1591 on Training is 30.297974246231156\n",
            "Epoch #2. Accuracy on batch 1592 on Training is 30.294648462021343\n",
            "Epoch #2. Accuracy on batch 1593 on Training is 30.293287327478044\n",
            "Epoch #2. Accuracy on batch 1594 on Training is 30.28996865203762\n",
            "Epoch #2. Accuracy on batch 1595 on Training is 30.290570175438596\n",
            "Epoch #2. Accuracy on batch 1596 on Training is 30.300954915466498\n",
            "Epoch #2. Accuracy on batch 1597 on Training is 30.305459949937422\n",
            "Epoch #2. Accuracy on batch 1598 on Training is 30.30214196372733\n",
            "Epoch #2. Accuracy on batch 1599 on Training is 30.296875\n",
            "Batch Id 1600 is having training loss of 2221.375732421875\n",
            "15.21487045288086\n",
            "Epoch #2. Accuracy on batch 1600 on Training is 30.303326046221112\n",
            "Epoch #2. Accuracy on batch 1601 on Training is 30.305867665418226\n",
            "Epoch #2. Accuracy on batch 1602 on Training is 30.29865876481597\n",
            "Epoch #2. Accuracy on batch 1603 on Training is 30.29535536159601\n",
            "Epoch #2. Accuracy on batch 1604 on Training is 30.301791277258566\n",
            "Epoch #2. Accuracy on batch 1605 on Training is 30.306273349937733\n",
            "Epoch #2. Accuracy on batch 1606 on Training is 30.30491599253267\n",
            "Epoch #2. Accuracy on batch 1607 on Training is 30.307447139303484\n",
            "Epoch #2. Accuracy on batch 1608 on Training is 30.304148539465505\n",
            "Epoch #2. Accuracy on batch 1609 on Training is 30.3027950310559\n",
            "Epoch #2. Accuracy on batch 1610 on Training is 30.30532278088144\n",
            "Epoch #2. Accuracy on batch 1611 on Training is 30.30203163771712\n",
            "Epoch #2. Accuracy on batch 1612 on Training is 30.302619342839428\n",
            "Epoch #2. Accuracy on batch 1613 on Training is 30.31482342007435\n",
            "Epoch #2. Accuracy on batch 1614 on Training is 30.31733746130031\n",
            "Epoch #2. Accuracy on batch 1615 on Training is 30.31404702970297\n",
            "Epoch #2. Accuracy on batch 1616 on Training is 30.31269325912183\n",
            "Epoch #2. Accuracy on batch 1617 on Training is 30.317135352286773\n",
            "Epoch #2. Accuracy on batch 1618 on Training is 30.31385114268067\n",
            "Epoch #2. Accuracy on batch 1619 on Training is 30.320216049382715\n",
            "Batch Id 1620 is having training loss of 2249.301513671875\n",
            "18.683521270751953\n",
            "Epoch #2. Accuracy on batch 1620 on Training is 30.31886181369525\n",
            "Epoch #2. Accuracy on batch 1621 on Training is 30.32521578298397\n",
            "Epoch #2. Accuracy on batch 1622 on Training is 30.320009242144177\n",
            "Epoch #2. Accuracy on batch 1623 on Training is 30.31480911330049\n",
            "Epoch #2. Accuracy on batch 1624 on Training is 30.321153846153845\n",
            "Epoch #2. Accuracy on batch 1625 on Training is 30.327490774907748\n",
            "Epoch #2. Accuracy on batch 1626 on Training is 30.326137062077443\n",
            "Epoch #2. Accuracy on batch 1627 on Training is 30.319026412776413\n",
            "Epoch #2. Accuracy on batch 1628 on Training is 30.31767955801105\n",
            "Epoch #2. Accuracy on batch 1629 on Training is 30.31825153374233\n",
            "Epoch #2. Accuracy on batch 1630 on Training is 30.32265481299816\n",
            "Epoch #2. Accuracy on batch 1631 on Training is 30.325137867647058\n",
            "Epoch #2. Accuracy on batch 1632 on Training is 30.327617881200243\n",
            "Epoch #2. Accuracy on batch 1633 on Training is 30.328182374541004\n",
            "Epoch #2. Accuracy on batch 1634 on Training is 30.326834862385322\n",
            "Epoch #2. Accuracy on batch 1635 on Training is 30.32166870415648\n",
            "Epoch #2. Accuracy on batch 1636 on Training is 30.32032681734881\n",
            "Epoch #2. Accuracy on batch 1637 on Training is 30.328525641025642\n",
            "Epoch #2. Accuracy on batch 1638 on Training is 30.334807809640026\n",
            "Epoch #2. Accuracy on batch 1639 on Training is 30.333460365853657\n",
            "Batch Id 1640 is having training loss of 2222.631591796875\n",
            "31.784664154052734\n",
            "Epoch #2. Accuracy on batch 1640 on Training is 30.335923217550274\n",
            "Epoch #2. Accuracy on batch 1641 on Training is 30.336479902557855\n",
            "Epoch #2. Accuracy on batch 1642 on Training is 30.34083992696287\n",
            "Epoch #2. Accuracy on batch 1643 on Training is 30.33949209245742\n",
            "Epoch #2. Accuracy on batch 1644 on Training is 30.347644376899694\n",
            "Epoch #2. Accuracy on batch 1645 on Training is 30.35388821385176\n",
            "Epoch #2. Accuracy on batch 1646 on Training is 30.35443230115361\n",
            "Epoch #2. Accuracy on batch 1647 on Training is 30.35307949029126\n",
            "Epoch #2. Accuracy on batch 1648 on Training is 30.351728320194056\n",
            "Epoch #2. Accuracy on batch 1649 on Training is 30.348484848484848\n",
            "Epoch #2. Accuracy on batch 1650 on Training is 30.349030890369473\n",
            "Epoch #2. Accuracy on batch 1651 on Training is 30.345792978208234\n",
            "Epoch #2. Accuracy on batch 1652 on Training is 30.350120992135512\n",
            "Epoch #2. Accuracy on batch 1653 on Training is 30.358222490931077\n",
            "Epoch #2. Accuracy on batch 1654 on Training is 30.36442598187311\n",
            "Epoch #2. Accuracy on batch 1655 on Training is 30.366847826086957\n",
            "Epoch #2. Accuracy on batch 1656 on Training is 30.35983705491853\n",
            "Epoch #2. Accuracy on batch 1657 on Training is 30.358489143546443\n",
            "Epoch #2. Accuracy on batch 1658 on Training is 30.359026522001205\n",
            "Epoch #2. Accuracy on batch 1659 on Training is 30.36144578313253\n",
            "Batch Id 1660 is having training loss of 2196.798095703125\n",
            "20.222780227661133\n",
            "Epoch #2. Accuracy on batch 1660 on Training is 30.3582179409994\n",
            "Epoch #2. Accuracy on batch 1661 on Training is 30.354993983152827\n",
            "Epoch #2. Accuracy on batch 1662 on Training is 30.361169573060735\n",
            "Epoch #2. Accuracy on batch 1663 on Training is 30.36170372596154\n",
            "Epoch #2. Accuracy on batch 1664 on Training is 30.358483483483482\n",
            "Epoch #2. Accuracy on batch 1665 on Training is 30.357142857142858\n",
            "Epoch #2. Accuracy on batch 1666 on Training is 30.361427714457108\n",
            "Epoch #2. Accuracy on batch 1667 on Training is 30.36570743405276\n",
            "Epoch #2. Accuracy on batch 1668 on Training is 30.368109646494908\n",
            "Epoch #2. Accuracy on batch 1669 on Training is 30.36676646706587\n",
            "Epoch #2. Accuracy on batch 1670 on Training is 30.369165170556553\n",
            "Epoch #2. Accuracy on batch 1671 on Training is 30.3752990430622\n",
            "Epoch #2. Accuracy on batch 1672 on Training is 30.377689778840406\n",
            "Epoch #2. Accuracy on batch 1673 on Training is 30.381944444444443\n",
            "Epoch #2. Accuracy on batch 1674 on Training is 30.384328358208954\n",
            "Epoch #2. Accuracy on batch 1675 on Training is 30.39789677804296\n",
            "Epoch #2. Accuracy on batch 1676 on Training is 30.394677996422182\n",
            "Epoch #2. Accuracy on batch 1677 on Training is 30.39891239570918\n",
            "Epoch #2. Accuracy on batch 1678 on Training is 30.399419297200716\n",
            "Epoch #2. Accuracy on batch 1679 on Training is 30.394345238095237\n",
            "Batch Id 1680 is having training loss of 2171.15625\n",
            "34.095855712890625\n",
            "Epoch #2. Accuracy on batch 1680 on Training is 30.398572278405712\n",
            "Epoch #2. Accuracy on batch 1681 on Training is 30.3916468489893\n",
            "Epoch #2. Accuracy on batch 1682 on Training is 30.403297682709447\n",
            "Epoch #2. Accuracy on batch 1683 on Training is 30.400089073634206\n",
            "Epoch #2. Accuracy on batch 1684 on Training is 30.402448071216618\n",
            "Epoch #2. Accuracy on batch 1685 on Training is 30.408511269276392\n",
            "Epoch #2. Accuracy on batch 1686 on Training is 30.412714878482515\n",
            "Epoch #2. Accuracy on batch 1687 on Training is 30.416913507109005\n",
            "Epoch #2. Accuracy on batch 1688 on Training is 30.419256956779158\n",
            "Epoch #2. Accuracy on batch 1689 on Training is 30.41974852071006\n",
            "Epoch #2. Accuracy on batch 1690 on Training is 30.410999408633945\n",
            "Epoch #2. Accuracy on batch 1691 on Training is 30.400413711583923\n",
            "Epoch #2. Accuracy on batch 1692 on Training is 30.400915534554045\n",
            "Epoch #2. Accuracy on batch 1693 on Training is 30.405106257378986\n",
            "Epoch #2. Accuracy on batch 1694 on Training is 30.407448377581122\n",
            "Epoch #2. Accuracy on batch 1695 on Training is 30.40241745283019\n",
            "Epoch #2. Accuracy on batch 1696 on Training is 30.40475839717148\n",
            "Epoch #2. Accuracy on batch 1697 on Training is 30.40341578327444\n",
            "Epoch #2. Accuracy on batch 1698 on Training is 30.405753384343733\n",
            "Epoch #2. Accuracy on batch 1699 on Training is 30.41360294117647\n",
            "Batch Id 1700 is having training loss of 2160.823486328125\n",
            "27.059480667114258\n",
            "Epoch #2. Accuracy on batch 1700 on Training is 30.415931804820694\n",
            "Epoch #2. Accuracy on batch 1701 on Training is 30.42376615746181\n",
            "Epoch #2. Accuracy on batch 1702 on Training is 30.424251321197886\n",
            "Epoch #2. Accuracy on batch 1703 on Training is 30.424735915492956\n",
            "Epoch #2. Accuracy on batch 1704 on Training is 30.427052785923753\n",
            "Epoch #2. Accuracy on batch 1705 on Training is 30.433030480656505\n",
            "Epoch #2. Accuracy on batch 1706 on Training is 30.433509080257764\n",
            "Epoch #2. Accuracy on batch 1707 on Training is 30.42849824355972\n",
            "Epoch #2. Accuracy on batch 1708 on Training is 30.423493270918666\n",
            "Epoch #2. Accuracy on batch 1709 on Training is 30.429459064327485\n",
            "Epoch #2. Accuracy on batch 1710 on Training is 30.4354178842782\n",
            "Epoch #2. Accuracy on batch 1711 on Training is 30.439544392523363\n",
            "Epoch #2. Accuracy on batch 1712 on Training is 30.443666082895504\n",
            "Epoch #2. Accuracy on batch 1713 on Training is 30.442313302217038\n",
            "Epoch #2. Accuracy on batch 1714 on Training is 30.431851311953352\n",
            "Epoch #2. Accuracy on batch 1715 on Training is 30.434149184149184\n",
            "Epoch #2. Accuracy on batch 1716 on Training is 30.43644437973209\n",
            "Epoch #2. Accuracy on batch 1717 on Training is 30.43691792782305\n",
            "Epoch #2. Accuracy on batch 1718 on Training is 30.430119255381037\n",
            "Epoch #2. Accuracy on batch 1719 on Training is 30.43422965116279\n",
            "Batch Id 1720 is having training loss of 2147.442626953125\n",
            "12.55098819732666\n",
            "Epoch #2. Accuracy on batch 1720 on Training is 30.434703660662407\n",
            "Epoch #2. Accuracy on batch 1721 on Training is 30.43517711962834\n",
            "Epoch #2. Accuracy on batch 1722 on Training is 30.433836331979105\n",
            "Epoch #2. Accuracy on batch 1723 on Training is 30.432497099767982\n",
            "Epoch #2. Accuracy on batch 1724 on Training is 30.431159420289855\n",
            "Epoch #2. Accuracy on batch 1725 on Training is 30.437065469293163\n",
            "Epoch #2. Accuracy on batch 1726 on Training is 30.430298204979735\n",
            "Epoch #2. Accuracy on batch 1727 on Training is 30.42534722222222\n",
            "Epoch #2. Accuracy on batch 1728 on Training is 30.42763157894737\n",
            "Epoch #2. Accuracy on batch 1729 on Training is 30.42991329479769\n",
            "Epoch #2. Accuracy on batch 1730 on Training is 30.441218948584634\n",
            "Epoch #2. Accuracy on batch 1731 on Training is 30.44709872979215\n",
            "Epoch #2. Accuracy on batch 1732 on Training is 30.445758799769187\n",
            "Epoch #2. Accuracy on batch 1733 on Training is 30.446222606689734\n",
            "Epoch #2. Accuracy on batch 1734 on Training is 30.439481268011527\n",
            "Epoch #2. Accuracy on batch 1735 on Training is 30.434547811059907\n",
            "Epoch #2. Accuracy on batch 1736 on Training is 30.435017271157168\n",
            "Epoch #2. Accuracy on batch 1737 on Training is 30.43189010356732\n",
            "Epoch #2. Accuracy on batch 1738 on Training is 30.428766532489938\n",
            "Epoch #2. Accuracy on batch 1739 on Training is 30.427442528735632\n",
            "Batch Id 1740 is having training loss of 2145.49462890625\n",
            "22.715648651123047\n",
            "Epoch #2. Accuracy on batch 1740 on Training is 30.43329982768524\n",
            "Epoch #2. Accuracy on batch 1741 on Training is 30.435562571756602\n",
            "Epoch #2. Accuracy on batch 1742 on Training is 30.439615605278256\n",
            "Epoch #2. Accuracy on batch 1743 on Training is 30.434704701834864\n",
            "Epoch #2. Accuracy on batch 1744 on Training is 30.428008595988537\n",
            "Epoch #2. Accuracy on batch 1745 on Training is 30.432058991981673\n",
            "Epoch #2. Accuracy on batch 1746 on Training is 30.43073840870063\n",
            "Epoch #2. Accuracy on batch 1747 on Training is 30.429419336384438\n",
            "Epoch #2. Accuracy on batch 1748 on Training is 30.428101772441394\n",
            "Epoch #2. Accuracy on batch 1749 on Training is 30.430357142857144\n",
            "Epoch #2. Accuracy on batch 1750 on Training is 30.432609937178754\n",
            "Epoch #2. Accuracy on batch 1751 on Training is 30.43129280821918\n",
            "Epoch #2. Accuracy on batch 1752 on Training is 30.431759840273816\n",
            "Epoch #2. Accuracy on batch 1753 on Training is 30.432226339794756\n",
            "Epoch #2. Accuracy on batch 1754 on Training is 30.432692307692307\n",
            "Epoch #2. Accuracy on batch 1755 on Training is 30.43137813211845\n",
            "Epoch #2. Accuracy on batch 1756 on Training is 30.43184405236198\n",
            "Epoch #2. Accuracy on batch 1757 on Training is 30.43053185437998\n",
            "Epoch #2. Accuracy on batch 1758 on Training is 30.43277430358158\n",
            "Epoch #2. Accuracy on batch 1759 on Training is 30.44034090909091\n",
            "Batch Id 1760 is having training loss of 2156.3779296875\n",
            "332.4026794433594\n",
            "Epoch #2. Accuracy on batch 1760 on Training is 30.43725156161272\n",
            "Epoch #2. Accuracy on batch 1761 on Training is 30.43239216799092\n",
            "Epoch #2. Accuracy on batch 1762 on Training is 30.427538287010776\n",
            "Epoch #2. Accuracy on batch 1763 on Training is 30.42800453514739\n",
            "Epoch #2. Accuracy on batch 1764 on Training is 30.430240793201133\n",
            "Epoch #2. Accuracy on batch 1765 on Training is 30.44132219705549\n",
            "Epoch #2. Accuracy on batch 1766 on Training is 30.44708545557442\n",
            "Epoch #2. Accuracy on batch 1767 on Training is 30.451074660633484\n",
            "Epoch #2. Accuracy on batch 1768 on Training is 30.45152628603731\n",
            "Epoch #2. Accuracy on batch 1769 on Training is 30.448446327683616\n",
            "Epoch #2. Accuracy on batch 1770 on Training is 30.450663466967814\n",
            "Epoch #2. Accuracy on batch 1771 on Training is 30.445823927765236\n",
            "Epoch #2. Accuracy on batch 1772 on Training is 30.448040045121264\n",
            "Epoch #2. Accuracy on batch 1773 on Training is 30.444968996617813\n",
            "Epoch #2. Accuracy on batch 1774 on Training is 30.443661971830984\n",
            "Epoch #2. Accuracy on batch 1775 on Training is 30.44411599099099\n",
            "Epoch #2. Accuracy on batch 1776 on Training is 30.441052335396737\n",
            "Epoch #2. Accuracy on batch 1777 on Training is 30.436234533183352\n",
            "Epoch #2. Accuracy on batch 1778 on Training is 30.438448566610454\n",
            "Epoch #2. Accuracy on batch 1779 on Training is 30.44241573033708\n",
            "Batch Id 1780 is having training loss of 2156.74755859375\n",
            "39914.00390625\n",
            "Epoch #2. Accuracy on batch 1780 on Training is 30.43234138124649\n",
            "Epoch #2. Accuracy on batch 1781 on Training is 30.438061167227833\n",
            "Epoch #2. Accuracy on batch 1782 on Training is 30.442021873247334\n",
            "Epoch #2. Accuracy on batch 1783 on Training is 30.442474775784753\n",
            "Epoch #2. Accuracy on batch 1784 on Training is 30.439425770308123\n",
            "Epoch #2. Accuracy on batch 1785 on Training is 30.44687849944009\n",
            "Epoch #2. Accuracy on batch 1786 on Training is 30.449076664801343\n",
            "Epoch #2. Accuracy on batch 1787 on Training is 30.454767897091724\n",
            "Epoch #2. Accuracy on batch 1788 on Training is 30.45695919508105\n",
            "Epoch #2. Accuracy on batch 1789 on Training is 30.45914804469274\n",
            "Epoch #2. Accuracy on batch 1790 on Training is 30.45435510887772\n",
            "Epoch #2. Accuracy on batch 1791 on Training is 30.45654296875\n",
            "Epoch #2. Accuracy on batch 1792 on Training is 30.45175683212493\n",
            "Epoch #2. Accuracy on batch 1793 on Training is 30.452201783723524\n",
            "Epoch #2. Accuracy on batch 1794 on Training is 30.442200557103064\n",
            "Epoch #2. Accuracy on batch 1795 on Training is 30.439170378619153\n",
            "Epoch #2. Accuracy on batch 1796 on Training is 30.434404563160825\n",
            "Epoch #2. Accuracy on batch 1797 on Training is 30.433120133481648\n",
            "Epoch #2. Accuracy on batch 1798 on Training is 30.428362979433018\n",
            "Epoch #2. Accuracy on batch 1799 on Training is 30.427083333333332\n",
            "Batch Id 1800 is having training loss of 2154.516357421875\n",
            "16.958383560180664\n",
            "Epoch #2. Accuracy on batch 1800 on Training is 30.42059966685175\n",
            "Epoch #2. Accuracy on batch 1801 on Training is 30.412389012208656\n",
            "Epoch #2. Accuracy on batch 1802 on Training is 30.41285357737105\n",
            "Epoch #2. Accuracy on batch 1803 on Training is 30.42024667405765\n",
            "Epoch #2. Accuracy on batch 1804 on Training is 30.420706371191137\n",
            "Epoch #2. Accuracy on batch 1805 on Training is 30.426356589147286\n",
            "Epoch #2. Accuracy on batch 1806 on Training is 30.421624239070283\n",
            "Epoch #2. Accuracy on batch 1807 on Training is 30.422082411504423\n",
            "Epoch #2. Accuracy on batch 1808 on Training is 30.419085129906026\n",
            "Epoch #2. Accuracy on batch 1809 on Training is 30.414364640883978\n",
            "Epoch #2. Accuracy on batch 1810 on Training is 30.41482606294865\n",
            "Epoch #2. Accuracy on batch 1811 on Training is 30.41183774834437\n",
            "Epoch #2. Accuracy on batch 1812 on Training is 30.407129067843353\n",
            "Epoch #2. Accuracy on batch 1813 on Training is 30.4127618522602\n",
            "Epoch #2. Accuracy on batch 1814 on Training is 30.41322314049587\n",
            "Epoch #2. Accuracy on batch 1815 on Training is 30.410242290748897\n",
            "Epoch #2. Accuracy on batch 1816 on Training is 30.40898458998349\n",
            "Epoch #2. Accuracy on batch 1817 on Training is 30.40772827282728\n",
            "Epoch #2. Accuracy on batch 1818 on Training is 30.40647333699835\n",
            "Epoch #2. Accuracy on batch 1819 on Training is 30.400068681318682\n",
            "Batch Id 1820 is having training loss of 2140.262939453125\n",
            "27.209056854248047\n",
            "Epoch #2. Accuracy on batch 1820 on Training is 30.397103239978033\n",
            "Epoch #2. Accuracy on batch 1821 on Training is 30.399286498353458\n",
            "Epoch #2. Accuracy on batch 1822 on Training is 30.398038946791004\n",
            "Epoch #2. Accuracy on batch 1823 on Training is 30.388226425438596\n",
            "Epoch #2. Accuracy on batch 1824 on Training is 30.388698630136986\n",
            "Epoch #2. Accuracy on batch 1825 on Training is 30.387458926615555\n",
            "Epoch #2. Accuracy on batch 1826 on Training is 30.39306239737274\n",
            "Epoch #2. Accuracy on batch 1827 on Training is 30.388402625820568\n",
            "Epoch #2. Accuracy on batch 1828 on Training is 30.385456533624932\n",
            "Epoch #2. Accuracy on batch 1829 on Training is 30.37568306010929\n",
            "Epoch #2. Accuracy on batch 1830 on Training is 30.379574003276897\n",
            "Epoch #2. Accuracy on batch 1831 on Training is 30.37663755458515\n",
            "Epoch #2. Accuracy on batch 1832 on Training is 30.365180032733225\n",
            "Epoch #2. Accuracy on batch 1833 on Training is 30.365662486368592\n",
            "Epoch #2. Accuracy on batch 1834 on Training is 30.364441416893733\n",
            "Epoch #2. Accuracy on batch 1835 on Training is 30.36151960784314\n",
            "Epoch #2. Accuracy on batch 1836 on Training is 30.3654055525313\n",
            "Epoch #2. Accuracy on batch 1837 on Training is 30.367587051142547\n",
            "Epoch #2. Accuracy on batch 1838 on Training is 30.364668297988036\n",
            "Epoch #2. Accuracy on batch 1839 on Training is 30.35835597826087\n",
            "Batch Id 1840 is having training loss of 2137.391357421875\n",
            "32.818241119384766\n",
            "Epoch #2. Accuracy on batch 1840 on Training is 30.3520505160239\n",
            "Epoch #2. Accuracy on batch 1841 on Training is 30.354234527687296\n",
            "Epoch #2. Accuracy on batch 1842 on Training is 30.3564161692892\n",
            "Epoch #2. Accuracy on batch 1843 on Training is 30.358595444685466\n",
            "Epoch #2. Accuracy on batch 1844 on Training is 30.35569105691057\n",
            "Epoch #2. Accuracy on batch 1845 on Training is 30.351096966413866\n",
            "Epoch #2. Accuracy on batch 1846 on Training is 30.349891716296696\n",
            "Epoch #2. Accuracy on batch 1847 on Training is 30.34868777056277\n",
            "Epoch #2. Accuracy on batch 1848 on Training is 30.35424553812872\n",
            "Epoch #2. Accuracy on batch 1849 on Training is 30.35472972972973\n",
            "Epoch #2. Accuracy on batch 1850 on Training is 30.355213398163155\n",
            "Epoch #2. Accuracy on batch 1851 on Training is 30.350634449244062\n",
            "Epoch #2. Accuracy on batch 1852 on Training is 30.34774689692391\n",
            "Epoch #2. Accuracy on batch 1853 on Training is 30.346548004314993\n",
            "Epoch #2. Accuracy on batch 1854 on Training is 30.350404312668463\n",
            "Epoch #2. Accuracy on batch 1855 on Training is 30.352572737068964\n",
            "Epoch #2. Accuracy on batch 1856 on Training is 30.353056004308023\n",
            "Epoch #2. Accuracy on batch 1857 on Training is 30.355220667384284\n",
            "Epoch #2. Accuracy on batch 1858 on Training is 30.35402097902098\n",
            "Epoch #2. Accuracy on batch 1859 on Training is 30.356182795698924\n",
            "Batch Id 1860 is having training loss of 2123.499755859375\n",
            "58.17009735107422\n",
            "Epoch #2. Accuracy on batch 1860 on Training is 30.351625470177325\n",
            "Epoch #2. Accuracy on batch 1861 on Training is 30.352107948442534\n",
            "Epoch #2. Accuracy on batch 1862 on Training is 30.349235104669887\n",
            "Epoch #2. Accuracy on batch 1863 on Training is 30.351394849785407\n",
            "Epoch #2. Accuracy on batch 1864 on Training is 30.3485254691689\n",
            "Epoch #2. Accuracy on batch 1865 on Training is 30.35235798499464\n",
            "Epoch #2. Accuracy on batch 1866 on Training is 30.34279592929834\n",
            "Epoch #2. Accuracy on batch 1867 on Training is 30.339935760171308\n",
            "Epoch #2. Accuracy on batch 1868 on Training is 30.340422685928303\n",
            "Epoch #2. Accuracy on batch 1869 on Training is 30.34090909090909\n",
            "Epoch #2. Accuracy on batch 1870 on Training is 30.338054516301444\n",
            "Epoch #2. Accuracy on batch 1871 on Training is 30.331864316239315\n",
            "Epoch #2. Accuracy on batch 1872 on Training is 30.33235451147891\n",
            "Epoch #2. Accuracy on batch 1873 on Training is 30.324506403415153\n",
            "Epoch #2. Accuracy on batch 1874 on Training is 30.321666666666665\n",
            "Epoch #2. Accuracy on batch 1875 on Training is 30.315498400852878\n",
            "Epoch #2. Accuracy on batch 1876 on Training is 30.319326052210975\n",
            "Epoch #2. Accuracy on batch 1877 on Training is 30.31482960596379\n",
            "Epoch #2. Accuracy on batch 1878 on Training is 30.323642895156997\n",
            "Epoch #2. Accuracy on batch 1879 on Training is 30.32746010638298\n",
            "Batch Id 1880 is having training loss of 2152.481689453125\n",
            "14.38138198852539\n",
            "Epoch #2. Accuracy on batch 1880 on Training is 30.327950558213715\n",
            "Epoch #2. Accuracy on batch 1881 on Training is 30.326780021253985\n",
            "Epoch #2. Accuracy on batch 1882 on Training is 30.327270313329795\n",
            "Epoch #2. Accuracy on batch 1883 on Training is 30.332736199575372\n",
            "Epoch #2. Accuracy on batch 1884 on Training is 30.334880636604776\n",
            "Epoch #2. Accuracy on batch 1885 on Training is 30.332051961823964\n",
            "Epoch #2. Accuracy on batch 1886 on Training is 30.342474827768946\n",
            "Epoch #2. Accuracy on batch 1887 on Training is 30.347921080508474\n",
            "Epoch #2. Accuracy on batch 1888 on Training is 30.34178136580201\n",
            "Epoch #2. Accuracy on batch 1889 on Training is 30.342261904761905\n",
            "Epoch #2. Accuracy on batch 1890 on Training is 30.34604706504495\n",
            "Epoch #2. Accuracy on batch 1891 on Training is 30.34156976744186\n",
            "Epoch #2. Accuracy on batch 1892 on Training is 30.335446381405177\n",
            "Epoch #2. Accuracy on batch 1893 on Training is 30.33262935586061\n",
            "Epoch #2. Accuracy on batch 1894 on Training is 30.329815303430077\n",
            "Epoch #2. Accuracy on batch 1895 on Training is 30.33194883966245\n",
            "Epoch #2. Accuracy on batch 1896 on Training is 30.33078545071165\n",
            "Epoch #2. Accuracy on batch 1897 on Training is 30.327976817702844\n",
            "Epoch #2. Accuracy on batch 1898 on Training is 30.325171142706687\n",
            "Epoch #2. Accuracy on batch 1899 on Training is 30.324013157894736\n",
            "Batch Id 1900 is having training loss of 2200.68701171875\n",
            "12.502032279968262\n",
            "Epoch #2. Accuracy on batch 1900 on Training is 30.322856391372962\n",
            "Epoch #2. Accuracy on batch 1901 on Training is 30.315128811777075\n",
            "Epoch #2. Accuracy on batch 1902 on Training is 30.317262217551235\n",
            "Epoch #2. Accuracy on batch 1903 on Training is 30.317752100840337\n",
            "Epoch #2. Accuracy on batch 1904 on Training is 30.321522309711288\n",
            "Epoch #2. Accuracy on batch 1905 on Training is 30.320369884575026\n",
            "Epoch #2. Accuracy on batch 1906 on Training is 30.324134766649188\n",
            "Epoch #2. Accuracy on batch 1907 on Training is 30.32953354297694\n",
            "Epoch #2. Accuracy on batch 1908 on Training is 30.333289680460975\n",
            "Epoch #2. Accuracy on batch 1909 on Training is 30.337041884816752\n",
            "Epoch #2. Accuracy on batch 1910 on Training is 30.335884353741495\n",
            "Epoch #2. Accuracy on batch 1911 on Training is 30.334728033472803\n",
            "Epoch #2. Accuracy on batch 1912 on Training is 30.331939362258233\n",
            "Epoch #2. Accuracy on batch 1913 on Training is 30.332419017763847\n",
            "Epoch #2. Accuracy on batch 1914 on Training is 30.33289817232376\n",
            "Epoch #2. Accuracy on batch 1915 on Training is 30.32359081419624\n",
            "Epoch #2. Accuracy on batch 1916 on Training is 30.319183620239958\n",
            "Epoch #2. Accuracy on batch 1917 on Training is 30.318039624608968\n",
            "Epoch #2. Accuracy on batch 1918 on Training is 30.31852527357999\n",
            "Epoch #2. Accuracy on batch 1919 on Training is 30.322265625\n",
            "Batch Id 1920 is having training loss of 2194.562255859375\n",
            "20.50445556640625\n",
            "Epoch #2. Accuracy on batch 1920 on Training is 30.319495054659033\n",
            "Epoch #2. Accuracy on batch 1921 on Training is 30.321605098855358\n",
            "Epoch #2. Accuracy on batch 1922 on Training is 30.31558762350494\n",
            "Epoch #2. Accuracy on batch 1923 on Training is 30.322570166320165\n",
            "Epoch #2. Accuracy on batch 1924 on Training is 30.324675324675326\n",
            "Epoch #2. Accuracy on batch 1925 on Training is 30.333268431983385\n",
            "Epoch #2. Accuracy on batch 1926 on Training is 30.343474312402698\n",
            "Epoch #2. Accuracy on batch 1927 on Training is 30.348807053941908\n",
            "Epoch #2. Accuracy on batch 1928 on Training is 30.34765422498704\n",
            "Epoch #2. Accuracy on batch 1929 on Training is 30.343264248704664\n",
            "Epoch #2. Accuracy on batch 1930 on Training is 30.34049715173485\n",
            "Epoch #2. Accuracy on batch 1931 on Training is 30.33611542443064\n",
            "Epoch #2. Accuracy on batch 1932 on Training is 30.336588204862906\n",
            "Epoch #2. Accuracy on batch 1933 on Training is 30.345139607032056\n",
            "Epoch #2. Accuracy on batch 1934 on Training is 30.34560723514212\n",
            "Epoch #2. Accuracy on batch 1935 on Training is 30.342846074380166\n",
            "Epoch #2. Accuracy on batch 1936 on Training is 30.33847444501807\n",
            "Epoch #2. Accuracy on batch 1937 on Training is 30.334107327141382\n",
            "Epoch #2. Accuracy on batch 1938 on Training is 30.33457968024755\n",
            "Epoch #2. Accuracy on batch 1939 on Training is 30.33827319587629\n",
            "Batch Id 1940 is having training loss of 2241.89697265625\n",
            "80.9201431274414\n",
            "Epoch #2. Accuracy on batch 1940 on Training is 30.350012879958783\n",
            "Epoch #2. Accuracy on batch 1941 on Training is 30.34725798146241\n",
            "Epoch #2. Accuracy on batch 1942 on Training is 30.350939269171384\n",
            "Epoch #2. Accuracy on batch 1943 on Training is 30.349794238683128\n",
            "Epoch #2. Accuracy on batch 1944 on Training is 30.347043701799485\n",
            "Epoch #2. Accuracy on batch 1945 on Training is 30.345901849948614\n",
            "Epoch #2. Accuracy on batch 1946 on Training is 30.346366204417052\n",
            "Epoch #2. Accuracy on batch 1947 on Training is 30.343621663244353\n",
            "Epoch #2. Accuracy on batch 1948 on Training is 30.342483324781938\n",
            "Epoch #2. Accuracy on batch 1949 on Training is 30.33974358974359\n",
            "Epoch #2. Accuracy on batch 1950 on Training is 30.337006663249614\n",
            "Epoch #2. Accuracy on batch 1951 on Training is 30.33267161885246\n",
            "Epoch #2. Accuracy on batch 1952 on Training is 30.3347414234511\n",
            "Epoch #2. Accuracy on batch 1953 on Training is 30.333610542476972\n",
            "Epoch #2. Accuracy on batch 1954 on Training is 30.33407928388747\n",
            "Epoch #2. Accuracy on batch 1955 on Training is 30.33294989775051\n",
            "Epoch #2. Accuracy on batch 1956 on Training is 30.339805825242717\n",
            "Epoch #2. Accuracy on batch 1957 on Training is 30.341866700715016\n",
            "Epoch #2. Accuracy on batch 1958 on Training is 30.34073506891271\n",
            "Epoch #2. Accuracy on batch 1959 on Training is 30.34438775510204\n",
            "Batch Id 1960 is having training loss of 2219.671875\n",
            "45.18217468261719\n",
            "Epoch #2. Accuracy on batch 1960 on Training is 30.34484956654768\n",
            "Epoch #2. Accuracy on batch 1961 on Training is 30.348496432212027\n",
            "Epoch #2. Accuracy on batch 1962 on Training is 30.35054763117677\n",
            "Epoch #2. Accuracy on batch 1963 on Training is 30.352596741344197\n",
            "Epoch #2. Accuracy on batch 1964 on Training is 30.349872773536894\n",
            "Epoch #2. Accuracy on batch 1965 on Training is 30.34079348931841\n",
            "Epoch #2. Accuracy on batch 1966 on Training is 30.338078291814945\n",
            "Epoch #2. Accuracy on batch 1967 on Training is 30.335365853658537\n",
            "Epoch #2. Accuracy on batch 1968 on Training is 30.33106907059421\n",
            "Epoch #2. Accuracy on batch 1969 on Training is 30.32994923857868\n",
            "Epoch #2. Accuracy on batch 1970 on Training is 30.330416032470826\n",
            "Epoch #2. Accuracy on batch 1971 on Training is 30.3292976673428\n",
            "Epoch #2. Accuracy on batch 1972 on Training is 30.32818043588444\n",
            "Epoch #2. Accuracy on batch 1973 on Training is 30.338145896656535\n",
            "Epoch #2. Accuracy on batch 1974 on Training is 30.34018987341772\n",
            "Epoch #2. Accuracy on batch 1975 on Training is 30.33432439271255\n",
            "Epoch #2. Accuracy on batch 1976 on Training is 30.337948912493676\n",
            "Epoch #2. Accuracy on batch 1977 on Training is 30.339989888776543\n",
            "Epoch #2. Accuracy on batch 1978 on Training is 30.34044972208186\n",
            "Epoch #2. Accuracy on batch 1979 on Training is 30.34090909090909\n",
            "Batch Id 1980 is having training loss of 2233.710205078125\n",
            "2590.1396484375\n",
            "Epoch #2. Accuracy on batch 1980 on Training is 30.33663553760727\n",
            "Epoch #2. Accuracy on batch 1981 on Training is 30.341826437941474\n",
            "Epoch #2. Accuracy on batch 1982 on Training is 30.337556732223902\n",
            "Epoch #2. Accuracy on batch 1983 on Training is 30.339591733870968\n",
            "Epoch #2. Accuracy on batch 1984 on Training is 30.34005037783375\n",
            "Epoch #2. Accuracy on batch 1985 on Training is 30.346802618328297\n",
            "Epoch #2. Accuracy on batch 1986 on Training is 30.35040261701057\n",
            "Epoch #2. Accuracy on batch 1987 on Training is 30.35085513078471\n",
            "Epoch #2. Accuracy on batch 1988 on Training is 30.352878330819507\n",
            "Epoch #2. Accuracy on batch 1989 on Training is 30.350188442211056\n",
            "Epoch #2. Accuracy on batch 1990 on Training is 30.35220994475138\n",
            "Epoch #2. Accuracy on batch 1991 on Training is 30.355798192771083\n",
            "Epoch #2. Accuracy on batch 1992 on Training is 30.356246864024083\n",
            "Epoch #2. Accuracy on batch 1993 on Training is 30.351993480441323\n",
            "Epoch #2. Accuracy on batch 1994 on Training is 30.355576441102755\n",
            "Epoch #2. Accuracy on batch 1995 on Training is 30.35759018036072\n",
            "Epoch #2. Accuracy on batch 1996 on Training is 30.350212819228844\n",
            "Epoch #2. Accuracy on batch 1997 on Training is 30.336586586586588\n",
            "Epoch #2. Accuracy on batch 1998 on Training is 30.340170085042523\n",
            "Epoch #2. Accuracy on batch 1999 on Training is 30.3421875\n",
            "Batch Id 2000 is having training loss of 2227.57373046875\n",
            "24.335290908813477\n",
            "Epoch #2. Accuracy on batch 2000 on Training is 30.337956021989005\n",
            "Epoch #2. Accuracy on batch 2001 on Training is 30.332167832167833\n",
            "Epoch #2. Accuracy on batch 2002 on Training is 30.340426859710433\n",
            "Epoch #2. Accuracy on batch 2003 on Training is 30.339321357285428\n",
            "Epoch #2. Accuracy on batch 2004 on Training is 30.3428927680798\n",
            "Epoch #2. Accuracy on batch 2005 on Training is 30.341787138584248\n",
            "Epoch #2. Accuracy on batch 2006 on Training is 30.340682610861982\n",
            "Epoch #2. Accuracy on batch 2007 on Training is 30.342691733067728\n",
            "Epoch #2. Accuracy on batch 2008 on Training is 30.347809855649576\n",
            "Epoch #2. Accuracy on batch 2009 on Training is 30.345149253731343\n",
            "Epoch #2. Accuracy on batch 2010 on Training is 30.351815017404277\n",
            "Epoch #2. Accuracy on batch 2011 on Training is 30.344495526838966\n",
            "Epoch #2. Accuracy on batch 2012 on Training is 30.344945355191257\n",
            "Epoch #2. Accuracy on batch 2013 on Training is 30.345394736842106\n",
            "Epoch #2. Accuracy on batch 2014 on Training is 30.345843672456574\n",
            "Epoch #2. Accuracy on batch 2015 on Training is 30.344742063492063\n",
            "Epoch #2. Accuracy on batch 2016 on Training is 30.346740208230045\n",
            "Epoch #2. Accuracy on batch 2017 on Training is 30.347187809712587\n",
            "Epoch #2. Accuracy on batch 2018 on Training is 30.352278355621596\n",
            "Epoch #2. Accuracy on batch 2019 on Training is 30.35272277227723\n",
            "Batch Id 2020 is having training loss of 2231.381591796875\n",
            "2677.0205078125\n",
            "Epoch #2. Accuracy on batch 2020 on Training is 30.360898070262248\n",
            "Epoch #2. Accuracy on batch 2021 on Training is 30.35670128585559\n",
            "Epoch #2. Accuracy on batch 2022 on Training is 30.35559812160158\n",
            "Epoch #2. Accuracy on batch 2023 on Training is 30.366847826086957\n",
            "Epoch #2. Accuracy on batch 2024 on Training is 30.373456790123456\n",
            "Epoch #2. Accuracy on batch 2025 on Training is 30.37851678183613\n",
            "Epoch #2. Accuracy on batch 2026 on Training is 30.375863344844596\n",
            "Epoch #2. Accuracy on batch 2027 on Training is 30.380917159763314\n",
            "Epoch #2. Accuracy on batch 2028 on Training is 30.381345490389354\n",
            "Epoch #2. Accuracy on batch 2029 on Training is 30.383312807881772\n",
            "Epoch #2. Accuracy on batch 2030 on Training is 30.382200886262925\n",
            "Epoch #2. Accuracy on batch 2031 on Training is 30.388779527559056\n",
            "Epoch #2. Accuracy on batch 2032 on Training is 30.390740285292672\n",
            "Epoch #2. Accuracy on batch 2033 on Training is 30.389626352015732\n",
            "Epoch #2. Accuracy on batch 2034 on Training is 30.388513513513512\n",
            "Epoch #2. Accuracy on batch 2035 on Training is 30.382797151277014\n",
            "Epoch #2. Accuracy on batch 2036 on Training is 30.381688757977418\n",
            "Epoch #2. Accuracy on batch 2037 on Training is 30.385181550539745\n",
            "Epoch #2. Accuracy on batch 2038 on Training is 30.38713830308975\n",
            "Epoch #2. Accuracy on batch 2039 on Training is 30.387561274509803\n",
            "Batch Id 2040 is having training loss of 2244.94921875\n",
            "1531.3878173828125\n",
            "Epoch #2. Accuracy on batch 2040 on Training is 30.39104605585497\n",
            "Epoch #2. Accuracy on batch 2041 on Training is 30.391466699314396\n",
            "Epoch #2. Accuracy on batch 2042 on Training is 30.39647577092511\n",
            "Epoch #2. Accuracy on batch 2043 on Training is 30.401479941291583\n",
            "Epoch #2. Accuracy on batch 2044 on Training is 30.4049511002445\n",
            "Epoch #2. Accuracy on batch 2045 on Training is 30.40078201368524\n",
            "Epoch #2. Accuracy on batch 2046 on Training is 30.40730337078652\n",
            "Epoch #2. Accuracy on batch 2047 on Training is 30.40771484375\n",
            "Epoch #2. Accuracy on batch 2048 on Training is 30.405075646656904\n",
            "Epoch #2. Accuracy on batch 2049 on Training is 30.411585365853657\n",
            "Epoch #2. Accuracy on batch 2050 on Training is 30.410470502194052\n",
            "Epoch #2. Accuracy on batch 2051 on Training is 30.4093567251462\n",
            "Epoch #2. Accuracy on batch 2052 on Training is 30.40824403312226\n",
            "Epoch #2. Accuracy on batch 2053 on Training is 30.40561100292113\n",
            "Epoch #2. Accuracy on batch 2054 on Training is 30.40450121654501\n",
            "Epoch #2. Accuracy on batch 2055 on Training is 30.401872568093385\n",
            "Epoch #2. Accuracy on batch 2056 on Training is 30.400765678172096\n",
            "Epoch #2. Accuracy on batch 2057 on Training is 30.404215257531582\n",
            "Epoch #2. Accuracy on batch 2058 on Training is 30.40310830500243\n",
            "Epoch #2. Accuracy on batch 2059 on Training is 30.403519417475728\n",
            "Batch Id 2060 is having training loss of 2231.92236328125\n",
            "32.560455322265625\n",
            "Epoch #2. Accuracy on batch 2060 on Training is 30.402413876758853\n",
            "Epoch #2. Accuracy on batch 2061 on Training is 30.401309408341415\n",
            "Epoch #2. Accuracy on batch 2062 on Training is 30.39717644207465\n",
            "Epoch #2. Accuracy on batch 2063 on Training is 30.39001937984496\n",
            "Epoch #2. Accuracy on batch 2064 on Training is 30.391949152542374\n",
            "Epoch #2. Accuracy on batch 2065 on Training is 30.392364472410456\n",
            "Epoch #2. Accuracy on batch 2066 on Training is 30.397314949201743\n",
            "Epoch #2. Accuracy on batch 2067 on Training is 30.39470502901354\n",
            "Epoch #2. Accuracy on batch 2068 on Training is 30.396628806186563\n",
            "Epoch #2. Accuracy on batch 2069 on Training is 30.394021739130434\n",
            "Epoch #2. Accuracy on batch 2070 on Training is 30.38839932399807\n",
            "Epoch #2. Accuracy on batch 2071 on Training is 30.38429054054054\n",
            "Epoch #2. Accuracy on batch 2072 on Training is 30.37717076700434\n",
            "Epoch #2. Accuracy on batch 2073 on Training is 30.374578109932497\n",
            "Epoch #2. Accuracy on batch 2074 on Training is 30.36897590361446\n",
            "Epoch #2. Accuracy on batch 2075 on Training is 30.361873795761078\n",
            "Epoch #2. Accuracy on batch 2076 on Training is 30.366815117958595\n",
            "Epoch #2. Accuracy on batch 2077 on Training is 30.370247834456208\n",
            "Epoch #2. Accuracy on batch 2078 on Training is 30.370670995670995\n",
            "Epoch #2. Accuracy on batch 2079 on Training is 30.368088942307693\n",
            "Batch Id 2080 is having training loss of 2223.12841796875\n",
            "25.912324905395508\n",
            "Epoch #2. Accuracy on batch 2080 on Training is 30.368512734262374\n",
            "Epoch #2. Accuracy on batch 2081 on Training is 30.370437079731026\n",
            "Epoch #2. Accuracy on batch 2082 on Training is 30.370859337494\n",
            "Epoch #2. Accuracy on batch 2083 on Training is 30.36828214971209\n",
            "Epoch #2. Accuracy on batch 2084 on Training is 30.368705035971225\n",
            "Epoch #2. Accuracy on batch 2085 on Training is 30.364633269415148\n",
            "Epoch #2. Accuracy on batch 2086 on Training is 30.36954959271682\n",
            "Epoch #2. Accuracy on batch 2087 on Training is 30.36548132183908\n",
            "Epoch #2. Accuracy on batch 2088 on Training is 30.364408808042125\n",
            "Epoch #2. Accuracy on batch 2089 on Training is 30.369318181818183\n",
            "Epoch #2. Accuracy on batch 2090 on Training is 30.368244858919176\n",
            "Epoch #2. Accuracy on batch 2091 on Training is 30.365678776290633\n",
            "Epoch #2. Accuracy on batch 2092 on Training is 30.364608217869087\n",
            "Epoch #2. Accuracy on batch 2093 on Training is 30.36652340019102\n",
            "Epoch #2. Accuracy on batch 2094 on Training is 30.374403341288783\n",
            "Epoch #2. Accuracy on batch 2095 on Training is 30.37482108778626\n",
            "Epoch #2. Accuracy on batch 2096 on Training is 30.370767763471626\n",
            "Epoch #2. Accuracy on batch 2097 on Training is 30.365228789323165\n",
            "Epoch #2. Accuracy on batch 2098 on Training is 30.36565030967127\n",
            "Epoch #2. Accuracy on batch 2099 on Training is 30.37202380952381\n",
            "Batch Id 2100 is having training loss of 2220.855224609375\n",
            "16.247886657714844\n",
            "Epoch #2. Accuracy on batch 2100 on Training is 30.36797953355545\n",
            "Epoch #2. Accuracy on batch 2101 on Training is 30.35947906755471\n",
            "Epoch #2. Accuracy on batch 2102 on Training is 30.359902520209225\n",
            "Epoch #2. Accuracy on batch 2103 on Training is 30.357355038022813\n",
            "Epoch #2. Accuracy on batch 2104 on Training is 30.359263657957246\n",
            "Epoch #2. Accuracy on batch 2105 on Training is 30.35968660968661\n",
            "Epoch #2. Accuracy on batch 2106 on Training is 30.360109159943047\n",
            "Epoch #2. Accuracy on batch 2107 on Training is 30.36201375711575\n",
            "Epoch #2. Accuracy on batch 2108 on Training is 30.36688003793267\n",
            "Epoch #2. Accuracy on batch 2109 on Training is 30.36729857819905\n",
            "Epoch #2. Accuracy on batch 2110 on Training is 30.363275698720987\n",
            "Epoch #2. Accuracy on batch 2111 on Training is 30.363695549242426\n",
            "Epoch #2. Accuracy on batch 2112 on Training is 30.36115712257454\n",
            "Epoch #2. Accuracy on batch 2113 on Training is 30.3586210974456\n",
            "Epoch #2. Accuracy on batch 2114 on Training is 30.36052009456265\n",
            "Epoch #2. Accuracy on batch 2115 on Training is 30.355033081285445\n",
            "Epoch #2. Accuracy on batch 2116 on Training is 30.353979688238073\n",
            "Epoch #2. Accuracy on batch 2117 on Training is 30.35882908404155\n",
            "Epoch #2. Accuracy on batch 2118 on Training is 30.35924964605946\n",
            "Epoch #2. Accuracy on batch 2119 on Training is 30.35377358490566\n",
            "Batch Id 2120 is having training loss of 2211.172607421875\n",
            "19.85719108581543\n",
            "Epoch #2. Accuracy on batch 2120 on Training is 30.354196133899105\n",
            "Epoch #2. Accuracy on batch 2121 on Training is 30.351672950047124\n",
            "Epoch #2. Accuracy on batch 2122 on Training is 30.362399905793687\n",
            "Epoch #2. Accuracy on batch 2123 on Training is 30.36281779661017\n",
            "Epoch #2. Accuracy on batch 2124 on Training is 30.361764705882354\n",
            "Epoch #2. Accuracy on batch 2125 on Training is 30.35777281279398\n",
            "Epoch #2. Accuracy on batch 2126 on Training is 30.356723084156087\n",
            "Epoch #2. Accuracy on batch 2127 on Training is 30.360079887218046\n",
            "Epoch #2. Accuracy on batch 2128 on Training is 30.35903006106153\n",
            "Epoch #2. Accuracy on batch 2129 on Training is 30.363849765258216\n",
            "Epoch #2. Accuracy on batch 2130 on Training is 30.36133270764899\n",
            "Epoch #2. Accuracy on batch 2131 on Training is 30.363215290806753\n",
            "Epoch #2. Accuracy on batch 2132 on Training is 30.365096108766995\n",
            "Epoch #2. Accuracy on batch 2133 on Training is 30.366975164011247\n",
            "Epoch #2. Accuracy on batch 2134 on Training is 30.37324355971897\n",
            "Epoch #2. Accuracy on batch 2135 on Training is 30.375117041198504\n",
            "Epoch #2. Accuracy on batch 2136 on Training is 30.37698876930276\n",
            "Epoch #2. Accuracy on batch 2137 on Training is 30.37008886810103\n",
            "Epoch #2. Accuracy on batch 2138 on Training is 30.36611734455353\n",
            "Epoch #2. Accuracy on batch 2139 on Training is 30.367990654205606\n",
            "Batch Id 2140 is having training loss of 2213.66064453125\n",
            "408.4072265625\n",
            "Epoch #2. Accuracy on batch 2140 on Training is 30.364023820644558\n",
            "Epoch #2. Accuracy on batch 2141 on Training is 30.36297852474323\n",
            "Epoch #2. Accuracy on batch 2142 on Training is 30.35318478768082\n",
            "Epoch #2. Accuracy on batch 2143 on Training is 30.355060634328357\n",
            "Epoch #2. Accuracy on batch 2144 on Training is 30.34965034965035\n",
            "Epoch #2. Accuracy on batch 2145 on Training is 30.347157502329917\n",
            "Epoch #2. Accuracy on batch 2146 on Training is 30.35194457382394\n",
            "Epoch #2. Accuracy on batch 2147 on Training is 30.349452979515828\n",
            "Epoch #2. Accuracy on batch 2148 on Training is 30.342601209865055\n",
            "Epoch #2. Accuracy on batch 2149 on Training is 30.338662790697676\n",
            "Epoch #2. Accuracy on batch 2150 on Training is 30.336180846118083\n",
            "Epoch #2. Accuracy on batch 2151 on Training is 30.33515334572491\n",
            "Epoch #2. Accuracy on batch 2152 on Training is 30.33557826288899\n",
            "Epoch #2. Accuracy on batch 2153 on Training is 30.330199628597956\n",
            "Epoch #2. Accuracy on batch 2154 on Training is 30.334976798143853\n",
            "Epoch #2. Accuracy on batch 2155 on Training is 30.336850649350648\n",
            "Epoch #2. Accuracy on batch 2156 on Training is 30.332927677329625\n",
            "Epoch #2. Accuracy on batch 2157 on Training is 30.333352641334567\n",
            "Epoch #2. Accuracy on batch 2158 on Training is 30.330882352941178\n",
            "Epoch #2. Accuracy on batch 2159 on Training is 30.33130787037037\n",
            "Batch Id 2160 is having training loss of 2220.878173828125\n",
            "27.503143310546875\n",
            "Epoch #2. Accuracy on batch 2160 on Training is 30.327394724664508\n",
            "Epoch #2. Accuracy on batch 2161 on Training is 30.332157724329324\n",
            "Epoch #2. Accuracy on batch 2162 on Training is 30.32535829865927\n",
            "Epoch #2. Accuracy on batch 2163 on Training is 30.32434149722736\n",
            "Epoch #2. Accuracy on batch 2164 on Training is 30.323325635103927\n",
            "Epoch #2. Accuracy on batch 2165 on Training is 30.32375346260388\n",
            "Epoch #2. Accuracy on batch 2166 on Training is 30.324180895246887\n",
            "Epoch #2. Accuracy on batch 2167 on Training is 30.333256457564577\n",
            "Epoch #2. Accuracy on batch 2168 on Training is 30.336560627017057\n",
            "Epoch #2. Accuracy on batch 2169 on Training is 30.331221198156683\n",
            "Epoch #2. Accuracy on batch 2170 on Training is 30.334523261169966\n",
            "Epoch #2. Accuracy on batch 2171 on Training is 30.334944751381215\n",
            "Epoch #2. Accuracy on batch 2172 on Training is 30.331051541647494\n",
            "Epoch #2. Accuracy on batch 2173 on Training is 30.32572447102116\n",
            "Epoch #2. Accuracy on batch 2174 on Training is 30.326149425287355\n",
            "Epoch #2. Accuracy on batch 2175 on Training is 30.32082950367647\n",
            "Epoch #2. Accuracy on batch 2176 on Training is 30.32843362425356\n",
            "Epoch #2. Accuracy on batch 2177 on Training is 30.324552341597798\n",
            "Epoch #2. Accuracy on batch 2178 on Training is 30.323542909591556\n",
            "Epoch #2. Accuracy on batch 2179 on Training is 30.32540137614679\n",
            "Batch Id 2180 is having training loss of 2269.029541015625\n",
            "25.734174728393555\n",
            "Epoch #2. Accuracy on batch 2180 on Training is 30.324392480513527\n",
            "Epoch #2. Accuracy on batch 2181 on Training is 30.327681026581118\n",
            "Epoch #2. Accuracy on batch 2182 on Training is 30.329535043518096\n",
            "Epoch #2. Accuracy on batch 2183 on Training is 30.338541666666668\n",
            "Epoch #2. Accuracy on batch 2184 on Training is 30.337528604118994\n",
            "Epoch #2. Accuracy on batch 2185 on Training is 30.342234675205855\n",
            "Epoch #2. Accuracy on batch 2186 on Training is 30.34550754458162\n",
            "Epoch #2. Accuracy on batch 2187 on Training is 30.341636197440586\n",
            "Epoch #2. Accuracy on batch 2188 on Training is 30.337768387391503\n",
            "Epoch #2. Accuracy on batch 2189 on Training is 30.33818493150685\n",
            "Epoch #2. Accuracy on batch 2190 on Training is 30.33860109539023\n",
            "Epoch #2. Accuracy on batch 2191 on Training is 30.331888686131386\n",
            "Epoch #2. Accuracy on batch 2192 on Training is 30.330882352941178\n",
            "Epoch #2. Accuracy on batch 2193 on Training is 30.332725615314494\n",
            "Epoch #2. Accuracy on batch 2194 on Training is 30.333143507972665\n",
            "Epoch #2. Accuracy on batch 2195 on Training is 30.32929189435337\n",
            "Epoch #2. Accuracy on batch 2196 on Training is 30.33397815202549\n",
            "Epoch #2. Accuracy on batch 2197 on Training is 30.331551410373066\n",
            "Epoch #2. Accuracy on batch 2198 on Training is 30.333390177353344\n",
            "Epoch #2. Accuracy on batch 2199 on Training is 30.328125\n",
            "Batch Id 2200 is having training loss of 2249.6396484375\n",
            "8.89972972869873\n",
            "Epoch #2. Accuracy on batch 2200 on Training is 30.3313834620627\n",
            "Epoch #2. Accuracy on batch 2201 on Training is 30.326123978201636\n",
            "Epoch #2. Accuracy on batch 2202 on Training is 30.32796187017703\n",
            "Epoch #2. Accuracy on batch 2203 on Training is 30.328380217785845\n",
            "Epoch #2. Accuracy on batch 2204 on Training is 30.330215419501133\n",
            "Epoch #2. Accuracy on batch 2205 on Training is 30.33204895738894\n",
            "Epoch #2. Accuracy on batch 2206 on Training is 30.336712732215677\n",
            "Epoch #2. Accuracy on batch 2207 on Training is 30.328634510869566\n",
            "Epoch #2. Accuracy on batch 2208 on Training is 30.330466274332277\n",
            "Epoch #2. Accuracy on batch 2209 on Training is 30.32522624434389\n",
            "Epoch #2. Accuracy on batch 2210 on Training is 30.329884667571235\n",
            "Epoch #2. Accuracy on batch 2211 on Training is 30.323236889692584\n",
            "Epoch #2. Accuracy on batch 2212 on Training is 30.325067781292365\n",
            "Epoch #2. Accuracy on batch 2213 on Training is 30.32125112917796\n",
            "Epoch #2. Accuracy on batch 2214 on Training is 30.323081264108353\n",
            "Epoch #2. Accuracy on batch 2215 on Training is 30.32067915162455\n",
            "Epoch #2. Accuracy on batch 2216 on Training is 30.32391745602165\n",
            "Epoch #2. Accuracy on batch 2217 on Training is 30.325743913435527\n",
            "Epoch #2. Accuracy on batch 2218 on Training is 30.323343848580443\n",
            "Epoch #2. Accuracy on batch 2219 on Training is 30.32376126126126\n",
            "Batch Id 2220 is having training loss of 2249.451416015625\n",
            "21.561574935913086\n",
            "Epoch #2. Accuracy on batch 2220 on Training is 30.32558532192706\n",
            "Epoch #2. Accuracy on batch 2221 on Training is 30.327407740774078\n",
            "Epoch #2. Accuracy on batch 2222 on Training is 30.322199730094468\n",
            "Epoch #2. Accuracy on batch 2223 on Training is 30.3240220323741\n",
            "Epoch #2. Accuracy on batch 2224 on Training is 30.32443820224719\n",
            "Epoch #2. Accuracy on batch 2225 on Training is 30.32625786163522\n",
            "Epoch #2. Accuracy on batch 2226 on Training is 30.321059721598562\n",
            "Epoch #2. Accuracy on batch 2227 on Training is 30.31165843806104\n",
            "Epoch #2. Accuracy on batch 2228 on Training is 30.313481381785554\n",
            "Epoch #2. Accuracy on batch 2229 on Training is 30.31670403587444\n",
            "Epoch #2. Accuracy on batch 2230 on Training is 30.310118780815777\n",
            "Epoch #2. Accuracy on batch 2231 on Training is 30.31053987455197\n",
            "Epoch #2. Accuracy on batch 2232 on Training is 30.310960591133004\n",
            "Epoch #2. Accuracy on batch 2233 on Training is 30.315577439570276\n",
            "Epoch #2. Accuracy on batch 2234 on Training is 30.31459731543624\n",
            "Epoch #2. Accuracy on batch 2235 on Training is 30.3108228980322\n",
            "Epoch #2. Accuracy on batch 2236 on Training is 30.308448815377737\n",
            "Epoch #2. Accuracy on batch 2237 on Training is 30.307473190348524\n",
            "Epoch #2. Accuracy on batch 2238 on Training is 30.309289861545334\n",
            "Epoch #2. Accuracy on batch 2239 on Training is 30.305524553571427\n",
            "Batch Id 2240 is having training loss of 2246.976806640625\n",
            "18.38497543334961\n",
            "Epoch #2. Accuracy on batch 2240 on Training is 30.30594600624721\n",
            "Epoch #2. Accuracy on batch 2241 on Training is 30.309154772524533\n",
            "Epoch #2. Accuracy on batch 2242 on Training is 30.306787784217565\n",
            "Epoch #2. Accuracy on batch 2243 on Training is 30.30581550802139\n",
            "Epoch #2. Accuracy on batch 2244 on Training is 30.306236080178174\n",
            "Epoch #2. Accuracy on batch 2245 on Training is 30.30804764024933\n",
            "Epoch #2. Accuracy on batch 2246 on Training is 30.3084668446818\n",
            "Epoch #2. Accuracy on batch 2247 on Training is 30.306105427046262\n",
            "Epoch #2. Accuracy on batch 2248 on Training is 30.302356602934637\n",
            "Epoch #2. Accuracy on batch 2249 on Training is 30.304166666666667\n",
            "Epoch #2. Accuracy on batch 2250 on Training is 30.30181030653043\n",
            "Epoch #2. Accuracy on batch 2251 on Training is 30.305006660746002\n",
            "Epoch #2. Accuracy on batch 2252 on Training is 30.306813138038173\n",
            "Epoch #2. Accuracy on batch 2253 on Training is 30.30723158828749\n",
            "Epoch #2. Accuracy on batch 2254 on Training is 30.29517738359202\n",
            "Epoch #2. Accuracy on batch 2255 on Training is 30.291445035460992\n",
            "Epoch #2. Accuracy on batch 2256 on Training is 30.287715994683207\n",
            "Epoch #2. Accuracy on batch 2257 on Training is 30.293678033658104\n",
            "Epoch #2. Accuracy on batch 2258 on Training is 30.291334661354583\n",
            "Epoch #2. Accuracy on batch 2259 on Training is 30.29728982300885\n",
            "Batch Id 2260 is having training loss of 2248.587646484375\n",
            "27216.24609375\n",
            "Epoch #2. Accuracy on batch 2260 on Training is 30.294946926138877\n",
            "Epoch #2. Accuracy on batch 2261 on Training is 30.295369142351902\n",
            "Epoch #2. Accuracy on batch 2262 on Training is 30.29855280600972\n",
            "Epoch #2. Accuracy on batch 2263 on Training is 30.298973056537104\n",
            "Epoch #2. Accuracy on batch 2264 on Training is 30.30077262693157\n",
            "Epoch #2. Accuracy on batch 2265 on Training is 30.29843336275375\n",
            "Epoch #2. Accuracy on batch 2266 on Training is 30.298853109836788\n",
            "Epoch #2. Accuracy on batch 2267 on Training is 30.29513888888889\n",
            "Epoch #2. Accuracy on batch 2268 on Training is 30.301068752754517\n",
            "Epoch #2. Accuracy on batch 2269 on Training is 30.305616740088105\n",
            "Epoch #2. Accuracy on batch 2270 on Training is 30.30603258476442\n",
            "Epoch #2. Accuracy on batch 2271 on Training is 30.303697183098592\n",
            "Epoch #2. Accuracy on batch 2272 on Training is 30.30548834139903\n",
            "Epoch #2. Accuracy on batch 2273 on Training is 30.3059036939314\n",
            "Epoch #2. Accuracy on batch 2274 on Training is 30.304945054945055\n",
            "Epoch #2. Accuracy on batch 2275 on Training is 30.309479349736378\n",
            "Epoch #2. Accuracy on batch 2276 on Training is 30.314009661835748\n",
            "Epoch #2. Accuracy on batch 2277 on Training is 30.317164179104477\n",
            "Epoch #2. Accuracy on batch 2278 on Training is 30.31483106625713\n",
            "Epoch #2. Accuracy on batch 2279 on Training is 30.30701754385965\n",
            "Batch Id 2280 is having training loss of 2245.173583984375\n",
            "31.033893585205078\n",
            "Epoch #2. Accuracy on batch 2280 on Training is 30.310170977641384\n",
            "Epoch #2. Accuracy on batch 2281 on Training is 30.31879929886065\n",
            "Epoch #2. Accuracy on batch 2282 on Training is 30.326051248357423\n",
            "Epoch #2. Accuracy on batch 2283 on Training is 30.327823992994745\n",
            "Epoch #2. Accuracy on batch 2284 on Training is 30.332330415754925\n",
            "Epoch #2. Accuracy on batch 2285 on Training is 30.33409886264217\n",
            "Epoch #2. Accuracy on batch 2286 on Training is 30.335865763008307\n",
            "Epoch #2. Accuracy on batch 2287 on Training is 30.333533653846153\n",
            "Epoch #2. Accuracy on batch 2288 on Training is 30.33393403232853\n",
            "Epoch #2. Accuracy on batch 2289 on Training is 30.334334061135372\n",
            "Epoch #2. Accuracy on batch 2290 on Training is 30.32927760803143\n",
            "Epoch #2. Accuracy on batch 2291 on Training is 30.322862129144852\n",
            "Epoch #2. Accuracy on batch 2292 on Training is 30.321903619712167\n",
            "Epoch #2. Accuracy on batch 2293 on Training is 30.322308195292067\n",
            "Epoch #2. Accuracy on batch 2294 on Training is 30.324074074074073\n",
            "Epoch #2. Accuracy on batch 2295 on Training is 30.321755226480835\n",
            "Epoch #2. Accuracy on batch 2296 on Training is 30.319438397910318\n",
            "Epoch #2. Accuracy on batch 2297 on Training is 30.3157637075718\n",
            "Epoch #2. Accuracy on batch 2298 on Training is 30.31888864723793\n",
            "Epoch #2. Accuracy on batch 2299 on Training is 30.324728260869566\n",
            "Batch Id 2300 is having training loss of 2231.8759765625\n",
            "12311.5185546875\n",
            "Epoch #2. Accuracy on batch 2300 on Training is 30.321056062581487\n",
            "Epoch #2. Accuracy on batch 2301 on Training is 30.322817115551693\n",
            "Epoch #2. Accuracy on batch 2302 on Training is 30.324576639166306\n",
            "Epoch #2. Accuracy on batch 2303 on Training is 30.32769097222222\n",
            "Epoch #2. Accuracy on batch 2304 on Training is 30.32537960954447\n",
            "Epoch #2. Accuracy on batch 2305 on Training is 30.327135732870772\n",
            "Epoch #2. Accuracy on batch 2306 on Training is 30.328890333766797\n",
            "Epoch #2. Accuracy on batch 2307 on Training is 30.330643414211437\n",
            "Epoch #2. Accuracy on batch 2308 on Training is 30.337808575140752\n",
            "Epoch #2. Accuracy on batch 2309 on Training is 30.34090909090909\n",
            "Epoch #2. Accuracy on batch 2310 on Training is 30.33859800951969\n",
            "Epoch #2. Accuracy on batch 2311 on Training is 30.337640570934255\n",
            "Epoch #2. Accuracy on batch 2312 on Training is 30.342088197146563\n",
            "Epoch #2. Accuracy on batch 2313 on Training is 30.334377700950736\n",
            "Epoch #2. Accuracy on batch 2314 on Training is 30.33342332613391\n",
            "Epoch #2. Accuracy on batch 2315 on Training is 30.32977115716753\n",
            "Epoch #2. Accuracy on batch 2316 on Training is 30.334214501510573\n",
            "Epoch #2. Accuracy on batch 2317 on Training is 30.333261432269197\n",
            "Epoch #2. Accuracy on batch 2318 on Training is 30.329614057783527\n",
            "Epoch #2. Accuracy on batch 2319 on Training is 30.320581896551722\n",
            "Batch Id 2320 is having training loss of 2241.79150390625\n",
            "26.472431182861328\n",
            "Epoch #2. Accuracy on batch 2320 on Training is 30.320982335200345\n",
            "Epoch #2. Accuracy on batch 2321 on Training is 30.318690783807064\n",
            "Epoch #2. Accuracy on batch 2322 on Training is 30.320436934997847\n",
            "Epoch #2. Accuracy on batch 2323 on Training is 30.31949225473322\n",
            "Epoch #2. Accuracy on batch 2324 on Training is 30.322580645161292\n",
            "Epoch #2. Accuracy on batch 2325 on Training is 30.321635855546003\n",
            "Epoch #2. Accuracy on batch 2326 on Training is 30.31934894714224\n",
            "Epoch #2. Accuracy on batch 2327 on Training is 30.321091065292098\n",
            "Epoch #2. Accuracy on batch 2328 on Training is 30.325515242593386\n",
            "Epoch #2. Accuracy on batch 2329 on Training is 30.325912017167383\n",
            "Epoch #2. Accuracy on batch 2330 on Training is 30.324967824967825\n",
            "Epoch #2. Accuracy on batch 2331 on Training is 30.326704545454547\n",
            "Epoch #2. Accuracy on batch 2332 on Training is 30.32576082297471\n",
            "Epoch #2. Accuracy on batch 2333 on Training is 30.323479005998287\n",
            "Epoch #2. Accuracy on batch 2334 on Training is 30.32789079229122\n",
            "Epoch #2. Accuracy on batch 2335 on Training is 30.33096104452055\n",
            "Epoch #2. Accuracy on batch 2336 on Training is 30.330017115960633\n",
            "Epoch #2. Accuracy on batch 2337 on Training is 30.329073994867407\n",
            "Epoch #2. Accuracy on batch 2338 on Training is 30.325459598118854\n",
            "Epoch #2. Accuracy on batch 2339 on Training is 30.32719017094017\n",
            "Batch Id 2340 is having training loss of 2232.184326171875\n",
            "43.110286712646484\n",
            "Epoch #2. Accuracy on batch 2340 on Training is 30.323579666809056\n",
            "Epoch #2. Accuracy on batch 2341 on Training is 30.318637916310845\n",
            "Epoch #2. Accuracy on batch 2342 on Training is 30.320369184805806\n",
            "Epoch #2. Accuracy on batch 2343 on Training is 30.319432593856654\n",
            "Epoch #2. Accuracy on batch 2344 on Training is 30.31449893390192\n",
            "Epoch #2. Accuracy on batch 2345 on Training is 30.316229752770674\n",
            "Epoch #2. Accuracy on batch 2346 on Training is 30.3192905837239\n",
            "Epoch #2. Accuracy on batch 2347 on Training is 30.321017887563883\n",
            "Epoch #2. Accuracy on batch 2348 on Training is 30.324074074074073\n",
            "Epoch #2. Accuracy on batch 2349 on Training is 30.324468085106382\n",
            "Epoch #2. Accuracy on batch 2350 on Training is 30.328849425776266\n",
            "Epoch #2. Accuracy on batch 2351 on Training is 30.3265837585034\n",
            "Epoch #2. Accuracy on batch 2352 on Training is 30.319007649808754\n",
            "Epoch #2. Accuracy on batch 2353 on Training is 30.31143797790994\n",
            "Epoch #2. Accuracy on batch 2354 on Training is 30.3052016985138\n",
            "Epoch #2. Accuracy on batch 2355 on Training is 30.300297113752123\n",
            "Epoch #2. Accuracy on batch 2356 on Training is 30.3060033941451\n",
            "Epoch #2. Accuracy on batch 2357 on Training is 30.303753180661577\n",
            "Epoch #2. Accuracy on batch 2358 on Training is 30.30150487494701\n",
            "Epoch #2. Accuracy on batch 2359 on Training is 30.300582627118644\n",
            "Batch Id 2360 is having training loss of 2222.9541015625\n",
            "47.9532470703125\n",
            "Epoch #2. Accuracy on batch 2360 on Training is 30.2996611605252\n",
            "Epoch #2. Accuracy on batch 2361 on Training is 30.302709568162573\n",
            "Epoch #2. Accuracy on batch 2362 on Training is 30.304432924248836\n",
            "Epoch #2. Accuracy on batch 2363 on Training is 30.30086717428088\n",
            "Epoch #2. Accuracy on batch 2364 on Training is 30.29994714587738\n",
            "Epoch #2. Accuracy on batch 2365 on Training is 30.301669484361792\n",
            "Epoch #2. Accuracy on batch 2366 on Training is 30.303390367553867\n",
            "Epoch #2. Accuracy on batch 2367 on Training is 30.30642947635135\n",
            "Epoch #2. Accuracy on batch 2368 on Training is 30.301551287463063\n",
            "Epoch #2. Accuracy on batch 2369 on Training is 30.30195147679325\n",
            "Epoch #2. Accuracy on batch 2370 on Training is 30.307623365668494\n",
            "Epoch #2. Accuracy on batch 2371 on Training is 30.305385750421586\n",
            "Epoch #2. Accuracy on batch 2372 on Training is 30.308417614833544\n",
            "Epoch #2. Accuracy on batch 2373 on Training is 30.300916175231677\n",
            "Epoch #2. Accuracy on batch 2374 on Training is 30.298684210526314\n",
            "Epoch #2. Accuracy on batch 2375 on Training is 30.299084595959595\n",
            "Epoch #2. Accuracy on batch 2376 on Training is 30.29422591501893\n",
            "Epoch #2. Accuracy on batch 2377 on Training is 30.293313708999158\n",
            "Epoch #2. Accuracy on batch 2378 on Training is 30.295029424127783\n",
            "Epoch #2. Accuracy on batch 2379 on Training is 30.29936974789916\n",
            "Batch Id 2380 is having training loss of 2212.726318359375\n",
            "122.15652465820312\n",
            "Epoch #2. Accuracy on batch 2380 on Training is 30.297144057118857\n",
            "Epoch #2. Accuracy on batch 2381 on Training is 30.297544080604535\n",
            "Epoch #2. Accuracy on batch 2382 on Training is 30.295321023919428\n",
            "Epoch #2. Accuracy on batch 2383 on Training is 30.293099832214764\n",
            "Epoch #2. Accuracy on batch 2384 on Training is 30.29350104821803\n",
            "Epoch #2. Accuracy on batch 2385 on Training is 30.295211651299244\n",
            "Epoch #2. Accuracy on batch 2386 on Training is 30.29692082111437\n",
            "Epoch #2. Accuracy on batch 2387 on Training is 30.294702680067\n",
            "Epoch #2. Accuracy on batch 2388 on Training is 30.30033486814567\n",
            "Epoch #2. Accuracy on batch 2389 on Training is 30.305962343096233\n",
            "Epoch #2. Accuracy on batch 2390 on Training is 30.306357172731076\n",
            "Epoch #2. Accuracy on batch 2391 on Training is 30.306751672240804\n",
            "Epoch #2. Accuracy on batch 2392 on Training is 30.312369410781447\n",
            "Epoch #2. Accuracy on batch 2393 on Training is 30.3140664160401\n",
            "Epoch #2. Accuracy on batch 2394 on Training is 30.311847599164928\n",
            "Epoch #2. Accuracy on batch 2395 on Training is 30.307022120200333\n",
            "Epoch #2. Accuracy on batch 2396 on Training is 30.29959324155194\n",
            "Epoch #2. Accuracy on batch 2397 on Training is 30.298686405337783\n",
            "Epoch #2. Accuracy on batch 2398 on Training is 30.29256982075865\n",
            "Epoch #2. Accuracy on batch 2399 on Training is 30.3046875\n",
            "Batch Id 2400 is having training loss of 2216.021484375\n",
            "11781.447265625\n",
            "Epoch #2. Accuracy on batch 2400 on Training is 30.305081216159934\n",
            "Epoch #2. Accuracy on batch 2401 on Training is 30.301571606994173\n",
            "Epoch #2. Accuracy on batch 2402 on Training is 30.298064918851434\n",
            "Epoch #2. Accuracy on batch 2403 on Training is 30.29976081530782\n",
            "Epoch #2. Accuracy on batch 2404 on Training is 30.29885654885655\n",
            "Epoch #2. Accuracy on batch 2405 on Training is 30.299251870324188\n",
            "Epoch #2. Accuracy on batch 2406 on Training is 30.290558786871625\n",
            "Epoch #2. Accuracy on batch 2407 on Training is 30.297446013289036\n",
            "Epoch #2. Accuracy on batch 2408 on Training is 30.300435865504358\n",
            "Epoch #2. Accuracy on batch 2409 on Training is 30.302126556016596\n",
            "Epoch #2. Accuracy on batch 2410 on Training is 30.307704272086273\n",
            "Epoch #2. Accuracy on batch 2411 on Training is 30.30809494195688\n",
            "Epoch #2. Accuracy on batch 2412 on Training is 30.30978035640282\n",
            "Epoch #2. Accuracy on batch 2413 on Training is 30.315347970173985\n",
            "Epoch #2. Accuracy on batch 2414 on Training is 30.317028985507246\n",
            "Epoch #2. Accuracy on batch 2415 on Training is 30.318708609271525\n",
            "Epoch #2. Accuracy on batch 2416 on Training is 30.319093918080267\n",
            "Epoch #2. Accuracy on batch 2417 on Training is 30.316894127378\n",
            "Epoch #2. Accuracy on batch 2418 on Training is 30.31598801157503\n",
            "Epoch #2. Accuracy on batch 2419 on Training is 30.31379132231405\n",
            "Batch Id 2420 is having training loss of 2199.717529296875\n",
            "9.413193702697754\n",
            "Epoch #2. Accuracy on batch 2420 on Training is 30.315468814539447\n",
            "Epoch #2. Accuracy on batch 2421 on Training is 30.30940338563171\n",
            "Epoch #2. Accuracy on batch 2422 on Training is 30.3097915806851\n",
            "Epoch #2. Accuracy on batch 2423 on Training is 30.310179455445546\n",
            "Epoch #2. Accuracy on batch 2424 on Training is 30.310567010309278\n",
            "Epoch #2. Accuracy on batch 2425 on Training is 30.309666117065127\n",
            "Epoch #2. Accuracy on batch 2426 on Training is 30.31005356407087\n",
            "Epoch #2. Accuracy on batch 2427 on Training is 30.305292421746294\n",
            "Epoch #2. Accuracy on batch 2428 on Training is 30.299248662000824\n",
            "Epoch #2. Accuracy on batch 2429 on Training is 30.30221193415638\n",
            "Epoch #2. Accuracy on batch 2430 on Training is 30.30260180995475\n",
            "Epoch #2. Accuracy on batch 2431 on Training is 30.30299136513158\n",
            "Epoch #2. Accuracy on batch 2432 on Training is 30.30209617755857\n",
            "Epoch #2. Accuracy on batch 2433 on Training is 30.299917830731307\n",
            "Epoch #2. Accuracy on batch 2434 on Training is 30.297741273100616\n",
            "Epoch #2. Accuracy on batch 2435 on Training is 30.301980706075533\n",
            "Epoch #2. Accuracy on batch 2436 on Training is 30.298522773902338\n",
            "Epoch #2. Accuracy on batch 2437 on Training is 30.304040196882692\n",
            "Epoch #2. Accuracy on batch 2438 on Training is 30.3069905699057\n",
            "Epoch #2. Accuracy on batch 2439 on Training is 30.30609631147541\n",
            "Batch Id 2440 is having training loss of 2200.86328125\n",
            "216.50489807128906\n",
            "Epoch #2. Accuracy on batch 2440 on Training is 30.29880172060631\n",
            "Epoch #2. Accuracy on batch 2441 on Training is 30.301750614250615\n",
            "Epoch #2. Accuracy on batch 2442 on Training is 30.307255423659434\n",
            "Epoch #2. Accuracy on batch 2443 on Training is 30.303805237315874\n",
            "Epoch #2. Accuracy on batch 2444 on Training is 30.304192229038854\n",
            "Epoch #2. Accuracy on batch 2445 on Training is 30.302023712183157\n",
            "Epoch #2. Accuracy on batch 2446 on Training is 30.306242337556192\n",
            "Epoch #2. Accuracy on batch 2447 on Training is 30.306627859477125\n",
            "Epoch #2. Accuracy on batch 2448 on Training is 30.309565128623927\n",
            "Epoch #2. Accuracy on batch 2449 on Training is 30.308673469387756\n",
            "Epoch #2. Accuracy on batch 2450 on Training is 30.310332517339862\n",
            "Epoch #2. Accuracy on batch 2451 on Training is 30.315813621533444\n",
            "Epoch #2. Accuracy on batch 2452 on Training is 30.3123726049735\n",
            "Epoch #2. Accuracy on batch 2453 on Training is 30.31275468622657\n",
            "Epoch #2. Accuracy on batch 2454 on Training is 30.31186354378819\n",
            "Epoch #2. Accuracy on batch 2455 on Training is 30.318607491856678\n",
            "Epoch #2. Accuracy on batch 2456 on Training is 30.32153032153032\n",
            "Epoch #2. Accuracy on batch 2457 on Training is 30.321908055329537\n",
            "Epoch #2. Accuracy on batch 2458 on Training is 30.32228548190321\n",
            "Epoch #2. Accuracy on batch 2459 on Training is 30.326473577235774\n",
            "Batch Id 2460 is having training loss of 2183.220458984375\n",
            "21.511991500854492\n",
            "Epoch #2. Accuracy on batch 2460 on Training is 30.328118650954895\n",
            "Epoch #2. Accuracy on batch 2461 on Training is 30.329762388302193\n",
            "Epoch #2. Accuracy on batch 2462 on Training is 30.328867235079173\n",
            "Epoch #2. Accuracy on batch 2463 on Training is 30.327972808441558\n",
            "Epoch #2. Accuracy on batch 2464 on Training is 30.332150101419877\n",
            "Epoch #2. Accuracy on batch 2465 on Training is 30.332522303325224\n",
            "Epoch #2. Accuracy on batch 2466 on Training is 30.32656059991893\n",
            "Epoch #2. Accuracy on batch 2467 on Training is 30.330733387358183\n",
            "Epoch #2. Accuracy on batch 2468 on Training is 30.331105710814096\n",
            "Epoch #2. Accuracy on batch 2469 on Training is 30.32894736842105\n",
            "Epoch #2. Accuracy on batch 2470 on Training is 30.333114123836502\n",
            "Epoch #2. Accuracy on batch 2471 on Training is 30.33348503236246\n",
            "Epoch #2. Accuracy on batch 2472 on Training is 30.32880105135463\n",
            "Epoch #2. Accuracy on batch 2473 on Training is 30.327910266774456\n",
            "Epoch #2. Accuracy on batch 2474 on Training is 30.3270202020202\n",
            "Epoch #2. Accuracy on batch 2475 on Training is 30.327392972536348\n",
            "Epoch #2. Accuracy on batch 2476 on Training is 30.33028865563181\n",
            "Epoch #2. Accuracy on batch 2477 on Training is 30.331920903954803\n",
            "Epoch #2. Accuracy on batch 2478 on Training is 30.33229124647035\n",
            "Epoch #2. Accuracy on batch 2479 on Training is 30.327620967741936\n",
            "Batch Id 2480 is having training loss of 2166.82861328125\n",
            "624.8832397460938\n",
            "Epoch #2. Accuracy on batch 2480 on Training is 30.322954453849253\n",
            "Epoch #2. Accuracy on batch 2481 on Training is 30.320809830781627\n",
            "Epoch #2. Accuracy on batch 2482 on Training is 30.319925493354813\n",
            "Epoch #2. Accuracy on batch 2483 on Training is 30.319041867954912\n",
            "Epoch #2. Accuracy on batch 2484 on Training is 30.315643863179073\n",
            "Epoch #2. Accuracy on batch 2485 on Training is 30.316019710378118\n",
            "Epoch #2. Accuracy on batch 2486 on Training is 30.3226779252111\n",
            "Epoch #2. Accuracy on batch 2487 on Training is 30.321794614147908\n",
            "Epoch #2. Accuracy on batch 2488 on Training is 30.31965648854962\n",
            "Epoch #2. Accuracy on batch 2489 on Training is 30.316265060240966\n",
            "Epoch #2. Accuracy on batch 2490 on Training is 30.31663990365315\n",
            "Epoch #2. Accuracy on batch 2491 on Training is 30.31576043338684\n",
            "Epoch #2. Accuracy on batch 2492 on Training is 30.31488166867228\n",
            "Epoch #2. Accuracy on batch 2493 on Training is 30.31525661587811\n",
            "Epoch #2. Accuracy on batch 2494 on Training is 30.32064128256513\n",
            "Epoch #2. Accuracy on batch 2495 on Training is 30.31475360576923\n",
            "Epoch #2. Accuracy on batch 2496 on Training is 30.315128153784542\n",
            "Epoch #2. Accuracy on batch 2497 on Training is 30.310498398718977\n",
            "Epoch #2. Accuracy on batch 2498 on Training is 30.310874349739898\n",
            "Epoch #2. Accuracy on batch 2499 on Training is 30.31375\n",
            "Batch Id 2500 is having training loss of 2163.58984375\n",
            "81.20668029785156\n",
            "Epoch #2. Accuracy on batch 2500 on Training is 30.307876849260296\n",
            "Epoch #2. Accuracy on batch 2501 on Training is 30.31949440447642\n",
            "Epoch #2. Accuracy on batch 2502 on Training is 30.321114662405115\n",
            "Epoch #2. Accuracy on batch 2503 on Training is 30.315245607028753\n",
            "Epoch #2. Accuracy on batch 2504 on Training is 30.31936127744511\n",
            "Epoch #2. Accuracy on batch 2505 on Training is 30.31474461292897\n",
            "Epoch #2. Accuracy on batch 2506 on Training is 30.312624650977263\n",
            "Epoch #2. Accuracy on batch 2507 on Training is 30.3117523923445\n",
            "Epoch #2. Accuracy on batch 2508 on Training is 30.309635312873656\n",
            "Epoch #2. Accuracy on batch 2509 on Training is 30.306274900398407\n",
            "Epoch #2. Accuracy on batch 2510 on Training is 30.30789526085225\n",
            "Epoch #2. Accuracy on batch 2511 on Training is 30.30702627388535\n",
            "Epoch #2. Accuracy on batch 2512 on Training is 30.306157978511738\n",
            "Epoch #2. Accuracy on batch 2513 on Training is 30.305290373906125\n",
            "Epoch #2. Accuracy on batch 2514 on Training is 30.305666003976143\n",
            "Epoch #2. Accuracy on batch 2515 on Training is 30.311009538950714\n",
            "Epoch #2. Accuracy on batch 2516 on Training is 30.31014104092173\n",
            "Epoch #2. Accuracy on batch 2517 on Training is 30.314237490071484\n",
            "Epoch #2. Accuracy on batch 2518 on Training is 30.31709011512505\n",
            "Epoch #2. Accuracy on batch 2519 on Training is 30.316220238095237\n",
            "Batch Id 2520 is having training loss of 2161.716796875\n",
            "25.184795379638672\n",
            "Epoch #2. Accuracy on batch 2520 on Training is 30.311632288774295\n",
            "Epoch #2. Accuracy on batch 2521 on Training is 30.310765265662173\n",
            "Epoch #2. Accuracy on batch 2522 on Training is 30.30989892984542\n",
            "Epoch #2. Accuracy on batch 2523 on Training is 30.31027139461173\n",
            "Epoch #2. Accuracy on batch 2524 on Training is 30.31188118811881\n",
            "Epoch #2. Accuracy on batch 2525 on Training is 30.30730403800475\n",
            "Epoch #2. Accuracy on batch 2526 on Training is 30.311387020182035\n",
            "Epoch #2. Accuracy on batch 2527 on Training is 30.308049841772153\n",
            "Epoch #2. Accuracy on batch 2528 on Training is 30.301008303677342\n",
            "Epoch #2. Accuracy on batch 2529 on Training is 30.302618577075098\n",
            "Epoch #2. Accuracy on batch 2530 on Training is 30.301758198340575\n",
            "Epoch #2. Accuracy on batch 2531 on Training is 30.29843009478673\n",
            "Epoch #2. Accuracy on batch 2532 on Training is 30.298805763916306\n",
            "Epoch #2. Accuracy on batch 2533 on Training is 30.30411404893449\n",
            "Epoch #2. Accuracy on batch 2534 on Training is 30.310650887573964\n",
            "Epoch #2. Accuracy on batch 2535 on Training is 30.315950315457414\n",
            "Epoch #2. Accuracy on batch 2536 on Training is 30.31755025620812\n",
            "Epoch #2. Accuracy on batch 2537 on Training is 30.321611505122142\n",
            "Epoch #2. Accuracy on batch 2538 on Training is 30.318284757778653\n",
            "Epoch #2. Accuracy on batch 2539 on Training is 30.31496062992126\n",
            "Batch Id 2540 is having training loss of 2181.122802734375\n",
            "20.506610870361328\n",
            "Epoch #2. Accuracy on batch 2540 on Training is 30.316558441558442\n",
            "Epoch #2. Accuracy on batch 2541 on Training is 30.314466955153424\n",
            "Epoch #2. Accuracy on batch 2542 on Training is 30.31975029492725\n",
            "Epoch #2. Accuracy on batch 2543 on Training is 30.31888757861635\n",
            "Epoch #2. Accuracy on batch 2544 on Training is 30.315569744597248\n",
            "Epoch #2. Accuracy on batch 2545 on Training is 30.30979968578162\n",
            "Epoch #2. Accuracy on batch 2546 on Training is 30.308941892422457\n",
            "Epoch #2. Accuracy on batch 2547 on Training is 30.311764128728413\n",
            "Epoch #2. Accuracy on batch 2548 on Training is 30.309680266771284\n",
            "Epoch #2. Accuracy on batch 2549 on Training is 30.316176470588236\n",
            "Epoch #2. Accuracy on batch 2550 on Training is 30.309192473539788\n",
            "Epoch #2. Accuracy on batch 2551 on Training is 30.315683777429467\n",
            "Epoch #2. Accuracy on batch 2552 on Training is 30.314825695260478\n",
            "Epoch #2. Accuracy on batch 2553 on Training is 30.315191855912296\n",
            "Epoch #2. Accuracy on batch 2554 on Training is 30.31188845401174\n",
            "Epoch #2. Accuracy on batch 2555 on Training is 30.303697183098592\n",
            "Epoch #2. Accuracy on batch 2556 on Training is 30.301622995698082\n",
            "Epoch #2. Accuracy on batch 2557 on Training is 30.306880375293197\n",
            "Epoch #2. Accuracy on batch 2558 on Training is 30.306027745212972\n",
            "Epoch #2. Accuracy on batch 2559 on Training is 30.303955078125\n",
            "Batch Id 2560 is having training loss of 2210.7431640625\n",
            "63.45028305053711\n",
            "Epoch #2. Accuracy on batch 2560 on Training is 30.307985162046077\n",
            "Epoch #2. Accuracy on batch 2561 on Training is 30.313231850117095\n",
            "Epoch #2. Accuracy on batch 2562 on Training is 30.31359734685915\n",
            "Epoch #2. Accuracy on batch 2563 on Training is 30.30908736349454\n",
            "Epoch #2. Accuracy on batch 2564 on Training is 30.30458089668616\n",
            "Epoch #2. Accuracy on batch 2565 on Training is 30.30251363990647\n",
            "Epoch #2. Accuracy on batch 2566 on Training is 30.30166536813401\n",
            "Epoch #2. Accuracy on batch 2567 on Training is 30.298383956386292\n",
            "Epoch #2. Accuracy on batch 2568 on Training is 30.297537952510705\n",
            "Epoch #2. Accuracy on batch 2569 on Training is 30.295476653696497\n",
            "Epoch #2. Accuracy on batch 2570 on Training is 30.298278879813303\n",
            "Epoch #2. Accuracy on batch 2571 on Training is 30.296218895800934\n",
            "Epoch #2. Accuracy on batch 2572 on Training is 30.296589584143025\n",
            "Epoch #2. Accuracy on batch 2573 on Training is 30.30181623931624\n",
            "Epoch #2. Accuracy on batch 2574 on Training is 30.304611650485437\n",
            "Epoch #2. Accuracy on batch 2575 on Training is 30.30376552795031\n",
            "Epoch #2. Accuracy on batch 2576 on Training is 30.30534536282499\n",
            "Epoch #2. Accuracy on batch 2577 on Training is 30.30328743211792\n",
            "Epoch #2. Accuracy on batch 2578 on Training is 30.302442807289648\n",
            "Epoch #2. Accuracy on batch 2579 on Training is 30.3015988372093\n",
            "Batch Id 2580 is having training loss of 2194.35107421875\n",
            "19.467071533203125\n",
            "Epoch #2. Accuracy on batch 2580 on Training is 30.300755521115846\n",
            "Epoch #2. Accuracy on batch 2581 on Training is 30.302333462432223\n",
            "Epoch #2. Accuracy on batch 2582 on Training is 30.302700348432055\n",
            "Epoch #2. Accuracy on batch 2583 on Training is 30.313951238390093\n",
            "Epoch #2. Accuracy on batch 2584 on Training is 30.316731141199227\n",
            "Epoch #2. Accuracy on batch 2585 on Training is 30.31104988399072\n",
            "Epoch #2. Accuracy on batch 2586 on Training is 30.311412833397757\n",
            "Epoch #2. Accuracy on batch 2587 on Training is 30.31056800618238\n",
            "Epoch #2. Accuracy on batch 2588 on Training is 30.303688682889145\n",
            "Epoch #2. Accuracy on batch 2589 on Training is 30.304054054054053\n",
            "Epoch #2. Accuracy on batch 2590 on Training is 30.30924353531455\n",
            "Epoch #2. Accuracy on batch 2591 on Training is 30.305989583333332\n",
            "Epoch #2. Accuracy on batch 2592 on Training is 30.307558812186656\n",
            "Epoch #2. Accuracy on batch 2593 on Training is 30.30551272166538\n",
            "Epoch #2. Accuracy on batch 2594 on Training is 30.29985549132948\n",
            "Epoch #2. Accuracy on batch 2595 on Training is 30.30142526964561\n",
            "Epoch #2. Accuracy on batch 2596 on Training is 30.295773969965346\n",
            "Epoch #2. Accuracy on batch 2597 on Training is 30.297344110854503\n",
            "Epoch #2. Accuracy on batch 2598 on Training is 30.29049634474798\n",
            "Epoch #2. Accuracy on batch 2599 on Training is 30.294471153846153\n",
            "Batch Id 2600 is having training loss of 2190.954345703125\n",
            "32.953514099121094\n",
            "Epoch #2. Accuracy on batch 2600 on Training is 30.292435601691658\n",
            "Epoch #2. Accuracy on batch 2601 on Training is 30.286798616448884\n",
            "Epoch #2. Accuracy on batch 2602 on Training is 30.2871686515559\n",
            "Epoch #2. Accuracy on batch 2603 on Training is 30.285138248847925\n",
            "Epoch #2. Accuracy on batch 2604 on Training is 30.286708253358924\n",
            "Epoch #2. Accuracy on batch 2605 on Training is 30.283480429777438\n",
            "Epoch #2. Accuracy on batch 2606 on Training is 30.282652474108172\n",
            "Epoch #2. Accuracy on batch 2607 on Training is 30.283023389570552\n",
            "Epoch #2. Accuracy on batch 2608 on Training is 30.280998466845535\n",
            "Epoch #2. Accuracy on batch 2609 on Training is 30.280172413793103\n",
            "Epoch #2. Accuracy on batch 2610 on Training is 30.278150134048257\n",
            "Epoch #2. Accuracy on batch 2611 on Training is 30.272540199081163\n",
            "Epoch #2. Accuracy on batch 2612 on Training is 30.272914274779946\n",
            "Epoch #2. Accuracy on batch 2613 on Training is 30.274483550114766\n",
            "Epoch #2. Accuracy on batch 2614 on Training is 30.273661567877628\n",
            "Epoch #2. Accuracy on batch 2615 on Training is 30.275229357798164\n",
            "Epoch #2. Accuracy on batch 2616 on Training is 30.275601834161254\n",
            "Epoch #2. Accuracy on batch 2617 on Training is 30.273586707410235\n",
            "Epoch #2. Accuracy on batch 2618 on Training is 30.275152730049637\n",
            "Epoch #2. Accuracy on batch 2619 on Training is 30.275524809160306\n",
            "Batch Id 2620 is having training loss of 2175.885986328125\n",
            "30.53580093383789\n",
            "Epoch #2. Accuracy on batch 2620 on Training is 30.280665776421213\n",
            "Epoch #2. Accuracy on batch 2621 on Training is 30.27984363081617\n",
            "Epoch #2. Accuracy on batch 2622 on Training is 30.284979031643157\n",
            "Epoch #2. Accuracy on batch 2623 on Training is 30.28296493902439\n",
            "Epoch #2. Accuracy on batch 2624 on Training is 30.283333333333335\n",
            "Epoch #2. Accuracy on batch 2625 on Training is 30.281321401370906\n",
            "Epoch #2. Accuracy on batch 2626 on Training is 30.281690140845072\n",
            "Epoch #2. Accuracy on batch 2627 on Training is 30.280869482496193\n",
            "Epoch #2. Accuracy on batch 2628 on Training is 30.278860783567897\n",
            "Epoch #2. Accuracy on batch 2629 on Training is 30.281606463878326\n",
            "Epoch #2. Accuracy on batch 2630 on Training is 30.283162295705054\n",
            "Epoch #2. Accuracy on batch 2631 on Training is 30.289466185410333\n",
            "Epoch #2. Accuracy on batch 2632 on Training is 30.291017850360806\n",
            "Epoch #2. Accuracy on batch 2633 on Training is 30.29019552012149\n",
            "Epoch #2. Accuracy on batch 2634 on Training is 30.289373814041745\n",
            "Epoch #2. Accuracy on batch 2635 on Training is 30.282625189681337\n",
            "Epoch #2. Accuracy on batch 2636 on Training is 30.28417709518392\n",
            "Epoch #2. Accuracy on batch 2637 on Training is 30.288097043214556\n",
            "Epoch #2. Accuracy on batch 2638 on Training is 30.28846153846154\n",
            "Epoch #2. Accuracy on batch 2639 on Training is 30.294744318181817\n",
            "Batch Id 2640 is having training loss of 2167.552978515625\n",
            "205.89259338378906\n",
            "Epoch #2. Accuracy on batch 2640 on Training is 30.28918970087088\n",
            "Epoch #2. Accuracy on batch 2641 on Training is 30.287187736563208\n",
            "Epoch #2. Accuracy on batch 2642 on Training is 30.289916761256148\n",
            "Epoch #2. Accuracy on batch 2643 on Training is 30.29146180030257\n",
            "Epoch #2. Accuracy on batch 2644 on Training is 30.2882797731569\n",
            "Epoch #2. Accuracy on batch 2645 on Training is 30.29100529100529\n",
            "Epoch #2. Accuracy on batch 2646 on Training is 30.29254816773706\n",
            "Epoch #2. Accuracy on batch 2647 on Training is 30.28936933534743\n",
            "Epoch #2. Accuracy on batch 2648 on Training is 30.287372593431485\n",
            "Epoch #2. Accuracy on batch 2649 on Training is 30.284198113207548\n",
            "Epoch #2. Accuracy on batch 2650 on Training is 30.278668427008675\n",
            "Epoch #2. Accuracy on batch 2651 on Training is 30.2825697586727\n",
            "Epoch #2. Accuracy on batch 2652 on Training is 30.284112325669053\n",
            "Epoch #2. Accuracy on batch 2653 on Training is 30.285653730218538\n",
            "Epoch #2. Accuracy on batch 2654 on Training is 30.284839924670433\n",
            "Epoch #2. Accuracy on batch 2655 on Training is 30.28402673192771\n",
            "Epoch #2. Accuracy on batch 2656 on Training is 30.290270982310876\n",
            "Epoch #2. Accuracy on batch 2657 on Training is 30.288280662151994\n",
            "Epoch #2. Accuracy on batch 2658 on Training is 30.2851165851824\n",
            "Epoch #2. Accuracy on batch 2659 on Training is 30.28312969924812\n",
            "Batch Id 2660 is having training loss of 2177.071044921875\n",
            "50236.8203125\n",
            "Epoch #2. Accuracy on batch 2660 on Training is 30.275272453964675\n",
            "Epoch #2. Accuracy on batch 2661 on Training is 30.275638617580768\n",
            "Epoch #2. Accuracy on batch 2662 on Training is 30.278351483289523\n",
            "Epoch #2. Accuracy on batch 2663 on Training is 30.279889264264263\n",
            "Epoch #2. Accuracy on batch 2664 on Training is 30.28142589118199\n",
            "Epoch #2. Accuracy on batch 2665 on Training is 30.282961365341336\n",
            "Epoch #2. Accuracy on batch 2666 on Training is 30.284495688038994\n",
            "Epoch #2. Accuracy on batch 2667 on Training is 30.28954272863568\n",
            "Epoch #2. Accuracy on batch 2668 on Training is 30.295756837766955\n",
            "Epoch #2. Accuracy on batch 2669 on Training is 30.2937734082397\n",
            "Epoch #2. Accuracy on batch 2670 on Training is 30.287111568700862\n",
            "Epoch #2. Accuracy on batch 2671 on Training is 30.28864146706587\n",
            "Epoch #2. Accuracy on batch 2672 on Training is 30.291339319117096\n",
            "Epoch #2. Accuracy on batch 2673 on Training is 30.295203814510096\n",
            "Epoch #2. Accuracy on batch 2674 on Training is 30.299065420560748\n",
            "Epoch #2. Accuracy on batch 2675 on Training is 30.29358183856502\n",
            "Epoch #2. Accuracy on batch 2676 on Training is 30.295106462457976\n",
            "Epoch #2. Accuracy on batch 2677 on Training is 30.294296116504853\n",
            "Epoch #2. Accuracy on batch 2678 on Training is 30.288820455393804\n",
            "Epoch #2. Accuracy on batch 2679 on Training is 30.29151119402985\n",
            "Batch Id 2680 is having training loss of 2168.77392578125\n",
            "15.72822380065918\n",
            "Epoch #2. Accuracy on batch 2680 on Training is 30.291868705706825\n",
            "Epoch #2. Accuracy on batch 2681 on Training is 30.28756524981357\n",
            "Epoch #2. Accuracy on batch 2682 on Training is 30.289088706671635\n",
            "Epoch #2. Accuracy on batch 2683 on Training is 30.290611028315947\n",
            "Epoch #2. Accuracy on batch 2684 on Training is 30.293296089385475\n",
            "Epoch #2. Accuracy on batch 2685 on Training is 30.29016195085629\n",
            "Epoch #2. Accuracy on batch 2686 on Training is 30.295171194640865\n",
            "Epoch #2. Accuracy on batch 2687 on Training is 30.29203869047619\n",
            "Epoch #2. Accuracy on batch 2688 on Training is 30.297043510598737\n",
            "Epoch #2. Accuracy on batch 2689 on Training is 30.29275092936803\n",
            "Epoch #2. Accuracy on batch 2690 on Training is 30.29775176514307\n",
            "Epoch #2. Accuracy on batch 2691 on Training is 30.298105497771175\n",
            "Epoch #2. Accuracy on batch 2692 on Training is 30.297298551800967\n",
            "Epoch #2. Accuracy on batch 2693 on Training is 30.297652190051966\n",
            "Epoch #2. Accuracy on batch 2694 on Training is 30.30148423005566\n",
            "Epoch #2. Accuracy on batch 2695 on Training is 30.306472551928785\n",
            "Epoch #2. Accuracy on batch 2696 on Training is 30.306822395253985\n",
            "Epoch #2. Accuracy on batch 2697 on Training is 30.308330244625648\n",
            "Epoch #2. Accuracy on batch 2698 on Training is 30.306363467951094\n",
            "Epoch #2. Accuracy on batch 2699 on Training is 30.31134259259259\n",
            "Batch Id 2700 is having training loss of 2153.852783203125\n",
            "12.750096321105957\n",
            "Epoch #2. Accuracy on batch 2700 on Training is 30.311690114772308\n",
            "Epoch #2. Accuracy on batch 2701 on Training is 30.315507031828275\n",
            "Epoch #2. Accuracy on batch 2702 on Training is 30.31585275619682\n",
            "Epoch #2. Accuracy on batch 2703 on Training is 30.31619822485207\n",
            "Epoch #2. Accuracy on batch 2704 on Training is 30.316543438077634\n",
            "Epoch #2. Accuracy on batch 2705 on Training is 30.320352919438285\n",
            "Epoch #2. Accuracy on batch 2706 on Training is 30.3264684152198\n",
            "Epoch #2. Accuracy on batch 2707 on Training is 30.326809453471196\n",
            "Epoch #2. Accuracy on batch 2708 on Training is 30.325996677740864\n",
            "Epoch #2. Accuracy on batch 2709 on Training is 30.319418819188193\n",
            "Epoch #2. Accuracy on batch 2710 on Training is 30.31976208041313\n",
            "Epoch #2. Accuracy on batch 2711 on Training is 30.32240966076696\n",
            "Epoch #2. Accuracy on batch 2712 on Training is 30.32159970512348\n",
            "Epoch #2. Accuracy on batch 2713 on Training is 30.323093220338983\n",
            "Epoch #2. Accuracy on batch 2714 on Training is 30.318830570902396\n",
            "Epoch #2. Accuracy on batch 2715 on Training is 30.319173416789397\n",
            "Epoch #2. Accuracy on batch 2716 on Training is 30.324116672800884\n",
            "Epoch #2. Accuracy on batch 2717 on Training is 30.33020603384842\n",
            "Epoch #2. Accuracy on batch 2718 on Training is 30.3259470393527\n",
            "Epoch #2. Accuracy on batch 2719 on Training is 30.330882352941178\n",
            "Batch Id 2720 is having training loss of 2139.8857421875\n",
            "21.821443557739258\n",
            "Epoch #2. Accuracy on batch 2720 on Training is 30.33236861447997\n",
            "Epoch #2. Accuracy on batch 2721 on Training is 30.330409625275532\n",
            "Epoch #2. Accuracy on batch 2722 on Training is 30.333042600073448\n",
            "Epoch #2. Accuracy on batch 2723 on Training is 30.32879038179148\n",
            "Epoch #2. Accuracy on batch 2724 on Training is 30.325688073394495\n",
            "Epoch #2. Accuracy on batch 2725 on Training is 30.328319882611886\n",
            "Epoch #2. Accuracy on batch 2726 on Training is 30.326365969930325\n",
            "Epoch #2. Accuracy on batch 2727 on Training is 30.32441348973607\n",
            "Epoch #2. Accuracy on batch 2728 on Training is 30.32017222425797\n",
            "Epoch #2. Accuracy on batch 2729 on Training is 30.317078754578755\n",
            "Epoch #2. Accuracy on batch 2730 on Training is 30.319708897839618\n",
            "Epoch #2. Accuracy on batch 2731 on Training is 30.314330161054173\n",
            "Epoch #2. Accuracy on batch 2732 on Training is 30.310098792535676\n",
            "Epoch #2. Accuracy on batch 2733 on Training is 30.31272860277981\n",
            "Epoch #2. Accuracy on batch 2734 on Training is 30.30850091407678\n",
            "Epoch #2. Accuracy on batch 2735 on Training is 30.30656067251462\n",
            "Epoch #2. Accuracy on batch 2736 on Training is 30.308047131896238\n",
            "Epoch #2. Accuracy on batch 2737 on Training is 30.3129565376187\n",
            "Epoch #2. Accuracy on batch 2738 on Training is 30.315580503833516\n",
            "Epoch #2. Accuracy on batch 2739 on Training is 30.31478102189781\n",
            "Batch Id 2740 is having training loss of 2131.587158203125\n",
            "19.845487594604492\n",
            "Epoch #2. Accuracy on batch 2740 on Training is 30.316262313024442\n",
            "Epoch #2. Accuracy on batch 2741 on Training is 30.3143234865062\n",
            "Epoch #2. Accuracy on batch 2742 on Training is 30.308968282901933\n",
            "Epoch #2. Accuracy on batch 2743 on Training is 30.310450072886297\n",
            "Epoch #2. Accuracy on batch 2744 on Training is 30.311930783242257\n",
            "Epoch #2. Accuracy on batch 2745 on Training is 30.31341041514931\n",
            "Epoch #2. Accuracy on batch 2746 on Training is 30.31488896978522\n",
            "Epoch #2. Accuracy on batch 2747 on Training is 30.318640829694324\n",
            "Epoch #2. Accuracy on batch 2748 on Training is 30.318979628955983\n",
            "Epoch #2. Accuracy on batch 2749 on Training is 30.31477272727273\n",
            "Epoch #2. Accuracy on batch 2750 on Training is 30.316248636859324\n",
            "Epoch #2. Accuracy on batch 2751 on Training is 30.316587936046513\n",
            "Epoch #2. Accuracy on batch 2752 on Training is 30.312386487468217\n",
            "Epoch #2. Accuracy on batch 2753 on Training is 30.308188090050834\n",
            "Epoch #2. Accuracy on batch 2754 on Training is 30.310798548094375\n",
            "Epoch #2. Accuracy on batch 2755 on Training is 30.313407111756167\n",
            "Epoch #2. Accuracy on batch 2756 on Training is 30.31601378309757\n",
            "Epoch #2. Accuracy on batch 2757 on Training is 30.315219361856418\n",
            "Epoch #2. Accuracy on batch 2758 on Training is 30.316690830010874\n",
            "Epoch #2. Accuracy on batch 2759 on Training is 30.31816123188406\n",
            "Batch Id 2760 is having training loss of 2116.8642578125\n",
            "26.530963897705078\n",
            "Epoch #2. Accuracy on batch 2760 on Training is 30.31510322346976\n",
            "Epoch #2. Accuracy on batch 2761 on Training is 30.31544170890659\n",
            "Epoch #2. Accuracy on batch 2762 on Training is 30.313517915309447\n",
            "Epoch #2. Accuracy on batch 2763 on Training is 30.316117945007235\n",
            "Epoch #2. Accuracy on batch 2764 on Training is 30.31532549728752\n",
            "Epoch #2. Accuracy on batch 2765 on Training is 30.313403832248735\n",
            "Epoch #2. Accuracy on batch 2766 on Training is 30.314871702204552\n",
            "Epoch #2. Accuracy on batch 2767 on Training is 30.315209537572255\n",
            "Epoch #2. Accuracy on batch 2768 on Training is 30.311032863849764\n",
            "Epoch #2. Accuracy on batch 2769 on Training is 30.311371841155236\n",
            "Epoch #2. Accuracy on batch 2770 on Training is 30.30945507037171\n",
            "Epoch #2. Accuracy on batch 2771 on Training is 30.306412337662337\n",
            "Epoch #2. Accuracy on batch 2772 on Training is 30.304498737829064\n",
            "Epoch #2. Accuracy on batch 2773 on Training is 30.304839581831292\n",
            "Epoch #2. Accuracy on batch 2774 on Training is 30.306306306306308\n",
            "Epoch #2. Accuracy on batch 2775 on Training is 30.30552053314121\n",
            "Epoch #2. Accuracy on batch 2776 on Training is 30.30473532589125\n",
            "Epoch #2. Accuracy on batch 2777 on Training is 30.303950683945285\n",
            "Epoch #2. Accuracy on batch 2778 on Training is 30.30766462756387\n",
            "Epoch #2. Accuracy on batch 2779 on Training is 30.30687949640288\n",
            "Batch Id 2780 is having training loss of 2102.212158203125\n",
            "16.179643630981445\n",
            "Epoch #2. Accuracy on batch 2780 on Training is 30.30834232290543\n",
            "Epoch #2. Accuracy on batch 2781 on Training is 30.3019410496046\n",
            "Epoch #2. Accuracy on batch 2782 on Training is 30.300035932447\n",
            "Epoch #2. Accuracy on batch 2783 on Training is 30.305989583333332\n",
            "Epoch #2. Accuracy on batch 2784 on Training is 30.307450628366247\n",
            "Epoch #2. Accuracy on batch 2785 on Training is 30.306667264895907\n",
            "Epoch #2. Accuracy on batch 2786 on Training is 30.308127018299245\n",
            "Epoch #2. Accuracy on batch 2787 on Training is 30.307343974175037\n",
            "Epoch #2. Accuracy on batch 2788 on Training is 30.308802438149876\n",
            "Epoch #2. Accuracy on batch 2789 on Training is 30.303539426523297\n",
            "Epoch #2. Accuracy on batch 2790 on Training is 30.307237549265498\n",
            "Epoch #2. Accuracy on batch 2791 on Training is 30.30645594555874\n",
            "Epoch #2. Accuracy on batch 2792 on Training is 30.30455603293949\n",
            "Epoch #2. Accuracy on batch 2793 on Training is 30.300420544022906\n",
            "Epoch #2. Accuracy on batch 2794 on Training is 30.3007602862254\n",
            "Epoch #2. Accuracy on batch 2795 on Training is 30.298864449213163\n",
            "Epoch #2. Accuracy on batch 2796 on Training is 30.2992045048266\n",
            "Epoch #2. Accuracy on batch 2797 on Training is 30.29954431736955\n",
            "Epoch #2. Accuracy on batch 2798 on Training is 30.302116827438372\n",
            "Epoch #2. Accuracy on batch 2799 on Training is 30.3046875\n",
            "Batch Id 2800 is having training loss of 2110.084716796875\n",
            "18.250890731811523\n",
            "Epoch #2. Accuracy on batch 2800 on Training is 30.30725633702249\n",
            "Epoch #2. Accuracy on batch 2801 on Training is 30.305362241256244\n",
            "Epoch #2. Accuracy on batch 2802 on Training is 30.30012486621477\n",
            "Epoch #2. Accuracy on batch 2803 on Training is 30.296005706134093\n",
            "Epoch #2. Accuracy on batch 2804 on Training is 30.289661319073083\n",
            "Epoch #2. Accuracy on batch 2805 on Training is 30.295571988595867\n",
            "Epoch #2. Accuracy on batch 2806 on Training is 30.293685429283933\n",
            "Epoch #2. Accuracy on batch 2807 on Training is 30.29513888888889\n",
            "Epoch #2. Accuracy on batch 2808 on Training is 30.293253826984692\n",
            "Epoch #2. Accuracy on batch 2809 on Training is 30.29470640569395\n",
            "Epoch #2. Accuracy on batch 2810 on Training is 30.291711134827462\n",
            "Epoch #2. Accuracy on batch 2811 on Training is 30.287606685633\n",
            "Epoch #2. Accuracy on batch 2812 on Training is 30.28905972271596\n",
            "Epoch #2. Accuracy on batch 2813 on Training is 30.28718017057569\n",
            "Epoch #2. Accuracy on batch 2814 on Training is 30.286412078152754\n",
            "Epoch #2. Accuracy on batch 2815 on Training is 30.292302911931817\n",
            "Epoch #2. Accuracy on batch 2816 on Training is 30.290424210152644\n",
            "Epoch #2. Accuracy on batch 2817 on Training is 30.291873669268984\n",
            "Epoch #2. Accuracy on batch 2818 on Training is 30.287779354380987\n",
            "Epoch #2. Accuracy on batch 2819 on Training is 30.28701241134752\n",
            "Batch Id 2820 is having training loss of 2134.055419921875\n",
            "95448.625\n",
            "Epoch #2. Accuracy on batch 2820 on Training is 30.285138248847925\n",
            "Epoch #2. Accuracy on batch 2821 on Training is 30.282158043940466\n",
            "Epoch #2. Accuracy on batch 2822 on Training is 30.282500885582714\n",
            "Epoch #2. Accuracy on batch 2823 on Training is 30.285056657223794\n",
            "Epoch #2. Accuracy on batch 2824 on Training is 30.28429203539823\n",
            "Epoch #2. Accuracy on batch 2825 on Training is 30.283527954706297\n",
            "Epoch #2. Accuracy on batch 2826 on Training is 30.281659002476122\n",
            "Epoch #2. Accuracy on batch 2827 on Training is 30.28421145685997\n",
            "Epoch #2. Accuracy on batch 2828 on Training is 30.28344821491693\n",
            "Epoch #2. Accuracy on batch 2829 on Training is 30.279372791519435\n",
            "Epoch #2. Accuracy on batch 2830 on Training is 30.278611797951253\n",
            "Epoch #2. Accuracy on batch 2831 on Training is 30.28116172316384\n",
            "Epoch #2. Accuracy on batch 2832 on Training is 30.282606777267915\n",
            "Epoch #2. Accuracy on batch 2833 on Training is 30.284050811573746\n",
            "Epoch #2. Accuracy on batch 2834 on Training is 30.284391534391535\n",
            "Epoch #2. Accuracy on batch 2835 on Training is 30.283630112834977\n",
            "Epoch #2. Accuracy on batch 2836 on Training is 30.283970743743392\n",
            "Epoch #2. Accuracy on batch 2837 on Training is 30.284311134601833\n",
            "Epoch #2. Accuracy on batch 2838 on Training is 30.28355054596689\n",
            "Epoch #2. Accuracy on batch 2839 on Training is 30.286091549295776\n",
            "Batch Id 2840 is having training loss of 2143.22216796875\n",
            "67980.9921875\n",
            "Epoch #2. Accuracy on batch 2840 on Training is 30.277631115804294\n",
            "Epoch #2. Accuracy on batch 2841 on Training is 30.28347114707952\n",
            "Epoch #2. Accuracy on batch 2842 on Training is 30.283811115019347\n",
            "Epoch #2. Accuracy on batch 2843 on Training is 30.28524964838256\n",
            "Epoch #2. Accuracy on batch 2844 on Training is 30.286687170474515\n",
            "Epoch #2. Accuracy on batch 2845 on Training is 30.285927617709067\n",
            "Epoch #2. Accuracy on batch 2846 on Training is 30.28187565858799\n",
            "Epoch #2. Accuracy on batch 2847 on Training is 30.284410112359552\n",
            "Epoch #2. Accuracy on batch 2848 on Training is 30.28365215865216\n",
            "Epoch #2. Accuracy on batch 2849 on Training is 30.283991228070175\n",
            "Epoch #2. Accuracy on batch 2850 on Training is 30.28323395299895\n",
            "Epoch #2. Accuracy on batch 2851 on Training is 30.28138148667602\n",
            "Epoch #2. Accuracy on batch 2852 on Training is 30.28391167192429\n",
            "Epoch #2. Accuracy on batch 2853 on Training is 30.2864400840925\n",
            "Epoch #2. Accuracy on batch 2854 on Training is 30.2834938704028\n",
            "Epoch #2. Accuracy on batch 2855 on Training is 30.284926470588236\n",
            "Epoch #2. Accuracy on batch 2856 on Training is 30.286358067903397\n",
            "Epoch #2. Accuracy on batch 2857 on Training is 30.286695241427573\n",
            "Epoch #2. Accuracy on batch 2858 on Training is 30.284846100034976\n",
            "Epoch #2. Accuracy on batch 2859 on Training is 30.278627622377623\n",
            "Batch Id 2860 is having training loss of 2128.823486328125\n",
            "28.778074264526367\n",
            "Epoch #2. Accuracy on batch 2860 on Training is 30.276782593498776\n",
            "Epoch #2. Accuracy on batch 2861 on Training is 30.27493885394829\n",
            "Epoch #2. Accuracy on batch 2862 on Training is 30.27309640237513\n",
            "Epoch #2. Accuracy on batch 2863 on Training is 30.266890712290504\n",
            "Epoch #2. Accuracy on batch 2864 on Training is 30.272687609075042\n",
            "Epoch #2. Accuracy on batch 2865 on Training is 30.2719382414515\n",
            "Epoch #2. Accuracy on batch 2866 on Training is 30.272279386117894\n",
            "Epoch #2. Accuracy on batch 2867 on Training is 30.275889121338913\n",
            "Epoch #2. Accuracy on batch 2868 on Training is 30.27296096200767\n",
            "Epoch #2. Accuracy on batch 2869 on Training is 30.27330139372822\n",
            "Epoch #2. Accuracy on batch 2870 on Training is 30.272553117380703\n",
            "Epoch #2. Accuracy on batch 2871 on Training is 30.268541086350975\n",
            "Epoch #2. Accuracy on batch 2872 on Training is 30.27105812739297\n",
            "Epoch #2. Accuracy on batch 2873 on Training is 30.276835421016006\n",
            "Epoch #2. Accuracy on batch 2874 on Training is 30.27391304347826\n",
            "Epoch #2. Accuracy on batch 2875 on Training is 30.27751216968011\n",
            "Epoch #2. Accuracy on batch 2876 on Training is 30.27785019117136\n",
            "Epoch #2. Accuracy on batch 2877 on Training is 30.280359624739404\n",
            "Epoch #2. Accuracy on batch 2878 on Training is 30.278525529697813\n",
            "Epoch #2. Accuracy on batch 2879 on Training is 30.27886284722222\n",
            "Batch Id 2880 is having training loss of 2138.66845703125\n",
            "20.99953842163086\n",
            "Epoch #2. Accuracy on batch 2880 on Training is 30.27919993057966\n",
            "Epoch #2. Accuracy on batch 2881 on Training is 30.279536780013878\n",
            "Epoch #2. Accuracy on batch 2882 on Training is 30.2798733957683\n",
            "Epoch #2. Accuracy on batch 2883 on Training is 30.2747919556172\n",
            "Epoch #2. Accuracy on batch 2884 on Training is 30.27946273830156\n",
            "Epoch #2. Accuracy on batch 2885 on Training is 30.284130284130285\n",
            "Epoch #2. Accuracy on batch 2886 on Training is 30.285547280914443\n",
            "Epoch #2. Accuracy on batch 2887 on Training is 30.28479916897507\n",
            "Epoch #2. Accuracy on batch 2888 on Training is 30.277561439944616\n",
            "Epoch #2. Accuracy on batch 2889 on Training is 30.274653979238753\n",
            "Epoch #2. Accuracy on batch 2890 on Training is 30.27931511587686\n",
            "Epoch #2. Accuracy on batch 2891 on Training is 30.283973029045644\n",
            "Epoch #2. Accuracy on batch 2892 on Training is 30.28754752851711\n",
            "Epoch #2. Accuracy on batch 2893 on Training is 30.284640635798205\n",
            "Epoch #2. Accuracy on batch 2894 on Training is 30.291450777202073\n",
            "Epoch #2. Accuracy on batch 2895 on Training is 30.292860842541437\n",
            "Epoch #2. Accuracy on batch 2896 on Training is 30.29534863652054\n",
            "Epoch #2. Accuracy on batch 2897 on Training is 30.29459972394755\n",
            "Epoch #2. Accuracy on batch 2898 on Training is 30.298163159710246\n",
            "Epoch #2. Accuracy on batch 2899 on Training is 30.294181034482758\n",
            "Batch Id 2900 is having training loss of 2126.0234375\n",
            "13.035886764526367\n",
            "Epoch #2. Accuracy on batch 2900 on Training is 30.294510513615993\n",
            "Epoch #2. Accuracy on batch 2901 on Training is 30.29483976567884\n",
            "Epoch #2. Accuracy on batch 2902 on Training is 30.293015845676887\n",
            "Epoch #2. Accuracy on batch 2903 on Training is 30.296573691460054\n",
            "Epoch #2. Accuracy on batch 2904 on Training is 30.297977624784853\n",
            "Epoch #2. Accuracy on batch 2905 on Training is 30.30153131452168\n",
            "Epoch #2. Accuracy on batch 2906 on Training is 30.30185758513932\n",
            "Epoch #2. Accuracy on batch 2907 on Training is 30.30218363136176\n",
            "Epoch #2. Accuracy on batch 2908 on Training is 30.303583705740806\n",
            "Epoch #2. Accuracy on batch 2909 on Training is 30.303908934707902\n",
            "Epoch #2. Accuracy on batch 2910 on Training is 30.29993988320165\n",
            "Epoch #2. Accuracy on batch 2911 on Training is 30.2981198489011\n",
            "Epoch #2. Accuracy on batch 2912 on Training is 30.2930827325781\n",
            "Epoch #2. Accuracy on batch 2913 on Training is 30.297700754975978\n",
            "Epoch #2. Accuracy on batch 2914 on Training is 30.302315608919383\n",
            "Epoch #2. Accuracy on batch 2915 on Training is 30.30692729766804\n",
            "Epoch #2. Accuracy on batch 2916 on Training is 30.310464518340762\n",
            "Epoch #2. Accuracy on batch 2917 on Training is 30.30650274160384\n",
            "Epoch #2. Accuracy on batch 2918 on Training is 30.304684823569715\n",
            "Epoch #2. Accuracy on batch 2919 on Training is 30.302868150684933\n",
            "Batch Id 2920 is having training loss of 2139.5439453125\n",
            "18.57419204711914\n",
            "Epoch #2. Accuracy on batch 2920 on Training is 30.29998288257446\n",
            "Epoch #2. Accuracy on batch 2921 on Training is 30.30565537303217\n",
            "Epoch #2. Accuracy on batch 2922 on Training is 30.30597844680123\n",
            "Epoch #2. Accuracy on batch 2923 on Training is 30.30202633378933\n",
            "Epoch #2. Accuracy on batch 2924 on Training is 30.30128205128205\n",
            "Epoch #2. Accuracy on batch 2925 on Training is 30.298402255639097\n",
            "Epoch #2. Accuracy on batch 2926 on Training is 30.297659719849676\n",
            "Epoch #2. Accuracy on batch 2927 on Training is 30.29691769125683\n",
            "Epoch #2. Accuracy on batch 2928 on Training is 30.300443837487197\n",
            "Epoch #2. Accuracy on batch 2929 on Training is 30.299701365187712\n",
            "Epoch #2. Accuracy on batch 2930 on Training is 30.298959399522346\n",
            "Epoch #2. Accuracy on batch 2931 on Training is 30.298217939972716\n",
            "Epoch #2. Accuracy on batch 2932 on Training is 30.29960790998977\n",
            "Epoch #2. Accuracy on batch 2933 on Training is 30.29886673483299\n",
            "Epoch #2. Accuracy on batch 2934 on Training is 30.298126064735946\n",
            "Epoch #2. Accuracy on batch 2935 on Training is 30.29951464577657\n",
            "Epoch #2. Accuracy on batch 2936 on Training is 30.299838270343887\n",
            "Epoch #2. Accuracy on batch 2937 on Training is 30.301225323349218\n",
            "Epoch #2. Accuracy on batch 2938 on Training is 30.301548145627766\n",
            "Epoch #2. Accuracy on batch 2939 on Training is 30.298681972789115\n",
            "Batch Id 2940 is having training loss of 2126.7314453125\n",
            "32.76812744140625\n",
            "Epoch #2. Accuracy on batch 2940 on Training is 30.292630057803468\n",
            "Epoch #2. Accuracy on batch 2941 on Training is 30.291893269884433\n",
            "Epoch #2. Accuracy on batch 2942 on Training is 30.292218824328916\n",
            "Epoch #2. Accuracy on batch 2943 on Training is 30.293605638586957\n",
            "Epoch #2. Accuracy on batch 2944 on Training is 30.294991511035654\n",
            "Epoch #2. Accuracy on batch 2945 on Training is 30.293194161575016\n",
            "Epoch #2. Accuracy on batch 2946 on Training is 30.29670003393281\n",
            "Epoch #2. Accuracy on batch 2947 on Training is 30.303383649932158\n",
            "Epoch #2. Accuracy on batch 2948 on Training is 30.30476432689047\n",
            "Epoch #2. Accuracy on batch 2949 on Training is 30.304025423728813\n",
            "Epoch #2. Accuracy on batch 2950 on Training is 30.304345984412063\n",
            "Epoch #2. Accuracy on batch 2951 on Training is 30.30149051490515\n",
            "Epoch #2. Accuracy on batch 2952 on Training is 30.300753471046395\n",
            "Epoch #2. Accuracy on batch 2953 on Training is 30.304248476641842\n",
            "Epoch #2. Accuracy on batch 2954 on Training is 30.303510998307953\n",
            "Epoch #2. Accuracy on batch 2955 on Training is 30.304888362652232\n",
            "Epoch #2. Accuracy on batch 2956 on Training is 30.306264795400743\n",
            "Epoch #2. Accuracy on batch 2957 on Training is 30.30552738336714\n",
            "Epoch #2. Accuracy on batch 2958 on Training is 30.30162216965191\n",
            "Epoch #2. Accuracy on batch 2959 on Training is 30.29666385135135\n",
            "Batch Id 2960 is having training loss of 2124.7080078125\n",
            "9.430243492126465\n",
            "Epoch #2. Accuracy on batch 2960 on Training is 30.299096588990206\n",
            "Epoch #2. Accuracy on batch 2961 on Training is 30.303637744767048\n",
            "Epoch #2. Accuracy on batch 2962 on Training is 30.306066486668918\n",
            "Epoch #2. Accuracy on batch 2963 on Training is 30.304276315789473\n",
            "Epoch #2. Accuracy on batch 2964 on Training is 30.30881112984823\n",
            "Epoch #2. Accuracy on batch 2965 on Training is 30.315450101146325\n",
            "Epoch #2. Accuracy on batch 2966 on Training is 30.311552072800808\n",
            "Epoch #2. Accuracy on batch 2967 on Training is 30.310815363881403\n",
            "Epoch #2. Accuracy on batch 2968 on Training is 30.312184237116874\n",
            "Epoch #2. Accuracy on batch 2969 on Training is 30.3125\n",
            "Epoch #2. Accuracy on batch 2970 on Training is 30.311763715920566\n",
            "Epoch #2. Accuracy on batch 2971 on Training is 30.313130888290715\n",
            "Epoch #2. Accuracy on batch 2972 on Training is 30.31029263370333\n",
            "Epoch #2. Accuracy on batch 2973 on Training is 30.31165938130464\n",
            "Epoch #2. Accuracy on batch 2974 on Training is 30.310924369747898\n",
            "Epoch #2. Accuracy on batch 2975 on Training is 30.308089717741936\n",
            "Epoch #2. Accuracy on batch 2976 on Training is 30.307356399059454\n",
            "Epoch #2. Accuracy on batch 2977 on Training is 30.30977165883143\n",
            "Epoch #2. Accuracy on batch 2978 on Training is 30.309038267875128\n",
            "Epoch #2. Accuracy on batch 2979 on Training is 30.31459731543624\n",
            "Batch Id 2980 is having training loss of 2138.323486328125\n",
            "25.882610321044922\n",
            "Epoch #2. Accuracy on batch 2980 on Training is 30.312814491781282\n",
            "Epoch #2. Accuracy on batch 2981 on Training is 30.313128772635814\n",
            "Epoch #2. Accuracy on batch 2982 on Training is 30.309252430439155\n",
            "Epoch #2. Accuracy on batch 2983 on Training is 30.310614946380696\n",
            "Epoch #2. Accuracy on batch 2984 on Training is 30.30778894472362\n",
            "Epoch #2. Accuracy on batch 2985 on Training is 30.30810448760884\n",
            "Epoch #2. Accuracy on batch 2986 on Training is 30.308419819216606\n",
            "Epoch #2. Accuracy on batch 2987 on Training is 30.3076890896921\n",
            "Epoch #2. Accuracy on batch 2988 on Training is 30.306958849113414\n",
            "Epoch #2. Accuracy on batch 2989 on Training is 30.307274247491637\n",
            "Epoch #2. Accuracy on batch 2990 on Training is 30.305499832831828\n",
            "Epoch #2. Accuracy on batch 2991 on Training is 30.30581550802139\n",
            "Epoch #2. Accuracy on batch 2992 on Training is 30.312395589709322\n",
            "Epoch #2. Accuracy on batch 2993 on Training is 30.31375250501002\n",
            "Epoch #2. Accuracy on batch 2994 on Training is 30.31093489148581\n",
            "Epoch #2. Accuracy on batch 2995 on Training is 30.306033044058744\n",
            "Epoch #2. Accuracy on batch 2996 on Training is 30.30739072405739\n",
            "Epoch #2. Accuracy on batch 2997 on Training is 30.30457805203469\n",
            "Epoch #2. Accuracy on batch 2998 on Training is 30.306977325775257\n",
            "Epoch #2. Accuracy on batch 2999 on Training is 30.3\n",
            "Batch Id 3000 is having training loss of 2130.21337890625\n",
            "36.22057342529297\n",
            "Epoch #2. Accuracy on batch 3000 on Training is 30.300316561146285\n",
            "Epoch #2. Accuracy on batch 3001 on Training is 30.298550966022653\n",
            "Epoch #2. Accuracy on batch 3002 on Training is 30.295745920745922\n",
            "Epoch #2. Accuracy on batch 3003 on Training is 30.291902463382158\n",
            "Epoch #2. Accuracy on batch 3004 on Training is 30.28910149750416\n",
            "Epoch #2. Accuracy on batch 3005 on Training is 30.28630239520958\n",
            "Epoch #2. Accuracy on batch 3006 on Training is 30.28662287994679\n",
            "Epoch #2. Accuracy on batch 3007 on Training is 30.28278756648936\n",
            "Epoch #2. Accuracy on batch 3008 on Training is 30.28103190428714\n",
            "Epoch #2. Accuracy on batch 3009 on Training is 30.282392026578073\n",
            "Epoch #2. Accuracy on batch 3010 on Training is 30.2847891066091\n",
            "Epoch #2. Accuracy on batch 3011 on Training is 30.28718459495352\n",
            "Epoch #2. Accuracy on batch 3012 on Training is 30.285079984231384\n",
            "Epoch #2. Batch Id 0 is having validation loss of 24.86566925048828\n",
            "24.86566925048828\n",
            "Epoch #2. Batch Id 0 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 1 is having validation loss of 86.74049377441406\n",
            "148.6153106689453\n",
            "Epoch #2. Batch Id 1 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 2 is having validation loss of 5000.68310546875\n",
            "14828.56640625\n",
            "Epoch #2. Batch Id 2 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 3 is having validation loss of 3751.99462890625\n",
            "5.929316520690918\n",
            "Epoch #2. Batch Id 3 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 4 is having validation loss of 3020.150390625\n",
            "92.77374267578125\n",
            "Epoch #2. Batch Id 4 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 5 is having validation loss of 2524.0771484375\n",
            "43.710662841796875\n",
            "Epoch #2. Batch Id 5 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 6 is having validation loss of 2167.786865234375\n",
            "30.045618057250977\n",
            "Epoch #2. Batch Id 6 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 7 is having validation loss of 3836.41357421875\n",
            "15516.7998046875\n",
            "Epoch #2. Batch Id 7 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 8 is having validation loss of 3418.841796875\n",
            "78.2665786743164\n",
            "Epoch #2. Batch Id 8 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 9 is having validation loss of 31309.7890625\n",
            "282328.3125\n",
            "Epoch #2. Batch Id 9 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 10 is having validation loss of 33071.80859375\n",
            "50691.9921875\n",
            "Epoch #2. Batch Id 10 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 11 is having validation loss of 35348.65234375\n",
            "60393.9296875\n",
            "Epoch #2. Batch Id 11 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 12 is having validation loss of 32644.923828125\n",
            "200.1865234375\n",
            "Epoch #2. Batch Id 12 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 13 is having validation loss of 30314.724609375\n",
            "22.14211082458496\n",
            "Epoch #2. Batch Id 13 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 14 is having validation loss of 28315.306640625\n",
            "323.44293212890625\n",
            "Epoch #2. Batch Id 14 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 15 is having validation loss of 26545.818359375\n",
            "3.484743118286133\n",
            "Epoch #2. Batch Id 15 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 16 is having validation loss of 49971.5234375\n",
            "424782.75\n",
            "Epoch #2. Batch Id 16 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 17 is having validation loss of 52852.19140625\n",
            "101823.546875\n",
            "Epoch #2. Batch Id 17 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 18 is having validation loss of 53885.29296875\n",
            "72481.09375\n",
            "Epoch #2. Batch Id 18 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 19 is having validation loss of 51204.49609375\n",
            "269.3863830566406\n",
            "Epoch #2. Batch Id 19 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 20 is having validation loss of 49436.4375\n",
            "14075.296875\n",
            "Epoch #2. Batch Id 20 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 21 is having validation loss of 47200.84765625\n",
            "253.5019073486328\n",
            "Epoch #2. Batch Id 21 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 22 is having validation loss of 45155.03125\n",
            "147.04055786132812\n",
            "Epoch #2. Batch Id 22 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 23 is having validation loss of 43286.65625\n",
            "313.986328125\n",
            "Epoch #2. Batch Id 23 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 24 is having validation loss of 41559.015625\n",
            "95.65443420410156\n",
            "Epoch #2. Batch Id 24 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 25 is having validation loss of 39964.984375\n",
            "114.18026733398438\n",
            "Epoch #2. Batch Id 25 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 26 is having validation loss of 38486.76171875\n",
            "53.011234283447266\n",
            "Epoch #2. Batch Id 26 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 27 is having validation loss of 37858.203125\n",
            "20887.119140625\n",
            "Epoch #2. Batch Id 27 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 28 is having validation loss of 36557.3828125\n",
            "134.46188354492188\n",
            "Epoch #2. Batch Id 28 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 29 is having validation loss of 35342.86328125\n",
            "121.82868957519531\n",
            "Epoch #2. Batch Id 29 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 30 is having validation loss of 34203.62890625\n",
            "26.594741821289062\n",
            "Epoch #2. Batch Id 30 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 31 is having validation loss of 33138.00390625\n",
            "103.65890502929688\n",
            "Epoch #2. Batch Id 31 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 32 is having validation loss of 32135.08984375\n",
            "41.83481216430664\n",
            "Epoch #2. Batch Id 32 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 33 is having validation loss of 31279.380859375\n",
            "3040.993408203125\n",
            "Epoch #2. Batch Id 33 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 34 is having validation loss of 30386.583984375\n",
            "31.48514747619629\n",
            "Epoch #2. Batch Id 34 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 35 is having validation loss of 29543.126953125\n",
            "22.123292922973633\n",
            "Epoch #2. Batch Id 35 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 36 is having validation loss of 28747.478515625\n",
            "104.12385559082031\n",
            "Epoch #2. Batch Id 36 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 37 is having validation loss of 27994.5625\n",
            "136.68841552734375\n",
            "Epoch #2. Batch Id 37 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 38 is having validation loss of 27279.9453125\n",
            "124.48831176757812\n",
            "Epoch #2. Batch Id 38 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 39 is having validation loss of 26599.35546875\n",
            "56.32167434692383\n",
            "Epoch #2. Batch Id 39 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 40 is having validation loss of 25950.953125\n",
            "14.853392601013184\n",
            "Epoch #2. Batch Id 40 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 41 is having validation loss of 25334.12109375\n",
            "43.97765350341797\n",
            "Epoch #2. Batch Id 41 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 42 is having validation loss of 24753.005859375\n",
            "346.1562194824219\n",
            "Epoch #2. Batch Id 42 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 43 is having validation loss of 24217.240234375\n",
            "1179.345703125\n",
            "Epoch #2. Batch Id 43 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 44 is having validation loss of 33135.72265625\n",
            "425548.90625\n",
            "Epoch #2. Batch Id 44 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 45 is having validation loss of 32436.533203125\n",
            "973.0422973632812\n",
            "Epoch #2. Batch Id 45 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 46 is having validation loss of 31747.263671875\n",
            "40.84086990356445\n",
            "Epoch #2. Batch Id 46 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 47 is having validation loss of 31085.931640625\n",
            "3.3176825046539307\n",
            "Epoch #2. Batch Id 47 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 48 is having validation loss of 31292.384765625\n",
            "41202.1796875\n",
            "Epoch #2. Batch Id 48 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 49 is having validation loss of 34224.07421875\n",
            "177876.953125\n",
            "Epoch #2. Batch Id 49 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 50 is having validation loss of 37167.78515625\n",
            "184353.40625\n",
            "Epoch #2. Batch Id 50 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 51 is having validation loss of 36453.35546875\n",
            "17.39868927001953\n",
            "Epoch #2. Batch Id 51 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 52 is having validation loss of 41521.28515625\n",
            "305053.65625\n",
            "Epoch #2. Batch Id 52 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 53 is having validation loss of 40753.50390625\n",
            "61.07759475708008\n",
            "Epoch #2. Batch Id 53 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 54 is having validation loss of 40015.12890625\n",
            "142.96080017089844\n",
            "Epoch #2. Batch Id 54 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 55 is having validation loss of 39301.375\n",
            "44.934349060058594\n",
            "Epoch #2. Batch Id 55 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 56 is having validation loss of 38622.92578125\n",
            "629.7274169921875\n",
            "Epoch #2. Batch Id 56 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 57 is having validation loss of 37958.53125\n",
            "88.01649475097656\n",
            "Epoch #2. Batch Id 57 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 58 is having validation loss of 37315.29296875\n",
            "7.38721227645874\n",
            "Epoch #2. Batch Id 58 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 59 is having validation loss of 36697.74609375\n",
            "262.52825927734375\n",
            "Epoch #2. Batch Id 59 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 60 is having validation loss of 36096.2109375\n",
            "4.015739917755127\n",
            "Epoch #2. Batch Id 60 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 61 is having validation loss of 35520.7578125\n",
            "418.1278381347656\n",
            "Epoch #2. Batch Id 61 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 62 is having validation loss of 34957.140625\n",
            "12.936714172363281\n",
            "Epoch #2. Batch Id 62 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 63 is having validation loss of 34740.41015625\n",
            "21086.369140625\n",
            "Epoch #2. Batch Id 63 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 64 is having validation loss of 34206.01953125\n",
            "5.050056457519531\n",
            "Epoch #2. Batch Id 64 is having validation accuracy of 0.0\n",
            "Epoch #2. Batch Id 65 is having validation loss of 33688.09765625\n",
            "23.15339469909668\n",
            "Epoch #2. Batch Id 65 is having validation accuracy of 0.2840909090909091\n",
            "Epoch #2. Batch Id 66 is having validation loss of 33228.7578125\n",
            "2912.306640625\n",
            "Epoch #2. Batch Id 66 is having validation accuracy of 0.6996268656716418\n",
            "Epoch #2. Batch Id 67 is having validation loss of 32740.240234375\n",
            "9.513944625854492\n",
            "Epoch #2. Batch Id 67 is having validation accuracy of 0.9191176470588235\n",
            "Epoch #2. Batch Id 68 is having validation loss of 32265.904296875\n",
            "11.018826484680176\n",
            "Epoch #2. Batch Id 68 is having validation accuracy of 1.358695652173913\n",
            "Epoch #2. Batch Id 69 is having validation loss of 31805.36328125\n",
            "28.094934463500977\n",
            "Epoch #2. Batch Id 69 is having validation accuracy of 1.7857142857142858\n",
            "Epoch #2. Batch Id 70 is having validation loss of 31435.986328125\n",
            "5579.6611328125\n",
            "Epoch #2. Batch Id 70 is having validation accuracy of 2.288732394366197\n",
            "Epoch #2. Batch Id 71 is having validation loss of 30999.833984375\n",
            "33.052490234375\n",
            "Epoch #2. Batch Id 71 is having validation accuracy of 2.734375\n",
            "Epoch #2. Batch Id 72 is having validation loss of 30632.94140625\n",
            "4216.6455078125\n",
            "Epoch #2. Batch Id 72 is having validation accuracy of 3.2534246575342465\n",
            "Epoch #2. Batch Id 73 is having validation loss of 30219.216796875\n",
            "17.347503662109375\n",
            "Epoch #2. Batch Id 73 is having validation accuracy of 3.800675675675676\n",
            "Epoch #2. Batch Id 74 is having validation loss of 29816.630859375\n",
            "25.29629898071289\n",
            "Epoch #2. Batch Id 74 is having validation accuracy of 4.25\n",
            "Epoch #2. Batch Id 75 is having validation loss of 29424.513671875\n",
            "15.66352367401123\n",
            "Epoch #2. Batch Id 75 is having validation accuracy of 4.6875\n",
            "Epoch #2. Batch Id 76 is having validation loss of 29042.830078125\n",
            "34.81594467163086\n",
            "Epoch #2. Batch Id 76 is having validation accuracy of 5.154220779220779\n",
            "Epoch #2. Batch Id 77 is having validation loss of 28685.005859375\n",
            "1132.5203857421875\n",
            "Epoch #2. Batch Id 77 is having validation accuracy of 5.408653846153846\n",
            "Epoch #2. Batch Id 78 is having validation loss of 28322.541015625\n",
            "50.3122673034668\n",
            "Epoch #2. Batch Id 78 is having validation accuracy of 5.617088607594937\n",
            "Epoch #2. Batch Id 79 is having validation loss of 27968.712890625\n",
            "16.309967041015625\n",
            "Epoch #2. Batch Id 79 is having validation accuracy of 5.8984375\n",
            "Epoch #2. Batch Id 80 is having validation loss of 27623.72265625\n",
            "24.563539505004883\n",
            "Epoch #2. Batch Id 80 is having validation accuracy of 6.25\n",
            "Epoch #2. Batch Id 81 is having validation loss of 27287.240234375\n",
            "32.093528747558594\n",
            "Epoch #2. Batch Id 81 is having validation accuracy of 6.478658536585366\n",
            "Epoch #2. Batch Id 82 is having validation loss of 26961.255859375\n",
            "230.49766540527344\n",
            "Epoch #2. Batch Id 82 is having validation accuracy of 6.8147590361445785\n",
            "Epoch #2. Batch Id 83 is having validation loss of 26640.68359375\n",
            "33.127662658691406\n",
            "Epoch #2. Batch Id 83 is having validation accuracy of 7.217261904761905\n",
            "Epoch #2. Batch Id 84 is having validation loss of 26327.443359375\n",
            "15.240063667297363\n",
            "Epoch #2. Batch Id 84 is having validation accuracy of 7.536764705882353\n",
            "Epoch #2. Batch Id 85 is having validation loss of 26021.6015625\n",
            "25.102266311645508\n",
            "Epoch #2. Batch Id 85 is having validation accuracy of 7.957848837209302\n",
            "Epoch #2. Batch Id 86 is having validation loss of 25722.626953125\n",
            "10.7990140914917\n",
            "Epoch #2. Batch Id 86 is having validation accuracy of 8.369252873563218\n",
            "Epoch #2. Batch Id 87 is having validation loss of 25430.541015625\n",
            "19.002660751342773\n",
            "Epoch #2. Batch Id 87 is having validation accuracy of 8.664772727272727\n",
            "Epoch #2. Batch Id 88 is having validation loss of 25145.509765625\n",
            "62.83228302001953\n",
            "Epoch #2. Batch Id 88 is having validation accuracy of 8.848314606741573\n",
            "Epoch #2. Batch Id 89 is having validation loss of 24866.28125\n",
            "14.972166061401367\n",
            "Epoch #2. Batch Id 89 is having validation accuracy of 9.097222222222221\n",
            "Epoch #2. Batch Id 90 is having validation loss of 24593.525390625\n",
            "45.51712417602539\n",
            "Epoch #2. Batch Id 90 is having validation accuracy of 9.340659340659341\n",
            "Epoch #2. Batch Id 91 is having validation loss of 24326.443359375\n",
            "21.91926383972168\n",
            "Epoch #2. Batch Id 91 is having validation accuracy of 9.612771739130435\n",
            "Epoch #2. Batch Id 92 is having validation loss of 24065.765625\n",
            "83.34334564208984\n",
            "Epoch #2. Batch Id 92 is having validation accuracy of 9.845430107526882\n",
            "Epoch #2. Batch Id 93 is having validation loss of 23810.00390625\n",
            "24.148818969726562\n",
            "Epoch #2. Batch Id 93 is having validation accuracy of 10.106382978723405\n",
            "Epoch #2. Batch Id 94 is having validation loss of 23559.666015625\n",
            "27.876062393188477\n",
            "Epoch #2. Batch Id 94 is having validation accuracy of 10.460526315789474\n",
            "Epoch #2. Batch Id 95 is having validation loss of 23314.341796875\n",
            "8.534235000610352\n",
            "Epoch #2. Batch Id 95 is having validation accuracy of 10.83984375\n",
            "Epoch #2. Batch Id 96 is having validation loss of 23077.224609375\n",
            "314.0511169433594\n",
            "Epoch #2. Batch Id 96 is having validation accuracy of 11.050257731958762\n",
            "Epoch #2. Batch Id 97 is having validation loss of 22842.4375\n",
            "68.17456817626953\n",
            "Epoch #2. Batch Id 97 is having validation accuracy of 11.383928571428571\n",
            "Epoch #2. Batch Id 98 is having validation loss of 22611.912109375\n",
            "20.363964080810547\n",
            "Epoch #2. Batch Id 98 is having validation accuracy of 11.58459595959596\n",
            "Epoch #2. Batch Id 99 is having validation loss of 22386.0703125\n",
            "27.734195709228516\n",
            "Epoch #2. Batch Id 99 is having validation accuracy of 11.78125\n",
            "Epoch #2. Batch Id 100 is having validation loss of 22165.025390625\n",
            "60.476966857910156\n",
            "Epoch #2. Batch Id 100 is having validation accuracy of 11.881188118811881\n",
            "Epoch #2. Batch Id 101 is having validation loss of 21947.970703125\n",
            "25.524520874023438\n",
            "Epoch #2. Batch Id 101 is having validation accuracy of 12.16299019607843\n",
            "Epoch #2. Batch Id 102 is having validation loss of 21735.08203125\n",
            "20.382104873657227\n",
            "Epoch #2. Batch Id 102 is having validation accuracy of 12.469660194174757\n",
            "Epoch #2. Batch Id 103 is having validation loss of 21526.419921875\n",
            "34.255348205566406\n",
            "Epoch #2. Batch Id 103 is having validation accuracy of 12.530048076923077\n",
            "Epoch #2. Batch Id 104 is having validation loss of 21321.650390625\n",
            "25.557029724121094\n",
            "Epoch #2. Batch Id 104 is having validation accuracy of 12.886904761904763\n",
            "Epoch #2. Batch Id 105 is having validation loss of 21120.857421875\n",
            "37.54286575317383\n",
            "Epoch #2. Batch Id 105 is having validation accuracy of 13.119103773584905\n",
            "Epoch #2. Batch Id 106 is having validation loss of 20924.056640625\n",
            "63.23519515991211\n",
            "Epoch #2. Batch Id 106 is having validation accuracy of 13.288551401869158\n",
            "Epoch #2. Batch Id 107 is having validation loss of 20730.671875\n",
            "38.463863372802734\n",
            "Epoch #2. Batch Id 107 is having validation accuracy of 13.45486111111111\n",
            "Epoch #2. Batch Id 108 is having validation loss of 20540.65625\n",
            "18.99220085144043\n",
            "Epoch #2. Batch Id 108 is having validation accuracy of 13.53211009174312\n",
            "Epoch #2. Batch Id 109 is having validation loss of 20354.291015625\n",
            "40.40297317504883\n",
            "Epoch #2. Batch Id 109 is having validation accuracy of 13.607954545454545\n",
            "Epoch #2. Batch Id 110 is having validation loss of 20171.7578125\n",
            "93.0477294921875\n",
            "Epoch #2. Batch Id 110 is having validation accuracy of 13.682432432432432\n",
            "Epoch #2. Batch Id 111 is having validation loss of 19991.80078125\n",
            "16.573400497436523\n",
            "Epoch #2. Batch Id 111 is having validation accuracy of 13.922991071428571\n",
            "Epoch #2. Batch Id 112 is having validation loss of 19814.986328125\n",
            "11.867151260375977\n",
            "Epoch #2. Batch Id 112 is having validation accuracy of 14.15929203539823\n",
            "Epoch #2. Batch Id 113 is having validation loss of 19641.4453125\n",
            "31.400169372558594\n",
            "Epoch #2. Batch Id 113 is having validation accuracy of 14.30921052631579\n",
            "Epoch #2. Batch Id 114 is having validation loss of 19470.8984375\n",
            "28.56072998046875\n",
            "Epoch #2. Batch Id 114 is having validation accuracy of 14.53804347826087\n",
            "Epoch #2. Batch Id 115 is having validation loss of 19303.32421875\n",
            "32.19883728027344\n",
            "Epoch #2. Batch Id 115 is having validation accuracy of 14.547413793103448\n",
            "Epoch #2. Batch Id 116 is having validation loss of 19138.466796875\n",
            "14.999778747558594\n",
            "Epoch #2. Batch Id 116 is having validation accuracy of 14.663461538461538\n",
            "Epoch #2. Batch Id 117 is having validation loss of 18976.515625\n",
            "28.24712371826172\n",
            "Epoch #2. Batch Id 117 is having validation accuracy of 14.804025423728813\n",
            "Epoch #2. Batch Id 118 is having validation loss of 18817.400390625\n",
            "41.89879608154297\n",
            "Epoch #2. Batch Id 118 is having validation accuracy of 14.942226890756302\n",
            "Epoch #2. Batch Id 119 is having validation loss of 18863.5546875\n",
            "24355.91015625\n",
            "Epoch #2. Batch Id 119 is having validation accuracy of 15.15625\n",
            "Epoch #2. Batch Id 120 is having validation loss of 18707.84765625\n",
            "23.10121726989746\n",
            "Epoch #2. Batch Id 120 is having validation accuracy of 15.49586776859504\n",
            "Epoch #2. Batch Id 121 is having validation loss of 19128.748046875\n",
            "70057.6015625\n",
            "Epoch #2. Batch Id 121 is having validation accuracy of 15.522540983606557\n",
            "Epoch #2. Batch Id 122 is having validation loss of 19043.697265625\n",
            "8667.5556640625\n",
            "Epoch #2. Batch Id 122 is having validation accuracy of 15.65040650406504\n",
            "Epoch #2. Batch Id 123 is having validation loss of 18890.21875\n",
            "12.389394760131836\n",
            "Epoch #2. Batch Id 123 is having validation accuracy of 15.851814516129032\n",
            "Epoch #2. Batch Id 124 is having validation loss of 18739.376953125\n",
            "35.110347747802734\n",
            "Epoch #2. Batch Id 124 is having validation accuracy of 16.1\n",
            "Epoch #2. Batch Id 125 is having validation loss of 18590.837890625\n",
            "23.546770095825195\n",
            "Epoch #2. Batch Id 125 is having validation accuracy of 16.319444444444443\n",
            "Epoch #2. Batch Id 126 is having validation loss of 18444.609375\n",
            "19.750442504882812\n",
            "Epoch #2. Batch Id 126 is having validation accuracy of 16.313976377952756\n",
            "Epoch #2. Batch Id 127 is having validation loss of 18300.8828125\n",
            "47.49934768676758\n",
            "Epoch #2. Batch Id 127 is having validation accuracy of 16.4306640625\n",
            "Epoch #2. Batch Id 128 is having validation loss of 18189.19921875\n",
            "3893.694091796875\n",
            "Epoch #2. Batch Id 128 is having validation accuracy of 16.521317829457363\n",
            "Epoch #2. Batch Id 129 is having validation loss of 18049.3671875\n",
            "10.98862075805664\n",
            "Epoch #2. Batch Id 129 is having validation accuracy of 16.58653846153846\n",
            "Epoch #2. Batch Id 130 is having validation loss of 17911.677734375\n",
            "12.000398635864258\n",
            "Epoch #2. Batch Id 130 is having validation accuracy of 16.72232824427481\n",
            "Epoch #2. Batch Id 131 is having validation loss of 17776.439453125\n",
            "60.2125129699707\n",
            "Epoch #2. Batch Id 131 is having validation accuracy of 16.927083333333332\n",
            "Epoch #2. Batch Id 132 is having validation loss of 17642.923828125\n",
            "18.947513580322266\n",
            "Epoch #2. Batch Id 132 is having validation accuracy of 16.8703007518797\n",
            "Epoch #2. Batch Id 133 is having validation loss of 17669.771484375\n",
            "21240.533203125\n",
            "Epoch #2. Batch Id 133 is having validation accuracy of 16.93097014925373\n",
            "Epoch #2. Batch Id 134 is having validation loss of 17538.951171875\n",
            "9.045727729797363\n",
            "Epoch #2. Batch Id 134 is having validation accuracy of 17.175925925925927\n",
            "Epoch #2. Batch Id 135 is having validation loss of 17410.263671875\n",
            "37.576473236083984\n",
            "Epoch #2. Batch Id 135 is having validation accuracy of 17.233455882352942\n",
            "Epoch #2. Batch Id 136 is having validation loss of 17283.2734375\n",
            "12.470562934875488\n",
            "Epoch #2. Batch Id 136 is having validation accuracy of 17.404197080291972\n",
            "Epoch #2. Batch Id 137 is having validation loss of 17158.13671875\n",
            "14.273463249206543\n",
            "Epoch #2. Batch Id 137 is having validation accuracy of 17.6856884057971\n",
            "Epoch #2. Batch Id 138 is having validation loss of 17039.53125\n",
            "671.8568115234375\n",
            "Epoch #2. Batch Id 138 is having validation accuracy of 17.715827338129497\n",
            "Epoch #2. Batch Id 139 is having validation loss of 16918.017578125\n",
            "27.521686553955078\n",
            "Epoch #2. Batch Id 139 is having validation accuracy of 17.8125\n",
            "Epoch #2. Batch Id 140 is having validation loss of 16798.171875\n",
            "19.66594696044922\n",
            "Epoch #2. Batch Id 140 is having validation accuracy of 17.92996453900709\n",
            "Epoch #2. Batch Id 141 is having validation loss of 16727.6953125\n",
            "6790.47265625\n",
            "Epoch #2. Batch Id 141 is having validation accuracy of 18.111795774647888\n",
            "Epoch #2. Batch Id 142 is having validation loss of 16610.8671875\n",
            "21.202632904052734\n",
            "Epoch #2. Batch Id 142 is having validation accuracy of 18.291083916083917\n",
            "Epoch #2. Batch Id 143 is having validation loss of 16495.671875\n",
            "22.7242374420166\n",
            "Epoch #2. Batch Id 143 is having validation accuracy of 18.51128472222222\n",
            "Epoch #2. Batch Id 144 is having validation loss of 16452.576171875\n",
            "10246.724609375\n",
            "Epoch #2. Batch Id 144 is having validation accuracy of 18.728448275862068\n",
            "Epoch #2. Batch Id 145 is having validation loss of 16340.0849609375\n",
            "28.92934226989746\n",
            "Epoch #2. Batch Id 145 is having validation accuracy of 18.728595890410958\n",
            "Epoch #2. Batch Id 146 is having validation loss of 16229.1279296875\n",
            "29.464317321777344\n",
            "Epoch #2. Batch Id 146 is having validation accuracy of 18.856292517006803\n",
            "Epoch #2. Batch Id 147 is having validation loss of 16119.697265625\n",
            "33.4508171081543\n",
            "Epoch #2. Batch Id 147 is having validation accuracy of 18.96114864864865\n",
            "Epoch #2. Batch Id 148 is having validation loss of 16011.7158203125\n",
            "30.466421127319336\n",
            "Epoch #2. Batch Id 148 is having validation accuracy of 19.106543624161073\n",
            "Epoch #2. Batch Id 149 is having validation loss of 15907.890625\n",
            "437.9469299316406\n",
            "Epoch #2. Batch Id 149 is having validation accuracy of 19.1875\n",
            "Epoch #2. Batch Id 150 is having validation loss of 15802.86328125\n",
            "48.739471435546875\n",
            "Epoch #2. Batch Id 150 is having validation accuracy of 19.329470198675498\n",
            "Epoch #2. Batch Id 151 is having validation loss of 15700.83984375\n",
            "295.2489929199219\n",
            "Epoch #2. Batch Id 151 is having validation accuracy of 19.407894736842106\n",
            "Epoch #2. Batch Id 152 is having validation loss of 15598.3759765625\n",
            "23.82648468017578\n",
            "Epoch #2. Batch Id 152 is having validation accuracy of 19.526143790849673\n",
            "Epoch #2. Batch Id 153 is having validation loss of 15497.1494140625\n",
            "9.427281379699707\n",
            "Epoch #2. Batch Id 153 is having validation accuracy of 19.683441558441558\n",
            "Epoch #2. Batch Id 154 is having validation loss of 15397.328125\n",
            "24.9068660736084\n",
            "Epoch #2. Batch Id 154 is having validation accuracy of 19.778225806451612\n",
            "Epoch #2. Batch Id 155 is having validation loss of 15298.8056640625\n",
            "27.874534606933594\n",
            "Epoch #2. Batch Id 155 is having validation accuracy of 19.81169871794872\n",
            "Epoch #2. Batch Id 156 is having validation loss of 15702.4970703125\n",
            "78678.390625\n",
            "Epoch #2. Batch Id 156 is having validation accuracy of 19.964171974522294\n",
            "Epoch #2. Batch Id 157 is having validation loss of 15727.2919921875\n",
            "19620.119140625\n",
            "Epoch #2. Batch Id 157 is having validation accuracy of 20.11471518987342\n",
            "Epoch #2. Batch Id 158 is having validation loss of 15628.45703125\n",
            "12.548827171325684\n",
            "Epoch #2. Batch Id 158 is having validation accuracy of 20.16509433962264\n",
            "Epoch #2. Batch Id 159 is having validation loss of 15531.3564453125\n",
            "92.36495208740234\n",
            "Epoch #2. Batch Id 159 is having validation accuracy of 20.21484375\n",
            "Epoch #2. Batch Id 160 is having validation loss of 15435.1064453125\n",
            "35.126121520996094\n",
            "Epoch #2. Batch Id 160 is having validation accuracy of 20.16692546583851\n",
            "Epoch #2. Batch Id 161 is having validation loss of 15339.96875\n",
            "22.750415802001953\n",
            "Epoch #2. Batch Id 161 is having validation accuracy of 20.17746913580247\n",
            "Epoch #2. Batch Id 162 is having validation loss of 15246.072265625\n",
            "34.832244873046875\n",
            "Epoch #2. Batch Id 162 is having validation accuracy of 20.341257668711656\n",
            "Epoch #2. Batch Id 163 is having validation loss of 15156.5107421875\n",
            "557.9697265625\n",
            "Epoch #2. Batch Id 163 is having validation accuracy of 20.388719512195124\n",
            "Epoch #2. Batch Id 164 is having validation loss of 15064.923828125\n",
            "44.645790100097656\n",
            "Epoch #2. Batch Id 164 is having validation accuracy of 20.435606060606062\n",
            "Epoch #2. Batch Id 165 is having validation loss of 14974.27734375\n",
            "17.559167861938477\n",
            "Epoch #2. Batch Id 165 is having validation accuracy of 20.481927710843372\n",
            "Epoch #2. Batch Id 166 is having validation loss of 14884.708984375\n",
            "16.359046936035156\n",
            "Epoch #2. Batch Id 166 is having validation accuracy of 20.565119760479043\n",
            "Epoch #2. Batch Id 167 is having validation loss of 14796.30078125\n",
            "32.213348388671875\n",
            "Epoch #2. Batch Id 167 is having validation accuracy of 20.647321428571427\n",
            "Epoch #2. Batch Id 168 is having validation loss of 14708.828125\n",
            "13.440123558044434\n",
            "Epoch #2. Batch Id 168 is having validation accuracy of 20.65458579881657\n",
            "Epoch #2. Batch Id 169 is having validation loss of 14636.4296875\n",
            "2401.117919921875\n",
            "Epoch #2. Batch Id 169 is having validation accuracy of 20.753676470588236\n",
            "Epoch #2. Batch Id 170 is having validation loss of 14550.9560546875\n",
            "20.52077865600586\n",
            "Epoch #2. Batch Id 170 is having validation accuracy of 20.778508771929825\n",
            "Epoch #2. Batch Id 171 is having validation loss of 14477.2255859375\n",
            "1869.3843994140625\n",
            "Epoch #2. Batch Id 171 is having validation accuracy of 20.78488372093023\n",
            "Epoch #2. Batch Id 172 is having validation loss of 14393.681640625\n",
            "24.158226013183594\n",
            "Epoch #2. Batch Id 172 is having validation accuracy of 20.89956647398844\n",
            "Epoch #2. Batch Id 173 is having validation loss of 14311.5830078125\n",
            "108.58202362060547\n",
            "Epoch #2. Batch Id 173 is having validation accuracy of 21.012931034482758\n",
            "Epoch #2. Batch Id 174 is having validation loss of 14246.591796875\n",
            "2938.153076171875\n",
            "Epoch #2. Batch Id 174 is having validation accuracy of 20.982142857142858\n",
            "Epoch #2. Batch Id 175 is having validation loss of 14165.78125\n",
            "23.8991641998291\n",
            "Epoch #2. Batch Id 175 is having validation accuracy of 21.040482954545453\n",
            "Epoch #2. Batch Id 176 is having validation loss of 14085.9912109375\n",
            "43.02886962890625\n",
            "Epoch #2. Batch Id 176 is having validation accuracy of 21.009887005649716\n",
            "Epoch #2. Batch Id 177 is having validation loss of 14155.6884765625\n",
            "26492.142578125\n",
            "Epoch #2. Batch Id 177 is having validation accuracy of 20.944522471910112\n",
            "Epoch #2. Batch Id 178 is having validation loss of 14076.63671875\n",
            "5.355875015258789\n",
            "Epoch #2. Batch Id 178 is having validation accuracy of 20.98463687150838\n",
            "Epoch #2. Batch Id 179 is having validation loss of 13999.1474609375\n",
            "128.56968688964844\n",
            "Epoch #2. Batch Id 179 is having validation accuracy of 21.07638888888889\n",
            "Epoch #2. Batch Id 180 is having validation loss of 13921.9287109375\n",
            "22.55116081237793\n",
            "Epoch #2. Batch Id 180 is having validation accuracy of 21.25345303867403\n",
            "Epoch #2. Batch Id 181 is having validation loss of 13846.1171875\n",
            "124.1943130493164\n",
            "Epoch #2. Batch Id 181 is having validation accuracy of 21.34271978021978\n",
            "Epoch #2. Batch Id 182 is having validation loss of 13770.5185546875\n",
            "11.63388442993164\n",
            "Epoch #2. Batch Id 182 is having validation accuracy of 21.48224043715847\n",
            "Epoch #2. Batch Id 183 is having validation loss of 13695.80078125\n",
            "22.41362953186035\n",
            "Epoch #2. Batch Id 183 is having validation accuracy of 21.535326086956523\n",
            "Epoch #2. Batch Id 184 is having validation loss of 13621.8662109375\n",
            "17.8192081451416\n",
            "Epoch #2. Batch Id 184 is having validation accuracy of 21.638513513513512\n",
            "Epoch #2. Batch Id 185 is having validation loss of 13548.7275390625\n",
            "18.16345977783203\n",
            "Epoch #2. Batch Id 185 is having validation accuracy of 21.774193548387096\n",
            "Epoch #2. Batch Id 186 is having validation loss of 13476.7333984375\n",
            "85.87937927246094\n",
            "Epoch #2. Batch Id 186 is having validation accuracy of 21.808155080213904\n",
            "Epoch #2. Batch Id 187 is having validation loss of 13405.1708984375\n",
            "23.07147979736328\n",
            "Epoch #2. Batch Id 187 is having validation accuracy of 21.924867021276597\n",
            "Epoch #2. Batch Id 188 is having validation loss of 13444.9521484375\n",
            "20923.802734375\n",
            "Epoch #2. Batch Id 188 is having validation accuracy of 22.007275132275133\n",
            "Epoch #2. Batch Id 189 is having validation loss of 13424.630859375\n",
            "9583.8935546875\n",
            "Epoch #2. Batch Id 189 is having validation accuracy of 21.99013157894737\n",
            "Epoch #2. Batch Id 190 is having validation loss of 13354.4638671875\n",
            "22.81879997253418\n",
            "Epoch #2. Batch Id 190 is having validation accuracy of 22.022251308900522\n",
            "Epoch #2. Batch Id 191 is having validation loss of 13285.06640625\n",
            "30.10597801208496\n",
            "Epoch #2. Batch Id 191 is having validation accuracy of 22.054036458333332\n",
            "Epoch #2. Batch Id 192 is having validation loss of 13216.3125\n",
            "15.481340408325195\n",
            "Epoch #2. Batch Id 192 is having validation accuracy of 22.101683937823836\n",
            "Epoch #2. Batch Id 193 is having validation loss of 13148.822265625\n",
            "123.1408920288086\n",
            "Epoch #2. Batch Id 193 is having validation accuracy of 22.132731958762886\n",
            "Epoch #2. Batch Id 194 is having validation loss of 13081.5048828125\n",
            "21.89946746826172\n",
            "Epoch #2. Batch Id 194 is having validation accuracy of 22.115384615384617\n",
            "Epoch #2. Batch Id 195 is having validation loss of 13014.884765625\n",
            "24.001338958740234\n",
            "Epoch #2. Batch Id 195 is having validation accuracy of 22.082270408163264\n",
            "Epoch #2. Batch Id 196 is having validation loss of 12948.96875\n",
            "29.509830474853516\n",
            "Epoch #2. Batch Id 196 is having validation accuracy of 22.16053299492386\n",
            "Epoch #2. Batch Id 197 is having validation loss of 12884.1201171875\n",
            "108.95734405517578\n",
            "Epoch #2. Batch Id 197 is having validation accuracy of 22.15909090909091\n",
            "Epoch #2. Batch Id 198 is having validation loss of 12835.2041015625\n",
            "3149.8427734375\n",
            "Epoch #2. Batch Id 198 is having validation accuracy of 22.189070351758794\n",
            "Epoch #2. Batch Id 199 is having validation loss of 12835.7021484375\n",
            "12934.8525390625\n",
            "Epoch #2. Batch Id 199 is having validation accuracy of 22.171875\n",
            "Epoch #2. Batch Id 200 is having validation loss of 12771.9814453125\n",
            "27.803747177124023\n",
            "Epoch #2. Batch Id 200 is having validation accuracy of 22.18594527363184\n",
            "Epoch #2. Batch Id 201 is having validation loss of 12708.8681640625\n",
            "23.013927459716797\n",
            "Epoch #2. Batch Id 201 is having validation accuracy of 22.153465346534652\n",
            "Epoch #2. Batch Id 202 is having validation loss of 12646.5146484375\n",
            "51.03384017944336\n",
            "Epoch #2. Batch Id 202 is having validation accuracy of 22.167487684729064\n",
            "Epoch #2. Batch Id 203 is having validation loss of 12584.751953125\n",
            "46.8569450378418\n",
            "Epoch #2. Batch Id 203 is having validation accuracy of 22.15073529411765\n",
            "Epoch #2. Batch Id 204 is having validation loss of 12523.4462890625\n",
            "17.073728561401367\n",
            "Epoch #2. Batch Id 204 is having validation accuracy of 22.271341463414632\n",
            "Epoch #2. Batch Id 205 is having validation loss of 12462.732421875\n",
            "16.42897605895996\n",
            "Epoch #2. Batch Id 205 is having validation accuracy of 22.33009708737864\n",
            "Epoch #2. Batch Id 206 is having validation loss of 12403.1171875\n",
            "122.28593444824219\n",
            "Epoch #2. Batch Id 206 is having validation accuracy of 22.327898550724637\n",
            "Epoch #2. Batch Id 207 is having validation loss of 12343.70703125\n",
            "45.74872589111328\n",
            "Epoch #2. Batch Id 207 is having validation accuracy of 22.265625\n",
            "Epoch #2. Batch Id 208 is having validation loss of 12284.787109375\n",
            "29.538476943969727\n",
            "Epoch #2. Batch Id 208 is having validation accuracy of 22.278708133971293\n",
            "Epoch #2. Batch Id 209 is having validation loss of 12233.03125\n",
            "1416.1390380859375\n",
            "Epoch #2. Batch Id 209 is having validation accuracy of 22.291666666666668\n",
            "Epoch #2. Batch Id 210 is having validation loss of 12175.2880859375\n",
            "49.21347427368164\n",
            "Epoch #2. Batch Id 210 is having validation accuracy of 22.348933649289098\n",
            "Epoch #2. Batch Id 211 is having validation loss of 12117.9609375\n",
            "21.954959869384766\n",
            "Epoch #2. Batch Id 211 is having validation accuracy of 22.40566037735849\n",
            "Epoch #2. Batch Id 212 is having validation loss of 12061.205078125\n",
            "29.031248092651367\n",
            "Epoch #2. Batch Id 212 is having validation accuracy of 22.491197183098592\n",
            "Epoch #2. Batch Id 213 is having validation loss of 12005.0361328125\n",
            "41.115501403808594\n",
            "Epoch #2. Batch Id 213 is having validation accuracy of 22.444509345794394\n",
            "Epoch #2. Batch Id 214 is having validation loss of 11949.2734375\n",
            "15.959607124328613\n",
            "Epoch #2. Batch Id 214 is having validation accuracy of 22.441860465116278\n",
            "Epoch #2. Batch Id 215 is having validation loss of 11894.0810546875\n",
            "27.693071365356445\n",
            "Epoch #2. Batch Id 215 is having validation accuracy of 22.48263888888889\n",
            "Epoch #2. Batch Id 216 is having validation loss of 11839.3291015625\n",
            "12.910506248474121\n",
            "Epoch #2. Batch Id 216 is having validation accuracy of 22.55184331797235\n",
            "Epoch #2. Batch Id 217 is having validation loss of 11785.1884765625\n",
            "36.625946044921875\n",
            "Epoch #2. Batch Id 217 is having validation accuracy of 22.52006880733945\n",
            "Epoch #2. Batch Id 218 is having validation loss of 12003.6328125\n",
            "59624.44140625\n",
            "Epoch #2. Batch Id 218 is having validation accuracy of 22.559931506849313\n",
            "Epoch #2. Batch Id 219 is having validation loss of 11949.1787109375\n",
            "23.625778198242188\n",
            "Epoch #2. Batch Id 219 is having validation accuracy of 22.571022727272727\n",
            "Epoch #2. Batch Id 220 is having validation loss of 11895.18359375\n",
            "16.36151123046875\n",
            "Epoch #2. Batch Id 220 is having validation accuracy of 22.596153846153847\n",
            "Epoch #2. Batch Id 221 is having validation loss of 11841.740234375\n",
            "30.703861236572266\n",
            "Epoch #2. Batch Id 221 is having validation accuracy of 22.60698198198198\n",
            "Epoch #2. Batch Id 222 is having validation loss of 11788.7587890625\n",
            "26.858890533447266\n",
            "Epoch #2. Batch Id 222 is having validation accuracy of 22.617713004484305\n",
            "Epoch #2. Batch Id 223 is having validation loss of 11736.240234375\n",
            "24.698415756225586\n",
            "Epoch #2. Batch Id 223 is having validation accuracy of 22.698102678571427\n",
            "Epoch #2. Batch Id 224 is having validation loss of 11684.18359375\n",
            "23.471778869628906\n",
            "Epoch #2. Batch Id 224 is having validation accuracy of 22.680555555555557\n",
            "Epoch #2. Batch Id 225 is having validation loss of 11632.5947265625\n",
            "25.081424713134766\n",
            "Epoch #2. Batch Id 225 is having validation accuracy of 22.690818584070797\n",
            "Epoch #2. Batch Id 226 is having validation loss of 11581.431640625\n",
            "18.589120864868164\n",
            "Epoch #2. Batch Id 226 is having validation accuracy of 22.783590308370044\n",
            "Epoch #2. Batch Id 227 is having validation loss of 11619.88671875\n",
            "20349.146484375\n",
            "Epoch #2. Batch Id 227 is having validation accuracy of 22.875548245614034\n",
            "Epoch #2. Batch Id 228 is having validation loss of 11569.2421875\n",
            "22.35577392578125\n",
            "Epoch #2. Batch Id 228 is having validation accuracy of 22.857532751091703\n",
            "Epoch #2. Batch Id 229 is having validation loss of 11518.98046875\n",
            "9.15599536895752\n",
            "Epoch #2. Batch Id 229 is having validation accuracy of 22.921195652173914\n",
            "Epoch #2. Batch Id 230 is having validation loss of 11469.203125\n",
            "20.407663345336914\n",
            "Epoch #2. Batch Id 230 is having validation accuracy of 22.943722943722943\n",
            "Epoch #2. Batch Id 231 is having validation loss of 11419.888671875\n",
            "28.21432113647461\n",
            "Epoch #2. Batch Id 231 is having validation accuracy of 23.046875\n",
            "Epoch #2. Batch Id 232 is having validation loss of 11370.96875\n",
            "21.659820556640625\n",
            "Epoch #2. Batch Id 232 is having validation accuracy of 23.135729613733904\n",
            "Epoch #2. Batch Id 233 is having validation loss of 11322.4697265625\n",
            "22.12100601196289\n",
            "Epoch #2. Batch Id 233 is having validation accuracy of 23.237179487179485\n",
            "Epoch #2. Batch Id 234 is having validation loss of 11274.3125\n",
            "5.5545783042907715\n",
            "Epoch #2. Batch Id 234 is having validation accuracy of 23.351063829787233\n",
            "Epoch #2. Batch Id 235 is having validation loss of 11226.5966796875\n",
            "13.358091354370117\n",
            "Epoch #2. Batch Id 235 is having validation accuracy of 23.42425847457627\n",
            "Epoch #2. Batch Id 236 is having validation loss of 11179.6103515625\n",
            "90.74207305908203\n",
            "Epoch #2. Batch Id 236 is having validation accuracy of 23.43090717299578\n",
            "Epoch #2. Batch Id 237 is having validation loss of 11132.6953125\n",
            "13.940439224243164\n",
            "Epoch #2. Batch Id 237 is having validation accuracy of 23.51628151260504\n",
            "Epoch #2. Batch Id 238 is having validation loss of 11086.21875\n",
            "24.79796028137207\n",
            "Epoch #2. Batch Id 238 is having validation accuracy of 23.58786610878661\n",
            "Epoch #2. Batch Id 239 is having validation loss of 11064.0732421875\n",
            "5771.26171875\n",
            "Epoch #2. Batch Id 239 is having validation accuracy of 23.580729166666668\n",
            "Epoch #2. Batch Id 240 is having validation loss of 11018.3583984375\n",
            "46.76211166381836\n",
            "Epoch #2. Batch Id 240 is having validation accuracy of 23.62551867219917\n",
            "Epoch #2. Batch Id 241 is having validation loss of 10972.87890625\n",
            "12.428810119628906\n",
            "Epoch #2. Batch Id 241 is having validation accuracy of 23.68285123966942\n",
            "Epoch #2. Batch Id 242 is having validation loss of 10927.7978515625\n",
            "18.11482810974121\n",
            "Epoch #2. Batch Id 242 is having validation accuracy of 23.778292181069958\n",
            "Epoch #2. Batch Id 243 is having validation loss of 10913.630859375\n",
            "7471.068359375\n",
            "Epoch #2. Batch Id 243 is having validation accuracy of 23.83452868852459\n",
            "Epoch #2. Batch Id 244 is having validation loss of 10967.8359375\n",
            "24193.806640625\n",
            "Epoch #2. Batch Id 244 is having validation accuracy of 23.864795918367346\n",
            "Epoch #2. Batch Id 245 is having validation loss of 10923.32421875\n",
            "17.9359188079834\n",
            "Epoch #2. Batch Id 245 is having validation accuracy of 23.945630081300813\n",
            "Epoch #2. Batch Id 246 is having validation loss of 10879.1513671875\n",
            "12.59510612487793\n",
            "Epoch #2. Batch Id 246 is having validation accuracy of 23.987854251012145\n",
            "Epoch #2. Batch Id 247 is having validation loss of 10835.392578125\n",
            "26.930402755737305\n",
            "Epoch #2. Batch Id 247 is having validation accuracy of 23.96673387096774\n",
            "Epoch #2. Batch Id 248 is having validation loss of 10791.9326171875\n",
            "13.870121002197266\n",
            "Epoch #2. Batch Id 248 is having validation accuracy of 24.03363453815261\n",
            "Epoch #2. Batch Id 249 is having validation loss of 10920.365234375\n",
            "42900.15625\n",
            "Epoch #2. Batch Id 249 is having validation accuracy of 24.0625\n",
            "Epoch #2. Batch Id 250 is having validation loss of 10876.9326171875\n",
            "18.870664596557617\n",
            "Epoch #2. Batch Id 250 is having validation accuracy of 24.10358565737052\n",
            "Epoch #2. Batch Id 251 is having validation loss of 10833.9150390625\n",
            "36.44513702392578\n",
            "Epoch #2. Batch Id 251 is having validation accuracy of 24.119543650793652\n",
            "Epoch #2. Batch Id 252 is having validation loss of 10791.20703125\n",
            "28.859819412231445\n",
            "Epoch #2. Batch Id 252 is having validation accuracy of 24.1600790513834\n",
            "Epoch #2. Batch Id 253 is having validation loss of 10748.857421875\n",
            "34.39765548706055\n",
            "Epoch #2. Batch Id 253 is having validation accuracy of 24.187992125984252\n",
            "Epoch #2. Batch Id 254 is having validation loss of 10707.62109375\n",
            "233.70773315429688\n",
            "Epoch #2. Batch Id 254 is having validation accuracy of 24.215686274509803\n",
            "Epoch #2. Batch Id 255 is having validation loss of 10665.9326171875\n",
            "35.44352722167969\n",
            "Epoch #2. Batch Id 255 is having validation accuracy of 24.23095703125\n",
            "Epoch #2. Batch Id 256 is having validation loss of 10872.0498046875\n",
            "63638.07421875\n",
            "Epoch #2. Batch Id 256 is having validation accuracy of 24.246108949416342\n",
            "Epoch #2. Batch Id 257 is having validation loss of 10830.015625\n",
            "27.310962677001953\n",
            "Epoch #2. Batch Id 257 is having validation accuracy of 24.29748062015504\n",
            "Epoch #2. Batch Id 258 is having validation loss of 10788.2890625\n",
            "22.958751678466797\n",
            "Epoch #2. Batch Id 258 is having validation accuracy of 24.30019305019305\n",
            "Epoch #2. Batch Id 259 is having validation loss of 10746.8564453125\n",
            "15.930793762207031\n",
            "Epoch #2. Batch Id 259 is having validation accuracy of 24.278846153846153\n",
            "Epoch #2. Batch Id 260 is having validation loss of 10705.7919921875\n",
            "29.048051834106445\n",
            "Epoch #2. Batch Id 260 is having validation accuracy of 24.32950191570881\n",
            "Epoch #2. Batch Id 261 is having validation loss of 10665.0654296875\n",
            "35.496089935302734\n",
            "Epoch #2. Batch Id 261 is having validation accuracy of 24.32013358778626\n",
            "Epoch #2. Batch Id 262 is having validation loss of 10716.345703125\n",
            "24151.7265625\n",
            "Epoch #2. Batch Id 262 is having validation accuracy of 24.334600760456272\n",
            "Epoch #2. Batch Id 263 is having validation loss of 10675.84765625\n",
            "24.85205078125\n",
            "Epoch #2. Batch Id 263 is having validation accuracy of 24.31344696969697\n",
            "Epoch #2. Batch Id 264 is having validation loss of 10635.6533203125\n",
            "24.466785430908203\n",
            "Epoch #2. Batch Id 264 is having validation accuracy of 24.316037735849058\n",
            "Epoch #2. Batch Id 265 is having validation loss of 10595.7587890625\n",
            "23.601364135742188\n",
            "Epoch #2. Batch Id 265 is having validation accuracy of 24.295112781954888\n",
            "Epoch #2. Batch Id 266 is having validation loss of 10556.158203125\n",
            "22.46111297607422\n",
            "Epoch #2. Batch Id 266 is having validation accuracy of 24.30945692883895\n",
            "Epoch #2. Batch Id 267 is having validation loss of 10516.83984375\n",
            "18.84984588623047\n",
            "Epoch #2. Batch Id 267 is having validation accuracy of 24.31203358208955\n",
            "Epoch #2. Batch Id 268 is having validation loss of 10477.7998046875\n",
            "15.004067420959473\n",
            "Epoch #2. Batch Id 268 is having validation accuracy of 24.349442379182157\n",
            "Epoch #2. Batch Id 269 is having validation loss of 10439.0927734375\n",
            "26.776342391967773\n",
            "Epoch #2. Batch Id 269 is having validation accuracy of 24.35185185185185\n",
            "Epoch #2. Batch Id 270 is having validation loss of 10401.44921875\n",
            "237.57383728027344\n",
            "Epoch #2. Batch Id 270 is having validation accuracy of 24.388837638376383\n",
            "Epoch #2. Batch Id 271 is having validation loss of 10363.296875\n",
            "24.126928329467773\n",
            "Epoch #2. Batch Id 271 is having validation accuracy of 24.425551470588236\n",
            "Epoch #2. Batch Id 272 is having validation loss of 10325.39453125\n",
            "15.957990646362305\n",
            "Epoch #2. Batch Id 272 is having validation accuracy of 24.42765567765568\n",
            "Epoch #2. Batch Id 273 is having validation loss of 10287.814453125\n",
            "28.461633682250977\n",
            "Epoch #2. Batch Id 273 is having validation accuracy of 24.4867700729927\n",
            "Epoch #2. Batch Id 274 is having validation loss of 10250.474609375\n",
            "19.30171012878418\n",
            "Epoch #2. Batch Id 274 is having validation accuracy of 24.556818181818183\n",
            "Epoch #2. Batch Id 275 is having validation loss of 10233.5673828125\n",
            "5584.17822265625\n",
            "Epoch #2. Batch Id 275 is having validation accuracy of 24.547101449275363\n",
            "Epoch #2. Batch Id 276 is having validation loss of 10196.705078125\n",
            "22.646957397460938\n",
            "Epoch #2. Batch Id 276 is having validation accuracy of 24.627707581227437\n",
            "Epoch #2. Batch Id 277 is having validation loss of 10160.087890625\n",
            "17.085948944091797\n",
            "Epoch #2. Batch Id 277 is having validation accuracy of 24.60656474820144\n",
            "Epoch #2. Batch Id 278 is having validation loss of 10128.0263671875\n",
            "1214.8046875\n",
            "Epoch #2. Batch Id 278 is having validation accuracy of 24.63037634408602\n",
            "Epoch #2. Batch Id 279 is having validation loss of 10091.98828125\n",
            "37.450950622558594\n",
            "Epoch #2. Batch Id 279 is having validation accuracy of 24.631696428571427\n",
            "Epoch #2. Batch Id 280 is having validation loss of 10056.1279296875\n",
            "15.270801544189453\n",
            "Epoch #2. Batch Id 280 is having validation accuracy of 24.69973309608541\n",
            "Epoch #2. Batch Id 281 is having validation loss of 10021.21484375\n",
            "210.64205932617188\n",
            "Epoch #2. Batch Id 281 is having validation accuracy of 24.68971631205674\n",
            "Epoch #2. Batch Id 282 is having validation loss of 9985.9169921875\n",
            "31.92407989501953\n",
            "Epoch #2. Batch Id 282 is having validation accuracy of 24.70185512367491\n",
            "Epoch #2. Batch Id 283 is having validation loss of 9950.849609375\n",
            "26.737571716308594\n",
            "Epoch #2. Batch Id 283 is having validation accuracy of 24.746919014084508\n",
            "Epoch #2. Batch Id 284 is having validation loss of 9916.03125\n",
            "27.58816146850586\n",
            "Epoch #2. Batch Id 284 is having validation accuracy of 24.74780701754386\n",
            "Epoch #2. Batch Id 285 is having validation loss of 9881.4033203125\n",
            "12.533882141113281\n",
            "Epoch #2. Batch Id 285 is having validation accuracy of 24.803321678321677\n",
            "Epoch #2. Batch Id 286 is having validation loss of 9847.154296875\n",
            "51.81559753417969\n",
            "Epoch #2. Batch Id 286 is having validation accuracy of 24.782229965156795\n",
            "Epoch #2. Batch Id 287 is having validation loss of 9813.2255859375\n",
            "75.71851348876953\n",
            "Epoch #2. Batch Id 287 is having validation accuracy of 24.815538194444443\n",
            "Epoch #2. Batch Id 288 is having validation loss of 9794.6923828125\n",
            "4457.2255859375\n",
            "Epoch #2. Batch Id 288 is having validation accuracy of 24.848615916955016\n",
            "Epoch #2. Batch Id 289 is having validation loss of 9760.98828125\n",
            "20.574810028076172\n",
            "Epoch #2. Batch Id 289 is having validation accuracy of 24.913793103448278\n",
            "Epoch #2. Batch Id 290 is having validation loss of 9727.5283203125\n",
            "24.257333755493164\n",
            "Epoch #2. Batch Id 290 is having validation accuracy of 24.9463058419244\n",
            "Epoch #2. Batch Id 291 is having validation loss of 9694.2919921875\n",
            "22.411182403564453\n",
            "Epoch #2. Batch Id 291 is having validation accuracy of 25.032106164383563\n",
            "Epoch #2. Batch Id 292 is having validation loss of 9661.267578125\n",
            "18.251422882080078\n",
            "Epoch #2. Batch Id 292 is having validation accuracy of 25.053327645051194\n",
            "Epoch #2. Batch Id 293 is having validation loss of 9628.466796875\n",
            "17.75603485107422\n",
            "Epoch #2. Batch Id 293 is having validation accuracy of 25.095663265306122\n",
            "Epoch #2. Batch Id 294 is having validation loss of 9643.572265625\n",
            "14084.72265625\n",
            "Epoch #2. Batch Id 294 is having validation accuracy of 25.13771186440678\n",
            "Epoch #2. Batch Id 295 is having validation loss of 9611.083984375\n",
            "27.15212059020996\n",
            "Epoch #2. Batch Id 295 is having validation accuracy of 25.116131756756758\n",
            "Epoch #2. Batch Id 296 is having validation loss of 9611.236328125\n",
            "9656.248046875\n",
            "Epoch #2. Batch Id 296 is having validation accuracy of 25.126262626262626\n",
            "Epoch #2. Batch Id 297 is having validation loss of 9579.0302734375\n",
            "13.75964069366455\n",
            "Epoch #2. Batch Id 297 is having validation accuracy of 25.188758389261746\n",
            "Epoch #2. Batch Id 298 is having validation loss of 9547.02734375\n",
            "10.018631935119629\n",
            "Epoch #2. Batch Id 298 is having validation accuracy of 25.25083612040134\n",
            "Epoch #2. Batch Id 299 is having validation loss of 9515.3193359375\n",
            "34.571868896484375\n",
            "Epoch #2. Batch Id 299 is having validation accuracy of 25.25\n",
            "Epoch #2. Batch Id 300 is having validation loss of 9483.775390625\n",
            "20.608518600463867\n",
            "Epoch #2. Batch Id 300 is having validation accuracy of 25.290697674418606\n",
            "Epoch #2. Batch Id 301 is having validation loss of 9586.53515625\n",
            "40517.1484375\n",
            "Epoch #2. Batch Id 301 is having validation accuracy of 25.269039735099337\n",
            "Epoch #2. Batch Id 302 is having validation loss of 9555.0693359375\n",
            "52.52836227416992\n",
            "Epoch #2. Batch Id 302 is having validation accuracy of 25.309405940594058\n",
            "Epoch #2. Batch Id 303 is having validation loss of 9523.7607421875\n",
            "37.35600662231445\n",
            "Epoch #2. Batch Id 303 is having validation accuracy of 25.318667763157894\n",
            "Epoch #2. Batch Id 304 is having validation loss of 9492.58984375\n",
            "16.784862518310547\n",
            "Epoch #2. Batch Id 304 is having validation accuracy of 25.399590163934427\n",
            "Epoch #2. Batch Id 305 is having validation loss of 9461.67578125\n",
            "32.98567581176758\n",
            "Epoch #2. Batch Id 305 is having validation accuracy of 25.42892156862745\n",
            "Epoch #2. Batch Id 306 is having validation loss of 9430.9091796875\n",
            "16.38883399963379\n",
            "Epoch #2. Batch Id 306 is having validation accuracy of 25.44788273615635\n",
            "Epoch #2. Batch Id 307 is having validation loss of 9400.796875\n",
            "156.1685028076172\n",
            "Epoch #2. Batch Id 307 is having validation accuracy of 25.405844155844157\n",
            "Epoch #2. Batch Id 308 is having validation loss of 9370.4033203125\n",
            "9.174307823181152\n",
            "Epoch #2. Batch Id 308 is having validation accuracy of 25.424757281553397\n",
            "Epoch #2. Batch Id 309 is having validation loss of 9340.228515625\n",
            "16.093263626098633\n",
            "Epoch #2. Batch Id 309 is having validation accuracy of 25.403225806451612\n",
            "Epoch #2. Batch Id 310 is having validation loss of 9310.2490234375\n",
            "16.481956481933594\n",
            "Epoch #2. Batch Id 310 is having validation accuracy of 25.40192926045016\n",
            "Epoch #2. Batch Id 311 is having validation loss of 9280.5087890625\n",
            "31.390575408935547\n",
            "Epoch #2. Batch Id 311 is having validation accuracy of 25.430689102564102\n",
            "Epoch #2. Batch Id 312 is having validation loss of 9250.9150390625\n",
            "17.70931053161621\n",
            "Epoch #2. Batch Id 312 is having validation accuracy of 25.47923322683706\n",
            "Epoch #2. Batch Id 313 is having validation loss of 9221.5478515625\n",
            "29.591632843017578\n",
            "Epoch #2. Batch Id 313 is having validation accuracy of 25.507563694267517\n",
            "Epoch #2. Batch Id 314 is having validation loss of 9192.419921875\n",
            "46.29989242553711\n",
            "Epoch #2. Batch Id 314 is having validation accuracy of 25.50595238095238\n",
            "Epoch #2. Batch Id 315 is having validation loss of 9163.3525390625\n",
            "7.235426902770996\n",
            "Epoch #2. Batch Id 315 is having validation accuracy of 25.553797468354432\n",
            "Epoch #2. Batch Id 316 is having validation loss of 9134.5693359375\n",
            "39.113529205322266\n",
            "Epoch #2. Batch Id 316 is having validation accuracy of 25.542192429022084\n",
            "Epoch #2. Batch Id 317 is having validation loss of 9105.8994140625\n",
            "17.503795623779297\n",
            "Epoch #2. Batch Id 317 is having validation accuracy of 25.520833333333332\n",
            "Epoch #2. Batch Id 318 is having validation loss of 9077.5380859375\n",
            "58.708045959472656\n",
            "Epoch #2. Batch Id 318 is having validation accuracy of 25.480015673981192\n",
            "Epoch #2. Batch Id 319 is having validation loss of 9049.2646484375\n",
            "29.97785758972168\n",
            "Epoch #2. Batch Id 319 is having validation accuracy of 25.48828125\n",
            "Epoch #2. Batch Id 320 is having validation loss of 9021.10546875\n",
            "10.198929786682129\n",
            "Epoch #2. Batch Id 320 is having validation accuracy of 25.54517133956386\n",
            "Epoch #2. Batch Id 321 is having validation loss of 8993.1513671875\n",
            "19.742313385009766\n",
            "Epoch #2. Batch Id 321 is having validation accuracy of 25.553183229813666\n",
            "Epoch #2. Batch Id 322 is having validation loss of 9075.7705078125\n",
            "35679.08203125\n",
            "Epoch #2. Batch Id 322 is having validation accuracy of 25.657894736842106\n",
            "Epoch #2. Batch Id 323 is having validation loss of 9178.265625\n",
            "42284.19140625\n",
            "Epoch #2. Batch Id 323 is having validation accuracy of 25.713734567901234\n",
            "Epoch #2. Batch Id 324 is having validation loss of 9150.0869140625\n",
            "20.071443557739258\n",
            "Epoch #2. Batch Id 324 is having validation accuracy of 25.721153846153847\n",
            "Epoch #2. Batch Id 325 is having validation loss of 9122.111328125\n",
            "30.17591667175293\n",
            "Epoch #2. Batch Id 325 is having validation accuracy of 25.738113496932517\n",
            "Epoch #2. Batch Id 326 is having validation loss of 9094.2861328125\n",
            "23.265094757080078\n",
            "Epoch #2. Batch Id 326 is having validation accuracy of 25.716743119266056\n",
            "Epoch #2. Batch Id 327 is having validation loss of 9066.5947265625\n",
            "11.375584602355957\n",
            "Epoch #2. Batch Id 327 is having validation accuracy of 25.79077743902439\n",
            "Epoch #2. Batch Id 328 is having validation loss of 9039.12890625\n",
            "30.252517700195312\n",
            "Epoch #2. Batch Id 328 is having validation accuracy of 25.845364741641337\n",
            "Epoch #2. Batch Id 329 is having validation loss of 9059.625\n",
            "15802.9560546875\n",
            "Epoch #2. Batch Id 329 is having validation accuracy of 25.90909090909091\n",
            "Epoch #2. Batch Id 330 is having validation loss of 9032.3408203125\n",
            "28.66146469116211\n",
            "Epoch #2. Batch Id 330 is having validation accuracy of 25.906344410876134\n",
            "Epoch #2. Batch Id 331 is having validation loss of 9005.23046875\n",
            "31.67942237854004\n",
            "Epoch #2. Batch Id 331 is having validation accuracy of 25.903614457831324\n",
            "Epoch #2. Batch Id 332 is having validation loss of 8978.6640625\n",
            "158.77366638183594\n",
            "Epoch #2. Batch Id 332 is having validation accuracy of 25.9009009009009\n",
            "Epoch #2. Batch Id 333 is having validation loss of 8951.814453125\n",
            "11.005509376525879\n",
            "Epoch #2. Batch Id 333 is having validation accuracy of 25.973053892215567\n",
            "Epoch #2. Batch Id 334 is having validation loss of 8925.4306640625\n",
            "113.2606201171875\n",
            "Epoch #2. Batch Id 334 is having validation accuracy of 25.970149253731343\n",
            "Epoch #2. Batch Id 335 is having validation loss of 9081.013671875\n",
            "61201.3359375\n",
            "Epoch #2. Batch Id 335 is having validation accuracy of 25.95796130952381\n",
            "Epoch #2. Batch Id 336 is having validation loss of 9054.1142578125\n",
            "15.916407585144043\n",
            "Epoch #2. Batch Id 336 is having validation accuracy of 25.94584569732938\n",
            "Epoch #2. Batch Id 337 is having validation loss of 9027.39453125\n",
            "22.738792419433594\n",
            "Epoch #2. Batch Id 337 is having validation accuracy of 25.989275147928993\n",
            "Epoch #2. Batch Id 338 is having validation loss of 9035.837890625\n",
            "11889.6279296875\n",
            "Epoch #2. Batch Id 338 is having validation accuracy of 25.9679203539823\n",
            "Epoch #2. Batch Id 339 is having validation loss of 9009.3251953125\n",
            "21.654645919799805\n",
            "Epoch #2. Batch Id 339 is having validation accuracy of 26.001838235294116\n",
            "Epoch #2. Batch Id 340 is having validation loss of 8982.9208984375\n",
            "5.343900680541992\n",
            "Epoch #2. Batch Id 340 is having validation accuracy of 26.053885630498534\n",
            "Epoch #2. Batch Id 341 is having validation loss of 8989.4765625\n",
            "11224.98828125\n",
            "Epoch #2. Batch Id 341 is having validation accuracy of 26.06907894736842\n",
            "Epoch #2. Batch Id 342 is having validation loss of 8963.353515625\n",
            "29.12740135192871\n",
            "Epoch #2. Batch Id 342 is having validation accuracy of 26.077822433321156\n",
            "Эпоха #2 train_loss: 0.022596394643187523, val_loss: 0.8187206387519836\n",
            "Потрачено 14.2 минут на 2 эпоху\n",
            "Batch Id 0 is having training loss of 124.19871520996094\n",
            "124.19871520996094\n",
            "Epoch #3. Accuracy on batch 0 on Training is 28.125\n",
            "Epoch #3. Accuracy on batch 1 on Training is 25.0\n",
            "Epoch #3. Accuracy on batch 2 on Training is 30.208333333333332\n",
            "Epoch #3. Accuracy on batch 3 on Training is 29.6875\n",
            "Epoch #3. Accuracy on batch 4 on Training is 26.25\n",
            "Epoch #3. Accuracy on batch 5 on Training is 25.0\n",
            "Epoch #3. Accuracy on batch 6 on Training is 24.553571428571427\n",
            "Epoch #3. Accuracy on batch 7 on Training is 25.390625\n",
            "Epoch #3. Accuracy on batch 8 on Training is 26.041666666666668\n",
            "Epoch #3. Accuracy on batch 9 on Training is 27.1875\n",
            "Epoch #3. Accuracy on batch 10 on Training is 26.988636363636363\n",
            "Epoch #3. Accuracy on batch 11 on Training is 28.645833333333332\n",
            "Epoch #3. Accuracy on batch 12 on Training is 28.846153846153847\n",
            "Epoch #3. Accuracy on batch 13 on Training is 28.571428571428573\n",
            "Epoch #3. Accuracy on batch 14 on Training is 29.375\n",
            "Epoch #3. Accuracy on batch 15 on Training is 28.7109375\n",
            "Epoch #3. Accuracy on batch 16 on Training is 29.227941176470587\n",
            "Epoch #3. Accuracy on batch 17 on Training is 28.645833333333332\n",
            "Epoch #3. Accuracy on batch 18 on Training is 28.782894736842106\n",
            "Epoch #3. Accuracy on batch 19 on Training is 29.0625\n",
            "Batch Id 20 is having training loss of 6307.84814453125\n",
            "21.466583251953125\n",
            "Epoch #3. Accuracy on batch 20 on Training is 29.761904761904763\n",
            "Epoch #3. Accuracy on batch 21 on Training is 30.255681818181817\n",
            "Epoch #3. Accuracy on batch 22 on Training is 30.706521739130434\n",
            "Epoch #3. Accuracy on batch 23 on Training is 30.46875\n",
            "Epoch #3. Accuracy on batch 24 on Training is 30.625\n",
            "Epoch #3. Accuracy on batch 25 on Training is 30.64903846153846\n",
            "Epoch #3. Accuracy on batch 26 on Training is 30.555555555555557\n",
            "Epoch #3. Accuracy on batch 27 on Training is 30.691964285714285\n",
            "Epoch #3. Accuracy on batch 28 on Training is 30.81896551724138\n",
            "Epoch #3. Accuracy on batch 29 on Training is 31.145833333333332\n",
            "Epoch #3. Accuracy on batch 30 on Training is 31.149193548387096\n",
            "Epoch #3. Accuracy on batch 31 on Training is 30.859375\n",
            "Epoch #3. Accuracy on batch 32 on Training is 31.060606060606062\n",
            "Epoch #3. Accuracy on batch 33 on Training is 31.066176470588236\n",
            "Epoch #3. Accuracy on batch 34 on Training is 30.625\n",
            "Epoch #3. Accuracy on batch 35 on Training is 30.729166666666668\n",
            "Epoch #3. Accuracy on batch 36 on Training is 30.320945945945947\n",
            "Epoch #3. Accuracy on batch 37 on Training is 30.263157894736842\n",
            "Epoch #3. Accuracy on batch 38 on Training is 30.28846153846154\n",
            "Epoch #3. Accuracy on batch 39 on Training is 30.546875\n",
            "Batch Id 40 is having training loss of 4156.6552734375\n",
            "174.2169189453125\n",
            "Epoch #3. Accuracy on batch 40 on Training is 30.48780487804878\n",
            "Epoch #3. Accuracy on batch 41 on Training is 30.282738095238095\n",
            "Epoch #3. Accuracy on batch 42 on Training is 29.86918604651163\n",
            "Epoch #3. Accuracy on batch 43 on Training is 29.616477272727273\n",
            "Epoch #3. Accuracy on batch 44 on Training is 29.65277777777778\n",
            "Epoch #3. Accuracy on batch 45 on Training is 29.55163043478261\n",
            "Epoch #3. Accuracy on batch 46 on Training is 29.25531914893617\n",
            "Epoch #3. Accuracy on batch 47 on Training is 29.166666666666668\n",
            "Epoch #3. Accuracy on batch 48 on Training is 29.081632653061224\n",
            "Epoch #3. Accuracy on batch 49 on Training is 29.375\n",
            "Epoch #3. Accuracy on batch 50 on Training is 29.044117647058822\n",
            "Epoch #3. Accuracy on batch 51 on Training is 29.326923076923077\n",
            "Epoch #3. Accuracy on batch 52 on Training is 29.12735849056604\n",
            "Epoch #3. Accuracy on batch 53 on Training is 29.108796296296298\n",
            "Epoch #3. Accuracy on batch 54 on Training is 29.03409090909091\n",
            "Epoch #3. Accuracy on batch 55 on Training is 29.017857142857142\n",
            "Epoch #3. Accuracy on batch 56 on Training is 29.05701754385965\n",
            "Epoch #3. Accuracy on batch 57 on Training is 29.040948275862068\n",
            "Epoch #3. Accuracy on batch 58 on Training is 28.972457627118644\n",
            "Epoch #3. Accuracy on batch 59 on Training is 28.854166666666668\n",
            "Batch Id 60 is having training loss of 3465.929931640625\n",
            "44.253597259521484\n",
            "Epoch #3. Accuracy on batch 60 on Training is 29.149590163934427\n",
            "Epoch #3. Accuracy on batch 61 on Training is 29.284274193548388\n",
            "Epoch #3. Accuracy on batch 62 on Training is 29.464285714285715\n",
            "Epoch #3. Accuracy on batch 63 on Training is 29.541015625\n",
            "Epoch #3. Accuracy on batch 64 on Training is 29.51923076923077\n",
            "Epoch #3. Accuracy on batch 65 on Training is 29.40340909090909\n",
            "Epoch #3. Accuracy on batch 66 on Training is 29.524253731343283\n",
            "Epoch #3. Accuracy on batch 67 on Training is 29.6875\n",
            "Epoch #3. Accuracy on batch 68 on Training is 29.71014492753623\n",
            "Epoch #3. Accuracy on batch 69 on Training is 29.6875\n",
            "Epoch #3. Accuracy on batch 70 on Training is 29.445422535211268\n",
            "Epoch #3. Accuracy on batch 71 on Training is 29.51388888888889\n",
            "Epoch #3. Accuracy on batch 72 on Training is 29.794520547945204\n",
            "Epoch #3. Accuracy on batch 73 on Training is 29.77195945945946\n",
            "Epoch #3. Accuracy on batch 74 on Training is 30.0\n",
            "Epoch #3. Accuracy on batch 75 on Training is 30.098684210526315\n",
            "Epoch #3. Accuracy on batch 76 on Training is 30.15422077922078\n",
            "Epoch #3. Accuracy on batch 77 on Training is 30.16826923076923\n",
            "Epoch #3. Accuracy on batch 78 on Training is 30.22151898734177\n",
            "Epoch #3. Accuracy on batch 79 on Training is 30.3125\n",
            "Batch Id 80 is having training loss of 2946.39501953125\n",
            "5883.57080078125\n",
            "Epoch #3. Accuracy on batch 80 on Training is 30.169753086419753\n",
            "Epoch #3. Accuracy on batch 81 on Training is 29.992378048780488\n",
            "Epoch #3. Accuracy on batch 82 on Training is 29.96987951807229\n",
            "Epoch #3. Accuracy on batch 83 on Training is 30.022321428571427\n",
            "Epoch #3. Accuracy on batch 84 on Training is 29.96323529411765\n",
            "Epoch #3. Accuracy on batch 85 on Training is 29.905523255813954\n",
            "Epoch #3. Accuracy on batch 86 on Training is 29.813218390804597\n",
            "Epoch #3. Accuracy on batch 87 on Training is 29.829545454545453\n",
            "Epoch #3. Accuracy on batch 88 on Training is 29.634831460674157\n",
            "Epoch #3. Accuracy on batch 89 on Training is 29.6875\n",
            "Epoch #3. Accuracy on batch 90 on Training is 29.77335164835165\n",
            "Epoch #3. Accuracy on batch 91 on Training is 29.82336956521739\n",
            "Epoch #3. Accuracy on batch 92 on Training is 29.838709677419356\n",
            "Epoch #3. Accuracy on batch 93 on Training is 29.6875\n",
            "Epoch #3. Accuracy on batch 94 on Training is 29.605263157894736\n",
            "Epoch #3. Accuracy on batch 95 on Training is 29.6875\n",
            "Epoch #3. Accuracy on batch 96 on Training is 29.7680412371134\n",
            "Epoch #3. Accuracy on batch 97 on Training is 29.878826530612244\n",
            "Epoch #3. Accuracy on batch 98 on Training is 30.018939393939394\n",
            "Epoch #3. Accuracy on batch 99 on Training is 30.03125\n",
            "Batch Id 100 is having training loss of 3107.421142578125\n",
            "31.54592514038086\n",
            "Epoch #3. Accuracy on batch 100 on Training is 30.043316831683168\n",
            "Epoch #3. Accuracy on batch 101 on Training is 29.96323529411765\n",
            "Epoch #3. Accuracy on batch 102 on Training is 29.945388349514563\n",
            "Epoch #3. Accuracy on batch 103 on Training is 30.048076923076923\n",
            "Epoch #3. Accuracy on batch 104 on Training is 29.970238095238095\n",
            "Epoch #3. Accuracy on batch 105 on Training is 29.923349056603772\n",
            "Epoch #3. Accuracy on batch 106 on Training is 29.848130841121495\n",
            "Epoch #3. Accuracy on batch 107 on Training is 29.832175925925927\n",
            "Epoch #3. Accuracy on batch 108 on Training is 30.045871559633028\n",
            "Epoch #3. Accuracy on batch 109 on Training is 30.056818181818183\n",
            "Epoch #3. Accuracy on batch 110 on Training is 29.98310810810811\n",
            "Epoch #3. Accuracy on batch 111 on Training is 29.938616071428573\n",
            "Epoch #3. Accuracy on batch 112 on Training is 29.86725663716814\n",
            "Epoch #3. Accuracy on batch 113 on Training is 29.906798245614034\n",
            "Epoch #3. Accuracy on batch 114 on Training is 29.72826086956522\n",
            "Epoch #3. Accuracy on batch 115 on Training is 29.768318965517242\n",
            "Epoch #3. Accuracy on batch 116 on Training is 29.727564102564102\n",
            "Epoch #3. Accuracy on batch 117 on Training is 29.766949152542374\n",
            "Epoch #3. Accuracy on batch 118 on Training is 29.831932773109244\n",
            "Epoch #3. Accuracy on batch 119 on Training is 29.84375\n",
            "Batch Id 120 is having training loss of 3114.85009765625\n",
            "24.41839027404785\n",
            "Epoch #3. Accuracy on batch 120 on Training is 29.88119834710744\n",
            "Epoch #3. Accuracy on batch 121 on Training is 30.020491803278688\n",
            "Epoch #3. Accuracy on batch 122 on Training is 30.15752032520325\n",
            "Epoch #3. Accuracy on batch 123 on Training is 30.267137096774192\n",
            "Epoch #3. Accuracy on batch 124 on Training is 30.175\n",
            "Epoch #3. Accuracy on batch 125 on Training is 30.307539682539684\n",
            "Epoch #3. Accuracy on batch 126 on Training is 30.16732283464567\n",
            "Epoch #3. Accuracy on batch 127 on Training is 30.224609375\n",
            "Epoch #3. Accuracy on batch 128 on Training is 30.208333333333332\n",
            "Epoch #3. Accuracy on batch 129 on Training is 30.192307692307693\n",
            "Epoch #3. Accuracy on batch 130 on Training is 30.224236641221374\n",
            "Epoch #3. Accuracy on batch 131 on Training is 30.208333333333332\n",
            "Epoch #3. Accuracy on batch 132 on Training is 30.263157894736842\n",
            "Epoch #3. Accuracy on batch 133 on Training is 30.223880597014926\n",
            "Epoch #3. Accuracy on batch 134 on Training is 30.23148148148148\n",
            "Epoch #3. Accuracy on batch 135 on Training is 30.284926470588236\n",
            "Epoch #3. Accuracy on batch 136 on Training is 30.31478102189781\n",
            "Epoch #3. Accuracy on batch 137 on Training is 30.253623188405797\n",
            "Epoch #3. Accuracy on batch 138 on Training is 30.17086330935252\n",
            "Epoch #3. Accuracy on batch 139 on Training is 30.089285714285715\n",
            "Batch Id 140 is having training loss of 3434.583740234375\n",
            "12.609526634216309\n",
            "Epoch #3. Accuracy on batch 140 on Training is 30.141843971631207\n",
            "Epoch #3. Accuracy on batch 141 on Training is 30.127640845070424\n",
            "Epoch #3. Accuracy on batch 142 on Training is 30.048076923076923\n",
            "Epoch #3. Accuracy on batch 143 on Training is 29.90451388888889\n",
            "Epoch #3. Accuracy on batch 144 on Training is 29.95689655172414\n",
            "Epoch #3. Accuracy on batch 145 on Training is 29.965753424657535\n",
            "Epoch #3. Accuracy on batch 146 on Training is 29.910714285714285\n",
            "Epoch #3. Accuracy on batch 147 on Training is 29.85641891891892\n",
            "Epoch #3. Accuracy on batch 148 on Training is 29.886744966442954\n",
            "Epoch #3. Accuracy on batch 149 on Training is 30.0\n",
            "Epoch #3. Accuracy on batch 150 on Training is 29.987582781456954\n",
            "Epoch #3. Accuracy on batch 151 on Training is 30.057565789473685\n",
            "Epoch #3. Accuracy on batch 152 on Training is 30.044934640522875\n",
            "Epoch #3. Accuracy on batch 153 on Training is 30.113636363636363\n",
            "Epoch #3. Accuracy on batch 154 on Training is 30.201612903225808\n",
            "Epoch #3. Accuracy on batch 155 on Training is 30.16826923076923\n",
            "Epoch #3. Accuracy on batch 156 on Training is 30.195063694267517\n",
            "Epoch #3. Accuracy on batch 157 on Training is 30.26107594936709\n",
            "Epoch #3. Accuracy on batch 158 on Training is 30.24764150943396\n",
            "Epoch #3. Accuracy on batch 159 on Training is 30.1953125\n",
            "Batch Id 160 is having training loss of 3143.357421875\n",
            "422.40911865234375\n",
            "Epoch #3. Accuracy on batch 160 on Training is 30.221273291925467\n",
            "Epoch #3. Accuracy on batch 161 on Training is 30.266203703703702\n",
            "Epoch #3. Accuracy on batch 162 on Training is 30.21472392638037\n",
            "Epoch #3. Accuracy on batch 163 on Training is 30.182926829268293\n",
            "Epoch #3. Accuracy on batch 164 on Training is 30.170454545454547\n",
            "Epoch #3. Accuracy on batch 165 on Training is 30.23343373493976\n",
            "Epoch #3. Accuracy on batch 166 on Training is 30.29565868263473\n",
            "Epoch #3. Accuracy on batch 167 on Training is 30.245535714285715\n",
            "Epoch #3. Accuracy on batch 168 on Training is 30.28846153846154\n",
            "Epoch #3. Accuracy on batch 169 on Training is 30.183823529411764\n",
            "Epoch #3. Accuracy on batch 170 on Training is 30.244883040935672\n",
            "Epoch #3. Accuracy on batch 171 on Training is 30.123546511627907\n",
            "Epoch #3. Accuracy on batch 172 on Training is 30.057803468208093\n",
            "Epoch #3. Accuracy on batch 173 on Training is 30.082614942528735\n",
            "Epoch #3. Accuracy on batch 174 on Training is 30.107142857142858\n",
            "Epoch #3. Accuracy on batch 175 on Training is 30.202414772727273\n",
            "Epoch #3. Accuracy on batch 176 on Training is 30.173022598870055\n",
            "Epoch #3. Accuracy on batch 177 on Training is 30.0561797752809\n",
            "Epoch #3. Accuracy on batch 178 on Training is 30.09776536312849\n",
            "Epoch #3. Accuracy on batch 179 on Training is 30.17361111111111\n",
            "Batch Id 180 is having training loss of 3083.701171875\n",
            "395.275390625\n",
            "Epoch #3. Accuracy on batch 180 on Training is 30.162292817679557\n",
            "Epoch #3. Accuracy on batch 181 on Training is 30.11675824175824\n",
            "Epoch #3. Accuracy on batch 182 on Training is 30.174180327868854\n",
            "Epoch #3. Accuracy on batch 183 on Training is 30.230978260869566\n",
            "Epoch #3. Accuracy on batch 184 on Training is 30.219594594594593\n",
            "Epoch #3. Accuracy on batch 185 on Training is 30.241935483870968\n",
            "Epoch #3. Accuracy on batch 186 on Training is 30.31417112299465\n",
            "Epoch #3. Accuracy on batch 187 on Training is 30.269281914893618\n",
            "Epoch #3. Accuracy on batch 188 on Training is 30.2744708994709\n",
            "Epoch #3. Accuracy on batch 189 on Training is 30.19736842105263\n",
            "Epoch #3. Accuracy on batch 190 on Training is 30.202879581151834\n",
            "Epoch #3. Accuracy on batch 191 on Training is 30.159505208333332\n",
            "Epoch #3. Accuracy on batch 192 on Training is 30.197538860103627\n",
            "Epoch #3. Accuracy on batch 193 on Training is 30.09020618556701\n",
            "Epoch #3. Accuracy on batch 194 on Training is 30.096153846153847\n",
            "Epoch #3. Accuracy on batch 195 on Training is 30.054209183673468\n",
            "Epoch #3. Accuracy on batch 196 on Training is 30.012690355329948\n",
            "Epoch #3. Accuracy on batch 197 on Training is 29.95580808080808\n",
            "Epoch #3. Accuracy on batch 198 on Training is 29.962311557788944\n",
            "Epoch #3. Accuracy on batch 199 on Training is 29.984375\n",
            "Batch Id 200 is having training loss of 2916.137939453125\n",
            "19.25701141357422\n",
            "Epoch #3. Accuracy on batch 200 on Training is 29.990671641791046\n",
            "Epoch #3. Accuracy on batch 201 on Training is 30.027846534653467\n",
            "Epoch #3. Accuracy on batch 202 on Training is 30.01847290640394\n",
            "Epoch #3. Accuracy on batch 203 on Training is 29.993872549019606\n",
            "Epoch #3. Accuracy on batch 204 on Training is 30.03048780487805\n",
            "Epoch #3. Accuracy on batch 205 on Training is 30.03640776699029\n",
            "Epoch #3. Accuracy on batch 206 on Training is 29.9969806763285\n",
            "Epoch #3. Accuracy on batch 207 on Training is 29.98798076923077\n",
            "Epoch #3. Accuracy on batch 208 on Training is 29.99401913875598\n",
            "Epoch #3. Accuracy on batch 209 on Training is 30.014880952380953\n",
            "Epoch #3. Accuracy on batch 210 on Training is 29.96149289099526\n",
            "Epoch #3. Accuracy on batch 211 on Training is 29.923349056603772\n",
            "Epoch #3. Accuracy on batch 212 on Training is 29.988262910798124\n",
            "Epoch #3. Accuracy on batch 213 on Training is 30.037967289719628\n",
            "Epoch #3. Accuracy on batch 214 on Training is 30.01453488372093\n",
            "Epoch #3. Accuracy on batch 215 on Training is 29.97685185185185\n",
            "Epoch #3. Accuracy on batch 216 on Training is 29.982718894009217\n",
            "Epoch #3. Accuracy on batch 217 on Training is 30.045871559633028\n",
            "Epoch #3. Accuracy on batch 218 on Training is 30.037100456621005\n",
            "Epoch #3. Accuracy on batch 219 on Training is 30.056818181818183\n",
            "Batch Id 220 is having training loss of 2659.89892578125\n",
            "12.295492172241211\n",
            "Epoch #3. Accuracy on batch 220 on Training is 30.048076923076923\n",
            "Epoch #3. Accuracy on batch 221 on Training is 30.05349099099099\n",
            "Epoch #3. Accuracy on batch 222 on Training is 30.07286995515695\n",
            "Epoch #3. Accuracy on batch 223 on Training is 30.092075892857142\n",
            "Epoch #3. Accuracy on batch 224 on Training is 30.11111111111111\n",
            "Epoch #3. Accuracy on batch 225 on Training is 30.116150442477878\n",
            "Epoch #3. Accuracy on batch 226 on Training is 30.10737885462555\n",
            "Epoch #3. Accuracy on batch 227 on Training is 30.08497807017544\n",
            "Epoch #3. Accuracy on batch 228 on Training is 30.062772925764193\n",
            "Epoch #3. Accuracy on batch 229 on Training is 29.972826086956523\n",
            "Epoch #3. Accuracy on batch 230 on Training is 30.04599567099567\n",
            "Epoch #3. Accuracy on batch 231 on Training is 30.02424568965517\n",
            "Epoch #3. Accuracy on batch 232 on Training is 30.002682403433475\n",
            "Epoch #3. Accuracy on batch 233 on Training is 29.96794871794872\n",
            "Epoch #3. Accuracy on batch 234 on Training is 29.9468085106383\n",
            "Epoch #3. Accuracy on batch 235 on Training is 29.939088983050848\n",
            "Epoch #3. Accuracy on batch 236 on Training is 29.957805907172997\n",
            "Epoch #3. Accuracy on batch 237 on Training is 29.98949579831933\n",
            "Epoch #3. Accuracy on batch 238 on Training is 29.994769874476987\n",
            "Epoch #3. Accuracy on batch 239 on Training is 30.052083333333332\n",
            "Batch Id 240 is having training loss of 2441.959716796875\n",
            "35.627220153808594\n",
            "Epoch #3. Accuracy on batch 240 on Training is 29.99221991701245\n",
            "Epoch #3. Accuracy on batch 241 on Training is 30.074896694214875\n",
            "Epoch #3. Accuracy on batch 242 on Training is 30.041152263374485\n",
            "Epoch #3. Accuracy on batch 243 on Training is 30.046106557377048\n",
            "Epoch #3. Accuracy on batch 244 on Training is 30.012755102040817\n",
            "Epoch #3. Accuracy on batch 245 on Training is 30.01778455284553\n",
            "Epoch #3. Accuracy on batch 246 on Training is 30.022773279352226\n",
            "Epoch #3. Accuracy on batch 247 on Training is 30.065524193548388\n",
            "Epoch #3. Accuracy on batch 248 on Training is 30.05773092369478\n",
            "Epoch #3. Accuracy on batch 249 on Training is 30.05\n",
            "Epoch #3. Accuracy on batch 250 on Training is 30.12948207171315\n",
            "Epoch #3. Accuracy on batch 251 on Training is 30.146329365079364\n",
            "Epoch #3. Accuracy on batch 252 on Training is 30.101284584980238\n",
            "Epoch #3. Accuracy on batch 253 on Training is 30.056594488188978\n",
            "Epoch #3. Accuracy on batch 254 on Training is 30.03676470588235\n",
            "Epoch #3. Accuracy on batch 255 on Training is 30.0537109375\n",
            "Epoch #3. Accuracy on batch 256 on Training is 30.070525291828794\n",
            "Epoch #3. Accuracy on batch 257 on Training is 30.050872093023255\n",
            "Epoch #3. Accuracy on batch 258 on Training is 30.06756756756757\n",
            "Epoch #3. Accuracy on batch 259 on Training is 30.048076923076923\n",
            "Batch Id 260 is having training loss of 2743.076904296875\n",
            "14.682422637939453\n",
            "Epoch #3. Accuracy on batch 260 on Training is 29.992816091954023\n",
            "Epoch #3. Accuracy on batch 261 on Training is 29.93797709923664\n",
            "Epoch #3. Accuracy on batch 262 on Training is 29.966730038022813\n",
            "Epoch #3. Accuracy on batch 263 on Training is 29.924242424242426\n",
            "Epoch #3. Accuracy on batch 264 on Training is 29.91745283018868\n",
            "Epoch #3. Accuracy on batch 265 on Training is 29.945958646616543\n",
            "Epoch #3. Accuracy on batch 266 on Training is 29.997659176029963\n",
            "Epoch #3. Accuracy on batch 267 on Training is 30.00233208955224\n",
            "Epoch #3. Accuracy on batch 268 on Training is 30.018587360594797\n",
            "Epoch #3. Accuracy on batch 269 on Training is 30.02314814814815\n",
            "Epoch #3. Accuracy on batch 270 on Training is 30.062269372693727\n",
            "Epoch #3. Accuracy on batch 271 on Training is 30.05514705882353\n",
            "Epoch #3. Accuracy on batch 272 on Training is 30.070970695970697\n",
            "Epoch #3. Accuracy on batch 273 on Training is 30.08667883211679\n",
            "Epoch #3. Accuracy on batch 274 on Training is 30.102272727272727\n",
            "Epoch #3. Accuracy on batch 275 on Training is 30.10643115942029\n",
            "Epoch #3. Accuracy on batch 276 on Training is 30.110559566787003\n",
            "Epoch #3. Accuracy on batch 277 on Training is 30.08093525179856\n",
            "Epoch #3. Accuracy on batch 278 on Training is 30.085125448028673\n",
            "Epoch #3. Accuracy on batch 279 on Training is 30.111607142857142\n",
            "Batch Id 280 is having training loss of 2716.51611328125\n",
            "19.665712356567383\n",
            "Epoch #3. Accuracy on batch 280 on Training is 30.115658362989326\n",
            "Epoch #3. Accuracy on batch 281 on Training is 30.07535460992908\n",
            "Epoch #3. Accuracy on batch 282 on Training is 30.057420494699645\n",
            "Epoch #3. Accuracy on batch 283 on Training is 30.06161971830986\n",
            "Epoch #3. Accuracy on batch 284 on Training is 30.05482456140351\n",
            "Epoch #3. Accuracy on batch 285 on Training is 30.048076923076923\n",
            "Epoch #3. Accuracy on batch 286 on Training is 30.09581881533101\n",
            "Epoch #3. Accuracy on batch 287 on Training is 30.164930555555557\n",
            "Epoch #3. Accuracy on batch 288 on Training is 30.136245674740483\n",
            "Epoch #3. Accuracy on batch 289 on Training is 30.14008620689655\n",
            "Epoch #3. Accuracy on batch 290 on Training is 30.10094501718213\n",
            "Epoch #3. Accuracy on batch 291 on Training is 30.11558219178082\n",
            "Epoch #3. Accuracy on batch 292 on Training is 30.17278156996587\n",
            "Epoch #3. Accuracy on batch 293 on Training is 30.208333333333332\n",
            "Epoch #3. Accuracy on batch 294 on Training is 30.21186440677966\n",
            "Epoch #3. Accuracy on batch 295 on Training is 30.194256756756758\n",
            "Epoch #3. Accuracy on batch 296 on Training is 30.187289562289564\n",
            "Epoch #3. Accuracy on batch 297 on Training is 30.169882550335572\n",
            "Epoch #3. Accuracy on batch 298 on Training is 30.16304347826087\n",
            "Epoch #3. Accuracy on batch 299 on Training is 30.208333333333332\n",
            "Batch Id 300 is having training loss of 2624.65869140625\n",
            "16.2413387298584\n",
            "Epoch #3. Accuracy on batch 300 on Training is 30.20141196013289\n",
            "Epoch #3. Accuracy on batch 301 on Training is 30.173841059602648\n",
            "Epoch #3. Accuracy on batch 302 on Training is 30.208333333333332\n",
            "Epoch #3. Accuracy on batch 303 on Training is 30.252878289473685\n",
            "Epoch #3. Accuracy on batch 304 on Training is 30.24590163934426\n",
            "Epoch #3. Accuracy on batch 305 on Training is 30.238970588235293\n",
            "Epoch #3. Accuracy on batch 306 on Training is 30.221905537459282\n",
            "Epoch #3. Accuracy on batch 307 on Training is 30.255681818181817\n",
            "Epoch #3. Accuracy on batch 308 on Training is 30.238673139158575\n",
            "Epoch #3. Accuracy on batch 309 on Training is 30.302419354838708\n",
            "Epoch #3. Accuracy on batch 310 on Training is 30.315514469453376\n",
            "Epoch #3. Accuracy on batch 311 on Training is 30.30849358974359\n",
            "Epoch #3. Accuracy on batch 312 on Training is 30.281549520766774\n",
            "Epoch #3. Accuracy on batch 313 on Training is 30.324442675159236\n",
            "Epoch #3. Accuracy on batch 314 on Training is 30.36706349206349\n",
            "Epoch #3. Accuracy on batch 315 on Training is 30.399525316455698\n",
            "Epoch #3. Accuracy on batch 316 on Training is 30.441640378548897\n",
            "Epoch #3. Accuracy on batch 317 on Training is 30.43435534591195\n",
            "Epoch #3. Accuracy on batch 318 on Training is 30.4173197492163\n",
            "Epoch #3. Accuracy on batch 319 on Training is 30.41015625\n",
            "Batch Id 320 is having training loss of 2466.618408203125\n",
            "329.8583068847656\n",
            "Epoch #3. Accuracy on batch 320 on Training is 30.41277258566978\n",
            "Epoch #3. Accuracy on batch 321 on Training is 30.425077639751553\n",
            "Epoch #3. Accuracy on batch 322 on Training is 30.379256965944272\n",
            "Epoch #3. Accuracy on batch 323 on Training is 30.39158950617284\n",
            "Epoch #3. Accuracy on batch 324 on Training is 30.403846153846153\n",
            "Epoch #3. Accuracy on batch 325 on Training is 30.377684049079754\n",
            "Epoch #3. Accuracy on batch 326 on Training is 30.37079510703364\n",
            "Epoch #3. Accuracy on batch 327 on Training is 30.3734756097561\n",
            "Epoch #3. Accuracy on batch 328 on Training is 30.338145896656535\n",
            "Epoch #3. Accuracy on batch 329 on Training is 30.293560606060606\n",
            "Epoch #3. Accuracy on batch 330 on Training is 30.305891238670696\n",
            "Epoch #3. Accuracy on batch 331 on Training is 30.280496987951807\n",
            "Epoch #3. Accuracy on batch 332 on Training is 30.26463963963964\n",
            "Epoch #3. Accuracy on batch 333 on Training is 30.26758982035928\n",
            "Epoch #3. Accuracy on batch 334 on Training is 30.25186567164179\n",
            "Epoch #3. Accuracy on batch 335 on Training is 30.226934523809526\n",
            "Epoch #3. Accuracy on batch 336 on Training is 30.239243323442135\n",
            "Epoch #3. Accuracy on batch 337 on Training is 30.25147928994083\n",
            "Epoch #3. Accuracy on batch 338 on Training is 30.309734513274336\n",
            "Epoch #3. Accuracy on batch 339 on Training is 30.303308823529413\n",
            "Batch Id 340 is having training loss of 2528.723388671875\n",
            "40.54507064819336\n",
            "Epoch #3. Accuracy on batch 340 on Training is 30.28775659824047\n",
            "Epoch #3. Accuracy on batch 341 on Training is 30.263157894736842\n",
            "Epoch #3. Accuracy on batch 342 on Training is 30.266034985422742\n",
            "Epoch #3. Accuracy on batch 343 on Training is 30.296148255813954\n",
            "Epoch #3. Accuracy on batch 344 on Training is 30.26268115942029\n",
            "Epoch #3. Accuracy on batch 345 on Training is 30.265534682080926\n",
            "Epoch #3. Accuracy on batch 346 on Training is 30.24135446685879\n",
            "Epoch #3. Accuracy on batch 347 on Training is 30.24425287356322\n",
            "Epoch #3. Accuracy on batch 348 on Training is 30.21131805157593\n",
            "Epoch #3. Accuracy on batch 349 on Training is 30.232142857142858\n",
            "Epoch #3. Accuracy on batch 350 on Training is 30.24394586894587\n",
            "Epoch #3. Accuracy on batch 351 on Training is 30.246803977272727\n",
            "Epoch #3. Accuracy on batch 352 on Training is 30.249645892351275\n",
            "Epoch #3. Accuracy on batch 353 on Training is 30.25247175141243\n",
            "Epoch #3. Accuracy on batch 354 on Training is 30.29049295774648\n",
            "Epoch #3. Accuracy on batch 355 on Training is 30.319522471910112\n",
            "Epoch #3. Accuracy on batch 356 on Training is 30.260854341736696\n",
            "Epoch #3. Accuracy on batch 357 on Training is 30.228701117318437\n",
            "Epoch #3. Accuracy on batch 358 on Training is 30.231545961002787\n",
            "Epoch #3. Accuracy on batch 359 on Training is 30.234375\n",
            "Batch Id 360 is having training loss of 2462.011962890625\n",
            "21.397104263305664\n",
            "Epoch #3. Accuracy on batch 360 on Training is 30.24584487534626\n",
            "Epoch #3. Accuracy on batch 361 on Training is 30.248618784530386\n",
            "Epoch #3. Accuracy on batch 362 on Training is 30.225550964187327\n",
            "Epoch #3. Accuracy on batch 363 on Training is 30.211195054945055\n",
            "Epoch #3. Accuracy on batch 364 on Training is 30.19691780821918\n",
            "Epoch #3. Accuracy on batch 365 on Training is 30.225409836065573\n",
            "Epoch #3. Accuracy on batch 366 on Training is 30.228201634877383\n",
            "Epoch #3. Accuracy on batch 367 on Training is 30.256453804347824\n",
            "Epoch #3. Accuracy on batch 368 on Training is 30.199864498644985\n",
            "Epoch #3. Accuracy on batch 369 on Training is 30.219594594594593\n",
            "Epoch #3. Accuracy on batch 370 on Training is 30.24764150943396\n",
            "Epoch #3. Accuracy on batch 371 on Training is 30.225134408602152\n",
            "Epoch #3. Accuracy on batch 372 on Training is 30.20274798927614\n",
            "Epoch #3. Accuracy on batch 373 on Training is 30.155414438502675\n",
            "Epoch #3. Accuracy on batch 374 on Training is 30.166666666666668\n",
            "Epoch #3. Accuracy on batch 375 on Training is 30.152925531914892\n",
            "Epoch #3. Accuracy on batch 376 on Training is 30.16412466843501\n",
            "Epoch #3. Accuracy on batch 377 on Training is 30.166997354497354\n",
            "Epoch #3. Accuracy on batch 378 on Training is 30.16985488126649\n",
            "Epoch #3. Accuracy on batch 379 on Training is 30.19736842105263\n",
            "Batch Id 380 is having training loss of 2618.557373046875\n",
            "34.15012741088867\n",
            "Epoch #3. Accuracy on batch 380 on Training is 30.208333333333332\n",
            "Epoch #3. Accuracy on batch 381 on Training is 30.202879581151834\n",
            "Epoch #3. Accuracy on batch 382 on Training is 30.164817232375977\n",
            "Epoch #3. Accuracy on batch 383 on Training is 30.192057291666668\n",
            "Epoch #3. Accuracy on batch 384 on Training is 30.20292207792208\n",
            "Epoch #3. Accuracy on batch 385 on Training is 30.197538860103627\n",
            "Epoch #3. Accuracy on batch 386 on Training is 30.1437338501292\n",
            "Epoch #3. Accuracy on batch 387 on Training is 30.12242268041237\n",
            "Epoch #3. Accuracy on batch 388 on Training is 30.13335475578406\n",
            "Epoch #3. Accuracy on batch 389 on Training is 30.15224358974359\n",
            "Epoch #3. Accuracy on batch 390 on Training is 30.16304347826087\n",
            "Epoch #3. Accuracy on batch 391 on Training is 30.11001275510204\n",
            "Epoch #3. Accuracy on batch 392 on Training is 30.12881679389313\n",
            "Epoch #3. Accuracy on batch 393 on Training is 30.139593908629443\n",
            "Epoch #3. Accuracy on batch 394 on Training is 30.134493670886076\n",
            "Epoch #3. Accuracy on batch 395 on Training is 30.14520202020202\n",
            "Epoch #3. Accuracy on batch 396 on Training is 30.163727959697734\n",
            "Epoch #3. Accuracy on batch 397 on Training is 30.1821608040201\n",
            "Epoch #3. Accuracy on batch 398 on Training is 30.19266917293233\n",
            "Epoch #3. Accuracy on batch 399 on Training is 30.2265625\n",
            "Batch Id 400 is having training loss of 2593.1474609375\n",
            "14.249984741210938\n",
            "Epoch #3. Accuracy on batch 400 on Training is 30.244700748129677\n",
            "Epoch #3. Accuracy on batch 401 on Training is 30.239427860696516\n",
            "Epoch #3. Accuracy on batch 402 on Training is 30.25744416873449\n",
            "Epoch #3. Accuracy on batch 403 on Training is 30.25990099009901\n",
            "Epoch #3. Accuracy on batch 404 on Training is 30.262345679012345\n",
            "Epoch #3. Accuracy on batch 405 on Training is 30.249384236453203\n",
            "Epoch #3. Accuracy on batch 406 on Training is 30.236486486486488\n",
            "Epoch #3. Accuracy on batch 407 on Training is 30.238970588235293\n",
            "Epoch #3. Accuracy on batch 408 on Training is 30.23380195599022\n",
            "Epoch #3. Accuracy on batch 409 on Training is 30.266768292682926\n",
            "Epoch #3. Accuracy on batch 410 on Training is 30.27676399026764\n",
            "Epoch #3. Accuracy on batch 411 on Training is 30.294296116504853\n",
            "Epoch #3. Accuracy on batch 412 on Training is 30.319309927360774\n",
            "Epoch #3. Accuracy on batch 413 on Training is 30.321557971014492\n",
            "Epoch #3. Accuracy on batch 414 on Training is 30.33132530120482\n",
            "Epoch #3. Accuracy on batch 415 on Training is 30.348557692307693\n",
            "Epoch #3. Accuracy on batch 416 on Training is 30.350719424460433\n",
            "Epoch #3. Accuracy on batch 417 on Training is 30.345394736842106\n",
            "Epoch #3. Accuracy on batch 418 on Training is 30.340095465393794\n",
            "Epoch #3. Accuracy on batch 419 on Training is 30.364583333333332\n",
            "Batch Id 420 is having training loss of 2544.222412109375\n",
            "6748.751953125\n",
            "Epoch #3. Accuracy on batch 420 on Training is 30.3666864608076\n",
            "Epoch #3. Accuracy on batch 421 on Training is 30.353969194312796\n",
            "Epoch #3. Accuracy on batch 422 on Training is 30.35608747044917\n",
            "Epoch #3. Accuracy on batch 423 on Training is 30.36556603773585\n",
            "Epoch #3. Accuracy on batch 424 on Training is 30.316176470588236\n",
            "Epoch #3. Accuracy on batch 425 on Training is 30.311032863849764\n",
            "Epoch #3. Accuracy on batch 426 on Training is 30.349824355971897\n",
            "Epoch #3. Accuracy on batch 427 on Training is 30.33002336448598\n",
            "Epoch #3. Accuracy on batch 428 on Training is 30.339452214452216\n",
            "Epoch #3. Accuracy on batch 429 on Training is 30.348837209302324\n",
            "Epoch #3. Accuracy on batch 430 on Training is 30.365429234338748\n",
            "Epoch #3. Accuracy on batch 431 on Training is 30.36747685185185\n",
            "Epoch #3. Accuracy on batch 432 on Training is 30.34786374133949\n",
            "Epoch #3. Accuracy on batch 433 on Training is 30.371543778801843\n",
            "Epoch #3. Accuracy on batch 434 on Training is 30.36637931034483\n",
            "Epoch #3. Accuracy on batch 435 on Training is 30.361238532110093\n",
            "Epoch #3. Accuracy on batch 436 on Training is 30.363272311212814\n",
            "Epoch #3. Accuracy on batch 437 on Training is 30.372431506849313\n",
            "Epoch #3. Accuracy on batch 438 on Training is 30.374430523917994\n",
            "Epoch #3. Accuracy on batch 439 on Training is 30.36221590909091\n",
            "Batch Id 440 is having training loss of 2432.330078125\n",
            "65.80829620361328\n",
            "Epoch #3. Accuracy on batch 440 on Training is 30.34297052154195\n",
            "Epoch #3. Accuracy on batch 441 on Training is 30.352092760180994\n",
            "Epoch #3. Accuracy on batch 442 on Training is 30.340011286681715\n",
            "Epoch #3. Accuracy on batch 443 on Training is 30.34206081081081\n",
            "Epoch #3. Accuracy on batch 444 on Training is 30.33005617977528\n",
            "Epoch #3. Accuracy on batch 445 on Training is 30.360145739910315\n",
            "Epoch #3. Accuracy on batch 446 on Training is 30.369127516778523\n",
            "Epoch #3. Accuracy on batch 447 on Training is 30.357142857142858\n",
            "Epoch #3. Accuracy on batch 448 on Training is 30.3869710467706\n",
            "Epoch #3. Accuracy on batch 449 on Training is 30.395833333333332\n",
            "Epoch #3. Accuracy on batch 450 on Training is 30.383869179600886\n",
            "Epoch #3. Accuracy on batch 451 on Training is 30.399612831858406\n",
            "Epoch #3. Accuracy on batch 452 on Training is 30.408388520971304\n",
            "Epoch #3. Accuracy on batch 453 on Training is 30.430892070484582\n",
            "Epoch #3. Accuracy on batch 454 on Training is 30.432692307692307\n",
            "Epoch #3. Accuracy on batch 455 on Training is 30.43448464912281\n",
            "Epoch #3. Accuracy on batch 456 on Training is 30.463621444201312\n",
            "Epoch #3. Accuracy on batch 457 on Training is 30.45169213973799\n",
            "Epoch #3. Accuracy on batch 458 on Training is 30.439814814814813\n",
            "Epoch #3. Accuracy on batch 459 on Training is 30.380434782608695\n",
            "Batch Id 460 is having training loss of 2591.1279296875\n",
            "40.27696990966797\n",
            "Epoch #3. Accuracy on batch 460 on Training is 30.389099783080262\n",
            "Epoch #3. Accuracy on batch 461 on Training is 30.390963203463205\n",
            "Epoch #3. Accuracy on batch 462 on Training is 30.39281857451404\n",
            "Epoch #3. Accuracy on batch 463 on Training is 30.408135775862068\n",
            "Epoch #3. Accuracy on batch 464 on Training is 30.416666666666668\n",
            "Epoch #3. Accuracy on batch 465 on Training is 30.418454935622318\n",
            "Epoch #3. Accuracy on batch 466 on Training is 30.386777301927197\n",
            "Epoch #3. Accuracy on batch 467 on Training is 30.408653846153847\n",
            "Epoch #3. Accuracy on batch 468 on Training is 30.40378464818763\n",
            "Epoch #3. Accuracy on batch 469 on Training is 30.418882978723403\n",
            "Epoch #3. Accuracy on batch 470 on Training is 30.420647558386413\n",
            "Epoch #3. Accuracy on batch 471 on Training is 30.402542372881356\n",
            "Epoch #3. Accuracy on batch 472 on Training is 30.397727272727273\n",
            "Epoch #3. Accuracy on batch 473 on Training is 30.373154008438817\n",
            "Epoch #3. Accuracy on batch 474 on Training is 30.375\n",
            "Epoch #3. Accuracy on batch 475 on Training is 30.357142857142858\n",
            "Epoch #3. Accuracy on batch 476 on Training is 30.33280922431866\n",
            "Epoch #3. Accuracy on batch 477 on Training is 30.3543410041841\n",
            "Epoch #3. Accuracy on batch 478 on Training is 30.336638830897705\n",
            "Epoch #3. Accuracy on batch 479 on Training is 30.345052083333332\n",
            "Batch Id 480 is having training loss of 2488.680419921875\n",
            "379.7025146484375\n",
            "Epoch #3. Accuracy on batch 480 on Training is 30.327442827442827\n",
            "Epoch #3. Accuracy on batch 481 on Training is 30.303423236514522\n",
            "Epoch #3. Accuracy on batch 482 on Training is 30.285973084886127\n",
            "Epoch #3. Accuracy on batch 483 on Training is 30.294421487603305\n",
            "Epoch #3. Accuracy on batch 484 on Training is 30.2770618556701\n",
            "Epoch #3. Accuracy on batch 485 on Training is 30.29835390946502\n",
            "Epoch #3. Accuracy on batch 486 on Training is 30.261806981519506\n",
            "Epoch #3. Accuracy on batch 487 on Training is 30.263831967213115\n",
            "Epoch #3. Accuracy on batch 488 on Training is 30.278629856850717\n",
            "Epoch #3. Accuracy on batch 489 on Training is 30.28061224489796\n",
            "Epoch #3. Accuracy on batch 490 on Training is 30.269857433808554\n",
            "Epoch #3. Accuracy on batch 491 on Training is 30.227388211382113\n",
            "Epoch #3. Accuracy on batch 492 on Training is 30.24213995943205\n",
            "Epoch #3. Accuracy on batch 493 on Training is 30.263157894736842\n",
            "Epoch #3. Accuracy on batch 494 on Training is 30.24621212121212\n",
            "Epoch #3. Accuracy on batch 495 on Training is 30.248235887096776\n",
            "Epoch #3. Accuracy on batch 496 on Training is 30.269114688128774\n",
            "Epoch #3. Accuracy on batch 497 on Training is 30.220883534136547\n",
            "Epoch #3. Accuracy on batch 498 on Training is 30.210420841683366\n",
            "Epoch #3. Accuracy on batch 499 on Training is 30.2125\n",
            "Batch Id 500 is having training loss of 2634.5947265625\n",
            "22.75370979309082\n",
            "Epoch #3. Accuracy on batch 500 on Training is 30.202095808383234\n",
            "Epoch #3. Accuracy on batch 501 on Training is 30.21663346613546\n",
            "Epoch #3. Accuracy on batch 502 on Training is 30.218687872763418\n",
            "Epoch #3. Accuracy on batch 503 on Training is 30.202132936507937\n",
            "Epoch #3. Accuracy on batch 504 on Training is 30.21039603960396\n",
            "Epoch #3. Accuracy on batch 505 on Training is 30.18774703557312\n",
            "Epoch #3. Accuracy on batch 506 on Training is 30.183678500986193\n",
            "Epoch #3. Accuracy on batch 507 on Training is 30.19808070866142\n",
            "Epoch #3. Accuracy on batch 508 on Training is 30.17558939096267\n",
            "Epoch #3. Accuracy on batch 509 on Training is 30.189950980392158\n",
            "Epoch #3. Accuracy on batch 510 on Training is 30.222602739726028\n",
            "Epoch #3. Accuracy on batch 511 on Training is 30.21240234375\n",
            "Epoch #3. Accuracy on batch 512 on Training is 30.20224171539961\n",
            "Epoch #3. Accuracy on batch 513 on Training is 30.192120622568094\n",
            "Epoch #3. Accuracy on batch 514 on Training is 30.218446601941746\n",
            "Epoch #3. Accuracy on batch 515 on Training is 30.24467054263566\n",
            "Epoch #3. Accuracy on batch 516 on Training is 30.204303675048354\n",
            "Epoch #3. Accuracy on batch 517 on Training is 30.18219111969112\n",
            "Epoch #3. Accuracy on batch 518 on Training is 30.184248554913296\n",
            "Epoch #3. Accuracy on batch 519 on Training is 30.16826923076923\n",
            "Batch Id 520 is having training loss of 2783.833984375\n",
            "17470.49609375\n",
            "Epoch #3. Accuracy on batch 520 on Training is 30.164347408829176\n",
            "Epoch #3. Accuracy on batch 521 on Training is 30.142480842911876\n",
            "Epoch #3. Accuracy on batch 522 on Training is 30.13862332695985\n",
            "Epoch #3. Accuracy on batch 523 on Training is 30.146708015267176\n",
            "Epoch #3. Accuracy on batch 524 on Training is 30.13095238095238\n",
            "Epoch #3. Accuracy on batch 525 on Training is 30.12119771863118\n",
            "Epoch #3. Accuracy on batch 526 on Training is 30.117409867172675\n",
            "Epoch #3. Accuracy on batch 527 on Training is 30.107717803030305\n",
            "Epoch #3. Accuracy on batch 528 on Training is 30.109877126654066\n",
            "Epoch #3. Accuracy on batch 529 on Training is 30.13561320754717\n",
            "Epoch #3. Accuracy on batch 530 on Training is 30.131826741996232\n",
            "Epoch #3. Accuracy on batch 531 on Training is 30.133928571428573\n",
            "Epoch #3. Accuracy on batch 532 on Training is 30.16533771106942\n",
            "Epoch #3. Accuracy on batch 533 on Training is 30.179073033707866\n",
            "Epoch #3. Accuracy on batch 534 on Training is 30.169392523364486\n",
            "Epoch #3. Accuracy on batch 535 on Training is 30.183069029850746\n",
            "Epoch #3. Accuracy on batch 536 on Training is 30.190875232774673\n",
            "Epoch #3. Accuracy on batch 537 on Training is 30.192843866171003\n",
            "Epoch #3. Accuracy on batch 538 on Training is 30.18320964749536\n",
            "Epoch #3. Accuracy on batch 539 on Training is 30.19675925925926\n",
            "Batch Id 540 is having training loss of 2837.031494140625\n",
            "29.09395980834961\n",
            "Epoch #3. Accuracy on batch 540 on Training is 30.18137707948244\n",
            "Epoch #3. Accuracy on batch 541 on Training is 30.18911439114391\n",
            "Epoch #3. Accuracy on batch 542 on Training is 30.20257826887661\n",
            "Epoch #3. Accuracy on batch 543 on Training is 30.19875919117647\n",
            "Epoch #3. Accuracy on batch 544 on Training is 30.22362385321101\n",
            "Epoch #3. Accuracy on batch 545 on Training is 30.225503663003664\n",
            "Epoch #3. Accuracy on batch 546 on Training is 30.23308957952468\n",
            "Epoch #3. Accuracy on batch 547 on Training is 30.223540145985403\n",
            "Epoch #3. Accuracy on batch 548 on Training is 30.214025500910747\n",
            "Epoch #3. Accuracy on batch 549 on Training is 30.227272727272727\n",
            "Epoch #3. Accuracy on batch 550 on Training is 30.22912885662432\n",
            "Epoch #3. Accuracy on batch 551 on Training is 30.21399456521739\n",
            "Epoch #3. Accuracy on batch 552 on Training is 30.22151898734177\n",
            "Epoch #3. Accuracy on batch 553 on Training is 30.206453068592058\n",
            "Epoch #3. Accuracy on batch 554 on Training is 30.2027027027027\n",
            "Epoch #3. Accuracy on batch 555 on Training is 30.198965827338128\n",
            "Epoch #3. Accuracy on batch 556 on Training is 30.200852782764812\n",
            "Epoch #3. Accuracy on batch 557 on Training is 30.197132616487455\n",
            "Epoch #3. Accuracy on batch 558 on Training is 30.182245080500895\n",
            "Epoch #3. Accuracy on batch 559 on Training is 30.161830357142858\n",
            "Batch Id 560 is having training loss of 2839.660888671875\n",
            "19.031906127929688\n",
            "Epoch #3. Accuracy on batch 560 on Training is 30.16934046345811\n",
            "Epoch #3. Accuracy on batch 561 on Training is 30.16570284697509\n",
            "Epoch #3. Accuracy on batch 562 on Training is 30.17317939609236\n",
            "Epoch #3. Accuracy on batch 563 on Training is 30.18617021276596\n",
            "Epoch #3. Accuracy on batch 564 on Training is 30.19358407079646\n",
            "Epoch #3. Accuracy on batch 565 on Training is 30.200971731448764\n",
            "Epoch #3. Accuracy on batch 566 on Training is 30.191798941798943\n",
            "Epoch #3. Accuracy on batch 567 on Training is 30.171654929577464\n",
            "Epoch #3. Accuracy on batch 568 on Training is 30.16805799648506\n",
            "Epoch #3. Accuracy on batch 569 on Training is 30.158991228070175\n",
            "Epoch #3. Accuracy on batch 570 on Training is 30.160901926444833\n",
            "Epoch #3. Accuracy on batch 571 on Training is 30.16826923076923\n",
            "Epoch #3. Accuracy on batch 572 on Training is 30.18106457242583\n",
            "Epoch #3. Accuracy on batch 573 on Training is 30.177482578397214\n",
            "Epoch #3. Accuracy on batch 574 on Training is 30.17391304347826\n",
            "Epoch #3. Accuracy on batch 575 on Training is 30.192057291666668\n",
            "Epoch #3. Accuracy on batch 576 on Training is 30.21555459272097\n",
            "Epoch #3. Accuracy on batch 577 on Training is 30.206531141868513\n",
            "Epoch #3. Accuracy on batch 578 on Training is 30.229922279792746\n",
            "Epoch #3. Accuracy on batch 579 on Training is 30.226293103448278\n",
            "Batch Id 580 is having training loss of 2761.18994140625\n",
            "21.32346534729004\n",
            "Epoch #3. Accuracy on batch 580 on Training is 30.23343373493976\n",
            "Epoch #3. Accuracy on batch 581 on Training is 30.235180412371133\n",
            "Epoch #3. Accuracy on batch 582 on Training is 30.23156089193825\n",
            "Epoch #3. Accuracy on batch 583 on Training is 30.23865582191781\n",
            "Epoch #3. Accuracy on batch 584 on Training is 30.235042735042736\n",
            "Epoch #3. Accuracy on batch 585 on Training is 30.215443686006825\n",
            "Epoch #3. Accuracy on batch 586 on Training is 30.211882453151617\n",
            "Epoch #3. Accuracy on batch 587 on Training is 30.208333333333332\n",
            "Epoch #3. Accuracy on batch 588 on Training is 30.210101867572156\n",
            "Epoch #3. Accuracy on batch 589 on Training is 30.20656779661017\n",
            "Epoch #3. Accuracy on batch 590 on Training is 30.192470389170897\n",
            "Epoch #3. Accuracy on batch 591 on Training is 30.20481418918919\n",
            "Epoch #3. Accuracy on batch 592 on Training is 30.1960370994941\n",
            "Epoch #3. Accuracy on batch 593 on Training is 30.171506734006734\n",
            "Epoch #3. Accuracy on batch 594 on Training is 30.168067226890756\n",
            "Epoch #3. Accuracy on batch 595 on Training is 30.175125838926174\n",
            "Epoch #3. Accuracy on batch 596 on Training is 30.1821608040201\n",
            "Epoch #3. Accuracy on batch 597 on Training is 30.189172240802677\n",
            "Epoch #3. Accuracy on batch 598 on Training is 30.19094323873122\n",
            "Epoch #3. Accuracy on batch 599 on Training is 30.182291666666668\n",
            "Batch Id 600 is having training loss of 2751.69580078125\n",
            "47.347312927246094\n",
            "Epoch #3. Accuracy on batch 600 on Training is 30.178868552412645\n",
            "Epoch #3. Accuracy on batch 601 on Training is 30.185838870431894\n",
            "Epoch #3. Accuracy on batch 602 on Training is 30.192786069651742\n",
            "Epoch #3. Accuracy on batch 603 on Training is 30.163493377483444\n",
            "Epoch #3. Accuracy on batch 604 on Training is 30.180785123966942\n",
            "Epoch #3. Accuracy on batch 605 on Training is 30.187706270627064\n",
            "Epoch #3. Accuracy on batch 606 on Training is 30.189456342668862\n",
            "Epoch #3. Accuracy on batch 607 on Training is 30.186060855263158\n",
            "Epoch #3. Accuracy on batch 608 on Training is 30.16215106732348\n",
            "Epoch #3. Accuracy on batch 609 on Training is 30.16393442622951\n",
            "Epoch #3. Accuracy on batch 610 on Training is 30.140139116202946\n",
            "Epoch #3. Accuracy on batch 611 on Training is 30.131740196078432\n",
            "Epoch #3. Accuracy on batch 612 on Training is 30.108075040783035\n",
            "Epoch #3. Accuracy on batch 613 on Training is 30.104845276872965\n",
            "Epoch #3. Accuracy on batch 614 on Training is 30.116869918699187\n",
            "Epoch #3. Accuracy on batch 615 on Training is 30.113636363636363\n",
            "Epoch #3. Accuracy on batch 616 on Training is 30.11547811993517\n",
            "Epoch #3. Accuracy on batch 617 on Training is 30.12742718446602\n",
            "Epoch #3. Accuracy on batch 618 on Training is 30.149434571890147\n",
            "Epoch #3. Accuracy on batch 619 on Training is 30.141129032258064\n",
            "Batch Id 620 is having training loss of 2775.784423828125\n",
            "17.954919815063477\n",
            "Epoch #3. Accuracy on batch 620 on Training is 30.12781803542673\n",
            "Epoch #3. Accuracy on batch 621 on Training is 30.119573954983924\n",
            "Epoch #3. Accuracy on batch 622 on Training is 30.136436597110755\n",
            "Epoch #3. Accuracy on batch 623 on Training is 30.133213141025642\n",
            "Epoch #3. Accuracy on batch 624 on Training is 30.14\n",
            "Epoch #3. Accuracy on batch 625 on Training is 30.1517571884984\n",
            "Epoch #3. Accuracy on batch 626 on Training is 30.158492822966508\n",
            "Epoch #3. Accuracy on batch 627 on Training is 30.180135350318473\n",
            "Epoch #3. Accuracy on batch 628 on Training is 30.176868044515103\n",
            "Epoch #3. Accuracy on batch 629 on Training is 30.183531746031747\n",
            "Epoch #3. Accuracy on batch 630 on Training is 30.175316957210775\n",
            "Epoch #3. Accuracy on batch 631 on Training is 30.167128164556964\n",
            "Epoch #3. Accuracy on batch 632 on Training is 30.154028436018958\n",
            "Epoch #3. Accuracy on batch 633 on Training is 30.126182965299684\n",
            "Epoch #3. Accuracy on batch 634 on Training is 30.12795275590551\n",
            "Epoch #3. Accuracy on batch 635 on Training is 30.129716981132077\n",
            "Epoch #3. Accuracy on batch 636 on Training is 30.13638147566719\n",
            "Epoch #3. Accuracy on batch 637 on Training is 30.13322884012539\n",
            "Epoch #3. Accuracy on batch 638 on Training is 30.13986697965571\n",
            "Epoch #3. Accuracy on batch 639 on Training is 30.1220703125\n",
            "Batch Id 640 is having training loss of 2696.41748046875\n",
            "3921.0029296875\n",
            "Epoch #3. Accuracy on batch 640 on Training is 30.109204368174726\n",
            "Epoch #3. Accuracy on batch 641 on Training is 30.120716510903428\n",
            "Epoch #3. Accuracy on batch 642 on Training is 30.10303265940902\n",
            "Epoch #3. Accuracy on batch 643 on Training is 30.104813664596275\n",
            "Epoch #3. Accuracy on batch 644 on Training is 30.0968992248062\n",
            "Epoch #3. Accuracy on batch 645 on Training is 30.118034055727556\n",
            "Epoch #3. Accuracy on batch 646 on Training is 30.114953632148378\n",
            "Epoch #3. Accuracy on batch 647 on Training is 30.11670524691358\n",
            "Epoch #3. Accuracy on batch 648 on Training is 30.113636363636363\n",
            "Epoch #3. Accuracy on batch 649 on Training is 30.120192307692307\n",
            "Epoch #3. Accuracy on batch 650 on Training is 30.141129032258064\n",
            "Epoch #3. Accuracy on batch 651 on Training is 30.13803680981595\n",
            "Epoch #3. Accuracy on batch 652 on Training is 30.17323889739663\n",
            "Epoch #3. Accuracy on batch 653 on Training is 30.155772171253822\n",
            "Epoch #3. Accuracy on batch 654 on Training is 30.171755725190838\n",
            "Epoch #3. Accuracy on batch 655 on Training is 30.1781631097561\n",
            "Epoch #3. Accuracy on batch 656 on Training is 30.170281582952814\n",
            "Epoch #3. Accuracy on batch 657 on Training is 30.171922492401215\n",
            "Epoch #3. Accuracy on batch 658 on Training is 30.178300455235206\n",
            "Epoch #3. Accuracy on batch 659 on Training is 30.189393939393938\n",
            "Batch Id 660 is having training loss of 2622.251953125\n",
            "45.826393127441406\n",
            "Epoch #3. Accuracy on batch 660 on Training is 30.1768154311649\n",
            "Epoch #3. Accuracy on batch 661 on Training is 30.183157099697887\n",
            "Epoch #3. Accuracy on batch 662 on Training is 30.19419306184012\n",
            "Epoch #3. Accuracy on batch 663 on Training is 30.162838855421686\n",
            "Epoch #3. Accuracy on batch 664 on Training is 30.164473684210527\n",
            "Epoch #3. Accuracy on batch 665 on Training is 30.170795795795797\n",
            "Epoch #3. Accuracy on batch 666 on Training is 30.186469265367318\n",
            "Epoch #3. Accuracy on batch 667 on Training is 30.19741766467066\n",
            "Epoch #3. Accuracy on batch 668 on Training is 30.198991031390136\n",
            "Epoch #3. Accuracy on batch 669 on Training is 30.200559701492537\n",
            "Epoch #3. Accuracy on batch 670 on Training is 30.19746646795827\n",
            "Epoch #3. Accuracy on batch 671 on Training is 30.199032738095237\n",
            "Epoch #3. Accuracy on batch 672 on Training is 30.186664190193166\n",
            "Epoch #3. Accuracy on batch 673 on Training is 30.17433234421365\n",
            "Epoch #3. Accuracy on batch 674 on Training is 30.180555555555557\n",
            "Epoch #3. Accuracy on batch 675 on Training is 30.20525147928994\n",
            "Epoch #3. Accuracy on batch 676 on Training is 30.19294682422452\n",
            "Epoch #3. Accuracy on batch 677 on Training is 30.194505899705014\n",
            "Epoch #3. Accuracy on batch 678 on Training is 30.209867452135494\n",
            "Epoch #3. Accuracy on batch 679 on Training is 30.225183823529413\n",
            "Batch Id 680 is having training loss of 2624.402587890625\n",
            "25.14204978942871\n",
            "Epoch #3. Accuracy on batch 680 on Training is 30.23127753303965\n",
            "Epoch #3. Accuracy on batch 681 on Training is 30.26026392961877\n",
            "Epoch #3. Accuracy on batch 682 on Training is 30.275439238653\n",
            "Epoch #3. Accuracy on batch 683 on Training is 30.299707602339183\n",
            "Epoch #3. Accuracy on batch 684 on Training is 30.282846715328468\n",
            "Epoch #3. Accuracy on batch 685 on Training is 30.279701166180757\n",
            "Epoch #3. Accuracy on batch 686 on Training is 30.29475982532751\n",
            "Epoch #3. Accuracy on batch 687 on Training is 30.309774709302324\n",
            "Epoch #3. Accuracy on batch 688 on Training is 30.31567489114659\n",
            "Epoch #3. Accuracy on batch 689 on Training is 30.307971014492754\n",
            "Epoch #3. Accuracy on batch 690 on Training is 30.29124457308249\n",
            "Epoch #3. Accuracy on batch 691 on Training is 30.30166184971098\n",
            "Epoch #3. Accuracy on batch 692 on Training is 30.307539682539684\n",
            "Epoch #3. Accuracy on batch 693 on Training is 30.295389048991353\n",
            "Epoch #3. Accuracy on batch 694 on Training is 30.301258992805757\n",
            "Epoch #3. Accuracy on batch 695 on Training is 30.29364224137931\n",
            "Epoch #3. Accuracy on batch 696 on Training is 30.295014347202297\n",
            "Epoch #3. Accuracy on batch 697 on Training is 30.29638252148997\n",
            "Epoch #3. Accuracy on batch 698 on Training is 30.30221745350501\n",
            "Epoch #3. Accuracy on batch 699 on Training is 30.299107142857142\n",
            "Batch Id 700 is having training loss of 2621.12353515625\n",
            "22.58611488342285\n",
            "Epoch #3. Accuracy on batch 700 on Training is 30.29154778887304\n",
            "Epoch #3. Accuracy on batch 701 on Training is 30.292913105413106\n",
            "Epoch #3. Accuracy on batch 702 on Training is 30.289829302987197\n",
            "Epoch #3. Accuracy on batch 703 on Training is 30.304509943181817\n",
            "Epoch #3. Accuracy on batch 704 on Training is 30.30141843971631\n",
            "Epoch #3. Accuracy on batch 705 on Training is 30.316041076487252\n",
            "Epoch #3. Accuracy on batch 706 on Training is 30.312942008486562\n",
            "Epoch #3. Accuracy on batch 707 on Training is 30.318679378531073\n",
            "Epoch #3. Accuracy on batch 708 on Training is 30.306770098730606\n",
            "Epoch #3. Accuracy on batch 709 on Training is 30.316901408450704\n",
            "Epoch #3. Accuracy on batch 710 on Training is 30.27865682137834\n",
            "Epoch #3. Accuracy on batch 711 on Training is 30.262464887640448\n",
            "Epoch #3. Accuracy on batch 712 on Training is 30.237552594670408\n",
            "Epoch #3. Accuracy on batch 713 on Training is 30.234593837535012\n",
            "Epoch #3. Accuracy on batch 714 on Training is 30.21416083916084\n",
            "Epoch #3. Accuracy on batch 715 on Training is 30.202513966480446\n",
            "Epoch #3. Accuracy on batch 716 on Training is 30.20397489539749\n",
            "Epoch #3. Accuracy on batch 717 on Training is 30.192374651810585\n",
            "Epoch #3. Accuracy on batch 718 on Training is 30.202538247566064\n",
            "Epoch #3. Accuracy on batch 719 on Training is 30.203993055555557\n",
            "Batch Id 720 is having training loss of 3008.342529296875\n",
            "21.116212844848633\n",
            "Epoch #3. Accuracy on batch 720 on Training is 30.205443828016644\n",
            "Epoch #3. Accuracy on batch 721 on Training is 30.202562326869806\n",
            "Epoch #3. Accuracy on batch 722 on Training is 30.186721991701244\n",
            "Epoch #3. Accuracy on batch 723 on Training is 30.192506906077348\n",
            "Epoch #3. Accuracy on batch 724 on Training is 30.185344827586206\n",
            "Epoch #3. Accuracy on batch 725 on Training is 30.18250688705234\n",
            "Epoch #3. Accuracy on batch 726 on Training is 30.17967675378267\n",
            "Epoch #3. Accuracy on batch 727 on Training is 30.189732142857142\n",
            "Epoch #3. Accuracy on batch 728 on Training is 30.204046639231823\n",
            "Epoch #3. Accuracy on batch 729 on Training is 30.209760273972602\n",
            "Epoch #3. Accuracy on batch 730 on Training is 30.232558139534884\n",
            "Epoch #3. Accuracy on batch 731 on Training is 30.251024590163933\n",
            "Epoch #3. Accuracy on batch 732 on Training is 30.256650750341063\n",
            "Epoch #3. Accuracy on batch 733 on Training is 30.245231607629428\n",
            "Epoch #3. Accuracy on batch 734 on Training is 30.276360544217688\n",
            "Epoch #3. Accuracy on batch 735 on Training is 30.277683423913043\n",
            "Epoch #3. Accuracy on batch 736 on Training is 30.26628222523745\n",
            "Epoch #3. Accuracy on batch 737 on Training is 30.25067750677507\n",
            "Epoch #3. Accuracy on batch 738 on Training is 30.25625845737483\n",
            "Epoch #3. Accuracy on batch 739 on Training is 30.25337837837838\n",
            "Batch Id 740 is having training loss of 3063.197265625\n",
            "60257.9375\n",
            "Epoch #3. Accuracy on batch 740 on Training is 30.242071524966263\n",
            "Epoch #3. Accuracy on batch 741 on Training is 30.26027628032345\n",
            "Epoch #3. Accuracy on batch 742 on Training is 30.265814266487215\n",
            "Epoch #3. Accuracy on batch 743 on Training is 30.25453629032258\n",
            "Epoch #3. Accuracy on batch 744 on Training is 30.251677852348994\n",
            "Epoch #3. Accuracy on batch 745 on Training is 30.24882707774799\n",
            "Epoch #3. Accuracy on batch 746 on Training is 30.241800535475235\n",
            "Epoch #3. Accuracy on batch 747 on Training is 30.247326203208555\n",
            "Epoch #3. Accuracy on batch 748 on Training is 30.236148197596794\n",
            "Epoch #3. Accuracy on batch 749 on Training is 30.216666666666665\n",
            "Epoch #3. Accuracy on batch 750 on Training is 30.21804260985353\n",
            "Epoch #3. Accuracy on batch 751 on Training is 30.227726063829788\n",
            "Epoch #3. Accuracy on batch 752 on Training is 30.229083665338646\n",
            "Epoch #3. Accuracy on batch 753 on Training is 30.242871352785144\n",
            "Epoch #3. Accuracy on batch 754 on Training is 30.244205298013245\n",
            "Epoch #3. Accuracy on batch 755 on Training is 30.23726851851852\n",
            "Epoch #3. Accuracy on batch 756 on Training is 30.205581241743726\n",
            "Epoch #3. Accuracy on batch 757 on Training is 30.211081794195252\n",
            "Epoch #3. Accuracy on batch 758 on Training is 30.212450592885375\n",
            "Epoch #3. Accuracy on batch 759 on Training is 30.213815789473685\n",
            "Batch Id 760 is having training loss of 3060.707275390625\n",
            "1283.2032470703125\n",
            "Epoch #3. Accuracy on batch 760 on Training is 30.219283837056505\n",
            "Epoch #3. Accuracy on batch 761 on Training is 30.224737532808398\n",
            "Epoch #3. Accuracy on batch 762 on Training is 30.242463958060288\n",
            "Epoch #3. Accuracy on batch 763 on Training is 30.24378272251309\n",
            "Epoch #3. Accuracy on batch 764 on Training is 30.249183006535947\n",
            "Epoch #3. Accuracy on batch 765 on Training is 30.23417101827676\n",
            "Epoch #3. Accuracy on batch 766 on Training is 30.223272490221643\n",
            "Epoch #3. Accuracy on batch 767 on Training is 30.216471354166668\n",
            "Epoch #3. Accuracy on batch 768 on Training is 30.20968790637191\n",
            "Epoch #3. Accuracy on batch 769 on Training is 30.211038961038962\n",
            "Epoch #3. Accuracy on batch 770 on Training is 30.196173800259402\n",
            "Epoch #3. Accuracy on batch 771 on Training is 30.193490932642487\n",
            "Epoch #3. Accuracy on batch 772 on Training is 30.18272962483829\n",
            "Epoch #3. Accuracy on batch 773 on Training is 30.176033591731265\n",
            "Epoch #3. Accuracy on batch 774 on Training is 30.181451612903224\n",
            "Epoch #3. Accuracy on batch 775 on Training is 30.202963917525775\n",
            "Epoch #3. Accuracy on batch 776 on Training is 30.196267696267697\n",
            "Epoch #3. Accuracy on batch 777 on Training is 30.209672236503856\n",
            "Epoch #3. Accuracy on batch 778 on Training is 30.223042362002566\n",
            "Epoch #3. Accuracy on batch 779 on Training is 30.220352564102566\n",
            "Batch Id 780 is having training loss of 3170.000244140625\n",
            "30.719253540039062\n",
            "Epoch #3. Accuracy on batch 780 on Training is 30.20566581306018\n",
            "Epoch #3. Accuracy on batch 781 on Training is 30.203005115089514\n",
            "Epoch #3. Accuracy on batch 782 on Training is 30.180395913154534\n",
            "Epoch #3. Accuracy on batch 783 on Training is 30.181760204081634\n",
            "Epoch #3. Accuracy on batch 784 on Training is 30.17515923566879\n",
            "Epoch #3. Accuracy on batch 785 on Training is 30.21230916030534\n",
            "Epoch #3. Accuracy on batch 786 on Training is 30.217598475222363\n",
            "Epoch #3. Accuracy on batch 787 on Training is 30.214942893401016\n",
            "Epoch #3. Accuracy on batch 788 on Training is 30.200411913814957\n",
            "Epoch #3. Accuracy on batch 789 on Training is 30.19382911392405\n",
            "Epoch #3. Accuracy on batch 790 on Training is 30.179361567635905\n",
            "Epoch #3. Accuracy on batch 791 on Training is 30.18465909090909\n",
            "Epoch #3. Accuracy on batch 792 on Training is 30.186002522068097\n",
            "Epoch #3. Accuracy on batch 793 on Training is 30.191278337531486\n",
            "Epoch #3. Accuracy on batch 794 on Training is 30.18867924528302\n",
            "Epoch #3. Accuracy on batch 795 on Training is 30.1821608040201\n",
            "Epoch #3. Accuracy on batch 796 on Training is 30.159974905897116\n",
            "Epoch #3. Accuracy on batch 797 on Training is 30.165256892230577\n",
            "Epoch #3. Accuracy on batch 798 on Training is 30.16270337922403\n",
            "Epoch #3. Accuracy on batch 799 on Training is 30.1796875\n",
            "Batch Id 800 is having training loss of 3101.6123046875\n",
            "11.373515129089355\n",
            "Epoch #3. Accuracy on batch 800 on Training is 30.19272784019975\n",
            "Epoch #3. Accuracy on batch 801 on Training is 30.194046134663342\n",
            "Epoch #3. Accuracy on batch 802 on Training is 30.18368617683686\n",
            "Epoch #3. Accuracy on batch 803 on Training is 30.17723880597015\n",
            "Epoch #3. Accuracy on batch 804 on Training is 30.178571428571427\n",
            "Epoch #3. Accuracy on batch 805 on Training is 30.176023573200993\n",
            "Epoch #3. Accuracy on batch 806 on Training is 30.165737298636927\n",
            "Epoch #3. Accuracy on batch 807 on Training is 30.155476485148515\n",
            "Epoch #3. Accuracy on batch 808 on Training is 30.156829419035848\n",
            "Epoch #3. Accuracy on batch 809 on Training is 30.150462962962962\n",
            "Epoch #3. Accuracy on batch 810 on Training is 30.151818742293464\n",
            "Epoch #3. Accuracy on batch 811 on Training is 30.13777709359606\n",
            "Epoch #3. Accuracy on batch 812 on Training is 30.13530135301353\n",
            "Epoch #3. Accuracy on batch 813 on Training is 30.14818796068796\n",
            "Epoch #3. Accuracy on batch 814 on Training is 30.130368098159508\n",
            "Epoch #3. Accuracy on batch 815 on Training is 30.10876225490196\n",
            "Epoch #3. Accuracy on batch 816 on Training is 30.121634026927783\n",
            "Epoch #3. Accuracy on batch 817 on Training is 30.12301344743276\n",
            "Epoch #3. Accuracy on batch 818 on Training is 30.093864468864467\n",
            "Epoch #3. Accuracy on batch 819 on Training is 30.10670731707317\n",
            "Batch Id 820 is having training loss of 3086.42529296875\n",
            "28.670700073242188\n",
            "Epoch #3. Accuracy on batch 820 on Training is 30.11951887941535\n",
            "Epoch #3. Accuracy on batch 821 on Training is 30.101885644768856\n",
            "Epoch #3. Accuracy on batch 822 on Training is 30.103280680437425\n",
            "Epoch #3. Accuracy on batch 823 on Training is 30.089502427184467\n",
            "Epoch #3. Accuracy on batch 824 on Training is 30.083333333333332\n",
            "Epoch #3. Accuracy on batch 825 on Training is 30.09231234866828\n",
            "Epoch #3. Accuracy on batch 826 on Training is 30.10882708585248\n",
            "Epoch #3. Accuracy on batch 827 on Training is 30.11020531400966\n",
            "Epoch #3. Accuracy on batch 828 on Training is 30.107810615199035\n",
            "Epoch #3. Accuracy on batch 829 on Training is 30.10918674698795\n",
            "Epoch #3. Accuracy on batch 830 on Training is 30.114320096269555\n",
            "Epoch #3. Accuracy on batch 831 on Training is 30.11192908653846\n",
            "Epoch #3. Accuracy on batch 832 on Training is 30.10579231692677\n",
            "Epoch #3. Accuracy on batch 833 on Training is 30.10341726618705\n",
            "Epoch #3. Accuracy on batch 834 on Training is 30.112275449101798\n",
            "Epoch #3. Accuracy on batch 835 on Training is 30.12111244019139\n",
            "Epoch #3. Accuracy on batch 836 on Training is 30.133661887694146\n",
            "Epoch #3. Accuracy on batch 837 on Training is 30.13126491646778\n",
            "Epoch #3. Accuracy on batch 838 on Training is 30.12142431466031\n",
            "Epoch #3. Accuracy on batch 839 on Training is 30.122767857142858\n",
            "Batch Id 840 is having training loss of 3082.166748046875\n",
            "24.774494171142578\n",
            "Epoch #3. Accuracy on batch 840 on Training is 30.13897146254459\n",
            "Epoch #3. Accuracy on batch 841 on Training is 30.155136579572446\n",
            "Epoch #3. Accuracy on batch 842 on Training is 30.160142348754448\n",
            "Epoch #3. Accuracy on batch 843 on Training is 30.161433649289098\n",
            "Epoch #3. Accuracy on batch 844 on Training is 30.166420118343197\n",
            "Epoch #3. Accuracy on batch 845 on Training is 30.16770094562648\n",
            "Epoch #3. Accuracy on batch 846 on Training is 30.168978748524204\n",
            "Epoch #3. Accuracy on batch 847 on Training is 30.173938679245282\n",
            "Epoch #3. Accuracy on batch 848 on Training is 30.16416372202591\n",
            "Epoch #3. Accuracy on batch 849 on Training is 30.158088235294116\n",
            "Epoch #3. Accuracy on batch 850 on Training is 30.155699177438308\n",
            "Epoch #3. Accuracy on batch 851 on Training is 30.156983568075116\n",
            "Epoch #3. Accuracy on batch 852 on Training is 30.150937866354045\n",
            "Epoch #3. Accuracy on batch 853 on Training is 30.16320257611241\n",
            "Epoch #3. Accuracy on batch 854 on Training is 30.160818713450293\n",
            "Epoch #3. Accuracy on batch 855 on Training is 30.165741822429908\n",
            "Epoch #3. Accuracy on batch 856 on Training is 30.16336056009335\n",
            "Epoch #3. Accuracy on batch 857 on Training is 30.16826923076923\n",
            "Epoch #3. Accuracy on batch 858 on Training is 30.165890570430733\n",
            "Epoch #3. Accuracy on batch 859 on Training is 30.174418604651162\n",
            "Batch Id 860 is having training loss of 3012.1044921875\n",
            "18.546964645385742\n",
            "Epoch #3. Accuracy on batch 860 on Training is 30.18655632984901\n",
            "Epoch #3. Accuracy on batch 861 on Training is 30.184164733178655\n",
            "Epoch #3. Accuracy on batch 862 on Training is 30.18177867902665\n",
            "Epoch #3. Accuracy on batch 863 on Training is 30.17578125\n",
            "Epoch #3. Accuracy on batch 864 on Training is 30.19508670520231\n",
            "Epoch #3. Accuracy on batch 865 on Training is 30.20352193995381\n",
            "Epoch #3. Accuracy on batch 866 on Training is 30.211937716262977\n",
            "Epoch #3. Accuracy on batch 867 on Training is 30.21673387096774\n",
            "Epoch #3. Accuracy on batch 868 on Training is 30.214326812428077\n",
            "Epoch #3. Accuracy on batch 869 on Training is 30.226293103448278\n",
            "Epoch #3. Accuracy on batch 870 on Training is 30.23105625717566\n",
            "Epoch #3. Accuracy on batch 871 on Training is 30.2322247706422\n",
            "Epoch #3. Accuracy on batch 872 on Training is 30.233390607101946\n",
            "Epoch #3. Accuracy on batch 873 on Training is 30.24170480549199\n",
            "Epoch #3. Accuracy on batch 874 on Training is 30.24642857142857\n",
            "Epoch #3. Accuracy on batch 875 on Training is 30.240439497716896\n",
            "Epoch #3. Accuracy on batch 876 on Training is 30.248717217787913\n",
            "Epoch #3. Accuracy on batch 877 on Training is 30.24629840546697\n",
            "Epoch #3. Accuracy on batch 878 on Training is 30.254550625711037\n",
            "Epoch #3. Accuracy on batch 879 on Training is 30.255681818181817\n",
            "Batch Id 880 is having training loss of 2951.318359375\n",
            "17.21006965637207\n",
            "Epoch #3. Accuracy on batch 880 on Training is 30.27454597048808\n",
            "Epoch #3. Accuracy on batch 881 on Training is 30.272108843537413\n",
            "Epoch #3. Accuracy on batch 882 on Training is 30.287372593431485\n",
            "Epoch #3. Accuracy on batch 883 on Training is 30.295531674208146\n",
            "Epoch #3. Accuracy on batch 884 on Training is 30.300141242937855\n",
            "Epoch #3. Accuracy on batch 885 on Training is 30.301213318284425\n",
            "Epoch #3. Accuracy on batch 886 on Training is 30.30228297632469\n",
            "Epoch #3. Accuracy on batch 887 on Training is 30.292792792792792\n",
            "Epoch #3. Accuracy on batch 888 on Training is 30.28683914510686\n",
            "Epoch #3. Accuracy on batch 889 on Training is 30.298455056179776\n",
            "Epoch #3. Accuracy on batch 890 on Training is 30.29601571268238\n",
            "Epoch #3. Accuracy on batch 891 on Training is 30.286575112107624\n",
            "Epoch #3. Accuracy on batch 892 on Training is 30.29115341545353\n",
            "Epoch #3. Accuracy on batch 893 on Training is 30.288730425055927\n",
            "Epoch #3. Accuracy on batch 894 on Training is 30.293296089385475\n",
            "Epoch #3. Accuracy on batch 895 on Training is 30.304827008928573\n",
            "Epoch #3. Accuracy on batch 896 on Training is 30.302396878483837\n",
            "Epoch #3. Accuracy on batch 897 on Training is 30.31389198218263\n",
            "Epoch #3. Accuracy on batch 898 on Training is 30.314933259176865\n",
            "Epoch #3. Accuracy on batch 899 on Training is 30.30902777777778\n",
            "Batch Id 900 is having training loss of 2887.0107421875\n",
            "15.653104782104492\n",
            "Epoch #3. Accuracy on batch 900 on Training is 30.310072142064374\n",
            "Epoch #3. Accuracy on batch 901 on Training is 30.307649667405766\n",
            "Epoch #3. Accuracy on batch 902 on Training is 30.29485049833887\n",
            "Epoch #3. Accuracy on batch 903 on Training is 30.28553650442478\n",
            "Epoch #3. Accuracy on batch 904 on Training is 30.293508287292816\n",
            "Epoch #3. Accuracy on batch 905 on Training is 30.273868653421633\n",
            "Epoch #3. Accuracy on batch 906 on Training is 30.278390297684673\n",
            "Epoch #3. Accuracy on batch 907 on Training is 30.282901982378856\n",
            "Epoch #3. Accuracy on batch 908 on Training is 30.270214521452147\n",
            "Epoch #3. Accuracy on batch 909 on Training is 30.28846153846154\n",
            "Epoch #3. Accuracy on batch 910 on Training is 30.303238199780463\n",
            "Epoch #3. Accuracy on batch 911 on Training is 30.300849780701753\n",
            "Epoch #3. Accuracy on batch 912 on Training is 30.288198247535597\n",
            "Epoch #3. Accuracy on batch 913 on Training is 30.296088621444202\n",
            "Epoch #3. Accuracy on batch 914 on Training is 30.28346994535519\n",
            "Epoch #3. Accuracy on batch 915 on Training is 30.281113537117903\n",
            "Epoch #3. Accuracy on batch 916 on Training is 30.278762268266085\n",
            "Epoch #3. Accuracy on batch 917 on Training is 30.269607843137255\n",
            "Epoch #3. Accuracy on batch 918 on Training is 30.270674646354735\n",
            "Epoch #3. Accuracy on batch 919 on Training is 30.27513586956522\n",
            "Batch Id 920 is having training loss of 2878.127685546875\n",
            "33.69010543823242\n",
            "Epoch #3. Accuracy on batch 920 on Training is 30.276194353963085\n",
            "Epoch #3. Accuracy on batch 921 on Training is 30.27725054229935\n",
            "Epoch #3. Accuracy on batch 922 on Training is 30.281690140845072\n",
            "Epoch #3. Accuracy on batch 923 on Training is 30.275974025974026\n",
            "Epoch #3. Accuracy on batch 924 on Training is 30.260135135135137\n",
            "Epoch #3. Accuracy on batch 925 on Training is 30.267953563714904\n",
            "Epoch #3. Accuracy on batch 926 on Training is 30.27912621359223\n",
            "Epoch #3. Accuracy on batch 927 on Training is 30.280172413793103\n",
            "Epoch #3. Accuracy on batch 928 on Training is 30.27448869752422\n",
            "Epoch #3. Accuracy on batch 929 on Training is 30.262096774193548\n",
            "Epoch #3. Accuracy on batch 930 on Training is 30.25980128893663\n",
            "Epoch #3. Accuracy on batch 931 on Training is 30.267569742489272\n",
            "Epoch #3. Accuracy on batch 932 on Training is 30.265273311897108\n",
            "Epoch #3. Accuracy on batch 933 on Training is 30.262981798715202\n",
            "Epoch #3. Accuracy on batch 934 on Training is 30.25066844919786\n",
            "Epoch #3. Accuracy on batch 935 on Training is 30.248397435897434\n",
            "Epoch #3. Accuracy on batch 936 on Training is 30.249466382070437\n",
            "Epoch #3. Accuracy on batch 937 on Training is 30.247201492537314\n",
            "Epoch #3. Accuracy on batch 938 on Training is 30.248269435569757\n",
            "Epoch #3. Accuracy on batch 939 on Training is 30.252659574468087\n",
            "Batch Id 940 is having training loss of 2860.365966796875\n",
            "22.9461669921875\n",
            "Epoch #3. Accuracy on batch 940 on Training is 30.243756641870352\n",
            "Epoch #3. Accuracy on batch 941 on Training is 30.248142250530787\n",
            "Epoch #3. Accuracy on batch 942 on Training is 30.255832449628844\n",
            "Epoch #3. Accuracy on batch 943 on Training is 30.263506355932204\n",
            "Epoch #3. Accuracy on batch 944 on Training is 30.27777777777778\n",
            "Epoch #3. Accuracy on batch 945 on Training is 30.275502114164905\n",
            "Epoch #3. Accuracy on batch 946 on Training is 30.27653115100317\n",
            "Epoch #3. Accuracy on batch 947 on Training is 30.277558016877638\n",
            "Epoch #3. Accuracy on batch 948 on Training is 30.26541095890411\n",
            "Epoch #3. Accuracy on batch 949 on Training is 30.26644736842105\n",
            "Epoch #3. Accuracy on batch 950 on Training is 30.254337539432175\n",
            "Epoch #3. Accuracy on batch 951 on Training is 30.268513655462186\n",
            "Epoch #3. Accuracy on batch 952 on Training is 30.28266002098636\n",
            "Epoch #3. Accuracy on batch 953 on Training is 30.29677672955975\n",
            "Epoch #3. Accuracy on batch 954 on Training is 30.294502617801047\n",
            "Epoch #3. Accuracy on batch 955 on Training is 30.292233263598327\n",
            "Epoch #3. Accuracy on batch 956 on Training is 30.286703239289444\n",
            "Epoch #3. Accuracy on batch 957 on Training is 30.281184759916492\n",
            "Epoch #3. Accuracy on batch 958 on Training is 30.278936392075078\n",
            "Epoch #3. Accuracy on batch 959 on Training is 30.289713541666668\n",
            "Batch Id 960 is having training loss of 2808.452392578125\n",
            "35.534217834472656\n",
            "Epoch #3. Accuracy on batch 960 on Training is 30.28095733610822\n",
            "Epoch #3. Accuracy on batch 961 on Training is 30.29495841995842\n",
            "Epoch #3. Accuracy on batch 962 on Training is 30.28946002076843\n",
            "Epoch #3. Accuracy on batch 963 on Training is 30.277489626556015\n",
            "Epoch #3. Accuracy on batch 964 on Training is 30.2720207253886\n",
            "Epoch #3. Accuracy on batch 965 on Training is 30.282738095238095\n",
            "Epoch #3. Accuracy on batch 966 on Training is 30.28050672182006\n",
            "Epoch #3. Accuracy on batch 967 on Training is 30.291193181818183\n",
            "Epoch #3. Accuracy on batch 968 on Training is 30.2921826625387\n",
            "Epoch #3. Accuracy on batch 969 on Training is 30.273840206185568\n",
            "Epoch #3. Accuracy on batch 970 on Training is 30.271627188465498\n",
            "Epoch #3. Accuracy on batch 971 on Training is 30.266203703703702\n",
            "Epoch #3. Accuracy on batch 972 on Training is 30.27042651593011\n",
            "Epoch #3. Accuracy on batch 973 on Training is 30.27784907597536\n",
            "Epoch #3. Accuracy on batch 974 on Training is 30.291666666666668\n",
            "Epoch #3. Accuracy on batch 975 on Training is 30.29905225409836\n",
            "Epoch #3. Accuracy on batch 976 on Training is 30.293628454452406\n",
            "Epoch #3. Accuracy on batch 977 on Training is 30.294606339468302\n",
            "Epoch #3. Accuracy on batch 978 on Training is 30.292390194075587\n",
            "Epoch #3. Accuracy on batch 979 on Training is 30.293367346938776\n",
            "Batch Id 980 is having training loss of 2752.7421875\n",
            "24.546356201171875\n",
            "Epoch #3. Accuracy on batch 980 on Training is 30.28797145769623\n",
            "Epoch #3. Accuracy on batch 981 on Training is 30.29849796334012\n",
            "Epoch #3. Accuracy on batch 982 on Training is 30.280391658189217\n",
            "Epoch #3. Accuracy on batch 983 on Training is 30.284552845528456\n",
            "Epoch #3. Accuracy on batch 984 on Training is 30.28236040609137\n",
            "Epoch #3. Accuracy on batch 985 on Training is 30.27700304259635\n",
            "Epoch #3. Accuracy on batch 986 on Training is 30.271656534954406\n",
            "Epoch #3. Accuracy on batch 987 on Training is 30.26632085020243\n",
            "Epoch #3. Accuracy on batch 988 on Training is 30.283114256825076\n",
            "Epoch #3. Accuracy on batch 989 on Training is 30.28409090909091\n",
            "Epoch #3. Accuracy on batch 990 on Training is 30.278758829465186\n",
            "Epoch #3. Accuracy on batch 991 on Training is 30.270287298387096\n",
            "Epoch #3. Accuracy on batch 992 on Training is 30.28386203423968\n",
            "Epoch #3. Accuracy on batch 993 on Training is 30.275402414486923\n",
            "Epoch #3. Accuracy on batch 994 on Training is 30.276381909547737\n",
            "Epoch #3. Accuracy on batch 995 on Training is 30.280496987951807\n",
            "Epoch #3. Accuracy on batch 996 on Training is 30.275200601805416\n",
            "Epoch #3. Accuracy on batch 997 on Training is 30.27304609218437\n",
            "Epoch #3. Accuracy on batch 998 on Training is 30.26776776776777\n",
            "Epoch #3. Accuracy on batch 999 on Training is 30.2625\n",
            "Batch Id 1000 is having training loss of 2780.6142578125\n",
            "9.636832237243652\n",
            "Epoch #3. Accuracy on batch 1000 on Training is 30.275974025974026\n",
            "Epoch #3. Accuracy on batch 1001 on Training is 30.273827345309382\n",
            "Epoch #3. Accuracy on batch 1002 on Training is 30.284147557328016\n",
            "Epoch #3. Accuracy on batch 1003 on Training is 30.2726593625498\n",
            "Epoch #3. Accuracy on batch 1004 on Training is 30.270522388059703\n",
            "Epoch #3. Accuracy on batch 1005 on Training is 30.27770874751491\n",
            "Epoch #3. Accuracy on batch 1006 on Training is 30.27246772591857\n",
            "Epoch #3. Accuracy on batch 1007 on Training is 30.2703373015873\n",
            "Epoch #3. Accuracy on batch 1008 on Training is 30.258919722497524\n",
            "Epoch #3. Accuracy on batch 1009 on Training is 30.235148514851485\n",
            "Epoch #3. Accuracy on batch 1010 on Training is 30.229970326409497\n",
            "Epoch #3. Accuracy on batch 1011 on Training is 30.227890316205535\n",
            "Epoch #3. Accuracy on batch 1012 on Training is 30.21964461994077\n",
            "Epoch #3. Accuracy on batch 1013 on Training is 30.223742603550296\n",
            "Epoch #3. Accuracy on batch 1014 on Training is 30.221674876847292\n",
            "Epoch #3. Accuracy on batch 1015 on Training is 30.22576279527559\n",
            "Epoch #3. Accuracy on batch 1016 on Training is 30.220624385447394\n",
            "Epoch #3. Accuracy on batch 1017 on Training is 30.215496070726914\n",
            "Epoch #3. Accuracy on batch 1018 on Training is 30.21037782139352\n",
            "Epoch #3. Accuracy on batch 1019 on Training is 30.220588235294116\n",
            "Batch Id 1020 is having training loss of 2795.485107421875\n",
            "22.749967575073242\n",
            "Epoch #3. Accuracy on batch 1020 on Training is 30.22771792360431\n",
            "Epoch #3. Accuracy on batch 1021 on Training is 30.225660469667318\n",
            "Epoch #3. Accuracy on batch 1022 on Training is 30.208333333333332\n",
            "Epoch #3. Accuracy on batch 1023 on Training is 30.206298828125\n",
            "Epoch #3. Accuracy on batch 1024 on Training is 30.195121951219512\n",
            "Epoch #3. Accuracy on batch 1025 on Training is 30.183966861598442\n",
            "Epoch #3. Accuracy on batch 1026 on Training is 30.188047711781888\n",
            "Epoch #3. Accuracy on batch 1027 on Training is 30.183000972762645\n",
            "Epoch #3. Accuracy on batch 1028 on Training is 30.17796404275996\n",
            "Epoch #3. Accuracy on batch 1029 on Training is 30.163834951456312\n",
            "Epoch #3. Accuracy on batch 1030 on Training is 30.164888457807955\n",
            "Epoch #3. Accuracy on batch 1031 on Training is 30.153827519379846\n",
            "Epoch #3. Accuracy on batch 1032 on Training is 30.151863504356243\n",
            "Epoch #3. Accuracy on batch 1033 on Training is 30.146881044487426\n",
            "Epoch #3. Accuracy on batch 1034 on Training is 30.14794685990338\n",
            "Epoch #3. Accuracy on batch 1035 on Training is 30.1429777992278\n",
            "Epoch #3. Accuracy on batch 1036 on Training is 30.125964320154292\n",
            "Epoch #3. Accuracy on batch 1037 on Training is 30.139089595375722\n",
            "Epoch #3. Accuracy on batch 1038 on Training is 30.143166506256016\n",
            "Epoch #3. Accuracy on batch 1039 on Training is 30.147235576923077\n",
            "Batch Id 1040 is having training loss of 2799.788818359375\n",
            "17.27968978881836\n",
            "Epoch #3. Accuracy on batch 1040 on Training is 30.160302593659942\n",
            "Epoch #3. Accuracy on batch 1041 on Training is 30.15834932821497\n",
            "Epoch #3. Accuracy on batch 1042 on Training is 30.150407478427613\n",
            "Epoch #3. Accuracy on batch 1043 on Training is 30.154454022988507\n",
            "Epoch #3. Accuracy on batch 1044 on Training is 30.161483253588518\n",
            "Epoch #3. Accuracy on batch 1045 on Training is 30.159536328871894\n",
            "Epoch #3. Accuracy on batch 1046 on Training is 30.163562559694366\n",
            "Epoch #3. Accuracy on batch 1047 on Training is 30.164599236641223\n",
            "Epoch #3. Accuracy on batch 1048 on Training is 30.18052907530982\n",
            "Epoch #3. Accuracy on batch 1049 on Training is 30.19345238095238\n",
            "Epoch #3. Accuracy on batch 1050 on Training is 30.18851094196004\n",
            "Epoch #3. Accuracy on batch 1051 on Training is 30.19546102661597\n",
            "Epoch #3. Accuracy on batch 1052 on Training is 30.202397910731243\n",
            "Epoch #3. Accuracy on batch 1053 on Training is 30.20339184060721\n",
            "Epoch #3. Accuracy on batch 1054 on Training is 30.213270142180093\n",
            "Epoch #3. Accuracy on batch 1055 on Training is 30.211292613636363\n",
            "Epoch #3. Accuracy on batch 1056 on Training is 30.21523178807947\n",
            "Epoch #3. Accuracy on batch 1057 on Training is 30.21030245746692\n",
            "Epoch #3. Accuracy on batch 1058 on Training is 30.211284230406044\n",
            "Epoch #3. Accuracy on batch 1059 on Training is 30.215212264150942\n",
            "Batch Id 1060 is having training loss of 2748.584716796875\n",
            "15.964531898498535\n",
            "Epoch #3. Accuracy on batch 1060 on Training is 30.219132893496703\n",
            "Epoch #3. Accuracy on batch 1061 on Training is 30.23187382297552\n",
            "Epoch #3. Accuracy on batch 1062 on Training is 30.25341015992474\n",
            "Epoch #3. Accuracy on batch 1063 on Training is 30.257283834586467\n",
            "Epoch #3. Accuracy on batch 1064 on Training is 30.252347417840376\n",
            "Epoch #3. Accuracy on batch 1065 on Training is 30.22983114446529\n",
            "Epoch #3. Accuracy on batch 1066 on Training is 30.23078725398313\n",
            "Epoch #3. Accuracy on batch 1067 on Training is 30.23174157303371\n",
            "Epoch #3. Accuracy on batch 1068 on Training is 30.23269410664172\n",
            "Epoch #3. Accuracy on batch 1069 on Training is 30.24532710280374\n",
            "Epoch #3. Accuracy on batch 1070 on Training is 30.25501867413632\n",
            "Epoch #3. Accuracy on batch 1071 on Training is 30.25303171641791\n",
            "Epoch #3. Accuracy on batch 1072 on Training is 30.256873252562908\n",
            "Epoch #3. Accuracy on batch 1073 on Training is 30.263617318435752\n",
            "Epoch #3. Accuracy on batch 1074 on Training is 30.267441860465116\n",
            "Epoch #3. Accuracy on batch 1075 on Training is 30.265450743494423\n",
            "Epoch #3. Accuracy on batch 1076 on Training is 30.2605617455896\n",
            "Epoch #3. Accuracy on batch 1077 on Training is 30.26437847866419\n",
            "Epoch #3. Accuracy on batch 1078 on Training is 30.273980537534754\n",
            "Epoch #3. Accuracy on batch 1079 on Training is 30.27488425925926\n",
            "Batch Id 1080 is having training loss of 2737.101806640625\n",
            "17.748779296875\n",
            "Epoch #3. Accuracy on batch 1080 on Training is 30.267113783533766\n",
            "Epoch #3. Accuracy on batch 1081 on Training is 30.265134011090574\n",
            "Epoch #3. Accuracy on batch 1082 on Training is 30.263157894736842\n",
            "Epoch #3. Accuracy on batch 1083 on Training is 30.255419741697416\n",
            "Epoch #3. Accuracy on batch 1084 on Training is 30.264976958525345\n",
            "Epoch #3. Accuracy on batch 1085 on Training is 30.263006445672193\n",
            "Epoch #3. Accuracy on batch 1086 on Training is 30.26966421343146\n",
            "Epoch #3. Accuracy on batch 1087 on Training is 30.261948529411764\n",
            "Epoch #3. Accuracy on batch 1088 on Training is 30.27720385674931\n",
            "Epoch #3. Accuracy on batch 1089 on Training is 30.289564220183486\n",
            "Epoch #3. Accuracy on batch 1090 on Training is 30.30763061411549\n",
            "Epoch #3. Accuracy on batch 1091 on Training is 30.302770146520146\n",
            "Epoch #3. Accuracy on batch 1092 on Training is 30.289341262580056\n",
            "Epoch #3. Accuracy on batch 1093 on Training is 30.27593692870201\n",
            "Epoch #3. Accuracy on batch 1094 on Training is 30.279680365296805\n",
            "Epoch #3. Accuracy on batch 1095 on Training is 30.274863138686133\n",
            "Epoch #3. Accuracy on batch 1096 on Training is 30.25865998176846\n",
            "Epoch #3. Accuracy on batch 1097 on Training is 30.256716757741348\n",
            "Epoch #3. Accuracy on batch 1098 on Training is 30.257620564149228\n",
            "Epoch #3. Accuracy on batch 1099 on Training is 30.25284090909091\n",
            "Batch Id 1100 is having training loss of 2764.181884765625\n",
            "8.361812591552734\n",
            "Epoch #3. Accuracy on batch 1100 on Training is 30.25374659400545\n",
            "Epoch #3. Accuracy on batch 1101 on Training is 30.2603221415608\n",
            "Epoch #3. Accuracy on batch 1102 on Training is 30.275385312783317\n",
            "Epoch #3. Accuracy on batch 1103 on Training is 30.281929347826086\n",
            "Epoch #3. Accuracy on batch 1104 on Training is 30.282805429864254\n",
            "Epoch #3. Accuracy on batch 1105 on Training is 30.286505424954793\n",
            "Epoch #3. Accuracy on batch 1106 on Training is 30.290198735320686\n",
            "Epoch #3. Accuracy on batch 1107 on Training is 30.288244584837546\n",
            "Epoch #3. Accuracy on batch 1108 on Training is 30.27784039675383\n",
            "Epoch #3. Accuracy on batch 1109 on Training is 30.28153153153153\n",
            "Epoch #3. Accuracy on batch 1110 on Training is 30.28521602160216\n",
            "Epoch #3. Accuracy on batch 1111 on Training is 30.283273381294965\n",
            "Epoch #3. Accuracy on batch 1112 on Training is 30.27571877807727\n",
            "Epoch #3. Accuracy on batch 1113 on Training is 30.25976211849192\n",
            "Epoch #3. Accuracy on batch 1114 on Training is 30.25224215246637\n",
            "Epoch #3. Accuracy on batch 1115 on Training is 30.250336021505376\n",
            "Epoch #3. Accuracy on batch 1116 on Training is 30.254028648164727\n",
            "Epoch #3. Accuracy on batch 1117 on Training is 30.252124329159212\n",
            "Epoch #3. Accuracy on batch 1118 on Training is 30.24743074173369\n",
            "Epoch #3. Accuracy on batch 1119 on Training is 30.242745535714285\n",
            "Batch Id 1120 is having training loss of 2758.005126953125\n",
            "426.15948486328125\n",
            "Epoch #3. Accuracy on batch 1120 on Training is 30.22691793041927\n",
            "Epoch #3. Accuracy on batch 1121 on Training is 30.219474153297682\n",
            "Epoch #3. Accuracy on batch 1122 on Training is 30.214826357969724\n",
            "Epoch #3. Accuracy on batch 1123 on Training is 30.226868327402133\n",
            "Epoch #3. Accuracy on batch 1124 on Training is 30.227777777777778\n",
            "Epoch #3. Accuracy on batch 1125 on Training is 30.223134991119004\n",
            "Epoch #3. Accuracy on batch 1126 on Training is 30.229591836734695\n",
            "Epoch #3. Accuracy on batch 1127 on Training is 30.23049645390071\n",
            "Epoch #3. Accuracy on batch 1128 on Training is 30.231399468556244\n",
            "Epoch #3. Accuracy on batch 1129 on Training is 30.221238938053098\n",
            "Epoch #3. Accuracy on batch 1130 on Training is 30.23320070733864\n",
            "Epoch #3. Accuracy on batch 1131 on Training is 30.25066254416961\n",
            "Epoch #3. Accuracy on batch 1132 on Training is 30.262577228596648\n",
            "Epoch #3. Accuracy on batch 1133 on Training is 30.2717151675485\n",
            "Epoch #3. Accuracy on batch 1134 on Training is 30.269823788546255\n",
            "Epoch #3. Accuracy on batch 1135 on Training is 30.270686619718308\n",
            "Epoch #3. Accuracy on batch 1136 on Training is 30.27429639401935\n",
            "Epoch #3. Accuracy on batch 1137 on Training is 30.269661687170476\n",
            "Epoch #3. Accuracy on batch 1138 on Training is 30.262291483757682\n",
            "Epoch #3. Accuracy on batch 1139 on Training is 30.25767543859649\n",
            "Batch Id 1140 is having training loss of 2714.244873046875\n",
            "19.87566375732422\n",
            "Epoch #3. Accuracy on batch 1140 on Training is 30.26676161262051\n",
            "Epoch #3. Accuracy on batch 1141 on Training is 30.259413309982488\n",
            "Epoch #3. Accuracy on batch 1142 on Training is 30.265748031496063\n",
            "Epoch #3. Accuracy on batch 1143 on Training is 30.277534965034967\n",
            "Epoch #3. Accuracy on batch 1144 on Training is 30.267467248908297\n",
            "Epoch #3. Accuracy on batch 1145 on Training is 30.276505235602095\n",
            "Epoch #3. Accuracy on batch 1146 on Training is 30.28825196163906\n",
            "Epoch #3. Accuracy on batch 1147 on Training is 30.294533972125436\n",
            "Epoch #3. Accuracy on batch 1148 on Training is 30.300805047867712\n",
            "Epoch #3. Accuracy on batch 1149 on Training is 30.29891304347826\n",
            "Epoch #3. Accuracy on batch 1150 on Training is 30.288879235447435\n",
            "Epoch #3. Accuracy on batch 1151 on Training is 30.281575520833332\n",
            "Epoch #3. Accuracy on batch 1152 on Training is 30.298677363399825\n",
            "Epoch #3. Accuracy on batch 1153 on Training is 30.29679376083189\n",
            "Epoch #3. Accuracy on batch 1154 on Training is 30.292207792207794\n",
            "Epoch #3. Accuracy on batch 1155 on Training is 30.287629757785467\n",
            "Epoch #3. Accuracy on batch 1156 on Training is 30.296564390665516\n",
            "Epoch #3. Accuracy on batch 1157 on Training is 30.294689119170986\n",
            "Epoch #3. Accuracy on batch 1158 on Training is 30.290120793787747\n",
            "Epoch #3. Accuracy on batch 1159 on Training is 30.29364224137931\n",
            "Batch Id 1160 is having training loss of 2668.42236328125\n",
            "25.305137634277344\n",
            "Epoch #3. Accuracy on batch 1160 on Training is 30.297157622739018\n",
            "Epoch #3. Accuracy on batch 1161 on Training is 30.289909638554217\n",
            "Epoch #3. Accuracy on batch 1162 on Training is 30.29073516766982\n",
            "Epoch #3. Accuracy on batch 1163 on Training is 30.286189862542955\n",
            "Epoch #3. Accuracy on batch 1164 on Training is 30.300429184549355\n",
            "Epoch #3. Accuracy on batch 1165 on Training is 30.306603773584907\n",
            "Epoch #3. Accuracy on batch 1166 on Training is 30.302056555269925\n",
            "Epoch #3. Accuracy on batch 1167 on Training is 30.305543664383563\n",
            "Epoch #3. Accuracy on batch 1168 on Training is 30.28229255774166\n",
            "Epoch #3. Accuracy on batch 1169 on Training is 30.2857905982906\n",
            "Epoch #3. Accuracy on batch 1170 on Training is 30.297288642186167\n",
            "Epoch #3. Accuracy on batch 1171 on Training is 30.303434300341298\n",
            "Epoch #3. Accuracy on batch 1172 on Training is 30.29358482523444\n",
            "Epoch #3. Accuracy on batch 1173 on Training is 30.302385008517888\n",
            "Epoch #3. Accuracy on batch 1174 on Training is 30.300531914893618\n",
            "Epoch #3. Accuracy on batch 1175 on Training is 30.306653911564627\n",
            "Epoch #3. Accuracy on batch 1176 on Training is 30.29949022939677\n",
            "Epoch #3. Accuracy on batch 1177 on Training is 30.29233870967742\n",
            "Epoch #3. Accuracy on batch 1178 on Training is 30.293150975402884\n",
            "Epoch #3. Accuracy on batch 1179 on Training is 30.286016949152543\n",
            "Batch Id 1180 is having training loss of 2653.028564453125\n",
            "28.666114807128906\n",
            "Epoch #3. Accuracy on batch 1180 on Training is 30.292125317527518\n",
            "Epoch #3. Accuracy on batch 1181 on Training is 30.29029187817259\n",
            "Epoch #3. Accuracy on batch 1182 on Training is 30.28846153846154\n",
            "Epoch #3. Accuracy on batch 1183 on Training is 30.27079814189189\n",
            "Epoch #3. Accuracy on batch 1184 on Training is 30.276898734177216\n",
            "Epoch #3. Accuracy on batch 1185 on Training is 30.261909780775717\n",
            "Epoch #3. Accuracy on batch 1186 on Training is 30.254844144903117\n",
            "Epoch #3. Accuracy on batch 1187 on Training is 30.247790404040405\n",
            "Epoch #3. Accuracy on batch 1188 on Training is 30.24863330529857\n",
            "Epoch #3. Accuracy on batch 1189 on Training is 30.2468487394958\n",
            "Epoch #3. Accuracy on batch 1190 on Training is 30.24769101595298\n",
            "Epoch #3. Accuracy on batch 1191 on Training is 30.243288590604028\n",
            "Epoch #3. Accuracy on batch 1192 on Training is 30.246751886001675\n",
            "Epoch #3. Accuracy on batch 1193 on Training is 30.247592127303182\n",
            "Epoch #3. Accuracy on batch 1194 on Training is 30.248430962343097\n",
            "Epoch #3. Accuracy on batch 1195 on Training is 30.244042642140467\n",
            "Epoch #3. Accuracy on batch 1196 on Training is 30.23705096073517\n",
            "Epoch #3. Accuracy on batch 1197 on Training is 30.230070951585976\n",
            "Epoch #3. Accuracy on batch 1198 on Training is 30.228315262718933\n",
            "Epoch #3. Accuracy on batch 1199 on Training is 30.231770833333332\n",
            "Batch Id 1200 is having training loss of 2670.111328125\n",
            "50.44670104980469\n",
            "Epoch #3. Accuracy on batch 1200 on Training is 30.23001665278934\n",
            "Epoch #3. Accuracy on batch 1201 on Training is 30.230865224625624\n",
            "Epoch #3. Accuracy on batch 1202 on Training is 30.234310058187862\n",
            "Epoch #3. Accuracy on batch 1203 on Training is 30.22996262458472\n",
            "Epoch #3. Accuracy on batch 1204 on Training is 30.235995850622405\n",
            "Epoch #3. Accuracy on batch 1205 on Training is 30.23424543946932\n",
            "Epoch #3. Accuracy on batch 1206 on Training is 30.232497928748966\n",
            "Epoch #3. Accuracy on batch 1207 on Training is 30.246274834437084\n",
            "Epoch #3. Accuracy on batch 1208 on Training is 30.24968982630273\n",
            "Epoch #3. Accuracy on batch 1209 on Training is 30.25826446280992\n",
            "Epoch #3. Accuracy on batch 1210 on Training is 30.259083402146985\n",
            "Epoch #3. Accuracy on batch 1211 on Training is 30.254744224422442\n",
            "Epoch #3. Accuracy on batch 1212 on Training is 30.273598516075847\n",
            "Epoch #3. Accuracy on batch 1213 on Training is 30.26668039538715\n",
            "Epoch #3. Accuracy on batch 1214 on Training is 30.262345679012345\n",
            "Epoch #3. Accuracy on batch 1215 on Training is 30.26058799342105\n",
            "Epoch #3. Accuracy on batch 1216 on Training is 30.251129827444537\n",
            "Epoch #3. Accuracy on batch 1217 on Training is 30.249384236453203\n",
            "Epoch #3. Accuracy on batch 1218 on Training is 30.24764150943396\n",
            "Epoch #3. Accuracy on batch 1219 on Training is 30.258709016393443\n",
            "Batch Id 1220 is having training loss of 2627.07080078125\n",
            "12.420509338378906\n",
            "Epoch #3. Accuracy on batch 1220 on Training is 30.26208026208026\n",
            "Epoch #3. Accuracy on batch 1221 on Training is 30.255216857610474\n",
            "Epoch #3. Accuracy on batch 1222 on Training is 30.25347506132461\n",
            "Epoch #3. Accuracy on batch 1223 on Training is 30.254289215686274\n",
            "Epoch #3. Accuracy on batch 1224 on Training is 30.244897959183675\n",
            "Epoch #3. Accuracy on batch 1225 on Training is 30.240619902120716\n",
            "Epoch #3. Accuracy on batch 1226 on Training is 30.238895680521598\n",
            "Epoch #3. Accuracy on batch 1227 on Training is 30.24735342019544\n",
            "Epoch #3. Accuracy on batch 1228 on Training is 30.253254678600488\n",
            "Epoch #3. Accuracy on batch 1229 on Training is 30.241361788617887\n",
            "Epoch #3. Accuracy on batch 1230 on Training is 30.242181153533714\n",
            "Epoch #3. Accuracy on batch 1231 on Training is 30.240462662337663\n",
            "Epoch #3. Accuracy on batch 1232 on Training is 30.241281427412815\n",
            "Epoch #3. Accuracy on batch 1233 on Training is 30.24463128038898\n",
            "Epoch #3. Accuracy on batch 1234 on Training is 30.237854251012145\n",
            "Epoch #3. Accuracy on batch 1235 on Training is 30.246258090614887\n",
            "Epoch #3. Accuracy on batch 1236 on Training is 30.247069523039613\n",
            "Epoch #3. Accuracy on batch 1237 on Training is 30.230210016155088\n",
            "Epoch #3. Accuracy on batch 1238 on Training is 30.22094430992736\n",
            "Epoch #3. Accuracy on batch 1239 on Training is 30.226814516129032\n",
            "Batch Id 1240 is having training loss of 2589.372314453125\n",
            "27.81671142578125\n",
            "Epoch #3. Accuracy on batch 1240 on Training is 30.2276390008058\n",
            "Epoch #3. Accuracy on batch 1241 on Training is 30.225946054750402\n",
            "Epoch #3. Accuracy on batch 1242 on Training is 30.226769911504423\n",
            "Epoch #3. Accuracy on batch 1243 on Training is 30.227592443729904\n",
            "Epoch #3. Accuracy on batch 1244 on Training is 30.21586345381526\n",
            "Epoch #3. Accuracy on batch 1245 on Training is 30.219201444622794\n",
            "Epoch #3. Accuracy on batch 1246 on Training is 30.220028067361667\n",
            "Epoch #3. Accuracy on batch 1247 on Training is 30.228365384615383\n",
            "Epoch #3. Accuracy on batch 1248 on Training is 30.231685348278624\n",
            "Epoch #3. Accuracy on batch 1249 on Training is 30.2275\n",
            "Epoch #3. Accuracy on batch 1250 on Training is 30.235811350919263\n",
            "Epoch #3. Accuracy on batch 1251 on Training is 30.25658945686901\n",
            "Epoch #3. Accuracy on batch 1252 on Training is 30.254888268156424\n",
            "Epoch #3. Accuracy on batch 1253 on Training is 30.250697767145134\n",
            "Epoch #3. Accuracy on batch 1254 on Training is 30.249003984063744\n",
            "Epoch #3. Accuracy on batch 1255 on Training is 30.249800955414013\n",
            "Epoch #3. Accuracy on batch 1256 on Training is 30.243138424821\n",
            "Epoch #3. Accuracy on batch 1257 on Training is 30.256359300476948\n",
            "Epoch #3. Accuracy on batch 1258 on Training is 30.247220015885624\n",
            "Epoch #3. Accuracy on batch 1259 on Training is 30.238095238095237\n",
            "Batch Id 1260 is having training loss of 2553.48291015625\n",
            "32.45295715332031\n",
            "Epoch #3. Accuracy on batch 1260 on Training is 30.24633227597145\n",
            "Epoch #3. Accuracy on batch 1261 on Training is 30.242175118858952\n",
            "Epoch #3. Accuracy on batch 1262 on Training is 30.23802454473476\n",
            "Epoch #3. Accuracy on batch 1263 on Training is 30.238825158227847\n",
            "Epoch #3. Accuracy on batch 1264 on Training is 30.23715415019763\n",
            "Epoch #3. Accuracy on batch 1265 on Training is 30.23301737756714\n",
            "Epoch #3. Accuracy on batch 1266 on Training is 30.23382004735596\n",
            "Epoch #3. Accuracy on batch 1267 on Training is 30.2346214511041\n",
            "Epoch #3. Accuracy on batch 1268 on Training is 30.22557131599685\n",
            "Epoch #3. Accuracy on batch 1269 on Training is 30.221456692913385\n",
            "Epoch #3. Accuracy on batch 1270 on Training is 30.224724626278523\n",
            "Epoch #3. Accuracy on batch 1271 on Training is 30.22307389937107\n",
            "Epoch #3. Accuracy on batch 1272 on Training is 30.221425765907306\n",
            "Epoch #3. Accuracy on batch 1273 on Training is 30.21978021978022\n",
            "Epoch #3. Accuracy on batch 1274 on Training is 30.220588235294116\n",
            "Epoch #3. Accuracy on batch 1275 on Training is 30.19935344827586\n",
            "Epoch #3. Accuracy on batch 1276 on Training is 30.19283476898982\n",
            "Epoch #3. Accuracy on batch 1277 on Training is 30.191216744913927\n",
            "Epoch #3. Accuracy on batch 1278 on Training is 30.184714620797497\n",
            "Epoch #3. Accuracy on batch 1279 on Training is 30.18798828125\n",
            "Batch Id 1280 is having training loss of 2559.280029296875\n",
            "30.461002349853516\n",
            "Epoch #3. Accuracy on batch 1280 on Training is 30.183938329430134\n",
            "Epoch #3. Accuracy on batch 1281 on Training is 30.18720748829953\n",
            "Epoch #3. Accuracy on batch 1282 on Training is 30.195342946219796\n",
            "Epoch #3. Accuracy on batch 1283 on Training is 30.201031931464176\n",
            "Epoch #3. Accuracy on batch 1284 on Training is 30.209143968871594\n",
            "Epoch #3. Accuracy on batch 1285 on Training is 30.202663297045103\n",
            "Epoch #3. Accuracy on batch 1286 on Training is 30.193764568764568\n",
            "Epoch #3. Accuracy on batch 1287 on Training is 30.19943711180124\n",
            "Epoch #3. Accuracy on batch 1288 on Training is 30.207525213343676\n",
            "Epoch #3. Accuracy on batch 1289 on Training is 30.213178294573645\n",
            "Epoch #3. Accuracy on batch 1290 on Training is 30.213981409759874\n",
            "Epoch #3. Accuracy on batch 1291 on Training is 30.205108359133128\n",
            "Epoch #3. Accuracy on batch 1292 on Training is 30.205916473317867\n",
            "Epoch #3. Accuracy on batch 1293 on Training is 30.206723338485318\n",
            "Epoch #3. Accuracy on batch 1294 on Training is 30.20511583011583\n",
            "Epoch #3. Accuracy on batch 1295 on Training is 30.21315586419753\n",
            "Epoch #3. Accuracy on batch 1296 on Training is 30.223592906707786\n",
            "Epoch #3. Accuracy on batch 1297 on Training is 30.22679121725732\n",
            "Epoch #3. Accuracy on batch 1298 on Training is 30.225173210161664\n",
            "Epoch #3. Accuracy on batch 1299 on Training is 30.23076923076923\n",
            "Batch Id 1300 is having training loss of 2608.503173828125\n",
            "18.613454818725586\n",
            "Epoch #3. Accuracy on batch 1300 on Training is 30.22915065334358\n",
            "Epoch #3. Accuracy on batch 1301 on Training is 30.232334869431643\n",
            "Epoch #3. Accuracy on batch 1302 on Training is 30.24031082118189\n",
            "Epoch #3. Accuracy on batch 1303 on Training is 30.23629217791411\n",
            "Epoch #3. Accuracy on batch 1304 on Training is 30.24185823754789\n",
            "Epoch #3. Accuracy on batch 1305 on Training is 30.233058958652375\n",
            "Epoch #3. Accuracy on batch 1306 on Training is 30.23383703136955\n",
            "Epoch #3. Accuracy on batch 1307 on Training is 30.237003058103976\n",
            "Epoch #3. Accuracy on batch 1308 on Training is 30.230614973262032\n",
            "Epoch #3. Accuracy on batch 1309 on Training is 30.24570610687023\n",
            "Epoch #3. Accuracy on batch 1310 on Training is 30.23693745232647\n",
            "Epoch #3. Accuracy on batch 1311 on Training is 30.230564024390244\n",
            "Epoch #3. Accuracy on batch 1312 on Training is 30.228960396039604\n",
            "Epoch #3. Accuracy on batch 1313 on Training is 30.232115677321158\n",
            "Epoch #3. Accuracy on batch 1314 on Training is 30.232889733840302\n",
            "Epoch #3. Accuracy on batch 1315 on Training is 30.228913373860184\n",
            "Epoch #3. Accuracy on batch 1316 on Training is 30.229688686408505\n",
            "Epoch #3. Accuracy on batch 1317 on Training is 30.235204855842184\n",
            "Epoch #3. Accuracy on batch 1318 on Training is 30.221758908263837\n",
            "Epoch #3. Accuracy on batch 1319 on Training is 30.220170454545453\n",
            "Batch Id 1320 is having training loss of 2572.683349609375\n",
            "15.588536262512207\n",
            "Epoch #3. Accuracy on batch 1320 on Training is 30.2304125662377\n",
            "Epoch #3. Accuracy on batch 1321 on Training is 30.228819969742815\n",
            "Epoch #3. Accuracy on batch 1322 on Training is 30.22722978080121\n",
            "Epoch #3. Accuracy on batch 1323 on Training is 30.23036253776435\n",
            "Epoch #3. Accuracy on batch 1324 on Training is 30.235849056603772\n",
            "Epoch #3. Accuracy on batch 1325 on Training is 30.248397435897434\n",
            "Epoch #3. Accuracy on batch 1326 on Training is 30.24679728711379\n",
            "Epoch #3. Accuracy on batch 1327 on Training is 30.249905873493976\n",
            "Epoch #3. Accuracy on batch 1328 on Training is 30.245955605718585\n",
            "Epoch #3. Accuracy on batch 1329 on Training is 30.24671052631579\n",
            "Epoch #3. Accuracy on batch 1330 on Training is 30.240420736288506\n",
            "Epoch #3. Accuracy on batch 1331 on Training is 30.24117867867868\n",
            "Epoch #3. Accuracy on batch 1332 on Training is 30.239591147786946\n",
            "Epoch #3. Accuracy on batch 1333 on Training is 30.230978260869566\n",
            "Epoch #3. Accuracy on batch 1334 on Training is 30.236423220973784\n",
            "Epoch #3. Accuracy on batch 1335 on Training is 30.227825598802394\n",
            "Epoch #3. Accuracy on batch 1336 on Training is 30.221578160059835\n",
            "Epoch #3. Accuracy on batch 1337 on Training is 30.210668908819134\n",
            "Epoch #3. Accuracy on batch 1338 on Training is 30.202109783420465\n",
            "Epoch #3. Accuracy on batch 1339 on Training is 30.198227611940297\n",
            "Batch Id 1340 is having training loss of 2613.537841796875\n",
            "29.903573989868164\n",
            "Epoch #3. Accuracy on batch 1340 on Training is 30.208333333333332\n",
            "Epoch #3. Accuracy on batch 1341 on Training is 30.202123695976155\n",
            "Epoch #3. Accuracy on batch 1342 on Training is 30.20290394638868\n",
            "Epoch #3. Accuracy on batch 1343 on Training is 30.19438244047619\n",
            "Epoch #3. Accuracy on batch 1344 on Training is 30.2021375464684\n",
            "Epoch #3. Accuracy on batch 1345 on Training is 30.214524517087668\n",
            "Epoch #3. Accuracy on batch 1346 on Training is 30.215293244246475\n",
            "Epoch #3. Accuracy on batch 1347 on Training is 30.223015578635014\n",
            "Epoch #3. Accuracy on batch 1348 on Training is 30.2191438102298\n",
            "Epoch #3. Accuracy on batch 1349 on Training is 30.21990740740741\n",
            "Epoch #3. Accuracy on batch 1350 on Training is 30.220669874167285\n",
            "Epoch #3. Accuracy on batch 1351 on Training is 30.232988165680474\n",
            "Epoch #3. Accuracy on batch 1352 on Training is 30.22681079083518\n",
            "Epoch #3. Accuracy on batch 1353 on Training is 30.232182422451995\n",
            "Epoch #3. Accuracy on batch 1354 on Training is 30.230627306273064\n",
            "Epoch #3. Accuracy on batch 1355 on Training is 30.22907448377581\n",
            "Epoch #3. Accuracy on batch 1356 on Training is 30.225221075902727\n",
            "Epoch #3. Accuracy on batch 1357 on Training is 30.221373343151694\n",
            "Epoch #3. Accuracy on batch 1358 on Training is 30.222130242825607\n",
            "Epoch #3. Accuracy on batch 1359 on Training is 30.21829044117647\n",
            "Batch Id 1360 is having training loss of 2611.494873046875\n",
            "45187.16796875\n",
            "Epoch #3. Accuracy on batch 1360 on Training is 30.219048493754592\n",
            "Epoch #3. Accuracy on batch 1361 on Training is 30.21751101321586\n",
            "Epoch #3. Accuracy on batch 1362 on Training is 30.225146735143067\n",
            "Epoch #3. Accuracy on batch 1363 on Training is 30.235062316715542\n",
            "Epoch #3. Accuracy on batch 1364 on Training is 30.231227106227106\n",
            "Epoch #3. Accuracy on batch 1365 on Training is 30.229685212298683\n",
            "Epoch #3. Accuracy on batch 1366 on Training is 30.237289685442576\n",
            "Epoch #3. Accuracy on batch 1367 on Training is 30.254020467836256\n",
            "Epoch #3. Accuracy on batch 1368 on Training is 30.245617238860483\n",
            "Epoch #3. Accuracy on batch 1369 on Training is 30.23722627737226\n",
            "Epoch #3. Accuracy on batch 1370 on Training is 30.23568563092633\n",
            "Epoch #3. Accuracy on batch 1371 on Training is 30.2341472303207\n",
            "Epoch #3. Accuracy on batch 1372 on Training is 30.234887108521487\n",
            "Epoch #3. Accuracy on batch 1373 on Training is 30.23335152838428\n",
            "Epoch #3. Accuracy on batch 1374 on Training is 30.222727272727273\n",
            "Epoch #3. Accuracy on batch 1375 on Training is 30.216660610465116\n",
            "Epoch #3. Accuracy on batch 1376 on Training is 30.22194989106754\n",
            "Epoch #3. Accuracy on batch 1377 on Training is 30.227231494920176\n",
            "Epoch #3. Accuracy on batch 1378 on Training is 30.23477157360406\n",
            "Epoch #3. Accuracy on batch 1379 on Training is 30.230978260869566\n",
            "Batch Id 1380 is having training loss of 2584.479248046875\n",
            "10.070343017578125\n",
            "Epoch #3. Accuracy on batch 1380 on Training is 30.233979000724112\n",
            "Epoch #3. Accuracy on batch 1381 on Training is 30.232452966714906\n",
            "Epoch #3. Accuracy on batch 1382 on Training is 30.230929139551698\n",
            "Epoch #3. Accuracy on batch 1383 on Training is 30.22489161849711\n",
            "Epoch #3. Accuracy on batch 1384 on Training is 30.221119133574007\n",
            "Epoch #3. Accuracy on batch 1385 on Training is 30.219606782106784\n",
            "Epoch #3. Accuracy on batch 1386 on Training is 30.222602739726028\n",
            "Epoch #3. Accuracy on batch 1387 on Training is 30.223342939481267\n",
            "Epoch #3. Accuracy on batch 1388 on Training is 30.224082073434126\n",
            "Epoch #3. Accuracy on batch 1389 on Training is 30.22257194244604\n",
            "Epoch #3. Accuracy on batch 1390 on Training is 30.225557153127248\n",
            "Epoch #3. Accuracy on batch 1391 on Training is 30.237517959770116\n",
            "Epoch #3. Accuracy on batch 1392 on Training is 30.22478463747308\n",
            "Epoch #3. Accuracy on batch 1393 on Training is 30.230003586800574\n",
            "Epoch #3. Accuracy on batch 1394 on Training is 30.224014336917563\n",
            "Epoch #3. Accuracy on batch 1395 on Training is 30.22698782234957\n",
            "Epoch #3. Accuracy on batch 1396 on Training is 30.22995705082319\n",
            "Epoch #3. Accuracy on batch 1397 on Training is 30.223980686695278\n",
            "Epoch #3. Accuracy on batch 1398 on Training is 30.222480343102216\n",
            "Epoch #3. Accuracy on batch 1399 on Training is 30.220982142857142\n",
            "Batch Id 1400 is having training loss of 2628.3359375\n",
            "26.992761611938477\n",
            "Epoch #3. Accuracy on batch 1400 on Training is 30.223947180585295\n",
            "Epoch #3. Accuracy on batch 1401 on Training is 30.222450071326676\n",
            "Epoch #3. Accuracy on batch 1402 on Training is 30.218727726300784\n",
            "Epoch #3. Accuracy on batch 1403 on Training is 30.21946225071225\n",
            "Epoch #3. Accuracy on batch 1404 on Training is 30.220195729537366\n",
            "Epoch #3. Accuracy on batch 1405 on Training is 30.220928165007113\n",
            "Epoch #3. Accuracy on batch 1406 on Training is 30.223880597014926\n",
            "Epoch #3. Accuracy on batch 1407 on Training is 30.229048295454547\n",
            "Epoch #3. Accuracy on batch 1408 on Training is 30.231990773598298\n",
            "Epoch #3. Accuracy on batch 1409 on Training is 30.22828014184397\n",
            "Epoch #3. Accuracy on batch 1410 on Training is 30.2245747696669\n",
            "Epoch #3. Accuracy on batch 1411 on Training is 30.22087464589235\n",
            "Epoch #3. Accuracy on batch 1412 on Training is 30.22381457891012\n",
            "Epoch #3. Accuracy on batch 1413 on Training is 30.22233026874116\n",
            "Epoch #3. Accuracy on batch 1414 on Training is 30.21643109540636\n",
            "Epoch #3. Accuracy on batch 1415 on Training is 30.219367937853107\n",
            "Epoch #3. Accuracy on batch 1416 on Training is 30.21788990825688\n",
            "Epoch #3. Accuracy on batch 1417 on Training is 30.225229196050776\n",
            "Epoch #3. Accuracy on batch 1418 on Training is 30.223749119097956\n",
            "Epoch #3. Accuracy on batch 1419 on Training is 30.231073943661972\n",
            "Batch Id 1420 is having training loss of 2621.244140625\n",
            "9.595306396484375\n",
            "Epoch #3. Accuracy on batch 1420 on Training is 30.231790992258972\n",
            "Epoch #3. Accuracy on batch 1421 on Training is 30.239099859353026\n",
            "Epoch #3. Accuracy on batch 1422 on Training is 30.239810260014053\n",
            "Epoch #3. Accuracy on batch 1423 on Training is 30.238325140449437\n",
            "Epoch #3. Accuracy on batch 1424 on Training is 30.24780701754386\n",
            "Epoch #3. Accuracy on batch 1425 on Training is 30.25289270687237\n",
            "Epoch #3. Accuracy on batch 1426 on Training is 30.251401541695866\n",
            "Epoch #3. Accuracy on batch 1427 on Training is 30.258665966386555\n",
            "Epoch #3. Accuracy on batch 1428 on Training is 30.263733379986004\n",
            "Epoch #3. Accuracy on batch 1429 on Training is 30.257867132867133\n",
            "Epoch #3. Accuracy on batch 1430 on Training is 30.262928022361983\n",
            "Epoch #3. Accuracy on batch 1431 on Training is 30.257070530726256\n",
            "Epoch #3. Accuracy on batch 1432 on Training is 30.24904047452896\n",
            "Epoch #3. Accuracy on batch 1433 on Training is 30.254096931659692\n",
            "Epoch #3. Accuracy on batch 1434 on Training is 30.248257839721255\n",
            "Epoch #3. Accuracy on batch 1435 on Training is 30.246779247910865\n",
            "Epoch #3. Accuracy on batch 1436 on Training is 30.245302713987474\n",
            "Epoch #3. Accuracy on batch 1437 on Training is 30.235135605006953\n",
            "Epoch #3. Accuracy on batch 1438 on Training is 30.233669214732455\n",
            "Epoch #3. Accuracy on batch 1439 on Training is 30.234375\n",
            "Batch Id 1440 is having training loss of 2591.09033203125\n",
            "13.343109130859375\n",
            "Epoch #3. Accuracy on batch 1440 on Training is 30.230742539902845\n",
            "Epoch #3. Accuracy on batch 1441 on Training is 30.231449375866852\n",
            "Epoch #3. Accuracy on batch 1442 on Training is 30.238652113652115\n",
            "Epoch #3. Accuracy on batch 1443 on Training is 30.23718836565097\n",
            "Epoch #3. Accuracy on batch 1444 on Training is 30.2378892733564\n",
            "Epoch #3. Accuracy on batch 1445 on Training is 30.240750345781468\n",
            "Epoch #3. Accuracy on batch 1446 on Training is 30.250086385625433\n",
            "Epoch #3. Accuracy on batch 1447 on Training is 30.248618784530386\n",
            "Epoch #3. Accuracy on batch 1448 on Training is 30.238526570048307\n",
            "Epoch #3. Accuracy on batch 1449 on Training is 30.24353448275862\n",
            "Epoch #3. Accuracy on batch 1450 on Training is 30.23561337008959\n",
            "Epoch #3. Accuracy on batch 1451 on Training is 30.236311983471076\n",
            "Epoch #3. Accuracy on batch 1452 on Training is 30.230557467309016\n",
            "Epoch #3. Accuracy on batch 1453 on Training is 30.231258596973866\n",
            "Epoch #3. Accuracy on batch 1454 on Training is 30.234106529209622\n",
            "Epoch #3. Accuracy on batch 1455 on Training is 30.224072802197803\n",
            "Epoch #3. Accuracy on batch 1456 on Training is 30.220487302676734\n",
            "Epoch #3. Accuracy on batch 1457 on Training is 30.219050068587105\n",
            "Epoch #3. Accuracy on batch 1458 on Training is 30.217614804660727\n",
            "Epoch #3. Accuracy on batch 1459 on Training is 30.216181506849313\n",
            "Batch Id 1460 is having training loss of 2603.96484375\n",
            "43.404048919677734\n",
            "Epoch #3. Accuracy on batch 1460 on Training is 30.21688911704312\n",
            "Epoch #3. Accuracy on batch 1461 on Training is 30.213320793433653\n",
            "Epoch #3. Accuracy on batch 1462 on Training is 30.211893369788108\n",
            "Epoch #3. Accuracy on batch 1463 on Training is 30.216871584699454\n",
            "Epoch #3. Accuracy on batch 1464 on Training is 30.215443686006825\n",
            "Epoch #3. Accuracy on batch 1465 on Training is 30.222544338335606\n",
            "Epoch #3. Accuracy on batch 1466 on Training is 30.22750511247444\n",
            "Epoch #3. Accuracy on batch 1467 on Training is 30.23884536784741\n",
            "Epoch #3. Accuracy on batch 1468 on Training is 30.237406398910824\n",
            "Epoch #3. Accuracy on batch 1469 on Training is 30.244472789115648\n",
            "Epoch #3. Accuracy on batch 1470 on Training is 30.245156356220257\n",
            "Epoch #3. Accuracy on batch 1471 on Training is 30.24583899456522\n",
            "Epoch #3. Accuracy on batch 1472 on Training is 30.25500678886626\n",
            "Epoch #3. Accuracy on batch 1473 on Training is 30.251441655359567\n",
            "Epoch #3. Accuracy on batch 1474 on Training is 30.25\n",
            "Epoch #3. Accuracy on batch 1475 on Training is 30.237974254742547\n",
            "Epoch #3. Accuracy on batch 1476 on Training is 30.23865944482058\n",
            "Epoch #3. Accuracy on batch 1477 on Training is 30.24145805142084\n",
            "Epoch #3. Accuracy on batch 1478 on Training is 30.23368830290737\n",
            "Epoch #3. Accuracy on batch 1479 on Training is 30.232263513513512\n",
            "Batch Id 1480 is having training loss of 2569.6083984375\n",
            "35.394073486328125\n",
            "Epoch #3. Accuracy on batch 1480 on Training is 30.23084064821067\n",
            "Epoch #3. Accuracy on batch 1481 on Training is 30.229419703103915\n",
            "Epoch #3. Accuracy on batch 1482 on Training is 30.23010788941335\n",
            "Epoch #3. Accuracy on batch 1483 on Training is 30.228689353099732\n",
            "Epoch #3. Accuracy on batch 1484 on Training is 30.214646464646464\n",
            "Epoch #3. Accuracy on batch 1485 on Training is 30.215343203230148\n",
            "Epoch #3. Accuracy on batch 1486 on Training is 30.218140551445863\n",
            "Epoch #3. Accuracy on batch 1487 on Training is 30.227234543010752\n",
            "Epoch #3. Accuracy on batch 1488 on Training is 30.225822699798524\n",
            "Epoch #3. Accuracy on batch 1489 on Training is 30.22231543624161\n",
            "Epoch #3. Accuracy on batch 1490 on Training is 30.21671696847753\n",
            "Epoch #3. Accuracy on batch 1491 on Training is 30.219504021447722\n",
            "Epoch #3. Accuracy on batch 1492 on Training is 30.213914936369726\n",
            "Epoch #3. Accuracy on batch 1493 on Training is 30.21251673360107\n",
            "Epoch #3. Accuracy on batch 1494 on Training is 30.21948160535117\n",
            "Epoch #3. Accuracy on batch 1495 on Training is 30.234792780748663\n",
            "Epoch #3. Accuracy on batch 1496 on Training is 30.24173346693387\n",
            "Epoch #3. Accuracy on batch 1497 on Training is 30.238234312416555\n",
            "Epoch #3. Accuracy on batch 1498 on Training is 30.24724816544363\n",
            "Epoch #3. Accuracy on batch 1499 on Training is 30.254166666666666\n",
            "Batch Id 1500 is having training loss of 2587.635986328125\n",
            "14039.5732421875\n",
            "Epoch #3. Accuracy on batch 1500 on Training is 30.24442038640906\n",
            "Epoch #3. Accuracy on batch 1501 on Training is 30.251331557922768\n",
            "Epoch #3. Accuracy on batch 1502 on Training is 30.2478376580173\n",
            "Epoch #3. Accuracy on batch 1503 on Training is 30.265126329787233\n",
            "Epoch #3. Accuracy on batch 1504 on Training is 30.26578073089701\n",
            "Epoch #3. Accuracy on batch 1505 on Training is 30.278884462151396\n",
            "Epoch #3. Accuracy on batch 1506 on Training is 30.27330789648308\n",
            "Epoch #3. Accuracy on batch 1507 on Training is 30.273955570291776\n",
            "Epoch #3. Accuracy on batch 1508 on Training is 30.27874420145792\n",
            "Epoch #3. Accuracy on batch 1509 on Training is 30.279387417218544\n",
            "Epoch #3. Accuracy on batch 1510 on Training is 30.269688947716745\n",
            "Epoch #3. Accuracy on batch 1511 on Training is 30.25586970899471\n",
            "Epoch #3. Accuracy on batch 1512 on Training is 30.26272306675479\n",
            "Epoch #3. Accuracy on batch 1513 on Training is 30.26750330250991\n",
            "Epoch #3. Accuracy on batch 1514 on Training is 30.28052805280528\n",
            "Epoch #3. Accuracy on batch 1515 on Training is 30.279106200527703\n",
            "Epoch #3. Accuracy on batch 1516 on Training is 30.28592617007251\n",
            "Epoch #3. Accuracy on batch 1517 on Training is 30.284502635046113\n",
            "Epoch #3. Accuracy on batch 1518 on Training is 30.285138248847925\n",
            "Epoch #3. Accuracy on batch 1519 on Training is 30.28782894736842\n",
            "Batch Id 1520 is having training loss of 2612.409423828125\n",
            "88.6495132446289\n",
            "Epoch #3. Accuracy on batch 1520 on Training is 30.284352399737013\n",
            "Epoch #3. Accuracy on batch 1521 on Training is 30.28498685939553\n",
            "Epoch #3. Accuracy on batch 1522 on Training is 30.27946487196323\n",
            "Epoch #3. Accuracy on batch 1523 on Training is 30.288303805774277\n",
            "Epoch #3. Accuracy on batch 1524 on Training is 30.28073770491803\n",
            "Epoch #3. Accuracy on batch 1525 on Training is 30.28137287024902\n",
            "Epoch #3. Accuracy on batch 1526 on Training is 30.27791421087099\n",
            "Epoch #3. Accuracy on batch 1527 on Training is 30.27446007853403\n",
            "Epoch #3. Accuracy on batch 1528 on Training is 30.277141922825376\n",
            "Epoch #3. Accuracy on batch 1529 on Training is 30.27777777777778\n",
            "Epoch #3. Accuracy on batch 1530 on Training is 30.278412802090138\n",
            "Epoch #3. Accuracy on batch 1531 on Training is 30.285166449086162\n",
            "Epoch #3. Accuracy on batch 1532 on Training is 30.298026744944554\n",
            "Epoch #3. Accuracy on batch 1533 on Training is 30.29864732724902\n",
            "Epoch #3. Accuracy on batch 1534 on Training is 30.295195439739413\n",
            "Epoch #3. Accuracy on batch 1535 on Training is 30.299886067708332\n",
            "Epoch #3. Accuracy on batch 1536 on Training is 30.302537410540012\n",
            "Epoch #3. Accuracy on batch 1537 on Training is 30.299089726918076\n",
            "Epoch #3. Accuracy on batch 1538 on Training is 30.295646523716698\n",
            "Epoch #3. Accuracy on batch 1539 on Training is 30.290178571428573\n",
            "Batch Id 1540 is having training loss of 2578.964599609375\n",
            "22.586294174194336\n",
            "Epoch #3. Accuracy on batch 1540 on Training is 30.28877352368592\n",
            "Epoch #3. Accuracy on batch 1541 on Training is 30.283317120622566\n",
            "Epoch #3. Accuracy on batch 1542 on Training is 30.28596889176928\n",
            "Epoch #3. Accuracy on batch 1543 on Training is 30.286593264248705\n",
            "Epoch #3. Accuracy on batch 1544 on Training is 30.283171521035598\n",
            "Epoch #3. Accuracy on batch 1545 on Training is 30.283796895213452\n",
            "Epoch #3. Accuracy on batch 1546 on Training is 30.28038138332256\n",
            "Epoch #3. Accuracy on batch 1547 on Training is 30.283026485788113\n",
            "Epoch #3. Accuracy on batch 1548 on Training is 30.283650742414462\n",
            "Epoch #3. Accuracy on batch 1549 on Training is 30.29032258064516\n",
            "Epoch #3. Accuracy on batch 1550 on Training is 30.288926499032883\n",
            "Epoch #3. Accuracy on batch 1551 on Training is 30.299613402061855\n",
            "Epoch #3. Accuracy on batch 1552 on Training is 30.298213135866067\n",
            "Epoch #3. Accuracy on batch 1553 on Training is 30.30083655083655\n",
            "Epoch #3. Accuracy on batch 1554 on Training is 30.305466237942124\n",
            "Epoch #3. Accuracy on batch 1555 on Training is 30.322140102827763\n",
            "Epoch #3. Accuracy on batch 1556 on Training is 30.316714836223507\n",
            "Epoch #3. Accuracy on batch 1557 on Training is 30.317313863928113\n",
            "Epoch #3. Accuracy on batch 1558 on Training is 30.307889672867223\n",
            "Epoch #3. Accuracy on batch 1559 on Training is 30.306490384615383\n",
            "Batch Id 1560 is having training loss of 2601.13232421875\n",
            "35.58454132080078\n",
            "Epoch #3. Accuracy on batch 1560 on Training is 30.31109865470852\n",
            "Epoch #3. Accuracy on batch 1561 on Training is 30.311699743918055\n",
            "Epoch #3. Accuracy on batch 1562 on Training is 30.308301343570058\n",
            "Epoch #3. Accuracy on batch 1563 on Training is 30.300911125319693\n",
            "Epoch #3. Accuracy on batch 1564 on Training is 30.303514376996805\n",
            "Epoch #3. Accuracy on batch 1565 on Training is 30.298132183908045\n",
            "Epoch #3. Accuracy on batch 1566 on Training is 30.302728142948308\n",
            "Epoch #3. Accuracy on batch 1567 on Training is 30.303332270408163\n",
            "Epoch #3. Accuracy on batch 1568 on Training is 30.305927342256215\n",
            "Epoch #3. Accuracy on batch 1569 on Training is 30.298566878980893\n",
            "Epoch #3. Accuracy on batch 1570 on Training is 30.301161680458307\n",
            "Epoch #3. Accuracy on batch 1571 on Training is 30.297789440203562\n",
            "Epoch #3. Accuracy on batch 1572 on Training is 30.300381436745074\n",
            "Epoch #3. Accuracy on batch 1573 on Training is 30.300984752223634\n",
            "Epoch #3. Accuracy on batch 1574 on Training is 30.297619047619047\n",
            "Epoch #3. Accuracy on batch 1575 on Training is 30.28632614213198\n",
            "Epoch #3. Accuracy on batch 1576 on Training is 30.292882054533926\n",
            "Epoch #3. Accuracy on batch 1577 on Training is 30.303390367553867\n",
            "Epoch #3. Accuracy on batch 1578 on Training is 30.309927169094365\n",
            "Epoch #3. Accuracy on batch 1579 on Training is 30.314477848101266\n",
            "Batch Id 1580 is having training loss of 2585.76513671875\n",
            "23194.1640625\n",
            "Epoch #3. Accuracy on batch 1580 on Training is 30.305186590765338\n",
            "Epoch #3. Accuracy on batch 1581 on Training is 30.30183312262958\n",
            "Epoch #3. Accuracy on batch 1582 on Training is 30.304406190777005\n",
            "Epoch #3. Accuracy on batch 1583 on Training is 30.29513888888889\n",
            "Epoch #3. Accuracy on batch 1584 on Training is 30.289826498422713\n",
            "Epoch #3. Accuracy on batch 1585 on Training is 30.282550441361916\n",
            "Epoch #3. Accuracy on batch 1586 on Training is 30.27725267800882\n",
            "Epoch #3. Accuracy on batch 1587 on Training is 30.27589735516373\n",
            "Epoch #3. Accuracy on batch 1588 on Training is 30.280443675267463\n",
            "Epoch #3. Accuracy on batch 1589 on Training is 30.281053459119498\n",
            "Epoch #3. Accuracy on batch 1590 on Training is 30.275769956002513\n",
            "Epoch #3. Accuracy on batch 1591 on Training is 30.274418969849247\n",
            "Epoch #3. Accuracy on batch 1592 on Training is 30.27110797237916\n",
            "Epoch #3. Accuracy on batch 1593 on Training is 30.269761606022584\n",
            "Epoch #3. Accuracy on batch 1594 on Training is 30.2782131661442\n",
            "Epoch #3. Accuracy on batch 1595 on Training is 30.269031954887218\n",
            "Epoch #3. Accuracy on batch 1596 on Training is 30.277473387601752\n",
            "Epoch #3. Accuracy on batch 1597 on Training is 30.27808197747184\n",
            "Epoch #3. Accuracy on batch 1598 on Training is 30.28846153846154\n",
            "Epoch #3. Accuracy on batch 1599 on Training is 30.287109375\n",
            "Batch Id 1600 is having training loss of 2593.597900390625\n",
            "23.65406608581543\n",
            "Epoch #3. Accuracy on batch 1600 on Training is 30.28575890068707\n",
            "Epoch #3. Accuracy on batch 1601 on Training is 30.282459425717853\n",
            "Epoch #3. Accuracy on batch 1602 on Training is 30.281113537117903\n",
            "Epoch #3. Accuracy on batch 1603 on Training is 30.27587281795511\n",
            "Epoch #3. Accuracy on batch 1604 on Training is 30.264797507788163\n",
            "Epoch #3. Accuracy on batch 1605 on Training is 30.263465130759652\n",
            "Epoch #3. Accuracy on batch 1606 on Training is 30.271857498444305\n",
            "Epoch #3. Accuracy on batch 1607 on Training is 30.2724657960199\n",
            "Epoch #3. Accuracy on batch 1608 on Training is 30.26918893722809\n",
            "Epoch #3. Accuracy on batch 1609 on Training is 30.258152173913043\n",
            "Epoch #3. Accuracy on batch 1610 on Training is 30.245189323401615\n",
            "Epoch #3. Accuracy on batch 1611 on Training is 30.241935483870968\n",
            "Epoch #3. Accuracy on batch 1612 on Training is 30.25224736515809\n",
            "Epoch #3. Accuracy on batch 1613 on Training is 30.248993184634447\n",
            "Epoch #3. Accuracy on batch 1614 on Training is 30.2515479876161\n",
            "Epoch #3. Accuracy on batch 1615 on Training is 30.246364480198018\n",
            "Epoch #3. Accuracy on batch 1616 on Training is 30.243119975262832\n",
            "Epoch #3. Accuracy on batch 1617 on Training is 30.236016687268233\n",
            "Epoch #3. Accuracy on batch 1618 on Training is 30.24050339715874\n",
            "Epoch #3. Accuracy on batch 1619 on Training is 30.23726851851852\n",
            "Batch Id 1620 is having training loss of 2562.21875\n",
            "37.8133430480957\n",
            "Epoch #3. Accuracy on batch 1620 on Training is 30.241748920419493\n",
            "Epoch #3. Accuracy on batch 1621 on Training is 30.244297163995068\n",
            "Epoch #3. Accuracy on batch 1622 on Training is 30.241065927295132\n",
            "Epoch #3. Accuracy on batch 1623 on Training is 30.24361145320197\n",
            "Epoch #3. Accuracy on batch 1624 on Training is 30.23076923076923\n",
            "Epoch #3. Accuracy on batch 1625 on Training is 30.231396063960638\n",
            "Epoch #3. Accuracy on batch 1626 on Training is 30.22818070067609\n",
            "Epoch #3. Accuracy on batch 1627 on Training is 30.23072788697789\n",
            "Epoch #3. Accuracy on batch 1628 on Training is 30.227516881522405\n",
            "Epoch #3. Accuracy on batch 1629 on Training is 30.22239263803681\n",
            "Epoch #3. Accuracy on batch 1630 on Training is 30.224938687921522\n",
            "Epoch #3. Accuracy on batch 1631 on Training is 30.233226102941178\n",
            "Epoch #3. Accuracy on batch 1632 on Training is 30.233848744641765\n",
            "Epoch #3. Accuracy on batch 1633 on Training is 30.232558139534884\n",
            "Epoch #3. Accuracy on batch 1634 on Training is 30.229357798165136\n",
            "Epoch #3. Accuracy on batch 1635 on Training is 30.237622249388753\n",
            "Epoch #3. Accuracy on batch 1636 on Training is 30.24205864386072\n",
            "Epoch #3. Accuracy on batch 1637 on Training is 30.238858363858363\n",
            "Epoch #3. Accuracy on batch 1638 on Training is 30.243288590604028\n",
            "Epoch #3. Accuracy on batch 1639 on Training is 30.241996951219512\n",
            "Batch Id 1640 is having training loss of 2538.7841796875\n",
            "751.2510375976562\n",
            "Epoch #3. Accuracy on batch 1640 on Training is 30.238802559414992\n",
            "Epoch #3. Accuracy on batch 1641 on Training is 30.233708891595615\n",
            "Epoch #3. Accuracy on batch 1642 on Training is 30.23813146682897\n",
            "Epoch #3. Accuracy on batch 1643 on Training is 30.233044403892944\n",
            "Epoch #3. Accuracy on batch 1644 on Training is 30.243161094224924\n",
            "Epoch #3. Accuracy on batch 1645 on Training is 30.245671324422844\n",
            "Epoch #3. Accuracy on batch 1646 on Training is 30.244383727990286\n",
            "Epoch #3. Accuracy on batch 1647 on Training is 30.243097694174757\n",
            "Epoch #3. Accuracy on batch 1648 on Training is 30.251288659793815\n",
            "Epoch #3. Accuracy on batch 1649 on Training is 30.244318181818183\n",
            "Epoch #3. Accuracy on batch 1650 on Training is 30.243034524530586\n",
            "Epoch #3. Accuracy on batch 1651 on Training is 30.237969128329297\n",
            "Epoch #3. Accuracy on batch 1652 on Training is 30.238581367211133\n",
            "Epoch #3. Accuracy on batch 1653 on Training is 30.235414147521162\n",
            "Epoch #3. Accuracy on batch 1654 on Training is 30.241691842900302\n",
            "Epoch #3. Accuracy on batch 1655 on Training is 30.244187801932366\n",
            "Epoch #3. Accuracy on batch 1656 on Training is 30.248566686783345\n",
            "Epoch #3. Accuracy on batch 1657 on Training is 30.25105548854041\n",
            "Epoch #3. Accuracy on batch 1658 on Training is 30.251657625075346\n",
            "Epoch #3. Accuracy on batch 1659 on Training is 30.24661144578313\n",
            "Batch Id 1660 is having training loss of 2516.905029296875\n",
            "12.281505584716797\n",
            "Epoch #3. Accuracy on batch 1660 on Training is 30.249096929560505\n",
            "Epoch #3. Accuracy on batch 1661 on Training is 30.255339951865224\n",
            "Epoch #3. Accuracy on batch 1662 on Training is 30.261575466025256\n",
            "Epoch #3. Accuracy on batch 1663 on Training is 30.25841346153846\n",
            "Epoch #3. Accuracy on batch 1664 on Training is 30.2515015015015\n",
            "Epoch #3. Accuracy on batch 1665 on Training is 30.257728091236494\n",
            "Epoch #3. Accuracy on batch 1666 on Training is 30.25644871025795\n",
            "Epoch #3. Accuracy on batch 1667 on Training is 30.258917865707435\n",
            "Epoch #3. Accuracy on batch 1668 on Training is 30.263256440982623\n",
            "Epoch #3. Accuracy on batch 1669 on Training is 30.26384730538922\n",
            "Epoch #3. Accuracy on batch 1670 on Training is 30.256956912028727\n",
            "Epoch #3. Accuracy on batch 1671 on Training is 30.251943779904305\n",
            "Epoch #3. Accuracy on batch 1672 on Training is 30.2506724447101\n",
            "Epoch #3. Accuracy on batch 1673 on Training is 30.24006869772999\n",
            "Epoch #3. Accuracy on batch 1674 on Training is 30.25\n",
            "Epoch #3. Accuracy on batch 1675 on Training is 30.250596658711217\n",
            "Epoch #3. Accuracy on batch 1676 on Training is 30.245602265951103\n",
            "Epoch #3. Accuracy on batch 1677 on Training is 30.242476162097734\n",
            "Epoch #3. Accuracy on batch 1678 on Training is 30.254243597379393\n",
            "Epoch #3. Accuracy on batch 1679 on Training is 30.25297619047619\n",
            "Batch Id 1680 is having training loss of 2506.50439453125\n",
            "19.053895950317383\n",
            "Epoch #3. Accuracy on batch 1680 on Training is 30.253569303985724\n",
            "Epoch #3. Accuracy on batch 1681 on Training is 30.254161712247324\n",
            "Epoch #3. Accuracy on batch 1682 on Training is 30.256610219845513\n",
            "Epoch #3. Accuracy on batch 1683 on Training is 30.2479216152019\n",
            "Epoch #3. Accuracy on batch 1684 on Training is 30.244807121661722\n",
            "Epoch #3. Accuracy on batch 1685 on Training is 30.249110320284696\n",
            "Epoch #3. Accuracy on batch 1686 on Training is 30.255260818020155\n",
            "Epoch #3. Accuracy on batch 1687 on Training is 30.26510663507109\n",
            "Epoch #3. Accuracy on batch 1688 on Training is 30.267539964476022\n",
            "Epoch #3. Accuracy on batch 1689 on Training is 30.26812130177515\n",
            "Epoch #3. Accuracy on batch 1690 on Training is 30.2705499704317\n",
            "Epoch #3. Accuracy on batch 1691 on Training is 30.26558806146572\n",
            "Epoch #3. Accuracy on batch 1692 on Training is 30.266169521559362\n",
            "Epoch #3. Accuracy on batch 1693 on Training is 30.27043978748524\n",
            "Epoch #3. Accuracy on batch 1694 on Training is 30.26364306784661\n",
            "Epoch #3. Accuracy on batch 1695 on Training is 30.269752358490567\n",
            "Epoch #3. Accuracy on batch 1696 on Training is 30.274012964054215\n",
            "Epoch #3. Accuracy on batch 1697 on Training is 30.274587750294465\n",
            "Epoch #3. Accuracy on batch 1698 on Training is 30.2751618599176\n",
            "Epoch #3. Accuracy on batch 1699 on Training is 30.27573529411765\n",
            "Batch Id 1700 is having training loss of 2485.44384765625\n",
            "25.278839111328125\n",
            "Epoch #3. Accuracy on batch 1700 on Training is 30.2744708994709\n",
            "Epoch #3. Accuracy on batch 1701 on Training is 30.267699764982375\n",
            "Epoch #3. Accuracy on batch 1702 on Training is 30.26093658250147\n",
            "Epoch #3. Accuracy on batch 1703 on Training is 30.257849178403756\n",
            "Epoch #3. Accuracy on batch 1704 on Training is 30.262096774193548\n",
            "Epoch #3. Accuracy on batch 1705 on Training is 30.257180539273154\n",
            "Epoch #3. Accuracy on batch 1706 on Training is 30.261423550087873\n",
            "Epoch #3. Accuracy on batch 1707 on Training is 30.254683840749415\n",
            "Epoch #3. Accuracy on batch 1708 on Training is 30.2479520187244\n",
            "Epoch #3. Accuracy on batch 1709 on Training is 30.254020467836256\n",
            "Epoch #3. Accuracy on batch 1710 on Training is 30.261908240794856\n",
            "Epoch #3. Accuracy on batch 1711 on Training is 30.249707943925234\n",
            "Epoch #3. Accuracy on batch 1712 on Training is 30.250291885580854\n",
            "Epoch #3. Accuracy on batch 1713 on Training is 30.24722870478413\n",
            "Epoch #3. Accuracy on batch 1714 on Training is 30.24963556851312\n",
            "Epoch #3. Accuracy on batch 1715 on Training is 30.259324009324008\n",
            "Epoch #3. Accuracy on batch 1716 on Training is 30.26172102504368\n",
            "Epoch #3. Accuracy on batch 1717 on Training is 30.265934225844006\n",
            "Epoch #3. Accuracy on batch 1718 on Training is 30.26832460732984\n",
            "Epoch #3. Accuracy on batch 1719 on Training is 30.26889534883721\n",
            "Batch Id 1720 is having training loss of 2581.922119140625\n",
            "177.24276733398438\n",
            "Epoch #3. Accuracy on batch 1720 on Training is 30.273097036606625\n",
            "Epoch #3. Accuracy on batch 1721 on Training is 30.264590592334496\n",
            "Epoch #3. Accuracy on batch 1722 on Training is 30.266976204294835\n",
            "Epoch #3. Accuracy on batch 1723 on Training is 30.2693590487239\n",
            "Epoch #3. Accuracy on batch 1724 on Training is 30.266304347826086\n",
            "Epoch #3. Accuracy on batch 1725 on Training is 30.268684820393975\n",
            "Epoch #3. Accuracy on batch 1726 on Training is 30.26925303995368\n",
            "Epoch #3. Accuracy on batch 1727 on Training is 30.2734375\n",
            "Epoch #3. Accuracy on batch 1728 on Training is 30.270387507229614\n",
            "Epoch #3. Accuracy on batch 1729 on Training is 30.270953757225435\n",
            "Epoch #3. Accuracy on batch 1730 on Training is 30.271519352975158\n",
            "Epoch #3. Accuracy on batch 1731 on Training is 30.264867205542725\n",
            "Epoch #3. Accuracy on batch 1732 on Training is 30.27264858626659\n",
            "Epoch #3. Accuracy on batch 1733 on Training is 30.271410034602077\n",
            "Epoch #3. Accuracy on batch 1734 on Training is 30.262968299711815\n",
            "Epoch #3. Accuracy on batch 1735 on Training is 30.261736751152075\n",
            "Epoch #3. Accuracy on batch 1736 on Training is 30.256908462867013\n",
            "Epoch #3. Accuracy on batch 1737 on Training is 30.25747986191024\n",
            "Epoch #3. Accuracy on batch 1738 on Training is 30.25984761357102\n",
            "Epoch #3. Accuracy on batch 1739 on Training is 30.256824712643677\n",
            "Batch Id 1740 is having training loss of 2552.80224609375\n",
            "11.77742862701416\n",
            "Epoch #3. Accuracy on batch 1740 on Training is 30.26278001148765\n",
            "Epoch #3. Accuracy on batch 1741 on Training is 30.272316303099885\n",
            "Epoch #3. Accuracy on batch 1742 on Training is 30.28184165232358\n",
            "Epoch #3. Accuracy on batch 1743 on Training is 30.28418864678899\n",
            "Epoch #3. Accuracy on batch 1744 on Training is 30.288323782234958\n",
            "Epoch #3. Accuracy on batch 1745 on Training is 30.290664375715924\n",
            "Epoch #3. Accuracy on batch 1746 on Training is 30.29657985117344\n",
            "Epoch #3. Accuracy on batch 1747 on Training is 30.289974256292908\n",
            "Epoch #3. Accuracy on batch 1748 on Training is 30.28158947970269\n",
            "Epoch #3. Accuracy on batch 1749 on Training is 30.28035714285714\n",
            "Epoch #3. Accuracy on batch 1750 on Training is 30.28269560251285\n",
            "Epoch #3. Accuracy on batch 1751 on Training is 30.277896689497716\n",
            "Epoch #3. Accuracy on batch 1752 on Training is 30.282016543069023\n",
            "Epoch #3. Accuracy on batch 1753 on Training is 30.287913340935006\n",
            "Epoch #3. Accuracy on batch 1754 on Training is 30.284900284900285\n",
            "Epoch #3. Accuracy on batch 1755 on Training is 30.27833143507973\n",
            "Epoch #3. Accuracy on batch 1756 on Training is 30.269991462720547\n",
            "Epoch #3. Accuracy on batch 1757 on Training is 30.261660978384526\n",
            "Epoch #3. Accuracy on batch 1758 on Training is 30.26399943149517\n",
            "Epoch #3. Accuracy on batch 1759 on Training is 30.26278409090909\n",
            "Batch Id 1760 is having training loss of 2559.947509765625\n",
            "20.768274307250977\n",
            "Epoch #3. Accuracy on batch 1760 on Training is 30.26157013060761\n",
            "Epoch #3. Accuracy on batch 1761 on Training is 30.26745175936436\n",
            "Epoch #3. Accuracy on batch 1762 on Training is 30.266236528644356\n",
            "Epoch #3. Accuracy on batch 1763 on Training is 30.26502267573696\n",
            "Epoch #3. Accuracy on batch 1764 on Training is 30.269121813031163\n",
            "Epoch #3. Accuracy on batch 1765 on Training is 30.26967723669309\n",
            "Epoch #3. Accuracy on batch 1766 on Training is 30.257852292020374\n",
            "Epoch #3. Accuracy on batch 1767 on Training is 30.24427319004525\n",
            "Epoch #3. Accuracy on batch 1768 on Training is 30.24484171848502\n",
            "Epoch #3. Accuracy on batch 1769 on Training is 30.247175141242938\n",
            "Epoch #3. Accuracy on batch 1770 on Training is 30.242447769621684\n",
            "Epoch #3. Accuracy on batch 1771 on Training is 30.246543453724605\n",
            "Epoch #3. Accuracy on batch 1772 on Training is 30.250634517766496\n",
            "Epoch #3. Accuracy on batch 1773 on Training is 30.26000563697858\n",
            "Epoch #3. Accuracy on batch 1774 on Training is 30.260563380281692\n",
            "Epoch #3. Accuracy on batch 1775 on Training is 30.26288006756757\n",
            "Epoch #3. Accuracy on batch 1776 on Training is 30.26871131119865\n",
            "Epoch #3. Accuracy on batch 1777 on Training is 30.269263217097862\n",
            "Epoch #3. Accuracy on batch 1778 on Training is 30.266301292861158\n",
            "Epoch #3. Accuracy on batch 1779 on Training is 30.265098314606742\n",
            "Batch Id 1780 is having training loss of 2532.228515625\n",
            "33.973026275634766\n",
            "Epoch #3. Accuracy on batch 1780 on Training is 30.269160583941606\n",
            "Epoch #3. Accuracy on batch 1781 on Training is 30.273218294051627\n",
            "Epoch #3. Accuracy on batch 1782 on Training is 30.268508132361188\n",
            "Epoch #3. Accuracy on batch 1783 on Training is 30.276065022421523\n",
            "Epoch #3. Accuracy on batch 1784 on Training is 30.274859943977592\n",
            "Epoch #3. Accuracy on batch 1785 on Training is 30.275405935050394\n",
            "Epoch #3. Accuracy on batch 1786 on Training is 30.284695019585897\n",
            "Epoch #3. Accuracy on batch 1787 on Training is 30.286982662192393\n",
            "Epoch #3. Accuracy on batch 1788 on Training is 30.289267747344887\n",
            "Epoch #3. Accuracy on batch 1789 on Training is 30.286312849162012\n",
            "Epoch #3. Accuracy on batch 1790 on Training is 30.283361250697933\n",
            "Epoch #3. Accuracy on batch 1791 on Training is 30.280412946428573\n",
            "Epoch #3. Accuracy on batch 1792 on Training is 30.279210819854992\n",
            "Epoch #3. Accuracy on batch 1793 on Training is 30.278010033444815\n",
            "Epoch #3. Accuracy on batch 1794 on Training is 30.275069637883007\n",
            "Epoch #3. Accuracy on batch 1795 on Training is 30.272132516703785\n",
            "Epoch #3. Accuracy on batch 1796 on Training is 30.27267668336116\n",
            "Epoch #3. Accuracy on batch 1797 on Training is 30.269744160177975\n",
            "Epoch #3. Accuracy on batch 1798 on Training is 30.27028904947193\n",
            "Epoch #3. Accuracy on batch 1799 on Training is 30.27777777777778\n",
            "Batch Id 1800 is having training loss of 2541.606689453125\n",
            "21.531951904296875\n",
            "Epoch #3. Accuracy on batch 1800 on Training is 30.274847307051637\n",
            "Epoch #3. Accuracy on batch 1801 on Training is 30.2805910099889\n",
            "Epoch #3. Accuracy on batch 1802 on Training is 30.281128674431503\n",
            "Epoch #3. Accuracy on batch 1803 on Training is 30.29032705099778\n",
            "Epoch #3. Accuracy on batch 1804 on Training is 30.289127423822716\n",
            "Epoch #3. Accuracy on batch 1805 on Training is 30.287929125138426\n",
            "Epoch #3. Accuracy on batch 1806 on Training is 30.281543995572772\n",
            "Epoch #3. Accuracy on batch 1807 on Training is 30.27516592920354\n",
            "Epoch #3. Accuracy on batch 1808 on Training is 30.2757048092869\n",
            "Epoch #3. Accuracy on batch 1809 on Training is 30.277969613259668\n",
            "Epoch #3. Accuracy on batch 1810 on Training is 30.287134180011044\n",
            "Epoch #3. Accuracy on batch 1811 on Training is 30.28076710816777\n",
            "Epoch #3. Accuracy on batch 1812 on Training is 30.281301709873137\n",
            "Epoch #3. Accuracy on batch 1813 on Training is 30.278390297684673\n",
            "Epoch #3. Accuracy on batch 1814 on Training is 30.27376033057851\n",
            "Epoch #3. Accuracy on batch 1815 on Training is 30.27601872246696\n",
            "Epoch #3. Accuracy on batch 1816 on Training is 30.279994496422674\n",
            "Epoch #3. Accuracy on batch 1817 on Training is 30.28740374037404\n",
            "Epoch #3. Accuracy on batch 1818 on Training is 30.28793293018142\n",
            "Epoch #3. Accuracy on batch 1819 on Training is 30.291895604395606\n",
            "Batch Id 1820 is having training loss of 2514.783203125\n",
            "133.58612060546875\n",
            "Epoch #3. Accuracy on batch 1820 on Training is 30.280409115870402\n",
            "Epoch #3. Accuracy on batch 1821 on Training is 30.27751097694841\n",
            "Epoch #3. Accuracy on batch 1822 on Training is 30.281472846955566\n",
            "Epoch #3. Accuracy on batch 1823 on Training is 30.28029057017544\n",
            "Epoch #3. Accuracy on batch 1824 on Training is 30.28082191780822\n",
            "Epoch #3. Accuracy on batch 1825 on Training is 30.276218510405258\n",
            "Epoch #3. Accuracy on batch 1826 on Training is 30.280172413793103\n",
            "Epoch #3. Accuracy on batch 1827 on Training is 30.267026805251643\n",
            "Epoch #3. Accuracy on batch 1828 on Training is 30.269272826681245\n",
            "Epoch #3. Accuracy on batch 1829 on Training is 30.2698087431694\n",
            "Epoch #3. Accuracy on batch 1830 on Training is 30.26863735663572\n",
            "Epoch #3. Accuracy on batch 1831 on Training is 30.2742903930131\n",
            "Epoch #3. Accuracy on batch 1832 on Training is 30.27823240589198\n",
            "Epoch #3. Accuracy on batch 1833 on Training is 30.270242639040347\n",
            "Epoch #3. Accuracy on batch 1834 on Training is 30.269073569482288\n",
            "Epoch #3. Accuracy on batch 1835 on Training is 30.26790577342048\n",
            "Epoch #3. Accuracy on batch 1836 on Training is 30.271842678279803\n",
            "Epoch #3. Accuracy on batch 1837 on Training is 30.274075081610444\n",
            "Epoch #3. Accuracy on batch 1838 on Training is 30.27630505709625\n",
            "Epoch #3. Accuracy on batch 1839 on Training is 30.28023097826087\n",
            "Batch Id 1840 is having training loss of 2611.537109375\n",
            "17.66360092163086\n",
            "Epoch #3. Accuracy on batch 1840 on Training is 30.28585008147746\n",
            "Epoch #3. Accuracy on batch 1841 on Training is 30.286373507057547\n",
            "Epoch #3. Accuracy on batch 1842 on Training is 30.28859196961476\n",
            "Epoch #3. Accuracy on batch 1843 on Training is 30.28911334056399\n",
            "Epoch #3. Accuracy on batch 1844 on Training is 30.286246612466126\n",
            "Epoch #3. Accuracy on batch 1845 on Training is 30.290154387865655\n",
            "Epoch #3. Accuracy on batch 1846 on Training is 30.292365998917163\n",
            "Epoch #3. Accuracy on batch 1847 on Training is 30.28442911255411\n",
            "Epoch #3. Accuracy on batch 1848 on Training is 30.274810708491078\n",
            "Epoch #3. Accuracy on batch 1849 on Training is 30.277027027027028\n",
            "Epoch #3. Accuracy on batch 1850 on Training is 30.279240950837384\n",
            "Epoch #3. Accuracy on batch 1851 on Training is 30.281452483801296\n",
            "Epoch #3. Accuracy on batch 1852 on Training is 30.27860226659471\n",
            "Epoch #3. Accuracy on batch 1853 on Training is 30.28249730312837\n",
            "Epoch #3. Accuracy on batch 1854 on Training is 30.28133423180593\n",
            "Epoch #3. Accuracy on batch 1855 on Training is 30.27848868534483\n",
            "Epoch #3. Accuracy on batch 1856 on Training is 30.2823774905762\n",
            "Epoch #3. Accuracy on batch 1857 on Training is 30.277852529601724\n",
            "Epoch #3. Accuracy on batch 1858 on Training is 30.28846153846154\n",
            "Epoch #3. Accuracy on batch 1859 on Training is 30.285618279569892\n",
            "Batch Id 1860 is having training loss of 2606.779052734375\n",
            "18.478914260864258\n",
            "Epoch #3. Accuracy on batch 1860 on Training is 30.291174099946264\n",
            "Epoch #3. Accuracy on batch 1861 on Training is 30.29168904403867\n",
            "Epoch #3. Accuracy on batch 1862 on Training is 30.283816425120772\n",
            "Epoch #3. Accuracy on batch 1863 on Training is 30.28601126609442\n",
            "Epoch #3. Accuracy on batch 1864 on Training is 30.279825737265416\n",
            "Epoch #3. Accuracy on batch 1865 on Training is 30.28369506966774\n",
            "Epoch #3. Accuracy on batch 1866 on Training is 30.282538832351367\n",
            "Epoch #3. Accuracy on batch 1867 on Training is 30.283056745182012\n",
            "Epoch #3. Accuracy on batch 1868 on Training is 30.278558052434455\n",
            "Epoch #3. Accuracy on batch 1869 on Training is 30.269050802139038\n",
            "Epoch #3. Accuracy on batch 1870 on Training is 30.269575093532872\n",
            "Epoch #3. Accuracy on batch 1871 on Training is 30.260082799145298\n",
            "Epoch #3. Accuracy on batch 1872 on Training is 30.26394821142552\n",
            "Epoch #3. Accuracy on batch 1873 on Training is 30.257804162219852\n",
            "Epoch #3. Accuracy on batch 1874 on Training is 30.255\n",
            "Epoch #3. Accuracy on batch 1875 on Training is 30.25719616204691\n",
            "Epoch #3. Accuracy on batch 1876 on Training is 30.25273042088439\n",
            "Epoch #3. Accuracy on batch 1877 on Training is 30.249933439829604\n",
            "Epoch #3. Accuracy on batch 1878 on Training is 30.25379191059074\n",
            "Epoch #3. Accuracy on batch 1879 on Training is 30.26097074468085\n",
            "Batch Id 1880 is having training loss of 2603.373779296875\n",
            "27.377073287963867\n",
            "Epoch #3. Accuracy on batch 1880 on Training is 30.25817384370016\n",
            "Epoch #3. Accuracy on batch 1881 on Training is 30.260361317747076\n",
            "Epoch #3. Accuracy on batch 1882 on Training is 30.265865639936273\n",
            "Epoch #3. Accuracy on batch 1883 on Training is 30.271364118895967\n",
            "Epoch #3. Accuracy on batch 1884 on Training is 30.278514588859416\n",
            "Epoch #3. Accuracy on batch 1885 on Training is 30.277372746553553\n",
            "Epoch #3. Accuracy on batch 1886 on Training is 30.281200317965023\n",
            "Epoch #3. Accuracy on batch 1887 on Training is 30.28667902542373\n",
            "Epoch #3. Accuracy on batch 1888 on Training is 30.29380624669137\n",
            "Epoch #3. Accuracy on batch 1889 on Training is 30.29100529100529\n",
            "Epoch #3. Accuracy on batch 1890 on Training is 30.293164992067688\n",
            "Epoch #3. Accuracy on batch 1891 on Training is 30.293670718816067\n",
            "Epoch #3. Accuracy on batch 1892 on Training is 30.29582673005811\n",
            "Epoch #3. Accuracy on batch 1893 on Training is 30.293030623020062\n",
            "Epoch #3. Accuracy on batch 1894 on Training is 30.296833773087073\n",
            "Epoch #3. Accuracy on batch 1895 on Training is 30.28579905063291\n",
            "Epoch #3. Accuracy on batch 1896 on Training is 30.284659989457037\n",
            "Epoch #3. Accuracy on batch 1897 on Training is 30.28187565858799\n",
            "Epoch #3. Accuracy on batch 1898 on Training is 30.284031068983676\n",
            "Epoch #3. Accuracy on batch 1899 on Training is 30.27796052631579\n",
            "Batch Id 1900 is having training loss of 2612.791748046875\n",
            "96.35269165039062\n",
            "Epoch #3. Accuracy on batch 1900 on Training is 30.273540241977905\n",
            "Epoch #3. Accuracy on batch 1901 on Training is 30.274053627760253\n",
            "Epoch #3. Accuracy on batch 1902 on Training is 30.282777193904362\n",
            "Epoch #3. Accuracy on batch 1903 on Training is 30.280002626050422\n",
            "Epoch #3. Accuracy on batch 1904 on Training is 30.287073490813647\n",
            "Epoch #3. Accuracy on batch 1905 on Training is 30.28757869884575\n",
            "Epoch #3. Accuracy on batch 1906 on Training is 30.28152857891977\n",
            "Epoch #3. Accuracy on batch 1907 on Training is 30.277122641509433\n",
            "Epoch #3. Accuracy on batch 1908 on Training is 30.275995285489785\n",
            "Epoch #3. Accuracy on batch 1909 on Training is 30.279777486910994\n",
            "Epoch #3. Accuracy on batch 1910 on Training is 30.28192046049189\n",
            "Epoch #3. Accuracy on batch 1911 on Training is 30.28569560669456\n",
            "Epoch #3. Accuracy on batch 1912 on Training is 30.286199686356507\n",
            "Epoch #3. Accuracy on batch 1913 on Training is 30.280172413793103\n",
            "Epoch #3. Accuracy on batch 1914 on Training is 30.282310704960835\n",
            "Epoch #3. Accuracy on batch 1915 on Training is 30.282815762004176\n",
            "Epoch #3. Accuracy on batch 1916 on Training is 30.280059989567032\n",
            "Epoch #3. Accuracy on batch 1917 on Training is 30.282194994786234\n",
            "Epoch #3. Accuracy on batch 1918 on Training is 30.285956227201666\n",
            "Epoch #3. Accuracy on batch 1919 on Training is 30.291341145833332\n",
            "Batch Id 1920 is having training loss of 2680.898681640625\n",
            "32953.4375\n",
            "Epoch #3. Accuracy on batch 1920 on Training is 30.288586673607497\n",
            "Epoch #3. Accuracy on batch 1921 on Training is 30.290712799167533\n",
            "Epoch #3. Accuracy on batch 1922 on Training is 30.296086843473738\n",
            "Epoch #3. Accuracy on batch 1923 on Training is 30.301455301455302\n",
            "Epoch #3. Accuracy on batch 1924 on Training is 30.301948051948052\n",
            "Epoch #3. Accuracy on batch 1925 on Training is 30.30244029075805\n",
            "Epoch #3. Accuracy on batch 1926 on Training is 30.307797093928386\n",
            "Epoch #3. Accuracy on batch 1927 on Training is 30.311527489626556\n",
            "Epoch #3. Accuracy on batch 1928 on Training is 30.305533955417314\n",
            "Epoch #3. Accuracy on batch 1929 on Training is 30.306023316062177\n",
            "Epoch #3. Accuracy on batch 1930 on Training is 30.309748834800622\n",
            "Epoch #3. Accuracy on batch 1931 on Training is 30.30376552795031\n",
            "Epoch #3. Accuracy on batch 1932 on Training is 30.31072167615106\n",
            "Epoch #3. Accuracy on batch 1933 on Training is 30.31282316442606\n",
            "Epoch #3. Accuracy on batch 1934 on Training is 30.30361757105943\n",
            "Epoch #3. Accuracy on batch 1935 on Training is 30.304106404958677\n",
            "Epoch #3. Accuracy on batch 1936 on Training is 30.304594734124937\n",
            "Epoch #3. Accuracy on batch 1937 on Training is 30.30669504643963\n",
            "Epoch #3. Accuracy on batch 1938 on Training is 30.297511603919546\n",
            "Epoch #3. Accuracy on batch 1939 on Training is 30.298002577319586\n",
            "Batch Id 1940 is having training loss of 2655.65234375\n",
            "13.575599670410156\n",
            "Epoch #3. Accuracy on batch 1940 on Training is 30.298493044822255\n",
            "Epoch #3. Accuracy on batch 1941 on Training is 30.297373841400617\n",
            "Epoch #3. Accuracy on batch 1942 on Training is 30.30108080288214\n",
            "Epoch #3. Accuracy on batch 1943 on Training is 30.301568930041153\n",
            "Epoch #3. Accuracy on batch 1944 on Training is 30.305269922879177\n",
            "Epoch #3. Accuracy on batch 1945 on Training is 30.305755395683452\n",
            "Epoch #3. Accuracy on batch 1946 on Training is 30.30945043656908\n",
            "Epoch #3. Accuracy on batch 1947 on Training is 30.31153747433265\n",
            "Epoch #3. Accuracy on batch 1948 on Training is 30.326449461262186\n",
            "Epoch #3. Accuracy on batch 1949 on Training is 30.322115384615383\n",
            "Epoch #3. Accuracy on batch 1950 on Training is 30.320989236289083\n",
            "Epoch #3. Accuracy on batch 1951 on Training is 30.32466700819672\n",
            "Epoch #3. Accuracy on batch 1952 on Training is 30.32194060419867\n",
            "Epoch #3. Accuracy on batch 1953 on Training is 30.31601842374616\n",
            "Epoch #3. Accuracy on batch 1954 on Training is 30.319693094629155\n",
            "Epoch #3. Accuracy on batch 1955 on Training is 30.3217663599182\n",
            "Epoch #3. Accuracy on batch 1956 on Training is 30.31904701073071\n",
            "Epoch #3. Accuracy on batch 1957 on Training is 30.317926455566905\n",
            "Epoch #3. Accuracy on batch 1958 on Training is 30.315211842776925\n",
            "Epoch #3. Accuracy on batch 1959 on Training is 30.3140943877551\n",
            "Batch Id 1960 is having training loss of 2663.822998046875\n",
            "73.9010009765625\n",
            "Epoch #3. Accuracy on batch 1960 on Training is 30.31775879653238\n",
            "Epoch #3. Accuracy on batch 1961 on Training is 30.32460499490316\n",
            "Epoch #3. Accuracy on batch 1962 on Training is 30.328260315843096\n",
            "Epoch #3. Accuracy on batch 1963 on Training is 30.32872963340122\n",
            "Epoch #3. Accuracy on batch 1964 on Training is 30.327608142493638\n",
            "Epoch #3. Accuracy on batch 1965 on Training is 30.329666836215665\n",
            "Epoch #3. Accuracy on batch 1966 on Training is 30.33648957803762\n",
            "Epoch #3. Accuracy on batch 1967 on Training is 30.335365853658537\n",
            "Epoch #3. Accuracy on batch 1968 on Training is 30.33583037074657\n",
            "Epoch #3. Accuracy on batch 1969 on Training is 30.33312182741117\n",
            "Epoch #3. Accuracy on batch 1970 on Training is 30.333587011669202\n",
            "Epoch #3. Accuracy on batch 1971 on Training is 30.327712981744423\n",
            "Epoch #3. Accuracy on batch 1972 on Training is 30.32659655347187\n",
            "Epoch #3. Accuracy on batch 1973 on Training is 30.327064336372846\n",
            "Epoch #3. Accuracy on batch 1974 on Training is 30.319620253164558\n",
            "Epoch #3. Accuracy on batch 1975 on Training is 30.310602226720647\n",
            "Epoch #3. Accuracy on batch 1976 on Training is 30.30949671219019\n",
            "Epoch #3. Accuracy on batch 1977 on Training is 30.316291708796765\n",
            "Epoch #3. Accuracy on batch 1978 on Training is 30.313605356240526\n",
            "Epoch #3. Accuracy on batch 1979 on Training is 30.315656565656564\n",
            "Batch Id 1980 is having training loss of 2689.460693359375\n",
            "21.51166343688965\n",
            "Epoch #3. Accuracy on batch 1980 on Training is 30.311395759717314\n",
            "Epoch #3. Accuracy on batch 1981 on Training is 30.31502270433905\n",
            "Epoch #3. Accuracy on batch 1982 on Training is 30.31391830559758\n",
            "Epoch #3. Accuracy on batch 1983 on Training is 30.312815020161292\n",
            "Epoch #3. Accuracy on batch 1984 on Training is 30.30698992443325\n",
            "Epoch #3. Accuracy on batch 1985 on Training is 30.301170694864048\n",
            "Epoch #3. Accuracy on batch 1986 on Training is 30.301648213387015\n",
            "Epoch #3. Accuracy on batch 1987 on Training is 30.300553319919516\n",
            "Epoch #3. Accuracy on batch 1988 on Training is 30.294746103569633\n",
            "Epoch #3. Accuracy on batch 1989 on Training is 30.299937185929647\n",
            "Epoch #3. Accuracy on batch 1990 on Training is 30.29727523857358\n",
            "Epoch #3. Accuracy on batch 1991 on Training is 30.29147841365462\n",
            "Epoch #3. Accuracy on batch 1992 on Training is 30.29039136979428\n",
            "Epoch #3. Accuracy on batch 1993 on Training is 30.28773821464393\n",
            "Epoch #3. Accuracy on batch 1994 on Training is 30.289786967418546\n",
            "Epoch #3. Accuracy on batch 1995 on Training is 30.28870240480962\n",
            "Epoch #3. Accuracy on batch 1996 on Training is 30.286054081121684\n",
            "Epoch #3. Accuracy on batch 1997 on Training is 30.28028028028028\n",
            "Epoch #3. Accuracy on batch 1998 on Training is 30.283891945972986\n",
            "Epoch #3. Accuracy on batch 1999 on Training is 30.2765625\n",
            "Batch Id 2000 is having training loss of 2702.68359375\n",
            "31.234071731567383\n",
            "Epoch #3. Accuracy on batch 2000 on Training is 30.275487256371814\n",
            "Epoch #3. Accuracy on batch 2001 on Training is 30.26660839160839\n",
            "Epoch #3. Accuracy on batch 2002 on Training is 30.27021967049426\n",
            "Epoch #3. Accuracy on batch 2003 on Training is 30.26758982035928\n",
            "Epoch #3. Accuracy on batch 2004 on Training is 30.268079800498754\n",
            "Epoch #3. Accuracy on batch 2005 on Training is 30.26545363908275\n",
            "Epoch #3. Accuracy on batch 2006 on Training is 30.259715994020926\n",
            "Epoch #3. Accuracy on batch 2007 on Training is 30.267990537848604\n",
            "Epoch #3. Accuracy on batch 2008 on Training is 30.270034843205575\n",
            "Epoch #3. Accuracy on batch 2009 on Training is 30.26741293532338\n",
            "Epoch #3. Accuracy on batch 2010 on Training is 30.26790154152163\n",
            "Epoch #3. Accuracy on batch 2011 on Training is 30.263730119284293\n",
            "Epoch #3. Accuracy on batch 2012 on Training is 30.26422006954794\n",
            "Epoch #3. Accuracy on batch 2013 on Training is 30.261606256206555\n",
            "Epoch #3. Accuracy on batch 2014 on Training is 30.25744416873449\n",
            "Epoch #3. Accuracy on batch 2015 on Training is 30.256386408730158\n",
            "Epoch #3. Accuracy on batch 2016 on Training is 30.256879028259792\n",
            "Epoch #3. Accuracy on batch 2017 on Training is 30.258919722497524\n",
            "Epoch #3. Accuracy on batch 2018 on Training is 30.253219415552255\n",
            "Epoch #3. Accuracy on batch 2019 on Training is 30.25061881188119\n",
            "Batch Id 2020 is having training loss of 2766.39013671875\n",
            "29.032381057739258\n",
            "Epoch #3. Accuracy on batch 2020 on Training is 30.248020781791194\n",
            "Epoch #3. Accuracy on batch 2021 on Training is 30.248516320474778\n",
            "Epoch #3. Accuracy on batch 2022 on Training is 30.23974295600593\n",
            "Epoch #3. Accuracy on batch 2023 on Training is 30.24333003952569\n",
            "Epoch #3. Accuracy on batch 2024 on Training is 30.24537037037037\n",
            "Epoch #3. Accuracy on batch 2025 on Training is 30.248951135241857\n",
            "Epoch #3. Accuracy on batch 2026 on Training is 30.257153428712382\n",
            "Epoch #3. Accuracy on batch 2027 on Training is 30.24993836291913\n",
            "Epoch #3. Accuracy on batch 2028 on Training is 30.2473509117792\n",
            "Epoch #3. Accuracy on batch 2029 on Training is 30.247844827586206\n",
            "Epoch #3. Accuracy on batch 2030 on Training is 30.245260955194485\n",
            "Epoch #3. Accuracy on batch 2031 on Training is 30.247293307086615\n",
            "Epoch #3. Accuracy on batch 2032 on Training is 30.24163797343827\n",
            "Epoch #3. Accuracy on batch 2033 on Training is 30.240597345132745\n",
            "Epoch #3. Accuracy on batch 2034 on Training is 30.236486486486488\n",
            "Epoch #3. Accuracy on batch 2035 on Training is 30.236984282907663\n",
            "Epoch #3. Accuracy on batch 2036 on Training is 30.240549828178693\n",
            "Epoch #3. Accuracy on batch 2037 on Training is 30.242578508341513\n",
            "Epoch #3. Accuracy on batch 2038 on Training is 30.246137812653263\n",
            "Epoch #3. Accuracy on batch 2039 on Training is 30.251225490196077\n",
            "Batch Id 2040 is having training loss of 2787.089111328125\n",
            "68914.921875\n",
            "Epoch #3. Accuracy on batch 2040 on Training is 30.239465948064673\n",
            "Epoch #3. Accuracy on batch 2041 on Training is 30.241491185112636\n",
            "Epoch #3. Accuracy on batch 2042 on Training is 30.23586637298091\n",
            "Epoch #3. Accuracy on batch 2043 on Training is 30.23636252446184\n",
            "Epoch #3. Accuracy on batch 2044 on Training is 30.23380195599022\n",
            "Epoch #3. Accuracy on batch 2045 on Training is 30.23277126099707\n",
            "Epoch #3. Accuracy on batch 2046 on Training is 30.23174157303371\n",
            "Epoch #3. Accuracy on batch 2047 on Training is 30.230712890625\n",
            "Epoch #3. Accuracy on batch 2048 on Training is 30.231210346510494\n",
            "Epoch #3. Accuracy on batch 2049 on Training is 30.23018292682927\n",
            "Epoch #3. Accuracy on batch 2050 on Training is 30.227632862018528\n",
            "Epoch #3. Accuracy on batch 2051 on Training is 30.228131091617932\n",
            "Epoch #3. Accuracy on batch 2052 on Training is 30.22558451047248\n",
            "Epoch #3. Accuracy on batch 2053 on Training is 30.229126095423563\n",
            "Epoch #3. Accuracy on batch 2054 on Training is 30.232664233576642\n",
            "Epoch #3. Accuracy on batch 2055 on Training is 30.239238813229573\n",
            "Epoch #3. Accuracy on batch 2056 on Training is 30.245807000486145\n",
            "Epoch #3. Accuracy on batch 2057 on Training is 30.247813411078717\n",
            "Epoch #3. Accuracy on batch 2058 on Training is 30.2574065080136\n",
            "Epoch #3. Accuracy on batch 2059 on Training is 30.2563713592233\n",
            "Batch Id 2060 is having training loss of 2764.995849609375\n",
            "35.849510192871094\n",
            "Epoch #3. Accuracy on batch 2060 on Training is 30.256853469189714\n",
            "Epoch #3. Accuracy on batch 2061 on Training is 30.25430407371484\n",
            "Epoch #3. Accuracy on batch 2062 on Training is 30.257816286960736\n",
            "Epoch #3. Accuracy on batch 2063 on Training is 30.25829699612403\n",
            "Epoch #3. Accuracy on batch 2064 on Training is 30.258777239709442\n",
            "Epoch #3. Accuracy on batch 2065 on Training is 30.25018151016457\n",
            "Epoch #3. Accuracy on batch 2066 on Training is 30.24764150943396\n",
            "Epoch #3. Accuracy on batch 2067 on Training is 30.249637330754354\n",
            "Epoch #3. Accuracy on batch 2068 on Training is 30.248610439826003\n",
            "Epoch #3. Accuracy on batch 2069 on Training is 30.246074879227052\n",
            "Epoch #3. Accuracy on batch 2070 on Training is 30.235997102848867\n",
            "Epoch #3. Accuracy on batch 2071 on Training is 30.23497828185328\n",
            "Epoch #3. Accuracy on batch 2072 on Training is 30.235467920887604\n",
            "Epoch #3. Accuracy on batch 2073 on Training is 30.240477338476374\n",
            "Epoch #3. Accuracy on batch 2074 on Training is 30.246987951807228\n",
            "Epoch #3. Accuracy on batch 2075 on Training is 30.258008188824665\n",
            "Epoch #3. Accuracy on batch 2076 on Training is 30.249458353394317\n",
            "Epoch #3. Accuracy on batch 2077 on Training is 30.252947545717035\n",
            "Epoch #3. Accuracy on batch 2078 on Training is 30.251924001924003\n",
            "Epoch #3. Accuracy on batch 2079 on Training is 30.24939903846154\n",
            "Batch Id 2080 is having training loss of 2809.8994140625\n",
            "23.556596755981445\n",
            "Epoch #3. Accuracy on batch 2080 on Training is 30.254384911100434\n",
            "Epoch #3. Accuracy on batch 2081 on Training is 30.253362151777136\n",
            "Epoch #3. Accuracy on batch 2082 on Training is 30.243338934229477\n",
            "Epoch #3. Accuracy on batch 2083 on Training is 30.24682101727447\n",
            "Epoch #3. Accuracy on batch 2084 on Training is 30.24580335731415\n",
            "Epoch #3. Accuracy on batch 2085 on Training is 30.244786673058485\n",
            "Epoch #3. Accuracy on batch 2086 on Training is 30.240776233828463\n",
            "Epoch #3. Accuracy on batch 2087 on Training is 30.24425287356322\n",
            "Epoch #3. Accuracy on batch 2088 on Training is 30.23725466730493\n",
            "Epoch #3. Accuracy on batch 2089 on Training is 30.230263157894736\n",
            "Epoch #3. Accuracy on batch 2090 on Training is 30.233739837398375\n",
            "Epoch #3. Accuracy on batch 2091 on Training is 30.232731835564053\n",
            "Epoch #3. Accuracy on batch 2092 on Training is 30.236204013377925\n",
            "Epoch #3. Accuracy on batch 2093 on Training is 30.23818051575931\n",
            "Epoch #3. Accuracy on batch 2094 on Training is 30.240155131264917\n",
            "Epoch #3. Accuracy on batch 2095 on Training is 30.236164122137403\n",
            "Epoch #3. Accuracy on batch 2096 on Training is 30.23217691940868\n",
            "Epoch #3. Accuracy on batch 2097 on Training is 30.231172545281222\n",
            "Epoch #3. Accuracy on batch 2098 on Training is 30.225702715578848\n",
            "Epoch #3. Accuracy on batch 2099 on Training is 30.22470238095238\n",
            "Batch Id 2100 is having training loss of 2800.584228515625\n",
            "21.595102310180664\n",
            "Epoch #3. Accuracy on batch 2100 on Training is 30.2251903855307\n",
            "Epoch #3. Accuracy on batch 2101 on Training is 30.21824452901998\n",
            "Epoch #3. Accuracy on batch 2102 on Training is 30.21576319543509\n",
            "Epoch #3. Accuracy on batch 2103 on Training is 30.21625475285171\n",
            "Epoch #3. Accuracy on batch 2104 on Training is 30.215261282660332\n",
            "Epoch #3. Accuracy on batch 2105 on Training is 30.208333333333332\n",
            "Epoch #3. Accuracy on batch 2106 on Training is 30.208827717133364\n",
            "Epoch #3. Accuracy on batch 2107 on Training is 30.21228652751423\n",
            "Epoch #3. Accuracy on batch 2108 on Training is 30.220187292555714\n",
            "Epoch #3. Accuracy on batch 2109 on Training is 30.22659952606635\n",
            "Epoch #3. Accuracy on batch 2110 on Training is 30.231525343439127\n",
            "Epoch #3. Accuracy on batch 2111 on Training is 30.234966856060606\n",
            "Epoch #3. Accuracy on batch 2112 on Training is 30.2369261713204\n",
            "Epoch #3. Accuracy on batch 2113 on Training is 30.23592715231788\n",
            "Epoch #3. Accuracy on batch 2114 on Training is 30.2378841607565\n",
            "Epoch #3. Accuracy on batch 2115 on Training is 30.245746691871457\n",
            "Epoch #3. Accuracy on batch 2116 on Training is 30.24622106754842\n",
            "Epoch #3. Accuracy on batch 2117 on Training is 30.243744098205855\n",
            "Epoch #3. Accuracy on batch 2118 on Training is 30.24569372345446\n",
            "Epoch #3. Accuracy on batch 2119 on Training is 30.24764150943396\n",
            "Batch Id 2120 is having training loss of 2867.5595703125\n",
            "124.24054718017578\n",
            "Epoch #3. Accuracy on batch 2120 on Training is 30.252534181989628\n",
            "Epoch #3. Accuracy on batch 2121 on Training is 30.2500589066918\n",
            "Epoch #3. Accuracy on batch 2122 on Training is 30.253473857748467\n",
            "Epoch #3. Accuracy on batch 2123 on Training is 30.242172787193972\n",
            "Epoch #3. Accuracy on batch 2124 on Training is 30.25\n",
            "Epoch #3. Accuracy on batch 2125 on Training is 30.250470366886173\n",
            "Epoch #3. Accuracy on batch 2126 on Training is 30.255347907851434\n",
            "Epoch #3. Accuracy on batch 2127 on Training is 30.25434680451128\n",
            "Epoch #3. Accuracy on batch 2128 on Training is 30.25334664161578\n",
            "Epoch #3. Accuracy on batch 2129 on Training is 30.247946009389672\n",
            "Epoch #3. Accuracy on batch 2130 on Training is 30.251349131862977\n",
            "Epoch #3. Accuracy on batch 2131 on Training is 30.251817542213885\n",
            "Epoch #3. Accuracy on batch 2132 on Training is 30.250820440693857\n",
            "Epoch #3. Accuracy on batch 2133 on Training is 30.25275304592315\n",
            "Epoch #3. Accuracy on batch 2134 on Training is 30.254683840749415\n",
            "Epoch #3. Accuracy on batch 2135 on Training is 30.256612827715355\n",
            "Epoch #3. Accuracy on batch 2136 on Training is 30.258540009358914\n",
            "Epoch #3. Accuracy on batch 2137 on Training is 30.256080449017773\n",
            "Epoch #3. Accuracy on batch 2138 on Training is 30.252162225338942\n",
            "Epoch #3. Accuracy on batch 2139 on Training is 30.25408878504673\n",
            "Batch Id 2140 is having training loss of 2938.833984375\n",
            "11.891502380371094\n",
            "Epoch #3. Accuracy on batch 2140 on Training is 30.260392340028023\n",
            "Epoch #3. Accuracy on batch 2141 on Training is 30.26814892623716\n",
            "Epoch #3. Accuracy on batch 2142 on Training is 30.267148856742885\n",
            "Epoch #3. Accuracy on batch 2143 on Training is 30.261777052238806\n",
            "Epoch #3. Accuracy on batch 2144 on Training is 30.263694638694638\n",
            "Epoch #3. Accuracy on batch 2145 on Training is 30.262698042870458\n",
            "Epoch #3. Accuracy on batch 2146 on Training is 30.258791336748953\n",
            "Epoch #3. Accuracy on batch 2147 on Training is 30.25779795158287\n",
            "Epoch #3. Accuracy on batch 2148 on Training is 30.25535132619823\n",
            "Epoch #3. Accuracy on batch 2149 on Training is 30.254360465116278\n",
            "Epoch #3. Accuracy on batch 2150 on Training is 30.25191771269177\n",
            "Epoch #3. Accuracy on batch 2151 on Training is 30.249477230483272\n",
            "Epoch #3. Accuracy on batch 2152 on Training is 30.24703901532745\n",
            "Epoch #3. Accuracy on batch 2153 on Training is 30.250406220984214\n",
            "Epoch #3. Accuracy on batch 2154 on Training is 30.25232018561485\n",
            "Epoch #3. Accuracy on batch 2155 on Training is 30.257131261595546\n",
            "Epoch #3. Accuracy on batch 2156 on Training is 30.261937876680573\n",
            "Epoch #3. Accuracy on batch 2157 on Training is 30.26094763670065\n",
            "Epoch #3. Accuracy on batch 2158 on Training is 30.264300602130618\n",
            "Epoch #3. Accuracy on batch 2159 on Training is 30.264756944444443\n",
            "Batch Id 2160 is having training loss of 2945.351318359375\n",
            "25.77349090576172\n",
            "Epoch #3. Accuracy on batch 2160 on Training is 30.26521286441462\n",
            "Epoch #3. Accuracy on batch 2161 on Training is 30.265668362627196\n",
            "Epoch #3. Accuracy on batch 2162 on Training is 30.26612343966713\n",
            "Epoch #3. Accuracy on batch 2163 on Training is 30.265134011090574\n",
            "Epoch #3. Accuracy on batch 2164 on Training is 30.259815242494227\n",
            "Epoch #3. Accuracy on batch 2165 on Training is 30.26171514312096\n",
            "Epoch #3. Accuracy on batch 2166 on Training is 30.26217120443009\n",
            "Epoch #3. Accuracy on batch 2167 on Training is 30.264068265682656\n",
            "Epoch #3. Accuracy on batch 2168 on Training is 30.260200553250346\n",
            "Epoch #3. Accuracy on batch 2169 on Training is 30.25921658986175\n",
            "Epoch #3. Accuracy on batch 2170 on Training is 30.26255181943805\n",
            "Epoch #3. Accuracy on batch 2171 on Training is 30.264445211786374\n",
            "Epoch #3. Accuracy on batch 2172 on Training is 30.260584445467096\n",
            "Epoch #3. Accuracy on batch 2173 on Training is 30.261039558417664\n",
            "Epoch #3. Accuracy on batch 2174 on Training is 30.26867816091954\n",
            "Epoch #3. Accuracy on batch 2175 on Training is 30.269129136029413\n",
            "Epoch #3. Accuracy on batch 2176 on Training is 30.273886081763894\n",
            "Epoch #3. Accuracy on batch 2177 on Training is 30.278638659320478\n",
            "Epoch #3. Accuracy on batch 2178 on Training is 30.271913721890776\n",
            "Epoch #3. Accuracy on batch 2179 on Training is 30.275229357798164\n",
            "Batch Id 2180 is having training loss of 2948.93896484375\n",
            "22.02997398376465\n",
            "Epoch #3. Accuracy on batch 2180 on Training is 30.275676295277396\n",
            "Epoch #3. Accuracy on batch 2181 on Training is 30.27325847846013\n",
            "Epoch #3. Accuracy on batch 2182 on Training is 30.275137425561155\n",
            "Epoch #3. Accuracy on batch 2183 on Training is 30.27415293040293\n",
            "Epoch #3. Accuracy on batch 2184 on Training is 30.274599542334094\n",
            "Epoch #3. Accuracy on batch 2185 on Training is 30.276475297346753\n",
            "Epoch #3. Accuracy on batch 2186 on Training is 30.27120484682213\n",
            "Epoch #3. Accuracy on batch 2187 on Training is 30.273080438756857\n",
            "Epoch #3. Accuracy on batch 2188 on Training is 30.272099132023754\n",
            "Epoch #3. Accuracy on batch 2189 on Training is 30.26969178082192\n",
            "Epoch #3. Accuracy on batch 2190 on Training is 30.268712916476495\n",
            "Epoch #3. Accuracy on batch 2191 on Training is 30.27058622262774\n",
            "Epoch #3. Accuracy on batch 2192 on Training is 30.27673278613771\n",
            "Epoch #3. Accuracy on batch 2193 on Training is 30.275752051048315\n",
            "Epoch #3. Accuracy on batch 2194 on Training is 30.269077448747154\n",
            "Epoch #3. Accuracy on batch 2195 on Training is 30.268101092896174\n",
            "Epoch #3. Accuracy on batch 2196 on Training is 30.265703231679563\n",
            "Epoch #3. Accuracy on batch 2197 on Training is 30.271838034576888\n",
            "Epoch #3. Accuracy on batch 2198 on Training is 30.26944065484311\n",
            "Epoch #3. Accuracy on batch 2199 on Training is 30.269886363636363\n",
            "Batch Id 2200 is having training loss of 2967.50390625\n",
            "22.518844604492188\n",
            "Epoch #3. Accuracy on batch 2200 on Training is 30.273171285779192\n",
            "Epoch #3. Accuracy on batch 2201 on Training is 30.27645322434151\n",
            "Epoch #3. Accuracy on batch 2202 on Training is 30.281150703586018\n",
            "Epoch #3. Accuracy on batch 2203 on Training is 30.275918784029038\n",
            "Epoch #3. Accuracy on batch 2204 on Training is 30.27777777777778\n",
            "Epoch #3. Accuracy on batch 2205 on Training is 30.27963508612874\n",
            "Epoch #3. Accuracy on batch 2206 on Training is 30.282906660625283\n",
            "Epoch #3. Accuracy on batch 2207 on Training is 30.284759963768117\n",
            "Epoch #3. Accuracy on batch 2208 on Training is 30.28378225441376\n",
            "Epoch #3. Accuracy on batch 2209 on Training is 30.284219457013574\n",
            "Epoch #3. Accuracy on batch 2210 on Training is 30.28182948891904\n",
            "Epoch #3. Accuracy on batch 2211 on Training is 30.276616184448464\n",
            "Epoch #3. Accuracy on batch 2212 on Training is 30.281292363307728\n",
            "Epoch #3. Accuracy on batch 2213 on Training is 30.27326106594399\n",
            "Epoch #3. Accuracy on batch 2214 on Training is 30.266647855530476\n",
            "Epoch #3. Accuracy on batch 2215 on Training is 30.26991200361011\n",
            "Epoch #3. Accuracy on batch 2216 on Training is 30.2675349571493\n",
            "Epoch #3. Accuracy on batch 2217 on Training is 30.265160054102797\n",
            "Epoch #3. Accuracy on batch 2218 on Training is 30.258562415502478\n",
            "Epoch #3. Accuracy on batch 2219 on Training is 30.25760135135135\n",
            "Batch Id 2220 is having training loss of 2956.178955078125\n",
            "24587.2578125\n",
            "Epoch #3. Accuracy on batch 2220 on Training is 30.252420081044576\n",
            "Epoch #3. Accuracy on batch 2221 on Training is 30.247243474347435\n",
            "Epoch #3. Accuracy on batch 2222 on Training is 30.242071524966263\n",
            "Epoch #3. Accuracy on batch 2223 on Training is 30.241119604316548\n",
            "Epoch #3. Accuracy on batch 2224 on Training is 30.241573033707866\n",
            "Epoch #3. Accuracy on batch 2225 on Training is 30.242026055705303\n",
            "Epoch #3. Accuracy on batch 2226 on Training is 30.242478670857658\n",
            "Epoch #3. Accuracy on batch 2227 on Training is 30.241528276481148\n",
            "Epoch #3. Accuracy on batch 2228 on Training is 30.237774786899955\n",
            "Epoch #3. Accuracy on batch 2229 on Training is 30.23822869955157\n",
            "Epoch #3. Accuracy on batch 2230 on Training is 30.24148363962349\n",
            "Epoch #3. Accuracy on batch 2231 on Training is 30.24893593189964\n",
            "Epoch #3. Accuracy on batch 2232 on Training is 30.252183161665922\n",
            "Epoch #3. Accuracy on batch 2233 on Training is 30.255427484333033\n",
            "Epoch #3. Accuracy on batch 2234 on Training is 30.254474272930647\n",
            "Epoch #3. Accuracy on batch 2235 on Training is 30.256317084078713\n",
            "Epoch #3. Accuracy on batch 2236 on Training is 30.253967367009388\n",
            "Epoch #3. Accuracy on batch 2237 on Training is 30.264186773905273\n",
            "Epoch #3. Accuracy on batch 2238 on Training is 30.26183564091112\n",
            "Epoch #3. Accuracy on batch 2239 on Training is 30.260881696428573\n",
            "Batch Id 2240 is having training loss of 2930.163818359375\n",
            "15.828690528869629\n",
            "Epoch #3. Accuracy on batch 2240 on Training is 30.262717536813923\n",
            "Epoch #3. Accuracy on batch 2241 on Training is 30.26733942908118\n",
            "Epoch #3. Accuracy on batch 2242 on Training is 30.267777530093625\n",
            "Epoch #3. Accuracy on batch 2243 on Training is 30.265430035650624\n",
            "Epoch #3. Accuracy on batch 2244 on Training is 30.268652561247215\n",
            "Epoch #3. Accuracy on batch 2245 on Training is 30.267698130008906\n",
            "Epoch #3. Accuracy on batch 2246 on Training is 30.26952603471295\n",
            "Epoch #3. Accuracy on batch 2247 on Training is 30.27274243772242\n",
            "Epoch #3. Accuracy on batch 2248 on Training is 30.269008448199198\n",
            "Epoch #3. Accuracy on batch 2249 on Training is 30.272222222222222\n",
            "Epoch #3. Accuracy on batch 2250 on Training is 30.27265659706797\n",
            "Epoch #3. Accuracy on batch 2251 on Training is 30.27309058614565\n",
            "Epoch #3. Accuracy on batch 2252 on Training is 30.274911229471815\n",
            "Epoch #3. Accuracy on batch 2253 on Training is 30.27534383318545\n",
            "Epoch #3. Accuracy on batch 2254 on Training is 30.277161862527716\n",
            "Epoch #3. Accuracy on batch 2255 on Training is 30.267896719858157\n",
            "Epoch #3. Accuracy on batch 2256 on Training is 30.26833185644661\n",
            "Epoch #3. Accuracy on batch 2257 on Training is 30.268766607617362\n",
            "Epoch #3. Accuracy on batch 2258 on Training is 30.27196768481629\n",
            "Epoch #3. Accuracy on batch 2259 on Training is 30.273783185840706\n",
            "Batch Id 2260 is having training loss of 2906.533447265625\n",
            "11.770212173461914\n",
            "Epoch #3. Accuracy on batch 2260 on Training is 30.279743476337902\n",
            "Epoch #3. Accuracy on batch 2261 on Training is 30.27879089301503\n",
            "Epoch #3. Accuracy on batch 2262 on Training is 30.27922006186478\n",
            "Epoch #3. Accuracy on batch 2263 on Training is 30.276888250883392\n",
            "Epoch #3. Accuracy on batch 2264 on Training is 30.281456953642383\n",
            "Epoch #3. Accuracy on batch 2265 on Training is 30.284642541924097\n",
            "Epoch #3. Accuracy on batch 2266 on Training is 30.28920379355977\n",
            "Epoch #3. Accuracy on batch 2267 on Training is 30.288249559082892\n",
            "Epoch #3. Accuracy on batch 2268 on Training is 30.288673424416043\n",
            "Epoch #3. Accuracy on batch 2269 on Training is 30.284966960352424\n",
            "Epoch #3. Accuracy on batch 2270 on Training is 30.284015852047556\n",
            "Epoch #3. Accuracy on batch 2271 on Training is 30.291318221830984\n",
            "Epoch #3. Accuracy on batch 2272 on Training is 30.287615486141664\n",
            "Epoch #3. Accuracy on batch 2273 on Training is 30.286664467897978\n",
            "Epoch #3. Accuracy on batch 2274 on Training is 30.28434065934066\n",
            "Epoch #3. Accuracy on batch 2275 on Training is 30.280645869947275\n",
            "Epoch #3. Accuracy on batch 2276 on Training is 30.27969916556873\n",
            "Epoch #3. Accuracy on batch 2277 on Training is 30.27738147497805\n",
            "Epoch #3. Accuracy on batch 2278 on Training is 30.27917946467749\n",
            "Epoch #3. Accuracy on batch 2279 on Training is 30.27549342105263\n",
            "Batch Id 2280 is having training loss of 2931.1494140625\n",
            "24.49545669555664\n",
            "Epoch #3. Accuracy on batch 2280 on Training is 30.277290661990357\n",
            "Epoch #3. Accuracy on batch 2281 on Training is 30.27634750219106\n",
            "Epoch #3. Accuracy on batch 2282 on Training is 30.27403635567236\n",
            "Epoch #3. Accuracy on batch 2283 on Training is 30.27309544658494\n",
            "Epoch #3. Accuracy on batch 2284 on Training is 30.269420131291028\n",
            "Epoch #3. Accuracy on batch 2285 on Training is 30.27121609798775\n",
            "Epoch #3. Accuracy on batch 2286 on Training is 30.271644075207696\n",
            "Epoch #3. Accuracy on batch 2287 on Training is 30.28163243006993\n",
            "Epoch #3. Accuracy on batch 2288 on Training is 30.28615115771079\n",
            "Epoch #3. Accuracy on batch 2289 on Training is 30.28657205240175\n",
            "Epoch #3. Accuracy on batch 2290 on Training is 30.286992579659536\n",
            "Epoch #3. Accuracy on batch 2291 on Training is 30.287412739965095\n",
            "Epoch #3. Accuracy on batch 2292 on Training is 30.27965547317924\n",
            "Epoch #3. Accuracy on batch 2293 on Training is 30.271904969485615\n",
            "Epoch #3. Accuracy on batch 2294 on Training is 30.272331154684096\n",
            "Epoch #3. Accuracy on batch 2295 on Training is 30.271395905923345\n",
            "Epoch #3. Accuracy on batch 2296 on Training is 30.277263822377012\n",
            "Epoch #3. Accuracy on batch 2297 on Training is 30.279046997389035\n",
            "Epoch #3. Accuracy on batch 2298 on Training is 30.27675076120052\n",
            "Epoch #3. Accuracy on batch 2299 on Training is 30.275815217391305\n",
            "Batch Id 2300 is having training loss of 2999.017578125\n",
            "27.79155158996582\n",
            "Epoch #3. Accuracy on batch 2300 on Training is 30.272164276401565\n",
            "Epoch #3. Accuracy on batch 2301 on Training is 30.273946568201563\n",
            "Epoch #3. Accuracy on batch 2302 on Training is 30.278441163699522\n",
            "Epoch #3. Accuracy on batch 2303 on Training is 30.28293185763889\n",
            "Epoch #3. Accuracy on batch 2304 on Training is 30.286062906724514\n",
            "Epoch #3. Accuracy on batch 2305 on Training is 30.28106027753686\n",
            "Epoch #3. Accuracy on batch 2306 on Training is 30.2787711313394\n",
            "Epoch #3. Accuracy on batch 2307 on Training is 30.27783795493934\n",
            "Epoch #3. Accuracy on batch 2308 on Training is 30.283672585534863\n",
            "Epoch #3. Accuracy on batch 2309 on Training is 30.280032467532468\n",
            "Epoch #3. Accuracy on batch 2310 on Training is 30.27504327131112\n",
            "Epoch #3. Accuracy on batch 2311 on Training is 30.27681660899654\n",
            "Epoch #3. Accuracy on batch 2312 on Training is 30.271833117163858\n",
            "Epoch #3. Accuracy on batch 2313 on Training is 30.26550345721694\n",
            "Epoch #3. Accuracy on batch 2314 on Training is 30.26862850971922\n",
            "Epoch #3. Accuracy on batch 2315 on Training is 30.266353626943005\n",
            "Epoch #3. Accuracy on batch 2316 on Training is 30.266778161415623\n",
            "Epoch #3. Accuracy on batch 2317 on Training is 30.269898619499568\n",
            "Epoch #3. Accuracy on batch 2318 on Training is 30.275711513583442\n",
            "Epoch #3. Accuracy on batch 2319 on Training is 30.282866379310345\n",
            "Batch Id 2320 is having training loss of 2991.6533203125\n",
            "29.04632568359375\n",
            "Epoch #3. Accuracy on batch 2320 on Training is 30.28059026281775\n",
            "Epoch #3. Accuracy on batch 2321 on Training is 30.282353574504736\n",
            "Epoch #3. Accuracy on batch 2322 on Training is 30.281424881618598\n",
            "Epoch #3. Accuracy on batch 2323 on Training is 30.28722030981067\n",
            "Epoch #3. Accuracy on batch 2324 on Training is 30.288978494623656\n",
            "Epoch #3. Accuracy on batch 2325 on Training is 30.29207867583835\n",
            "Epoch #3. Accuracy on batch 2326 on Training is 30.29517619252256\n",
            "Epoch #3. Accuracy on batch 2327 on Training is 30.287532216494846\n",
            "Epoch #3. Accuracy on batch 2328 on Training is 30.293312580506655\n",
            "Epoch #3. Accuracy on batch 2329 on Training is 30.291040772532188\n",
            "Epoch #3. Accuracy on batch 2330 on Training is 30.288770913770914\n",
            "Epoch #3. Accuracy on batch 2331 on Training is 30.290523156089193\n",
            "Epoch #3. Accuracy on batch 2332 on Training is 30.288255465066438\n",
            "Epoch #3. Accuracy on batch 2333 on Training is 30.284650814053126\n",
            "Epoch #3. Accuracy on batch 2334 on Training is 30.2877408993576\n",
            "Epoch #3. Accuracy on batch 2335 on Training is 30.296179366438356\n",
            "Epoch #3. Accuracy on batch 2336 on Training is 30.300599058622165\n",
            "Epoch #3. Accuracy on batch 2337 on Training is 30.29565868263473\n",
            "Epoch #3. Accuracy on batch 2338 on Training is 30.30007481829842\n",
            "Epoch #3. Accuracy on batch 2339 on Training is 30.293803418803417\n",
            "Batch Id 2340 is having training loss of 3046.639892578125\n",
            "5473.59521484375\n",
            "Epoch #3. Accuracy on batch 2340 on Training is 30.29154207603588\n",
            "Epoch #3. Accuracy on batch 2341 on Training is 30.287948334756617\n",
            "Epoch #3. Accuracy on batch 2342 on Training is 30.292360221937688\n",
            "Epoch #3. Accuracy on batch 2343 on Training is 30.29276877133106\n",
            "Epoch #3. Accuracy on batch 2344 on Training is 30.297174840085287\n",
            "Epoch #3. Accuracy on batch 2345 on Training is 30.292252770673485\n",
            "Epoch #3. Accuracy on batch 2346 on Training is 30.296655304644226\n",
            "Epoch #3. Accuracy on batch 2347 on Training is 30.29706132879046\n",
            "Epoch #3. Accuracy on batch 2348 on Training is 30.296136653895275\n",
            "Epoch #3. Accuracy on batch 2349 on Training is 30.29787234042553\n",
            "Epoch #3. Accuracy on batch 2350 on Training is 30.298277328796257\n",
            "Epoch #3. Accuracy on batch 2351 on Training is 30.301339285714285\n",
            "Epoch #3. Accuracy on batch 2352 on Training is 30.30174245643859\n",
            "Epoch #3. Accuracy on batch 2353 on Training is 30.29949022939677\n",
            "Epoch #3. Accuracy on batch 2354 on Training is 30.3052016985138\n",
            "Epoch #3. Accuracy on batch 2355 on Training is 30.302949915110357\n",
            "Epoch #3. Accuracy on batch 2356 on Training is 30.3060033941451\n",
            "Epoch #3. Accuracy on batch 2357 on Training is 30.314355385920273\n",
            "Epoch #3. Accuracy on batch 2358 on Training is 30.309453158117847\n",
            "Epoch #3. Accuracy on batch 2359 on Training is 30.316472457627118\n",
            "Batch Id 2360 is having training loss of 3023.9306640625\n",
            "59.58463668823242\n",
            "Epoch #3. Accuracy on batch 2360 on Training is 30.310249894112665\n",
            "Epoch #3. Accuracy on batch 2361 on Training is 30.311970787468248\n",
            "Epoch #3. Accuracy on batch 2362 on Training is 30.311045281421922\n",
            "Epoch #3. Accuracy on batch 2363 on Training is 30.316730118443317\n",
            "Epoch #3. Accuracy on batch 2364 on Training is 30.321088794926006\n",
            "Epoch #3. Accuracy on batch 2365 on Training is 30.325443786982248\n",
            "Epoch #3. Accuracy on batch 2366 on Training is 30.328474862695394\n",
            "Epoch #3. Accuracy on batch 2367 on Training is 30.330183699324323\n",
            "Epoch #3. Accuracy on batch 2368 on Training is 30.33452933727311\n",
            "Epoch #3. Accuracy on batch 2369 on Training is 30.334915611814345\n",
            "Epoch #3. Accuracy on batch 2370 on Training is 30.336619569801773\n",
            "Epoch #3. Accuracy on batch 2371 on Training is 30.333052276559865\n",
            "Epoch #3. Accuracy on batch 2372 on Training is 30.32948798988622\n",
            "Epoch #3. Accuracy on batch 2373 on Training is 30.33514111204718\n",
            "Epoch #3. Accuracy on batch 2374 on Training is 30.325\n",
            "Epoch #3. Accuracy on batch 2375 on Training is 30.329335016835017\n",
            "Epoch #3. Accuracy on batch 2376 on Training is 30.328407656710137\n",
            "Epoch #3. Accuracy on batch 2377 on Training is 30.326166947014297\n",
            "Epoch #3. Accuracy on batch 2378 on Training is 30.330496006725514\n",
            "Epoch #3. Accuracy on batch 2379 on Training is 30.329569327731093\n",
            "Batch Id 2380 is having training loss of 3007.714111328125\n",
            "412.7124328613281\n",
            "Epoch #3. Accuracy on batch 2380 on Training is 30.324706005879882\n",
            "Epoch #3. Accuracy on batch 2381 on Training is 30.32247061293031\n",
            "Epoch #3. Accuracy on batch 2382 on Training is 30.318925723877467\n",
            "Epoch #3. Accuracy on batch 2383 on Training is 30.32193791946309\n",
            "Epoch #3. Accuracy on batch 2384 on Training is 30.32494758909853\n",
            "Epoch #3. Accuracy on batch 2385 on Training is 30.32009639564124\n",
            "Epoch #3. Accuracy on batch 2386 on Training is 30.320485965647254\n",
            "Epoch #3. Accuracy on batch 2387 on Training is 30.322183835845895\n",
            "Epoch #3. Accuracy on batch 2388 on Training is 30.32257220594391\n",
            "Epoch #3. Accuracy on batch 2389 on Training is 30.326882845188283\n",
            "Epoch #3. Accuracy on batch 2390 on Training is 30.331189878711836\n",
            "Epoch #3. Accuracy on batch 2391 on Training is 30.331573996655518\n",
            "Epoch #3. Accuracy on batch 2392 on Training is 30.3267342248224\n",
            "Epoch #3. Accuracy on batch 2393 on Training is 30.329730576441104\n",
            "Epoch #3. Accuracy on batch 2394 on Training is 30.326200417536533\n",
            "Epoch #3. Accuracy on batch 2395 on Training is 30.322673205342237\n",
            "Epoch #3. Accuracy on batch 2396 on Training is 30.319148936170212\n",
            "Epoch #3. Accuracy on batch 2397 on Training is 30.316930775646373\n",
            "Epoch #3. Accuracy on batch 2398 on Training is 30.316017090454356\n",
            "Epoch #3. Accuracy on batch 2399 on Training is 30.3125\n",
            "Batch Id 2400 is having training loss of 2985.41943359375\n",
            "54.54372024536133\n",
            "Epoch #3. Accuracy on batch 2400 on Training is 30.312890462307372\n",
            "Epoch #3. Accuracy on batch 2401 on Training is 30.315882597835138\n",
            "Epoch #3. Accuracy on batch 2402 on Training is 30.316271327507284\n",
            "Epoch #3. Accuracy on batch 2403 on Training is 30.307560316139767\n",
            "Epoch #3. Accuracy on batch 2404 on Training is 30.306652806652806\n",
            "Epoch #3. Accuracy on batch 2405 on Training is 30.309642560266003\n",
            "Epoch #3. Accuracy on batch 2406 on Training is 30.312629829663482\n",
            "Epoch #3. Accuracy on batch 2407 on Training is 30.310423588039868\n",
            "Epoch #3. Accuracy on batch 2408 on Training is 30.312110834371108\n",
            "Epoch #3. Accuracy on batch 2409 on Training is 30.308609958506224\n",
            "Epoch #3. Accuracy on batch 2410 on Training is 30.307704272086273\n",
            "Epoch #3. Accuracy on batch 2411 on Training is 30.31198175787728\n",
            "Epoch #3. Accuracy on batch 2412 on Training is 30.303305014504765\n",
            "Epoch #3. Accuracy on batch 2413 on Training is 30.299813587406792\n",
            "Epoch #3. Accuracy on batch 2414 on Training is 30.301501035196686\n",
            "Epoch #3. Accuracy on batch 2415 on Training is 30.29283940397351\n",
            "Epoch #3. Accuracy on batch 2416 on Training is 30.289356640463385\n",
            "Epoch #3. Accuracy on batch 2417 on Training is 30.291046319272127\n",
            "Epoch #3. Accuracy on batch 2418 on Training is 30.28756717651922\n",
            "Epoch #3. Accuracy on batch 2419 on Training is 30.293130165289256\n",
            "Batch Id 2420 is having training loss of 2980.06884765625\n",
            "3435.730224609375\n",
            "Epoch #3. Accuracy on batch 2420 on Training is 30.29223461379595\n",
            "Epoch #3. Accuracy on batch 2421 on Training is 30.29004954582989\n",
            "Epoch #3. Accuracy on batch 2422 on Training is 30.290445728435824\n",
            "Epoch #3. Accuracy on batch 2423 on Training is 30.29470915841584\n",
            "Epoch #3. Accuracy on batch 2424 on Training is 30.288659793814432\n",
            "Epoch #3. Accuracy on batch 2425 on Training is 30.296784830997527\n",
            "Epoch #3. Accuracy on batch 2426 on Training is 30.2971775854965\n",
            "Epoch #3. Accuracy on batch 2427 on Training is 30.297570016474463\n",
            "Epoch #3. Accuracy on batch 2428 on Training is 30.301821737340468\n",
            "Epoch #3. Accuracy on batch 2429 on Training is 30.300925925925927\n",
            "Epoch #3. Accuracy on batch 2430 on Training is 30.298745372274784\n",
            "Epoch #3. Accuracy on batch 2431 on Training is 30.293996710526315\n",
            "Epoch #3. Accuracy on batch 2432 on Training is 30.291820797369503\n",
            "Epoch #3. Accuracy on batch 2433 on Training is 30.293498356614627\n",
            "Epoch #3. Accuracy on batch 2434 on Training is 30.293891170431213\n",
            "Epoch #3. Accuracy on batch 2435 on Training is 30.29684934318555\n",
            "Epoch #3. Accuracy on batch 2436 on Training is 30.295958145260567\n",
            "Epoch #3. Accuracy on batch 2437 on Training is 30.296349466776046\n",
            "Epoch #3. Accuracy on batch 2438 on Training is 30.291615416154162\n",
            "Epoch #3. Accuracy on batch 2439 on Training is 30.290727459016395\n",
            "Batch Id 2440 is having training loss of 2958.9951171875\n",
            "6.525458335876465\n",
            "Epoch #3. Accuracy on batch 2440 on Training is 30.288560016386725\n",
            "Epoch #3. Accuracy on batch 2441 on Training is 30.290233415233416\n",
            "Epoch #3. Accuracy on batch 2442 on Training is 30.2944637740483\n",
            "Epoch #3. Accuracy on batch 2443 on Training is 30.293576104746318\n",
            "Epoch #3. Accuracy on batch 2444 on Training is 30.291411042944784\n",
            "Epoch #3. Accuracy on batch 2445 on Training is 30.29435813573181\n",
            "Epoch #3. Accuracy on batch 2446 on Training is 30.293471597874948\n",
            "Epoch #3. Accuracy on batch 2447 on Training is 30.290032679738562\n",
            "Epoch #3. Accuracy on batch 2448 on Training is 30.29042466312781\n",
            "Epoch #3. Accuracy on batch 2449 on Training is 30.290816326530614\n",
            "Epoch #3. Accuracy on batch 2450 on Training is 30.28738270093839\n",
            "Epoch #3. Accuracy on batch 2451 on Training is 30.283951876019575\n",
            "Epoch #3. Accuracy on batch 2452 on Training is 30.284345699143906\n",
            "Epoch #3. Accuracy on batch 2453 on Training is 30.282192339038303\n",
            "Epoch #3. Accuracy on batch 2454 on Training is 30.282586558044805\n",
            "Epoch #3. Accuracy on batch 2455 on Training is 30.284252850162865\n",
            "Epoch #3. Accuracy on batch 2456 on Training is 30.28464590964591\n",
            "Epoch #3. Accuracy on batch 2457 on Training is 30.28503864930838\n",
            "Прервано пользователем\n"
          ]
        }
      ],
      "source": [
        "# Загрузка словарей с лоссами\n",
        "if last_epoch is not None:\n",
        "    train_losses = checkpoint['losses_train']\n",
        "    val_losses = checkpoint['losses_val']\n",
        "    train_accuracies = checkpoint['accuracies_train']\n",
        "    val_accuracies = checkpoint['accuracies_val']\n",
        "    train_f1_micros = checkpoint['train_f1_micro']\n",
        "    val_f1_micros = checkpoint['val_f1_micro']\n",
        "    train_f1_macros = checkpoint['train_f1_macro']\n",
        "    val_f1_macros = checkpoint['val_f1_macro']\n",
        "    train_f1_weighteds = checkpoint['train_f1_weighted']\n",
        "    val_f1_weighteds = checkpoint['val_f1_weighted']\n",
        "else:\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    train_f1_micros = []\n",
        "    val_f1_micros = []\n",
        "    train_f1_macros = []\n",
        "    val_f1_macros = []\n",
        "    train_f1_weighteds = []\n",
        "    val_f1_weighteds = []\n",
        "\n",
        "if last_epoch is None:\n",
        "    start_epoch = 0\n",
        "else:\n",
        "    start_epoch = last_epoch +1\n",
        "\n",
        "try:\n",
        "    for epoch in range(start_epoch, n_epochs):\n",
        "        start = time.time()\n",
        "        train_loss, train_accuracy, train_f1_micro, train_f1_macro, train_f1_weighted = train(train_data_loader, epoch)\n",
        "        val_loss, val_accuracy, val_f1_micro, val_f1_macro, val_f1_weighted = val(val_data_loader, epoch)\n",
        "        lr_scheduler.step()\n",
        "        print(f\"Эпоха #{epoch} train_loss: {train_loss}, val_loss: {val_loss}\")  \n",
        "        end = time.time()\n",
        "        print(f\"Потрачено {round((end - start) / 60, 1)} минут на {epoch} эпоху\")\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "        train_f1_micros.append(train_f1_micro)\n",
        "        val_f1_micros.append(val_f1_micro)\n",
        "        train_f1_macros.append(train_f1_macro)\n",
        "        val_f1_macros.append(val_f1_macro)\n",
        "        train_f1_weighteds.append(train_f1_weighted)\n",
        "        val_f1_weighteds.append(val_f1_weighted)\n",
        "        \n",
        "\n",
        "        torch.save({'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "                    'losses_train': train_losses,\n",
        "                    'losses_val': val_losses,\n",
        "                    'accuracies_train': train_accuracies,\n",
        "                    'accuracies_val': val_accuracies,\n",
        "                    'f1_micros_train': train_f1_micros,\n",
        "                    'f1_micros_val': val_f1_micros,\n",
        "                    'f1_macros_train': train_f1_macros,\n",
        "                    'f1_macros_val': val_f1_macros,\n",
        "                    'f1_weighteds_train': train_f1_weighteds,\n",
        "                    'f1_weighteds_val': val_f1_weighteds,\n",
        "                    }, os.path.join(checkpoints_path, f'chkpt_classifier_{model_name}_{epoch}.pth'))\n",
        "    \n",
        "        torch.save(model, os.path.join(checkpoints_path, f'model_classifier_{model_name}_{epoch}.pth'))\n",
        "    \n",
        "except KeyboardInterrupt:\n",
        "    print('Прервано пользователем')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(41, 116)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "item = 5509\n",
        "model.eval()\n",
        "pred = model(val_dataset.__getitem__(item)['images'].unsqueeze(0).to(device)).data.max(1,keepdim=True)[1], \n",
        "int(pred[0][0][0]), int(val_dataset.__getitem__(item)['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "RLL0C1078HWu",
        "outputId": "d92014cd-dea2-4e7e-ee4f-d54968066738"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB9O0lEQVR4nO3deVhUZf8G8HsWZoZ930VAxA1ZUpTUyl1yTSvTskCtrF/Zm6mlVu7mkpaWlr72Vr5vaaW2oZlalGVque8rbqDsIAzrzDBzfn8cGBhZBAUGhvtzXXPNzDlnznwHqLl9nuc8j0QQBAFEREREFkJq7gKIiIiI6hPDDREREVkUhhsiIiKyKAw3REREZFEYboiIiMiiMNwQERGRRWG4ISIiIovCcENEREQWheGGiIiILArDDRE1exs2bIBEIsG1a9eM2wICAjBs2DDzFVVBQEAAxo8fb+4yiFoMhhsiC5ecnIx58+bh+PHjlfZduHABr732Gnr27AmVSlUpIFQUEBAAiURS6fbiiy+aHBcfH4+JEyeiXbt2sLGxQZs2bfDcc88hJSWlAT4d1YecnBxMmjQJ7u7usLW1Rd++fXH06NEqj42Li0OXLl2gUqnQunVrzJ07FyUlJSbHpKSkYObMmejbty/s7e0hkUiwZ8+eRvgkRCK5uQsgooaVnJyM+fPnIyAgABERESb7Dhw4gA8//BCdOnVCx44dqwxAFUVERGDatGkm29q1a2fyfMaMGcjOzsbo0aMRHByMK1euYM2aNdi+fTuOHz8OLy+v+vhYVE8MBgOGDh2KEydO4PXXX4ebmxs+/vhj9OnTB0eOHEFwcLDx2J9//hkjR45Enz59sHr1apw6dQqLFi1Ceno61q5dazzuwoULWLZsGYKDgxEaGooDBw6Y46NRC8ZwQ3SPCgoKYGtra+4y7sqIESOQk5MDe3t7rFix4o7hxtfXF08//XSNx7z//vt44IEHIJWWNww//PDD6N27N9asWYNFixbVR+lUT7Zu3Yr9+/djy5YtePzxxwEATzzxBNq1a4e5c+di06ZNxmOnT5+OsLAw7N69G3K5+PXh4OCAxYsX49VXX0WHDh0AAF27dkVWVhZcXFywdetWjB49uvE/GLVo7JYiqoN58+ZBIpHg7NmzeOqpp+Ds7IwHHngAAPDll1+ia9eusLa2houLC8aOHYukpCST11+6dAmPPfYYvLy8oFKp0KpVK4wdOxa5ubnGYyQSCSZPnowffvgBnTt3hlKpREhICHbu3Fmpnps3b2LixInw9PQ0HvfZZ58Z9+/ZswfdunUDAEyYMMHYlbRhwwYAgIuLC+zt7ev0M9BqtSgoKKh2/0MPPWQSbMq2ubi44Ny5c3V6r5MnT2L8+PFo06YNVCoVvLy8MHHiRGRlZdX6HLt370ZERARUKhU6deqE7777rk41AMDnn3+Ofv36wcPDA0qlEp06dTJpqSgjCAIWLVqEVq1awcbGBn379sWZM2cqHZednY3p06cjNDQUdnZ2cHBwwODBg3HixAmT4/bs2QOJRILNmzdj/vz58PX1hb29PR5//HHk5uZCo9FgypQp8PDwgJ2dHSZMmACNRlOnz7Z161Z4enri0UcfNW5zd3fHE088gR9//NF4vrNnz+Ls2bOYNGmSMdgAwEsvvQRBELB161bjNnt7e7i4uNSpDqL6xJYbortQ1uWyePFiCIKAd955B7Nnz8YTTzyB5557DhkZGVi9ejUeeughHDt2DE5OTtBqtYiOjoZGo8Err7wCLy8v3Lx5E9u3b0dOTg4cHR2N5//rr7/w3Xff4aWXXoK9vT0+/PBDPPbYY0hMTISrqysAIC0tDffff78xDLm7u+Pnn3/Gs88+C7VajSlTpqBjx45YsGAB5syZg0mTJuHBBx8EAPTs2fOuPvdvv/0GGxsb6PV6+Pv747XXXsOrr756x9fl5+cjPz8fbm5udXq/X375BVeuXMGECRPg5eWFM2fOYP369Thz5gz+/vtvSCSSGl9/6dIljBkzBi+++CJiY2Px+eefY/To0di5cycGDhxY6zrWrl2LkJAQjBgxAnK5HNu2bcNLL70Eg8GAl19+2XjcnDlzsGjRIgwZMgRDhgzB0aNHMWjQIGi1WpPzXblyBT/88ANGjx6NwMBApKWl4d///jd69+6Ns2fPwsfHx+T4JUuWwNraGjNnzkRCQgJWr14NKysrSKVS3Lp1C/PmzcPff/+NDRs2IDAwEHPmzKn1Zzt27Bi6dOlSKZB2794d69evx8WLFxEaGopjx44BACIjI02O8/HxQatWrYz7iZoEgYhqbe7cuQIA4cknnzRuu3btmiCTyYR33nnH5NhTp04JcrncuP3YsWMCAGHLli01vgcAQaFQCAkJCcZtJ06cEAAIq1evNm579tlnBW9vbyEzM9Pk9WPHjhUcHR2FwsJCQRAE4dChQwIA4fPPP6/xfZcvXy4AEK5evVrl/uHDhwvLli0TfvjhB+HTTz8VHnzwQQGA8MYbb9R4XkEQhIULFwoAhPj4+DseW1HZZ6joq6++EgAIf/75p3Hb559/Xql2f39/AYDw7bffGrfl5uYK3t7ewn333XfPdURHRwtt2rQxPk9PTxcUCoUwdOhQwWAwGLe/+eabAgAhNjbWuK24uFjQ6/Um57t69aqgVCqFBQsWGLf9/vvvAgChc+fOglarNW5/8sknBYlEIgwePNjkHD169BD8/f3r9NlsbW2FiRMnVtr+008/CQCEnTt3CoJQ/veRmJhY6dhu3boJ999/f5Xn37JliwBA+P333+tUF9G9YLcU0V2oeIXQd999B4PBgCeeeAKZmZnGm5eXF4KDg/H7778DgLFlZteuXSgsLKzx/AMGDEBQUJDxeVhYGBwcHHDlyhUAYvfHt99+i+HDh0MQBJP3jY6ORm5ubrVXu9ytuLg4vPHGG3jkkUcwceJE/PHHH4iOjsb777+PGzduVPu6P//8E/Pnz8cTTzyBfv361ek9ra2tjY+Li4uRmZmJ+++/HwBq9fl8fHwwatQo43MHBwfExMTg2LFjSE1Nvas6cnNzkZmZid69e+PKlSvGLsVff/0VWq0Wr7zyikmL0pQpUyqdT6lUGltK9Ho9srKyYGdnh/bt21f5uWJiYmBlZWV8HhUVBUEQMHHiRJPjoqKikJSUVOnqpZoUFRVBqVRW2q5SqYz7K95Xd2zZfqKmgOGG6C4EBgYaH1+6dAmCICA4OBju7u4mt3PnziE9Pd34mqlTp+I///kP3NzcEB0djY8++shkvE2Z1q1bV9rm7OyMW7duAQAyMjKQk5OD9evXV3rPCRMmAIDxfRuKRCLBa6+9hpKSkmov8z1//jxGjRqFzp074z//+U+d3yM7OxuvvvoqPD09YW1tDXd3d+PPvqqf2+3atm1bqeuq7Oqu6i55r8q+ffswYMAA2NrawsnJCe7u7njzzTdN6rh+/ToAmFxdBIjjV5ydnU22GQwGrFy5EsHBwVAqlXBzc4O7uztOnjxZq7+HsqDs5+dXabvBYKjVz6aMtbV1leN0iouLjfsr3ld3bMUASGRuHHNDdBcq/o/cYDBAIpHg559/hkwmq3SsnZ2d8fF7772H8ePH48cff8Tu3bvxr3/9C0uWLMHff/+NVq1aGY+r6jyA2GJT9p4A8PTTTyM2NrbKY8PCwur+weqo7Ms1Ozu70r6kpCQMGjQIjo6O2LFjR50HLgPiVTv79+/H66+/joiICNjZ2cFgMODhhx82/gwa2uXLl9G/f3906NAB77//Pvz8/KBQKLBjxw6sXLnyrupYvHgxZs+ejYkTJ2LhwoVwcXGBVCrFlClTqjxfdX8Pd/o7qQ1vb+8q5yAq21Y2/sfb29u4/fZQlZKSgu7du9f6PYkaGsMN0T0KCgqCIAgIDAysNOdLVUJDQxEaGoq3334b+/fvR69evbBu3bo6XSLt7u4Oe3t76PV6DBgwoMZj7zTo9l6UdZO5u7ubbM/KysKgQYOg0WgQHx9v/GKsi1u3biE+Ph7z5883GSB76dKlWp8jISEBgiCY/AwuXrwIQJyUsDa2bdsGjUaDuLg4kxaUsu7GMv7+/sb62rRpY9yekZFhbHErs3XrVvTt2xeffvqpyfacnJw6D7q+VxEREdi7dy8MBoPJoOJ//vkHNjY2xr/psjmSDh8+bBJkkpOTcePGDUyaNKlR6yaqCbuliO7Ro48+CplMhvnz51f6F7MgCMbLltVqdaWxEKGhoZBKpXW+fFcmk+Gxxx7Dt99+i9OnT1fan5GRYXxcNgdPTk5Ond6jouzsbOj1epNtOp0OS5cuhUKhQN++fY3bCwoKMGTIENy8eRM7duyo1E1TW2WtErf/TFetWlXrcyQnJ+P77783Pler1fjf//6HiIiIWk8mWFUdubm5+Pzzz02OGzBgAKysrLB69WqTY6uqVyaTVfpcW7Zswc2bN2tVU316/PHHkZaWZnKJfGZmJrZs2YLhw4cbx9iEhISgQ4cOWL9+vcnfwtq1ayGRSIxz5BA1BWy5IbpHQUFBWLRoEWbNmoVr165h5MiRsLe3x9WrV/H9999j0qRJmD59On777TdMnjwZo0ePRrt27VBSUoIvvvjCGFTqaunSpfj9998RFRWF559/Hp06dUJ2djaOHj2KX3/91dhVFBQUBCcnJ6xbtw729vawtbVFVFQUAgMDkZubi9WrVwMQx5UAwJo1a+Dk5AQnJydMnjwZgDiYeNGiRXj88ccRGBiI7OxsbNq0CadPn8bixYtNgsK4ceNw8OBBTJw4EefOnTOZ28bOzg4jR46s1edzcHDAQw89hHfffRc6nQ6+vr7YvXs3rl69WuufUbt27fDss8/i0KFD8PT0xGeffYa0tLRKwaQmgwYNgkKhwPDhw/HCCy8gPz8fn3zyCTw8PEy6c9zd3TF9+nQsWbIEw4YNw5AhQ3Ds2DH8/PPPlVpjhg0bhgULFmDChAno2bMnTp06hY0bN5q0+DSWxx9/HPfffz8mTJiAs2fPGmco1uv1mD9/vsmxy5cvx4gRIzBo0CCMHTsWp0+fxpo1a/Dcc8+hY8eOJseWtUSWzfPzxRdf4K+//gIAvP32243wyahFM8clWkTNVdml4BkZGZX2ffvtt8IDDzwg2NraCra2tkKHDh2El19+Wbhw4YIgCIJw5coVYeLEiUJQUJCgUqkEFxcXoW/fvsKvv/5qch4Awssvv1zp/P7+/iaXEwuCIKSlpQkvv/yy4OfnJ1hZWQleXl5C//79hfXr15sc9+OPPwqdOnUS5HK5yWXhV69eFQBUeat4SfHhw4eF4cOHC76+voJCoRDs7OyEBx54QNi8eXOVddbmnLVx48YNYdSoUYKTk5Pg6OgojB49WkhOThYACHPnzjUeV92l4EOHDhV27dolhIWFCUqlUujQocMdL8WvSlxcnBAWFiaoVCohICBAWLZsmfDZZ59Vek+9Xi/Mnz9f8Pb2FqytrYU+ffoIp0+frvS7Ky4uFqZNm2Y8rlevXsKBAweE3r17C7179zYeV3Yp+O01l33eQ4cOmWyv6e+zJtnZ2cKzzz4ruLq6CjY2NkLv3r0rnbvM999/L0RERAhKpVJo1aqV8Pbbb5tcpl6mur8Bfu1QY5AIQh1GnhERERE1cRxzQ0RERBaFY26IqNHl5ubecdK3xlg9/E4T+VlbW5ssi9GcNJWfMZE5sFuKiBrd+PHj8d///rfGYxrjf013ukw+NjbWuMhoc9NUfsZE5sBwQ0SN7uzZs0hOTq7xmDvN31Mffv311xr3+/j4oFOnTg1eR0NoKj9jInNguCEiIiKLwgHFREREZFFa3IBig8GA5ORk2NvbN+i09ERERFR/BEFAXl4efHx8TJYKqUqLCzfJycmVFn0jIiKi5iEpKclkoeGqtLhwU7YycVJSEhwcHMxcDREREdWGWq2Gn5+f8Xu8Ji0u3JR1RTk4ODDcEBERNTO1GVLCAcVERERkURhuiIiIyKIw3BAREZFFYbghIiIii8JwQ0RERBaF4YaIiIgsCsMNERERWZQmEW4++ugjBAQEQKVSISoqCgcPHqz22D59+kAikVS6DR06tBErJiIioqbK7OHmm2++wdSpUzF37lwcPXoU4eHhiI6ORnp6epXHf/fdd0hJSTHeTp8+DZlMhtGjRzdy5URERNQUmT3cvP/++3j++ecxYcIEdOrUCevWrYONjQ0+++yzKo93cXGBl5eX8fbLL7/AxsaG4YaIiIgAmDncaLVaHDlyBAMGDDBuk0qlGDBgAA4cOFCrc3z66acYO3YsbG1tq9yv0WigVqtNbkRERGS5zBpuMjMzodfr4enpabLd09MTqampd3z9wYMHcfr0aTz33HPVHrNkyRI4Ojoab1wRnIiIyLKZvVvqXnz66acIDQ1F9+7dqz1m1qxZyM3NNd6SkpIasUIioiZKEABdkbmrIGoQZl0V3M3NDTKZDGlpaSbb09LS4OXlVeNrCwoK8PXXX2PBggU1HqdUKqFUKu+5ViIii6BOAU5+DRzfBGReBNr0AXpNEe9rsdoyUXNg1pYbhUKBrl27Ij4+3rjNYDAgPj4ePXr0qPG1W7ZsgUajwdNPP93QZRIRNW8lGuDMD8DG0cDKTsCv88RgAwBX9gBfjATW9wFOfwcY9GYrk6i+mLXlBgCmTp2K2NhYREZGonv37li1ahUKCgowYcIEAEBMTAx8fX2xZMkSk9d9+umnGDlyJFxdXc1RNhFR05dyAji2ETi1GSi6Vb7d737gvnFAq27A4c+Bo/8DUo4DWycALm2Anq8A4U8BViqzlU50L8websaMGYOMjAzMmTMHqampiIiIwM6dO42DjBMTEyGVmjYwXbhwAX/99Rd2795tjpKJiJqugiwxzBzbCKSdKt9u7wOEjwUixgFubcu3D3kX6D0DOLgeOPhvIPsKsP014PclwP0vApHPAtZOjf4xiO6FRBAEwdxFNCa1Wg1HR0fk5ubCwcHB3OUQEd07fQmQ8Ctw/Evgwk7AoBO3yxRAh6FAxNNAUF9AKqv5PNoCsRVn/xpAfUPcprAHIicA978EOHg37OcgqkFdvr8ZboiImquMC8CxL4GT3wD5FS7M8I4A7nsa6PwYYONS9/PqdcDpb4F9HwDpZ8VtMgUQNgbo9SrgFlwv5RPVBcNNDRhuiKhZK84Vg8exjcDNw+XbbdzE8BHxFODVuX7eSxCAS7uBv1YCiWUTq0rE1qAHXgNaRdbP+xDVAsNNDRhuiKjZMRiAq38AxzcC57YBJcXidokMaBctjqMJHgTIFQ1XQ+I/wL5VwIUd5dsCHhQvI2/bn5eRU4NjuKkBww0RNRvZV8X5aE58BeRWmIDUvYMYaMLGAPae1b++IaSfF7urTm0GDCXiNs9Q4IEpQKeRgMzs16mQhWK4qQHDDRE1adoC4OyPYqi5trd8u9IRCH1MHBzs28X8LSW5N4ADHwNHNgC6AnGbk794GXnEOEBhY9byyPIw3NSA4YaImhxBAJL+EQcHn/ke0OaX7pCIMwff97Q4zsXK2pxVVq0wGzj0KfDPWqAwS9xm4wpEvQh0e+7uBjQTVYHhpgYMN0TUZKiTxS6n45uArITy7c6BYutH+FjAqZks9qstFMcE7f8QyEkUt1nZAl3HAz1eAhxbmbU8qp5Ob0CxTo9inXivKSl/bLw32aaHpqT8cfkx5duC3O0wb0RIvdZZl+9vdo4SETUmXbE4KPf4RuDyb4BgELdb2QIhI8VQ49/T/N1OdaWwAbo/D3SdAJz9AfhrlTiJ4N8fiZMDhj4hXkbu0cHclTZpBoNQHhxuCxTFOgOKS/TQ6G7bXlJTOCl/XbHOUPra8tdoSgzQG+q/jSOvuKTez1kXbLkhImpogiAub3BsI3BqC1CcU76vdU9xKYROIwGlnZkKbACCACTEi1dYVRw71G6weBl56yizldZYinV65BTqkF2gxa1Crel9gRbZhTro1JlwyTsP36Lz8NUlIsegQorgihTBFcmCC1IEV6TBGSWN1BahspJCZSWDSi4zPlZayaCSl26var9cKh5Ttl8ug4eDEg8Gu9drbeyWqgHDDRE1moJMcYK9YxuB9DPl2x18gfAnxTlpXIPMV19juXEE2LcSOLcdQOlXTuse4mXkwYMAqVnXcK4Vnd6AnELdbeGk9L5AV2V4KdCaLkLqilx0ll5DZ8lVdJZeRaj0KlpJMu/43npIkQ0nZMjckSVzxy25B3KtPJCn9EC+0guFKi+UWLtBqbAyhouyoKGUy6AsCyQmIcU0qCitpFDKpZA04RZDhpsaMNwQUYPS64BLv4jdThd3ll8uLVOKg4Lve1ocJHynpRAsUeYl8TLyE1+XLxHh3lHsrgp9HJBZNUoZBoOA3CJdhXBSFkqqCy9aqOvYzeKOWwiVXkWY9Brus7qOTrgKd6HqIFNo5w+teyjgFQKFoRiK/GTI8pMhUd8Ux2XptXd+Q6mVuDyGQytxfJOjrxiiHVuV31s7N7/uzgoYbmrAcENEDSL9XOlSCJuBgvTy7T73ieNoQh8Xv1wIUKcAf38srkiuzRO3OfoBPV4GusQACttan8pgEJCnKUFO4W0h5bZwUt6yokNOoRZ3M8xEIgGcbRRwtrGCi60CzjYKuNhYobVVDtqWJKBV8UV4FJyH460zsCrKqOoMgGtbwCcC8A4Xl8nwCq15YVKDASjIENf6yr0JqG+Kl+Grb5Y/z0spH7tVEysbwMGnPOwYg49vaSjyBZT2df/BNBKGmxow3BBRvSnKAU5vFbudko+Wb7d1L10KYRzg2cls5TV1+sJb0P3zKawOrYOsUAwDOoUTLgc+iZM+Y5BhsEdecQnyinXIKy6BuvQ+z3hfgnzN3Q9cdVDJxZBiq4CLTel9WWixtSq9L9/voJJDpk4EUk4AycfF+5QTQGEVLTISKeDWXgwxZWHGK7RhwoO+RAw4VQWfsucFVYWtKigdK7T6lLX8VGgJcvAFrFT1/xlqgeGmBgw3RHRPDAbgyu+lSyFsB/QacbtUDgRHi4ODgwc1WheLuegNAvKrChya8uChrhBC8moIJkpo8ZhsLybJtiNAKi4AWiQo8LW+L/5TMgQ3ceeBqbYK2W3hpEJIqSK8ONlYwUpWw1gfgwG4dVUcCF4xzFQcDF5GKhe71yoGGc/OTWsiQ12xGHKMwadiS1Dp8+Lc2p3Lxs20tef2liB77waZqZrhpgYMN0R0V3RF4pw0+9cA2ZfLt3t0Kl8Kwa5+rw5pCIIgoFhnQKG2BIVafY0BRF1NKMkr1lUaLHsvFHIpHFRyOCqlGCQ9iCeKtyJQJ877Y4AMF9wH4lzgBJS4h8BeJYe9yqr0vvyxyuoexjAZ9EDWZdMgk3oS0KgrHyu1AjxDSruVSsOMR4jZWjPqlSav+uBT9lxXeOfzSKTigPEJO+58bB1wnhsiovpSmA0c+g/wz7/Lux+UjkDYaDHU+NzXIIM0tSUGFGn1KNSVoECjFx+XBpLC2x4XlT4uqPC44jFFOn3pOUpQqNOjPv9Jq5RLYa+ygsNtYcP0sXjvUMU2e5UcSnnFYNIfEGYCV/YA+1ZBemUPOmbsRMeMnUDbgeJl5PcyD5C+BMi8WB5kUk4AKSfLl5CoSKYUV1j3jigPMu4dG3aBUnNS2ovzEFU3F5EgAEW3KnR9VdUFliwOFjdzyyVbboiIqnLrOnDgI+DYF+X/WnX0A+5/CejyDKC0h94goEinR6GmQtAoDSMVHxdVFUgq7tOVoFBjekxJA0ysdjuVldQkbBgDirJyACnfb7pNIW/gy7iTj4lXWJ39sXzQbKtu4mXk7YfUfBm5XicO9E45UR5mUk8DJUWVj7WyEcfElA309Q4H3Nub/Uu62TEYxAH1JcWAc0C9nprdUjVguCGiiuNF8jVl4z/Ebhd52km0u/w5gtJ/hRRi10uiIgg/2jyG3eiJXC2QrylBgaYEmpJaXKFyj6xkElhbyWCrlMNaIYONQgYbhbz0vvyxtUIG29selx9f+ThrKxmk0mZ0WXDWZWD/anGpirJxTm7tSi8jfwKAAKSfrTDQ9ziQdqbqy6gV9oB3mGmQcQtumZfnNyMMNzVguCFqvsrGi+QV65CnKR//kV82FkRTPjYk/7bBrXkVgkxhpfEiAh6SnsQLsu3oJSufbO9PfSjW64fhL0NnANUHAYkEsLGSwVohh61SBmsrMVDYKuXGxzZKOWwqPlbITEOLVWkAUZYeYyVub/CWkeYmLw34Z524WKemdACsyklcTb1s7pyKlI5ikPGJKA0yEYBLm2YxcSCZYripAcMNkXkYDEKlwav5FQJKWVjJN7nyxrRVJb+4pF67a2zlBjym+Aex2IYgwzUA4mywJxz64aDPOBS4lA9gtVPKjd0xdkorkxYRlVXTntnVIhWrgSOfAwc+BvJTxW3WzqbjY7zDxUVI+buxCAw3NWC4IaofZWElq0CLrHwtsgs0yMwXJ0rLytcgs0CL7Hwtsgo0yC6dSK2+colEAtgp5XAoHf9RFjzsKo4HUd4eSsr32UmK4Xh2I+QH14kDIYHSFaxjgfv/D3BqXT+FUsMr0QA3j5bOyeLHIGPBeLUUUXOn1wHX9wPnfwIu/CzO4tp2INBxGNB2QJ1mcK0tQRBneq0qqJQFmKwCTem9OPPr3bSiqKyksFOWD161Kx3AandbKDHuKw0oZYNZ7VRy2Cpkd9dSok4RuzQOf17epWHrAUS9AHR7ljMIN0dyJeDfw9xVUBPDcEPUVGgLxFWUz/8krkl0+2RhpzaLN7kKCOoHdBgGtB8M2LhUeTpBEFCg1SM7X4vMAo2xFaW8pUWLzHyN8XF2gRZafd0HyNqr5HC1VcDVTgkXWwXc7MSJ0lxtlXC1E+/LtjvZKMwzhiT9vDgY9eQ35eMyXIOBnq+I89NYwhwlRGTEcENkTvkZwMWfgfM7xFlvS4rL99m4iuGlwzBxwOSFn2A4uw3SnGvAhR3AhR0wSGRIcbwPZxwexN/KHriscTZpbbmbq3lsFTK4lIYSY1CxU5YGGAVcbCs+Vtw2R0kTIghA4gHxMuKLO8u3+90P9PoX0G4wB5USWSiOuSFqbFmXxXBy/icg8W8A5f8J6hz8ke4zAOedHsRxtEdSjgY3bhUhVV2MrHwtinQlaC9JQrT0MKJlhxAivW5y6pOGQOzSd8MuQyQSBF8AEqispBVaUcRw4mZXIaiUbi8LMPc002tTYNAD57cD+z4Ebh4u3SgRV+Tu9Srg192s5RHR3eGA4how3FCjEwQg+Rj0Z7dDf/4nKLLOm+y+LA/Gr0IkviuKwAVDK9R0yTEgTlVf1nLSTpmNh0r+QZfCffDLPwFJxaDkFAR0HAqrkEcAny6W30qhKxLnQDmwBsi+Im6TKYGIJ4EerwBubc1bHxHdE4abGjDcUEPRlhiQkluEG7eKcDMrF5Lr++GVEo+OuXvhZihfNVgnyPCPoQN2GyLxq74rkuFm3KeykqKVsw1aOVuX3sTH3o4quJWOabFTyqseTJufUdoitF2cur7i5GX23mLLRYdhQMADljXramE2cPAT4OD68uURVE5A9+eB7pMAOw+zlkdE9YPhpgYMN3S3dHoDUnKKceNWIW7cKkJS6X3Z8zz1LTwkOYGBsiPoLz0GB0n5AnMFghJ7DOH4Hd1xybEHnFw8jOHFz6U8xLjaKupnvpRiNZDwi7hq9aVfxKutyqicgHYPi1deBfVvWisX18Wta+LyCEe/KJ9O37E10ONl4L6nAaWdWcsjovrFcFMDhhuqzu3hpfxefJyqLq40T4s7ctBfdhSDpIfRS3oaSkmJcV++3BmJ7n2QFzAIyuC+8HV3gZtdPYWXuijRAFf+AM5vEwcuF5a3IkFuDbTtL7bqtHu42iuvmpSbR4H9H5quNeQVJo6n6TQSkPE6CSJLxHBTA4ablkunNyA1txhJ2bUPL7dTyKW43zEbQ6yOoof2H7QuPG0yzkVwaQNJh2Fi90+ryKa3Vo1BDyT9I7bonN8G5CSW75PIgIBeQIfhYthx9DVfnbcTBCDhV/HKp2t7y7cH9RevfArszcnbiCwcw00NGG4sX06hFidv5OLUzVxczsgXx8DcKkJKblGtwkvFsS6tnK3RykmFdvpL8Ev7DTZXdkGSecH0RT5dysezuLdvPl+yggCknhLH6Jz/CUg7bbrfp4vYddVhOODezjw1lmiB09+KLTXpZ8VtUjnQ+TFxjhqvUPPURUSNjuGmBgw3liVfU4LTN3Nx6kYuTtzIwambubieVVjt8VWGlwqP3WyV4krJJVqxheD8T+Ig3byU8pNI5UDgQ2KgaT8EcPBphE/aCLKviJ/33DYg6SAqXqIOt3ZieOs4TAw9DR3gitXAkQ3A32uBvGRxm8IO6DpeXB7BsVXDvj8RNTkMNzVguGm+inV6nEtR42RZkLmRi4SMfFT1F+zvaoOwVk7o4GVfPnDX2RpudqXhpco3KB2Ee/4ncRCuRl2+T2EPBA8Qv+DbDgCsnRrkMzYZeWkVrrz6w3S1ZQff8pYq/171O8ZFnQL8s7Z0eYTSn7+dJxD1IhA50fJ/7kRULYabGjDcNA86vQEX0/Jw8kYuTt7IwckbubiQmlflWkbejiqEtXJEWCsnhLVyRKivI5xsFLV7o7zU8gn1bv8St/MUW2Y6DAMCHxTXsGmJinPFsHdum3ivKyjfZ+0sDkTuMExcEuJur7xKP1e6PMLm8t+BWzug57+AsCda7s+eiIwYbmrAcNP06A0Crmbm40RSaZC5mYuzyeoqlw5wtVWIAaaVE8JbOSK0lSM87Ou4LlDGxfJxJsYZbMveILi8VcK3q+VPfFdXumJxDp3z28QFPQuzyvdZ2YgBp+NwoF30nRehFATg+j5xJuFLu8q3t+4pDhIOjubPn4iMGG5qwHBjXoIgICm7yDg+5kRSDk7fzEWBVl/pWHuVvLQlRgwyYX5O8HFU1f1SaoMBuHmkPNBkXTLd36pb6fiZoeYbONsc6UuApL9Lr7zaDuQmle+TysXJAsuuHHPwLt9n0APn4sRQk3y0dKNEHM/T81XAr1ujfgwiah4YbmrAcNN4BEFAmlpjHB9TFmhyCnWVjrW2kqGzr4MYZPzELiZ/F5vqx8fcSYkWuPpneQtDflr5PpnCdECwvdddfkIyEgQg5YQYcs5tBzLOme73jRTDi5Ut8PfHwK2r4na5Coh4CugxGXANavy6iajZYLipAcNNw8ku0BqDzMkbOThxIxcZeZpKxylkUnT0tkdo6TiZ8FZOCHK3hVx2j10Q2gJxLpRz24CLu0wHBCsdgOBBYqBpOwBQ8XffoLIui7+H89uBG4cq77d2FpdG6PY8YOfe+PURUbPDcFMDhpv6oS7W4fSNXJy8WRpkknJxM6eo0nEyqQTBHnbGAb/hrZzQzssOSnk9TW5XdAu4sFP8Ir0cD5QUl++z8wI6lA4IDngQkNdykDHVL3UKcOEnsUWn6BYQMQ64bxygsDV3ZUTUjNTl+5vzlNMdFWn1OJOca3Ll0pXMgiqPbeNuizDf8iuXQnwcYa2o51l681LL52O5thcwlC95AOcAcUBrxxFiVwgHpJqfgzfQ7TnxRkTUCBhuqJIrGfnYfznLGGQupuVVObNvK2fr8kuwfR3RuZUjHFQNtNp09tXS8RxVTDDnEVIaaIYDniHNZ4ZgIiJqEAw3ZFSk1WPlrxfxn71XKi8Qaa8Ur1hq5SSOlfF1hKtdA849Igji3Cfntom3tFOm+1t1E8NMh2EciEpERCYYbggAcOByFmZ+d9K4dMH9bVwQ6e+C0FaOCG/lBC/HOs4lczcMBvHS4LJAk325fJ9EJl5a3LF0UUdLWfKAiIjqHcNNC6cu1mHJjvP46qC4OrSXgwrvjOqM/h09G6cAfQmQuL800GwvX0cIAGTK8knh2g8GbFwapyYiImrWGG5asF/PpuHtH04jVS1eYTQuqjVmDu4A+4YaN1OmbJbbc9vEpQ+Kssv3KezE2W07DAOCBwJK+4athYiILA7DTQuUla/B/G1nEXdCbCUJcLXB0sfCcH8b14Z7U00ecGl3+fpE2vzyfdYu4iXbHUcAgb0Bq0boAiMiIovFcNOCCIKAuBPJmBd3BrcKdZBKgOcfaoPXBrSDyqqeL9cGgIIs4OLPpXPQ/A7oK0zo5+Arts50HA607lG/K0sTEVGLxm+UFiI5pwhv/3Aav51PBwB08LLHu4+HIayVU/2+Ue7N0jlo4sRFEYUKi1+6BAGdRoiBxqcLL9kmIqIGYfZw89FHH2H58uVITU1FeHg4Vq9eje7du1d7fE5ODt566y189913yM7Ohr+/P1atWoUhQ4Y0YtXNh8EgYNPBRCz9+TzyNSVQyKR4pV9bvNgnCFb3utxBmazLYpg5t73yKtteYeVz0Lh3YKAhIqIGZ9Zw880332Dq1KlYt24doqKisGrVKkRHR+PChQvw8PCodLxWq8XAgQPh4eGBrVu3wtfXF9evX4eTk1PjF98MXM0swIxvT+LgVXHAbpfWTlj2WBiCPe9xkK4gAKmnyifVSz9bYacE8IsqDTTDxBmDiYiIGpFZ15aKiopCt27dsGbNGgCAwWCAn58fXnnlFcycObPS8evWrcPy5ctx/vx5WFnd3RU9LWFtqRK9Af/56ypW/nIRmhIDrK1keOPh9ojpEQDZ3a6ybTCICyCeixMDTc718n1SubjKdsfhQPuhgH0jXUZOREQtRrNYW0qr1eLIkSOYNWuWcZtUKsWAAQNw4MCBKl8TFxeHHj164OWXX8aPP/4Id3d3PPXUU5gxYwZksgYYENsMnU1WY8a3J3HqZi4A4MFgNyweFQo/F5u6n0yvE9duOrdNHEeTn1a+T24NtO0vBpp20eIqz0RERE2A2cJNZmYm9Ho9PD1N/5Xv6emJ8+fPV/maK1eu4LfffsO4ceOwY8cOJCQk4KWXXoJOp8PcuXOrfI1Go4FGU36Vjlqtrr8P0YRoSvRY81sC1u65jBKDAAeVHLOHdcLjXVtBUtM4F0EQL8suzCq9ZQP56WKoubADKM4tP1bpKAaZjsPFYMNVnYmIqAky+4DiujAYDPDw8MD69eshk8nQtWtX3Lx5E8uXL6823CxZsgTz589v5Eob15Hr2Zjx7SkkpOdDBQ1Gt1Ph9Yec4YKLwKm/KwSXCreiW+WP9drqT27rLi530HE4EPAQIFc03gcjIiK6C2YLN25ubpDJZEhLSzPZnpaWBi8vrypf4+3tDSsrK5MuqI4dOyI1NRVarRYKReUv3lmzZmHq1KnG52q1Gn5+fvX0KRpYiUZsSakUTsRtJfmZuJ6UCGVuBv4ryYOrKg8qaIFEAF/W8b2sbMTJ9GxcABtXwKOTOCDYLwqQssuPiIiaD7OFG4VCga5duyI+Ph4jR44EILbMxMfHY/LkyVW+plevXti0aRMMBgOkUvEy5osXL8Lb27vKYAMASqUSSmUDrl5dW3qdaWtJFWGl0raKs/hWQQ4gCABuv6JbphADio1reVipdKuw3doFUNzFmBwiIqImyKzdUlOnTkVsbCwiIyPRvXt3rFq1CgUFBZgwYQIAICYmBr6+vliyZAkA4P/+7/+wZs0avPrqq3jllVdw6dIlLF68GP/617/M+TFEOUnA6a3Vh5WKY1fqQiIzCSJapROOZEhxJEOKW4I9BBtXjOoVhtDgwPKworDjfDJERNRimTXcjBkzBhkZGZgzZw5SU1MRERGBnTt3GgcZJyYmGltoAMDPzw+7du3Ca6+9hrCwMPj6+uLVV1/FjBkzzPURyqmTgV/n3eEgiXhVUXUtKJW2u4iDeEt/Bj+fSsHsH88gM18DiQSI7RGA16Pbw1bZrIZOERERNSizznNjDg02z03uTeC3RTWEFVfA2umuxq+k5xVj7o9n8PPpVABAkLst3n08DF39XeqvfiIioiasWcxzY3EcfYFRa+v1lIIgYOuRG1i4/SzUxSWQSyV4sXcQJvdr2zALXRIREVkAhpsmKim7EG9+fwp7L2UCADr7OmDZY2EI8XE0c2VERERNG8NNE6M3CPjfgWtYvusCCrV6KOVSTB3YDs8+EAh5fS10SUREZMEYbpqQhPQ8vLH1JI4m5gAAuge6YOmjoWjjbmfewoiIiJoRhpsmQKc3YN2ey1j9WwK0egPslHLMHNwBT3VvDendLnRJRETUQjHcmNmpG7l4fesJnE/NAwD0be+Od0aFwsfJ2syVERERNU8MN2ZSrNNj5a8X8cmfV2AQAGcbK8wbEYIR4T41L3RJRERENWK4MYO/r2Rh5rcncS2rEAAwPNwH84Z3gqtdE1gmgoiIqJljuGlEecU6LP35PDb+kwgA8HRQYtHIUAzs5GnmyoiIiCwHw00j+e18Gt76/jRScosBAE92b41ZQzrAQWVl5sqIiIgsC8NNA8vK12DB9rP48XgyAMDf1QZLHg1FzyA3M1dGRERkmRhuGoggCIg7kYz5284iu0ALqQR47sE2eG1AO1gruHQCERFRQ2G4aQApuUV4+/vTiD+fDgDo4GWPZY+FIdzPybyFERERtQAMN/XIYBDw1aFELNlxHvmaEljJJHilXzBe7B0EhZxLJxARETUGhpt6ci2zADO/O4m/r2QDACL8nPDu42Fo52lv5sqIiIhaFoabenI1qwB/X8mGtZUM06PbY3zPAMi4dAIREVGjY7ipJ33be+CtIR0RHeKF1q425i6HiIioxWK4qUfPP9TG3CUQERG1eBzlSkRERBaF4YaIiIgsCsMNERERWRSGGyIiIrIoDDdERERkURhuiIiIyKIw3BAREZFFYbghIiIii8JwQ0RERBaF4YaIiIgsCsMNERERWRSGGyIiIrIoDDdERERkURhuiIiIyKIw3BAREZFFYbghIiIii8JwQ0RERBaF4YaIiIgsCsMNERERWRSGGyIiIrIoDDdERERkURhuiIiIyKIw3BAREZFFYbghIiIii8JwQ0RERBaF4YaIiIgsCsMNERERWRSGGyIiIrIoDDdERERkURhuiIiIyKIw3BAREZFFaRLh5qOPPkJAQABUKhWioqJw8ODBao/dsGEDJBKJyU2lUjVitURERNSUmT3cfPPNN5g6dSrmzp2Lo0ePIjw8HNHR0UhPT6/2NQ4ODkhJSTHerl+/3ogVExERUVNm9nDz/vvv4/nnn8eECRPQqVMnrFu3DjY2Nvjss8+qfY1EIoGXl5fx5unp2YgVExERUVNm1nCj1Wpx5MgRDBgwwLhNKpViwIABOHDgQLWvy8/Ph7+/P/z8/PDII4/gzJkz1R6r0WigVqtNbkRERGS5zBpuMjMzodfrK7W8eHp6IjU1tcrXtG/fHp999hl+/PFHfPnllzAYDOjZsydu3LhR5fFLliyBo6Oj8ebn51fvn4OIiIiaDrN3S9VVjx49EBMTg4iICPTu3Rvfffcd3N3d8e9//7vK42fNmoXc3FzjLSkpqZErJiIiosYkN+ebu7m5QSaTIS0tzWR7WloavLy8anUOKysr3HfffUhISKhyv1KphFKpvOdaiYiIqHkwa8uNQqFA165dER8fb9xmMBgQHx+PHj161Oocer0ep06dgre3d0OVSURERM2IWVtuAGDq1KmIjY1FZGQkunfvjlWrVqGgoAATJkwAAMTExMDX1xdLliwBACxYsAD3338/2rZti5ycHCxfvhzXr1/Hc889Z86PQURERE2E2cPNmDFjkJGRgTlz5iA1NRURERHYuXOncZBxYmIipNLyBqZbt27h+eefR2pqKpydndG1a1fs378fnTp1MtdHICIioiZEIgiCYO4iGpNarYajoyNyc3Ph4OBg7nKIiIioFury/d3srpYiIiIiqgnDDREREVkUhhsiIiKyKAw3REREZFEYboiIiMiiMNwQERGRRWG4ISIiIovCcENEREQWheGGiIiILArDDREREVkUhhsiIiKyKAw3REREZFEYboiIiMiiMNwQERGRRWG4ISIiIovCcENEREQWheGGiIiILArDDREREVkUhhsiIiKyKAw3REREZFEYboiIiMiiMNwQERGRRWG4ISIiIovCcENEREQWheGGiIiILArDDREREVkUhhsiIiKyKAw3REREZFEYboiIiMiiMNwQERGRRWG4ISIiIovCcENEREQWheGGiIiILMpdhZukpCTcuHHD+PzgwYOYMmUK1q9fX2+FEREREd2Nuwo3Tz31FH7//XcAQGpqKgYOHIiDBw/irbfewoIFC+q1QCIiIqK6uKtwc/r0aXTv3h0AsHnzZnTu3Bn79+/Hxo0bsWHDhvqsj4iIiKhO7irc6HQ6KJVKAMCvv/6KESNGAAA6dOiAlJSU+quOiIiIqI7uKtyEhIRg3bp12Lt3L3755Rc8/PDDAIDk5GS4urrWa4FEREREdXFX4WbZsmX497//jT59+uDJJ59EeHg4ACAuLs7YXUVERERkDhJBEIS7eaFer4darYazs7Nx27Vr12BjYwMPD496K7C+qdVqODo6Ijc3Fw4ODuYuh4iIiGqhLt/fd9VyU1RUBI1GYww2169fx6pVq3DhwoUmHWyIiIjI8t1VuHnkkUfwv//9DwCQk5ODqKgovPfeexg5ciTWrl1brwUSERER1cVdhZujR4/iwQcfBABs3boVnp6euH79Ov73v//hww8/rNcCiYiIiOrirsJNYWEh7O3tAQC7d+/Go48+CqlUivvvvx/Xr1+v1wKJiIiI6uKuwk3btm3xww8/ICkpCbt27cKgQYMAAOnp6RykS0RERGZ1V+Fmzpw5mD59OgICAtC9e3f06NEDgNiKc99999VrgURERER1cdeXgqempiIlJQXh4eGQSsWMdPDgQTg4OKBDhw71WmR94qXgREREzU9dvr/ld/smXl5e8PLyMq4O3qpVK07gR0RERGZ3V91SBoMBCxYsgKOjI/z9/eHv7w8nJycsXLgQBoOhzuf76KOPEBAQAJVKhaioKBw8eLBWr/v6668hkUgwcuTIOr8nERERWaa7CjdvvfUW1qxZg6VLl+LYsWM4duwYFi9ejNWrV2P27Nl1Otc333yDqVOnYu7cuTh69CjCw8MRHR2N9PT0Gl937do1TJ8+3XhJOhERERFwl2NufHx8sG7dOuNq4GV+/PFHvPTSS7h582atzxUVFYVu3bphzZo1AMRWIT8/P7zyyiuYOXNmla/R6/V46KGHMHHiROzduxc5OTn44YcfavV+HHNDRETU/DT48gvZ2dlVDhru0KEDsrOza30erVaLI0eOYMCAAeUFSaUYMGAADhw4UO3rFixYAA8PDzz77LN1K5yIiIgs3l2Fm/DwcGNLS0Vr1qxBWFhYrc+TmZkJvV4PT09Pk+2enp5ITU2t8jV//fUXPv30U3zyySe1eg+NRgO1Wm1yIyIiIst1V1dLvfvuuxg6dCh+/fVX4xw3Bw4cQFJSEnbs2FGvBVaUl5eHZ555Bp988gnc3Nxq9ZolS5Zg/vz5DVYTERERNS131XLTu3dvXLx4EaNGjUJOTg5ycnLw6KOP4syZM/jiiy9qfR43NzfIZDKkpaWZbE9LS4OXl1el4y9fvoxr165h+PDhkMvlkMvl+N///oe4uDjI5XJcvny50mtmzZqF3Nxc4y0pKanuH5iIiIiajbuexK8qJ06cQJcuXaDX62v9mqioKHTv3h2rV68GIA4obt26NSZPnlxpQHFxcTESEhJMtr399tvIy8vDBx98gHbt2kGhUNT4fhxQTERE1Pw0yiR+9WXq1KmIjY1FZGQkunfvjlWrVqGgoAATJkwAAMTExMDX1xdLliyBSqVC586dTV7v5OQEAJW2ExERUctk9nAzZswYZGRkYM6cOUhNTUVERAR27txpHGScmJhoXN6BiIiI6E7M3i3V2NgtRURE1Pw0WLfUo48+WuP+nJycupyOiIiIqN7VKdw4OjrecX9MTMw9FURERER0L+oUbj7//POGqoOIiIioXnCkLhEREVkUhhsiIiKyKAw3REREZFEYboiIiMiiMNwQERGRRWG4ISIiIovCcENEREQWheGGiIiILArDDREREVkUhhsiIiKyKAw3REREZFEYboiIiMii1GnhTCIiImq5BIMB+txc6LOzUZKVBX32LZRkZ0GflS3eZ9+CPisLiqAgeM+fZ7Y6GW6IiIhaKEEQYMjPhz4rCyXZt6DPzkJJVjb0t7LF+6wslGRni2EmOxv6W7cAvf6O5zUUFTVC9dVjuCEiaoEMRUXQpaRA7uEJmZ2tucuhemQoLKwQVExbV8pCi/F5djYEna7O7yF1dITcxQUyFxfx3rX03sUVclcXyL28GuCT1R7DDRGRhRO0WhRfvITi06dRdPoUik+fgebSJeO/wGUuLlD4+cGqdWsoWreGorUfrPzEe5mrKyQSiZk/Qctm0GpNuoGqbF25dcvYyiLcRauJ1MYGMlfX0qDiCpmLM+SlQUVWFmJcXSFzdoHc2QkShaIBPmn9YbghIrIggl4PzeXLKD59BsWnT6Ho9Blozp+HoNVWOlZiYwOhsBD67GwUZWej6MSJSsdIbWxg5ecHRevWsGrtB0Vp6LFq3RpWXl6QyPk1cjcEvR4lWVkoSUtHSXoaStLToUtPhz4zCyW3sk3GsBjy8up8folCAZmbK+TOZa0qrqUBpbx1RebsYgwvUpWqAT6l+fCvkoiomRIEAbrERBSdOo3iU6dQdOY0is+eg1BYWOlYqaMjrDt3hqpzZ1iHivdyT08YCgqgS0yENjEJ2qRE6BKToE1KgjbxOkpSUmEoLITmwgVoLlyoXICVFRQ+PmKLj5+fGH5KW3+sWrWyuC/M2igbw1KSno6StDTo0tLLH6enoSQ9AyVpaSjJzKzV2BUjuRxyZ+fS1hXn8oDiUtrKUtbqUto1JLW1adEtbhJBEARzF9GY1Go1HB0dkZubCwcHB3OXQ0RUK4IgoCQ1FUWnTqH41GkUnzmNotNnYFCrKx0rtbGBqlMnqEJDjUHGys+vzl92Bq0Wuhs3oUsqDT+JiWIQSkqCLinpjmM15J6eFbq7Slt/yrq7HB3rVEtTIGi1KMnIgC493bTFJU0ML2WtL1WFyypJpZC7uUHu6Qm5hwfkHu7i87LunwqtLFIHhxYdVoC6fX8z3BARNUElWVlikDl9RmyVOX0a+qysSsdJFAooO3aAdedQqEI7w7pzZygCAyGRyRq0PsFgQElaGrTXE01afMRWoEQY8vNrfL3U0RGKarq75O7ukEgbbxo2QRCgz8kpDyhpaaXhpazFRXxc1c+/OlJ7e8g9PWDlURpcPD1Ln5c+9vCE3NWF3Xp1wHBTA4YbImpq9Gp16WDf8iBTkpJS+UCZDMp27Uy6l5TBwZBYWTV+0TUoCwuVursSxSCkz8is8fUSpbJ8UHPF7i4/P1j5+tbp8xqKi0u7hyp0CaWnlbe+lAaaWl8xZGUFK3f30rDiCbmHO6zKwoqHB6w8PSD38IDUxqbWNVLt1OX7m5GRiKgRGQoLUXz2LIpOn0bxKfHqJd31xMoHSiRQtGljGmQ6dGgW41gkEgnkzs6QOzvDOjy80n5DYSG0STfE7q7bW36SkyFoNNBcSoDmUkLlk8tksPL2NrmiS+7lBYNabdriki6Od6mq2646MheX0laWii0uHqXhRWxxkTk5NWqrEt0dttwQETUQg1YLzfnzxiBTfPoUNJevAAZDpWOt/Pyg6hxi7F5SdeoEmZ2dGao2L0Gngy45udIAZ13idWiTbkAoLq7zOSXW1mJ3UHXdQ6XjXaRN/PLmlo4tN0REjUwoKYEmIUHsXjp1GsWnT6P44kWgiu4Ouadn+VVLIZ2h6hwCubOzGapueiRWVlD4+0Ph719pnyAIKEnPqDDA+Tp0iUnQpadB5uhU2iVUucVFam/f4gfjtjQMN0REdSQYDNBeuy7OI1MWZM6dq7JVQebkZHLVkiqkM6w8PcxQdfMnkUhg5SmOa7GJjDR3OdSEMdwQEdVAMBjEuWTOnEHxmbNikDl7tsqrgaR2dlCFhJQHmc6hsPL1YasBUSNjuCEiKiUIAnRJSWLX0pkz4mXYZ89WOUOsRKWCqmPHCpPihUIR4M/BpkRNAMMNEbVIgiBAd+OG2BJz5oyxZaaqq2skCgWUHTrAunMIVCHiTdm2LecoIWqi+F8mEVk8QRCgu3lTbIk5UxZmzsKQm1vpWImVFZQdOkAV0km8DLssyDSxuWSIqHoMN0RkUcQgk4ziM2fEW2nLjL66INO+vdga0zkE1mVBhpcEEzVrDDdE1GwJgoCSlBRxHpmywb5nzkCfk1P5YCsrqIKDS69YEsOMKjiYQYbIAjHcEFGzULZwZPGZMyZhRn/rVuWD5XIo2wXDOiREnEcmJATK9u04SRtRC8FwQ0RNjiAIKElLqxBkxMG+VS5cKJdDGRxsOkamXTtIlcrGL5yImgSGGyIyO11aujjQ9/QZFJ0RW2X0mVUsriiTQdm2rdilFBIC686doWzfnkGGiEww3BBRo9Klp5detSQO9i06e6bqVaJlMiiDgkrHyHQqDzLNYOFIIjIvhhsiqjNBEGAoKIQhPw96tRqGvDzo8/LK79V5pfsq3OflQZecjJKMjMonlErFIBMSYgwzqg4dILW2bvwPR0TNHsMNUQsk6HTQ5+fDoFZDn5cPQ566UjgxeV7FfVUrW9eKVAplUBuoOoWUX7nUoT2kNjb1+yGJqMViuCFqZgRBgFBYWDmcVNNaUlU4EYqK6qcYKyvI7O0htbeDzN6hhnt7yBzsIXNxgao9gwwRNSyGG6ImxlBYCM2Vq9BeToAm4TI0ly+jJDW1tEVFDX1+PqDX18t7SW1sIHVwgMzeDlJ7h9KgIgYRqd1t9/b2xv1ljyUqFReFJKImh+GGyEz0ajU0ly9De/myGGKuXIY24TJ0ycm1O4FcXh5Gqrs3CSelIcbBATI7O0jt7Lg2EhFZJP6fjaiBlWRnQ5OQAO2VK6UtMQnQJlyuemBtKZmrK5RBQVC2DYKiTRAUfq1KW1jKQ4rE2pqtJkREVWC4IaoHgiCgJD3DpCtJe1m8r3IG3VJyLy8o27SBom0QlEFtS8NMG8idnRuxeiIiy8JwQ1QHgsEAXXKKGGIuXzG2wmguX4YhP7/qF0kksPL1hTIoqDzEBLWBIigIMju7xv0AREQtAMMNURWEkhLobtyApmw8zOUEaC9fgebKleqvNJLJoGjd2tiVpGwbJAaawEDO10JE1IgYbqhFE7RaaK9fN4YY7ZXS+6tXIeh0Vb5GYmUFRWAgFEFtjF1JyqAgWPn7c2FGIqImgOGGWgRDURG0V6+WdyWVhZnExGovq5aoVKbjYUq7khR+frzKiIioCWsS/4f+6KOPsHz5cqSmpiI8PByrV69G9+7dqzz2u+++w+LFi5GQkACdTofg4GBMmzYNzzzzTCNXTU2Z9sYNqLdvR9HxE9BcvgzdjRuAIFR5rNTOTuw+Cgoqv0IpqC2sfLwhkUobuXIiIrpXZg8333zzDaZOnYp169YhKioKq1atQnR0NC5cuAAPD49Kx7u4uOCtt95Chw4doFAosH37dkyYMAEeHh6Ijo42wyegpkKfkwP1zp3IjduGoqNHK+2XOTlVaIUJEruV2raF3MODl1QTEVkQiSBU88/ZRhIVFYVu3bphzZo1AACDwQA/Pz+88sormDlzZq3O0aVLFwwdOhQLFy6847FqtRqOjo7Izc2Fg4PDPdVO5mfQapH/+x7kbotD/h9/AmXjZKRS2N5/P+z69YOyXbAYYlxczFssERHdtbp8f5u15Uar1eLIkSOYNWuWcZtUKsWAAQNw4MCBO75eEAT89ttvuHDhApYtW1blMRqNBhqNxvhcrVbfe+FkVoLBgKKjR5H7YxzUu3bBUOF3quzQAY4jRsBh6FBYeVZu+SMiIstn1nCTmZkJvV4PT09Pk+2enp44f/58ta/Lzc2Fr68vNBoNZDIZPv74YwwcOLDKY5csWYL58+fXa91kHporV8RAs22byRIFci8vOA4fBodhw6Fq386MFRIRUVNg9jE3d8Pe3h7Hjx9Hfn4+4uPjMXXqVLRp0wZ9+vSpdOysWbMwdepU43O1Wg0/P79GrJbuRUlmJtQ//YTcuG0oPnPGuF1qawv76Gg4jhgBm+7dOPCXiIiMzBpu3NzcIJPJkJaWZrI9LS0NXl5e1b5OKpWibdu2AICIiAicO3cOS5YsqTLcKJVKKJXKeq2bGpahsBB58b8hNy4OBfv3l1+qLZfD7oEH4PjICNj17QupSmXeQomIqEkya7hRKBTo2rUr4uPjMXLkSADigOL4+HhMnjy51ucxGAwm42qo+RH0ehT8/TfUcduQ98svMBQWGvepwsPEcTSDB3NQMBER3ZHZu6WmTp2K2NhYREZGonv37li1ahUKCgowYcIEAEBMTAx8fX2xZMkSAOIYmsjISAQFBUGj0WDHjh344osvsHbtWnN+DLoLgiBAc/48cuO2Qb19u8kq2VZ+fnAcPhyOI4ZDERBgviKJiKjZMXu4GTNmDDIyMjBnzhykpqYiIiICO3fuNA4yTkxMhLTCeIqCggK89NJLuHHjBqytrdGhQwd8+eWXGDNmjLk+AtWRLiUFudu3Qx0XB82lBON2maMj7IcMhuOIEbCOiODcM0RETYzeoIdaq8YtzS3kFOdUeX+r+Bb8Hfwxo/sMs9Vp9nluGhvnuTEPfV4e8nbvRm7cNhQePGicLViiUMCub19xHM0DD0DCtZmIiBqFIAjI1+WXhxNNDm4VV74vCyw5mhzkanIh4M6xobNrZ3w17Kt6rbfZzHNDlk3Q6ZC/9y9xgr3ffodQYVyUTbducBgxHA7R0ZAxZBIR3bPikmJjGKkxsFTYX2Iouav3clA4wFnlDCelE5yVznBSmd5723nX86erG4YbqleCIKD4xAlxHM2OHdDn5Bj3KYKC4DhiBByHDYWVr6/5iiQiauJ0Bh1yNbliWKlFYMnR5KCopOiu3stabm0STIyh5fb70mMclY6wklrV8yeuXww3VC+0168jd9t25G6Lg+56onG7zM0NjkOHwmHEcKg6deI4GiJqUAbBgBJDCUoMJdALeugNepQItz03lKBEKIHeoIde0N/5+LLnFY6v9r70+LL3qbj/TrXoDDqotWrkFOcgT5d3V59fLpXDReli0pJSMaC4qFxMnjspnaCSW960Ggw3dNdKbt2C+uefoY7bhqLjx43bJdbWsB84AI7DR8C2x/2QyPlnRkR1JwgC1Fo1MgozkFFUeiusfJ9VnAWdQQe9QV+r8SDNhQSSqltQqmhRcVaJNxu5Df8RCYYbqiODRiMuVBkXh/w//wRKSvtrpVLY9uwJxxHDYd+/P6S2tuYtlIiaLEEQkKvJNQ0p1QQXrUFbL+8pl8ohl8ghl8ohk8ogk8ggl4iP5VK5+LzivbTC/tvvbzu+bJ/J89L3M76XVF7z8aXPHZQOxsBir7CHTCqrl8/f0jDc0B0JBgMKDx9Gblwc8nbthiGvvLlU2amjOMHekCGw8uBClUQtmSAIyNHkIL0wHZlFmdUGloyiDOgMulqf10HhAA8bD7hZu1W6d7d2h6u1K5QyZbWBQirh8iwtDcMNVUuTkIDcH+OQu307SlJSjNvlPt5wHDYcjsOHQRkcbMYKiagxGAQDcjQ5lQKKMcRUaH2py9U3TkonY0Bxt3E3uTeGFxt3KGVcQofqhuGGTAg6HW5t2YKcrVuhOXvOuF1qbw+Hh6PhMHw4bCIjuVAlkQUwCAZkF2cjsyjTGFSqCiyZhZkoEWofWpyVznCzcYOHddWtLWX3ChnntaKGwXBDRoXHjiF13nxoLlwQN8jlsHvoITiOGAG7vn0g5QKkRM2CRq8xBpSsoiwxoBRlGm9lz7OLsusUWlxULnC3djcJLu427uLjCtusZE37MmGyfAw3BH1ODtLfex85W7YAAGROTnB76f/gMHw45M7OZq6OiADTK4cyi2sOLnna2l9GLIEEzirnyq0rFQKLu407XFWuDC3UbDDctGCCICD3xx+R/u5y6LOzAQCOjz0Kj+nTGWqIGolOr0NWcZaxpSWzOBOZheVBpWKAqcsgXIVUATdrN7jZuMFNJbawuFq7ii0vFQbiulq7NvkJ2YjqiuGmhdJcvozUefNReOgQAEAZ3BZe8+bBpmtXM1dG1PyVrdlj0qJSRXDJLMpEjianTud2UDgYA0rF4OJm7WYSWhwUDpzvhFoshpsWxlBUhMx1/0bWZ58BOh0kKhXcJ78Ml9hYSKz4rzeimpRd6pxSkFIpuGQVZxkH4WYVZaFYX1zr88olcpNWFTcb06Bi3M5BuES1wnDTguT/8QdSFy6C7sYNAIBdnz7wfPttKFpxnSciQAwvtzS3kJyfjJv5N03uUwpScDP/Zp3W77GzsqvUolKxlaVsu6PSkXOxENUjhpsWQJeWhrTFS5C3axcAQO7tDa+33oRd//5stqYWRRAEZBVnITk/WbwVJJsEmOT85Fq1uJSFkoohpezKoYrPreXWjfCpGoder4dOV/sxP0R3Q6FQQFoPU40w3FgwoaQEtzZuRMYHH8JQWAjIZHCJjYX7yy9xeQSySGXh5fZWl4pBRqPX1HgOCSRwt3GHr50vvG294WvnCx87H/jY+cDXzhdetl4talI5QRCQmpqKnJwcc5dCLYBUKkVgYCAUinvrfmW4sVBFJ04gZd58aM6JE/FZR0TAa/48qNq3N3NlRHfPIBiQWZRpDC5lXUXGAJOffMe1iCSQwMPGwyS0+NiahheOaylXFmw8PDxgY8NFGanhGAwGJCcnIyUlBa1bt76nvzWGGwujV6uRvnIlcr7+BhAESB0d4TFtKpwef5yzClOTZxAMyCjMQHKBaatLWZBJzk++4+XQUokUnjaeJq0uFYOMl40X52upJb1ebww2rq6u5i6HWgB3d3ckJyejpKQEVvdwkQvDjYUQBAHq7duRtnQZ9FlZAADHkSPh8cbrkLu4mLk6IpHeoEdGUUal7qKKg3bvtDaRVCKFl42XSVdRxSDjaevJeVvqSdkYGxsbGzNXQi1FWXeUXq9nuGnpNFeuInXBAhT+/TcAQNGmDbzmzoVtVHczV0Ytlc6gQ6I6EQk5CbiccxkJOQlIyElAkjrpjtP9yyQyeNl6GbuLTLqP7HzgYePB8NLI2BVFjaW+/tYYbpoxg0aDrH+vR9Ynn0DQ6SBRKuH2f/8H14kTILnHwVhEtaE36JGUl2QSYBJyEnBNfa3aFhi5RA4vWy9jaPG2K211KQ0y7jbukEv5vyYiunv8P0gzlb/3L6QuXAhdYiIAwPahB+E1ezYUfn5mrowskUEw4Gb+TZMQcznnMq7mXq326iMbuQ2CnIIQ5BSEtk5t0dapLdo4toGHjQdkUlkjfwIi89qwYQOmTJliUVedSSQSfP/99xg5cqS5S6mE4aaZ0aWlI33ZUqh3/AwAkHt4wPOtt2A/aCCbjumeCYKA1IJUY3i5lHMJl3Mu40rulWonr1PJVAh0DBQDjHNbY5DxsvXixHRkNuPHj8d///vfStsvXbqE5ORkLF++HEeOHEFKSkqjfEGPGTMGQ4YMadD3uJOAgABMmTIFU6ZMqZfzpaSkwLmJrkPIcNNMCHo9bn31NTJWrYIhPx+QSuHyzNNwe+VfkNlxzhqqG0EQkFGUUWlMzOWcyyjQFVT5GiupVXmIcWprbJHxtfNlSww1SQ8//DA+//xzk23u7u64dOkSwsPDMXHiRDz66KONUou1tTWsre9+UketVnvPc7/Uhl6vh0QiqdVEel5eXg1ez93iP6uagaJTp3HtiTFIW7QIhvx8qMLCELh1CzxnzWKwoTvKKsrCwZSD2HRuExYcWIDYn2PxwNcPoP+W/njhlxfw7qF38d2l73Ay4yQKdAWQS+QIcgxCdEA0Xop4Ce/3eR9xI+NwcNxBfDviWyx7aBmeD3se/Vr3Q2uH1gw21GQplUp4eXmZ3GQyGQYPHoxFixZh1KhRd3XegIAALFq0CDExMbCzs4O/vz/i4uKQkZGBRx55BHZ2dggLC8Phw4eNr9mwYQOcnJxMzrNt2zZ069YNKpUKbm5uJvUEBARg4cKFiImJgYODAyZNmgQA+PbbbxESEgKlUomAgAC89957taq5T58+uH79Ol577TVIJBJjS39ZXXFxcejUqROUSiUSExNx6NAhDBw4EG5ubnB0dETv3r1x9OhRk3NKJBL88MMPAIBr165BIpHgu+++Q9++fWFjY4Pw8HAcOHCgrj/eesGWmyZMn5eHjFUf4NamTeKcNfb24pw1o0dDIuMXCpnK1eSWdyfduoTLuZdxOecysouzqzxeKpGitX1rk1aYtk5t4e/gz3lgqFqCIKBIpzfLe1tbyZpM9/vKlSuxePFizJ49GytXrsQzzzyDnj17YuLEiVi+fDlmzJiBmJgYnDlzpsqaf/rpJ4waNQpvvfUW/ve//0Gr1WLHjh0mx6xYsQJz5szB3LlzAQBHjhzBE088gXnz5mHMmDHYv38/XnrpJbi6umL8+PE11vvdd98hPDwckyZNwvPPP2+yr7CwEMuWLcN//vMfuLq6wsPDA1euXEFsbCxWr14NQRDw3nvvYciQIbh06RLs7e2rfZ+33noLK1asQHBwMN566y08+eSTSEhIgFzeuHGD4aYJEgQB6h07kLZ0KfQZmQAAh+HD4TnjDcjd3MxcHZlbnjbP2JVU8T6jKKPK4yWQwNfO1zgeJsgpCMFOwQhwDGhRywhQ/SjS6dFpzi6zvPfZBdGwUdT+a2v79u2ws7MzPh88eDC2bNlSL7UMGTIEL7zwAgBgzpw5WLt2Lbp164bRo0cDAGbMmIEePXogLS2tyu6bd955B2PHjsX8+fON28LDw02O6devH6ZNm2Z8Pm7cOPTv3x+zZ88GALRr1w5nz57F8uXL7xhuXFxcIJPJYG9vX6kenU6Hjz/+2OT9+/XrZ3LM+vXr4eTkhD/++APDhg2r9n2mT5+OoUOHAgDmz5+PkJAQJCQkoEOHDjXWV98YbpoY7bVrSF2wEAX79wMAFAEB8Jo7B7Y9epi5MmpsgiDgRv4NnMg4gfNZ55GQK4aY1ILUal/jbettDC9BTkFo69wWgQ6BsLHiJGzU8vTt2xdr1641PretxzX1wsLCjI89PT0BAKGhoZW2paenVxlujh8/XqkF5XaRkZEmz8+dO4dHHnnEZFuvXr2watUq6PV6yO6yRV+hUJh8HgBIS0vD22+/jT179iA9PR16vR6FhYVILL1CtzoVz+Pt7Q1A/Bkw3LRQBq0WWZ98gqx/r4eg1UKiUMD1xRfg+txzkHLOmhahUFeIM1lncCLjBE5knMDJjJPVdil5WHugrXN5d1KQUxCCHINgp7Cr8nii+mJtJcPZBdFme++6sLW1Rdu2bRukloqz55Z1O1W1zWAwVPn62gwurs8wVhNra+tKXWexsbHIysrCBx98AH9/fyiVSvTo0QNabc1rt9XlZ9CQGG6agIL9+5E6fwG0168DAGx79YLXnNlQ+PubuTJqKIIg4Lr6ujHEnMg4gUs5l2AQTP8nIJfK0cmlE0LcQtDWqS2CnYPRxrENHJWOZqqcWjqJRFKnriGqWlhYGOLj4zFhwoRav6Zjx47Yt2+fybZ9+/ahXbt2tWq1USgU0OtrN15q3759+Pjjj42XryclJSEzM7PWtZob/0LNqCQjA2nL3oV6+3YAgNzdHZ6zZsJ+8OAmM2iO6ke+Nh+nMk8Zw8zJzJPI1eRWOs7TxhPh7uEIcw9DuHs4Orp25LgYonqWn5+PhIQE4/OrV6/i+PHjcHFxQevWrRulhrlz56J///4ICgrC2LFjUVJSgh07dmDGjBnVvmbatGno1q0bFi5ciDFjxuDAgQNYs2YNPv7441q9Z0BAAP7880+MHTsWSqUSbjWM4QwODsYXX3yByMhIqNVqvP766/d0KXtjY7gxA0GvR87mzUh/fyUMeXmAVArnp56C+6v/gqyGUejUPBgEA67mXjW2yJzIOIHLOZchQDA5TiFVIMQtBGFuYQhzF29etk133ggiS3H48GH07dvX+Hzq1KkAxK6YDRs2NEoNffr0wZYtW7Bw4UIsXboUDg4OeOihh2p8TZcuXbB582bMmTMHCxcuhLe3NxYsWHDHwcRlFixYgBdeeAFBQUHQaDQQBKHaYz/99FNMmjQJXbp0gZ+fHxYvXozp06fX5SOalUSo6dNZILVaDUdHR+Tm5sLBwaHR37/ozBmkzpuP4lOnAACqkBB4zZsH69DOjV4L1Y9cTS5OZZ4yhplTGaeQp8urdJyvna+xRSbcPRztndvzkmtq0oqLi3H16lUEBgZCpVKZuxxqAWr6m6vL9zdbbhqJPj8fGR9+iFtfbgQMBkjt7OD+2hQ4jx3LOWuaEb1Bj8u5l03GylzNvVrpOJVMhRC3EJMuJjdrXsZPRNQYGG4amCAIyNu1G2mLF6MkPR0A4DBkCDxmzoCVh4eZq6M7uVV8C6cyT+F4+nGczDyJ05mnq1yeoLV9a2OICXMPQ7BzMKykbJUham727t2LwYMHV7s/Pz+/EaupveZad0NhuGlA2sREpC5chIK9ewEAVq1bw2vOHNg90MvMlVFVSgwluHTrkkmrTGJe5TkdbOQ2CHULNYaZUPdQuKhczFAxEdW3yMhIHD9+3Nxl1FlzrbuhMNw0AINWi+zPPkPm2nUQNBpIrKzgOmkSXCc9D6mSV740FZlFmcYQczLjJM5knaly5etAx0CEuYUh3CMcYW5haOvUluspEVkoa2vrBpsbpyE117obCsNNPSv45yBS58+H9soVAIBNj/vhNWcOlIGBZq6sZdPpdbhw64LJBHk3829WOs7eyh6h7hVaZdxCOacMEVEzw3BTT0qyspD+7rvI/TEOACBzdYXnzJlwGDaUc9aYgU6vw4GUAziUeggnMk7gbNZZaPQak2MkkCDIKchk0G+gYyCkEqmZqiYiovrAcFNPCg8dEoONRALnJ8fCfcoUyMxwqXlLptVrcSD5AHZf343fE3+vdDm2o9LRZE6ZULdQ2Cs4rxARkaVhuKkn9tHRcImNgcPQobC+bQEyajhavRb7k/dj97Xd2JO0xyTQuFu7o7dfb0S4RyDcPRz+Dv5sRSMiagEYbuqJRCKB56xZ5i6jRSgLNLuu7cKepD3I15Vf4uhh7YGBAQMxyH8QIjwi2MVERNQCMdxQs6DRa7D/5n7svr672kATHRCNcPdwBhoianI2bNiAKVOmICcnx9yl3BOJRILvv/8eI0eONHcpNWK4oSarLNDsui620FScPM/DxgOD/AdhUMAgBhoiqmT8+PH473//W2n7pUuXkJycjOXLl+PIkSNISUlplC/rMWPGGFfYpobHcENNikavwb6b+4wtNFUFmuiAaIS5hzHQEFGNHn74YXz++ecm29zd3XHp0iWEh4dj4sSJePTRRxulFmtr63taVVur1UKhUNRjRZaN3w5kdhq9BvGJ8Zjx5wz0/qY3Xv39Vfx05ScU6ArgaeOJpzs+jS8Gf4FfHv8FM7rP4FgaIqoVpVIJLy8vk5tMJsPgwYOxaNEijBo16q7OGxAQgEWLFiEmJgZ2dnbw9/dHXFwcMjIy8Mgjj8DOzg5hYWE4fPiw8TUbNmyAk5OTyXm2bduGbt26QaVSwc3NzaSegIAALFy4EDExMXBwcMCkSZMAAN9++y1CQkKgVCoREBCA9957r1Y1v/nmm4iKiqq0PTw8HAsWLAAAHDp0CAMHDoSbmxscHR3Ru3dvHD16tK4/niaB3xBkFsUlxYhPjMcbf76Bh75+CFN+n4IdV3dUCjS7H9/NQEPUlAgCoC0wz00QzP3pjVauXIlevXrh2LFjGDp0KJ555hnExMTg6aefxtGjRxEUFISYmBgI1dT8008/YdSoURgyZAiOHTuG+Ph4dO/e3eSYFStWIDw8HMeOHcPs2bNx5MgRPPHEExg7dixOnTqFefPmYfbs2diwYcMd6x03bhwOHjyIy5cvG7edOXMGJ0+exFNPPQUAyMvLQ2xsLP766y/8/fffCA4OxpAhQ5CXl1fdaZssdktRoykuKca+m/uw6/ou/JH0BwpLCo37vGy9MNBfvMqJXU5ETZiuEFjsY573fjMZUNjW+vDt27fDzs7O+Hzw4MHYsmVLvZQyZMgQvPDCCwCAOXPmYO3atejWrRtGjx4NAJgxYwZ69OiBtLQ0eHl5VXr9O++8g7Fjx2L+/PnGbeHh4SbH9OvXD9OmTTM+HzduHPr374/Zs2cDANq1a4ezZ89i+fLlGD9+fI31hoSEIDw8HJs2bTK+fuPGjYiKijIu29CvXz+T16xfvx5OTk74448/MGzYsNr8WJqMJvEN8tFHHyEgIAAqlQpRUVE4ePBgtcd+8sknePDBB+Hs7AxnZ2cMGDCgxuPJvIpLivHr9V/xxh9voPc3vTFlzxT8fPVnFJYUwsvWC890egZfDvkSux7bhTe6vcEWGiKqN3379sXx48eNtw8//LDezh1WYT4zT09PAEBoaGilbenp6VW+/vjx4+jfv3+N7xEZGWny/Ny5c+jVy3Th5V69euHSpUvQ6/V3rHncuHHYtGkTAEAQBHz11VcYN26ccX9aWhqef/55BAcHw9HREQ4ODsjPz0diYuUFhJs6s7fcfPPNN5g6dSrWrVuHqKgorFq1CtHR0bhw4QI8PDwqHb9nzx48+eST6NmzJ1QqFZYtW4ZBgwbhzJkz8PX1NcMnoNsVlxTjr5t/Yde1Xfjjxh8mi1F623qLLTQBgxDqFsogQ9TcWNmILSjmeu86sLW1bbDFJK2srIyPyyYHrWqbwWCo8vW1GVxsa1v7VqraePLJJzFjxgwcPXoURUVFSEpKwpgxY4z7Y2NjkZWVhQ8++AD+/v5QKpXo0aMHtFptvdbRGMwebt5//308//zzmDBhAgBg3bp1+Omnn/DZZ59h5syZlY7fuHGjyfP//Oc/+PbbbxEfH4+YmJhGqZkqKyopwl83/8Lua7urDDRll22HuoVylmCi5kwiqVPXEFUtLCwM8fHxxu++2ujYsSP27dtnsm3fvn1o164dZDLZHV/fqlUr9O7dGxs3bkRRUREGDhxo0oiwb98+fPzxx8ZL1pOSkpCZmVnr+poSs4YbrVaLI0eOYFaFmX2lUikGDBiAAwcO1OochYWF0Ol0cHFxqXK/RqOBRlO+YKJarb63osmoLNDsurYLf974k4GGiJqF/Px8JCQkGJ9fvXoVx48fh4uLC1q3bt0oNcydOxf9+/dHUFAQxo4di5KSEuzYsQMzZsyo9jXTpk1Dt27dsHDhQowZMwYHDhzAmjVr8PHHH9f6fceNG4e5c+dCq9Vi5cqVJvuCg4PxxRdfIDIyEmq1Gq+//vo9Xb5uTmYNN5mZmdDr9ca+yTKenp44f/58rc4xY8YM+Pj4YMCAAVXuX7JkicmALbo3RSVF2HtjL3Zf310p0PjY+mBQwCAM8h+Ezm6dGWiIqEk6fPgw+vbta3w+depUAGK3TG2uPKoPffr0wZYtW7Bw4UIsXboUDg4OeOihh2p8TZcuXbB582bMmTMHCxcuhLe3NxYsWHDHwcQVPf7445g8eTJkMlmliQs//fRTTJo0CV26dIGfnx8WL16M6dOn38WnMz+JUN11ao0gOTkZvr6+2L9/P3r06GHc/sYbb+CPP/7AP//8U+Prly5dinfffRd79uwxGdxVUVUtN35+fsjNzYUDV+2ulUJdIfbe3Ivd13Zj7829VQaa6IBohLiGMNAQWZDi4mJcvXoVgYGBUKlU5i6HWoCa/ubUajUcHR1r9f1t1pYbNzc3yGQypKWlmWyv7tK5ilasWIGlS5fi119/rTbYAOIkTkqlsl7qbUnKAs2ua7vw182/TAKNr52vscuJgYaIiJoas4YbhUKBrl27Ij4+3tg8ZjAYEB8fj8mTJ1f7unfffRfvvPMOdu3aVelSObo3uZpcLD+0HLuu7UKxvti4vSzQRAdEo5NrJwYaIrJIe/fuxeDBg6vdn5+fX+0+c2qudTcUs18tNXXqVMTGxiIyMhLdu3fHqlWrUFBQYBxBHhMTA19fXyxZsgQAsGzZMsyZMwebNm1CQEAAUlNTAQB2dnYmkzVR3Z3MOInX/3gdyQXiZZ6+dr5il5M/Aw0RtQyRkZE4fvy4ucuos+Zad0Mxe7gZM2YMMjIyMGfOHKSmpiIiIgI7d+40DjJOTEyEVFo+F8ratWuh1Wrx+OOPm5xn7ty5mDdvXmOWbjEEQcAXZ7/AyiMrUSKUwM/eDwt7LUQXjy4MNETUolhbWzfY3DgNqbnW3VDMOqDYHOoyIKklyNXk4u19b2NP0h4AwCD/QZjXcx7sFfZmrYuIzI8DiqmxWcSAYjKvit1QVlIrvNHtDYxpP4atNURE1Kwx3LRAgiDgy3Nf4v0j76PEUIJWdq2wos8KhLiGmLs0IiKie8Zw08LkanIxe99s/J70OwBgoP9AzO85n91QRERkMRhuWpBTGafw+p+v42b+TVhJrTA9cjqe7PAku6GIiMiicEnmFkAQBHx59kvE7IzBzfyb8LXzxReDv8BTHZ9isCEionqxZ88eSCQS5OTkmLsUhhtLl6vJxZTfp2DZoWUoMZRgoP9AbB6+GSFuHF9DRJZr/PjxkEgklW4JCQn4888/MXz4cPj4+EAikeCHH34wd7lmce3aNUgkknqbH6dnz55ISUmBo6NjvZzvXjDcWLDTmacxZvsY/Jb0G+RSOWZ1n4X3er8HBwUvgSciy/fwww8jJSXF5BYYGIiCggKEh4fjo48+MneJ90Sn0zXK+2i12lodp1Ao4OXl1SR6BBhuLJAgCNh4biOe+fkZYzfUl4O/ZDcUEbUoSqUSXl5eJjeZTIbBgwdj0aJFGDVq1F2dNyAgAIsWLUJMTAzs7Ozg7++PuLg4ZGRk4JFHHoGdnR3CwsJw+PBh42uysrLw5JNPwtfXFzY2NggNDcVXX31lcl6DwYB3330Xbdu2hVKpROvWrfHOO+8AKG9l+eabb9C7d2+oVCps3LgRBoMBCxYsQKtWraBUKo0T4dZGYGAgAOC+++6DRCJBnz59AIitXiNHjsQ777wDHx8ftG/fHgDwxRdfIDIyEvb29vDy8sJTTz2F9PR04/lu75basGEDnJycsGvXLnTs2BF2dnbGwNnQGG4sjFqrxtQ9U7H04FKUGEowoPUAdkMRUb0RBAGFukKz3JrSnLMrV65Er169cOzYMQwdOhTPPPMMYmJi8PTTT+Po0aMICgpCTEyMsebi4mJ07doVP/30E06fPo1JkybhmWeewcGDB43nnDVrFpYuXYrZs2fj7Nmz2LRpk3G2/jIzZ87Eq6++inPnziE6OhoffPAB3nvvPaxYsQInT55EdHQ0RowYgUuXLt3xM5S996+//oqUlBR89913xn3x8fG4cOECfvnlF2zfvh2A2FK0cOFCnDhxAj/88AOuXbuG8ePH1/gehYWFWLFiBb744gv8+eefSExMxPTp02v1M74XvFrKgpzJPINpf0zDzfybkEvlmB45HU91YGsNEdWfopIiRG2KMst7//PUP7Cxsqn18du3bzdZc3Dw4MHYsmVLvdQyZMgQvPDCCwCAOXPmYO3atejWrRtGjx4NAJgxYwZ69OiBtLQ0eHl5wdfX1+RL/ZVXXsGuXbuwefNmdO/eHXl5efjggw+wZs0axMbGAgCCgoLwwAMPmLzvlClT8Oijjxqfr1ixAjNmzMDYsWMBiOsv/v7771i1atUdu93c3d0BAK6urvDy8jLZZ2tri//85z9QKBTGbRMnTjQ+btOmDT788EN069YN+fn51a7tqNPpsG7dOgQFBQEAJk+ejAULFtRYV31guLEAgiBg0/lNWHF4BUoMJfC188WK3ivQ2a2zuUsjIjKbvn37Yu3atcbntra29XbusLAw4+Oy1pXQ0NBK29LT0+Hl5QW9Xo/Fixdj8+bNuHnzJrRaLTQaDWxsxLB27tw5aDQa9O/fv8b3jYyMND5Wq9VITk5Gr169TI7p1asXTpw4cU+fLzQ01CTYAMCRI0cwb948nDhxArdu3YLBYAAgrgHZqVOnKs9jY2NjDDYA4O3tbdKV1VAYbpq5PG0e5u6fi1+u/wIA6N+6Pxb0WsBBw0TUIKzl1vjnqX/M9t51YWtr22CLSVpZWRkfl7WOV7WtLAAsX74cH3zwAVatWoXQ0FDY2tpiypQpxsG61ta1+2z1GdDq8j4FBQWIjo5GdHQ0Nm7cCHd3dyQmJiI6OrrGAccVfyaA+HNpjO5Fhptm7EzWGUzfMx038m9ALpVjWtdpGNdxHLuhiKjBSCSSOnUNkWjfvn145JFH8PTTTwMQQ8/FixeNLR7BwcGwtrZGfHw8nnvuuVqd08HBAT4+Pti3bx969+5t8l7du3e/4+vLWmb0ev0djz1//jyysrKwdOlS+Pn5AYDJgOmmhuGmGRIEAV+d/worDq+AzqCDr50vlj+0HKHuoXd+MRFRC5efn4+EhATj86tXr+L48eNwcXFB69atG+Q9g4ODsXXrVuzfvx/Ozs54//33kZaWZgw3KpUKM2bMwBtvvAGFQoFevXohIyMDZ86cwbPPPlvteV9//XXMnTsXQUFBiIiIwOeff47jx49j48aNd6zJw8MD1tbW2LlzJ1q1agWVSlXtHDWtW7eGQqHA6tWr8eKLL+L06dNYuHDh3f0wGgHDTTNzezdUP79+WNBrARyV5p80iYioOTh8+DD69u1rfD516lQAQGxsLDZs2NAg7/n222/jypUriI6Oho2NDSZNmoSRI0ciNzfXeMzs2bMhl8sxZ84cJCcnw9vbGy+++GKN5/3Xv/6F3NxcTJs2Denp6ejUqRPi4uIQHBx8x5rkcjk+/PBDLFiwAHPmzMGDDz6IPXv2VHmsu7s7NmzYgDfffBMffvghunTpghUrVmDEiBF1+jk0FonQlK6tawRqtRqOjo7Izc2Fg0PzGpdyNusspu2Zxm4oImoUxcXFuHr1KgIDA6FSqcxdDrUANf3N1eX7my03zYAgCPjmwjd499C70Bl08LH1wYreK9gNRUREVAVO4tfE5WnzMP2P6Xjnn3egM+jQ168vNg/fzGBDRNQA9u7dCzs7u2pvzcnixYur/RyDBw82d3kNii03TdjZrLOY/sd0JOUlQS6R47Wur+GZTs+wG4qIqIFERkbW20KS5vbiiy/iiSeeqHJfbS89b64Ybpqg27uhvG29saL3CoS5h935xUREdNesra0bbG6cxubi4gIXFxdzl2EWDDdNTL42H/MOzMOua7sAAH38+mBRr0W8GoqIiKiWGG6akHNZ5zDtj2nGbqgpXacgplMMu6GIiIjqgOGmCRAEAZsvbMayQ8uM3VDLey9HuHu4uUsjIiJqdhhuzCxfm4/5B+Zj57WdAIA+rfpg0QPshiIiIrpbDDdmdD77PKbtmYbEvER2QxEREdUTznNjBmXdUON+GofEvER42Xrh84c/R2xILIMNEZEF2rBhA5ycnMxdxj2TSCT44YcfzF3GHTHcNLJ8bT5m/DkDC/9eCK1Bi96temPr8K2I8Igwd2lERBZj/PjxkEgklW4JCQn4888/MXz4cPj4+DTal/WYMWNw8eLFBn8fEjHcNKLz2ecx9qex+Pnaz5BJZJjWdRo+7Pchx9cQETWAhx9+GCkpKSa3wMBAFBQUIDw8HB999FGj1WJtbQ0PD4+7fr1Wq63Haiwfw00jqNgNdV19HV62Xtjw8AaM7zweUgl/BUREDUGpVMLLy8vkJpPJMHjwYCxatAijRo26q/MGBARg0aJFiImJgZ2dHfz9/REXF4eMjAw88sgjsLOzQ1hYGA4fPmx8TVXdUtu2bUO3bt2gUqng5uZmUk9AQAAWLlyImJgYODg4YNKkSQCAb7/9FiEhIVAqlQgICMB7771Xq5rffPNNREVFVdoeHh6OBQsWAAAOHTqEgQMHws3NDY6OjujduzeOHj1a1x9Pk8Bv1gZWoCvAjL3l3VAPtXoIW4ZtYTcUETVLgiDAUFholpsgCOb++EYrV65Er169cOzYMQwdOhTPPPMMYmJi8PTTT+Po0aMICgpCTExMtTX/9NNPGDVqFIYMGYJjx44hPj4e3bt3NzlmxYoVCA8Px7FjxzB79mwcOXIETzzxBMaOHYtTp05h3rx5mD17NjZs2HDHeseNG4eDBw/i8uXLxm1nzpzByZMn8dRTTwEA8vLyEBsbi7/++gt///03goODMWTIEOTl5d39D8pMeLVUA7qQfQHT/5iOa+prkElkeLXLq4gNiWVrDRE1W0JRES506WqW925/9AgkNja1Pn779u0mi10OHjwYW7ZsqZdahgwZghdeeAEAMGfOHKxduxbdunXD6NGjAQAzZsxAjx49kJaWBi8vr0qvf+eddzB27FjMnz/fuC083HRus379+mHatGnG5+PGjUP//v0xe/ZsAEC7du1w9uxZLF++HOPHj6+x3pCQEISHh2PTpk3G12/cuBFRUVHG5Sb69etn8pr169fDyckJf/zxB4YNG1abH0uTwW/ZBiAIArZe3IpxO8bhmvoaPG08seHhDZjQeQKDDRFRI+nbty+OHz9uvH344Yf1du6wsPK1/jw9PQEAoaGhlbalp6dX+frjx4+jf//+Nb5HZGSkyfNz586hV69eJtt69eqFS5cuQa/X37HmcePGYdOmTQDE76mvvvoK48aNM+5PS0vD888/j+DgYDg6OsLBwQH5+flITEy847mbGrbc1LMCXQEWHFiAHVd3AAAe9H0Qix9YDCeVk3kLIyKqBxJra7Q/esRs710Xtra2DbYIppWVlfFx2RQeVW0zGAxVvr42q3Lb2treS4mVPPnkk5gxYwaOHj2KoqIiJCUlYcyYMcb9sbGxyMrKwgcffAB/f38olUr06NGjWQ5mZripR+yGIiJLJ5FI6tQ1RFULCwtDfHw8JkyYUOvXdOzYEfv27TPZtm/fPrRr1w4ymeyOr2/VqhV69+6NjRs3oqioCAMHDjS5gmvfvn34+OOPMWTIEABAUlISMjMza11fU8JwU09+T/wdr//5OjR6DTxsPLCi9wrc53GfucsiIqLb5OfnIyEhwfj86tWrOH78OFxcXNC6detGqWHu3Lno378/goKCMHbsWJSUlGDHjh2YMWNGta+ZNm0aunXrhoULF2LMmDE4cOAA1qxZg48//rjW7ztu3DjMnTsXWq0WK1euNNkXHByML774ApGRkVCr1Xj99ddr1cLUFLFJoZ60d2kPpUyJB3wfwNbhWxlsiIiaqMOHD+O+++7DffeJ/5+eOnUq7rvvPsyZM6fRaujTpw+2bNmCuLg4REREoF+/fjh48GCNr+nSpQs2b96Mr7/+Gp07d8acOXOwYMGCOw4mrujxxx9HVlYWCgsLMXLkSJN9n376KW7duoUuXbrgmWeewb/+9a97mpvHnCRCU7q2rhGo1Wo4OjoiNzcXDg4O9Xru6+rr8LP3YzcUEVmE4uJiXL16FYGBgVCpVOYuh1qAmv7m6vL9zW6peuTv4G/uEoiIiFo8NjEQERGV2rt3L+zs7Kq9NVXNte6GwpYbIiKiUpGRkTh+/Li5y6iz5lp3Q2G4ISIiKmVtbd1gc+M0pOZad0NhtxQRERFZFIYbIiKqUQu7qJbMqL7+1hhuiIioSmXLCRQWFpq5EmopypZ6qM2MyzXhmBsiIqqSTCaDk5OTcfFHGxsb45pJRPXNYDAgIyMDNjY2kMvvLZ4w3BARUbW8vLwAVL+6NVF9kkqlaN269T2HaIYbIiKqlkQigbe3Nzw8PKDT6cxdDlk4hUIBqfTeR8ww3BAR0R3JZLJ7HgdB1Fg4oJiIiIgsCsMNERERWRSGGyIiIrIoLW7MTdkEQWq12syVEBERUW2VfW/XZqK/Fhdu8vLyAAB+fn5mroSIiIjqKi8vD46OjjUeIxFa2LzaBoMBycnJsLe3r/fJqNRqNfz8/JCUlAQHB4d6PTfVHX8fTQt/H00Lfx9ND38nNRMEAXl5efDx8bnj5eItruVGKpWiVatWDfoeDg4O/MNsQvj7aFr4+2ha+Ptoevg7qd6dWmzKcEAxERERWRSGGyIiIrIoDDf1SKlUYu7cuVAqleYuhcDfR1PD30fTwt9H08PfSf1pcQOKiYiIyLKx5YaIiIgsCsMNERERWRSGGyIiIrIoDDdERERkURhu6slHH32EgIAAqFQqREVF4eDBg+YuqcVasmQJunXrBnt7e3h4eGDkyJG4cOGCucuiUkuXLoVEIsGUKVPMXUqLdfPmTTz99NNwdXWFtbU1QkNDcfjwYXOX1SLp9XrMnj0bgYGBsLa2RlBQEBYuXFir9ZOoegw39eCbb77B1KlTMXfuXBw9ehTh4eGIjo5Genq6uUtrkf744w+8/PLL+Pvvv/HLL79Ap9Nh0KBBKCgoMHdpLd6hQ4fw73//G2FhYeYupcW6desWevXqBSsrK/z88884e/Ys3nvvPTg7O5u7tBZp2bJlWLt2LdasWYNz585h2bJlePfdd7F69Wpzl9as8VLwehAVFYVu3bphzZo1AMT1q/z8/PDKK69g5syZZq6OMjIy4OHhgT/++AMPPfSQuctpsfLz89GlSxd8/PHHWLRoESIiIrBq1Spzl9XizJw5E/v27cPevXvNXQoBGDZsGDw9PfHpp58atz322GOwtrbGl19+acbKmje23NwjrVaLI0eOYMCAAcZtUqkUAwYMwIEDB8xYGZXJzc0FALi4uJi5kpbt5ZdfxtChQ03+W6HGFxcXh8jISIwePRoeHh6477778Mknn5i7rBarZ8+eiI+Px8WLFwEAJ06cwF9//YXBgwebubLmrcUtnFnfMjMzodfr4enpabLd09MT58+fN1NVVMZgMGDKlCno1asXOnfubO5yWqyvv/4aR48exaFDh8xdSot35coVrF27FlOnTsWbb76JQ4cO4V//+hcUCgViY2PNXV6LM3PmTKjVanTo0AEymQx6vR7vvPMOxo0bZ+7SmjWGG7JoL7/8Mk6fPo2//vrL3KW0WElJSXj11Vfxyy+/QKVSmbucFs9gMCAyMhKLFy8GANx33304ffo01q1bx3BjBps3b8bGjRuxadMmhISE4Pjx45gyZQp8fHz4+7gHDDf3yM3NDTKZDGlpaSbb09LS4OXlZaaqCAAmT56M7du3488//0SrVq3MXU6LdeTIEaSnp6NLly7GbXq9Hn/++SfWrFkDjUYDmUxmxgpbFm9vb3Tq1MlkW8eOHfHtt9+aqaKW7fXXX8fMmTMxduxYAEBoaCiuX7+OJUuWMNzcA465uUcKhQJdu3ZFfHy8cZvBYEB8fDx69OhhxspaLkEQMHnyZHz//ff47bffEBgYaO6SWrT+/fvj1KlTOH78uPEWGRmJcePG4fjx4ww2jaxXr16Vpka4ePEi/P39zVRRy1ZYWAip1PSrWCaTwWAwmKkiy8CWm3owdepUxMbGIjIyEt27d8eqVatQUFCACRMmmLu0Funll1/Gpk2b8OOPP8Le3h6pqakAAEdHR1hbW5u5upbH3t6+0ngnW1tbuLq6chyUGbz22mvo2bMnFi9ejCeeeAIHDx7E+vXrsX79enOX1iINHz4c77zzDlq3bo2QkBAcO3YM77//PiZOnGju0po1XgpeT9asWYPly5cjNTUVERER+PDDDxEVFWXuslokiURS5fbPP/8c48ePb9xiqEp9+vThpeBmtH37dsyaNQuXLl1CYGAgpk6diueff97cZbVIeXl5mD17Nr7//nukp6fDx8cHTz75JObMmQOFQmHu8pothhsiIiKyKBxzQ0RERBaF4YaIiIgsCsMNERERWRSGGyIiIrIoDDdERERkURhuiIiIyKIw3BAREZFFYbghohZPIpHghx9+MHcZRFRPGG6IyKzGjx8PiURS6fbwww+buzQiaqa4thQRmd3DDz+Mzz//3GSbUqk0UzVE1Nyx5YaIzE6pVMLLy8vk5uzsDEDsMlq7di0GDx4Ma2trtGnTBlu3bjV5/alTp9CvXz9YW1vD1dUVkyZNQn5+vskxn332GUJCQqBUKuHt7Y3Jkyeb7M/MzMSoUaNgY2OD4OBgxMXFNeyHJqIGw3BDRE3e7Nmz8dhjj+HEiRMYN24cxo4di3PnzgEACgoKEB0dDWdnZxw6dAhbtmzBr7/+ahJe1q5di5dffhmTJk3CqVOnEBcXh7Zt25q8x/z58/HEE0/g5MmTGDJkCMaNG4fs7OxG/ZxEVE8EIiIzio2NFWQymWBra2tye+eddwRBEAQAwosvvmjymqioKOH//u//BEEQhPXr1wvOzs5Cfn6+cf9PP/0kSKVSITU1VRAEQfDx8RHeeuutamsAILz99tvG5/n5+QIA4eeff663z0lEjYdjbojI7Pr27Yu1a9eabHNxcTE+7tGjh8m+Hj164Pjx4wCAc+fOITw8HLa2tsb9vXr1gsFgwIULFyCRSJCcnIz+/fvXWENYWJjxsa2tLRwcHJCenn63H4mIzIjhhojMztbWtlI3UX2xtrau1XFWVlYmzyUSCQwGQ0OUREQNjGNuiKjJ+/vvvys979ixIwCgY8eOOHHiBAoKCoz79+3bB6lUivbt28Pe3h4BAQGIj49v1JqJyHzYckNEZqfRaJCammqyTS6Xw83NDQCwZcsWREZG4oEHHsDGjRtx8OBBfPrppwCAcePGYe7cuYiNjcW8efOQkZGBV155Bc888ww8PT0BAPPmzcOLL74IDw8PDB48GHl5edi3bx9eeeWVxv2gRNQoGG6IyOx27twJb29vk23t27fH+fPnAYhXMn399dd46aWX4O3tja+++gqdOnUCANjY2GDXrl149dVX0a1bN9jY2OCxxx7D+++/bzxXbGwsiouLsXLlSkyfPh1ubm54/PHHG+8DElGjkgiCIJi7CCKi6kgkEnz//fcYOXKkuUshomaCY26IiIjIojDcEBERkUXhmBsiatLYc05EdcWWGyIiIrIoDDdERERkURhuiIiIyKIw3BAREZFFYbghIiIii8JwQ0RERBaF4YaIiIgsCsMNERERWRSGGyIiIrIo/w+sNsplELzTHwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(train_f1_micros, label='F1_micro_train')\n",
        "ax.plot(val_f1_micros, label='F1_micro_val')\n",
        "ax.plot(train_f1_macros, label='F1_macro_train')\n",
        "ax.plot(val_f1_macros, label='F1_micro_val')\n",
        "ax.set_title(model_name)\n",
        "ax.set(xlabel='Epoch', ylabel='Loss')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pVD7IpU8HWu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "242586dd62d544a39c122c7b1ed6efc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78cb1778f71b45b88ffdb20bfe0cd66e",
              "IPY_MODEL_6d83c78727204f529982e56c3bfe32c1",
              "IPY_MODEL_55191ea6a8eb4574aff8a9bc21fdd55a"
            ],
            "layout": "IPY_MODEL_ae7f4e349b634abd8b36184774421f7a"
          }
        },
        "4146164713eb4c2db70cf52335398a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55191ea6a8eb4574aff8a9bc21fdd55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b17d80f4da05457781be26c19a1dca17",
            "placeholder": "​",
            "style": "IPY_MODEL_8e403bce502349d28da4553899f80c33",
            "value": " 160M/160M [00:00&lt;00:00, 331MB/s]"
          }
        },
        "6d83c78727204f529982e56c3bfe32c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4146164713eb4c2db70cf52335398a3e",
            "max": 167502836,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e66226838c994913b2d58fd0db3f4282",
            "value": 167502836
          }
        },
        "78cb1778f71b45b88ffdb20bfe0cd66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e012c54a3a9f48b38c500c17227f67b8",
            "placeholder": "​",
            "style": "IPY_MODEL_91eb94ac4f6347c6b7d860b73e3742da",
            "value": "100%"
          }
        },
        "8e403bce502349d28da4553899f80c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91eb94ac4f6347c6b7d860b73e3742da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae7f4e349b634abd8b36184774421f7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b17d80f4da05457781be26c19a1dca17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e012c54a3a9f48b38c500c17227f67b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e66226838c994913b2d58fd0db3f4282": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
